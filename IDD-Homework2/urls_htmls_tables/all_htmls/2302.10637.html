<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.10637] A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy</title><meta property="og:description" content="Trustworthy artificial intelligence (AI) technology has revolutionized daily life and greatly benefited human society. Among various AI technologies, Federated Learning (FL) stands out as a promising solution for diver…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.10637">

<!--Generated on Fri Mar  1 00:49:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yifei Zhang<sup id="id6.6.id1" class="ltx_sup">∗</sup>,
Dun Zeng<sup id="id7.7.id2" class="ltx_sup">∗</sup>,
Jinglong Luo<sup id="id8.8.id3" class="ltx_sup">∗</sup>,
Zenglin Xu<sup id="id9.9.id4" class="ltx_sup">†</sup>
Irwin King<sup id="id10.10.id5" class="ltx_sup">†</sup>
</span><span class="ltx_author_notes">
Yifei Zhang and Irwin King was with the Department of Computer Science and Engineering, The Chinese University of Hong Kong, ShaTin, N.T., Hong Kong SAR, China. Email: {yfzhang,king}@cse.cuhk.hk
Zeng Dun was with the University of Electronic Science and Technology of China and Peng Cheng Lab. Email: zengdun@std.uestc.edu.cn
Jinglong Luo and Zenglin Xu was Harbin Institute of Technology, Shenzhen and Peng Cheng Lab Email: luojl@pcl.ac.cn and xuzenglin@hit.edu.cn
Yifei Zhang Dun Zeng and Jinglong Luo contribute equally. Corresponding Authors are Zengling Xu and Irwin King</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p"><span id="id11.id1.1" class="ltx_text">Trustworthy artificial intelligence (AI) technology has revolutionized daily life and greatly benefited human society. Among various AI technologies, Federated Learning (FL) stands out as a promising solution for diverse real-world scenarios, ranging from risk evaluation systems in finance to cutting-edge technologies like drug discovery in life sciences. However, challenges around data isolation and privacy threaten the trustworthiness of FL systems. Adversarial attacks against data privacy, learning algorithm stability, and system confidentiality are particularly concerning in the context of distributed training in federated learning. Therefore, it is crucial to develop FL in a trustworthy manner, with a focus on security, robustness, and privacy. In this survey, we propose a comprehensive roadmap for developing trustworthy FL systems and summarize existing efforts from three key aspects: security, robustness, and privacy. We outline the threats that pose vulnerabilities to trustworthy federated learning across different stages of development, including data processing, model training, and deployment. To guide the selection of the most appropriate defense methods, we discuss specific technical solutions for realizing each aspect of Trustworthy FL (TFL). Our approach differs from previous work that primarily discusses TFL from a legal perspective or presents FL from a high-level, non-technical viewpoint.
</span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
<span id="id12.id1" class="ltx_text">
Trustworthy Federated Learning, Privacy, Robustness, Security
</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction </span>
</h2>

<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span><span id="S1.SS1.1.1" class="ltx_text ltx_font_italic">From Trustworthy AI to Trustworthy Federated Learning</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Trustworthy AI has recently received increased attention due to the need to avoid the adverse effects that AI could have on people <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib248" title="" class="ltx_ref">248</a>, <a href="#bib.bib202" title="" class="ltx_ref">202</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib190" title="" class="ltx_ref">190</a>, <a href="#bib.bib171" title="" class="ltx_ref">171</a>]</cite>. There have been ongoing efforts to promote trustworthy AI, so that people can fully trust and live in harmony with AI technologies. Among various AI technologies <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib258" title="" class="ltx_ref">258</a>, <a href="#bib.bib189" title="" class="ltx_ref">189</a>, <a href="#bib.bib253" title="" class="ltx_ref">253</a>, <a href="#bib.bib256" title="" class="ltx_ref">256</a>, <a href="#bib.bib259" title="" class="ltx_ref">259</a>, <a href="#bib.bib257" title="" class="ltx_ref">257</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, Federated Learning (FL) stands out due to the demand for data privacy and data availability in distributed environments. The core idea of FL is to generate a collaboratively trained global learning model without sharing the data owned by the distributed clients <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib238" title="" class="ltx_ref">238</a>, <a href="#bib.bib172" title="" class="ltx_ref">172</a>, <a href="#bib.bib255" title="" class="ltx_ref">255</a>]</cite>. Since its introduction in 2016 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>, FL has been widely used in various areas, including finance <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, health <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite>, business, and entertainment. However, FL is vulnerable to adversarial attacks that are mainly focused on impairing the learning model or violating data privacy, posing significant threats to FL in safety-critical environments. Therefore, people increasingly expect FL to be private, reliable, and socially beneficial enough to be trusted. In this survey, we provide a summary of these efforts from the perspective of Trustworthy Federated Learning (TFL).</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">The trustworthiness of the system is based on the concept of ”trust,” which makes the system ”worthy” of being relied on. Trust can be defined as ”the relationship between a trustor and a trustee: the trustor trusts the trustee.” In the context of TFL, we define the trustee as the FL models or systems, and the trustor as the participants in FL, users, and regulators. From the perspective of software development, an FL model is trustworthy if it is free of threats in different development stages of an FL model (<em id="S1.SS1.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.SS1.p2.1.2" class="ltx_text"></span>, data processing, model training, and deployment), with three key aspects of trustworthiness, as we will discuss later. We define TFL as being safe and private for processing personal data (Privacy), stable and robust for training the model (Robustness), and confidential and correct for deploying systems (Security), as shown in Fig. <a href="#S1.F1.sf1" title="In Figure 1 ‣ 1.1 From Trustworthy AI to Trustworthy Federated Learning ‣ 1 Introduction ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2302.10637/assets/Content/privacy/pictures/TrustworthyFL.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="183" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">The development stage of TFL.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2302.10637/assets/Content/privacy/pictures/aspect.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="520" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Aspects in TFL</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">The overall framework of Trustworthy Federated Learning (TFL).</span></figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2302.10637/assets/x1.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="72" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.3.2" class="ltx_text" style="font-size:90%;">Threats in different stages of Trustworthy Federated Learning.</span></figcaption>
</figure>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table I</span>: </span><span id="S1.T1.3.2" class="ltx_text" style="font-size:90%;">The proposed taxonomy of Trustworthy Federated Learning</span></figcaption>
<div id="S1.T1.4" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:101.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-249.6pt,58.4pt) scale(0.46488951853409,0.46488951853409) ;">
<table id="S1.T1.4.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.T1.4.1.1.1" class="ltx_tr">
<td id="S1.T1.4.1.1.1.1" class="ltx_td ltx_border_r ltx_border_tt" style="padding-top:10pt;padding-bottom:10pt;"></td>
<td id="S1.T1.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:10pt;padding-bottom:10pt;" colspan="2"><span id="S1.T1.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Data Processing</span></td>
<td id="S1.T1.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:10pt;padding-bottom:10pt;" colspan="2"><span id="S1.T1.4.1.1.1.3.1" class="ltx_text ltx_font_bold">Model Traing</span></td>
<td id="S1.T1.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:10pt;padding-bottom:10pt;" colspan="2"><span id="S1.T1.4.1.1.1.4.1" class="ltx_text ltx_font_bold">Deployment</span></td>
</tr>
<tr id="S1.T1.4.1.2.2" class="ltx_tr">
<td id="S1.T1.4.1.2.2.1" class="ltx_td ltx_border_r" style="padding-top:10pt;padding-bottom:10pt;"></td>
<td id="S1.T1.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;">Treats</td>
<td id="S1.T1.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;">Defense</td>
<td id="S1.T1.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;">Treats</td>
<td id="S1.T1.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;">Defense</td>
<td id="S1.T1.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;">Treats</td>
<td id="S1.T1.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;">Defense</td>
</tr>
<tr id="S1.T1.4.1.3.3" class="ltx_tr">
<td id="S1.T1.4.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.3.3.1.1" class="ltx_text ltx_font_bold">Security</span></td>
<td id="S1.T1.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;" rowspan="2"><span id="S1.T1.4.1.3.3.2.1" class="ltx_text">
<span id="S1.T1.4.1.3.3.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:113.8pt;">
<span id="S1.T1.4.1.3.3.2.1.1.1" class="ltx_p">Information Leakage</span>
<span id="S1.I1" class="ltx_itemize">
<span id="S1.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I1.i1.p1" class="ltx_para">
<span id="S1.I1.i1.p1.1" class="ltx_p">Data &amp; Label Leakage <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>, <a href="#bib.bib261" title="" class="ltx_ref">261</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite></span>
</span></span>
<span id="S1.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I1.i2.p1" class="ltx_para">
<span id="S1.I1.i2.p1.1" class="ltx_p">Membership Leakage  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib160" title="" class="ltx_ref">160</a>, <a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite></span>
</span></span>
<span id="S1.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I1.i3.p1" class="ltx_para">
<span id="S1.I1.i3.p1.1" class="ltx_p">Properties Leakage  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.3.3.3.1" class="ltx_text">
<span id="S1.T1.4.1.3.3.3.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:85.4pt;">
<span id="S1.I2" class="ltx_itemize">
<span id="S1.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I2.i1.p1" class="ltx_para">
<span id="S1.I2.i1.p1.1" class="ltx_p">Cryptography-based Methods
 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib154" title="" class="ltx_ref">154</a>, <a href="#bib.bib105" title="" class="ltx_ref">105</a>, <a href="#bib.bib145" title="" class="ltx_ref">145</a>, <a href="#bib.bib205" title="" class="ltx_ref">205</a>, <a href="#bib.bib206" title="" class="ltx_ref">206</a>, <a href="#bib.bib175" title="" class="ltx_ref">175</a>, <a href="#bib.bib153" title="" class="ltx_ref">153</a>, <a href="#bib.bib119" title="" class="ltx_ref">119</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib107" title="" class="ltx_ref">107</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.3.3.4.1" class="ltx_text">
<span id="S1.T1.4.1.3.3.4.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:113.8pt;">
<span id="S1.T1.4.1.3.3.4.1.1.1" class="ltx_p">Gradient Inversion Attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib261" title="" class="ltx_ref">261</a>, <a href="#bib.bib242" title="" class="ltx_ref">242</a>, <a href="#bib.bib237" title="" class="ltx_ref">237</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite></span>
</span></span></td>
<td id="S1.T1.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.3.3.5.1" class="ltx_text">
<span id="S1.T1.4.1.3.3.5.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:85.4pt;">
<span id="S1.I3" class="ltx_itemize">
<span id="S1.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I3.i1.p1" class="ltx_para">
<span id="S1.I3.i1.p1.1" class="ltx_p">Cryptography-based Methods
 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib134" title="" class="ltx_ref">134</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib228" title="" class="ltx_ref">228</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib245" title="" class="ltx_ref">245</a>, <a href="#bib.bib251" title="" class="ltx_ref">251</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib264" title="" class="ltx_ref">264</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.3.3.6.1" class="ltx_text">
<span id="S1.T1.4.1.3.3.6.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:85.4pt;">
<span id="S1.T1.4.1.3.3.6.1.1.1" class="ltx_p">Deployment Security</span>
<span id="S1.I4" class="ltx_itemize">
<span id="S1.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I4.i1.p1" class="ltx_para">
<span id="S1.I4.i1.p1.1" class="ltx_p">Data security</span>
</span></span>
<span id="S1.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I4.i2.p1" class="ltx_para">
<span id="S1.I4.i2.p1.1" class="ltx_p">Model security</span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.3.3.7.1" class="ltx_text">
<span id="S1.T1.4.1.3.3.7.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:85.4pt;">
<span id="S1.I5" class="ltx_itemize">
<span id="S1.I5.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I5.i1.p1" class="ltx_para">
<span id="S1.I5.i1.p1.1" class="ltx_p">Cryptography-based Methods
 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib174" title="" class="ltx_ref">174</a>, <a href="#bib.bib125" title="" class="ltx_ref">125</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib100" title="" class="ltx_ref">100</a>, <a href="#bib.bib142" title="" class="ltx_ref">142</a>, <a href="#bib.bib169" title="" class="ltx_ref">169</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib163" title="" class="ltx_ref">163</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib271" title="" class="ltx_ref">271</a>, <a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite></span>
</span></span>
</span>
</span></span></td>
</tr>
<tr id="S1.T1.4.1.4.4" class="ltx_tr">
<td id="S1.T1.4.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.4.4.1.1" class="ltx_text ltx_font_bold">Privacy</span></td>
<td id="S1.T1.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.4.4.2.1" class="ltx_text">
<span id="S1.T1.4.1.4.4.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:85.4pt;">
<span id="S1.I6" class="ltx_itemize">
<span id="S1.I6.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I6.i1.p1" class="ltx_para">
<span id="S1.I6.i1.p1.1" class="ltx_p">Anonymization Methods  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib202" title="" class="ltx_ref">202</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib188" title="" class="ltx_ref">188</a>, <a href="#bib.bib222" title="" class="ltx_ref">222</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib262" title="" class="ltx_ref">262</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.4.4.3.1" class="ltx_text">
<span id="S1.T1.4.1.4.4.3.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:113.8pt;">
<span id="S1.T1.4.1.4.4.3.1.1.1" class="ltx_p">Training Phase Privacy Leakage</span>
<span id="S1.I7" class="ltx_itemize">
<span id="S1.I7.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I7.i1.p1" class="ltx_para">
<span id="S1.I7.i1.p1.1" class="ltx_p">Data &amp; Label Leakage <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>, <a href="#bib.bib261" title="" class="ltx_ref">261</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite></span>
</span></span>
<span id="S1.I7.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I7.i2.p1" class="ltx_para">
<span id="S1.I7.i2.p1.1" class="ltx_p">Membership Leakage  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>, <a href="#bib.bib149" title="" class="ltx_ref">149</a>, <a href="#bib.bib160" title="" class="ltx_ref">160</a>, <a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite></span>
</span></span>
<span id="S1.I7.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I7.i3.p1" class="ltx_para">
<span id="S1.I7.i3.p1.1" class="ltx_p">Properties Leakage  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.4.4.4.1" class="ltx_text">
<span id="S1.T1.4.1.4.4.4.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:113.8pt;">
<span id="S1.I8" class="ltx_itemize">
<span id="S1.I8.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I8.i1.p1" class="ltx_para">
<span id="S1.I8.i1.p1.1" class="ltx_p">DP-based methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib132" title="" class="ltx_ref">132</a>, <a href="#bib.bib131" title="" class="ltx_ref">131</a>, <a href="#bib.bib266" title="" class="ltx_ref">266</a>]</cite></span>
</span></span>
<span id="S1.I8.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I8.i2.p1" class="ltx_para">
<span id="S1.I8.i2.p1.1" class="ltx_p">Perturbation-based Method <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib214" title="" class="ltx_ref">214</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.4.4.5.1" class="ltx_text">
<span id="S1.T1.4.1.4.4.5.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:85.4pt;">
<span id="S1.T1.4.1.4.4.5.1.1.1" class="ltx_p">Inference attack</span>
<span id="S1.I9" class="ltx_itemize">
<span id="S1.I9.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I9.i1.p1" class="ltx_para">
<span id="S1.I9.i1.p1.1" class="ltx_p">Query-based attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite></span>
</span></span>
<span id="S1.I9.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I9.i2.p1" class="ltx_para">
<span id="S1.I9.i2.p1.1" class="ltx_p">Model-based attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib186" title="" class="ltx_ref">186</a>, <a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.4.4.6.1" class="ltx_text">
<span id="S1.T1.4.1.4.4.6.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:113.8pt;">
<span id="S1.I10" class="ltx_itemize">
<span id="S1.I10.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I10.i1.p1" class="ltx_para">
<span id="S1.I10.i1.p1.1" class="ltx_p">DP-based methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite></span>
</span></span>
<span id="S1.I10.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I10.i2.p1" class="ltx_para">
<span id="S1.I10.i2.p1.1" class="ltx_p">Perturbation-based Method <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib215" title="" class="ltx_ref">215</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite></span>
</span></span>
</span>
</span></span></td>
</tr>
<tr id="S1.T1.4.1.5.5" class="ltx_tr">
<td id="S1.T1.4.1.5.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;" rowspan="2"><span id="S1.T1.4.1.5.5.1.1" class="ltx_text ltx_font_bold">Robustness</span></td>
<td id="S1.T1.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;">Non-IID Data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib265" title="" class="ltx_ref">265</a>, <a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>
</td>
<td id="S1.T1.4.1.5.5.3" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"></td>
<td id="S1.T1.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;" rowspan="2"><span id="S1.T1.4.1.5.5.4.1" class="ltx_text">
<span id="S1.T1.4.1.5.5.4.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:99.6pt;">
<span id="S1.T1.4.1.5.5.4.1.1.1" class="ltx_p">Model Poisoning</span>
<span id="S1.I11" class="ltx_itemize">
<span id="S1.I11.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I11.i1.p1" class="ltx_para">
<span id="S1.I11.i1.p1.1" class="ltx_p">Backdoor Attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib207" title="" class="ltx_ref">207</a>, <a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib221" title="" class="ltx_ref">221</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite></span>
</span></span>
<span id="S1.I11.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I11.i2.p1" class="ltx_para">
<span id="S1.I11.i2.p1.1" class="ltx_p">Byzantine Attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;" rowspan="2"><span id="S1.T1.4.1.5.5.5.1" class="ltx_text">
<span id="S1.T1.4.1.5.5.5.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:99.6pt;">
<span id="S1.I12" class="ltx_itemize">
<span id="S1.I12.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I12.i1.p1" class="ltx_para">
<span id="S1.I12.i1.p1.1" class="ltx_p">Robust Aggregation <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib220" title="" class="ltx_ref">220</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib236" title="" class="ltx_ref">236</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>, <a href="#bib.bib218" title="" class="ltx_ref">218</a>, <a href="#bib.bib157" title="" class="ltx_ref">157</a>, <a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite></span>
</span></span>
<span id="S1.I12.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I12.i2.p1" class="ltx_para">
<span id="S1.I12.i2.p1.1" class="ltx_p">Byzantine Detection <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>, <a href="#bib.bib116" title="" class="ltx_ref">116</a>, <a href="#bib.bib223" title="" class="ltx_ref">223</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib260" title="" class="ltx_ref">260</a>]</cite></span>
</span></span>
<span id="S1.I12.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I12.i3.p1" class="ltx_para">
<span id="S1.I12.i3.p1.1" class="ltx_p">Hybrid Mechanism <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib263" title="" class="ltx_ref">263</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.5.5.6" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"></td>
<td id="S1.T1.4.1.5.5.7" class="ltx_td ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"></td>
</tr>
<tr id="S1.T1.4.1.6.6" class="ltx_tr">
<td id="S1.T1.4.1.6.6.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-top:10pt;padding-bottom:10pt;"><span id="S1.T1.4.1.6.6.1.1" class="ltx_text">
<span id="S1.T1.4.1.6.6.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:85.4pt;">
<span id="S1.T1.4.1.6.6.1.1.1.1" class="ltx_p">Data Poisoning<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib200" title="" class="ltx_ref">200</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite></span>
<span id="S1.I13" class="ltx_itemize">
<span id="S1.I13.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I13.i1.p1" class="ltx_para">
<span id="S1.I13.i1.p1.1" class="ltx_p">Label Flipping Attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite></span>
</span></span>
<span id="S1.I13.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I13.i2.p1" class="ltx_para">
<span id="S1.I13.i2.p1.1" class="ltx_p">Poisoning Sample Attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite></span>
</span></span>
</span>
</span></span></td>
<td id="S1.T1.4.1.6.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-top:10pt;padding-bottom:10pt;">
<span id="S1.T1.4.1.6.6.2.1" class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:99.6pt;">
<span id="S1.I14" class="ltx_itemize">
<span id="S1.I14.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I14.i1.p1" class="ltx_para">
<span id="S1.I14.i1.p1.1" class="ltx_p">Optimization-based Methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib208" title="" class="ltx_ref">208</a>, <a href="#bib.bib166" title="" class="ltx_ref">166</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite></span>
</span></span>
<span id="S1.I14.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span> 
<span id="S1.I14.i2.p1" class="ltx_para">
<span id="S1.I14.i2.p1.1" class="ltx_p">Knowledge-based Methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>, <a href="#bib.bib181" title="" class="ltx_ref">181</a>, <a href="#bib.bib272" title="" class="ltx_ref">272</a>, <a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite></span>
</span></span>
</span>
</span>
</td>
<td id="S1.T1.4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-top:10pt;padding-bottom:10pt;">N/A</td>
<td id="S1.T1.4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:10pt;padding-bottom:10pt;">N/A</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span><span id="S1.SS2.1.1" class="ltx_text ltx_font_italic">Framework of Trustworthy Federated Learning</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Federated learning offers a more versatile approach to dealing with distributed data. It differs from traditional centralized machine learning in several ways, such as data isolation, communication, non-IID distribution, and others. These characteristics make FL unique and require different trustworthiness practices compared to general AI and other learning types <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib248" title="" class="ltx_ref">248</a>]</cite>. To provide a better understanding of our TFL framework, we will begin by briefly describing potential threats in the different stages of FL</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<ul id="S1.I15" class="ltx_itemize">
<li id="S1.I15.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I15.i1.p1" class="ltx_para">
<p id="S1.I15.i1.p1.1" class="ltx_p"><span id="S1.I15.i1.p1.1.1" class="ltx_text ltx_font_bold">Data Processing.</span>
In the data processing stage, threats arise from potential information leakage and malicious attacks on the data. For instance, malicious actors can conduct data poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib111" title="" class="ltx_ref">111</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> in FL. They may modify the labels of training samples with a specific class, resulting in poor performance of the model on this class.</p>
</div>
</li>
<li id="S1.I15.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I15.i2.p1" class="ltx_para">
<p id="S1.I15.i2.p1.1" class="ltx_p"><span id="S1.I15.i2.p1.1.1" class="ltx_text ltx_font_bold">Model Training.</span>
During the model training process, a malicious participant in FL can perform model poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib219" title="" class="ltx_ref">219</a>, <a href="#bib.bib221" title="" class="ltx_ref">221</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> by uploading designed model parameters. The global model may have low accuracy due to the poisoned local updates. In addition to model poisoning attacks, Byzantine faults <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> are also common issues in distributed learning, where the parties may behave arbitrarily and upload random updates.</p>
</div>
</li>
<li id="S1.I15.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I15.i3.p1" class="ltx_para">
<p id="S1.I15.i3.p1.1" class="ltx_p"><span id="S1.I15.i3.p1.1.1" class="ltx_text ltx_font_bold">Deployment and Inference.</span>
After the model is learned, inference attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib186" title="" class="ltx_ref">186</a>, <a href="#bib.bib140" title="" class="ltx_ref">140</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite> can be conducted on it if it is published. The server may infer sensitive information about the training data from the exchanged model parameters. For example, membership inference attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib186" title="" class="ltx_ref">186</a>, <a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite> can infer whether a specific data record was used in the training. It is worth noting that inference attacks may also occur in the learning process by the FL manager, who has access to the local updates of the parties.</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS2.p3" class="ltx_para">
<p id="S1.SS2.p3.1" class="ltx_p">Then we briefly explain the three key core aspects of trustworthiness and its associated defense methods (Table <a href="#S1.T1" title="Table I ‣ 1.1 From Trustworthy AI to Trustworthy Federated Learning ‣ 1 Introduction ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>).</p>
</div>
<div id="S1.SS2.p4" class="ltx_para">
<ul id="S1.I16" class="ltx_itemize">
<li id="S1.I16.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I16.i1.p1" class="ltx_para">
<p id="S1.I16.i1.p1.1" class="ltx_p"><span id="S1.I16.i1.p1.1.1" class="ltx_text ltx_font_bold">Privacy.</span>
Privacy refers to how private data within FL can be protected to prevent it from being leaked. It is crucial to guarantee the privacy of FL data and model parameters, which are considered confidential information belonging to their owners, and to prevent any unauthorized use of the data that can directly or indirectly identify a person or household. This data covers a wide range of information, including names, ages, genders, face images, fingerprints, etc. Commitment to privacy protection is an essential factor in determining the trustworthiness of an FL system. This is not only because of the data value but also because of regulatory and legal requirements.</p>
</div>
</li>
<li id="S1.I16.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I16.i2.p1" class="ltx_para">
<p id="S1.I16.i2.p1.1" class="ltx_p"><span id="S1.I16.i2.p1.1.1" class="ltx_text ltx_font_bold">Robustness.</span>
Robustness refers to the ability of FL to remain stable under extreme conditions, particularly those created by attackers. This is essential because real environments where FL systems are deployed are usually complex and volatile. Robustness is a vital factor that affects the performance of FL systems in empirical environments. The lack of robustness may also cause unintended or harmful behavior by the system, thereby diminishing its trustworthiness.</p>
</div>
</li>
<li id="S1.I16.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I16.i3.p1" class="ltx_para">
<p id="S1.I16.i3.p1.1" class="ltx_p"><span id="S1.I16.i3.p1.1.1" class="ltx_text ltx_font_bold">Security.</span>
Security refers to the protective measures taken to prevent unauthorized users from gaining access to data. The core of security is to ensure that unauthorized users cannot access sensitive data. Therefore, the security of FL aims to ensure the confidentiality and correctness of computational data. Specifically, this data includes training and prediction data, intermediate parameters, and the results of the trained model. Unlike privacy, which targets individuals, security focuses more on systems, institutions, and the public interest.
</p>
</div>
</li>
</ul>
<p id="S1.SS2.p4.1" class="ltx_p">It is worth noting that previous works on FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib238" title="" class="ltx_ref">238</a>, <a href="#bib.bib232" title="" class="ltx_ref">232</a>]</cite> often use the terms privacy and security indiscriminately and refer to them as privacy-preserving federated learning (PPFL). However, these two concepts have different guarantees for TFL, and we aim to clarify the distinction between them. In TFL, security guarantees the confidentiality and correctness of the system. Protection is necessary to ensure that attackers cannot access the internal TFL, such as weight, gradients, and other sensitive information. On the other hand, privacy in TFL indicates how private information within FL can be protected to prevent it from being leaked. Some studies have found that private information, such as data records, proprieties, and membership, can be retrieved from the weight and gradient. Thus, privacy guarantees that even if attackers can access the internal TFL, such as weight, model, gradients, <em id="S1.SS2.p4.1.1" class="ltx_emph ltx_font_italic">etc</em>.<span id="S1.SS2.p4.1.2" class="ltx_text"></span>, private information can still be preserved.</p>
</div>
<div id="S1.SS2.p5" class="ltx_para">
<p id="S1.SS2.p5.1" class="ltx_p">Our survey focuses on providing technical solutions for each aspect of TFL in different development stages. This perspective sets it apart from recent related works, such as government guidelines <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite> that suggest building TFL systems through laws and regulations or reviews <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite> that discuss TFL realization from a high-level, non-technical perspective. Our main contributions are:</p>
</div>
<div id="S1.SS2.p6" class="ltx_para">
<ul id="S1.I17" class="ltx_itemize">
<li id="S1.I17.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I17.i1.p1" class="ltx_para">
<p id="S1.I17.i1.p1.1" class="ltx_p">We present a synopsis of threats and defense approaches for the core aspects of TFL (<em id="S1.I17.i1.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.I17.i1.p1.1.2" class="ltx_text"></span>, privacy, robustness, and security) in different development stages of FL (<em id="S1.I17.i1.p1.1.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S1.I17.i1.p1.1.4" class="ltx_text"></span>, data processing, model training, and deployment) to provide a general picture of the field of Trustworthy Federated Learning.</p>
</div>
</li>
<li id="S1.I17.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I17.i2.p1" class="ltx_para">
<p id="S1.I17.i2.p1.1" class="ltx_p">We discuss the challenges of trustworthiness in FL, clarify existing gaps, identify open research problems, and indicate future research directions.</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS2.p7" class="ltx_para">
<p id="S1.SS2.p7.1" class="ltx_p">In the remaining sections, we organize the survey as follows: In Section <a href="#S2" title="2 Threats in Trustworthy Federated Learning ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we provide an overview of existing threats in the TFL system to help readers understand the risks involved in building a TFL system from a software development perspective. In Section <a href="#S3" title="3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we detail the aspect of security, which ensures the confidentiality and correctness of computational data in TFL. In Section <a href="#S4" title="4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we detail the aspect of robustness, which makes a TFL system robust to the noisy perturbations of inputs and enables it to make trustworthy decisions. In Section <a href="#S5" title="5 Privacy ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we present the dimension of privacy, which guarantees a TFL system avoids leaking any private information.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Threats in Trustworthy Federated Learning</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Potential threats exist in all phases of federal learning, harming the trustworthiness of the system. The distribute nature of FL makes it vulnerable to information leakage and adversarial attack. In this section, we summarize and compare the existing studies on FL threats according to the aspects considered in Section <a href="#S1" title="1 Introduction ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span id="S2.SS1.1.1" class="ltx_text ltx_font_italic">Threats in Data Processing of Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">One main vulnerable stage of FL is the data processing. At this stage, raw data is cleaned, processed, and transformed into features that can be accepted by machine learning model. Due to the distributed nature of federated learning, Non-iid data and information leakage are common treats in unprotected FL environment. Meanwhile, malicious can to harm the model by sending poisoned data during data processing. In what follows, we summarize the potential threats in the data processing phase.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Information Leakage.</span> Information leakage exists in the data processing stages even if there is no direct data exchange in FL. In federal learning, although data is not directly involved in communication, the exchanged model parameters and gradients still contain private information. In the absence of data protection (<em id="S2.SS1.p2.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.SS1.p2.1.3" class="ltx_text"></span>, encryption, perturbation, or anonymization), a direct exchange of model and gradient derived from the local data causes privacy leaks. A number of studies show that the raw record, membership, and properties can be inferred from weight and gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib270" title="" class="ltx_ref">270</a>, <a href="#bib.bib261" title="" class="ltx_ref">261</a>]</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Non-IID Data.</span>
Due to distributed setting of FL, the data are preserved on isolated devices/institutions and cannot be centralized. Hence, the data samples are generated in various devices/institutions where the source distributions can be None Independent and Identically Distributed (None-IID) in many ways <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. A number of studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib265" title="" class="ltx_ref">265</a>, <a href="#bib.bib268" title="" class="ltx_ref">268</a>]</cite> have indicated that the performance drop of FL in Non-IID settings is inevitable. The divergence of local updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib265" title="" class="ltx_ref">265</a>]</cite> continues to accumulate, slowing down the model convergence and weakening model performance.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">Data Poisoning Attack.</span>
Data poisoning occurs during the data pre-processing step. The adversary adds a number of data samples to the training set with goal of miss classify the target label.
The label-flipping attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> is a common example. It does not change the data properties, but make the the target labels to another class.
For instance, hostile users can poison their data by replacing all labels of “apple” with labels of “banana”. As a result, the trained classifier cannot correctly categorize “apple” and it will incorrectly expect “apple” to be “banana”.
<cite class="ltx_cite ltx_citemacro_citet">Gu et al. [<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> design another practical poisoning attack called backdoor attacks.
In this scenario, an attacker can alter specific features or subsections of the original training dataset to implant backdoors into the model, so that the model responds according to the adversary’s intent if the input contains the backdoor features.
This kind of attack is difficult to identify as the performance of the poisoned model with clean inputs remains mostly unchanged.
Note that any FL clients are capable of launching a data poisoning attack.
The impact on the FL model is dependent on the frequency of the engagement of clients in attacks and the quantity of tainted training data.
</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span id="S2.SS2.1.1" class="ltx_text ltx_font_italic">Threats in Model Training of Federated Learning</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_bold">Model Poisoning Attack.</span>
Model poisoning attacks are intended to poison local updates before they are communicated to the server or to implant hidden backdoors inside the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
Because models are continuously updated, it is believed that model poisoning attacks more effective compared to data poisoning attacks.
Depending on the objectives of the attack, there are two types of poisoning-based attacks (<em id="S2.SS2.p1.1.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S2.SS2.p1.1.3" class="ltx_text"></span>, untargeted and targeted attacks).
In targeted model poisoning, the adversary seeks to induce the FL model to misclassify a collection of specified inputs with high probability.
The poisoned updates can be injected via manipulating the training process or generated by incorporating hidden backdoors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Bagdasaryan et al. [<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> shows the simple single-shot attack could be sufficient to harm the FL model. In untargeted attack poisoning, the adversary seeks to undermine the performance of the FL model. In a byzantine attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite>, the adversary players change their outputs to have the same distribution as the right model updates in order to evade detection. It behaves completely arbitrarily to diminish model performance.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Privacy Leakage and Communication Eavesdropping.</span>
Information leakage and communication eavesdropping are common issue during the training process, especially during weight and gradient updates.
It is important to note that information leakage is a privacy threat, whereas communication eavesdropping is a security threat.
In FL, three types of data must be transferred between clinets and server: weight, gradients, and final model.
Each of these data formats contains sensitive information about the training datasets that can be intercepted and utilized to reveal sensitive information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib240" title="" class="ltx_ref">240</a>]</cite>.
Clients communicate gradients/weights to the server, which collects them and returns them to clients for model updating in gradient/weight-update-based FL systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>.
Gradients are commonly calculated in deep neural network models by back-propagating throughout the whole network.
Specifically, the gradient is compute via the current layer activation and the error propagate fromt the loss. in the same way, the local model weight is update using the gradients compute form the local dataset. As a result, weight updating, gradient updating, and final model) may contain sensitive details about local data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib192" title="" class="ltx_ref">192</a>, <a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span><span id="S2.SS3.1.1" class="ltx_text ltx_font_italic">Threats in Development of Federated Learning</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.p1.1" class="ltx_p"><span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_bold">Inference Phase Data Security.</span>
In the phase of deployment or inference, the task initiator usually deploys the carefully-trained model to the cloud server to provide prediction services and get the related payment. The model parameters, as the intellectual property of the model owner, need to be effectively protected in order to continuously generate value. However, the curious cloud server may steal the model parameters during the deployment process.
Furthermore, to accomplish the prediction task, users need to upload their data, which may contain sensitive information such as gender, age, health status, <em id="S2.SS3.p1.1.2" class="ltx_emph ltx_font_italic">etc</em>.<span id="S2.SS3.p1.1.3" class="ltx_text"></span> being exposed to the cloud server. A lot of work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib174" title="" class="ltx_ref">174</a>, <a href="#bib.bib125" title="" class="ltx_ref">125</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib100" title="" class="ltx_ref">100</a>, <a href="#bib.bib142" title="" class="ltx_ref">142</a>, <a href="#bib.bib169" title="" class="ltx_ref">169</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib163" title="" class="ltx_ref">163</a>, <a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib271" title="" class="ltx_ref">271</a>, <a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite> emerged in order to address data leakage in the inference phase, and we will describe these studies in detail afterwards.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">Inference Phase Attack.</span>
The inference phase focuses on determining how to provide the query service to consumers, and it is also vulnerable to inference attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib185" title="" class="ltx_ref">185</a>, <a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>.
This kind of attack is launched in the inference phase after the model has been trained, which is usually referred to as an evasive or exploratory attack.
In general, the purpose of an inference attack is to produce inaccurate predictions or collect information about the model’s attributes rather than to alert the trained model. The threat during the inference phase is mostly associated with the final model, which is either published to clients or provided as an API for external users.
There are two key threats associated with inference attacks: (1) Model-based attacks and (2) Query-based attacks. Attackers have access to the model parameters and thus the query results as well as any intermediate computations, they can extract sensitive information about the participants’ training datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib249" title="" class="ltx_ref">249</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Security </span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, TFL is introduced from a security perspective, and we refer to these studies as Secure Federation Learning (SFL). Specifically, SFL guarantee the confidentiality and integrity of data and model during FL training and inference by employing secure computing include Secure Multi-Party Computation (SMPC) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib234" title="" class="ltx_ref">234</a>, <a href="#bib.bib235" title="" class="ltx_ref">235</a>]</cite> and Homomorphic Encryption (HE) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In Section <a href="#S3.SS1" title="3.1 The Definition of Secure Federated Learning ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, We first analyze the threats that exist in SFL and give a formal definition of SFL based on this.
Subsequently the secure computing techniques used to address the threats present in SFL are presented in Section <a href="#S3.SS2" title="3.2 Defense Methods in Secure Federate Learning ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. Finally, we provide an overview of SFL research works in terms of data security, model security, and system security in Section <a href="#S3.SS3" title="3.3 Secure Federated Learning Works ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span id="S3.SS1.1.1" class="ltx_text ltx_font_italic">The Definition of Secure Federated Learning</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In this section, we describe the threat models present in the FL training and prediction process and give the definition of SFL based on these threat models. Specifically, there are different threats to FL in different scenarios. These threats can be abstracted into different threat models. An SFL algorithm is secure under a certain threat model means that it can resist all attacks under that threat model.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The threat model of SFL can be divided into a semi-honest (passive) model and a malicious (active) model according to the system’s tolerance to the adversary’s capabilities. Specifically, under the assumption of a semi-honest model, the adversary will perform operations according to the protocol but tries to mine the private data of other participants through the information obtained in the process of executing the SFL protocol. And the security of SFL under the semi-honest model requires that the user’s private information is not available to the adversary. Unlike the semi-honest model, in the malicious model the adversary will violate the protocol in order to obtain private data.
The security of SFL under the malicious model also requires that the user’s private data is not available to the adversary. In addition, the security strengths of the SFL algorithms, sorted from weak to strong, are: abort, fair, and guaranteed output delivery (GOD). In detail, abort means that the security detects malicious behavior and terminates the protocol. Fairness means that the dishonest participant can get the output when and only when the honest participant gets the output result in the secure computing protocol. The GOD means that the dishonest participant cannot prevent the honest participant from obtaining the output during protocol execution.
Furthermore, the threat model of SFL can be divided into honest-majority and dishonest-majority according to the percentage of participants controlled by the adversary in the system. Specifically, the number of adversary-controlled participants in the honest majority model is less than half of the total number of participants. In contrast, in the dishonest majority model, the number of participants controlled by the adversary is greater than or equal to half of the total number of participants. Based on the threat model of SFL, we give the following definition of SFL.</p>
</div>
<div id="S3.Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="S3.Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition 3.1</span></span></h6>
<div id="S3.Thmdefinition1.p1" class="ltx_para">
<p id="S3.Thmdefinition1.p1.1" class="ltx_p"><span id="S3.Thmdefinition1.p1.1.1" class="ltx_text ltx_font_italic">The training process of FL can be seen as a function of <math id="S3.Thmdefinition1.p1.1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.Thmdefinition1.p1.1.1.m1.1a"><mi id="S3.Thmdefinition1.p1.1.1.m1.1.1" xref="S3.Thmdefinition1.p1.1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.1.1.m1.1b"><ci id="S3.Thmdefinition1.p1.1.1.m1.1.1.cmml" xref="S3.Thmdefinition1.p1.1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.1.1.m1.1c">m</annotation></semantics></math>-ary functionality, denoted by</span></p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.5" class="ltx_Math" alttext="f:(\{0,1\}^{*})m\rightarrow(\{0,1\}^{*})m." display="block"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5.1" xref="S3.E1.m1.5.5.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1" xref="S3.E1.m1.5.5.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.4" xref="S3.E1.m1.5.5.1.1.4.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="S3.E1.m1.5.5.1.1.3" xref="S3.E1.m1.5.5.1.1.3.cmml">:</mo><mrow id="S3.E1.m1.5.5.1.1.2" xref="S3.E1.m1.5.5.1.1.2.cmml"><mrow id="S3.E1.m1.5.5.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.1.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E1.m1.5.5.1.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.1.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.2.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.1.cmml">{</mo><mn id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">0</mn><mo id="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.1.cmml">,</mo><mn id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.2.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.1.cmml">}</mo></mrow><mo id="S3.E1.m1.5.5.1.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.3.cmml">∗</mo></msup><mo stretchy="false" id="S3.E1.m1.5.5.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.5.5.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.3.cmml">m</mi></mrow><mo stretchy="false" id="S3.E1.m1.5.5.1.1.2.3" xref="S3.E1.m1.5.5.1.1.2.3.cmml">→</mo><mrow id="S3.E1.m1.5.5.1.1.2.2" xref="S3.E1.m1.5.5.1.1.2.2.cmml"><mrow id="S3.E1.m1.5.5.1.1.2.2.1.1" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.1.1.2.2.1.1.2" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.cmml">(</mo><msup id="S3.E1.m1.5.5.1.1.2.2.1.1.1" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.cmml"><mrow id="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.2" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.1.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.2.1" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.1.cmml">{</mo><mn id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">0</mn><mo id="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.2.2" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.1.cmml">,</mo><mn id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">1</mn><mo stretchy="false" id="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.2.3" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.1.cmml">}</mo></mrow><mo id="S3.E1.m1.5.5.1.1.2.2.1.1.1.3" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.3.cmml">∗</mo></msup><mo stretchy="false" id="S3.E1.m1.5.5.1.1.2.2.1.1.3" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.1.1.2.2.2" xref="S3.E1.m1.5.5.1.1.2.2.2.cmml">​</mo><mi id="S3.E1.m1.5.5.1.1.2.2.3" xref="S3.E1.m1.5.5.1.1.2.2.3.cmml">m</mi></mrow></mrow></mrow><mo lspace="0em" id="S3.E1.m1.5.5.1.2" xref="S3.E1.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.1.1.cmml" xref="S3.E1.m1.5.5.1"><ci id="S3.E1.m1.5.5.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.3">:</ci><ci id="S3.E1.m1.5.5.1.1.4.cmml" xref="S3.E1.m1.5.5.1.1.4">𝑓</ci><apply id="S3.E1.m1.5.5.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.2"><ci id="S3.E1.m1.5.5.1.1.2.3.cmml" xref="S3.E1.m1.5.5.1.1.2.3">→</ci><apply id="S3.E1.m1.5.5.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1"><times id="S3.E1.m1.5.5.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.2"></times><apply id="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1">superscript</csymbol><set id="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.2"><cn type="integer" id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">0</cn><cn type="integer" id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">1</cn></set><times id="S3.E1.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.3"></times></apply><ci id="S3.E1.m1.5.5.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.3">𝑚</ci></apply><apply id="S3.E1.m1.5.5.1.1.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2.2"><times id="S3.E1.m1.5.5.1.1.2.2.2.cmml" xref="S3.E1.m1.5.5.1.1.2.2.2"></times><apply id="S3.E1.m1.5.5.1.1.2.2.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.2.2.1.1">superscript</csymbol><set id="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.2.2"><cn type="integer" id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">0</cn><cn type="integer" id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">1</cn></set><times id="S3.E1.m1.5.5.1.1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.2.2.1.1.1.3"></times></apply><ci id="S3.E1.m1.5.5.1.1.2.2.3.cmml" xref="S3.E1.m1.5.5.1.1.2.2.3">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">f:(\{0,1\}^{*})m\rightarrow(\{0,1\}^{*})m.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.Thmdefinition1.p1.11" class="ltx_p"><span id="S3.Thmdefinition1.p1.11.10" class="ltx_text ltx_font_italic">Specifically, <math id="S3.Thmdefinition1.p1.2.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.Thmdefinition1.p1.2.1.m1.1a"><mi id="S3.Thmdefinition1.p1.2.1.m1.1.1" xref="S3.Thmdefinition1.p1.2.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.2.1.m1.1b"><ci id="S3.Thmdefinition1.p1.2.1.m1.1.1.cmml" xref="S3.Thmdefinition1.p1.2.1.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.2.1.m1.1c">f</annotation></semantics></math> is a random process mapping string sequences of the form <math id="S3.Thmdefinition1.p1.3.2.m2.3" class="ltx_Math" alttext="x=(x_{1},\dots,x_{m})" display="inline"><semantics id="S3.Thmdefinition1.p1.3.2.m2.3a"><mrow id="S3.Thmdefinition1.p1.3.2.m2.3.3" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.cmml"><mi id="S3.Thmdefinition1.p1.3.2.m2.3.3.4" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.4.cmml">x</mi><mo id="S3.Thmdefinition1.p1.3.2.m2.3.3.3" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.3.cmml">=</mo><mrow id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.3" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.3.cmml">(</mo><msub id="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1" xref="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.cmml"><mi id="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.2" xref="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.2.cmml">x</mi><mn id="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.3" xref="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.4" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.Thmdefinition1.p1.3.2.m2.1.1" xref="S3.Thmdefinition1.p1.3.2.m2.1.1.cmml">…</mi><mo id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.5" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.3.cmml">,</mo><msub id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.cmml"><mi id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.2" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.2.cmml">x</mi><mi id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.3" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.6" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.3.2.m2.3b"><apply id="S3.Thmdefinition1.p1.3.2.m2.3.3.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3"><eq id="S3.Thmdefinition1.p1.3.2.m2.3.3.3.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.3"></eq><ci id="S3.Thmdefinition1.p1.3.2.m2.3.3.4.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.4">𝑥</ci><vector id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.3.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2"><apply id="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.1.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.2.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.3.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.Thmdefinition1.p1.3.2.m2.1.1.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.1.1">…</ci><apply id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.1.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.2.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.2">𝑥</ci><ci id="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.3.cmml" xref="S3.Thmdefinition1.p1.3.2.m2.3.3.2.2.2.3">𝑚</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.3.2.m2.3c">x=(x_{1},\dots,x_{m})</annotation></semantics></math> into sequences of random variables, <math id="S3.Thmdefinition1.p1.4.3.m3.5" class="ltx_Math" alttext="f_{1}(x),\dots,f_{m}(x)" display="inline"><semantics id="S3.Thmdefinition1.p1.4.3.m3.5a"><mrow id="S3.Thmdefinition1.p1.4.3.m3.5.5.2" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.3.cmml"><mrow id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.cmml"><msub id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.cmml"><mi id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.2" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.2.cmml">f</mi><mn id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.3" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.1" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.1.cmml">​</mo><mrow id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.3.2" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.cmml"><mo stretchy="false" id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.3.2.1" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.cmml">(</mo><mi id="S3.Thmdefinition1.p1.4.3.m3.1.1" xref="S3.Thmdefinition1.p1.4.3.m3.1.1.cmml">x</mi><mo stretchy="false" id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.3.2.2" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.3" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.3.cmml">,</mo><mi mathvariant="normal" id="S3.Thmdefinition1.p1.4.3.m3.3.3" xref="S3.Thmdefinition1.p1.4.3.m3.3.3.cmml">…</mi><mo id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.4" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.3.cmml">,</mo><mrow id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.cmml"><msub id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.cmml"><mi id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.2" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.2.cmml">f</mi><mi id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.3" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.1" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.1.cmml">​</mo><mrow id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.3.2" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.cmml"><mo stretchy="false" id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.3.2.1" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.cmml">(</mo><mi id="S3.Thmdefinition1.p1.4.3.m3.2.2" xref="S3.Thmdefinition1.p1.4.3.m3.2.2.cmml">x</mi><mo stretchy="false" id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.3.2.2" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.4.3.m3.5b"><list id="S3.Thmdefinition1.p1.4.3.m3.5.5.3.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2"><apply id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1"><times id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.1.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.1"></times><apply id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.1.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2">subscript</csymbol><ci id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.2.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.2">𝑓</ci><cn type="integer" id="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.3.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.4.4.1.1.2.3">1</cn></apply><ci id="S3.Thmdefinition1.p1.4.3.m3.1.1.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.1.1">𝑥</ci></apply><ci id="S3.Thmdefinition1.p1.4.3.m3.3.3.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.3.3">…</ci><apply id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2"><times id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.1.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.1"></times><apply id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.1.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2">subscript</csymbol><ci id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.2.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.2">𝑓</ci><ci id="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.3.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.5.5.2.2.2.3">𝑚</ci></apply><ci id="S3.Thmdefinition1.p1.4.3.m3.2.2.cmml" xref="S3.Thmdefinition1.p1.4.3.m3.2.2">𝑥</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.4.3.m3.5c">f_{1}(x),\dots,f_{m}(x)</annotation></semantics></math> such that, for every <math id="S3.Thmdefinition1.p1.5.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.Thmdefinition1.p1.5.4.m4.1a"><mi id="S3.Thmdefinition1.p1.5.4.m4.1.1" xref="S3.Thmdefinition1.p1.5.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.5.4.m4.1b"><ci id="S3.Thmdefinition1.p1.5.4.m4.1.1.cmml" xref="S3.Thmdefinition1.p1.5.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.5.4.m4.1c">i</annotation></semantics></math>, the <math id="S3.Thmdefinition1.p1.6.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.Thmdefinition1.p1.6.5.m5.1a"><mi id="S3.Thmdefinition1.p1.6.5.m5.1.1" xref="S3.Thmdefinition1.p1.6.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.6.5.m5.1b"><ci id="S3.Thmdefinition1.p1.6.5.m5.1.1.cmml" xref="S3.Thmdefinition1.p1.6.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.6.5.m5.1c">i</annotation></semantics></math>-th party <math id="S3.Thmdefinition1.p1.7.6.m6.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S3.Thmdefinition1.p1.7.6.m6.1a"><msub id="S3.Thmdefinition1.p1.7.6.m6.1.1" xref="S3.Thmdefinition1.p1.7.6.m6.1.1.cmml"><mi id="S3.Thmdefinition1.p1.7.6.m6.1.1.2" xref="S3.Thmdefinition1.p1.7.6.m6.1.1.2.cmml">P</mi><mi id="S3.Thmdefinition1.p1.7.6.m6.1.1.3" xref="S3.Thmdefinition1.p1.7.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.7.6.m6.1b"><apply id="S3.Thmdefinition1.p1.7.6.m6.1.1.cmml" xref="S3.Thmdefinition1.p1.7.6.m6.1.1"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.7.6.m6.1.1.1.cmml" xref="S3.Thmdefinition1.p1.7.6.m6.1.1">subscript</csymbol><ci id="S3.Thmdefinition1.p1.7.6.m6.1.1.2.cmml" xref="S3.Thmdefinition1.p1.7.6.m6.1.1.2">𝑃</ci><ci id="S3.Thmdefinition1.p1.7.6.m6.1.1.3.cmml" xref="S3.Thmdefinition1.p1.7.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.7.6.m6.1c">P_{i}</annotation></semantics></math> who initially holds an input <math id="S3.Thmdefinition1.p1.8.7.m7.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.Thmdefinition1.p1.8.7.m7.1a"><msub id="S3.Thmdefinition1.p1.8.7.m7.1.1" xref="S3.Thmdefinition1.p1.8.7.m7.1.1.cmml"><mi id="S3.Thmdefinition1.p1.8.7.m7.1.1.2" xref="S3.Thmdefinition1.p1.8.7.m7.1.1.2.cmml">x</mi><mi id="S3.Thmdefinition1.p1.8.7.m7.1.1.3" xref="S3.Thmdefinition1.p1.8.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.8.7.m7.1b"><apply id="S3.Thmdefinition1.p1.8.7.m7.1.1.cmml" xref="S3.Thmdefinition1.p1.8.7.m7.1.1"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.8.7.m7.1.1.1.cmml" xref="S3.Thmdefinition1.p1.8.7.m7.1.1">subscript</csymbol><ci id="S3.Thmdefinition1.p1.8.7.m7.1.1.2.cmml" xref="S3.Thmdefinition1.p1.8.7.m7.1.1.2">𝑥</ci><ci id="S3.Thmdefinition1.p1.8.7.m7.1.1.3.cmml" xref="S3.Thmdefinition1.p1.8.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.8.7.m7.1c">x_{i}</annotation></semantics></math>, wishes to obtain the <math id="S3.Thmdefinition1.p1.9.8.m8.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.Thmdefinition1.p1.9.8.m8.1a"><mi id="S3.Thmdefinition1.p1.9.8.m8.1.1" xref="S3.Thmdefinition1.p1.9.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.9.8.m8.1b"><ci id="S3.Thmdefinition1.p1.9.8.m8.1.1.cmml" xref="S3.Thmdefinition1.p1.9.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.9.8.m8.1c">i</annotation></semantics></math>-th element in <math id="S3.Thmdefinition1.p1.10.9.m9.3" class="ltx_Math" alttext="f(x_{1},\dots,x_{m})" display="inline"><semantics id="S3.Thmdefinition1.p1.10.9.m9.3a"><mrow id="S3.Thmdefinition1.p1.10.9.m9.3.3" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.cmml"><mi id="S3.Thmdefinition1.p1.10.9.m9.3.3.4" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.Thmdefinition1.p1.10.9.m9.3.3.3" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.3.cmml">​</mo><mrow id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.3.cmml"><mo stretchy="false" id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.3" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.3.cmml">(</mo><msub id="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1" xref="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.cmml"><mi id="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.2" xref="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.2.cmml">x</mi><mn id="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.3" xref="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.4" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.Thmdefinition1.p1.10.9.m9.1.1" xref="S3.Thmdefinition1.p1.10.9.m9.1.1.cmml">…</mi><mo id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.5" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.3.cmml">,</mo><msub id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.cmml"><mi id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.2" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.2.cmml">x</mi><mi id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.3" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.6" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.10.9.m9.3b"><apply id="S3.Thmdefinition1.p1.10.9.m9.3.3.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3"><times id="S3.Thmdefinition1.p1.10.9.m9.3.3.3.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.3"></times><ci id="S3.Thmdefinition1.p1.10.9.m9.3.3.4.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.4">𝑓</ci><vector id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.3.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2"><apply id="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.1.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1">subscript</csymbol><ci id="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.2.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.3.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.2.2.1.1.1.3">1</cn></apply><ci id="S3.Thmdefinition1.p1.10.9.m9.1.1.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.1.1">…</ci><apply id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.1.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2">subscript</csymbol><ci id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.2.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.2">𝑥</ci><ci id="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.3.cmml" xref="S3.Thmdefinition1.p1.10.9.m9.3.3.2.2.2.3">𝑚</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.10.9.m9.3c">f(x_{1},\dots,x_{m})</annotation></semantics></math> which is denoted by <math id="S3.Thmdefinition1.p1.11.10.m10.3" class="ltx_Math" alttext="f_{i}(x_{1},\dots,x_{m})" display="inline"><semantics id="S3.Thmdefinition1.p1.11.10.m10.3a"><mrow id="S3.Thmdefinition1.p1.11.10.m10.3.3" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.cmml"><msub id="S3.Thmdefinition1.p1.11.10.m10.3.3.4" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.4.cmml"><mi id="S3.Thmdefinition1.p1.11.10.m10.3.3.4.2" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.4.2.cmml">f</mi><mi id="S3.Thmdefinition1.p1.11.10.m10.3.3.4.3" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.4.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.Thmdefinition1.p1.11.10.m10.3.3.3" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.3.cmml">​</mo><mrow id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.3.cmml"><mo stretchy="false" id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.3" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.3.cmml">(</mo><msub id="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1" xref="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.cmml"><mi id="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.2" xref="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.2.cmml">x</mi><mn id="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.3" xref="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.4" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.Thmdefinition1.p1.11.10.m10.1.1" xref="S3.Thmdefinition1.p1.11.10.m10.1.1.cmml">…</mi><mo id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.5" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.3.cmml">,</mo><msub id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.cmml"><mi id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.2" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.2.cmml">x</mi><mi id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.3" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.6" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.11.10.m10.3b"><apply id="S3.Thmdefinition1.p1.11.10.m10.3.3.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3"><times id="S3.Thmdefinition1.p1.11.10.m10.3.3.3.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.3"></times><apply id="S3.Thmdefinition1.p1.11.10.m10.3.3.4.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.4"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.11.10.m10.3.3.4.1.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.4">subscript</csymbol><ci id="S3.Thmdefinition1.p1.11.10.m10.3.3.4.2.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.4.2">𝑓</ci><ci id="S3.Thmdefinition1.p1.11.10.m10.3.3.4.3.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.4.3">𝑖</ci></apply><vector id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.3.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2"><apply id="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.1.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1">subscript</csymbol><ci id="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.2.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.3.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.2.2.1.1.1.3">1</cn></apply><ci id="S3.Thmdefinition1.p1.11.10.m10.1.1.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.1.1">…</ci><apply id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.1.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2">subscript</csymbol><ci id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.2.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.2">𝑥</ci><ci id="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.3.cmml" xref="S3.Thmdefinition1.p1.11.10.m10.3.3.2.2.2.3">𝑚</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.11.10.m10.3c">f_{i}(x_{1},\dots,x_{m})</annotation></semantics></math>. The inference process of FL can be seen as a function of one-ary functionality, denoted by</span></p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.5" class="ltx_Math" alttext="g:\{0,1\}^{*}\rightarrow\{0,1\}^{*}." display="block"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5.1" xref="S3.E2.m1.5.5.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1" xref="S3.E2.m1.5.5.1.1.cmml"><mi id="S3.E2.m1.5.5.1.1.2" xref="S3.E2.m1.5.5.1.1.2.cmml">g</mi><mo lspace="0.278em" rspace="0.278em" id="S3.E2.m1.5.5.1.1.1" xref="S3.E2.m1.5.5.1.1.1.cmml">:</mo><mrow id="S3.E2.m1.5.5.1.1.3" xref="S3.E2.m1.5.5.1.1.3.cmml"><msup id="S3.E2.m1.5.5.1.1.3.2" xref="S3.E2.m1.5.5.1.1.3.2.cmml"><mrow id="S3.E2.m1.5.5.1.1.3.2.2.2" xref="S3.E2.m1.5.5.1.1.3.2.2.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.3.2.2.2.1" xref="S3.E2.m1.5.5.1.1.3.2.2.1.cmml">{</mo><mn id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">0</mn><mo id="S3.E2.m1.5.5.1.1.3.2.2.2.2" xref="S3.E2.m1.5.5.1.1.3.2.2.1.cmml">,</mo><mn id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.E2.m1.5.5.1.1.3.2.2.2.3" xref="S3.E2.m1.5.5.1.1.3.2.2.1.cmml">}</mo></mrow><mo id="S3.E2.m1.5.5.1.1.3.2.3" xref="S3.E2.m1.5.5.1.1.3.2.3.cmml">∗</mo></msup><mo stretchy="false" id="S3.E2.m1.5.5.1.1.3.1" xref="S3.E2.m1.5.5.1.1.3.1.cmml">→</mo><msup id="S3.E2.m1.5.5.1.1.3.3" xref="S3.E2.m1.5.5.1.1.3.3.cmml"><mrow id="S3.E2.m1.5.5.1.1.3.3.2.2" xref="S3.E2.m1.5.5.1.1.3.3.2.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.1.1.3.3.2.2.1" xref="S3.E2.m1.5.5.1.1.3.3.2.1.cmml">{</mo><mn id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">0</mn><mo id="S3.E2.m1.5.5.1.1.3.3.2.2.2" xref="S3.E2.m1.5.5.1.1.3.3.2.1.cmml">,</mo><mn id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">1</mn><mo stretchy="false" id="S3.E2.m1.5.5.1.1.3.3.2.2.3" xref="S3.E2.m1.5.5.1.1.3.3.2.1.cmml">}</mo></mrow><mo id="S3.E2.m1.5.5.1.1.3.3.3" xref="S3.E2.m1.5.5.1.1.3.3.3.cmml">∗</mo></msup></mrow></mrow><mo lspace="0em" id="S3.E2.m1.5.5.1.2" xref="S3.E2.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.1.1.cmml" xref="S3.E2.m1.5.5.1"><ci id="S3.E2.m1.5.5.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1">:</ci><ci id="S3.E2.m1.5.5.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2">𝑔</ci><apply id="S3.E2.m1.5.5.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.3"><ci id="S3.E2.m1.5.5.1.1.3.1.cmml" xref="S3.E2.m1.5.5.1.1.3.1">→</ci><apply id="S3.E2.m1.5.5.1.1.3.2.cmml" xref="S3.E2.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.1.1.3.2.1.cmml" xref="S3.E2.m1.5.5.1.1.3.2">superscript</csymbol><set id="S3.E2.m1.5.5.1.1.3.2.2.1.cmml" xref="S3.E2.m1.5.5.1.1.3.2.2.2"><cn type="integer" id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">0</cn><cn type="integer" id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">1</cn></set><times id="S3.E2.m1.5.5.1.1.3.2.3.cmml" xref="S3.E2.m1.5.5.1.1.3.2.3"></times></apply><apply id="S3.E2.m1.5.5.1.1.3.3.cmml" xref="S3.E2.m1.5.5.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.1.1.3.3.1.cmml" xref="S3.E2.m1.5.5.1.1.3.3">superscript</csymbol><set id="S3.E2.m1.5.5.1.1.3.3.2.1.cmml" xref="S3.E2.m1.5.5.1.1.3.3.2.2"><cn type="integer" id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">0</cn><cn type="integer" id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">1</cn></set><times id="S3.E2.m1.5.5.1.1.3.3.3.cmml" xref="S3.E2.m1.5.5.1.1.3.3.3"></times></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">g:\{0,1\}^{*}\rightarrow\{0,1\}^{*}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.Thmdefinition1.p1.17" class="ltx_p"><span id="S3.Thmdefinition1.p1.17.6" class="ltx_text ltx_font_italic">Specifically, <math id="S3.Thmdefinition1.p1.12.1.m1.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S3.Thmdefinition1.p1.12.1.m1.1a"><mi id="S3.Thmdefinition1.p1.12.1.m1.1.1" xref="S3.Thmdefinition1.p1.12.1.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.12.1.m1.1b"><ci id="S3.Thmdefinition1.p1.12.1.m1.1.1.cmml" xref="S3.Thmdefinition1.p1.12.1.m1.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.12.1.m1.1c">g</annotation></semantics></math> is a random process mapping string sequences of the form <math id="S3.Thmdefinition1.p1.13.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.Thmdefinition1.p1.13.2.m2.1a"><mi id="S3.Thmdefinition1.p1.13.2.m2.1.1" xref="S3.Thmdefinition1.p1.13.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.13.2.m2.1b"><ci id="S3.Thmdefinition1.p1.13.2.m2.1.1.cmml" xref="S3.Thmdefinition1.p1.13.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.13.2.m2.1c">y</annotation></semantics></math> into sequences of random variables, <math id="S3.Thmdefinition1.p1.14.3.m3.1" class="ltx_Math" alttext="g(y)" display="inline"><semantics id="S3.Thmdefinition1.p1.14.3.m3.1a"><mrow id="S3.Thmdefinition1.p1.14.3.m3.1.2" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.cmml"><mi id="S3.Thmdefinition1.p1.14.3.m3.1.2.2" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Thmdefinition1.p1.14.3.m3.1.2.1" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.1.cmml">​</mo><mrow id="S3.Thmdefinition1.p1.14.3.m3.1.2.3.2" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.cmml"><mo stretchy="false" id="S3.Thmdefinition1.p1.14.3.m3.1.2.3.2.1" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.cmml">(</mo><mi id="S3.Thmdefinition1.p1.14.3.m3.1.1" xref="S3.Thmdefinition1.p1.14.3.m3.1.1.cmml">y</mi><mo stretchy="false" id="S3.Thmdefinition1.p1.14.3.m3.1.2.3.2.2" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.14.3.m3.1b"><apply id="S3.Thmdefinition1.p1.14.3.m3.1.2.cmml" xref="S3.Thmdefinition1.p1.14.3.m3.1.2"><times id="S3.Thmdefinition1.p1.14.3.m3.1.2.1.cmml" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.1"></times><ci id="S3.Thmdefinition1.p1.14.3.m3.1.2.2.cmml" xref="S3.Thmdefinition1.p1.14.3.m3.1.2.2">𝑔</ci><ci id="S3.Thmdefinition1.p1.14.3.m3.1.1.cmml" xref="S3.Thmdefinition1.p1.14.3.m3.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.14.3.m3.1c">g(y)</annotation></semantics></math>, such that the client <math id="S3.Thmdefinition1.p1.15.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.Thmdefinition1.p1.15.4.m4.1a"><mi id="S3.Thmdefinition1.p1.15.4.m4.1.1" xref="S3.Thmdefinition1.p1.15.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.15.4.m4.1b"><ci id="S3.Thmdefinition1.p1.15.4.m4.1.1.cmml" xref="S3.Thmdefinition1.p1.15.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.15.4.m4.1c">C</annotation></semantics></math> who initially holds an input <math id="S3.Thmdefinition1.p1.16.5.m5.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.Thmdefinition1.p1.16.5.m5.1a"><mi id="S3.Thmdefinition1.p1.16.5.m5.1.1" xref="S3.Thmdefinition1.p1.16.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.16.5.m5.1b"><ci id="S3.Thmdefinition1.p1.16.5.m5.1.1.cmml" xref="S3.Thmdefinition1.p1.16.5.m5.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.16.5.m5.1c">y</annotation></semantics></math> wishes to obtain the <math id="S3.Thmdefinition1.p1.17.6.m6.1" class="ltx_Math" alttext="g(y)" display="inline"><semantics id="S3.Thmdefinition1.p1.17.6.m6.1a"><mrow id="S3.Thmdefinition1.p1.17.6.m6.1.2" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.cmml"><mi id="S3.Thmdefinition1.p1.17.6.m6.1.2.2" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.Thmdefinition1.p1.17.6.m6.1.2.1" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.1.cmml">​</mo><mrow id="S3.Thmdefinition1.p1.17.6.m6.1.2.3.2" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.cmml"><mo stretchy="false" id="S3.Thmdefinition1.p1.17.6.m6.1.2.3.2.1" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.cmml">(</mo><mi id="S3.Thmdefinition1.p1.17.6.m6.1.1" xref="S3.Thmdefinition1.p1.17.6.m6.1.1.cmml">y</mi><mo stretchy="false" id="S3.Thmdefinition1.p1.17.6.m6.1.2.3.2.2" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Thmdefinition1.p1.17.6.m6.1b"><apply id="S3.Thmdefinition1.p1.17.6.m6.1.2.cmml" xref="S3.Thmdefinition1.p1.17.6.m6.1.2"><times id="S3.Thmdefinition1.p1.17.6.m6.1.2.1.cmml" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.1"></times><ci id="S3.Thmdefinition1.p1.17.6.m6.1.2.2.cmml" xref="S3.Thmdefinition1.p1.17.6.m6.1.2.2">𝑔</ci><ci id="S3.Thmdefinition1.p1.17.6.m6.1.1.cmml" xref="S3.Thmdefinition1.p1.17.6.m6.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Thmdefinition1.p1.17.6.m6.1c">g(y)</annotation></semantics></math>. We call an FL algorithm as an SFL algorithm if it can complete the calculation of the training or inference process under a given threat model.</span></p>
</div>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_italic">Defense Methods in Secure Federate Learning</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In this section, we introduce the defense techniques commonly used in the SFL algorithms, such as SMPC, HE, and Trusted Execution Environment (TEE). Accordingly, SFL algorithms using different secure computing techniques will have different characteristics. For example, the SMPC-based secure computing algorithm can theoretically realize any computation, but it needs to spend a lot of communication costs. Conversely, the HE-based secure computing algorithm can implement addition and multiplication operations without any communication costs, but it requires huge computational overhead.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Secure Multi-Party Computation</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Secure Multi-Party Computation (SMPC) originated from the millionaire problem proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib234" title="" class="ltx_ref">234</a>]</cite>. The goal of SMPC is to allow a group of mutually untrusted data owners to work together on the computation of a function under the condition that the confidentiality of their independent data is not compromised. The main techniques currently implementing the SMPC protocol include Garbled Circuit (GC) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib235" title="" class="ltx_ref">235</a>]</cite>, Oblivious Transfer (OT) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite>, and Secret Sharing (SS) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib183" title="" class="ltx_ref">183</a>]</cite>.
All these techniques have limitations and usually require a combination with other techniques to construct efficient SFL algorithms. For example, in spite of, GC can theoretically enable secure computation of arbitrary functions in constant rounds, but transmitting the complete encrypted circuit will result in high communication costs. In contrast, while SS can achieve secure computation at a lower communication cost, it requires a larger number of communication rounds for complex operations.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p"><span id="S3.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Oblivious Transfer.</span> Oblivious transfer (OT) is proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite>. As a very important primitive in cryptography, OT not only can implement the SMPC protocol independently but also can integrate with other technologies to complete the construction of the SMPC protocol. There are generally two parties in the OT protocol namely, the <em id="S3.SS2.SSS1.p2.1.2" class="ltx_emph ltx_font_italic">sender</em> and the <em id="S3.SS2.SSS1.p2.1.3" class="ltx_emph ltx_font_italic">receiver</em>. The goal of the OT protocol is to enable the receiver to obtain certain information from the sender obliviously on the premise that the sender and receiver’s respective private information is not leaked.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p3.7" class="ltx_p"><span id="S3.SS2.SSS1.p3.7.1" class="ltx_text ltx_font_bold">Garbled Circuit.</span> Garbled circuit (GC) is a two-party SMPC protocol proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib234" title="" class="ltx_ref">234</a>]</cite>. The two parties in the GC are called <em id="S3.SS2.SSS1.p3.7.2" class="ltx_emph ltx_font_italic">garbler</em> and <em id="S3.SS2.SSS1.p3.7.3" class="ltx_emph ltx_font_italic">evaluator</em>. Suppose the input information of the garbler is <math id="S3.SS2.SSS1.p3.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mi id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><ci id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">x</annotation></semantics></math>, and the input information of the evaluator is <math id="S3.SS2.SSS1.p3.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.SSS1.p3.2.m2.1a"><mi id="S3.SS2.SSS1.p3.2.m2.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.2.m2.1b"><ci id="S3.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.2.m2.1c">y</annotation></semantics></math>. The main idea of GC is to convert computational functions into boolean circuits. In the obfuscation stage, the garbler converts the Boolean circuit corresponding to the calculation function into a garbled circuit and sends the garbled circuit and the random input label corresponding to <math id="S3.SS2.SSS1.p3.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.SSS1.p3.3.m3.1a"><mi id="S3.SS2.SSS1.p3.3.m3.1.1" xref="S3.SS2.SSS1.p3.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.3.m3.1b"><ci id="S3.SS2.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.3.m3.1c">x</annotation></semantics></math> to the evaluator.
The evaluator executes the OT protocol by interacting with the garbler and obtains the corresponding random input label of <math id="S3.SS2.SSS1.p3.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.SSS1.p3.4.m4.1a"><mi id="S3.SS2.SSS1.p3.4.m4.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.4.m4.1b"><ci id="S3.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.4.m4.1c">y</annotation></semantics></math>. The evaluator decrypts the garbled circuit using the random input tag to get the calculation result.
Finally, the evaluator sends the decrypted calculation result to the garbler. Since the garbled circuit and the random input label of <math id="S3.SS2.SSS1.p3.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.SSS1.p3.5.m5.1a"><mi id="S3.SS2.SSS1.p3.5.m5.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.5.m5.1b"><ci id="S3.SS2.SSS1.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.5.m5.1c">x</annotation></semantics></math> are random values for the calculator, they do not contain any information of <math id="S3.SS2.SSS1.p3.6.m6.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.SSS1.p3.6.m6.1a"><mi id="S3.SS2.SSS1.p3.6.m6.1.1" xref="S3.SS2.SSS1.p3.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.6.m6.1b"><ci id="S3.SS2.SSS1.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.6.m6.1c">x</annotation></semantics></math>, and the security of the OT protocol used ensures that the information of <math id="S3.SS2.SSS1.p3.7.m7.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.SSS1.p3.7.m7.1a"><mi id="S3.SS2.SSS1.p3.7.m7.1.1" xref="S3.SS2.SSS1.p3.7.m7.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.7.m7.1b"><ci id="S3.SS2.SSS1.p3.7.m7.1.1.cmml" xref="S3.SS2.SSS1.p3.7.m7.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.7.m7.1c">y</annotation></semantics></math> will not be leaked to the obfuscator. Therefore, the obfuscation circuit ensures that both parties involved in the calculation can obtain the calculation result without revealing their respective input data.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p4.21" class="ltx_p"><span id="S3.SS2.SSS1.p4.21.1" class="ltx_text ltx_font_bold">Secret Sharing.</span> Secret sharing (SS) is a technique independently proposed by Shamir <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib183" title="" class="ltx_ref">183</a>]</cite> and Blackly <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> with its full name called <math id="S3.SS2.SSS1.p4.1.m1.2" class="ltx_Math" alttext="(t,n)" display="inline"><semantics id="S3.SS2.SSS1.p4.1.m1.2a"><mrow id="S3.SS2.SSS1.p4.1.m1.2.3.2" xref="S3.SS2.SSS1.p4.1.m1.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.1.m1.2.3.2.1" xref="S3.SS2.SSS1.p4.1.m1.2.3.1.cmml">(</mo><mi id="S3.SS2.SSS1.p4.1.m1.1.1" xref="S3.SS2.SSS1.p4.1.m1.1.1.cmml">t</mi><mo id="S3.SS2.SSS1.p4.1.m1.2.3.2.2" xref="S3.SS2.SSS1.p4.1.m1.2.3.1.cmml">,</mo><mi id="S3.SS2.SSS1.p4.1.m1.2.2" xref="S3.SS2.SSS1.p4.1.m1.2.2.cmml">n</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.1.m1.2.3.2.3" xref="S3.SS2.SSS1.p4.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.1.m1.2b"><interval closure="open" id="S3.SS2.SSS1.p4.1.m1.2.3.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.2.3.2"><ci id="S3.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p4.1.m1.1.1">𝑡</ci><ci id="S3.SS2.SSS1.p4.1.m1.2.2.cmml" xref="S3.SS2.SSS1.p4.1.m1.2.2">𝑛</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.1.m1.2c">(t,n)</annotation></semantics></math>-threshold secret sharing schemes, where <math id="S3.SS2.SSS1.p4.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.SSS1.p4.2.m2.1a"><mi id="S3.SS2.SSS1.p4.2.m2.1.1" xref="S3.SS2.SSS1.p4.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.2.m2.1b"><ci id="S3.SS2.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p4.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.2.m2.1c">n</annotation></semantics></math> is the number of parties and <math id="S3.SS2.SSS1.p4.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.SSS1.p4.3.m3.1a"><mi id="S3.SS2.SSS1.p4.3.m3.1.1" xref="S3.SS2.SSS1.p4.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.3.m3.1b"><ci id="S3.SS2.SSS1.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p4.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.3.m3.1c">t</annotation></semantics></math> is a threshold value.
The security of SS requires that any less than <math id="S3.SS2.SSS1.p4.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.SSS1.p4.4.m4.1a"><mi id="S3.SS2.SSS1.p4.4.m4.1.1" xref="S3.SS2.SSS1.p4.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.4.m4.1b"><ci id="S3.SS2.SSS1.p4.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p4.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.4.m4.1c">t</annotation></semantics></math> parties cannot obtain any secret information jointly.
As a special case of secret sharing, <math id="S3.SS2.SSS1.p4.5.m5.2" class="ltx_Math" alttext="(2,2)" display="inline"><semantics id="S3.SS2.SSS1.p4.5.m5.2a"><mrow id="S3.SS2.SSS1.p4.5.m5.2.3.2" xref="S3.SS2.SSS1.p4.5.m5.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.5.m5.2.3.2.1" xref="S3.SS2.SSS1.p4.5.m5.2.3.1.cmml">(</mo><mn id="S3.SS2.SSS1.p4.5.m5.1.1" xref="S3.SS2.SSS1.p4.5.m5.1.1.cmml">2</mn><mo id="S3.SS2.SSS1.p4.5.m5.2.3.2.2" xref="S3.SS2.SSS1.p4.5.m5.2.3.1.cmml">,</mo><mn id="S3.SS2.SSS1.p4.5.m5.2.2" xref="S3.SS2.SSS1.p4.5.m5.2.2.cmml">2</mn><mo stretchy="false" id="S3.SS2.SSS1.p4.5.m5.2.3.2.3" xref="S3.SS2.SSS1.p4.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.5.m5.2b"><interval closure="open" id="S3.SS2.SSS1.p4.5.m5.2.3.1.cmml" xref="S3.SS2.SSS1.p4.5.m5.2.3.2"><cn type="integer" id="S3.SS2.SSS1.p4.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p4.5.m5.1.1">2</cn><cn type="integer" id="S3.SS2.SSS1.p4.5.m5.2.2.cmml" xref="S3.SS2.SSS1.p4.5.m5.2.2">2</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.5.m5.2c">(2,2)</annotation></semantics></math>-<em id="S3.SS2.SSS1.p4.21.2" class="ltx_emph ltx_font_italic">additive</em> secret sharing contains two algorithms: <math id="S3.SS2.SSS1.p4.6.m6.1" class="ltx_Math" alttext="Shr(\cdot)" display="inline"><semantics id="S3.SS2.SSS1.p4.6.m6.1a"><mrow id="S3.SS2.SSS1.p4.6.m6.1.2" xref="S3.SS2.SSS1.p4.6.m6.1.2.cmml"><mi id="S3.SS2.SSS1.p4.6.m6.1.2.2" xref="S3.SS2.SSS1.p4.6.m6.1.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.6.m6.1.2.1" xref="S3.SS2.SSS1.p4.6.m6.1.2.1.cmml">​</mo><mi id="S3.SS2.SSS1.p4.6.m6.1.2.3" xref="S3.SS2.SSS1.p4.6.m6.1.2.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.6.m6.1.2.1a" xref="S3.SS2.SSS1.p4.6.m6.1.2.1.cmml">​</mo><mi id="S3.SS2.SSS1.p4.6.m6.1.2.4" xref="S3.SS2.SSS1.p4.6.m6.1.2.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.6.m6.1.2.1b" xref="S3.SS2.SSS1.p4.6.m6.1.2.1.cmml">​</mo><mrow id="S3.SS2.SSS1.p4.6.m6.1.2.5.2" xref="S3.SS2.SSS1.p4.6.m6.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.6.m6.1.2.5.2.1" xref="S3.SS2.SSS1.p4.6.m6.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.6.m6.1.1" xref="S3.SS2.SSS1.p4.6.m6.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS2.SSS1.p4.6.m6.1.2.5.2.2" xref="S3.SS2.SSS1.p4.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.6.m6.1b"><apply id="S3.SS2.SSS1.p4.6.m6.1.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.1.2"><times id="S3.SS2.SSS1.p4.6.m6.1.2.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.1.2.1"></times><ci id="S3.SS2.SSS1.p4.6.m6.1.2.2.cmml" xref="S3.SS2.SSS1.p4.6.m6.1.2.2">𝑆</ci><ci id="S3.SS2.SSS1.p4.6.m6.1.2.3.cmml" xref="S3.SS2.SSS1.p4.6.m6.1.2.3">ℎ</ci><ci id="S3.SS2.SSS1.p4.6.m6.1.2.4.cmml" xref="S3.SS2.SSS1.p4.6.m6.1.2.4">𝑟</ci><ci id="S3.SS2.SSS1.p4.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p4.6.m6.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.6.m6.1c">Shr(\cdot)</annotation></semantics></math> and <math id="S3.SS2.SSS1.p4.7.m7.2" class="ltx_Math" alttext="Rec(\cdot,\cdot)" display="inline"><semantics id="S3.SS2.SSS1.p4.7.m7.2a"><mrow id="S3.SS2.SSS1.p4.7.m7.2.3" xref="S3.SS2.SSS1.p4.7.m7.2.3.cmml"><mi id="S3.SS2.SSS1.p4.7.m7.2.3.2" xref="S3.SS2.SSS1.p4.7.m7.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.7.m7.2.3.1" xref="S3.SS2.SSS1.p4.7.m7.2.3.1.cmml">​</mo><mi id="S3.SS2.SSS1.p4.7.m7.2.3.3" xref="S3.SS2.SSS1.p4.7.m7.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.7.m7.2.3.1a" xref="S3.SS2.SSS1.p4.7.m7.2.3.1.cmml">​</mo><mi id="S3.SS2.SSS1.p4.7.m7.2.3.4" xref="S3.SS2.SSS1.p4.7.m7.2.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.7.m7.2.3.1b" xref="S3.SS2.SSS1.p4.7.m7.2.3.1.cmml">​</mo><mrow id="S3.SS2.SSS1.p4.7.m7.2.3.5.2" xref="S3.SS2.SSS1.p4.7.m7.2.3.5.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.7.m7.2.3.5.2.1" xref="S3.SS2.SSS1.p4.7.m7.2.3.5.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.7.m7.1.1" xref="S3.SS2.SSS1.p4.7.m7.1.1.cmml">⋅</mo><mo rspace="0em" id="S3.SS2.SSS1.p4.7.m7.2.3.5.2.2" xref="S3.SS2.SSS1.p4.7.m7.2.3.5.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.7.m7.2.2" xref="S3.SS2.SSS1.p4.7.m7.2.2.cmml">⋅</mo><mo stretchy="false" id="S3.SS2.SSS1.p4.7.m7.2.3.5.2.3" xref="S3.SS2.SSS1.p4.7.m7.2.3.5.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.7.m7.2b"><apply id="S3.SS2.SSS1.p4.7.m7.2.3.cmml" xref="S3.SS2.SSS1.p4.7.m7.2.3"><times id="S3.SS2.SSS1.p4.7.m7.2.3.1.cmml" xref="S3.SS2.SSS1.p4.7.m7.2.3.1"></times><ci id="S3.SS2.SSS1.p4.7.m7.2.3.2.cmml" xref="S3.SS2.SSS1.p4.7.m7.2.3.2">𝑅</ci><ci id="S3.SS2.SSS1.p4.7.m7.2.3.3.cmml" xref="S3.SS2.SSS1.p4.7.m7.2.3.3">𝑒</ci><ci id="S3.SS2.SSS1.p4.7.m7.2.3.4.cmml" xref="S3.SS2.SSS1.p4.7.m7.2.3.4">𝑐</ci><interval closure="open" id="S3.SS2.SSS1.p4.7.m7.2.3.5.1.cmml" xref="S3.SS2.SSS1.p4.7.m7.2.3.5.2"><ci id="S3.SS2.SSS1.p4.7.m7.1.1.cmml" xref="S3.SS2.SSS1.p4.7.m7.1.1">⋅</ci><ci id="S3.SS2.SSS1.p4.7.m7.2.2.cmml" xref="S3.SS2.SSS1.p4.7.m7.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.7.m7.2c">Rec(\cdot,\cdot)</annotation></semantics></math>.
Let <math id="S3.SS2.SSS1.p4.8.m8.4" class="ltx_Math" alttext="([u]_{0},[u]_{1})" display="inline"><semantics id="S3.SS2.SSS1.p4.8.m8.4a"><mrow id="S3.SS2.SSS1.p4.8.m8.4.4.2" xref="S3.SS2.SSS1.p4.8.m8.4.4.3.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.8.m8.4.4.2.3" xref="S3.SS2.SSS1.p4.8.m8.4.4.3.cmml">(</mo><msub id="S3.SS2.SSS1.p4.8.m8.3.3.1.1" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.cmml"><mrow id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.2" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.2.1" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.8.m8.1.1" xref="S3.SS2.SSS1.p4.8.m8.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.2.2" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.3" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.3.cmml">0</mn></msub><mo id="S3.SS2.SSS1.p4.8.m8.4.4.2.4" xref="S3.SS2.SSS1.p4.8.m8.4.4.3.cmml">,</mo><msub id="S3.SS2.SSS1.p4.8.m8.4.4.2.2" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.cmml"><mrow id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.2" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.2.1" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.8.m8.2.2" xref="S3.SS2.SSS1.p4.8.m8.2.2.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.2.2" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.3" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S3.SS2.SSS1.p4.8.m8.4.4.2.5" xref="S3.SS2.SSS1.p4.8.m8.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.8.m8.4b"><interval closure="open" id="S3.SS2.SSS1.p4.8.m8.4.4.3.cmml" xref="S3.SS2.SSS1.p4.8.m8.4.4.2"><apply id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1">subscript</csymbol><apply id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.1.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.8.m8.1.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.1.1">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.8.m8.3.3.1.1.3.cmml" xref="S3.SS2.SSS1.p4.8.m8.3.3.1.1.3">0</cn></apply><apply id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.cmml" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2">subscript</csymbol><apply id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.1.1.cmml" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.8.m8.2.2.cmml" xref="S3.SS2.SSS1.p4.8.m8.2.2">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.8.m8.4.4.2.2.3.cmml" xref="S3.SS2.SSS1.p4.8.m8.4.4.2.2.3">1</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.8.m8.4c">([u]_{0},[u]_{1})</annotation></semantics></math> be the additive share of any <math id="S3.SS2.SSS1.p4.9.m9.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S3.SS2.SSS1.p4.9.m9.1a"><mi id="S3.SS2.SSS1.p4.9.m9.1.1" xref="S3.SS2.SSS1.p4.9.m9.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.9.m9.1b"><ci id="S3.SS2.SSS1.p4.9.m9.1.1.cmml" xref="S3.SS2.SSS1.p4.9.m9.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.9.m9.1c">u</annotation></semantics></math> on <math id="S3.SS2.SSS1.p4.10.m10.1" class="ltx_Math" alttext="Z_{L}" display="inline"><semantics id="S3.SS2.SSS1.p4.10.m10.1a"><msub id="S3.SS2.SSS1.p4.10.m10.1.1" xref="S3.SS2.SSS1.p4.10.m10.1.1.cmml"><mi id="S3.SS2.SSS1.p4.10.m10.1.1.2" xref="S3.SS2.SSS1.p4.10.m10.1.1.2.cmml">Z</mi><mi id="S3.SS2.SSS1.p4.10.m10.1.1.3" xref="S3.SS2.SSS1.p4.10.m10.1.1.3.cmml">L</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.10.m10.1b"><apply id="S3.SS2.SSS1.p4.10.m10.1.1.cmml" xref="S3.SS2.SSS1.p4.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.10.m10.1.1.1.cmml" xref="S3.SS2.SSS1.p4.10.m10.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p4.10.m10.1.1.2.cmml" xref="S3.SS2.SSS1.p4.10.m10.1.1.2">𝑍</ci><ci id="S3.SS2.SSS1.p4.10.m10.1.1.3.cmml" xref="S3.SS2.SSS1.p4.10.m10.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.10.m10.1c">Z_{L}</annotation></semantics></math>. <math id="S3.SS2.SSS1.p4.11.m11.5" class="ltx_Math" alttext="Shr(u)\rightarrow([u]_{0},[u]_{1})" display="inline"><semantics id="S3.SS2.SSS1.p4.11.m11.5a"><mrow id="S3.SS2.SSS1.p4.11.m11.5.5" xref="S3.SS2.SSS1.p4.11.m11.5.5.cmml"><mrow id="S3.SS2.SSS1.p4.11.m11.5.5.4" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.cmml"><mi id="S3.SS2.SSS1.p4.11.m11.5.5.4.2" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.11.m11.5.5.4.1" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.1.cmml">​</mo><mi id="S3.SS2.SSS1.p4.11.m11.5.5.4.3" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.11.m11.5.5.4.1a" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.1.cmml">​</mo><mi id="S3.SS2.SSS1.p4.11.m11.5.5.4.4" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.11.m11.5.5.4.1b" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.1.cmml">​</mo><mrow id="S3.SS2.SSS1.p4.11.m11.5.5.4.5.2" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.5.5.4.5.2.1" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.cmml">(</mo><mi id="S3.SS2.SSS1.p4.11.m11.1.1" xref="S3.SS2.SSS1.p4.11.m11.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.5.5.4.5.2.2" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.5.5.3" xref="S3.SS2.SSS1.p4.11.m11.5.5.3.cmml">→</mo><mrow id="S3.SS2.SSS1.p4.11.m11.5.5.2.2" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.3" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.3.cmml">(</mo><msub id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.cmml"><mrow id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.2" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.2.1" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.11.m11.2.2" xref="S3.SS2.SSS1.p4.11.m11.2.2.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.2.2" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.3" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.3.cmml">0</mn></msub><mo id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.4" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.3.cmml">,</mo><msub id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.cmml"><mrow id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.2" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.2.1" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.11.m11.3.3" xref="S3.SS2.SSS1.p4.11.m11.3.3.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.2.2" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.3" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.5" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.11.m11.5b"><apply id="S3.SS2.SSS1.p4.11.m11.5.5.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5"><ci id="S3.SS2.SSS1.p4.11.m11.5.5.3.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.3">→</ci><apply id="S3.SS2.SSS1.p4.11.m11.5.5.4.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.4"><times id="S3.SS2.SSS1.p4.11.m11.5.5.4.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.1"></times><ci id="S3.SS2.SSS1.p4.11.m11.5.5.4.2.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.2">𝑆</ci><ci id="S3.SS2.SSS1.p4.11.m11.5.5.4.3.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.3">ℎ</ci><ci id="S3.SS2.SSS1.p4.11.m11.5.5.4.4.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.4.4">𝑟</ci><ci id="S3.SS2.SSS1.p4.11.m11.1.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.1.1">𝑢</ci></apply><interval closure="open" id="S3.SS2.SSS1.p4.11.m11.5.5.2.3.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2"><apply id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1">subscript</csymbol><apply id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.1.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.11.m11.2.2.cmml" xref="S3.SS2.SSS1.p4.11.m11.2.2">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.11.m11.4.4.1.1.1.3">0</cn></apply><apply id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2">subscript</csymbol><apply id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.1.1.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.11.m11.3.3.cmml" xref="S3.SS2.SSS1.p4.11.m11.3.3">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.3.cmml" xref="S3.SS2.SSS1.p4.11.m11.5.5.2.2.2.3">1</cn></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.11.m11.5c">Shr(u)\rightarrow([u]_{0},[u]_{1})</annotation></semantics></math> is used to generate the share by randomly selecting a number <math id="S3.SS2.SSS1.p4.12.m12.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.SSS1.p4.12.m12.1a"><mi id="S3.SS2.SSS1.p4.12.m12.1.1" xref="S3.SS2.SSS1.p4.12.m12.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.12.m12.1b"><ci id="S3.SS2.SSS1.p4.12.m12.1.1.cmml" xref="S3.SS2.SSS1.p4.12.m12.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.12.m12.1c">r</annotation></semantics></math> from <math id="S3.SS2.SSS1.p4.13.m13.1" class="ltx_Math" alttext="Z_{L}" display="inline"><semantics id="S3.SS2.SSS1.p4.13.m13.1a"><msub id="S3.SS2.SSS1.p4.13.m13.1.1" xref="S3.SS2.SSS1.p4.13.m13.1.1.cmml"><mi id="S3.SS2.SSS1.p4.13.m13.1.1.2" xref="S3.SS2.SSS1.p4.13.m13.1.1.2.cmml">Z</mi><mi id="S3.SS2.SSS1.p4.13.m13.1.1.3" xref="S3.SS2.SSS1.p4.13.m13.1.1.3.cmml">L</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.13.m13.1b"><apply id="S3.SS2.SSS1.p4.13.m13.1.1.cmml" xref="S3.SS2.SSS1.p4.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.13.m13.1.1.1.cmml" xref="S3.SS2.SSS1.p4.13.m13.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p4.13.m13.1.1.2.cmml" xref="S3.SS2.SSS1.p4.13.m13.1.1.2">𝑍</ci><ci id="S3.SS2.SSS1.p4.13.m13.1.1.3.cmml" xref="S3.SS2.SSS1.p4.13.m13.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.13.m13.1c">Z_{L}</annotation></semantics></math>, letting <math id="S3.SS2.SSS1.p4.14.m14.1" class="ltx_Math" alttext="[u]_{0}=r" display="inline"><semantics id="S3.SS2.SSS1.p4.14.m14.1a"><mrow id="S3.SS2.SSS1.p4.14.m14.1.2" xref="S3.SS2.SSS1.p4.14.m14.1.2.cmml"><msub id="S3.SS2.SSS1.p4.14.m14.1.2.2" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.cmml"><mrow id="S3.SS2.SSS1.p4.14.m14.1.2.2.2.2" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.14.m14.1.2.2.2.2.1" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.14.m14.1.1" xref="S3.SS2.SSS1.p4.14.m14.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.14.m14.1.2.2.2.2.2" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.14.m14.1.2.2.3" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.3.cmml">0</mn></msub><mo id="S3.SS2.SSS1.p4.14.m14.1.2.1" xref="S3.SS2.SSS1.p4.14.m14.1.2.1.cmml">=</mo><mi id="S3.SS2.SSS1.p4.14.m14.1.2.3" xref="S3.SS2.SSS1.p4.14.m14.1.2.3.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.14.m14.1b"><apply id="S3.SS2.SSS1.p4.14.m14.1.2.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2"><eq id="S3.SS2.SSS1.p4.14.m14.1.2.1.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2.1"></eq><apply id="S3.SS2.SSS1.p4.14.m14.1.2.2.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.14.m14.1.2.2.1.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2.2">subscript</csymbol><apply id="S3.SS2.SSS1.p4.14.m14.1.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.14.m14.1.2.2.2.1.1.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.14.m14.1.1.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.1">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.14.m14.1.2.2.3.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2.2.3">0</cn></apply><ci id="S3.SS2.SSS1.p4.14.m14.1.2.3.cmml" xref="S3.SS2.SSS1.p4.14.m14.1.2.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.14.m14.1c">[u]_{0}=r</annotation></semantics></math>, and computing <math id="S3.SS2.SSS1.p4.15.m15.2" class="ltx_Math" alttext="[u]_{1}=(u-r)\mod L" display="inline"><semantics id="S3.SS2.SSS1.p4.15.m15.2a"><mrow id="S3.SS2.SSS1.p4.15.m15.2.2" xref="S3.SS2.SSS1.p4.15.m15.2.2.cmml"><msub id="S3.SS2.SSS1.p4.15.m15.2.2.3" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.cmml"><mrow id="S3.SS2.SSS1.p4.15.m15.2.2.3.2.2" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.15.m15.2.2.3.2.2.1" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.15.m15.1.1" xref="S3.SS2.SSS1.p4.15.m15.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.15.m15.2.2.3.2.2.2" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.15.m15.2.2.3.3" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.3.cmml">1</mn></msub><mo id="S3.SS2.SSS1.p4.15.m15.2.2.2" xref="S3.SS2.SSS1.p4.15.m15.2.2.2.cmml">=</mo><mrow id="S3.SS2.SSS1.p4.15.m15.2.2.1" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.cmml"><mrow id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.2" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.cmml"><mi id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.2" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.2.cmml">u</mi><mo id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.1" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.1.cmml">−</mo><mi id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.3" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.3.cmml">r</mi></mrow><mo stretchy="false" id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.3" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.SSS1.p4.15.m15.2.2.1.2" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.2.cmml">mod</mo><mi id="S3.SS2.SSS1.p4.15.m15.2.2.1.3" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.3.cmml">L</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.15.m15.2b"><apply id="S3.SS2.SSS1.p4.15.m15.2.2.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2"><eq id="S3.SS2.SSS1.p4.15.m15.2.2.2.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.2"></eq><apply id="S3.SS2.SSS1.p4.15.m15.2.2.3.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.15.m15.2.2.3.1.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.3">subscript</csymbol><apply id="S3.SS2.SSS1.p4.15.m15.2.2.3.2.1.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.15.m15.2.2.3.2.1.1.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.15.m15.1.1.cmml" xref="S3.SS2.SSS1.p4.15.m15.1.1">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.15.m15.2.2.3.3.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.3.3">1</cn></apply><apply id="S3.SS2.SSS1.p4.15.m15.2.2.1.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.1"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.15.m15.2.2.1.2.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.2">modulo</csymbol><apply id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1"><minus id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.1"></minus><ci id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.2">𝑢</ci><ci id="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.1.1.1.3">𝑟</ci></apply><ci id="S3.SS2.SSS1.p4.15.m15.2.2.1.3.cmml" xref="S3.SS2.SSS1.p4.15.m15.2.2.1.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.15.m15.2c">[u]_{1}=(u-r)\mod L</annotation></semantics></math>. Note that due to the randomness of <math id="S3.SS2.SSS1.p4.16.m16.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.SSS1.p4.16.m16.1a"><mi id="S3.SS2.SSS1.p4.16.m16.1.1" xref="S3.SS2.SSS1.p4.16.m16.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.16.m16.1b"><ci id="S3.SS2.SSS1.p4.16.m16.1.1.cmml" xref="S3.SS2.SSS1.p4.16.m16.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.16.m16.1c">r</annotation></semantics></math>, neither a single <math id="S3.SS2.SSS1.p4.17.m17.1" class="ltx_Math" alttext="[u]_{0}" display="inline"><semantics id="S3.SS2.SSS1.p4.17.m17.1a"><msub id="S3.SS2.SSS1.p4.17.m17.1.2" xref="S3.SS2.SSS1.p4.17.m17.1.2.cmml"><mrow id="S3.SS2.SSS1.p4.17.m17.1.2.2.2" xref="S3.SS2.SSS1.p4.17.m17.1.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.17.m17.1.2.2.2.1" xref="S3.SS2.SSS1.p4.17.m17.1.2.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.17.m17.1.1" xref="S3.SS2.SSS1.p4.17.m17.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.17.m17.1.2.2.2.2" xref="S3.SS2.SSS1.p4.17.m17.1.2.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.17.m17.1.2.3" xref="S3.SS2.SSS1.p4.17.m17.1.2.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.17.m17.1b"><apply id="S3.SS2.SSS1.p4.17.m17.1.2.cmml" xref="S3.SS2.SSS1.p4.17.m17.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.17.m17.1.2.1.cmml" xref="S3.SS2.SSS1.p4.17.m17.1.2">subscript</csymbol><apply id="S3.SS2.SSS1.p4.17.m17.1.2.2.1.cmml" xref="S3.SS2.SSS1.p4.17.m17.1.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.17.m17.1.2.2.1.1.cmml" xref="S3.SS2.SSS1.p4.17.m17.1.2.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.17.m17.1.1.cmml" xref="S3.SS2.SSS1.p4.17.m17.1.1">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.17.m17.1.2.3.cmml" xref="S3.SS2.SSS1.p4.17.m17.1.2.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.17.m17.1c">[u]_{0}</annotation></semantics></math> nor <math id="S3.SS2.SSS1.p4.18.m18.1" class="ltx_Math" alttext="[u]_{1}" display="inline"><semantics id="S3.SS2.SSS1.p4.18.m18.1a"><msub id="S3.SS2.SSS1.p4.18.m18.1.2" xref="S3.SS2.SSS1.p4.18.m18.1.2.cmml"><mrow id="S3.SS2.SSS1.p4.18.m18.1.2.2.2" xref="S3.SS2.SSS1.p4.18.m18.1.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.18.m18.1.2.2.2.1" xref="S3.SS2.SSS1.p4.18.m18.1.2.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.18.m18.1.1" xref="S3.SS2.SSS1.p4.18.m18.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.18.m18.1.2.2.2.2" xref="S3.SS2.SSS1.p4.18.m18.1.2.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.18.m18.1.2.3" xref="S3.SS2.SSS1.p4.18.m18.1.2.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.18.m18.1b"><apply id="S3.SS2.SSS1.p4.18.m18.1.2.cmml" xref="S3.SS2.SSS1.p4.18.m18.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.18.m18.1.2.1.cmml" xref="S3.SS2.SSS1.p4.18.m18.1.2">subscript</csymbol><apply id="S3.SS2.SSS1.p4.18.m18.1.2.2.1.cmml" xref="S3.SS2.SSS1.p4.18.m18.1.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.18.m18.1.2.2.1.1.cmml" xref="S3.SS2.SSS1.p4.18.m18.1.2.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.18.m18.1.1.cmml" xref="S3.SS2.SSS1.p4.18.m18.1.1">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.18.m18.1.2.3.cmml" xref="S3.SS2.SSS1.p4.18.m18.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.18.m18.1c">[u]_{1}</annotation></semantics></math> can be used to infer the original value of <math id="S3.SS2.SSS1.p4.19.m19.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S3.SS2.SSS1.p4.19.m19.1a"><mi id="S3.SS2.SSS1.p4.19.m19.1.1" xref="S3.SS2.SSS1.p4.19.m19.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.19.m19.1b"><ci id="S3.SS2.SSS1.p4.19.m19.1.1.cmml" xref="S3.SS2.SSS1.p4.19.m19.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.19.m19.1c">u</annotation></semantics></math>. The algorithm <math id="S3.SS2.SSS1.p4.20.m20.4" class="ltx_Math" alttext="Rec([u]_{0},[u]_{1})\rightarrow u" display="inline"><semantics id="S3.SS2.SSS1.p4.20.m20.4a"><mrow id="S3.SS2.SSS1.p4.20.m20.4.4" xref="S3.SS2.SSS1.p4.20.m20.4.4.cmml"><mrow id="S3.SS2.SSS1.p4.20.m20.4.4.2" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.cmml"><mi id="S3.SS2.SSS1.p4.20.m20.4.4.2.4" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.4.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.20.m20.4.4.2.3" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.3.cmml">​</mo><mi id="S3.SS2.SSS1.p4.20.m20.4.4.2.5" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.20.m20.4.4.2.3a" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.3.cmml">​</mo><mi id="S3.SS2.SSS1.p4.20.m20.4.4.2.6" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p4.20.m20.4.4.2.3b" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.3.cmml">​</mo><mrow id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.3" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.3.cmml">(</mo><msub id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.cmml"><mrow id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.2" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.2.1" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.20.m20.1.1" xref="S3.SS2.SSS1.p4.20.m20.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.2.2" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.3" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.3.cmml">0</mn></msub><mo id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.4" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.cmml"><mrow id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.2" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.2.1" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.20.m20.2.2" xref="S3.SS2.SSS1.p4.20.m20.2.2.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.2.2" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.3" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.5" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.SSS1.p4.20.m20.4.4.3" xref="S3.SS2.SSS1.p4.20.m20.4.4.3.cmml">→</mo><mi id="S3.SS2.SSS1.p4.20.m20.4.4.4" xref="S3.SS2.SSS1.p4.20.m20.4.4.4.cmml">u</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.20.m20.4b"><apply id="S3.SS2.SSS1.p4.20.m20.4.4.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4"><ci id="S3.SS2.SSS1.p4.20.m20.4.4.3.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.3">→</ci><apply id="S3.SS2.SSS1.p4.20.m20.4.4.2.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2"><times id="S3.SS2.SSS1.p4.20.m20.4.4.2.3.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.3"></times><ci id="S3.SS2.SSS1.p4.20.m20.4.4.2.4.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.4">𝑅</ci><ci id="S3.SS2.SSS1.p4.20.m20.4.4.2.5.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.5">𝑒</ci><ci id="S3.SS2.SSS1.p4.20.m20.4.4.2.6.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.6">𝑐</ci><interval closure="open" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.3.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2"><apply id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1">subscript</csymbol><apply id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.1.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.20.m20.1.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.1.1">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.20.m20.3.3.1.1.1.1.3">0</cn></apply><apply id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2">subscript</csymbol><apply id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.1.1.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.20.m20.2.2.cmml" xref="S3.SS2.SSS1.p4.20.m20.2.2">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.3.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.2.2.2.2.3">1</cn></apply></interval></apply><ci id="S3.SS2.SSS1.p4.20.m20.4.4.4.cmml" xref="S3.SS2.SSS1.p4.20.m20.4.4.4">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.20.m20.4c">Rec([u]_{0},[u]_{1})\rightarrow u</annotation></semantics></math> is used to reconstruct the original value from the additive shares, which can be done by simply calculating <math id="S3.SS2.SSS1.p4.21.m21.3" class="ltx_Math" alttext="([u]_{0}+[u]_{1})\mod L" display="inline"><semantics id="S3.SS2.SSS1.p4.21.m21.3a"><mrow id="S3.SS2.SSS1.p4.21.m21.3.3" xref="S3.SS2.SSS1.p4.21.m21.3.3.cmml"><mrow id="S3.SS2.SSS1.p4.21.m21.3.3.1.1" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.2" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.cmml"><msub id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.cmml"><mrow id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.2" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.2.1" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.21.m21.1.1" xref="S3.SS2.SSS1.p4.21.m21.1.1.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.2.2" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.3" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.1" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.1.cmml">+</mo><msub id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.cmml"><mrow id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.2" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.2.1" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.1.1.cmml">[</mo><mi id="S3.SS2.SSS1.p4.21.m21.2.2" xref="S3.SS2.SSS1.p4.21.m21.2.2.cmml">u</mi><mo stretchy="false" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.2.2" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.1.1.cmml">]</mo></mrow><mn id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.3" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.3.cmml">1</mn></msub></mrow><mo stretchy="false" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.3" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.SSS1.p4.21.m21.3.3.2" xref="S3.SS2.SSS1.p4.21.m21.3.3.2.cmml">mod</mo><mi id="S3.SS2.SSS1.p4.21.m21.3.3.3" xref="S3.SS2.SSS1.p4.21.m21.3.3.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p4.21.m21.3b"><apply id="S3.SS2.SSS1.p4.21.m21.3.3.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.21.m21.3.3.2.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.2">modulo</csymbol><apply id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1"><plus id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.1"></plus><apply id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2">subscript</csymbol><apply id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.1.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.21.m21.1.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.1.1">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.2.3">0</cn></apply><apply id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3">subscript</csymbol><apply id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.2"><csymbol cd="latexml" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.1.1.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.2.2.1">delimited-[]</csymbol><ci id="S3.SS2.SSS1.p4.21.m21.2.2.cmml" xref="S3.SS2.SSS1.p4.21.m21.2.2">𝑢</ci></apply><cn type="integer" id="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS2.SSS1.p4.21.m21.3.3.3.cmml" xref="S3.SS2.SSS1.p4.21.m21.3.3.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p4.21.m21.3c">([u]_{0}+[u]_{1})\mod L</annotation></semantics></math>. The additive secret-sharing technique has been widely used to construct SMPC protocols for ML operations <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>, <a href="#bib.bib205" title="" class="ltx_ref">205</a>, <a href="#bib.bib206" title="" class="ltx_ref">206</a>, <a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite>. GMW <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> represents a function as a Boolean circuit and uses the value of XOR-based SS. Compared with addition secret sharing, ”XOR” is used instead of addition and ”AND” is used instead of multiplication in GMW.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Homomorphic Encryption</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Homomorphic encryption (HE) makes the operation of plaintext and ciphertext satisfy the homomorphic property, <em id="S3.SS2.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS2.SSS2.p1.1.2" class="ltx_text"></span>, it supports the operation of ciphertext on multiple data, and the result of decryption is the same as the result of the operation of the plaintext of data. Formally, we have</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.6" class="ltx_Math" alttext="f([x_{1}],[x_{2}],\cdots,[x_{n}])\rightarrow[f(x_{1},x_{2},\cdots,x_{n})],\text{ where }\forall x\in\mathcal{X},x_{1},x_{2},\cdots,x_{n}\rightarrow[x_{1}],[x_{2}],\cdots,[x_{n}]." display="block"><semantics id="S3.E3.m1.6a"><mrow id="S3.E3.m1.6.6.1"><mrow id="S3.E3.m1.6.6.1.1.2" xref="S3.E3.m1.6.6.1.1.3.cmml"><mrow id="S3.E3.m1.6.6.1.1.1.1" xref="S3.E3.m1.6.6.1.1.1.1.cmml"><mrow id="S3.E3.m1.6.6.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.1.1.3.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.3.5" xref="S3.E3.m1.6.6.1.1.1.1.3.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.6.6.1.1.1.1.3.4" xref="S3.E3.m1.6.6.1.1.1.1.3.4.cmml">​</mo><mrow id="S3.E3.m1.6.6.1.1.1.1.3.3.3" xref="S3.E3.m1.6.6.1.1.1.1.3.3.4.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.3.3.3.4" xref="S3.E3.m1.6.6.1.1.1.1.3.3.4.cmml">(</mo><mrow id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml">[</mo><msub id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow><mo id="S3.E3.m1.6.6.1.1.1.1.3.3.3.5" xref="S3.E3.m1.6.6.1.1.1.1.3.3.4.cmml">,</mo><mrow id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.2.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.2" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.2.1.cmml">[</mo><msub id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.2" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.3" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.3.cmml">2</mn></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.3" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.2.1.cmml">]</mo></mrow><mo id="S3.E3.m1.6.6.1.1.1.1.3.3.3.6" xref="S3.E3.m1.6.6.1.1.1.1.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">⋯</mi><mo id="S3.E3.m1.6.6.1.1.1.1.3.3.3.7" xref="S3.E3.m1.6.6.1.1.1.1.3.3.4.cmml">,</mo><mrow id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.2.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.2" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.2.1.cmml">[</mo><msub id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.2" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.2.cmml">x</mi><mi id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.3" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.3" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.2.1.cmml">]</mo></mrow><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.3.3.3.8" xref="S3.E3.m1.6.6.1.1.1.1.3.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.5" xref="S3.E3.m1.6.6.1.1.1.1.5.cmml">→</mo><mrow id="S3.E3.m1.6.6.1.1.1.1.4.1" xref="S3.E3.m1.6.6.1.1.1.1.4.2.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.4.1.2" xref="S3.E3.m1.6.6.1.1.1.1.4.2.1.cmml">[</mo><mrow id="S3.E3.m1.6.6.1.1.1.1.4.1.1" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.4.1.1.5" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.4" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.4.cmml">​</mo><mrow id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.4.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.4" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.4.cmml">(</mo><msub id="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.2" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.5" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.4.cmml">,</mo><msub id="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.2" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.3" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.3.cmml">2</mn></msub><mo id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.6" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">⋯</mi><mo id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.7" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.4.cmml">,</mo><msub id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.2" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.2.cmml">x</mi><mi id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.3" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.8" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.6.6.1.1.1.1.4.1.3" xref="S3.E3.m1.6.6.1.1.1.1.4.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E3.m1.6.6.1.1.2.3" xref="S3.E3.m1.6.6.1.1.3a.cmml">,</mo><mrow id="S3.E3.m1.6.6.1.1.2.2.2" xref="S3.E3.m1.6.6.1.1.2.2.3.cmml"><mrow id="S3.E3.m1.6.6.1.1.2.2.1.1" xref="S3.E3.m1.6.6.1.1.2.2.1.1.cmml"><mrow id="S3.E3.m1.6.6.1.1.2.2.1.1.4" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.cmml"><mtext id="S3.E3.m1.6.6.1.1.2.2.1.1.4.2" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.2a.cmml"> where </mtext><mo lspace="0.167em" rspace="0em" id="S3.E3.m1.6.6.1.1.2.2.1.1.4.1" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.1.cmml">​</mo><mrow id="S3.E3.m1.6.6.1.1.2.2.1.1.4.3" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.cmml"><mo rspace="0.167em" id="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.1" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.1.cmml">∀</mo><mi id="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.2" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.2.cmml">x</mi></mrow></mrow><mo id="S3.E3.m1.6.6.1.1.2.2.1.1.3" xref="S3.E3.m1.6.6.1.1.2.2.1.1.3.cmml">∈</mo><mrow id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml">𝒳</mi><mo id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.3" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.3.cmml">,</mo><msub id="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1" xref="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.4" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.3.cmml">,</mo><msub id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.cmml"><mi id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.2" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.3" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.3.cmml">2</mn></msub><mo id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.5" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.E3.m1.5.5" xref="S3.E3.m1.5.5.cmml">⋯</mi></mrow></mrow><mo id="S3.E3.m1.6.6.1.1.2.2.2.3" xref="S3.E3.m1.6.6.1.1.2.2.3a.cmml">,</mo><mrow id="S3.E3.m1.6.6.1.1.2.2.2.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.cmml"><msub id="S3.E3.m1.6.6.1.1.2.2.2.2.5" xref="S3.E3.m1.6.6.1.1.2.2.2.2.5.cmml"><mi id="S3.E3.m1.6.6.1.1.2.2.2.2.5.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.5.2.cmml">x</mi><mi id="S3.E3.m1.6.6.1.1.2.2.2.2.5.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.5.3.cmml">n</mi></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.2.2.2.2.4" xref="S3.E3.m1.6.6.1.1.2.2.2.2.4.cmml">→</mo><mrow id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.4.cmml"><mrow id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.2.1.cmml">[</mo><msub id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.3.cmml">1</mn></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.2.1.cmml">]</mo></mrow><mo id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.4" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.4.cmml">,</mo><mrow id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.2.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.2.1.cmml">[</mo><msub id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.2.cmml">x</mi><mn id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.3.cmml">2</mn></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.2.1.cmml">]</mo></mrow><mo id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.5" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">⋯</mi><mo id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.6" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.4.cmml">,</mo><mrow id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.2.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.2.1.cmml">[</mo><msub id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.2" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.2.cmml">x</mi><mi id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.3" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.2.1.cmml">]</mo></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E3.m1.6.6.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.6b"><apply id="S3.E3.m1.6.6.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.3a.cmml" xref="S3.E3.m1.6.6.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E3.m1.6.6.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1"><ci id="S3.E3.m1.6.6.1.1.1.1.5.cmml" xref="S3.E3.m1.6.6.1.1.1.1.5">→</ci><apply id="S3.E3.m1.6.6.1.1.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3"><times id="S3.E3.m1.6.6.1.1.1.1.3.4.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.4"></times><ci id="S3.E3.m1.6.6.1.1.1.1.3.5.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.5">𝑓</ci><vector id="S3.E3.m1.6.6.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3"><apply id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.3">1</cn></apply></apply><apply id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.2.2.2.2.1.1.3">2</cn></apply></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">⋯</ci><apply id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.2.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.2">𝑥</ci><ci id="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3.3.3.1.1.3">𝑛</ci></apply></apply></vector></apply><apply id="S3.E3.m1.6.6.1.1.1.1.4.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.1.1.4.2.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.6.6.1.1.1.1.4.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1"><times id="S3.E3.m1.6.6.1.1.1.1.4.1.1.4.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.4"></times><ci id="S3.E3.m1.6.6.1.1.1.1.4.1.1.5.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.5">𝑓</ci><vector id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.4.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3"><apply id="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.1.1.1.3">1</cn></apply><apply id="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.2.2.2.3">2</cn></apply><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">⋯</ci><apply id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.2">𝑥</ci><ci id="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.4.1.1.3.3.3.3">𝑛</ci></apply></vector></apply></apply></apply><apply id="S3.E3.m1.6.6.1.1.2.2.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.2.2.3a.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E3.m1.6.6.1.1.2.2.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1"><in id="S3.E3.m1.6.6.1.1.2.2.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.3"></in><apply id="S3.E3.m1.6.6.1.1.2.2.1.1.4.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4"><times id="S3.E3.m1.6.6.1.1.2.2.1.1.4.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.1"></times><ci id="S3.E3.m1.6.6.1.1.2.2.1.1.4.2a.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.2"><mtext id="S3.E3.m1.6.6.1.1.2.2.1.1.4.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.2"> where </mtext></ci><apply id="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.3"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.1">for-all</csymbol><ci id="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.4.3.2">𝑥</ci></apply></apply><list id="S3.E3.m1.6.6.1.1.2.2.1.1.2.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2"><ci id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4">𝒳</ci><apply id="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.1.1.2.2.2.3">2</cn></apply><ci id="S3.E3.m1.5.5.cmml" xref="S3.E3.m1.5.5">⋯</ci></list></apply><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2"><ci id="S3.E3.m1.6.6.1.1.2.2.2.2.4.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.4">→</ci><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.5.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.5"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.2.2.2.2.5.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.5">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.2.2.2.2.5.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.5.2">𝑥</ci><ci id="S3.E3.m1.6.6.1.1.2.2.2.2.5.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.5.3">𝑛</ci></apply><list id="S3.E3.m1.6.6.1.1.2.2.2.2.3.4.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3"><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.2.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.1.1.1.1.1.3">1</cn></apply></apply><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.2">𝑥</ci><cn type="integer" id="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.2.2.2.1.1.3">2</cn></apply></apply><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">⋯</ci><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1"><csymbol cd="latexml" id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.2.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.2">𝑥</ci><ci id="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.2.2.2.2.3.3.3.1.1.3">𝑛</ci></apply></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.6c">f([x_{1}],[x_{2}],\cdots,[x_{n}])\rightarrow[f(x_{1},x_{2},\cdots,x_{n})],\text{ where }\forall x\in\mathcal{X},x_{1},x_{2},\cdots,x_{n}\rightarrow[x_{1}],[x_{2}],\cdots,[x_{n}].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p1.2" class="ltx_p">Homomorphic encryption originated in 1978 when  <cite class="ltx_cite ltx_citemacro_citet">Rivest et al. [<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite> proposed the concept of privacy homomorphism. However, as an open problem, it was not until 2009, when Gentry proposed the first fully homomorphic encryption scheme <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> that the feasibility of computing any function on encrypted data was demonstrated. According to the type and number of ciphertext operations that can be supported, homomorphic encryption can be classified as partial homomorphic encryption (PHE), somewhat homomorphic encryption (SHE), and fully homomorphic encryption (FHE). Specifically, PHE supports only a single type of ciphertext homomorphic operation, mainly including additive homomorphic encryption (AHE) and multiplicative homomorphic encryption (MHE), represented by Paillier <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite>, and ElGamal <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, respectively. SHE supports infinite addition and at least one multiplication operation in the ciphertext space and can be converted into a fully homomorphic encryption scheme using bootstrapping <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> technique. The construction of FHE follows Gentry’s blueprint, <em id="S3.SS2.SSS2.p1.2.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS2.SSS2.p1.2.2" class="ltx_text"></span>, it can perform any number of addition and multiplication operations in the ciphertext space. Most of the current mainstream FHE schemes are constructed based on the lattice difficulty problem, and the representative schemes include BGV <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, BFV <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, GSW <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>, CGGI <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, CKKS <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, <em id="S3.SS2.SSS2.p1.2.3" class="ltx_emph ltx_font_italic">etc</em>.<span id="S3.SS2.SSS2.p1.2.4" class="ltx_text"></span></p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Trusted Execution Environment</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">A Trusted Execution Environment (TEE) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib193" title="" class="ltx_ref">193</a>]</cite> enables a certain part of the federated learning process into a trusted environment in the cloud, whose code can be attested and verified. It provides several properties which guarantee that codes could be executed faithfully and privately. In detail, the confidentiality of TEEs guarantees the program process execution is secret, and the state of code is private; while the integrity of TEE ensures that the code’s execution cannot be affected. In addition, the measurement of TEE provides the remote party with proof of the code being executed and its starting state.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p">The main function of TEE in SFL is to reduce the attack surface of adversaries. For external adversaries, TEE prevents them from stealing training data and intermediate results of the model training process. For internal adversaries, such as servers and participants, TEE can prevent collusion attacks, model reversal attacks, backdoor attacks, <em id="S3.SS2.SSS3.p2.1.1" class="ltx_emph ltx_font_italic">etc</em>.<span id="S3.SS2.SSS3.p2.1.2" class="ltx_text"></span>, between them. Furthermore, TEE can be used to protect the model parameter information.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span id="S3.SS3.1.1" class="ltx_text ltx_font_italic">Secure Federated Learning Works</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In this section, we categorize the SFL-related works in terms of data security, model security, and system security. The specific roadmap is as follows. First, in data security, we give an overview of SFL algorithms that only protect data security. This type of algorithm is generally applied in the training phase.
To balance security and efficiency, they protect only part of the training process and we refer to it as partially secure federated training (PSFT).
Next, in model security, we review SFL algorithms that protect both model and data security. These algorithms enable fully secure federated training (FSFT) while supporting secure federated inference (SFI). Finally, we review representative security systems in SFL.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Data Security</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Here, we present an overview of the SFL algorithms that only protects data security, <em id="S3.SS3.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.SSS1.p1.1.2" class="ltx_text"></span>, PSFT. Specifically, We categorize the PSFT algorithms according to the different defense techniques used in them. As a class of SFL algorithms, PSFT protects part of the federal training process. In detail, the PSFT algorithm completes the training process by protecting the user’s local model gradients. The pipeline of PSFT is shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.3.1 Data Security ‣ 3.3 Secure Federated Learning Works ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2302.10637/assets/Content/security/pictures/PSFT1.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="892" height="129" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">The pipeline of partially secure federated training.</span></figcaption>
</figure>
<div id="S3.SS3.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p"><span id="S3.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_bold">SMPC-based PSFT.</span>
The SMPC-based PSFT algorithms have the advantage of low computational cost and communication volume. However, they usually requires more communication rounds and leaks the aggregation parameters to the server. As a well-known work,  <cite class="ltx_cite ltx_citemacro_citet">Bonawitz et al. [<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> proposes the first SMPC-based PSFT algorithm by using the <span id="S3.SS3.SSS1.p2.1.2" class="ltx_text ltx_font_italic">Diffie-Hellman</span> key exchange protocol  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> and secret sharing. Specifically, it can protect the local parameters under the semi-honest (malicious) model by three(four) rounds of communication, when there are participants dropped in each round. On top of that,  <cite class="ltx_cite ltx_citemacro_citet">Mandal et al. [<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite> reducing the communication cost by using non-interactive key generation and L-regular graphs. Subsequently, <cite class="ltx_cite ltx_citemacro_citet">Bell et al. [<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> demonstrated that each client only needs to share the public key and encrypted share with some of the clients to accomplish secure aggregation. Based on this finding, they further reduce the communication and computation costs. In addition to this, there are some SMPC-based PSFT algorithms <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> that use multiple non-colluding aggregation servers to protect local parameters. Specifically, participants send the shares of local parameters to the corresponding aggregation servers to achieve secure aggregation. Unlike  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> which considers user dropouts, this type of work focuses on how to reduce the amount of communication transmitted by participants. As the first work,  <cite class="ltx_cite ltx_citemacro_citet">Dong et al. [<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> proposes to reduce the communication volume by using a quantization approach. Inspired by this,  <cite class="ltx_cite ltx_citemacro_citet">Beguier and Tramel [<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> further reduces the communication and computational cost of the PSFT algorithm by fusing techniques such as model sparsification, model quantization, and error compensation, making the communication of the PSFT algorithm comparable to or lower than FedAvg.
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p"><span id="S3.SS3.SSS1.p3.1.1" class="ltx_text ltx_font_bold">HE-based PSFT.</span>
Compared with the SMPC-based PSFL algorithms, the HE-based PSFT algorithms have the advantage of additionally ensuring that the global model parameters are not leaked to the curious server. This advantage further reduces the risk of data leakage during the model training phase. Although, the HE-based PSFT algorithms provides strong security guarantees but adds significant computational and communication overheads. Specifically, directly using HE algorithms, such as Paillier cryptosystem to implement security parameter aggregation, causes its computational cost to account for 80% and increases communication by more than 150 times <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib245" title="" class="ltx_ref">245</a>]</cite>. To reduce the computation and communication overhead of the HE-based PSFT algorithms,  <cite class="ltx_cite ltx_citemacro_citet">Aono et al. [<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> proposes a packetized computation, which effectively improves the computation and communication efficiency by encrypting multiple plaintexts after encoding them into one large integer while guaranteeing the correctness of ciphertext computation. Subsequently,  <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. [<a href="#bib.bib245" title="" class="ltx_ref">245</a>]</cite> further reduces the computation and communication overhead of HE-based PSFT algorithms by encrypting the quantized gradients after packing them by deflating, cutting, and quantizing them in advance. In addition,  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib228" title="" class="ltx_ref">228</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib251" title="" class="ltx_ref">251</a>]</cite> designs HE-based PSFT algorithms with verifiable features by introducing bilinear aggregation signatures, homomorphic hashing,  <em id="S3.SS3.SSS1.p3.1.2" class="ltx_emph ltx_font_italic">etc</em>.<span id="S3.SS3.SSS1.p3.1.3" class="ltx_text"></span>, which effectively prevents malicious servers from corrupting or forging aggregation results.</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS1.p4.1" class="ltx_p"><span id="S3.SS3.SSS1.p4.1.1" class="ltx_text ltx_font_bold">TEE-based PSFT.</span> Unlike SMPC and HE, which achieve security assurance for FL at the algorithm level, TEE uses hardware isolation to reduce the risk of data leakage <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib247" title="" class="ltx_ref">247</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite>. Specially, the TEE effectively reducing the attack surface of adversaries in the FL system as well as preventing collusive attacks by participants in the FL system. The main problems faced by TEE in the construction of SFL systems include the lack of storage space and vulnerability to side-channel attacks. To address these problems,  <cite class="ltx_cite ltx_citemacro_citet">Cheng et al. [<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> adopts the ”Separation of power” approach to alleviate the problem of insufficient TEE memory by using multiple TEEs as aggregation servers to complete the aggregation of model parameters. At the same time, participants shuffle the parameters by random permutation before uploading them, effectively preventing TEE from side-channel attacks. In addition,  <cite class="ltx_cite ltx_citemacro_citet">Chen et al. [<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> uses TEE to protect the integrity of the FL training process and prevent malicious participants from tampering with or delaying the local training process. Furthermore, TEE can also provide additional model protection for FL algorithms, making the trained model accessible only to the task initiator after the FL task ends <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib247" title="" class="ltx_ref">247</a>]</cite>.</p>
</div>
<div id="S3.SS3.SSS1.p5" class="ltx_para">
<p id="S3.SS3.SSS1.p5.1" class="ltx_p">In addition to this, some PSFT algorithms consider scenarios in which participants’ data are divided according to features. In this setting, <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>, <a href="#bib.bib225" title="" class="ltx_ref">225</a>]</cite> design PSFT algorithms about linear regression and xgboost based on SMPC. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib233" title="" class="ltx_ref">233</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib254" title="" class="ltx_ref">254</a>]</cite> consider the design of the PSFT algorithms by using HE.
Specifically, <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>, <a href="#bib.bib233" title="" class="ltx_ref">233</a>]</cite> propose PSFT algorithms on logistic regression. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> propose the PSFT algorithm about tree-based model. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib254" title="" class="ltx_ref">254</a>]</cite> design PSFT algorithms about neural network. Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Chamani and Papadopoulos [<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> uses TEE to design PSFT algorithm. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib217" title="" class="ltx_ref">217</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> further improve the security of PSFT algorithms by fusing SMPC and HE. Recently, <cite class="ltx_cite ltx_citemacro_citet">Liu et al. [<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite> provides an overview of federal learning algorithms by features.</p>
</div>
<div id="S3.SS3.SSS1.p6" class="ltx_para">
<p id="S3.SS3.SSS1.p6.1" class="ltx_p">In general, PSFT algorithms based on different technologies have their own characteristics. Specifically, the SMPC-based PSFT algorithms have good computational efficiency and can solve the user dropout problem using SS, making them more suitable for scenarios where the participants are mobile devices. In contrast, the HE-based PSFT algorithm is more suitable for scenarios where participants have stable communication and strong computational power. Furtermore, TEE can provide stronger hardware protection on top of the algorithm protection. Although, the good efficiency of PSFT makes it possible to train complex models, however, PSFT leaks global parameters to users or aggregation servers. This may compromise the confidentiality of the data to some extent.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2302.10637/assets/Content/security/pictures/FSFT.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="561" height="236" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">The pipeline of fully secure federated training.</span></figcaption>
</figure>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Model Security</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">In the following, we present an overview of SFL algorithms that can protect both model and data security.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p"><span id="S3.SS3.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Fully Secure Federated Learning.</span>
Compared to the PSFT algorithms, which can only provide partial protection, FSFT algorithms achieve complete protection of the federation training process. Specifically, they convert the basic operations in machine learning such as matrix multiplication, and activation functions into corresponding secure operations using secure computing techniques. The FSFT algorithms usually adopts an architecture of outsourced computing, whose security relies on the assumption of non-collusion among the outsourced computing servers.
In detail, the data and model owner first encrypts the data and model and sends it to the cloud servers. Then, the cloud servers the use the encrypted data and model interactions to complete the FL training process to obtain the encrypted model parameters. The pipeline of FSFT is shown in Fig. <a href="#S3.F4" title="Figure 4 ‣ 3.3.1 Data Security ‣ 3.3 Secure Federated Learning Works ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We classify the work of FSFT according to the number of servers. A summary of the FSFT algorithms is shown in Table <a href="#S3.T2" title="Table II ‣ 3.3.2 Model Security ‣ 3.3 Secure Federated Learning Works ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.17.1.1" class="ltx_text" style="font-size:90%;">Table II</span>: </span><span id="S3.T2.18.2" class="ltx_text" style="font-size:90%;">Fully Secure Federated Train Algorithms</span></figcaption>
<div id="S3.T2.15" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:202.3pt;vertical-align:-48.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-214.0pt,76.0pt) scale(0.503233196236442,0.503233196236442) ;">
<table id="S3.T2.15.15" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.15.15.16.1" class="ltx_tr">
<th id="S3.T2.15.15.16.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2"><span id="S3.T2.15.15.16.1.1.1" class="ltx_text">No. of Servers</span></th>
<th id="S3.T2.15.15.16.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Security Model</th>
<th id="S3.T2.15.15.16.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T2.15.15.16.1.3.1" class="ltx_text">Secure Defense Methods</span></th>
<th id="S3.T2.15.15.16.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T2.15.15.16.1.4.1" class="ltx_text">Model</span></th>
<th id="S3.T2.15.15.16.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T2.15.15.16.1.5.1" class="ltx_text">Dataset</span></th>
<th id="S3.T2.15.15.16.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T2.15.15.16.1.6.1" class="ltx_text">References</span></th>
</tr>
<tr id="S3.T2.15.15.17.2" class="ltx_tr">
<th id="S3.T2.15.15.17.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Semi-honest</th>
<th id="S3.T2.15.15.17.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Malicious</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><mn id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><cn type="integer" id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">D</td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">✘</td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">GC/OT/SS/HE</td>
<td id="S3.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite>
</td>
<td id="S3.T2.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">MNIST</td>
<td id="S3.T2.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">SecureML  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite>
</td>
</tr>
<tr id="S3.T2.2.2.2" class="ltx_tr">
<th id="S3.T2.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T2.2.2.2.1.m1.1a"><mn id="S3.T2.2.2.2.1.m1.1.1" xref="S3.T2.2.2.2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.m1.1b"><cn type="integer" id="S3.T2.2.2.2.1.m1.1.1.cmml" xref="S3.T2.2.2.2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T2.2.2.2.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T2.2.2.2.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T2.2.2.2.4" class="ltx_td ltx_align_center">GC/OT/SS</td>
<td id="S3.T2.2.2.2.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</td>
<td id="S3.T2.2.2.2.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.2.2.2.7" class="ltx_td ltx_align_center">QUOTINENT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</td>
</tr>
<tr id="S3.T2.3.3.3" class="ltx_tr">
<th id="S3.T2.3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T2.3.3.3.1.m1.1a"><mn id="S3.T2.3.3.3.1.m1.1.1" xref="S3.T2.3.3.3.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b"><cn type="integer" id="S3.T2.3.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T2.3.3.3.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T2.3.3.3.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T2.3.3.3.4" class="ltx_td ltx_align_center">GC/OT/SS/HE</td>
<td id="S3.T2.3.3.3.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>
</td>
<td id="S3.T2.3.3.3.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.3.3.3.7" class="ltx_td ltx_align_center">ABY2.0 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>
</td>
</tr>
<tr id="S3.T2.4.4.4" class="ltx_tr">
<th id="S3.T2.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.4.4.4.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T2.4.4.4.1.m1.1a"><mn id="S3.T2.4.4.4.1.m1.1.1" xref="S3.T2.4.4.4.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.1.m1.1b"><cn type="integer" id="S3.T2.4.4.4.1.m1.1.1.cmml" xref="S3.T2.4.4.4.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T2.4.4.4.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T2.4.4.4.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T2.4.4.4.4" class="ltx_td ltx_align_center">GC/OT/SS/HE</td>
<td id="S3.T2.4.4.4.5" class="ltx_td ltx_align_center">PR <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>
</td>
<td id="S3.T2.4.4.4.6" class="ltx_td ltx_align_center">Smoking and Cancer</td>
<td id="S3.T2.4.4.4.7" class="ltx_td ltx_align_center"><cite class="ltx_cite ltx_citemacro_citet">Kelkar et al. [<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite></td>
</tr>
<tr id="S3.T2.5.5.5" class="ltx_tr">
<th id="S3.T2.5.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.T2.5.5.5.1.m1.1a"><mn id="S3.T2.5.5.5.1.m1.1.1" xref="S3.T2.5.5.5.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.1.m1.1b"><cn type="integer" id="S3.T2.5.5.5.1.m1.1.1.cmml" xref="S3.T2.5.5.5.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.1.m1.1c">3</annotation></semantics></math></th>
<td id="S3.T2.5.5.5.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.5.5.5.3" class="ltx_td ltx_align_center">Abort</td>
<td id="S3.T2.5.5.5.4" class="ltx_td ltx_align_center">GC/OT/SS</td>
<td id="S3.T2.5.5.5.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>
</td>
<td id="S3.T2.5.5.5.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.5.5.5.7" class="ltx_td ltx_align_center">ABY3 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>
</td>
</tr>
<tr id="S3.T2.6.6.6" class="ltx_tr">
<th id="S3.T2.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.6.6.6.1.m1.1" class="ltx_Math" alttext="3/4" display="inline"><semantics id="S3.T2.6.6.6.1.m1.1a"><mrow id="S3.T2.6.6.6.1.m1.1.1" xref="S3.T2.6.6.6.1.m1.1.1.cmml"><mn id="S3.T2.6.6.6.1.m1.1.1.2" xref="S3.T2.6.6.6.1.m1.1.1.2.cmml">3</mn><mo id="S3.T2.6.6.6.1.m1.1.1.1" xref="S3.T2.6.6.6.1.m1.1.1.1.cmml">/</mo><mn id="S3.T2.6.6.6.1.m1.1.1.3" xref="S3.T2.6.6.6.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.1.m1.1b"><apply id="S3.T2.6.6.6.1.m1.1.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1"><divide id="S3.T2.6.6.6.1.m1.1.1.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1.1"></divide><cn type="integer" id="S3.T2.6.6.6.1.m1.1.1.2.cmml" xref="S3.T2.6.6.6.1.m1.1.1.2">3</cn><cn type="integer" id="S3.T2.6.6.6.1.m1.1.1.3.cmml" xref="S3.T2.6.6.6.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.6.1.m1.1c">3/4</annotation></semantics></math></th>
<td id="S3.T2.6.6.6.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.6.6.6.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T2.6.6.6.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.6.6.6.5" class="ltx_td ltx_align_center">LeNet<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite>
</td>
<td id="S3.T2.6.6.6.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.6.6.6.7" class="ltx_td ltx_align_center">SecureNN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite>
</td>
</tr>
<tr id="S3.T2.7.7.7" class="ltx_tr">
<th id="S3.T2.7.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.7.7.7.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.T2.7.7.7.1.m1.1a"><mn id="S3.T2.7.7.7.1.m1.1.1" xref="S3.T2.7.7.7.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.1.m1.1b"><cn type="integer" id="S3.T2.7.7.7.1.m1.1.1.cmml" xref="S3.T2.7.7.7.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.7.1.m1.1c">3</annotation></semantics></math></th>
<td id="S3.T2.7.7.7.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.7.7.7.3" class="ltx_td ltx_align_center">Abort</td>
<td id="S3.T2.7.7.7.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.7.7.7.5" class="ltx_td ltx_align_center">VGG16 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>]</cite>
</td>
<td id="S3.T2.7.7.7.6" class="ltx_td ltx_align_center">Tiny ImageNet</td>
<td id="S3.T2.7.7.7.7" class="ltx_td ltx_align_center">FALCON <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>]</cite>
</td>
</tr>
<tr id="S3.T2.8.8.8" class="ltx_tr">
<th id="S3.T2.8.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.8.8.8.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.T2.8.8.8.1.m1.1a"><mn id="S3.T2.8.8.8.1.m1.1.1" xref="S3.T2.8.8.8.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.8.1.m1.1b"><cn type="integer" id="S3.T2.8.8.8.1.m1.1.1.cmml" xref="S3.T2.8.8.8.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.8.1.m1.1c">3</annotation></semantics></math></th>
<td id="S3.T2.8.8.8.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.8.8.8.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T2.8.8.8.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.8.8.8.5" class="ltx_td ltx_align_center">VGG16 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite>
</td>
<td id="S3.T2.8.8.8.6" class="ltx_td ltx_align_center">Tiny ImageNet</td>
<td id="S3.T2.8.8.8.7" class="ltx_td ltx_align_center">ARIANN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite>
</td>
</tr>
<tr id="S3.T2.9.9.9" class="ltx_tr">
<th id="S3.T2.9.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.T2.9.9.9.1.m1.1a"><mn id="S3.T2.9.9.9.1.m1.1.1" xref="S3.T2.9.9.9.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.9.1.m1.1b"><cn type="integer" id="S3.T2.9.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.9.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.9.1.m1.1c">3</annotation></semantics></math></th>
<td id="S3.T2.9.9.9.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.9.9.9.3" class="ltx_td ltx_align_center">Fairness</td>
<td id="S3.T2.9.9.9.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.9.9.9.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>
</td>
<td id="S3.T2.9.9.9.6" class="ltx_td ltx_align_center">Parkinson</td>
<td id="S3.T2.9.9.9.7" class="ltx_td ltx_align_center">BLAZE <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>
</td>
</tr>
<tr id="S3.T2.10.10.10" class="ltx_tr">
<th id="S3.T2.10.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.10.10.10.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.T2.10.10.10.1.m1.1a"><mn id="S3.T2.10.10.10.1.m1.1.1" xref="S3.T2.10.10.10.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.10.1.m1.1b"><cn type="integer" id="S3.T2.10.10.10.1.m1.1.1.cmml" xref="S3.T2.10.10.10.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.10.1.m1.1c">4</annotation></semantics></math></th>
<td id="S3.T2.10.10.10.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.10.10.10.3" class="ltx_td ltx_align_center">Fairness</td>
<td id="S3.T2.10.10.10.4" class="ltx_td ltx_align_center">GC/SS</td>
<td id="S3.T2.10.10.10.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>
</td>
<td id="S3.T2.10.10.10.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.10.10.10.7" class="ltx_td ltx_align_center">PrivPy <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>
</td>
</tr>
<tr id="S3.T2.11.11.11" class="ltx_tr">
<th id="S3.T2.11.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.11.11.11.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.T2.11.11.11.1.m1.1a"><mn id="S3.T2.11.11.11.1.m1.1.1" xref="S3.T2.11.11.11.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.11.1.m1.1b"><cn type="integer" id="S3.T2.11.11.11.1.m1.1.1.cmml" xref="S3.T2.11.11.11.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.11.1.m1.1c">4</annotation></semantics></math></th>
<td id="S3.T2.11.11.11.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.11.11.11.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T2.11.11.11.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.11.11.11.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S3.T2.11.11.11.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.11.11.11.7" class="ltx_td ltx_align_center">Trident <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
</tr>
<tr id="S3.T2.12.12.12" class="ltx_tr">
<th id="S3.T2.12.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.12.12.12.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.T2.12.12.12.1.m1.1a"><mn id="S3.T2.12.12.12.1.m1.1.1" xref="S3.T2.12.12.12.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.T2.12.12.12.1.m1.1b"><cn type="integer" id="S3.T2.12.12.12.1.m1.1.1.cmml" xref="S3.T2.12.12.12.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.12.12.1.m1.1c">4</annotation></semantics></math></th>
<td id="S3.T2.12.12.12.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.12.12.12.3" class="ltx_td ltx_align_center">GOD</td>
<td id="S3.T2.12.12.12.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.12.12.12.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="S3.T2.12.12.12.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.12.12.12.7" class="ltx_td ltx_align_center">Fantastic Four <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
</tr>
<tr id="S3.T2.13.13.13" class="ltx_tr">
<th id="S3.T2.13.13.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.T2.13.13.13.1.m1.1a"><mn id="S3.T2.13.13.13.1.m1.1.1" xref="S3.T2.13.13.13.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.T2.13.13.13.1.m1.1b"><cn type="integer" id="S3.T2.13.13.13.1.m1.1.1.cmml" xref="S3.T2.13.13.13.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.13.13.1.m1.1c">4</annotation></semantics></math></th>
<td id="S3.T2.13.13.13.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.13.13.13.3" class="ltx_td ltx_align_center">GOD</td>
<td id="S3.T2.13.13.13.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.13.13.13.5" class="ltx_td ltx_align_center">FC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S3.T2.13.13.13.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.13.13.13.7" class="ltx_td ltx_align_center">FLASH <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
</tr>
<tr id="S3.T2.14.14.14" class="ltx_tr">
<th id="S3.T2.14.14.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T2.14.14.14.1.m1.1" class="ltx_Math" alttext="3/4" display="inline"><semantics id="S3.T2.14.14.14.1.m1.1a"><mrow id="S3.T2.14.14.14.1.m1.1.1" xref="S3.T2.14.14.14.1.m1.1.1.cmml"><mn id="S3.T2.14.14.14.1.m1.1.1.2" xref="S3.T2.14.14.14.1.m1.1.1.2.cmml">3</mn><mo id="S3.T2.14.14.14.1.m1.1.1.1" xref="S3.T2.14.14.14.1.m1.1.1.1.cmml">/</mo><mn id="S3.T2.14.14.14.1.m1.1.1.3" xref="S3.T2.14.14.14.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.14.14.14.1.m1.1b"><apply id="S3.T2.14.14.14.1.m1.1.1.cmml" xref="S3.T2.14.14.14.1.m1.1.1"><divide id="S3.T2.14.14.14.1.m1.1.1.1.cmml" xref="S3.T2.14.14.14.1.m1.1.1.1"></divide><cn type="integer" id="S3.T2.14.14.14.1.m1.1.1.2.cmml" xref="S3.T2.14.14.14.1.m1.1.1.2">3</cn><cn type="integer" id="S3.T2.14.14.14.1.m1.1.1.3.cmml" xref="S3.T2.14.14.14.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.14.14.1.m1.1c">3/4</annotation></semantics></math></th>
<td id="S3.T2.14.14.14.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T2.14.14.14.3" class="ltx_td ltx_align_center">GOD</td>
<td id="S3.T2.14.14.14.4" class="ltx_td ltx_align_center">SS</td>
<td id="S3.T2.14.14.14.5" class="ltx_td ltx_align_center">LR <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>
</td>
<td id="S3.T2.14.14.14.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T2.14.14.14.7" class="ltx_td ltx_align_center">SWIFT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>
</td>
</tr>
<tr id="S3.T2.15.15.15" class="ltx_tr">
<th id="S3.T2.15.15.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb"><math id="S3.T2.15.15.15.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.T2.15.15.15.1.m1.1a"><mn id="S3.T2.15.15.15.1.m1.1.1" xref="S3.T2.15.15.15.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.T2.15.15.15.1.m1.1b"><cn type="integer" id="S3.T2.15.15.15.1.m1.1.1.cmml" xref="S3.T2.15.15.15.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.15.15.1.m1.1c">4</annotation></semantics></math></th>
<td id="S3.T2.15.15.15.2" class="ltx_td ltx_align_center ltx_border_bb">H</td>
<td id="S3.T2.15.15.15.3" class="ltx_td ltx_align_center ltx_border_bb">GOD</td>
<td id="S3.T2.15.15.15.4" class="ltx_td ltx_align_center ltx_border_bb">GC/SS</td>
<td id="S3.T2.15.15.15.5" class="ltx_td ltx_align_center ltx_border_bb">LeNet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>
</td>
<td id="S3.T2.15.15.15.6" class="ltx_td ltx_align_center ltx_border_bb">MNIST</td>
<td id="S3.T2.15.15.15.7" class="ltx_td ltx_align_center ltx_border_bb">Tetrad <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>
</td>
</tr>
</tbody>
</table>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span> 
<div id="S3.I1.ix1.p1" class="ltx_para">
<p id="S3.I1.ix1.p1.1" class="ltx_p">“✘” denotes not support; “H” denotes honest majority; “D” denotes dishonest majority; “LR” denotes logistic regression; “PR” denotes Poisson regression; “FC” denotes a fully connected neural network.</p>
</div>
</li>
<li id="S3.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2</span> 
<div id="S3.I1.ix2.p1" class="ltx_para">
<p id="S3.I1.ix2.p1.1" class="ltx_p">For the accuracy of the network structure, it is recommended to refer to the original paper. When work is performed on multiple models and datasets, we list only the most complex models and datasets in their experiments. Different works may tailor the network structure or dataset according to the characteristics of the designed FSFT algorithm, such as replacing the loss function, reducing the number of samples, <em id="S3.I1.ix2.p1.1.1" class="ltx_emph ltx_font_italic">etc</em>.<span id="S3.I1.ix2.p1.1.2" class="ltx_text"></span> For the accuracy of the experiments, it is recommended to refer to the original paper.</p>
</div>
</li>
</ul>
</span></div>
</figure>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p">Under the two server architecture, SecureML <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite> first introduces SS technology into model training for machine learning, and designed a secure SGD algorithm for semi-honest models by fusing GC. The effectiveness of SecureML is demonstrated by secure training of linear regression, logistic regression, and fully connected neural network on MNIST. Subsequently, Quotient <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> is designed by converting the original neural network into a three-valued neural network, <em id="S3.SS3.SSS2.p3.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.SSS2.p3.1.2" class="ltx_text"></span>, the parameters contain only <math id="S3.SS3.SSS2.p3.1.m1.3" class="ltx_Math" alttext="\{-1,0,1\}" display="inline"><semantics id="S3.SS3.SSS2.p3.1.m1.3a"><mrow id="S3.SS3.SSS2.p3.1.m1.3.3.1" xref="S3.SS3.SSS2.p3.1.m1.3.3.2.cmml"><mo stretchy="false" id="S3.SS3.SSS2.p3.1.m1.3.3.1.2" xref="S3.SS3.SSS2.p3.1.m1.3.3.2.cmml">{</mo><mrow id="S3.SS3.SSS2.p3.1.m1.3.3.1.1" xref="S3.SS3.SSS2.p3.1.m1.3.3.1.1.cmml"><mo id="S3.SS3.SSS2.p3.1.m1.3.3.1.1a" xref="S3.SS3.SSS2.p3.1.m1.3.3.1.1.cmml">−</mo><mn id="S3.SS3.SSS2.p3.1.m1.3.3.1.1.2" xref="S3.SS3.SSS2.p3.1.m1.3.3.1.1.2.cmml">1</mn></mrow><mo id="S3.SS3.SSS2.p3.1.m1.3.3.1.3" xref="S3.SS3.SSS2.p3.1.m1.3.3.2.cmml">,</mo><mn id="S3.SS3.SSS2.p3.1.m1.1.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.cmml">0</mn><mo id="S3.SS3.SSS2.p3.1.m1.3.3.1.4" xref="S3.SS3.SSS2.p3.1.m1.3.3.2.cmml">,</mo><mn id="S3.SS3.SSS2.p3.1.m1.2.2" xref="S3.SS3.SSS2.p3.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS3.SSS2.p3.1.m1.3.3.1.5" xref="S3.SS3.SSS2.p3.1.m1.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.1.m1.3b"><set id="S3.SS3.SSS2.p3.1.m1.3.3.2.cmml" xref="S3.SS3.SSS2.p3.1.m1.3.3.1"><apply id="S3.SS3.SSS2.p3.1.m1.3.3.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.3.3.1.1"><minus id="S3.SS3.SSS2.p3.1.m1.3.3.1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.3.3.1.1"></minus><cn type="integer" id="S3.SS3.SSS2.p3.1.m1.3.3.1.1.2.cmml" xref="S3.SS3.SSS2.p3.1.m1.3.3.1.1.2">1</cn></apply><cn type="integer" id="S3.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1">0</cn><cn type="integer" id="S3.SS3.SSS2.p3.1.m1.2.2.cmml" xref="S3.SS3.SSS2.p3.1.m1.2.2">1</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.1.m1.3c">\{-1,0,1\}</annotation></semantics></math>. The efficiency of SecureML is improved by a factor of 13 while maintaining the model performance. In addition, ABY2.0 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite> reduces the communication overhead of the online phase of the secure multiplication operator by proposing new SS semantics. On top of this, the overall efficiency of SecureML has been improved by up to 6.1 times. Furthermore,  <cite class="ltx_cite ltx_citemacro_citet">Kelkar et al. [<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite> achieves security computation of the exponential operator by transforming SS between different semantics and completes the training of <span id="S3.SS3.SSS2.p3.1.3" class="ltx_text ltx_font_italic">Poisson regression</span>.</p>
</div>
<div id="S3.SS3.SSS2.p4" class="ltx_para">
<p id="S3.SS3.SSS2.p4.1" class="ltx_p">Under a three-server architecture, ABY3 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> designs the FSFT algorithm under both semi-honest and malicious settings by fusing SS and GC. By optimizing the secure multiplication operator and the conversion protocol between SS and GC, the efficiency of SecureML is greatly improved. Experimental results show that  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> is 55,000 times faster than  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite> in secure neural network training. Subsequently, Blaze <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite> optimized ABY3 by proposing new SS semantics in a three-server architecture and achieved an efficiency improvement of up to 2,610 times. Unlike with ABY3 which uses three computational servers, SecureNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite> designs secure FSFT under a semi-honest model by introducing an auxiliary service server. With the assistance of the auxiliary server, SecureNN greatly reduces the communication and computation overhead caused by HE or OT in the preprocessing phase of FSFT under the two-service architecture. Experimental results show that secure neural networks trained using SecureNN over LAN and WAN are 79 and 553 times faster than SecureML, respectively. Subsequently, Falcon <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>]</cite> is designed by fusing the techniques of  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite> and  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>. By implementing secure computation of batch normalization functions,  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>]</cite> can accomplish secure training of complex neural network models including VGG16.
In addition, ARIANN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite> also designs the FSFT algorithm by using the auxiliary server model.
However, by resorting to the function secret sharing technique, ARIANN greatly optimizes the online efficiency of SecureNN nonlinear operations, i.e., achieves secure comparison operations with only one round of communication in the online phase.
Under a four-server architecture,
Privpy <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite> improves the efficiency of multiplicative online computation greatly by introducing replicated 2-out-of-4-SS. Furthermore,  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite> improve the efficiency or security of the FSFT, respectively.</p>
</div>
<div id="S3.SS3.SSS2.p5" class="ltx_para">
<p id="S3.SS3.SSS2.p5.1" class="ltx_p">In summary, the FSFT algorithms achieve complete protection of the training process compared to the PSFT Algorithm. Specifically, all sensitive data in the training process including intermediate parameters are effectively protected by the FSFT algorithms. Meanwhile, by using outsourced computing, they are making full use of the computing resources of the cloud server and reduce the local computing of the participants. Although the efficiency of FSFT algorithms have been greatly improved in recent years, however, they are still very slow and cannot complete most deep learning training tasks in a reasonable time. Therefore, they are suitable for simple training tasks with high security.</p>
</div>
<div id="S3.SS3.SSS2.p6" class="ltx_para ltx_noindent">
<p id="S3.SS3.SSS2.p6.1" class="ltx_p"><span id="S3.SS3.SSS2.p6.1.1" class="ltx_text ltx_font_bold">Secure Federated Inference (SFI).</span>
The SFI algorithms allow prediction tasks to be completed while protecting the security of the model provider’s model and the user’s prediction data. Specifically, they convert the operations in the prediction process, such as matrix multiplication and activation functions, into secure operations through secure computing techniques. They often adopt a client-server architecture. In detail, the model provider first deploys the model encrypted or publicly to a cloud server to provide inference services. Users with inference needs send the encrypted inference samples to the cloud servers. Then, the cloud server completes the inference task on the encrypted model and data, and returns the inference results to the user. The pipeline of SFI is shown in Fig. <a href="#S3.F5" title="Figure 5 ‣ 3.3.2 Model Security ‣ 3.3 Secure Federated Learning Works ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We also classify the SFI algorithm by the number of servers. A summary of the SFI algorithms is shown in Table <a href="#S3.T3" title="Table III ‣ 3.3.2 Model Security ‣ 3.3 Secure Federated Learning Works ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
<div id="S3.SS3.SSS2.p7" class="ltx_para">
<p id="S3.SS3.SSS2.p7.1" class="ltx_p">Under one server architecture, CryptoDL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> and CryptoNets <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> implemented deep convolutional neural networks for secure prediction on MNIST using HE. By using polynomials to approximate nonlinear activation functions, such as ReLU, Sigmoid, <em id="S3.SS3.SSS2.p7.1.1" class="ltx_emph ltx_font_italic">etc</em>.<span id="S3.SS3.SSS2.p7.1.2" class="ltx_text"></span>, they achieve the expected prediction performance of 99% on MNIST.
Subsequently, to address the problem that HE is difficult to achieve secure computation of nonlinear operations,  <cite class="ltx_cite ltx_citemacro_citet">Fenner and Pyzer-Knapp [<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> proposes a way of server-user interaction. Specifically, the server first completes the linear computation of SFI in the ciphertext state and sends the computation result to the user. The user decrypts and then completes the nonlinear computation in the plaintext state and sends the computed result encrypted to the server. THE-X <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, also adopts the same server-user interactive computation and uses linear neural networks to achieve the approximation of nonlinear operations, such as softmax and layer-norm. After optimization, THE-X achieves the first secure inference of BERT-tiny.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2302.10637/assets/Content/security/pictures/SFI.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="174" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.3.2" class="ltx_text" style="font-size:90%;">The pipeline of secure federated inference.</span></figcaption>
</figure>
<div id="S3.SS3.SSS2.p8" class="ltx_para">
<p id="S3.SS3.SSS2.p8.1" class="ltx_p">Under two server architecture, DeepSecure <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite> uses GC to achieve secure prediction and avoids polynomial approximation computation. Although <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite> uses a binarized neural network to optimize communication efficiency, the communication overhead is still huge. As one of the most famous working SFI, MiniONN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite> is designed by integrating HE and GC. By exploiting the advantages of different techniques, <em id="S3.SS3.SSS2.p8.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.SSS2.p8.1.2" class="ltx_text"></span>, HE for linear computation and GC for nonlinear computation, MiniONN greatly improves the overall efficiency of the SFI algorithm. Received inspiration from MiniONN Gazelle <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>, also designes the SFI algorithm by combing HE and GC and additionally improved the computational efficiency of HE by using single instruction, multiple data (SIMD). In addition, Delphi <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> improves the efficiency of the SFI algorithm by transferring the computation on HE in Gazelle to be done offline and introducing neural architecture search (NAS) to optimize the preprocessing. It is worth mentioning that Delphi is one of the earlier works that tried to accelerate SFI computation using GPUs. Furthermore, XONN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite> reduces the communication overhead by introducing model pruning and secret sharing techniques based on DeepSecure. Subsequently, Cryptflow2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite> optimizes the communication efficiency of the nonlinear activation function of the SFI algorithm using OT and the first ResNet50 and DenseNet121 security predictions were implemented by using Cryptflow2. Unlike existing SFI algorithms, which all use the same bit-width integers for computation, SIRNN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite> uses shorter bit-widths for part of the computation, further reducing the SFI algorithm communication cost, and designing a non-uniform bit-width SFI algorithm in a two-server architecture. Experimental results show that SIRNN can effectively support secure inference for Heads <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite>. As the state-of-the-art work in a two-server architecture, Cheetah <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> avoids the expensive rotation operation under the SIMD packing technique by cleverly constructing the mapping between plaintext and ciphertext, and improves the computation and communication efficiency of the linear layer of SFI algorithm. Besides, Cheetah also optimizes the nonlinear computation of SFI algorithm by using slient-OT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib231" title="" class="ltx_ref">231</a>]</cite>.</p>
</div>
<div id="S3.SS3.SSS2.p9" class="ltx_para">
<p id="S3.SS3.SSS2.p9.1" class="ltx_p">Under three server architecture, Chameleon <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib168" title="" class="ltx_ref">168</a>]</cite> optimizes the communication in the offline phase of the SFI algorithm and the conversion efficiency of GC and SS in the online phase by introducing an assistance server. Furthermore, through consistency detection and fair reconstruction protocols, Astra <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> implements a secure SFI algorithm under the malicious model. Through different forms of secret-sharing techniques Astra optimizes the communication efficiency of the online phase of the secure multiplication operator. 
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.SSS2.p10" class="ltx_para">
<p id="S3.SS3.SSS2.p10.1" class="ltx_p">Overall, SFI algorithms are well suited for Machine Learning as a Service (MLaaS) scenarios as they protect sensitive data during model deployment and inference.
Currently, they have been able to implement inference tasks for complex deep models in a reasonable time. In the design of algorithms, the technical route of simultaneously using multiple secure computing techniques to enhance the efficiency of SFI algorithms is gradually becoming mainstream. In addition, SFI algorithms are further enhanced effectively through the incorporation of methods such as model quantization and the interaction computation between client and server.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.16.1.1" class="ltx_text" style="font-size:90%;">Table III</span>: </span><span id="S3.T3.17.2" class="ltx_text" style="font-size:90%;">Secure Federated Inference Algorithms</span></figcaption>
<div id="S3.T3.14" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:165.8pt;vertical-align:-37.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-269.5pt,79.8pt) scale(0.445868199195628,0.445868199195628) ;">
<table id="S3.T3.14.14" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.14.14.15.1" class="ltx_tr">
<th id="S3.T3.14.14.15.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2"><span id="S3.T3.14.14.15.1.1.1" class="ltx_text">No. of Servers</span></th>
<th id="S3.T3.14.14.15.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Security Model</th>
<th id="S3.T3.14.14.15.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T3.14.14.15.1.3.1" class="ltx_text">Secure Defense Methods</span></th>
<th id="S3.T3.14.14.15.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T3.14.14.15.1.4.1" class="ltx_text">Model</span></th>
<th id="S3.T3.14.14.15.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T3.14.14.15.1.5.1" class="ltx_text">Dataset</span></th>
<th id="S3.T3.14.14.15.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T3.14.14.15.1.6.1" class="ltx_text">References</span></th>
</tr>
<tr id="S3.T3.14.14.16.2" class="ltx_tr">
<th id="S3.T3.14.14.16.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Semi-honest</th>
<th id="S3.T3.14.14.16.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Malicious</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<th id="S3.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><math id="S3.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.T3.1.1.1.1.m1.1a"><mn id="S3.T3.1.1.1.1.m1.1.1" xref="S3.T3.1.1.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.m1.1b"><cn type="integer" id="S3.T3.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.m1.1c">1</annotation></semantics></math></th>
<td id="S3.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">D</td>
<td id="S3.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">✘</td>
<td id="S3.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">HE</td>
<td id="S3.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">Shallow CNN</td>
<td id="S3.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">MNIST</td>
<td id="S3.T3.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">CryptoDL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>
</td>
</tr>
<tr id="S3.T3.2.2.2" class="ltx_tr">
<th id="S3.T3.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.T3.2.2.2.1.m1.1a"><mn id="S3.T3.2.2.2.1.m1.1.1" xref="S3.T3.2.2.2.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.1.m1.1b"><cn type="integer" id="S3.T3.2.2.2.1.m1.1.1.cmml" xref="S3.T3.2.2.2.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.1.m1.1c">1</annotation></semantics></math></th>
<td id="S3.T3.2.2.2.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.2.2.2.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.2.2.2.4" class="ltx_td ltx_align_center">HE</td>
<td id="S3.T3.2.2.2.5" class="ltx_td ltx_align_center">Shallow CNN</td>
<td id="S3.T3.2.2.2.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T3.2.2.2.7" class="ltx_td ltx_align_center">CryptoNets <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>
</td>
</tr>
<tr id="S3.T3.3.3.3" class="ltx_tr">
<th id="S3.T3.3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.3.3.3.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.T3.3.3.3.1.m1.1a"><mn id="S3.T3.3.3.3.1.m1.1.1" xref="S3.T3.3.3.3.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.1.m1.1b"><cn type="integer" id="S3.T3.3.3.3.1.m1.1.1.cmml" xref="S3.T3.3.3.3.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.1.m1.1c">1</annotation></semantics></math></th>
<td id="S3.T3.3.3.3.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.3.3.3.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.3.3.3.4" class="ltx_td ltx_align_center">HE</td>
<td id="S3.T3.3.3.3.5" class="ltx_td ltx_align_center">GP</td>
<td id="S3.T3.3.3.3.6" class="ltx_td ltx_align_center">P. falciparum</td>
<td id="S3.T3.3.3.3.7" class="ltx_td ltx_align_center"> <cite class="ltx_cite ltx_citemacro_citet">Fenner and Pyzer-Knapp [<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>
</td>
</tr>
<tr id="S3.T3.4.4.4" class="ltx_tr">
<th id="S3.T3.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.4.4.4.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.T3.4.4.4.1.m1.1a"><mn id="S3.T3.4.4.4.1.m1.1.1" xref="S3.T3.4.4.4.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.4.1.m1.1b"><cn type="integer" id="S3.T3.4.4.4.1.m1.1.1.cmml" xref="S3.T3.4.4.4.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.4.1.m1.1c">1</annotation></semantics></math></th>
<td id="S3.T3.4.4.4.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.4.4.4.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.4.4.4.4" class="ltx_td ltx_align_center">HE</td>
<td id="S3.T3.4.4.4.5" class="ltx_td ltx_align_center">BERT-tiny</td>
<td id="S3.T3.4.4.4.6" class="ltx_td ltx_align_center">MNLI</td>
<td id="S3.T3.4.4.4.7" class="ltx_td ltx_align_center">THE-X <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
</tr>
<tr id="S3.T3.5.5.5" class="ltx_tr">
<th id="S3.T3.5.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.5.5.5.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.5.5.5.1.m1.1a"><mn id="S3.T3.5.5.5.1.m1.1.1" xref="S3.T3.5.5.5.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.5.1.m1.1b"><cn type="integer" id="S3.T3.5.5.5.1.m1.1.1.cmml" xref="S3.T3.5.5.5.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.5.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.5.5.5.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.5.5.5.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.5.5.5.4" class="ltx_td ltx_align_center">GC</td>
<td id="S3.T3.5.5.5.5" class="ltx_td ltx_align_center">Shallow CNN</td>
<td id="S3.T3.5.5.5.6" class="ltx_td ltx_align_center">Smart-sensing</td>
<td id="S3.T3.5.5.5.7" class="ltx_td ltx_align_center">DeepSecure <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite>
</td>
</tr>
<tr id="S3.T3.6.6.6" class="ltx_tr">
<th id="S3.T3.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.6.6.6.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.6.6.6.1.m1.1a"><mn id="S3.T3.6.6.6.1.m1.1.1" xref="S3.T3.6.6.6.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.6.1.m1.1b"><cn type="integer" id="S3.T3.6.6.6.1.m1.1.1.cmml" xref="S3.T3.6.6.6.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.6.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.6.6.6.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.6.6.6.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.6.6.6.4" class="ltx_td ltx_align_center">GC/OT/SS/HE</td>
<td id="S3.T3.6.6.6.5" class="ltx_td ltx_align_center">Shallow CNN</td>
<td id="S3.T3.6.6.6.6" class="ltx_td ltx_align_center">CIFAR-10</td>
<td id="S3.T3.6.6.6.7" class="ltx_td ltx_align_center">MiniONN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>
</td>
</tr>
<tr id="S3.T3.7.7.7" class="ltx_tr">
<th id="S3.T3.7.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.7.7.7.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.7.7.7.1.m1.1a"><mn id="S3.T3.7.7.7.1.m1.1.1" xref="S3.T3.7.7.7.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.7.1.m1.1b"><cn type="integer" id="S3.T3.7.7.7.1.m1.1.1.cmml" xref="S3.T3.7.7.7.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.7.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.7.7.7.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.7.7.7.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.7.7.7.4" class="ltx_td ltx_align_center">GC/OT/SS/HE</td>
<td id="S3.T3.7.7.7.5" class="ltx_td ltx_align_center">Shallow CNN</td>
<td id="S3.T3.7.7.7.6" class="ltx_td ltx_align_center">CIFAR-10</td>
<td id="S3.T3.7.7.7.7" class="ltx_td ltx_align_center">Gazelle <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>
</td>
</tr>
<tr id="S3.T3.8.8.8" class="ltx_tr">
<th id="S3.T3.8.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.8.8.8.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.8.8.8.1.m1.1a"><mn id="S3.T3.8.8.8.1.m1.1.1" xref="S3.T3.8.8.8.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.8.1.m1.1b"><cn type="integer" id="S3.T3.8.8.8.1.m1.1.1.cmml" xref="S3.T3.8.8.8.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.8.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.8.8.8.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.8.8.8.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.8.8.8.4" class="ltx_td ltx_align_center">GC/OT/SS/HE</td>
<td id="S3.T3.8.8.8.5" class="ltx_td ltx_align_center">ResNet-32</td>
<td id="S3.T3.8.8.8.6" class="ltx_td ltx_align_center">CIFAR-100</td>
<td id="S3.T3.8.8.8.7" class="ltx_td ltx_align_center">Delphi <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>
</td>
</tr>
<tr id="S3.T3.9.9.9" class="ltx_tr">
<th id="S3.T3.9.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.9.9.9.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.9.9.9.1.m1.1a"><mn id="S3.T3.9.9.9.1.m1.1.1" xref="S3.T3.9.9.9.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.9.1.m1.1b"><cn type="integer" id="S3.T3.9.9.9.1.m1.1.1.cmml" xref="S3.T3.9.9.9.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.9.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.9.9.9.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.9.9.9.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.9.9.9.4" class="ltx_td ltx_align_center">GC/OT/SS</td>
<td id="S3.T3.9.9.9.5" class="ltx_td ltx_align_center">Shallow CNN</td>
<td id="S3.T3.9.9.9.6" class="ltx_td ltx_align_center">CIFAR-10</td>
<td id="S3.T3.9.9.9.7" class="ltx_td ltx_align_center">XONN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>
</td>
</tr>
<tr id="S3.T3.10.10.10" class="ltx_tr">
<th id="S3.T3.10.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.10.10.10.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.10.10.10.1.m1.1a"><mn id="S3.T3.10.10.10.1.m1.1.1" xref="S3.T3.10.10.10.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.10.1.m1.1b"><cn type="integer" id="S3.T3.10.10.10.1.m1.1.1.cmml" xref="S3.T3.10.10.10.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.10.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.10.10.10.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.10.10.10.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.10.10.10.4" class="ltx_td ltx_align_center">HE/OT/SS</td>
<td id="S3.T3.10.10.10.5" class="ltx_td ltx_align_center">DenseNet-121</td>
<td id="S3.T3.10.10.10.6" class="ltx_td ltx_align_center">ImageNet</td>
<td id="S3.T3.10.10.10.7" class="ltx_td ltx_align_center">Cryptflow2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite>
</td>
</tr>
<tr id="S3.T3.11.11.11" class="ltx_tr">
<th id="S3.T3.11.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.11.11.11.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.11.11.11.1.m1.1a"><mn id="S3.T3.11.11.11.1.m1.1.1" xref="S3.T3.11.11.11.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.11.11.11.1.m1.1b"><cn type="integer" id="S3.T3.11.11.11.1.m1.1.1.cmml" xref="S3.T3.11.11.11.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.11.11.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.11.11.11.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.11.11.11.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.11.11.11.4" class="ltx_td ltx_align_center">HE/OT/SS</td>
<td id="S3.T3.11.11.11.5" class="ltx_td ltx_align_center">DenseNet-121</td>
<td id="S3.T3.11.11.11.6" class="ltx_td ltx_align_center">ImageNet</td>
<td id="S3.T3.11.11.11.7" class="ltx_td ltx_align_center">Cheetah <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>
</td>
</tr>
<tr id="S3.T3.12.12.12" class="ltx_tr">
<th id="S3.T3.12.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.12.12.12.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.T3.12.12.12.1.m1.1a"><mn id="S3.T3.12.12.12.1.m1.1.1" xref="S3.T3.12.12.12.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.T3.12.12.12.1.m1.1b"><cn type="integer" id="S3.T3.12.12.12.1.m1.1.1.cmml" xref="S3.T3.12.12.12.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.12.12.1.m1.1c">2</annotation></semantics></math></th>
<td id="S3.T3.12.12.12.2" class="ltx_td ltx_align_center">D</td>
<td id="S3.T3.12.12.12.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.12.12.12.4" class="ltx_td ltx_align_center">OT/SS</td>
<td id="S3.T3.12.12.12.5" class="ltx_td ltx_align_center">Heads <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite>
</td>
<td id="S3.T3.12.12.12.6" class="ltx_td ltx_align_center">SCUT Head <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite>
</td>
<td id="S3.T3.12.12.12.7" class="ltx_td ltx_align_center">SIRNN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>
</td>
</tr>
<tr id="S3.T3.13.13.13" class="ltx_tr">
<th id="S3.T3.13.13.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><math id="S3.T3.13.13.13.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.T3.13.13.13.1.m1.1a"><mn id="S3.T3.13.13.13.1.m1.1.1" xref="S3.T3.13.13.13.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T3.13.13.13.1.m1.1b"><cn type="integer" id="S3.T3.13.13.13.1.m1.1.1.cmml" xref="S3.T3.13.13.13.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.13.13.1.m1.1c">3</annotation></semantics></math></th>
<td id="S3.T3.13.13.13.2" class="ltx_td ltx_align_center">H</td>
<td id="S3.T3.13.13.13.3" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T3.13.13.13.4" class="ltx_td ltx_align_center">GC/OT/SS</td>
<td id="S3.T3.13.13.13.5" class="ltx_td ltx_align_center">Shallow CNN</td>
<td id="S3.T3.13.13.13.6" class="ltx_td ltx_align_center">MNIST</td>
<td id="S3.T3.13.13.13.7" class="ltx_td ltx_align_center">Chameleon <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib168" title="" class="ltx_ref">168</a>]</cite>
</td>
</tr>
<tr id="S3.T3.14.14.14" class="ltx_tr">
<th id="S3.T3.14.14.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb"><math id="S3.T3.14.14.14.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.T3.14.14.14.1.m1.1a"><mn id="S3.T3.14.14.14.1.m1.1.1" xref="S3.T3.14.14.14.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.T3.14.14.14.1.m1.1b"><cn type="integer" id="S3.T3.14.14.14.1.m1.1.1.cmml" xref="S3.T3.14.14.14.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.14.14.14.1.m1.1c">3</annotation></semantics></math></th>
<td id="S3.T3.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb">H</td>
<td id="S3.T3.14.14.14.3" class="ltx_td ltx_align_center ltx_border_bb">Fairness</td>
<td id="S3.T3.14.14.14.4" class="ltx_td ltx_align_center ltx_border_bb">GC/OT/SS</td>
<td id="S3.T3.14.14.14.5" class="ltx_td ltx_align_center ltx_border_bb">SVM</td>
<td id="S3.T3.14.14.14.6" class="ltx_td ltx_align_center ltx_border_bb">MNIST</td>
<td id="S3.T3.14.14.14.7" class="ltx_td ltx_align_center ltx_border_bb">Astra <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
</tr>
</tbody>
</table>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span> 
<div id="S3.I2.ix1.p1" class="ltx_para">
<p id="S3.I2.ix1.p1.1" class="ltx_p">“✘” denotes not support; “H” means honest-majority; “D” means dishonest-majority.</p>
</div>
</li>
<li id="S3.I2.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2</span> 
<div id="S3.I2.ix2.p1" class="ltx_para">
<p id="S3.I2.ix2.p1.1" class="ltx_p">For the accuracy of the network structure, it is recommended to refer to the original paper. When work is performed on multiple models and datasets, we list only the most complex models and datasets in their experiments. Different works may tailor the network structure or dataset according to the characteristics of the designed FSFT algorithm, such as replacing the loss function, reducing the number of samples, <em id="S3.I2.ix2.p1.1.1" class="ltx_emph ltx_font_italic">etc</em>.<span id="S3.I2.ix2.p1.1.2" class="ltx_text"></span> For the sake of the accuracy of the experiments, it is recommended to refer to the original paper.</p>
</div>
</li>
</ul>
</span></div>
</figure>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Secure System</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">With the rapid development of SFL, corresponding SFL systems have emerged one after another. They efficiently support secure training or prediction tasks by integrating different SFL algorithms. In this section, we select some representative ones from them to introduce according to the maturity of the system and the amount of users, <em id="S3.SS3.SSS3.p1.1.1" class="ltx_emph ltx_font_italic">etc</em>. A summary of the SFL systems is shown in Table <a href="#S3.T4" title="Table IV ‣ 3.3.3 Secure System ‣ 3.3 Secure Federated Learning Works ‣ 3 Security ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.6" class="ltx_p">CrypTFlow <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> is an open-source SFL system under the Microsoft Research EzPC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> project. By using  <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> users can convert Tensorflow and ONNX models into SFL models. The CrypTFlow focuses on SFI tasks, and uses the security operators in SecureNN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite>. In addition, CrypTFlow can implement secure SFI algorithms under malicious models, by using TEE, <em id="S3.SS3.SSS3.p2.6.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.SSS3.p2.6.2" class="ltx_text"></span>, SGX. CrypTen <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> is an SFL system built on PyTorch to efficiently support FSFLT and SFI. By integrating with the generic PyTorch API, CrypTen lowers the barrier to use the SFL system, enabling machine learning researchers to easily experiment with machine learning models using secure computing techniques. PySyft <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib273" title="" class="ltx_ref">273</a>]</cite> is OpenMined’s open SFL system that provides secure and private data science in Python. PySyft supports both PSFLT, FSFLT, and SFI. In detail, the private data is decoupled from model training and inference by leveraging secure computing techniques such as SMPC and HE in Pysyft. FATE<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>FATE: https://github.com/FederatedAI/FATE.</span></span></span> is an SFL open-source project initiated by Webank’s AI Department. By implementing multiple secure computing protocols, FATE can effectively support PSFLT, FSFLT, and SFI. Furthermore, With the help of highly modular and flexible scheduling system, FATE has good performance and availability. SecretFlow <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>SecretFlow: https://github.com/secretflow/secretflow.</span></span></span> is a unified programming framework initiated by Ant for privacy-preserving data intelligence and machine learning. It provides an abstract device layer consisting of ordinary devices and secret devices, whereas cryptographic devices consist of cryptographic algorithms such as SMPC, HE, TEE, and hardware devices. With a device layer containing secret devices and a workflow layer that seamlessly integrates data processing, model training, and hyperparameter tuning, SecretFlow enables efficient SFT and SFI. Rosetta<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Rosetta: https://github.com/LatticeX-Foundation/Rosetta.</span></span></span> is a TensorFlow-based SFL system.
Specifically, by overloading TensorFlow’s API, Rosetta allows converting traditional TensorFlow-based algorithm code to SFL algorithm code with minimal changes. The current version of Rosetta integrates multiple SFL algorithms to support SFT and SFI. TF-encrypted<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>TF-encrypted: https://github.com/tf-encrypted/tf-encrypted.</span></span></span> is also a TensorFlow-based SFL system. Unlike Rosetta, TF Encrypted makes the system easier to use by leveraging the Keras API. By integrating the relevant SFL algorithms of SMPC and HE, TF Encrypted can effectively support SFT and SFI. CryptGPU <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib198" title="" class="ltx_ref">198</a>]</cite> and Piranha <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib213" title="" class="ltx_ref">213</a>]</cite> are two SFL systems that support GPU-accelerated computing and achieve the desired results. CryptGPU implements GPU acceleration of the SFL system by integer decomposition and then uses a submodule of the floating-point Kernel accelerated computational decomposition in Pytorch. Piranha, on the other hand, implements the integer Kernel directly on the GPU to support accelerated computation of the SFL system. PaddleFL<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>PaddleFL: https://github.com/PaddlePaddle/PaddleFL.</span></span></span> is an open-source SFL system based on PaddlePaddle<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>PaddlePaddle: https://www.paddlepaddle.org.cn.</span></span></span>. With PaddlePaddle’s large-scale distributed training and Kubernetes’ elastic scheduling capability for training tasks, PaddleFL can be easily deployed based on full-stack open-source software.</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.2" class="ltx_p">In summary, the current SFL systems are designed to provide an easy-to-use conversion tool for non-cryptography, distributed systems, or high-performance computing professionals. For the sake of the usage habits of machine learning researchers, existing SFL systems are usually developed on mainstream machine learning frameworks such as Tensorflow<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>TensorFlow: https://tensorflow.google.cn.</span></span></span> or Pytorch<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>Pytorch: https://pytorch.org.</span></span></span>. Specifically, through overloading the APIs of these deep learning frameworks, the SFL systems can convert a machine learning algorithm code to SFL algorithm code with only minor changes.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table IV</span>: </span><span id="S3.T4.3.2" class="ltx_text" style="font-size:90%;">Summary of SFL System</span></figcaption>
<div id="S3.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:260.2pt;height:99.6pt;vertical-align:-5.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-142.8pt,51.8pt) scale(0.476667074167489,0.476667074167489) ;">
<table id="S3.T4.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.4.1.1.1" class="ltx_tr">
<th id="S3.T4.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Techniques</th>
<th id="S3.T4.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">PSFT</th>
<th id="S3.T4.4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">FSFT</th>
<th id="S3.T4.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">SFI</th>
<th id="S3.T4.4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">GPU</th>
<th id="S3.T4.4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Frameworks</th>
<th id="S3.T4.4.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Systems</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.4.1.2.1" class="ltx_tr">
<td id="S3.T4.4.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">SMPC</td>
<td id="S3.T4.4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">✘</td>
<td id="S3.T4.4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">✘</td>
<td id="S3.T4.4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S3.T4.4.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">✘</td>
<td id="S3.T4.4.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">Tensorflow</td>
<td id="S3.T4.4.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">CrypTFlow <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>
</td>
</tr>
<tr id="S3.T4.4.1.3.2" class="ltx_tr">
<td id="S3.T4.4.1.3.2.1" class="ltx_td ltx_align_center">SMPC/TEE</td>
<td id="S3.T4.4.1.3.2.2" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.3.2.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.3.2.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.3.2.5" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.3.2.6" class="ltx_td ltx_align_center">Tensorflow</td>
<td id="S3.T4.4.1.3.2.7" class="ltx_td ltx_align_center">Rosetta</td>
</tr>
<tr id="S3.T4.4.1.4.3" class="ltx_tr">
<td id="S3.T4.4.1.4.3.1" class="ltx_td ltx_align_center">SMPC/HE/TEE</td>
<td id="S3.T4.4.1.4.3.2" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.4.3.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.4.3.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.4.3.5" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.4.3.6" class="ltx_td ltx_align_center">Tensorflow</td>
<td id="S3.T4.4.1.4.3.7" class="ltx_td ltx_align_center">TF-encrypted</td>
</tr>
<tr id="S3.T4.4.1.5.4" class="ltx_tr">
<td id="S3.T4.4.1.5.4.1" class="ltx_td ltx_align_center">SMPC</td>
<td id="S3.T4.4.1.5.4.2" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.5.4.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.5.4.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.5.4.5" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.5.4.6" class="ltx_td ltx_align_center">Pytorch</td>
<td id="S3.T4.4.1.5.4.7" class="ltx_td ltx_align_center">CrypTen <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>
</td>
</tr>
<tr id="S3.T4.4.1.6.5" class="ltx_tr">
<td id="S3.T4.4.1.6.5.1" class="ltx_td ltx_align_center">SMPC</td>
<td id="S3.T4.4.1.6.5.2" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.6.5.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.6.5.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.6.5.5" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.6.5.6" class="ltx_td ltx_align_center">Pytorch</td>
<td id="S3.T4.4.1.6.5.7" class="ltx_td ltx_align_center">CryptGPU <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib198" title="" class="ltx_ref">198</a>]</cite>
</td>
</tr>
<tr id="S3.T4.4.1.7.6" class="ltx_tr">
<td id="S3.T4.4.1.7.6.1" class="ltx_td ltx_align_center">SMPC/HE</td>
<td id="S3.T4.4.1.7.6.2" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.7.6.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.7.6.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.7.6.5" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.7.6.6" class="ltx_td ltx_align_center">Tensorflow/pytorch</td>
<td id="S3.T4.4.1.7.6.7" class="ltx_td ltx_align_center">Pysyft <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib273" title="" class="ltx_ref">273</a>]</cite>
</td>
</tr>
<tr id="S3.T4.4.1.8.7" class="ltx_tr">
<td id="S3.T4.4.1.8.7.1" class="ltx_td ltx_align_center">SMPC/HE</td>
<td id="S3.T4.4.1.8.7.2" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.8.7.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.8.7.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.8.7.5" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.8.7.6" class="ltx_td ltx_align_center">Tensorflow/pytorch</td>
<td id="S3.T4.4.1.8.7.7" class="ltx_td ltx_align_center">FATE</td>
</tr>
<tr id="S3.T4.4.1.9.8" class="ltx_tr">
<td id="S3.T4.4.1.9.8.1" class="ltx_td ltx_align_center">SMPC/HE/TEE</td>
<td id="S3.T4.4.1.9.8.2" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.9.8.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.9.8.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.9.8.5" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.9.8.6" class="ltx_td ltx_align_center">Tensorflow/pytorch</td>
<td id="S3.T4.4.1.9.8.7" class="ltx_td ltx_align_center">SecretFlow</td>
</tr>
<tr id="S3.T4.4.1.10.9" class="ltx_tr">
<td id="S3.T4.4.1.10.9.1" class="ltx_td ltx_align_center">SMPC</td>
<td id="S3.T4.4.1.10.9.2" class="ltx_td ltx_align_center">✘</td>
<td id="S3.T4.4.1.10.9.3" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.10.9.4" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.10.9.5" class="ltx_td ltx_align_center">✓</td>
<td id="S3.T4.4.1.10.9.6" class="ltx_td ltx_align_center">PaddlePaddle</td>
<td id="S3.T4.4.1.10.9.7" class="ltx_td ltx_align_center">PaddleFL</td>
</tr>
<tr id="S3.T4.4.1.11.10" class="ltx_tr">
<td id="S3.T4.4.1.11.10.1" class="ltx_td ltx_align_center ltx_border_bb">SMPC</td>
<td id="S3.T4.4.1.11.10.2" class="ltx_td ltx_align_center ltx_border_bb">✘</td>
<td id="S3.T4.4.1.11.10.3" class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td id="S3.T4.4.1.11.10.4" class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td id="S3.T4.4.1.11.10.5" class="ltx_td ltx_align_center ltx_border_bb">✓</td>
<td id="S3.T4.4.1.11.10.6" class="ltx_td ltx_align_center ltx_border_bb">NA</td>
<td id="S3.T4.4.1.11.10.7" class="ltx_td ltx_align_center ltx_border_bb">Piranha <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib213" title="" class="ltx_ref">213</a>]</cite>
</td>
</tr>
</tbody>
</table>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p">“✓” denotes supported; “✘” denotes not supported; “NA” denotes not adopted.</p>
</div>
</li>
</ul>
</span></div>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Robustness</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Robust federated learning (RFL) focuses on defending against threats to model performance during the model training process. Compared with SFL techniques that guarantee the correctness of computing results and protect the system from external attackers, RFL considers the threats from internal. More specifically, there are three main threats in RFL, which can not be defended in SFL techniques. Firstly, Non-IID data samples collected by decentralized and inaccessible FL clients could influence the performance of the federated learning model. Furthermore, Byzantine problems may happen to unreliable clients, causing these clients to upload poisoned or failed local models to the server. Moreover, vulnerable clients could be manipulated by human attackers, and then inject backdoors into FL models. Because these threats happen in the data processing or model training procedure in local clients, the above process can not be prevented by SFL techniques. Hence, additional techniques to guarantee the model performance in a federated learning system and prevent internal attacks are required, which can be summarized as robust federated learning.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">In the background, robustness is a vital component in trustworthy machine learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib204" title="" class="ltx_ref">204</a>]</cite>, as conventional machine learning models are vulnerable to various failures or attacks. When it comes to distributed machine learning systems, it also suffers unreliable clients and lossy communication channels. Federated learning (FL), as a new distributed learning paradigm with privacy-preserving requirements, will face the same even worse vulnerability in different ways. In this section, we focus on the robust techniques in the global aggregation stage on the FL server and discuss the main challenges in RFL that differ from a centralized and distributed data center. We put little attention to the robust system techniques because they have been summarised in the literature <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>, <a href="#bib.bib115" title="" class="ltx_ref">115</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. We categorize the threats to robustness FL into three classes (Non-IID issues, Byzantine problems, and targeted attacks) and discuss the defenses against them respectively.
In detail, we focus on the robustness to Non-IID data issues in Section <a href="#S4.SS1" title="4.1 Robustness to Non-IID Data ‣ 4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, the robustness to Byzantine problems in Section <a href="#S4.SS2" title="4.2 Robustness to Byzantine Problem ‣ 4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, and the robustness to targeted attacks in Section <a href="#S4.SS3" title="4.3 Robustness to Targeted Attacks ‣ 4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_italic">Robustness to Non-IID Data</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The vital methods of addressing the Non-IID data challenges are to improve the ability of FL algorithms against model divergence in local training and global aggregation procedures. With the rapid increase of research interest in FL, FL algorithms for Non-IID issues have been proposed in recent years. Furthermore, a review paper <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib268" title="" class="ltx_ref">268</a>]</cite> provides its category about FL on Non-IID data from the categories of Non-IID scenario and system view perspectives. In this section, we provide a different view to categorize the FL algorithms towards Non-IID data issues from a technical view.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Non-IID Data Issue</span>. Due to the privacy regulations that forbid the FL server from directly manipulating the local privacy data samples, the data samples are collected alone in various devices/institutions where the source distributions can be Non-IID in many ways <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. Hence, Non-IID data issues are a fundamental challenge in RFL, which results in model performance degradation compared with distributed learning with IID data. These issues commonly exist in FL applications, which further motivate the research against model performance degradation with Non-IID data.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Concretely, Non-IID data issues influence the model training performance of FL by causing the divergence of local updates <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib265" title="" class="ltx_ref">265</a>]</cite>. Although the authors claim that FedAvg <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite> could solve the Non-IID data issue to some extent, studies <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib265" title="" class="ltx_ref">265</a>, <a href="#bib.bib94" title="" class="ltx_ref">94</a>, <a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> have indicated that the performance drop of FL in Non-IID settings is inevitable. After each round of federated synchronization, local models share the same parameters but converge to different local optimums due to the heterogeneity in local data distributions. Consequently, the divergence of uploaded local update directions causes worse global aggregation results. This divergence usually continues to accumulate during the FL, slowing down the model convergence and weakening model performance. In detail, the scenarios of Non-IID clients can be categorized into several parties <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Feature Distribution Skew</span>. The marginal distribution of label <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{P}(x)" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><mrow id="S4.I1.i1.p1.1.m1.1.2" xref="S4.I1.i1.p1.1.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i1.p1.1.m1.1.2.2" xref="S4.I1.i1.p1.1.m1.1.2.2.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.2.1" xref="S4.I1.i1.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S4.I1.i1.p1.1.m1.1.2.3.2" xref="S4.I1.i1.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S4.I1.i1.p1.1.m1.1.2.3.2.1" xref="S4.I1.i1.p1.1.m1.1.2.cmml">(</mo><mi id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S4.I1.i1.p1.1.m1.1.2.3.2.2" xref="S4.I1.i1.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><apply id="S4.I1.i1.p1.1.m1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.2"><times id="S4.I1.i1.p1.1.m1.1.2.1.cmml" xref="S4.I1.i1.p1.1.m1.1.2.1"></times><ci id="S4.I1.i1.p1.1.m1.1.2.2.cmml" xref="S4.I1.i1.p1.1.m1.1.2.2">𝒫</ci><ci id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">\mathcal{P}(x)</annotation></semantics></math> varies across clients. In a handwriting recognition task, the same words written by different users may differ in stroke width, slant,   etc</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Label Distribution Skew</span>. The marginal distribution of label <math id="S4.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{P}(y)" display="inline"><semantics id="S4.I1.i2.p1.1.m1.1a"><mrow id="S4.I1.i2.p1.1.m1.1.2" xref="S4.I1.i2.p1.1.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i2.p1.1.m1.1.2.2" xref="S4.I1.i2.p1.1.m1.1.2.2.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S4.I1.i2.p1.1.m1.1.2.1" xref="S4.I1.i2.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S4.I1.i2.p1.1.m1.1.2.3.2" xref="S4.I1.i2.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S4.I1.i2.p1.1.m1.1.2.3.2.1" xref="S4.I1.i2.p1.1.m1.1.2.cmml">(</mo><mi id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">y</mi><mo stretchy="false" id="S4.I1.i2.p1.1.m1.1.2.3.2.2" xref="S4.I1.i2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><apply id="S4.I1.i2.p1.1.m1.1.2.cmml" xref="S4.I1.i2.p1.1.m1.1.2"><times id="S4.I1.i2.p1.1.m1.1.2.1.cmml" xref="S4.I1.i2.p1.1.m1.1.2.1"></times><ci id="S4.I1.i2.p1.1.m1.1.2.2.cmml" xref="S4.I1.i2.p1.1.m1.1.2.2">𝒫</ci><ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">\mathcal{P}(y)</annotation></semantics></math> may vary across clients. For instance, clients’ data are tied to personal preferences - customers only buy certain items on an online shopping website.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.2" class="ltx_p"><span id="S4.I1.i3.p1.2.1" class="ltx_text ltx_font_bold">Feature Concept Skew</span>. The condition distributions <math id="S4.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{P}(x|y)" display="inline"><semantics id="S4.I1.i3.p1.1.m1.1a"><mrow id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i3.p1.1.m1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.2.cmml">​</mo><mrow id="S4.I1.i3.p1.1.m1.1.1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I1.i3.p1.1.m1.1.1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.I1.i3.p1.1.m1.1.1.1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml"><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S4.I1.i3.p1.1.m1.1.1.1.1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S4.I1.i3.p1.1.m1.1.1.1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S4.I1.i3.p1.1.m1.1.1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b"><apply id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1"><times id="S4.I1.i3.p1.1.m1.1.1.2.cmml" xref="S4.I1.i3.p1.1.m1.1.1.2"></times><ci id="S4.I1.i3.p1.1.m1.1.1.3.cmml" xref="S4.I1.i3.p1.1.m1.1.1.3">𝒫</ci><apply id="S4.I1.i3.p1.1.m1.1.1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S4.I1.i3.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.2">𝑥</ci><ci id="S4.I1.i3.p1.1.m1.1.1.1.1.1.3.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1.1.1.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">\mathcal{P}(x|y)</annotation></semantics></math> vary across clients, and <math id="S4.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{P}(y)" display="inline"><semantics id="S4.I1.i3.p1.2.m2.1a"><mrow id="S4.I1.i3.p1.2.m2.1.2" xref="S4.I1.i3.p1.2.m2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i3.p1.2.m2.1.2.2" xref="S4.I1.i3.p1.2.m2.1.2.2.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.2.m2.1.2.1" xref="S4.I1.i3.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S4.I1.i3.p1.2.m2.1.2.3.2" xref="S4.I1.i3.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S4.I1.i3.p1.2.m2.1.2.3.2.1" xref="S4.I1.i3.p1.2.m2.1.2.cmml">(</mo><mi id="S4.I1.i3.p1.2.m2.1.1" xref="S4.I1.i3.p1.2.m2.1.1.cmml">y</mi><mo stretchy="false" id="S4.I1.i3.p1.2.m2.1.2.3.2.2" xref="S4.I1.i3.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.2.m2.1b"><apply id="S4.I1.i3.p1.2.m2.1.2.cmml" xref="S4.I1.i3.p1.2.m2.1.2"><times id="S4.I1.i3.p1.2.m2.1.2.1.cmml" xref="S4.I1.i3.p1.2.m2.1.2.1"></times><ci id="S4.I1.i3.p1.2.m2.1.2.2.cmml" xref="S4.I1.i3.p1.2.m2.1.2.2">𝒫</ci><ci id="S4.I1.i3.p1.2.m2.1.1.cmml" xref="S4.I1.i3.p1.2.m2.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.2.m2.1c">\mathcal{P}(y)</annotation></semantics></math> is the same. For instance, the images of items could vary widely at different times and with different illumination. Hence, the data samples with the same label could look very different.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.2" class="ltx_p"><span id="S4.I1.i4.p1.2.1" class="ltx_text ltx_font_bold">Label Concept Skew</span>. The condition distributions <math id="S4.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{P}(y|x)" display="inline"><semantics id="S4.I1.i4.p1.1.m1.1a"><mrow id="S4.I1.i4.p1.1.m1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i4.p1.1.m1.1.1.3" xref="S4.I1.i4.p1.1.m1.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S4.I1.i4.p1.1.m1.1.1.2" xref="S4.I1.i4.p1.1.m1.1.1.2.cmml">​</mo><mrow id="S4.I1.i4.p1.1.m1.1.1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.I1.i4.p1.1.m1.1.1.1.1.2" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.I1.i4.p1.1.m1.1.1.1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.cmml"><mi id="S4.I1.i4.p1.1.m1.1.1.1.1.1.2" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S4.I1.i4.p1.1.m1.1.1.1.1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S4.I1.i4.p1.1.m1.1.1.1.1.1.3" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S4.I1.i4.p1.1.m1.1.1.1.1.3" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.m1.1b"><apply id="S4.I1.i4.p1.1.m1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1"><times id="S4.I1.i4.p1.1.m1.1.1.2.cmml" xref="S4.I1.i4.p1.1.m1.1.1.2"></times><ci id="S4.I1.i4.p1.1.m1.1.1.3.cmml" xref="S4.I1.i4.p1.1.m1.1.1.3">𝒫</ci><apply id="S4.I1.i4.p1.1.m1.1.1.1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S4.I1.i4.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S4.I1.i4.p1.1.m1.1.1.1.1.1.2.cmml" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.2">𝑦</ci><ci id="S4.I1.i4.p1.1.m1.1.1.1.1.1.3.cmml" xref="S4.I1.i4.p1.1.m1.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.m1.1c">\mathcal{P}(y|x)</annotation></semantics></math> vary across clients and <math id="S4.I1.i4.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{P}(x)" display="inline"><semantics id="S4.I1.i4.p1.2.m2.1a"><mrow id="S4.I1.i4.p1.2.m2.1.2" xref="S4.I1.i4.p1.2.m2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.I1.i4.p1.2.m2.1.2.2" xref="S4.I1.i4.p1.2.m2.1.2.2.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S4.I1.i4.p1.2.m2.1.2.1" xref="S4.I1.i4.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S4.I1.i4.p1.2.m2.1.2.3.2" xref="S4.I1.i4.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S4.I1.i4.p1.2.m2.1.2.3.2.1" xref="S4.I1.i4.p1.2.m2.1.2.cmml">(</mo><mi id="S4.I1.i4.p1.2.m2.1.1" xref="S4.I1.i4.p1.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S4.I1.i4.p1.2.m2.1.2.3.2.2" xref="S4.I1.i4.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.2.m2.1b"><apply id="S4.I1.i4.p1.2.m2.1.2.cmml" xref="S4.I1.i4.p1.2.m2.1.2"><times id="S4.I1.i4.p1.2.m2.1.2.1.cmml" xref="S4.I1.i4.p1.2.m2.1.2.1"></times><ci id="S4.I1.i4.p1.2.m2.1.2.2.cmml" xref="S4.I1.i4.p1.2.m2.1.2.2">𝒫</ci><ci id="S4.I1.i4.p1.2.m2.1.1.cmml" xref="S4.I1.i4.p1.2.m2.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.2.m2.1c">\mathcal{P}(x)</annotation></semantics></math> is the same. Similar feature representations from different clients could have different labels because of personal preferences, and the same sentences may reflect different sentiments in language text.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">In real-world settings, the data distribution of clients can be the hybrid case of the above scenarios. Furthermore, the number of data samples may be unbalanced among clients as well. Overall, the Non-IID data issue is a basic threat to model performance. Hence, the RFL approaches to guarantee the performance of the FL model is important.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">RFL against Non-IID Data</span>. Training a robust shared global model for an FL system is the most important target to achieve in RFL. For example, FedAvg aims to train a shared model on decentralized privacy datasets, where the shared model shall generalize all distributions of all datasets. However, it could be hard with decentralized Non-IID data. To overcome the Non-IID data, the basic idea of FL for a shared model is to reduce the inconsistency among clients with Non-IID data. Moreover, depending on the problem formulation and targets, we broadly categorize them into optimization-based and knowledge-based methods. In this section, we focus on the robustness of the shared global model in the literature, where most approaches could be implemented on personalized FL at the same time.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">We note that personalized FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib197" title="" class="ltx_ref">197</a>]</cite> is another solution for Non-IID data issues, which trains personalized models for heterogeneous clients. Personalized FL is robust to Non-IID data issues in most cases, because personalized models usually are derived from the global model via fine-tuning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>, <a href="#bib.bib196" title="" class="ltx_ref">196</a>, <a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> or knowledge transferring <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>. Hence, the personalized model naturally fits the local distributions and inherits the robustness of the global model <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>. As the robustness of the global model also affects the inherited personalized models, we focus on the techniques for training a robust global model in the section.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para ltx_noindent">
<p id="S4.SS1.p7.1" class="ltx_p"><span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_bold">Optimization-based Methods</span>. The basic idea of optimization-based methods is to reduce the divergence of local updates via distributed convex/non-convex optimization techniques. Typically, the proposed optimization-based methods are based on the optimization framework of FedAvg, and further implement various frameworks from different motivations. In detail, FedProx <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> adds a proximal term on the client update procedure to restrict their updates to be close. SCAFFOLD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> uses control variates (variance reduction) to correct for the “client drift” in its local updates. FedNova <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib208" title="" class="ltx_ref">208</a>]</cite> implements a normalized averaging method that eliminates objective inconsistency while preserving fast error convergence. <cite class="ltx_cite ltx_citemacro_citet">Reddi et al. [<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite> propose a generalized FedAvg named FedOPT including client optimization and server optimization procedure. Then, FedOPT derives FedADAGRAD, FedYOGI, and FedADAM by specializing in global optimizer on the server side. FedDyn <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> proposes a solution for a fundamental dilemma, in that the minima of the local-device level empirical loss are inconsistent with those of the global empirical loss. Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Reisizadeh et al. [<a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite> propose FLRA, a general Byzantine-robust federated optimization approach against distribution shifts in samples located in different clients. In summary, optimization-based methods usually are flexible with promising convergence analysis.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para ltx_noindent">
<p id="S4.SS1.p8.1" class="ltx_p"><span id="S4.SS1.p8.1.1" class="ltx_text ltx_font_bold">Knowledge-based Methods</span>. Differing from the optimization formulations, knowledge-based approaches for Non-IID issues are motivated by knowledge-transferring techniques. The main drawback of such approaches is the requirement of a proxy dataset on the FL server. For instance, <cite class="ltx_cite ltx_citemacro_citet">Jeong et al. [<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> introduces knowledge distillation and proposed federated distillation (FD). FD exchanges model outputs as opposed to FL based on exchanging model parameters. FedKD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite> presents several advanced FD applications harnessing wireless channel characteristics and/or exploiting proxy datasets, thereby achieving even higher accuracy than FL. <cite class="ltx_cite ltx_citemacro_citet">Li and Wang [<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> demonstrate the model heterogeneity problems in FL, where the models differ in clients. Then, federated model distillation (FedMD), based on transfer learning and knowledge distillation, enables FL for independently designed models. Knowledge distillation usually depends on a proxy dataset, making it impractical unless such a prerequisite is satisﬁed. In the above approaches, the quality of the proxy dataset also affects the performance of the FL model, which make knowledge-based approaches unreliable in real applications. To solve that, FedGEN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib272" title="" class="ltx_ref">272</a>]</cite> implements a data-free knowledge distillation approach to address heterogeneous FL, where the server learns a lightweight generator to ensemble user information in a data-free manner, which is then broadcasted to users, regulating local training using the learned knowledge as an inductive bias.</p>
</div>
<div id="S4.SS1.p9" class="ltx_para ltx_noindent">
<p id="S4.SS1.p9.1" class="ltx_p"><span id="S4.SS1.p9.1.1" class="ltx_text ltx_font_bold">Clustering-based Methods</span>. Clustering-based methods address Non-IID data issues via cluster clients with similar data distributions. Clustering-based methods are usually orthogonal with optimization and knowledge-based algorithms. Hence, we can run federated optimization algorithms among the clients in the same cluster, which is also known as clustered federated learning (CFL). CFL is presented in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>, which recursively bi-partition clients into two conflict clients clusters according to the gradients. The clustering-based methods are based on the following assumption <a href="#S4.Thmtheorem1" title="Assumption 4.1 (Clustered Federated Learning [178]) ‣ 4.1 Robustness to Non-IID Data ‣ 4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
<div id="S4.Thmtheorem1" class="ltx_theorem ltx_theorem_assumption">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="S4.Thmtheorem1.1.1.1" class="ltx_text ltx_font_bold">Assumption 4.1</span></span><span id="S4.Thmtheorem1.2.2" class="ltx_text ltx_font_bold"> (Clustered Federated Learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>)</span>
</h6>
<div id="S4.Thmtheorem1.p1" class="ltx_para">
<p id="S4.Thmtheorem1.p1.3" class="ltx_p"><span id="S4.Thmtheorem1.p1.3.3" class="ltx_text ltx_font_italic">There exists a partitioning <math id="S4.Thmtheorem1.p1.1.1.m1.6" class="ltx_Math" alttext="\mathcal{C}=\{c_{1},\dots,c_{K}\},\bigcup_{k=1}^{K}c_{k}=\{1,\dots,N\}" display="inline"><semantics id="S4.Thmtheorem1.p1.1.1.m1.6a"><mrow id="S4.Thmtheorem1.p1.1.1.m1.6.6.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.3.cmml"><mrow id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.4" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.4.cmml">𝒞</mi><mo id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.3" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.3.cmml">=</mo><mrow id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.3.cmml"><mo stretchy="false" id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.3" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.3.cmml">{</mo><msub id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.cmml"><mi id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.2" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.2.cmml">c</mi><mn id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.3" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.4" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.3.cmml">,</mo><mi mathvariant="normal" id="S4.Thmtheorem1.p1.1.1.m1.1.1" xref="S4.Thmtheorem1.p1.1.1.m1.1.1.cmml">…</mi><mo id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.5" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.3.cmml">,</mo><msub id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.cmml"><mi id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.2.cmml">c</mi><mi id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.3" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.3.cmml">K</mi></msub><mo stretchy="false" id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.6" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.3.cmml">}</mo></mrow></mrow><mo rspace="0em" id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.3" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.3a.cmml">,</mo><mrow id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.cmml"><mrow id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.cmml"><msubsup id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.cmml"><mo id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.2.cmml">⋃</mo><mrow id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.cmml"><mi id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.2.cmml">k</mi><mo id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.1" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.1.cmml">=</mo><mn id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.3" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.3" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.3.cmml">K</mi></msubsup><msub id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.cmml"><mi id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.2.cmml">c</mi><mi id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.3" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.3.cmml">k</mi></msub></mrow><mo id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.1" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.1.cmml">=</mo><mrow id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.1.cmml"><mo stretchy="false" id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.2.1" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.1.cmml">{</mo><mn id="S4.Thmtheorem1.p1.1.1.m1.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.2.2.cmml">1</mn><mo id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.2.2" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S4.Thmtheorem1.p1.1.1.m1.3.3" xref="S4.Thmtheorem1.p1.1.1.m1.3.3.cmml">…</mi><mo id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.2.3" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.1.cmml">,</mo><mi id="S4.Thmtheorem1.p1.1.1.m1.4.4" xref="S4.Thmtheorem1.p1.1.1.m1.4.4.cmml">N</mi><mo stretchy="false" id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.2.4" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmtheorem1.p1.1.1.m1.6b"><apply id="S4.Thmtheorem1.p1.1.1.m1.6.6.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2"><csymbol cd="ambiguous" id="S4.Thmtheorem1.p1.1.1.m1.6.6.3a.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.3">formulae-sequence</csymbol><apply id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1"><eq id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.3"></eq><ci id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.4.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.4">𝒞</ci><set id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2"><apply id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1">subscript</csymbol><ci id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.2">𝑐</ci><cn type="integer" id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.1.1.1.3">1</cn></apply><ci id="S4.Thmtheorem1.p1.1.1.m1.1.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.1.1">…</ci><apply id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2">subscript</csymbol><ci id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.2">𝑐</ci><ci id="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.5.5.1.1.2.2.2.3">𝐾</ci></apply></set></apply><apply id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2"><eq id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.1"></eq><apply id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2"><apply id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1"><csymbol cd="ambiguous" id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1">superscript</csymbol><apply id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1"><csymbol cd="ambiguous" id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1">subscript</csymbol><union id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.2"></union><apply id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3"><eq id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.1"></eq><ci id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.2">𝑘</ci><cn type="integer" id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.2.3.3">1</cn></apply></apply><ci id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.1.3">𝐾</ci></apply><apply id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2">subscript</csymbol><ci id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.2">𝑐</ci><ci id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.2.2.3">𝑘</ci></apply></apply><set id="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.1.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.6.6.2.2.3.2"><cn type="integer" id="S4.Thmtheorem1.p1.1.1.m1.2.2.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.2.2">1</cn><ci id="S4.Thmtheorem1.p1.1.1.m1.3.3.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.3.3">…</ci><ci id="S4.Thmtheorem1.p1.1.1.m1.4.4.cmml" xref="S4.Thmtheorem1.p1.1.1.m1.4.4">𝑁</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmtheorem1.p1.1.1.m1.6c">\mathcal{C}=\{c_{1},\dots,c_{K}\},\bigcup_{k=1}^{K}c_{k}=\{1,\dots,N\}</annotation></semantics></math> (<math id="S4.Thmtheorem1.p1.2.2.m2.1" class="ltx_Math" alttext="N\geq K\geq 2" display="inline"><semantics id="S4.Thmtheorem1.p1.2.2.m2.1a"><mrow id="S4.Thmtheorem1.p1.2.2.m2.1.1" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.cmml"><mi id="S4.Thmtheorem1.p1.2.2.m2.1.1.2" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.2.cmml">N</mi><mo id="S4.Thmtheorem1.p1.2.2.m2.1.1.3" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.3.cmml">≥</mo><mi id="S4.Thmtheorem1.p1.2.2.m2.1.1.4" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.4.cmml">K</mi><mo id="S4.Thmtheorem1.p1.2.2.m2.1.1.5" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.5.cmml">≥</mo><mn id="S4.Thmtheorem1.p1.2.2.m2.1.1.6" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.6.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmtheorem1.p1.2.2.m2.1b"><apply id="S4.Thmtheorem1.p1.2.2.m2.1.1.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1"><and id="S4.Thmtheorem1.p1.2.2.m2.1.1a.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1"></and><apply id="S4.Thmtheorem1.p1.2.2.m2.1.1b.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1"><geq id="S4.Thmtheorem1.p1.2.2.m2.1.1.3.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.3"></geq><ci id="S4.Thmtheorem1.p1.2.2.m2.1.1.2.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.2">𝑁</ci><ci id="S4.Thmtheorem1.p1.2.2.m2.1.1.4.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.4">𝐾</ci></apply><apply id="S4.Thmtheorem1.p1.2.2.m2.1.1c.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1"><geq id="S4.Thmtheorem1.p1.2.2.m2.1.1.5.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.5"></geq><share href="#S4.Thmtheorem1.p1.2.2.m2.1.1.4.cmml" id="S4.Thmtheorem1.p1.2.2.m2.1.1d.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1"></share><cn type="integer" id="S4.Thmtheorem1.p1.2.2.m2.1.1.6.cmml" xref="S4.Thmtheorem1.p1.2.2.m2.1.1.6">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmtheorem1.p1.2.2.m2.1c">N\geq K\geq 2</annotation></semantics></math>) of the client population, such that every subset of clients <math id="S4.Thmtheorem1.p1.3.3.m3.1" class="ltx_Math" alttext="c_{k}\in\mathcal{C}" display="inline"><semantics id="S4.Thmtheorem1.p1.3.3.m3.1a"><mrow id="S4.Thmtheorem1.p1.3.3.m3.1.1" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.cmml"><msub id="S4.Thmtheorem1.p1.3.3.m3.1.1.2" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.2.cmml"><mi id="S4.Thmtheorem1.p1.3.3.m3.1.1.2.2" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.2.2.cmml">c</mi><mi id="S4.Thmtheorem1.p1.3.3.m3.1.1.2.3" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.2.3.cmml">k</mi></msub><mo id="S4.Thmtheorem1.p1.3.3.m3.1.1.1" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.Thmtheorem1.p1.3.3.m3.1.1.3" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.3.cmml">𝒞</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmtheorem1.p1.3.3.m3.1b"><apply id="S4.Thmtheorem1.p1.3.3.m3.1.1.cmml" xref="S4.Thmtheorem1.p1.3.3.m3.1.1"><in id="S4.Thmtheorem1.p1.3.3.m3.1.1.1.cmml" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.1"></in><apply id="S4.Thmtheorem1.p1.3.3.m3.1.1.2.cmml" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.Thmtheorem1.p1.3.3.m3.1.1.2.1.cmml" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.2">subscript</csymbol><ci id="S4.Thmtheorem1.p1.3.3.m3.1.1.2.2.cmml" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.2.2">𝑐</ci><ci id="S4.Thmtheorem1.p1.3.3.m3.1.1.2.3.cmml" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.2.3">𝑘</ci></apply><ci id="S4.Thmtheorem1.p1.3.3.m3.1.1.3.cmml" xref="S4.Thmtheorem1.p1.3.3.m3.1.1.3">𝒞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmtheorem1.p1.3.3.m3.1c">c_{k}\in\mathcal{C}</annotation></semantics></math> satisfies the distribution learning assumption (i.e., the data distribution among these clients is similar).</span></p>
</div>
</div>
<div id="S4.SS1.p10" class="ltx_para">
<p id="S4.SS1.p10.1" class="ltx_p">The key component of clustering-based methods is the algorithm to privacy-respectively distinguish the data distribution of clients and then conduct clustering on these clients. CFL works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib191" title="" class="ltx_ref">191</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib155" title="" class="ltx_ref">155</a>, <a href="#bib.bib211" title="" class="ltx_ref">211</a>, <a href="#bib.bib226" title="" class="ltx_ref">226</a>]</cite> clusters clients using K-means clustering based on client parameters. CFL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>, <a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite> separates clients into two partitions, which are congruent. FL+HC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> uses local updates to produce hierarchical clustering. IFCA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>/HypCluster <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite> implicitly clusters clients by broadcasting different models to them and allowing them to choose which cluster to join based on local empirical loss (hypothesis-based clustering). For the model updating method, CFL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib178" title="" class="ltx_ref">178</a>, <a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite> utilizes FedAvg to train cluster models for each cluster during the cluster model updating procedure, ignoring the fact that knowledge from one cluster may help the learning of other clusters. IFCA conducts parameters-sharing in feature extractor layers and trains personalized output layers via FedAvg. In addition, FedGSP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib244" title="" class="ltx_ref">244</a>]</cite> assigns clients to homogeneous clusters to minimize the overall distribution divergence among clusters, and increases the degree of parallelism by reassigning more clusters in each round. This idea was further extended to a hierarchical cloud-edge-end FL framework for 5G empowered industries, namded a FedGS, to improve industrial FL performance on non-IID data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>.</p>
</div>
<div id="S4.SS1.p11" class="ltx_para">
<p id="S4.SS1.p11.1" class="ltx_p">Overall, current CFL methods focus on how to cluster clients better mostly. They learn federated model within client cluster alone and isolated. However, how to enables the federated learning process more efficient across clusters is another open problem in CFL.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.10637/assets/x2.png" id="S4.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">Federated learning with benign clients.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2302.10637/assets/x3.png" id="S4.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="244" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Federated learning with unreliable clients.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">The illustration of threats in RFL.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_italic">Robustness to Byzantine Problem</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The failures that happen on the client side may damage the efficiency of the FL system, which can be summarized as the Byzantine problem (the models uploaded from clients are unreliable). In this section, we review the Byzantine problem in FL and summarise the defenses against them.
FL server is susceptible to malicious clients as a distributed learning paradigm due to the inaccessibility of clients’ local training data and the uninspectable local training processes as shown in Fig. <a href="#S4.F6.sf2" title="In Figure 6 ‣ 4.1 Robustness to Non-IID Data ‣ 4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>. In this case, the server cannot be sure whether the clients are honest and benign. The Byzantine problems usually happen during the client update procedure. A subset of clients may be corrupted by an adversary or random failure during the FL. These clients may upload poison local updates to the server. The federated optimization procedure will be ruined if the server unconsciously aggregates these poisoned updates. In this section, an untargeted attack is a specific scenario of the Byzantine problem (clients that may behave abnormally, or even exhibit arbitrary and potentially adversarial behavior). That is, the behavior of a subset of clients is arbitrary as defined in Definition <a href="#S4.Thmdefinition1" title="Definition 4.1 ‣ 4.2 Robustness to Byzantine Problem ‣ 4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. Considering there are <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">p</annotation></semantics></math> Byzantine clients in an FL system, the affection of the Byzantine attacks on distributed learning can be described as follows:</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.6" class="ltx_Math" alttext="w=w-\Lambda(\Delta w_{1},\dots,\tilde{\Delta w_{1}},\dots,\tilde{{\Delta w_{p}}},\dots,\Delta w_{K})," display="block"><semantics id="S4.E4.m1.6a"><mrow id="S4.E4.m1.6.6.1" xref="S4.E4.m1.6.6.1.1.cmml"><mrow id="S4.E4.m1.6.6.1.1" xref="S4.E4.m1.6.6.1.1.cmml"><mi id="S4.E4.m1.6.6.1.1.4" xref="S4.E4.m1.6.6.1.1.4.cmml">w</mi><mo id="S4.E4.m1.6.6.1.1.3" xref="S4.E4.m1.6.6.1.1.3.cmml">=</mo><mrow id="S4.E4.m1.6.6.1.1.2" xref="S4.E4.m1.6.6.1.1.2.cmml"><mi id="S4.E4.m1.6.6.1.1.2.4" xref="S4.E4.m1.6.6.1.1.2.4.cmml">w</mi><mo id="S4.E4.m1.6.6.1.1.2.3" xref="S4.E4.m1.6.6.1.1.2.3.cmml">−</mo><mrow id="S4.E4.m1.6.6.1.1.2.2" xref="S4.E4.m1.6.6.1.1.2.2.cmml"><mi mathvariant="normal" id="S4.E4.m1.6.6.1.1.2.2.4" xref="S4.E4.m1.6.6.1.1.2.2.4.cmml">Λ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.6.6.1.1.2.2.3" xref="S4.E4.m1.6.6.1.1.2.2.3.cmml">​</mo><mrow id="S4.E4.m1.6.6.1.1.2.2.2.2" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml"><mo stretchy="false" id="S4.E4.m1.6.6.1.1.2.2.2.2.3" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">(</mo><mrow id="S4.E4.m1.6.6.1.1.1.1.1.1.1" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S4.E4.m1.6.6.1.1.1.1.1.1.1.2" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.6.6.1.1.1.1.1.1.1.1" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="S4.E4.m1.6.6.1.1.1.1.1.1.1.3" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.2" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.2.cmml">w</mi><mn id="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="S4.E4.m1.6.6.1.1.2.2.2.2.4" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">,</mo><mi mathvariant="normal" id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml">…</mi><mo id="S4.E4.m1.6.6.1.1.2.2.2.2.5" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">,</mo><mover accent="true" id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml"><mrow id="S4.E4.m1.2.2.2" xref="S4.E4.m1.2.2.2.cmml"><mi mathvariant="normal" id="S4.E4.m1.2.2.2.2" xref="S4.E4.m1.2.2.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.2.1" xref="S4.E4.m1.2.2.2.1.cmml">​</mo><msub id="S4.E4.m1.2.2.2.3" xref="S4.E4.m1.2.2.2.3.cmml"><mi id="S4.E4.m1.2.2.2.3.2" xref="S4.E4.m1.2.2.2.3.2.cmml">w</mi><mn id="S4.E4.m1.2.2.2.3.3" xref="S4.E4.m1.2.2.2.3.3.cmml">1</mn></msub></mrow><mo id="S4.E4.m1.2.2.1" xref="S4.E4.m1.2.2.1.cmml">~</mo></mover><mo id="S4.E4.m1.6.6.1.1.2.2.2.2.6" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">,</mo><mi mathvariant="normal" id="S4.E4.m1.3.3" xref="S4.E4.m1.3.3.cmml">…</mi><mo id="S4.E4.m1.6.6.1.1.2.2.2.2.7" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">,</mo><mover accent="true" id="S4.E4.m1.4.4" xref="S4.E4.m1.4.4.cmml"><mrow id="S4.E4.m1.4.4.2" xref="S4.E4.m1.4.4.2.cmml"><mi mathvariant="normal" id="S4.E4.m1.4.4.2.2" xref="S4.E4.m1.4.4.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.2.1" xref="S4.E4.m1.4.4.2.1.cmml">​</mo><msub id="S4.E4.m1.4.4.2.3" xref="S4.E4.m1.4.4.2.3.cmml"><mi id="S4.E4.m1.4.4.2.3.2" xref="S4.E4.m1.4.4.2.3.2.cmml">w</mi><mi id="S4.E4.m1.4.4.2.3.3" xref="S4.E4.m1.4.4.2.3.3.cmml">p</mi></msub></mrow><mo id="S4.E4.m1.4.4.1" xref="S4.E4.m1.4.4.1.cmml">~</mo></mover><mo id="S4.E4.m1.6.6.1.1.2.2.2.2.8" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">,</mo><mi mathvariant="normal" id="S4.E4.m1.5.5" xref="S4.E4.m1.5.5.cmml">…</mi><mo id="S4.E4.m1.6.6.1.1.2.2.2.2.9" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">,</mo><mrow id="S4.E4.m1.6.6.1.1.2.2.2.2.2" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S4.E4.m1.6.6.1.1.2.2.2.2.2.2" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.6.6.1.1.2.2.2.2.2.1" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.1.cmml">​</mo><msub id="S4.E4.m1.6.6.1.1.2.2.2.2.2.3" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.cmml"><mi id="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.2" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.2.cmml">w</mi><mi id="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.3" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.3.cmml">K</mi></msub></mrow><mo stretchy="false" id="S4.E4.m1.6.6.1.1.2.2.2.2.10" xref="S4.E4.m1.6.6.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E4.m1.6.6.1.2" xref="S4.E4.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.6b"><apply id="S4.E4.m1.6.6.1.1.cmml" xref="S4.E4.m1.6.6.1"><eq id="S4.E4.m1.6.6.1.1.3.cmml" xref="S4.E4.m1.6.6.1.1.3"></eq><ci id="S4.E4.m1.6.6.1.1.4.cmml" xref="S4.E4.m1.6.6.1.1.4">𝑤</ci><apply id="S4.E4.m1.6.6.1.1.2.cmml" xref="S4.E4.m1.6.6.1.1.2"><minus id="S4.E4.m1.6.6.1.1.2.3.cmml" xref="S4.E4.m1.6.6.1.1.2.3"></minus><ci id="S4.E4.m1.6.6.1.1.2.4.cmml" xref="S4.E4.m1.6.6.1.1.2.4">𝑤</ci><apply id="S4.E4.m1.6.6.1.1.2.2.cmml" xref="S4.E4.m1.6.6.1.1.2.2"><times id="S4.E4.m1.6.6.1.1.2.2.3.cmml" xref="S4.E4.m1.6.6.1.1.2.2.3"></times><ci id="S4.E4.m1.6.6.1.1.2.2.4.cmml" xref="S4.E4.m1.6.6.1.1.2.2.4">Λ</ci><vector id="S4.E4.m1.6.6.1.1.2.2.2.3.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2"><apply id="S4.E4.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1"><times id="S4.E4.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.1"></times><ci id="S4.E4.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.2">Δ</ci><apply id="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.2">𝑤</ci><cn type="integer" id="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.6.6.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1">…</ci><apply id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"><ci id="S4.E4.m1.2.2.1.cmml" xref="S4.E4.m1.2.2.1">~</ci><apply id="S4.E4.m1.2.2.2.cmml" xref="S4.E4.m1.2.2.2"><times id="S4.E4.m1.2.2.2.1.cmml" xref="S4.E4.m1.2.2.2.1"></times><ci id="S4.E4.m1.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2">Δ</ci><apply id="S4.E4.m1.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.3"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.3.1.cmml" xref="S4.E4.m1.2.2.2.3">subscript</csymbol><ci id="S4.E4.m1.2.2.2.3.2.cmml" xref="S4.E4.m1.2.2.2.3.2">𝑤</ci><cn type="integer" id="S4.E4.m1.2.2.2.3.3.cmml" xref="S4.E4.m1.2.2.2.3.3">1</cn></apply></apply></apply><ci id="S4.E4.m1.3.3.cmml" xref="S4.E4.m1.3.3">…</ci><apply id="S4.E4.m1.4.4.cmml" xref="S4.E4.m1.4.4"><ci id="S4.E4.m1.4.4.1.cmml" xref="S4.E4.m1.4.4.1">~</ci><apply id="S4.E4.m1.4.4.2.cmml" xref="S4.E4.m1.4.4.2"><times id="S4.E4.m1.4.4.2.1.cmml" xref="S4.E4.m1.4.4.2.1"></times><ci id="S4.E4.m1.4.4.2.2.cmml" xref="S4.E4.m1.4.4.2.2">Δ</ci><apply id="S4.E4.m1.4.4.2.3.cmml" xref="S4.E4.m1.4.4.2.3"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.2.3.1.cmml" xref="S4.E4.m1.4.4.2.3">subscript</csymbol><ci id="S4.E4.m1.4.4.2.3.2.cmml" xref="S4.E4.m1.4.4.2.3.2">𝑤</ci><ci id="S4.E4.m1.4.4.2.3.3.cmml" xref="S4.E4.m1.4.4.2.3.3">𝑝</ci></apply></apply></apply><ci id="S4.E4.m1.5.5.cmml" xref="S4.E4.m1.5.5">…</ci><apply id="S4.E4.m1.6.6.1.1.2.2.2.2.2.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2"><times id="S4.E4.m1.6.6.1.1.2.2.2.2.2.1.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.1"></times><ci id="S4.E4.m1.6.6.1.1.2.2.2.2.2.2.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.2">Δ</ci><apply id="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.1.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.3">subscript</csymbol><ci id="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.2.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.2">𝑤</ci><ci id="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.3.cmml" xref="S4.E4.m1.6.6.1.1.2.2.2.2.2.3.3">𝐾</ci></apply></apply></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.6c">w=w-\Lambda(\Delta w_{1},\dots,\tilde{\Delta w_{1}},\dots,\tilde{{\Delta w_{p}}},\dots,\Delta w_{K}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.2" class="ltx_p">where <math id="S4.SS2.p1.2.m1.1" class="ltx_Math" alttext="\tilde{\Delta w}" display="inline"><semantics id="S4.SS2.p1.2.m1.1a"><mover accent="true" id="S4.SS2.p1.2.m1.1.1" xref="S4.SS2.p1.2.m1.1.1.cmml"><mrow id="S4.SS2.p1.2.m1.1.1.2" xref="S4.SS2.p1.2.m1.1.1.2.cmml"><mi mathvariant="normal" id="S4.SS2.p1.2.m1.1.1.2.2" xref="S4.SS2.p1.2.m1.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m1.1.1.2.1" xref="S4.SS2.p1.2.m1.1.1.2.1.cmml">​</mo><mi id="S4.SS2.p1.2.m1.1.1.2.3" xref="S4.SS2.p1.2.m1.1.1.2.3.cmml">w</mi></mrow><mo id="S4.SS2.p1.2.m1.1.1.1" xref="S4.SS2.p1.2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m1.1b"><apply id="S4.SS2.p1.2.m1.1.1.cmml" xref="S4.SS2.p1.2.m1.1.1"><ci id="S4.SS2.p1.2.m1.1.1.1.cmml" xref="S4.SS2.p1.2.m1.1.1.1">~</ci><apply id="S4.SS2.p1.2.m1.1.1.2.cmml" xref="S4.SS2.p1.2.m1.1.1.2"><times id="S4.SS2.p1.2.m1.1.1.2.1.cmml" xref="S4.SS2.p1.2.m1.1.1.2.1"></times><ci id="S4.SS2.p1.2.m1.1.1.2.2.cmml" xref="S4.SS2.p1.2.m1.1.1.2.2">Δ</ci><ci id="S4.SS2.p1.2.m1.1.1.2.3.cmml" xref="S4.SS2.p1.2.m1.1.1.2.3">𝑤</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m1.1c">\tilde{\Delta w}</annotation></semantics></math> denotes the gradients from Byzantine clients. The Byzantine gradients may cause the optimization direction deviates from the global optimum. Hence, effective Byzantine-robust FL approaches are urgently needed to guarantee the model performance of FL. The FL server could not observe the process that happened on the client side including data processing and client local training. Hence, the information for the server to determine the identity of clients is only the uploaded local updates. Based on that observation, the Byzantine-robust FL that defends the Byzantine problem could be categorized into (1) Robust aggregation, (2) Byzantine detection, and (3) Hybrid mechanism.</p>
</div>
<div id="S4.Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="S4.Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition 4.1</span></span></h6>
<div id="S4.Thmdefinition1.p1" class="ltx_para">
<p id="S4.Thmdefinition1.p1.3" class="ltx_p"><span id="S4.Thmdefinition1.p1.3.1" class="ltx_text ltx_font_italic">[Byzantine client <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>] A Byzantine client can upload arbitrary local updates to the server</span></p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.2" class="ltx_Math" alttext="\Delta w_{i}=\begin{cases}*,\;\quad\quad\quad\quad\quad\,\,\text{if the $i$-th client is Byzantine},\\
\nabla F_{i}(w_{i};\mathcal{D}_{i}),\quad\text{otherwise},\end{cases}" display="block"><semantics id="S4.E5.m1.2a"><mrow id="S4.E5.m1.2.3" xref="S4.E5.m1.2.3.cmml"><mrow id="S4.E5.m1.2.3.2" xref="S4.E5.m1.2.3.2.cmml"><mi mathvariant="normal" id="S4.E5.m1.2.3.2.2" xref="S4.E5.m1.2.3.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.3.2.1" xref="S4.E5.m1.2.3.2.1.cmml">​</mo><msub id="S4.E5.m1.2.3.2.3" xref="S4.E5.m1.2.3.2.3.cmml"><mi id="S4.E5.m1.2.3.2.3.2" xref="S4.E5.m1.2.3.2.3.2.cmml">w</mi><mi id="S4.E5.m1.2.3.2.3.3" xref="S4.E5.m1.2.3.2.3.3.cmml">i</mi></msub></mrow><mo id="S4.E5.m1.2.3.1" xref="S4.E5.m1.2.3.1.cmml">=</mo><mrow id="S4.E5.m1.2.2" xref="S4.E5.m1.2.3.3.1.cmml"><mo id="S4.E5.m1.2.2.3" xref="S4.E5.m1.2.3.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S4.E5.m1.2.2.2" xref="S4.E5.m1.2.3.3.1.cmml"><mtr id="S4.E5.m1.2.2.2a" xref="S4.E5.m1.2.3.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E5.m1.2.2.2b" xref="S4.E5.m1.2.3.3.1.cmml"><mrow id="S4.E5.m1.1.1.1.1.1.1.3" xref="S4.E5.m1.2.3.3.1.cmml"><mrow id="S4.E5.m1.1.1.1.1.1.1.3.1.2" xref="S4.E5.m1.1.1.1.1.1.1.3.1.1.cmml"><mo rspace="0em" id="S4.E5.m1.1.1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.1.1.2.cmml">∗</mo><mo rspace="5.777em" id="S4.E5.m1.1.1.1.1.1.1.3.1.2.1" xref="S4.E5.m1.1.1.1.1.1.1.3.1.1.cmml">,</mo><mrow id="S4.E5.m1.1.1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.1c.cmml"><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.1.1.1.1.1.1.1.1a" xref="S4.E5.m1.1.1.1.1.1.1.1.1c.cmml">if the </mtext><mi id="S4.E5.m1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml">i</mi><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.1.1.1.1.1.1.1.1b" xref="S4.E5.m1.1.1.1.1.1.1.1.1c.cmml">-th client is Byzantine</mtext></mrow></mrow><mo id="S4.E5.m1.1.1.1.1.1.1.3.2" xref="S4.E5.m1.2.3.3.1.cmml">,</mo></mrow></mtd><mtd id="S4.E5.m1.2.2.2c" xref="S4.E5.m1.2.3.3.1.1.cmml"></mtd></mtr><mtr id="S4.E5.m1.2.2.2d" xref="S4.E5.m1.2.3.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E5.m1.2.2.2e" xref="S4.E5.m1.2.3.3.1.cmml"><mrow id="S4.E5.m1.2.2.2.2.1.1.2" xref="S4.E5.m1.2.3.3.1.cmml"><mrow id="S4.E5.m1.2.2.2.2.1.1.2.1.1" xref="S4.E5.m1.2.2.2.2.1.1.2.1.2.cmml"><mrow id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.cmml"><mrow id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.cmml"><mo rspace="0.167em" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.1" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.1.cmml">∇</mo><msub id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.cmml"><mi id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.2" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.2.cmml">F</mi><mi id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.3" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.3.cmml">i</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.3" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.3.cmml">​</mo><mrow id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.3.cmml"><mo stretchy="false" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.3" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.3.cmml">(</mo><msub id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.cmml"><mi id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.2.cmml">w</mi><mi id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.4" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.3.cmml">;</mo><msub id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.2" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.2.cmml">𝒟</mi><mi id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.3" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.5" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo rspace="1.167em" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.2" xref="S4.E5.m1.2.2.2.2.1.1.2.1.2.cmml">,</mo><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.2.2.2.2.1.1.1" xref="S4.E5.m1.2.2.2.2.1.1.1a.cmml">otherwise</mtext></mrow><mo id="S4.E5.m1.2.2.2.2.1.1.2.2" xref="S4.E5.m1.2.3.3.1.cmml">,</mo></mrow></mtd><mtd id="S4.E5.m1.2.2.2f" xref="S4.E5.m1.2.3.3.1.1.cmml"></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.2b"><apply id="S4.E5.m1.2.3.cmml" xref="S4.E5.m1.2.3"><eq id="S4.E5.m1.2.3.1.cmml" xref="S4.E5.m1.2.3.1"></eq><apply id="S4.E5.m1.2.3.2.cmml" xref="S4.E5.m1.2.3.2"><times id="S4.E5.m1.2.3.2.1.cmml" xref="S4.E5.m1.2.3.2.1"></times><ci id="S4.E5.m1.2.3.2.2.cmml" xref="S4.E5.m1.2.3.2.2">Δ</ci><apply id="S4.E5.m1.2.3.2.3.cmml" xref="S4.E5.m1.2.3.2.3"><csymbol cd="ambiguous" id="S4.E5.m1.2.3.2.3.1.cmml" xref="S4.E5.m1.2.3.2.3">subscript</csymbol><ci id="S4.E5.m1.2.3.2.3.2.cmml" xref="S4.E5.m1.2.3.2.3.2">𝑤</ci><ci id="S4.E5.m1.2.3.2.3.3.cmml" xref="S4.E5.m1.2.3.2.3.3">𝑖</ci></apply></apply><apply id="S4.E5.m1.2.3.3.1.cmml" xref="S4.E5.m1.2.2"><csymbol cd="latexml" id="S4.E5.m1.2.3.3.1.1.cmml" xref="S4.E5.m1.2.2.3">cases</csymbol><list id="S4.E5.m1.1.1.1.1.1.1.3.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3.1.2"><times id="S4.E5.m1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.2"></times><ci id="S4.E5.m1.1.1.1.1.1.1.1.1c.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1"><mrow id="S4.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1"><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.1.1.1.1.1.1.1.1a.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1">if the </mtext><mi id="S4.E5.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.m1.1.1">i</mi><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.1.1.1.1.1.1.1.1b.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1">-th client is Byzantine</mtext></mrow></ci></list><ci id="S4.E5.m1.2.3.3.1.3a.cmml" xref="S4.E5.m1.2.2"><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.2.3.3.1.3.cmml" xref="S4.E5.m1.2.2.3">otherwise</mtext></ci><list id="S4.E5.m1.2.2.2.2.1.1.2.1.2.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1"><apply id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1"><times id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.3.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.3"></times><apply id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4"><ci id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.1.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.1">∇</ci><apply id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.1.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2">subscript</csymbol><ci id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.2.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.2">𝐹</ci><ci id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.3.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.4.2.3">𝑖</ci></apply></apply><list id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.3.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2"><apply id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.2">𝑤</ci><ci id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.1.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.2.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.2">𝒟</ci><ci id="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.3.cmml" xref="S4.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2.3">𝑖</ci></apply></list></apply><ci id="S4.E5.m1.2.2.2.2.1.1.1a.cmml" xref="S4.E5.m1.2.2.2.2.1.1.1"><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.2.2.2.2.1.1.1.cmml" xref="S4.E5.m1.2.2.2.2.1.1.1">otherwise</mtext></ci></list><ci id="S4.E5.m1.2.3.3.1.5a.cmml" xref="S4.E5.m1.2.2"><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.2.3.3.1.5.cmml" xref="S4.E5.m1.2.2.3">otherwise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.2c">\Delta w_{i}=\begin{cases}*,\;\quad\quad\quad\quad\quad\,\,\text{if the $i$-th client is Byzantine},\\
\nabla F_{i}(w_{i};\mathcal{D}_{i}),\quad\text{otherwise},\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S4.Thmdefinition1.p1.2" class="ltx_p"><span id="S4.Thmdefinition1.p1.2.2" class="ltx_text ltx_font_italic">where “*” represents arbitrary values and <math id="S4.Thmdefinition1.p1.1.1.m1.1" class="ltx_Math" alttext="F_{i}" display="inline"><semantics id="S4.Thmdefinition1.p1.1.1.m1.1a"><msub id="S4.Thmdefinition1.p1.1.1.m1.1.1" xref="S4.Thmdefinition1.p1.1.1.m1.1.1.cmml"><mi id="S4.Thmdefinition1.p1.1.1.m1.1.1.2" xref="S4.Thmdefinition1.p1.1.1.m1.1.1.2.cmml">F</mi><mi id="S4.Thmdefinition1.p1.1.1.m1.1.1.3" xref="S4.Thmdefinition1.p1.1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.1.1.m1.1b"><apply id="S4.Thmdefinition1.p1.1.1.m1.1.1.cmml" xref="S4.Thmdefinition1.p1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.Thmdefinition1.p1.1.1.m1.1.1.1.cmml" xref="S4.Thmdefinition1.p1.1.1.m1.1.1">subscript</csymbol><ci id="S4.Thmdefinition1.p1.1.1.m1.1.1.2.cmml" xref="S4.Thmdefinition1.p1.1.1.m1.1.1.2">𝐹</ci><ci id="S4.Thmdefinition1.p1.1.1.m1.1.1.3.cmml" xref="S4.Thmdefinition1.p1.1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.1.1.m1.1c">F_{i}</annotation></semantics></math> represents client <math id="S4.Thmdefinition1.p1.2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.Thmdefinition1.p1.2.2.m2.1a"><mi id="S4.Thmdefinition1.p1.2.2.m2.1.1" xref="S4.Thmdefinition1.p1.2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.2.2.m2.1b"><ci id="S4.Thmdefinition1.p1.2.2.m2.1.1.cmml" xref="S4.Thmdefinition1.p1.2.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.2.2.m2.1c">i</annotation></semantics></math>’s objective function.</span></p>
</div>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Robust Aggregation</span>. The main goal of robust aggregation approaches is to mitigate the influence of Byzantine clients on global aggregation. Robust aggregation techniques are effective in traditional data center distributed machine learning. A robust aggregation scheme assumes that the poisoned local model updates are geometrically far from benign ones. Hence, methods in the literature aim to build a robust aggregation rule that can mitigate the impacts of malicious attacks to a certain degree. For example in distributed learning, Krum <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and Bulyan <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> select the local updates with the smallest Euclidean distances to the remaining ones and aggregate them to update the global model. Medoid and Marginal Median <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib220" title="" class="ltx_ref">220</a>]</cite> select a subset of clients as a representative set and uses its update to estimate the true center. GeoMed <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> estimates the center based on the local updates without distinguishing the malicious from the normal ones. Trimmed Mean and Median <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib236" title="" class="ltx_ref">236</a>]</cite> remove the biggest and smallest values and take the average and median of the remaining ones as the aggregated value for each of the model parameters among all the local model updates. Depending on their aggregation techniques, there are implicit voting majority rules in several methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib236" title="" class="ltx_ref">236</a>]</cite>, that is, a certain local model update away from others should follow the majority direction. Consequently, they may fail when the number of Byzantine clients is too large. Hence, they have a theoretical break point, indicating the maximum number of Byzantine clients that can be defended as summarised in Table <a href="#S4.T5" title="Table V ‣ 4.2 Robustness to Byzantine Problem ‣ 4 Robustness ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>. Overall, robust distributed learning approaches are proposed based on the assumption that the data samples are IID in clients, which conflicts with real-world FL. Besides, the Non-IID scenarios would cause updates to diverge, making the geometric-based robust approaches fail.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Other robust aggregation techniques mitigate the influence of Byzantine clients via adding regularization terms <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>, <a href="#bib.bib147" title="" class="ltx_ref">147</a>, <a href="#bib.bib223" title="" class="ltx_ref">223</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Li et al. [<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite> enhance the robustness against Byzantine attacks via adding an additional <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><msub id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">l</mi><mn id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">l_{1}</annotation></semantics></math>-norm regularization on the cost function. Zeno+ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib223" title="" class="ltx_ref">223</a>]</cite> estimates the descent of the loss value in asynchronous SGD and declines the Byzantine clients’ contribution via penalty term. <cite class="ltx_cite ltx_citemacro_citet">Muñoz-González et al. [<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> proposes Adaptive Federated Averaging (AFA) to estimate the quality of the client’s updates and dynamically adjust its averaging weights. Regularization-based methods provide robust analysis under the general cases in optimization and the performance usually is better than geometric-based methods.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">In summary, mitigating the influence of poisoned local updates on global optimization procedures is the main idea of robust aggregation approaches. Most of the above robust aggregation schemes suffer from significant performance degradation when a relatively large proportion of clients are compromised, or data among clients is highly Non-IID. Furthermore, recently proposed poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite> for FL can bypass these robust aggregation algorithms. Motivated by these new challenges, the Byzantine-robust federated optimization approaches have been proposed <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib218" title="" class="ltx_ref">218</a>, <a href="#bib.bib157" title="" class="ltx_ref">157</a>, <a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite>, which reveals the further challenges for robust aggregation techniques. From an application view, most of the Byzantine-robust federated optimization approaches assume failure modes without generality. The complex and unpredictable threats <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> in FL motivate further studies on general Byzantine robustness, which is an open problem.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">Byzantine Detection</span>. Byzantine detection schemes are to identify and exclude malicious local updates so that Byzantine clients will not damage the FL system. Depending on the detection rules of such approaches, we further categorize these methods as validation-based methods and gradient-based methods. For validation-based methods, Error Rate-based Rejection (ERR) rejects local updates that would decrease the global model’s accuracy. Loss Function-based Rejection (LFR) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> ranks the model’s credibility according to the loss decrease. For gradient-based methods, <cite class="ltx_cite ltx_citemacro_citet">Li et al. [<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> use a variational autoencoder (VAE) to capture model-update statistics and distinguish malicious clients from benign ones accordingly. <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. [<a href="#bib.bib260" title="" class="ltx_ref">260</a>]</cite> observe that the model updates from a client in multiple iterations are inconsistent and propose FLDetector <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib260" title="" class="ltx_ref">260</a>]</cite> to check their model-updates consistency. Recently, BytoChain <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> introduces a Byzantine resistant secure blockchained federated learning framework, which executes heavy verification workflows in parallel and detects byzantine attacks through a byzantine resistant consensus Proof-of-Accuracy (PoA).
In summary, Byzantine detection is compatible with most federated optimization algorithms. Hence, they are more robust than Robust-aggregation schemes. Thus, byzantine detection is a promising direction for exploring robust federated learning. However, these approaches require extra calculation on the server and client <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib260" title="" class="ltx_ref">260</a>, <a href="#bib.bib260" title="" class="ltx_ref">260</a>, <a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>, or additional public data on the server <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para ltx_noindent">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Hybrid Mechanism</span>. Other works combine the above schemes and propose a hybrid defense mechanism. DiverseFl <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite> trains a bootstrapping model for each client using some of the client’s local data and compares the trained model with her submitted local model update to examine the local training process. FLTrust <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> trains a bootstrapping model on a public dataset and uses cosine similarities between local model updates and the trained bootstrapping model to rank the model’s credibility. CoMT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> couples the process of teaching and learning and thus produces directly a robust prediction model despite the extremely pervasive systematic data corruption. FedInv <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib263" title="" class="ltx_ref">263</a>]</cite> conducts a privacy-respecting model inversion <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite> to the local updates and obtains a dummy dataset. Then, FedInv scores and clusters local model updates by Wasserstein distance of the dummy dataset and removes those updates that are far from others. Hybrid mechanism robust federated learning approaches smartly preserve the advantages of both robust aggregation and Byzantine detection techniques, however, usually consume more resources. Hence, the resource-efficient robust approach is also an open problem in applications.</p>
</div>
<figure id="S4.T5" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table V</span>: </span><span id="S4.T5.3.2" class="ltx_text" style="font-size:90%;">Summary of representative defenses</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.T5.4" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:420.6pt;height:173.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-246.9pt,102.1pt) scale(0.459935672263754,0.459935672263754) ;">
<table id="S4.T5.4.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.4.1.1.1" class="ltx_tr">
<td id="S4.T5.4.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T5.4.1.1.1.1.1" class="ltx_text">Category</span></td>
<td id="S4.T5.4.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T5.4.1.1.1.2.1" class="ltx_text">Type</span></td>
<td id="S4.T5.4.1.1.1.3" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T5.4.1.1.1.3.1" class="ltx_text">Method</span></td>
<td id="S4.T5.4.1.1.1.4" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T5.4.1.1.1.4.1" class="ltx_text">Technique</span></td>
<td id="S4.T5.4.1.1.1.5" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T5.4.1.1.1.5.1" class="ltx_text">Break Point</span></td>
<td id="S4.T5.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t" colspan="3">Robust to threats</td>
</tr>
<tr id="S4.T5.4.1.2.2" class="ltx_tr">
<td id="S4.T5.4.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Non-IID Data</td>
<td id="S4.T5.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Byzantine Problem</td>
<td id="S4.T5.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Targeted Attacks</td>
</tr>
<tr id="S4.T5.4.1.3.3" class="ltx_tr">
<td id="S4.T5.4.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="8"><span id="S4.T5.4.1.3.3.1.1" class="ltx_text">Robust Aggregation</span></td>
<td id="S4.T5.4.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="5"><span id="S4.T5.4.1.3.3.2.1" class="ltx_text">Geometric-based</span></td>
<td id="S4.T5.4.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">Krum<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>
</td>
<td id="S4.T5.4.1.3.3.4" class="ltx_td ltx_align_left ltx_border_t">Euclidean distance</td>
<td id="S4.T5.4.1.3.3.5" class="ltx_td ltx_align_left ltx_border_t">(K-2)/2K</td>
<td id="S4.T5.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">✘</td>
<td id="S4.T5.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">✘</td>
</tr>
<tr id="S4.T5.4.1.4.4" class="ltx_tr">
<td id="S4.T5.4.1.4.4.1" class="ltx_td ltx_align_left">BGD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T5.4.1.4.4.2" class="ltx_td ltx_align_left">Geometric median</td>
<td id="S4.T5.4.1.4.4.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.4.4.4" class="ltx_td ltx_align_center">✘</td>
<td id="S4.T5.4.1.4.4.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.4.4.6" class="ltx_td ltx_align_center">✘</td>
</tr>
<tr id="S4.T5.4.1.5.5" class="ltx_tr">
<td id="S4.T5.4.1.5.5.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Xie et al. [<a href="#bib.bib220" title="" class="ltx_ref">220</a>]</cite></td>
<td id="S4.T5.4.1.5.5.2" class="ltx_td ltx_align_left">Geometric median</td>
<td id="S4.T5.4.1.5.5.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.5.5.4" class="ltx_td ltx_align_center">✘</td>
<td id="S4.T5.4.1.5.5.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.5.5.6" class="ltx_td ltx_align_center">✘</td>
</tr>
<tr id="S4.T5.4.1.6.6" class="ltx_tr">
<td id="S4.T5.4.1.6.6.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Yin et al. [<a href="#bib.bib236" title="" class="ltx_ref">236</a>]</cite></td>
<td id="S4.T5.4.1.6.6.2" class="ltx_td ltx_align_left">Coordinate-wise median</td>
<td id="S4.T5.4.1.6.6.3" class="ltx_td ltx_align_left">K/2</td>
<td id="S4.T5.4.1.6.6.4" class="ltx_td ltx_align_center">✘</td>
<td id="S4.T5.4.1.6.6.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.6.6.6" class="ltx_td ltx_align_center">✘</td>
</tr>
<tr id="S4.T5.4.1.7.7" class="ltx_tr">
<td id="S4.T5.4.1.7.7.1" class="ltx_td ltx_align_left">Bulyan <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>
</td>
<td id="S4.T5.4.1.7.7.2" class="ltx_td ltx_align_left">Krum + trimmed median</td>
<td id="S4.T5.4.1.7.7.3" class="ltx_td ltx_align_left">(K-3)/4K</td>
<td id="S4.T5.4.1.7.7.4" class="ltx_td ltx_align_center">✘</td>
<td id="S4.T5.4.1.7.7.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.7.7.6" class="ltx_td ltx_align_center">✘</td>
</tr>
<tr id="S4.T5.4.1.8.8" class="ltx_tr">
<td id="S4.T5.4.1.8.8.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S4.T5.4.1.8.8.1.1" class="ltx_text">Regularization-based</span></td>
<td id="S4.T5.4.1.8.8.2" class="ltx_td ltx_align_left ltx_border_t">Zeno++ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib223" title="" class="ltx_ref">223</a>]</cite>
</td>
<td id="S4.T5.4.1.8.8.3" class="ltx_td ltx_align_left ltx_border_t">Inner-product validation</td>
<td id="S4.T5.4.1.8.8.4" class="ltx_td ltx_align_left ltx_border_t">NA</td>
<td id="S4.T5.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_t">✘</td>
<td id="S4.T5.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_t">✘</td>
</tr>
<tr id="S4.T5.4.1.9.9" class="ltx_tr">
<td id="S4.T5.4.1.9.9.1" class="ltx_td ltx_align_left">AFA<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite>
</td>
<td id="S4.T5.4.1.9.9.2" class="ltx_td ltx_align_left">Gradient similarity</td>
<td id="S4.T5.4.1.9.9.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.9.9.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.9.9.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.9.9.6" class="ltx_td ltx_align_center">✘</td>
</tr>
<tr id="S4.T5.4.1.10.10" class="ltx_tr">
<td id="S4.T5.4.1.10.10.1" class="ltx_td ltx_align_left">RSA<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>
</td>
<td id="S4.T5.4.1.10.10.2" class="ltx_td ltx_align_left">Loss regularization</td>
<td id="S4.T5.4.1.10.10.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.10.10.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.10.10.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.10.10.6" class="ltx_td ltx_align_center">✘</td>
</tr>
<tr id="S4.T5.4.1.11.11" class="ltx_tr">
<td id="S4.T5.4.1.11.11.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="5"><span id="S4.T5.4.1.11.11.1.1" class="ltx_text">Byzantine Detection</span></td>
<td id="S4.T5.4.1.11.11.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T5.4.1.11.11.2.1" class="ltx_text">Validation-based</span></td>
<td id="S4.T5.4.1.11.11.3" class="ltx_td ltx_align_left ltx_border_t">ERR&amp;LFR <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>
</td>
<td id="S4.T5.4.1.11.11.4" class="ltx_td ltx_align_left ltx_border_t">Global validation</td>
<td id="S4.T5.4.1.11.11.5" class="ltx_td ltx_align_left ltx_border_t">NA</td>
<td id="S4.T5.4.1.11.11.6" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.11.11.7" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.11.11.8" class="ltx_td ltx_align_center ltx_border_t">✓</td>
</tr>
<tr id="S4.T5.4.1.12.12" class="ltx_tr">
<td id="S4.T5.4.1.12.12.1" class="ltx_td ltx_align_left">Baffle<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S4.T5.4.1.12.12.2" class="ltx_td ltx_align_left">Loss feed-back</td>
<td id="S4.T5.4.1.12.12.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.12.12.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.12.12.5" class="ltx_td ltx_align_center">✘</td>
<td id="S4.T5.4.1.12.12.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T5.4.1.13.13" class="ltx_tr">
<td id="S4.T5.4.1.13.13.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="S4.T5.4.1.13.13.1.1" class="ltx_text">Gradient-based</span></td>
<td id="S4.T5.4.1.13.13.2" class="ltx_td ltx_align_left ltx_border_t">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>
</td>
<td id="S4.T5.4.1.13.13.3" class="ltx_td ltx_align_left ltx_border_t">Gradient similarity</td>
<td id="S4.T5.4.1.13.13.4" class="ltx_td ltx_align_left ltx_border_t">NA</td>
<td id="S4.T5.4.1.13.13.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.13.13.6" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.13.13.7" class="ltx_td ltx_align_center ltx_border_t">✓</td>
</tr>
<tr id="S4.T5.4.1.14.14" class="ltx_tr">
<td id="S4.T5.4.1.14.14.1" class="ltx_td ltx_align_left">FLDetector<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib260" title="" class="ltx_ref">260</a>]</cite>
</td>
<td id="S4.T5.4.1.14.14.2" class="ltx_td ltx_align_left">Gradient consistency</td>
<td id="S4.T5.4.1.14.14.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.14.14.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.14.14.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.14.14.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T5.4.1.15.15" class="ltx_tr">
<td id="S4.T5.4.1.15.15.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Li et al. [<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite></td>
<td id="S4.T5.4.1.15.15.2" class="ltx_td ltx_align_left">Anomaly detection</td>
<td id="S4.T5.4.1.15.15.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.15.15.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.15.15.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.15.15.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T5.4.1.16.16" class="ltx_tr">
<td id="S4.T5.4.1.16.16.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="5"><span id="S4.T5.4.1.16.16.1.1" class="ltx_text">Hybrid Mechanism</span></td>
<td id="S4.T5.4.1.16.16.2" class="ltx_td ltx_border_t" rowspan="4"></td>
<td id="S4.T5.4.1.16.16.3" class="ltx_td ltx_align_left ltx_border_t">CoMT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>
</td>
<td id="S4.T5.4.1.16.16.4" class="ltx_td ltx_align_left ltx_border_t">Collaborative teaching</td>
<td id="S4.T5.4.1.16.16.5" class="ltx_td ltx_align_left ltx_border_t">NA</td>
<td id="S4.T5.4.1.16.16.6" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.16.16.7" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S4.T5.4.1.16.16.8" class="ltx_td ltx_align_center ltx_border_t">✘</td>
</tr>
<tr id="S4.T5.4.1.17.17" class="ltx_tr">
<td id="S4.T5.4.1.17.17.1" class="ltx_td ltx_align_left">FLTrust <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>
</td>
<td id="S4.T5.4.1.17.17.2" class="ltx_td ltx_align_left">Global fine-tuning</td>
<td id="S4.T5.4.1.17.17.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.17.17.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.17.17.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.17.17.6" class="ltx_td ltx_align_center">✘</td>
</tr>
<tr id="S4.T5.4.1.18.18" class="ltx_tr">
<td id="S4.T5.4.1.18.18.1" class="ltx_td ltx_align_left">FedInv <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib263" title="" class="ltx_ref">263</a>]</cite>
</td>
<td id="S4.T5.4.1.18.18.2" class="ltx_td ltx_align_left">Gradient-based clustering</td>
<td id="S4.T5.4.1.18.18.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.18.18.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.18.18.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.18.18.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T5.4.1.19.19" class="ltx_tr">
<td id="S4.T5.4.1.19.19.1" class="ltx_td ltx_align_left">DiverseFl <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite>
</td>
<td id="S4.T5.4.1.19.19.2" class="ltx_td ltx_align_left">Filter update</td>
<td id="S4.T5.4.1.19.19.3" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.19.19.4" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.19.19.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.19.19.6" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T5.4.1.20.20" class="ltx_tr">
<td id="S4.T5.4.1.20.20.1" class="ltx_td"></td>
<td id="S4.T5.4.1.20.20.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_citet">Sun et al. [<a href="#bib.bib195" title="" class="ltx_ref">195</a>]</cite></td>
<td id="S4.T5.4.1.20.20.3" class="ltx_td ltx_align_left">Clipping and DP</td>
<td id="S4.T5.4.1.20.20.4" class="ltx_td ltx_align_left">NA</td>
<td id="S4.T5.4.1.20.20.5" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T5.4.1.20.20.6" class="ltx_td ltx_align_center">✘</td>
<td id="S4.T5.4.1.20.20.7" class="ltx_td ltx_align_center">✓</td>
</tr>
<tr id="S4.T5.4.1.21.21" class="ltx_tr">
<td id="S4.T5.4.1.21.21.1" class="ltx_td ltx_border_b"></td>
<td id="S4.T5.4.1.21.21.2" class="ltx_td ltx_border_b"></td>
<td id="S4.T5.4.1.21.21.3" class="ltx_td ltx_align_left ltx_border_b">CRFL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib224" title="" class="ltx_ref">224</a>]</cite>
</td>
<td id="S4.T5.4.1.21.21.4" class="ltx_td ltx_align_left ltx_border_b">Clipping and smoothing</td>
<td id="S4.T5.4.1.21.21.5" class="ltx_td ltx_align_left ltx_border_b">NA</td>
<td id="S4.T5.4.1.21.21.6" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S4.T5.4.1.21.21.7" class="ltx_td ltx_align_center ltx_border_b">✘</td>
<td id="S4.T5.4.1.21.21.8" class="ltx_td ltx_align_center ltx_border_b">✓</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul id="S4.I2" class="ltx_itemize ltx_centering ltx_figure_panel">
<li id="S4.I2.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1</span> 
<div id="S4.I2.ix1.p1" class="ltx_para">
<p id="S4.I2.ix1.p1.1" class="ltx_p">“✓” denotes supported, and “✘” denotes not supported or not studied.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_flex_break"></div>
</div>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span><span id="S4.SS3.1.1" class="ltx_text ltx_font_italic">Robustness to Targeted Attacks</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In targeted attacks, the attackers usually could manipulate the learning process of multiple clients and inject specific backdoors into the FL model. In this way. the FL model will output unexpected results on specific inputs with trigger, while the model performance on clean data is normal. Thus, attacks with specific targets are more dangerous threats to RFL. The most discussed targeted attack in the literature is backdoor attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite>, which can be further enhanced by Sybil attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> in FL. The backdoors in the trained model could be triggered at any time and make the model output unexpected results during the inference stage. The Sybil attacks could manipulate the model training process to control the behaviors of the FL model (backdoor FL models are easier). In this section, we introduce the targeted attacks in FL and review the proposed solutions in the literature.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Backdoor Attacks</span>. An adversary can conduct complex attacks (<em id="S4.SS3.p2.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS3.p2.1.3" class="ltx_text"></span>, both data poisoning and model poisoning) to implant a backdoor trigger into the learned model. Usually, the model will behave normally on clean data, while predicting a target class if the trigger appears. The backdoor attacks in FL are carried out by adversary clients with smartly organized data/model poisoning attacks. <cite class="ltx_cite ltx_citemacro_citet">Bagdasaryan et al. [<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> introduce semantic backdoors in FL that cause the model to misclassify even unmodified inputs. Edge-case backdoors <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite> force a model to misclassify on seemingly easy inputs that are however unlikely to be part of the training, or test data, <em id="S4.SS3.p2.1.4" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS3.p2.1.5" class="ltx_text"></span>, they live on the tail of the input distribution. Badnet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> lets Byzantine clients inject label-flipped data samples with specific backdoor triggers into the training datasets. <cite class="ltx_cite ltx_citemacro_citet">Xie et al. [<a href="#bib.bib221" title="" class="ltx_ref">221</a>]</cite> propose DBA (distributed backdoor attack), which decomposes a global trigger pattern into separate local patterns and embeds them into the training set of different adversarial parties respectively. <cite class="ltx_cite ltx_citemacro_citet">Liu et al. [<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite> propose a two-phase backdoor attack, which includes a preliminary phase for a whole population distribution inference attack and generates a well-crafted dataset and the later injected backdoor attacks would benefit from the crafted dataset. If an attacker could inject <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">c</annotation></semantics></math>, fake participants, into the FL system, the FL may suffer from Sybil attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. A single Sybil attacker could launch arbitrary attacks by influencing the fake participants. For example, Sybil clients contribute updates towards a specific poisoning objective <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, which achieves targeted attacks (inject backdoors) and untargeted attacks (ruin model performance). In summary, backdoor attacks are a well-designed combination of poisoning attacks from adversaries. Its form and target could vary in real-world applications, which makes it hard to be detected and defend.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Defense</span>. The main idea of defending against backdoor attacks is to prevent the formulation of backdoor triggers in model training, as the backdoor attacks can be considered to add an implicit predicting task into the model without noticing and use a trigger to launch a such predicting task in the inference stage. Compared with the defense approaches against the Byzantine problem, targeted attacks are harder to defend as the adversaries may not damage the model performance on clean datasets. Based on the observation that backdoor attackers are likely to produce updates with large norms, several studies are proposed to defend against backdoor attacks by manipulating those suspicious gradients. For example, <cite class="ltx_cite ltx_citemacro_citet">Sun et al. [<a href="#bib.bib195" title="" class="ltx_ref">195</a>]</cite> suggests using norm thresholding and differential privacy (clipping updates) to defend against backdoor attacks. CRFL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib224" title="" class="ltx_ref">224</a>]</cite> exploits clipping and smoothing on model parameters to control the global model smoothness. A sample-wise robustness certification on backdoors with limited magnitude is proved in the paper. The above techniques clip gradients from all clients to destroy the backdoor tasks. However, the hidden cost is the loss of performance of model training. The targeted attacks are basically conducted via model poisoning and data poisoning. Hence, previously discussed robust aggregation methods and Byzantine detection schemes could defend against backdoor attacks to some extent. Based on that, BaFFLe <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> utilizes data information feedback from multiple clients for uncovering model poisoning and detecting backdoor attacks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Privacy</span>
</h2>

<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table VI</span>: </span><span id="S5.T6.3.2" class="ltx_text" style="font-size:90%;">A Summary of the Relationship between Privacy Treats and the Existing Methods</span></figcaption>
<div id="S5.T6.4" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:30.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1200.7pt,85.2pt) scale(0.152955053140483,0.152955053140483) ;">
<table id="S5.T6.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T6.4.1.1.1" class="ltx_tr">
<th id="S5.T6.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;" colspan="3" rowspan="3"><span id="S5.T6.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Privacy Threats</span></th>
<td id="S5.T6.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;" colspan="5"><span id="S5.T6.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Defense Methods</span></td>
</tr>
<tr id="S5.T6.4.1.2.2" class="ltx_tr">
<td id="S5.T6.4.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" colspan="2">Diff. Privacy</td>
<td id="S5.T6.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" colspan="2">Perturbation</td>
<td id="S5.T6.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.2.2.3.1" class="ltx_text">Anonymization</span></td>
</tr>
<tr id="S5.T6.4.1.3.3" class="ltx_tr">
<td id="S5.T6.4.1.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Local Diff. Privacy</td>
<td id="S5.T6.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Global Diff. Privacy</td>
<td id="S5.T6.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Additive</td>
<td id="S5.T6.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Multiplicative</td>
</tr>
<tr id="S5.T6.4.1.4.4" class="ltx_tr">
<th id="S5.T6.4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.4.4.1.1" class="ltx_text ltx_font_bold">Data &amp; Label Leakage</span></th>
<th id="S5.T6.4.1.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Parameter Updating</th>
<th id="S5.T6.4.1.4.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib239" title="" class="ltx_ref">239</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>, <a href="#bib.bib261" title="" class="ltx_ref">261</a>]</cite></th>
<td id="S5.T6.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.4.4.4.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib180" title="" class="ltx_ref">180</a>, <a href="#bib.bib203" title="" class="ltx_ref">203</a>]</cite></span></td>
<td id="S5.T6.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.4.4.5.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite></span></td>
<td id="S5.T6.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.4.4.6.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib215" title="" class="ltx_ref">215</a>, <a href="#bib.bib228" title="" class="ltx_ref">228</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite></span></td>
<td id="S5.T6.4.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.4.4.7.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite></span></td>
<td id="S5.T6.4.1.4.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.4.4.8.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib188" title="" class="ltx_ref">188</a>, <a href="#bib.bib222" title="" class="ltx_ref">222</a>]</cite></span></td>
</tr>
<tr id="S5.T6.4.1.5.5" class="ltx_tr">
<th id="S5.T6.4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Gradient Updating</th>
<th id="S5.T6.4.1.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>, <a href="#bib.bib230" title="" class="ltx_ref">230</a>, <a href="#bib.bib92" title="" class="ltx_ref">92</a>, <a href="#bib.bib212" title="" class="ltx_ref">212</a>, <a href="#bib.bib241" title="" class="ltx_ref">241</a>]</cite></th>
</tr>
<tr id="S5.T6.4.1.6.6" class="ltx_tr">
<th id="S5.T6.4.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.6.6.1.1" class="ltx_text ltx_font_bold">Membership Leakage</span></th>
<th id="S5.T6.4.1.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Training Phase</th>
<th id="S5.T6.4.1.6.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib202" title="" class="ltx_ref">202</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite></th>
<td id="S5.T6.4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.6.6.4.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib194" title="" class="ltx_ref">194</a>]</cite></span></td>
<td id="S5.T6.4.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.6.6.5.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite></span></td>
<td id="S5.T6.4.1.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.6.6.6.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite></span></td>
<td id="S5.T6.4.1.6.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.6.6.7.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite></span></td>
<td id="S5.T6.4.1.6.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.6.6.8.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib180" title="" class="ltx_ref">180</a>, <a href="#bib.bib192" title="" class="ltx_ref">192</a>]</cite></span></td>
</tr>
<tr id="S5.T6.4.1.7.7" class="ltx_tr">
<th id="S5.T6.4.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Inference Phase</th>
<th id="S5.T6.4.1.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib186" title="" class="ltx_ref">186</a>, <a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite></th>
</tr>
<tr id="S5.T6.4.1.8.8" class="ltx_tr">
<th id="S5.T6.4.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.8.8.1.1" class="ltx_text ltx_font_bold">Proporties Leakage</span></th>
<th id="S5.T6.4.1.8.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Individual Proporties</th>
<th id="S5.T6.4.1.8.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib209" title="" class="ltx_ref">209</a>, <a href="#bib.bib250" title="" class="ltx_ref">250</a>]</cite></th>
<td id="S5.T6.4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.8.8.4.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib266" title="" class="ltx_ref">266</a>, <a href="#bib.bib267" title="" class="ltx_ref">267</a>]</cite></span></td>
<td id="S5.T6.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.8.8.5.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib201" title="" class="ltx_ref">201</a>]</cite></span></td>
<td id="S5.T6.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.8.8.6.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib214" title="" class="ltx_ref">214</a>, <a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite></span></td>
<td id="S5.T6.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.8.8.7.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite></span></td>
<td id="S5.T6.4.1.8.8.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S5.T6.4.1.8.8.8.1" class="ltx_text"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib180" title="" class="ltx_ref">180</a>, <a href="#bib.bib192" title="" class="ltx_ref">192</a>]</cite></span></td>
</tr>
</tbody>
<tfoot class="ltx_tfoot">
<tr id="S5.T6.4.1.9.1" class="ltx_tr">
<th id="S5.T6.4.1.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Population Proporties</th>
<th id="S5.T6.4.1.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>, <a href="#bib.bib141" title="" class="ltx_ref">141</a>, <a href="#bib.bib229" title="" class="ltx_ref">229</a>, <a href="#bib.bib269" title="" class="ltx_ref">269</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite></th>
</tr>
</tfoot>
</table>
</span></div>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">A privacy attack in federated learning (FL) aims to expose personal information about users who are participating in the machine learning task. This not only endangers the privacy of the data used to train the machine learning models, but also the individuals who voluntarily share their personal information. Initially, it was believed that FL was a distributed machine learning paradigm that could protect personal information. However, the learning process is vulnerable to real-world applications and faces a wide range of attacks. Despite the fact that private data is never shared, exchanged models are prone to remembering the private information of the training dataset. In this section, we present a taxonomy that aims to simplify the understanding of different privacy attacks, as shown in Table <a href="#S5.T6" title="Table VI ‣ 5 Privacy ‣ A Survey of Trustworthy Federated Learning with Perspectives on Security, Robustness, and Privacy" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span id="S5.SS1.1.1" class="ltx_text ltx_font_italic">Privacy Threats in Trustworthy Federated Learning</span>
</h3>

<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Data &amp; Label Leakage</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">In the context of Federated Learning, the data and label attack is also commonly referred to as the reconstruction attack. The goal of these attacks is to recover the dataset of a client who participates in an FL task. The attacks typically aim to generate the original training data samples and their corresponding labels. The most common data types that can be targeted by these attacks are images or plain text, which often contain private information owned by the parties.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p2.1" class="ltx_p"><span id="S5.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Gradient-based Data Leakage.</span>
In a gradient-based Federated Learning (FL) training procedure, as described in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib239" title="" class="ltx_ref">239</a>]</cite>, selected clients share their gradients with the federated server in communication rounds. However, model gradients may cause a significant amount of privacy leakage as they are derived from the participants’ private training datasets. By observing, altering, or listening in on gradient updates during the training process, an adversary (e.g., participants or eavesdroppers) can infer private data using gradients obtained via the training datasets <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib270" title="" class="ltx_ref">270</a>, <a href="#bib.bib261" title="" class="ltx_ref">261</a>]</cite>.</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para">
<p id="S5.SS1.SSS1.p3.1" class="ltx_p">To obtain the training inputs and labels, an optimization algorithm designed by <cite class="ltx_cite ltx_citemacro_citet">Zhu et al. [<a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite> first creates a dummy dataset made up of fictitious samples and labels. Dummy gradients are then obtained using standard forward and backward propagation on the fictitious dataset. The learning process is accomplished by minimizing the difference between the fake gradient and the real gradient. By using this approach, the attacker can infer the training samples and labels with a limited number of training rounds.</p>
</div>
<div id="S5.SS1.SSS1.p4" class="ltx_para">
<p id="S5.SS1.SSS1.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhao et al. [<a href="#bib.bib261" title="" class="ltx_ref">261</a>]</cite> expanded on the attack proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib270" title="" class="ltx_ref">270</a>]</cite> by utilizing the relationship between the ground-truth labels and the gradient signs.</p>
</div>
<div id="S5.SS1.SSS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS1.p5.1" class="ltx_p"><span id="S5.SS1.SSS1.p5.1.1" class="ltx_text ltx_font_bold">Weight-Based Data Leakage.</span></p>
</div>
<div id="S5.SS1.SSS1.p6" class="ltx_para">
<p id="S5.SS1.SSS1.p6.1" class="ltx_p">In weight-based Federated Learning (FL) frameworks, as described in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>, selected clients share their local model parameters with the federated server in communication rounds. Multiple participants have access to the aggregated parameters that the server calculates. A weight update can, therefore, expose the provided data to adversarial participants or eavesdroppers <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib230" title="" class="ltx_ref">230</a>]</cite>. Malicious participants can calculate the differences between FL models in different update rounds by repeatedly saving the parameters.</p>
</div>
<div id="S5.SS1.SSS1.p7" class="ltx_para">
<p id="S5.SS1.SSS1.p7.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Xu et al. [<a href="#bib.bib230" title="" class="ltx_ref">230</a>]</cite> showed that the model weight can be trained to reveal sensitive information by controlling specific participants during the training phase. In addition, <cite class="ltx_cite ltx_citemacro_citet">Hitaj et al. [<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> offer a Generative Adversarial Network (GAN)-based active attack for recovering training images, where the key to training the GAN is employing the global model as a discriminator. The attacker misleads the target client to release more information about the target label. Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. [<a href="#bib.bib212" title="" class="ltx_ref">212</a>]</cite> have altered the GAN architecture to a multitask GAN.</p>
</div>
<div id="S5.SS1.SSS1.p8" class="ltx_para">
<p id="S5.SS1.SSS1.p8.1" class="ltx_p">Apart from GAN-based attacks, <cite class="ltx_cite ltx_citemacro_citet">Yuan et al. [<a href="#bib.bib241" title="" class="ltx_ref">241</a>]</cite> focus on reconstructing text via model parameters in natural language processing tasks, especially for language modeling.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Membership Leakage</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">Membership inference is a technique used to determine whether a given data sample was part of the training dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite>. For instance, it can be used to identify whether a particular patient’s records were used to train a classifier for a specific disease.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS2.p2.1" class="ltx_p"><span id="S5.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Traing Phase Membership Leakage.</span>
The work by <cite class="ltx_cite ltx_citemacro_citet">Shokri et al. [<a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite> focused on the membership inference attack against privacy leakage in machine learning, where an inference model is trained to determine whether a given data sample belongs to the training dataset.</p>
</div>
<div id="S5.SS1.SSS2.p3" class="ltx_para">
<p id="S5.SS1.SSS2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Truex et al. [<a href="#bib.bib202" title="" class="ltx_ref">202</a>]</cite> extended this approach to a broader context, demonstrating its data-driven nature and high transferability.</p>
</div>
<div id="S5.SS1.SSS2.p4" class="ltx_para">
<p id="S5.SS1.SSS2.p4.1" class="ltx_p">Recent studies have identified the gradients and embedding layers as the two areas facing privacy leakage in membership inference attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite>. It has been shown that the embedding of a deep learning network can expose the locations of words in the training data through non-zero gradients, allowing an adversary to conduct a membership inference attack. To address this issue, <cite class="ltx_cite ltx_citemacro_citet">Hitaj et al. [<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> evaluated membership inference attacks against generative models, revealing that many models based on boundary equilibrium GANs or deep GANs are vulnerable to privacy leaks.</p>
</div>
<div id="S5.SS1.SSS2.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS2.p5.1" class="ltx_p"><span id="S5.SS1.SSS2.p5.1.1" class="ltx_text ltx_font_bold">Inference Phase Membership Leakage</span>
During the inference phase, <cite class="ltx_cite ltx_citemacro_citet">Fredrikson et al. [<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> developed an inversion method for retrieving private information, revealing that it can expose user-level information.</p>
</div>
<div id="S5.SS1.SSS2.p6" class="ltx_para">
<p id="S5.SS1.SSS2.p6.1" class="ltx_p">In a similar vein, <cite class="ltx_cite ltx_citemacro_citet">Melis et al. [<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite> investigated membership privacy leakage during the inference phase, demonstrating that deep learning models can disclose the placements of words in a batch. In this case, inference attacks are primarily responsible for privacy leaks when attackers can only access model query outputs, such as those returned by a machine learning-as-a-service API <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib202" title="" class="ltx_ref">202</a>]</cite>.</p>
</div>
<div id="S5.SS1.SSS2.p7" class="ltx_para">
<p id="S5.SS1.SSS2.p7.1" class="ltx_p">Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Shokri et al. [<a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite> explored privacy leakage during the inference phase by examining the inference membership attack against model query results. In this approach, an inference model is trained to distinguish between training and non-training data samples.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Property Inference Attack</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">This type of attack aims to determine whether an unrelated property of a client or the FL task population is present in the FL model, with the objective of acquiring a characteristic that should not be shared. For example, consider a machine learning model designed to detect faces. An attack might attempt to infer whether training images contain faces with blue eyes, even though this characteristic is unrelated to the primary goal of the model.</p>
</div>
<div id="S5.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS3.p2.1" class="ltx_p"><span id="S5.SS1.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Property on Population Distribution.</span>
This type of attack aims to infer the distribution of a feature in a group of clients. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. [<a href="#bib.bib209" title="" class="ltx_ref">209</a>]</cite> propose a set of passive attacks using stochastic gradient descent that can be used to infer the label in each training round. To accomplish this, the attacker needs to possess internal knowledge as well as partial external knowledge, which includes information about the number of clients, the average number of labels, and the number of data samples per label.</p>
</div>
<div id="S5.SS1.SSS3.p3" class="ltx_para">
<p id="S5.SS1.SSS3.p3.1" class="ltx_p">In a more general FL setting, <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. [<a href="#bib.bib250" title="" class="ltx_ref">250</a>]</cite> propose a passive attack with limited knowledge to infer the distribution of sensitive features in the training datasets.</p>
</div>
<div id="S5.SS1.SSS3.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.SSS3.p4.1" class="ltx_p"><span id="S5.SS1.SSS3.p4.1.1" class="ltx_text ltx_font_bold">Property on Individual Distribution.</span>
Attackers may attempt to infer the presence of an unrelated property in target clients. With stochastic gradient descent, <cite class="ltx_cite ltx_citemacro_citet">Mo et al. [<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite> propose a formal evaluation process to measure the leak of such properties in deep neural networks. Both passive and active property inference attacks have been created by <cite class="ltx_cite ltx_citemacro_citet">Melis et al. [<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite> using internal knowledge, with multitasking learning used to power the active attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib252" title="" class="ltx_ref">252</a>]</cite>. In a regular FL setting, <cite class="ltx_cite ltx_citemacro_citet">Xu and Li [<a href="#bib.bib229" title="" class="ltx_ref">229</a>]</cite> propose two attacks, passive and active, with the active attack leveraging CycleGAN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib269" title="" class="ltx_ref">269</a>]</cite> to reconstruct gradients using the target attribute. <cite class="ltx_cite ltx_citemacro_citet">Chase et al. [<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> suggest a poisoning attack to infer properties, which requires partial internal information to modify the target client’s dataset and external knowledge. Finally, in an unusual FL environment using blockchain-assisted HFL, <cite class="ltx_cite ltx_citemacro_citet">Shen et al. [<a href="#bib.bib184" title="" class="ltx_ref">184</a>]</cite> propose an active attack.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span id="S5.SS2.1.1" class="ltx_text ltx_font_italic">Privacy Defences Method for Trustworthy FL</span>
</h3>

<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Differential Privacy</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Differential Privacy (DP) allows for information leakage while carefully limiting the harm to people whose private data is stored in a training set. In essence, it hides a person’s personal information by introducing random noise. This type of noise is proportional to the largest modification that a single person can make to the output. It should be noted that DP makes the assumption that the adversary has any external knowledge.</p>
</div>
<div id="S5.Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="S5.Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition 5.1</span></span><span id="S5.Thmdefinition1.2.2" class="ltx_text ltx_font_bold"> (Differential Privacy <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite>)</span>
</h6>
<div id="S5.Thmdefinition1.p1" class="ltx_para">
<p id="S5.Thmdefinition1.p1.5" class="ltx_p"><span id="S5.Thmdefinition1.p1.5.5" class="ltx_text ltx_font_italic">A database access mechanism, <math id="S5.Thmdefinition1.p1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S5.Thmdefinition1.p1.1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.Thmdefinition1.p1.1.1.m1.1.1" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.1.1.m1.1b"><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.1.1.m1.1c">\mathcal{M}</annotation></semantics></math>, preserves <math id="S5.Thmdefinition1.p1.2.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.Thmdefinition1.p1.2.2.m2.1a"><mi id="S5.Thmdefinition1.p1.2.2.m2.1.1" xref="S5.Thmdefinition1.p1.2.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.2.2.m2.1b"><ci id="S5.Thmdefinition1.p1.2.2.m2.1.1.cmml" xref="S5.Thmdefinition1.p1.2.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.2.2.m2.1c">\epsilon</annotation></semantics></math>-DP if for all neighboring databases <math id="S5.Thmdefinition1.p1.3.3.m3.2" class="ltx_Math" alttext="x,y" display="inline"><semantics id="S5.Thmdefinition1.p1.3.3.m3.2a"><mrow id="S5.Thmdefinition1.p1.3.3.m3.2.3.2" xref="S5.Thmdefinition1.p1.3.3.m3.2.3.1.cmml"><mi id="S5.Thmdefinition1.p1.3.3.m3.1.1" xref="S5.Thmdefinition1.p1.3.3.m3.1.1.cmml">x</mi><mo id="S5.Thmdefinition1.p1.3.3.m3.2.3.2.1" xref="S5.Thmdefinition1.p1.3.3.m3.2.3.1.cmml">,</mo><mi id="S5.Thmdefinition1.p1.3.3.m3.2.2" xref="S5.Thmdefinition1.p1.3.3.m3.2.2.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.3.3.m3.2b"><list id="S5.Thmdefinition1.p1.3.3.m3.2.3.1.cmml" xref="S5.Thmdefinition1.p1.3.3.m3.2.3.2"><ci id="S5.Thmdefinition1.p1.3.3.m3.1.1.cmml" xref="S5.Thmdefinition1.p1.3.3.m3.1.1">𝑥</ci><ci id="S5.Thmdefinition1.p1.3.3.m3.2.2.cmml" xref="S5.Thmdefinition1.p1.3.3.m3.2.2">𝑦</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.3.3.m3.2c">x,y</annotation></semantics></math> and each possible output of <math id="S5.Thmdefinition1.p1.4.4.m4.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S5.Thmdefinition1.p1.4.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S5.Thmdefinition1.p1.4.4.m4.1.1" xref="S5.Thmdefinition1.p1.4.4.m4.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.4.4.m4.1b"><ci id="S5.Thmdefinition1.p1.4.4.m4.1.1.cmml" xref="S5.Thmdefinition1.p1.4.4.m4.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.4.4.m4.1c">\mathcal{M}</annotation></semantics></math>, represented by <math id="S5.Thmdefinition1.p1.5.5.m5.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S5.Thmdefinition1.p1.5.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S5.Thmdefinition1.p1.5.5.m5.1.1" xref="S5.Thmdefinition1.p1.5.5.m5.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.5.5.m5.1b"><ci id="S5.Thmdefinition1.p1.5.5.m5.1.1.cmml" xref="S5.Thmdefinition1.p1.5.5.m5.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.5.5.m5.1c">\mathcal{S}</annotation></semantics></math>, it holds that:</span></p>
<table id="S5.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E6.m1.3" class="ltx_Math" alttext="P[\mathcal{M}(x)\in\mathcal{S}]\leq e^{\epsilon}P[\mathcal{M}(y)\in\mathcal{S}]." display="block"><semantics id="S5.E6.m1.3a"><mrow id="S5.E6.m1.3.3.1" xref="S5.E6.m1.3.3.1.1.cmml"><mrow id="S5.E6.m1.3.3.1.1" xref="S5.E6.m1.3.3.1.1.cmml"><mrow id="S5.E6.m1.3.3.1.1.1" xref="S5.E6.m1.3.3.1.1.1.cmml"><mi id="S5.E6.m1.3.3.1.1.1.3" xref="S5.E6.m1.3.3.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.3.3.1.1.1.2" xref="S5.E6.m1.3.3.1.1.1.2.cmml">​</mo><mrow id="S5.E6.m1.3.3.1.1.1.1.1" xref="S5.E6.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E6.m1.3.3.1.1.1.1.1.2" xref="S5.E6.m1.3.3.1.1.1.1.2.1.cmml">[</mo><mrow id="S5.E6.m1.3.3.1.1.1.1.1.1" xref="S5.E6.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S5.E6.m1.3.3.1.1.1.1.1.1.2" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E6.m1.3.3.1.1.1.1.1.1.2.2" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.3.3.1.1.1.1.1.1.2.1" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S5.E6.m1.3.3.1.1.1.1.1.1.2.3.2" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E6.m1.3.3.1.1.1.1.1.1.2.3.2.1" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><mi id="S5.E6.m1.1.1" xref="S5.E6.m1.1.1.cmml">x</mi><mo stretchy="false" id="S5.E6.m1.3.3.1.1.1.1.1.1.2.3.2.2" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.E6.m1.3.3.1.1.1.1.1.1.1" xref="S5.E6.m1.3.3.1.1.1.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S5.E6.m1.3.3.1.1.1.1.1.1.3" xref="S5.E6.m1.3.3.1.1.1.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S5.E6.m1.3.3.1.1.1.1.1.3" xref="S5.E6.m1.3.3.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S5.E6.m1.3.3.1.1.3" xref="S5.E6.m1.3.3.1.1.3.cmml">≤</mo><mrow id="S5.E6.m1.3.3.1.1.2" xref="S5.E6.m1.3.3.1.1.2.cmml"><msup id="S5.E6.m1.3.3.1.1.2.3" xref="S5.E6.m1.3.3.1.1.2.3.cmml"><mi id="S5.E6.m1.3.3.1.1.2.3.2" xref="S5.E6.m1.3.3.1.1.2.3.2.cmml">e</mi><mi id="S5.E6.m1.3.3.1.1.2.3.3" xref="S5.E6.m1.3.3.1.1.2.3.3.cmml">ϵ</mi></msup><mo lspace="0em" rspace="0em" id="S5.E6.m1.3.3.1.1.2.2" xref="S5.E6.m1.3.3.1.1.2.2.cmml">​</mo><mi id="S5.E6.m1.3.3.1.1.2.4" xref="S5.E6.m1.3.3.1.1.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.3.3.1.1.2.2a" xref="S5.E6.m1.3.3.1.1.2.2.cmml">​</mo><mrow id="S5.E6.m1.3.3.1.1.2.1.1" xref="S5.E6.m1.3.3.1.1.2.1.2.cmml"><mo stretchy="false" id="S5.E6.m1.3.3.1.1.2.1.1.2" xref="S5.E6.m1.3.3.1.1.2.1.2.1.cmml">[</mo><mrow id="S5.E6.m1.3.3.1.1.2.1.1.1" xref="S5.E6.m1.3.3.1.1.2.1.1.1.cmml"><mrow id="S5.E6.m1.3.3.1.1.2.1.1.1.2" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E6.m1.3.3.1.1.2.1.1.1.2.2" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.E6.m1.3.3.1.1.2.1.1.1.2.1" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.1.cmml">​</mo><mrow id="S5.E6.m1.3.3.1.1.2.1.1.1.2.3.2" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.cmml"><mo stretchy="false" id="S5.E6.m1.3.3.1.1.2.1.1.1.2.3.2.1" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.cmml">(</mo><mi id="S5.E6.m1.2.2" xref="S5.E6.m1.2.2.cmml">y</mi><mo stretchy="false" id="S5.E6.m1.3.3.1.1.2.1.1.1.2.3.2.2" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.E6.m1.3.3.1.1.2.1.1.1.1" xref="S5.E6.m1.3.3.1.1.2.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S5.E6.m1.3.3.1.1.2.1.1.1.3" xref="S5.E6.m1.3.3.1.1.2.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S5.E6.m1.3.3.1.1.2.1.1.3" xref="S5.E6.m1.3.3.1.1.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo lspace="0em" id="S5.E6.m1.3.3.1.2" xref="S5.E6.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E6.m1.3b"><apply id="S5.E6.m1.3.3.1.1.cmml" xref="S5.E6.m1.3.3.1"><leq id="S5.E6.m1.3.3.1.1.3.cmml" xref="S5.E6.m1.3.3.1.1.3"></leq><apply id="S5.E6.m1.3.3.1.1.1.cmml" xref="S5.E6.m1.3.3.1.1.1"><times id="S5.E6.m1.3.3.1.1.1.2.cmml" xref="S5.E6.m1.3.3.1.1.1.2"></times><ci id="S5.E6.m1.3.3.1.1.1.3.cmml" xref="S5.E6.m1.3.3.1.1.1.3">𝑃</ci><apply id="S5.E6.m1.3.3.1.1.1.1.2.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S5.E6.m1.3.3.1.1.1.1.2.1.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S5.E6.m1.3.3.1.1.1.1.1.1.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1.1"><in id="S5.E6.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1.1.1"></in><apply id="S5.E6.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2"><times id="S5.E6.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.1"></times><ci id="S5.E6.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1.1.2.2">ℳ</ci><ci id="S5.E6.m1.1.1.cmml" xref="S5.E6.m1.1.1">𝑥</ci></apply><ci id="S5.E6.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S5.E6.m1.3.3.1.1.1.1.1.1.3">𝒮</ci></apply></apply></apply><apply id="S5.E6.m1.3.3.1.1.2.cmml" xref="S5.E6.m1.3.3.1.1.2"><times id="S5.E6.m1.3.3.1.1.2.2.cmml" xref="S5.E6.m1.3.3.1.1.2.2"></times><apply id="S5.E6.m1.3.3.1.1.2.3.cmml" xref="S5.E6.m1.3.3.1.1.2.3"><csymbol cd="ambiguous" id="S5.E6.m1.3.3.1.1.2.3.1.cmml" xref="S5.E6.m1.3.3.1.1.2.3">superscript</csymbol><ci id="S5.E6.m1.3.3.1.1.2.3.2.cmml" xref="S5.E6.m1.3.3.1.1.2.3.2">𝑒</ci><ci id="S5.E6.m1.3.3.1.1.2.3.3.cmml" xref="S5.E6.m1.3.3.1.1.2.3.3">italic-ϵ</ci></apply><ci id="S5.E6.m1.3.3.1.1.2.4.cmml" xref="S5.E6.m1.3.3.1.1.2.4">𝑃</ci><apply id="S5.E6.m1.3.3.1.1.2.1.2.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1"><csymbol cd="latexml" id="S5.E6.m1.3.3.1.1.2.1.2.1.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1.2">delimited-[]</csymbol><apply id="S5.E6.m1.3.3.1.1.2.1.1.1.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1.1"><in id="S5.E6.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1.1.1"></in><apply id="S5.E6.m1.3.3.1.1.2.1.1.1.2.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2"><times id="S5.E6.m1.3.3.1.1.2.1.1.1.2.1.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.1"></times><ci id="S5.E6.m1.3.3.1.1.2.1.1.1.2.2.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1.1.2.2">ℳ</ci><ci id="S5.E6.m1.2.2.cmml" xref="S5.E6.m1.2.2">𝑦</ci></apply><ci id="S5.E6.m1.3.3.1.1.2.1.1.1.3.cmml" xref="S5.E6.m1.3.3.1.1.2.1.1.1.3">𝒮</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E6.m1.3c">P[\mathcal{M}(x)\in\mathcal{S}]\leq e^{\epsilon}P[\mathcal{M}(y)\in\mathcal{S}].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S5.Thmdefinition1.p1.6" class="ltx_p"><span id="S5.Thmdefinition1.p1.6.1" class="ltx_text ltx_font_italic">If, on the other hand, for <math id="S5.Thmdefinition1.p1.6.1.m1.1" class="ltx_Math" alttext="0&lt;\delta&lt;1" display="inline"><semantics id="S5.Thmdefinition1.p1.6.1.m1.1a"><mrow id="S5.Thmdefinition1.p1.6.1.m1.1.1" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.cmml"><mn id="S5.Thmdefinition1.p1.6.1.m1.1.1.2" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.2.cmml">0</mn><mo id="S5.Thmdefinition1.p1.6.1.m1.1.1.3" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.3.cmml">&lt;</mo><mi id="S5.Thmdefinition1.p1.6.1.m1.1.1.4" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.4.cmml">δ</mi><mo id="S5.Thmdefinition1.p1.6.1.m1.1.1.5" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.5.cmml">&lt;</mo><mn id="S5.Thmdefinition1.p1.6.1.m1.1.1.6" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.6.1.m1.1b"><apply id="S5.Thmdefinition1.p1.6.1.m1.1.1.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1"><and id="S5.Thmdefinition1.p1.6.1.m1.1.1a.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1"></and><apply id="S5.Thmdefinition1.p1.6.1.m1.1.1b.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1"><lt id="S5.Thmdefinition1.p1.6.1.m1.1.1.3.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.3"></lt><cn type="integer" id="S5.Thmdefinition1.p1.6.1.m1.1.1.2.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.2">0</cn><ci id="S5.Thmdefinition1.p1.6.1.m1.1.1.4.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.4">𝛿</ci></apply><apply id="S5.Thmdefinition1.p1.6.1.m1.1.1c.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1"><lt id="S5.Thmdefinition1.p1.6.1.m1.1.1.5.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.5"></lt><share href="#S5.Thmdefinition1.p1.6.1.m1.1.1.4.cmml" id="S5.Thmdefinition1.p1.6.1.m1.1.1d.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1"></share><cn type="integer" id="S5.Thmdefinition1.p1.6.1.m1.1.1.6.cmml" xref="S5.Thmdefinition1.p1.6.1.m1.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.6.1.m1.1c">0&lt;\delta&lt;1</annotation></semantics></math> it holds that:</span></p>
<table id="S5.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E7.m1.3" class="ltx_Math" alttext="P[\mathcal{M}(x)\in\mathcal{S}]\leq e^{\epsilon}P[\mathcal{M}(y)\in\mathcal{S}]+\delta," display="block"><semantics id="S5.E7.m1.3a"><mrow id="S5.E7.m1.3.3.1" xref="S5.E7.m1.3.3.1.1.cmml"><mrow id="S5.E7.m1.3.3.1.1" xref="S5.E7.m1.3.3.1.1.cmml"><mrow id="S5.E7.m1.3.3.1.1.1" xref="S5.E7.m1.3.3.1.1.1.cmml"><mi id="S5.E7.m1.3.3.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.3.3.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.2.cmml">​</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E7.m1.3.3.1.1.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.1.2.1.cmml">[</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E7.m1.3.3.1.1.1.1.1.1.2.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.3.3.1.1.1.1.1.1.2.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S5.E7.m1.3.3.1.1.1.1.1.1.2.3.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E7.m1.3.3.1.1.1.1.1.1.2.3.2.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><mi id="S5.E7.m1.1.1" xref="S5.E7.m1.1.1.cmml">x</mi><mo stretchy="false" id="S5.E7.m1.3.3.1.1.1.1.1.1.2.3.2.2" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.E7.m1.3.3.1.1.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S5.E7.m1.3.3.1.1.1.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S5.E7.m1.3.3.1.1.1.1.1.3" xref="S5.E7.m1.3.3.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S5.E7.m1.3.3.1.1.3" xref="S5.E7.m1.3.3.1.1.3.cmml">≤</mo><mrow id="S5.E7.m1.3.3.1.1.2" xref="S5.E7.m1.3.3.1.1.2.cmml"><mrow id="S5.E7.m1.3.3.1.1.2.1" xref="S5.E7.m1.3.3.1.1.2.1.cmml"><msup id="S5.E7.m1.3.3.1.1.2.1.3" xref="S5.E7.m1.3.3.1.1.2.1.3.cmml"><mi id="S5.E7.m1.3.3.1.1.2.1.3.2" xref="S5.E7.m1.3.3.1.1.2.1.3.2.cmml">e</mi><mi id="S5.E7.m1.3.3.1.1.2.1.3.3" xref="S5.E7.m1.3.3.1.1.2.1.3.3.cmml">ϵ</mi></msup><mo lspace="0em" rspace="0em" id="S5.E7.m1.3.3.1.1.2.1.2" xref="S5.E7.m1.3.3.1.1.2.1.2.cmml">​</mo><mi id="S5.E7.m1.3.3.1.1.2.1.4" xref="S5.E7.m1.3.3.1.1.2.1.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.3.3.1.1.2.1.2a" xref="S5.E7.m1.3.3.1.1.2.1.2.cmml">​</mo><mrow id="S5.E7.m1.3.3.1.1.2.1.1.1" xref="S5.E7.m1.3.3.1.1.2.1.1.2.cmml"><mo stretchy="false" id="S5.E7.m1.3.3.1.1.2.1.1.1.2" xref="S5.E7.m1.3.3.1.1.2.1.1.2.1.cmml">[</mo><mrow id="S5.E7.m1.3.3.1.1.2.1.1.1.1" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.cmml"><mrow id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.2" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.1" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.1.cmml">​</mo><mrow id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.3.2" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.3.2.1" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.cmml">(</mo><mi id="S5.E7.m1.2.2" xref="S5.E7.m1.2.2.cmml">y</mi><mo stretchy="false" id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.3.2.2" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.E7.m1.3.3.1.1.2.1.1.1.1.1" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S5.E7.m1.3.3.1.1.2.1.1.1.1.3" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.3.cmml">𝒮</mi></mrow><mo stretchy="false" id="S5.E7.m1.3.3.1.1.2.1.1.1.3" xref="S5.E7.m1.3.3.1.1.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S5.E7.m1.3.3.1.1.2.2" xref="S5.E7.m1.3.3.1.1.2.2.cmml">+</mo><mi id="S5.E7.m1.3.3.1.1.2.3" xref="S5.E7.m1.3.3.1.1.2.3.cmml">δ</mi></mrow></mrow><mo id="S5.E7.m1.3.3.1.2" xref="S5.E7.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E7.m1.3b"><apply id="S5.E7.m1.3.3.1.1.cmml" xref="S5.E7.m1.3.3.1"><leq id="S5.E7.m1.3.3.1.1.3.cmml" xref="S5.E7.m1.3.3.1.1.3"></leq><apply id="S5.E7.m1.3.3.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1"><times id="S5.E7.m1.3.3.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.2"></times><ci id="S5.E7.m1.3.3.1.1.1.3.cmml" xref="S5.E7.m1.3.3.1.1.1.3">𝑃</ci><apply id="S5.E7.m1.3.3.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S5.E7.m1.3.3.1.1.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1"><in id="S5.E7.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.1"></in><apply id="S5.E7.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2"><times id="S5.E7.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.1"></times><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.2.2">ℳ</ci><ci id="S5.E7.m1.1.1.cmml" xref="S5.E7.m1.1.1">𝑥</ci></apply><ci id="S5.E7.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S5.E7.m1.3.3.1.1.1.1.1.1.3">𝒮</ci></apply></apply></apply><apply id="S5.E7.m1.3.3.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.2"><plus id="S5.E7.m1.3.3.1.1.2.2.cmml" xref="S5.E7.m1.3.3.1.1.2.2"></plus><apply id="S5.E7.m1.3.3.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.2.1"><times id="S5.E7.m1.3.3.1.1.2.1.2.cmml" xref="S5.E7.m1.3.3.1.1.2.1.2"></times><apply id="S5.E7.m1.3.3.1.1.2.1.3.cmml" xref="S5.E7.m1.3.3.1.1.2.1.3"><csymbol cd="ambiguous" id="S5.E7.m1.3.3.1.1.2.1.3.1.cmml" xref="S5.E7.m1.3.3.1.1.2.1.3">superscript</csymbol><ci id="S5.E7.m1.3.3.1.1.2.1.3.2.cmml" xref="S5.E7.m1.3.3.1.1.2.1.3.2">𝑒</ci><ci id="S5.E7.m1.3.3.1.1.2.1.3.3.cmml" xref="S5.E7.m1.3.3.1.1.2.1.3.3">italic-ϵ</ci></apply><ci id="S5.E7.m1.3.3.1.1.2.1.4.cmml" xref="S5.E7.m1.3.3.1.1.2.1.4">𝑃</ci><apply id="S5.E7.m1.3.3.1.1.2.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1"><csymbol cd="latexml" id="S5.E7.m1.3.3.1.1.2.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1.2">delimited-[]</csymbol><apply id="S5.E7.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1"><in id="S5.E7.m1.3.3.1.1.2.1.1.1.1.1.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.1"></in><apply id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2"><times id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.1.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.1"></times><ci id="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.2.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.2.2">ℳ</ci><ci id="S5.E7.m1.2.2.cmml" xref="S5.E7.m1.2.2">𝑦</ci></apply><ci id="S5.E7.m1.3.3.1.1.2.1.1.1.1.3.cmml" xref="S5.E7.m1.3.3.1.1.2.1.1.1.1.3">𝒮</ci></apply></apply></apply><ci id="S5.E7.m1.3.3.1.1.2.3.cmml" xref="S5.E7.m1.3.3.1.1.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E7.m1.3c">P[\mathcal{M}(x)\in\mathcal{S}]\leq e^{\epsilon}P[\mathcal{M}(y)\in\mathcal{S}]+\delta,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S5.Thmdefinition1.p1.11" class="ltx_p"><span id="S5.Thmdefinition1.p1.11.5" class="ltx_text ltx_font_italic">then the mechanism possesses the property of <math id="S5.Thmdefinition1.p1.7.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S5.Thmdefinition1.p1.7.1.m1.2a"><mrow id="S5.Thmdefinition1.p1.7.1.m1.2.3.2" xref="S5.Thmdefinition1.p1.7.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.Thmdefinition1.p1.7.1.m1.2.3.2.1" xref="S5.Thmdefinition1.p1.7.1.m1.2.3.1.cmml">(</mo><mi id="S5.Thmdefinition1.p1.7.1.m1.1.1" xref="S5.Thmdefinition1.p1.7.1.m1.1.1.cmml">ϵ</mi><mo id="S5.Thmdefinition1.p1.7.1.m1.2.3.2.2" xref="S5.Thmdefinition1.p1.7.1.m1.2.3.1.cmml">,</mo><mi id="S5.Thmdefinition1.p1.7.1.m1.2.2" xref="S5.Thmdefinition1.p1.7.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S5.Thmdefinition1.p1.7.1.m1.2.3.2.3" xref="S5.Thmdefinition1.p1.7.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.7.1.m1.2b"><interval closure="open" id="S5.Thmdefinition1.p1.7.1.m1.2.3.1.cmml" xref="S5.Thmdefinition1.p1.7.1.m1.2.3.2"><ci id="S5.Thmdefinition1.p1.7.1.m1.1.1.cmml" xref="S5.Thmdefinition1.p1.7.1.m1.1.1">italic-ϵ</ci><ci id="S5.Thmdefinition1.p1.7.1.m1.2.2.cmml" xref="S5.Thmdefinition1.p1.7.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.7.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-DP, also known as approximate DP. In other words, DP specifies a ”privacy budget” given by <math id="S5.Thmdefinition1.p1.8.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.Thmdefinition1.p1.8.2.m2.1a"><mi id="S5.Thmdefinition1.p1.8.2.m2.1.1" xref="S5.Thmdefinition1.p1.8.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.8.2.m2.1b"><ci id="S5.Thmdefinition1.p1.8.2.m2.1.1.cmml" xref="S5.Thmdefinition1.p1.8.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.8.2.m2.1c">\epsilon</annotation></semantics></math> and <math id="S5.Thmdefinition1.p1.9.3.m3.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S5.Thmdefinition1.p1.9.3.m3.1a"><mi id="S5.Thmdefinition1.p1.9.3.m3.1.1" xref="S5.Thmdefinition1.p1.9.3.m3.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.9.3.m3.1b"><ci id="S5.Thmdefinition1.p1.9.3.m3.1.1.cmml" xref="S5.Thmdefinition1.p1.9.3.m3.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.9.3.m3.1c">\delta</annotation></semantics></math>. The way in which it is spent is given by the concept of privacy loss. The privacy loss allows us to reinterpret both, <math id="S5.Thmdefinition1.p1.10.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.Thmdefinition1.p1.10.4.m4.1a"><mi id="S5.Thmdefinition1.p1.10.4.m4.1.1" xref="S5.Thmdefinition1.p1.10.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.10.4.m4.1b"><ci id="S5.Thmdefinition1.p1.10.4.m4.1.1.cmml" xref="S5.Thmdefinition1.p1.10.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.10.4.m4.1c">\epsilon</annotation></semantics></math> and <math id="S5.Thmdefinition1.p1.11.5.m5.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S5.Thmdefinition1.p1.11.5.m5.1a"><mi id="S5.Thmdefinition1.p1.11.5.m5.1.1" xref="S5.Thmdefinition1.p1.11.5.m5.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.11.5.m5.1b"><ci id="S5.Thmdefinition1.p1.11.5.m5.1.1.cmml" xref="S5.Thmdefinition1.p1.11.5.m5.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.11.5.m5.1c">\delta</annotation></semantics></math> in a more intuitive way:</span></p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><math id="S5.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.I1.i1.p1.1.m1.1a"><mi id="S5.I1.i1.p1.1.m1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.m1.1b"><ci id="S5.I1.i1.p1.1.m1.1.1.cmml" xref="S5.I1.i1.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.m1.1c">\epsilon</annotation></semantics></math><span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_italic"> limits the quantity of privacy loss permitted, that is, our privacy budget.</span></p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.4" class="ltx_p"><math id="S5.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S5.I1.i2.p1.1.m1.1a"><mi id="S5.I1.i2.p1.1.m1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.m1.1b"><ci id="S5.I1.i2.p1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.m1.1c">\delta</annotation></semantics></math><span id="S5.I1.i2.p1.4.1" class="ltx_text ltx_font_italic"> is the probability of exceeding the privacy budget given by </span><math id="S5.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.I1.i2.p1.2.m2.1a"><mi id="S5.I1.i2.p1.2.m2.1.1" xref="S5.I1.i2.p1.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.2.m2.1b"><ci id="S5.I1.i2.p1.2.m2.1.1.cmml" xref="S5.I1.i2.p1.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.2.m2.1c">\epsilon</annotation></semantics></math><span id="S5.I1.i2.p1.4.2" class="ltx_text ltx_font_italic"> so that we can ensure that with probability </span><math id="S5.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="1-\delta" display="inline"><semantics id="S5.I1.i2.p1.3.m3.1a"><mrow id="S5.I1.i2.p1.3.m3.1.1" xref="S5.I1.i2.p1.3.m3.1.1.cmml"><mn id="S5.I1.i2.p1.3.m3.1.1.2" xref="S5.I1.i2.p1.3.m3.1.1.2.cmml">1</mn><mo id="S5.I1.i2.p1.3.m3.1.1.1" xref="S5.I1.i2.p1.3.m3.1.1.1.cmml">−</mo><mi id="S5.I1.i2.p1.3.m3.1.1.3" xref="S5.I1.i2.p1.3.m3.1.1.3.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.3.m3.1b"><apply id="S5.I1.i2.p1.3.m3.1.1.cmml" xref="S5.I1.i2.p1.3.m3.1.1"><minus id="S5.I1.i2.p1.3.m3.1.1.1.cmml" xref="S5.I1.i2.p1.3.m3.1.1.1"></minus><cn type="integer" id="S5.I1.i2.p1.3.m3.1.1.2.cmml" xref="S5.I1.i2.p1.3.m3.1.1.2">1</cn><ci id="S5.I1.i2.p1.3.m3.1.1.3.cmml" xref="S5.I1.i2.p1.3.m3.1.1.3">𝛿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.3.m3.1c">1-\delta</annotation></semantics></math><span id="S5.I1.i2.p1.4.3" class="ltx_text ltx_font_italic">, the privacy loss will not be greater than </span><math id="S5.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S5.I1.i2.p1.4.m4.1a"><mi id="S5.I1.i2.p1.4.m4.1.1" xref="S5.I1.i2.p1.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.4.m4.1b"><ci id="S5.I1.i2.p1.4.m4.1.1.cmml" xref="S5.I1.i2.p1.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.4.m4.1c">\epsilon</annotation></semantics></math><span id="S5.I1.i2.p1.4.4" class="ltx_text ltx_font_italic">.</span></p>
</div>
</li>
</ul>
</div>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">and there are mainly two types of DP (<em id="S5.SS2.SSS1.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.SS2.SSS1.p2.1.2" class="ltx_text"></span>, Global Differential Privacy and Local Differential Privacy)</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p3.1" class="ltx_p"><span id="S5.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Global Differential Privacy Methods.</span>
The global differential privacy scheme has been widely used in many federated learning (FL) methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Geyer et al. [<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> presented an FL framework based on global differential privacy by incorporating the Gaussian mechanism to protect client datasets. Specifically, the global model is obtained by randomly selecting different clients at each training round <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. The server then adds random noise to the aggregated global model, which prevents adversary clients from inferring the private information of other clients from the global model.</p>
</div>
<div id="S5.SS2.SSS1.p4" class="ltx_para">
<p id="S5.SS2.SSS1.p4.1" class="ltx_p">However, this framework is vulnerable to malicious servers since they have access to clean model updates from the participants. To address this issue, <cite class="ltx_cite ltx_citemacro_citet">Hao et al. [<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> proposed adding noise to the local gradients instead of the aggregated model. Following this paradigm, <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> proposed a differential privacy-based privacy-preserving language model at the user level, which achieved comparative performance while preserving privacy. However, one challenge of this method is the trade-off between privacy and utility, as differential privacy inevitably incurs high computation costs.</p>
</div>
<div id="S5.SS2.SSS1.p5" class="ltx_para">
<p id="S5.SS2.SSS1.p5.1" class="ltx_p">Overall, the global differential privacy method has an advantage in preserving privacy at a limited cost to model performance. This is because differential privacy is applied to the entire dataset with limited noise, guaranteeing a good statistical distribution.</p>
</div>
<div id="S5.SS2.SSS1.p6" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p6.1" class="ltx_p"><span id="S5.SS2.SSS1.p6.1.1" class="ltx_text ltx_font_bold">Local Differential Privacy Methods.</span>
Various federated learning (FL) approaches have employed the local differential privacy mechanism <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib126" title="" class="ltx_ref">126</a>, <a href="#bib.bib132" title="" class="ltx_ref">132</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib180" title="" class="ltx_ref">180</a>, <a href="#bib.bib194" title="" class="ltx_ref">194</a>, <a href="#bib.bib194" title="" class="ltx_ref">194</a>, <a href="#bib.bib203" title="" class="ltx_ref">203</a>, <a href="#bib.bib210" title="" class="ltx_ref">210</a>, <a href="#bib.bib216" title="" class="ltx_ref">216</a>, <a href="#bib.bib266" title="" class="ltx_ref">266</a>, <a href="#bib.bib267" title="" class="ltx_ref">267</a>]</cite>. The first attempt to combine local differential privacy scheme with deep neural networks was proposed by <cite class="ltx_cite ltx_citemacro_citet">Abadi et al. [<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. This privacy-preserving method involves two operations: clipping the norm of updating gradients to limit sensitive information in the data, and injecting noise into clipped gradients. However, this method was not applied to FL systems.</p>
</div>
<div id="S5.SS2.SSS1.p7" class="ltx_para">
<p id="S5.SS2.SSS1.p7.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib267" title="" class="ltx_ref">267</a>]</cite> investigated local differential privacy and evaluated both efficiency and privacy loss in the setting of FL, ignoring the impact of local differential privacy on model performance. <cite class="ltx_cite ltx_citemacro_citet">Bhowmick et al. [<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> designed a local differential privacy-based method that is free from reconstruction attacks. This approach employs local differential privacy to protect the privacy of samples on the client side and to ensure the privacy of the global model on the server side. In mobile edge computing, <cite class="ltx_cite ltx_citemacro_citet">Lu et al. [<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> proposed asynchronous FL, which adopts local differential privacy for local model updates. In the Internet-of-Things, <cite class="ltx_cite ltx_citemacro_citet">Cao et al. [<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> designed an FL framework with local differential privacy as its privacy utility. <cite class="ltx_cite ltx_citemacro_citet">Truex et al. [<a href="#bib.bib203" title="" class="ltx_ref">203</a>]</cite> scaled the local differential privacy approach to large-scale network training. In the field of natural language processing, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. [<a href="#bib.bib210" title="" class="ltx_ref">210</a>]</cite> used a local differential privacy FL framework for industrial-level text mining tasks and showed that it can guarantee data privacy while maintaining model accuracy.</p>
</div>
<div id="S5.SS2.SSS1.p8" class="ltx_para">
<p id="S5.SS2.SSS1.p8.1" class="ltx_p">In summary, due to the nature of local differential privacy methods, they offer a stronger privacy guarantee compared to global differential privacy-based FL methods.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Perturbation Methods</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">They are an alternative approach to provide defenses against privacy attacks that are not based on DP. Its main aim is to introduce noise to the most vulnerable components of
the federated learning, such as shared model parameters or the local dataset of each client, to reduce the amount of information an attacker can extract. There are mainly two types of perturbation methods (<em id="S5.SS2.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.SS2.SSS2.p1.1.2" class="ltx_text"></span>, additive based Methods and multiplicative based Methods)</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p"><span id="S5.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Additive Perturbation Methods.</span>
Additive perturbation-based FL methods are a popular class of privacy-preserving techniques in FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib201" title="" class="ltx_ref">201</a>, <a href="#bib.bib214" title="" class="ltx_ref">214</a>, <a href="#bib.bib228" title="" class="ltx_ref">228</a>]</cite>. These methods aim to incorporate random noise into the weight updates or gradient updates to prevent private information leakage during training. While some methods add noise to the model parameters <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib201" title="" class="ltx_ref">201</a>, <a href="#bib.bib228" title="" class="ltx_ref">228</a>]</cite>, others add noise to the gradient updates <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib201" title="" class="ltx_ref">201</a>, <a href="#bib.bib228" title="" class="ltx_ref">228</a>]</cite>.</p>
</div>
<div id="S5.SS2.SSS2.p3" class="ltx_para">
<p id="S5.SS2.SSS2.p3.1" class="ltx_p">One challenge with these methods is to balance the privacy guarantee with the model’s accuracy. To address this challenge, <cite class="ltx_cite ltx_citemacro_citet">Chamikara et al. [<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> propose a lossless data perturbation method that maintains model accuracy while providing a strong privacy guarantee. In this method, random noise is added to the data, rather than the model or gradients.</p>
</div>
<div id="S5.SS2.SSS2.p4" class="ltx_para">
<p id="S5.SS2.SSS2.p4.1" class="ltx_p">Other studies, such as <cite class="ltx_cite ltx_citemacro_citet">Hu et al. [<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Liu et al. [<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite>, focus on designing personalized FL models that add noise to intermediate updates or data attributes to ensure privacy. However, one limitation of additive perturbation methods is that they may not be a lossless solution and can affect the model’s performance. Additionally, these methods are vulnerable to noise reduction attacks, which can compromise the privacy of the data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>.</p>
</div>
<div id="S5.SS2.SSS2.p5" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p5.1" class="ltx_p"><span id="S5.SS2.SSS2.p5.1.1" class="ltx_text ltx_font_bold">Multiplicative Perturbation Methods.</span>
Multiplicative perturbation is an alternative method to adding random noise to data in perturbation-based machine learning. This technique transforms the original data into some space <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib246" title="" class="ltx_ref">246</a>]</cite>, and has been adapted for use in the context of the Internet of Things (IoT) in federated learning (FL) systems. Several studies have explored the use of multiplicative perturbation to preserve data privacy in FL, including <cite class="ltx_cite ltx_citemacro_citet">Chamikara et al. [<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Jiang et al. [<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>.</p>
</div>
<div id="S5.SS2.SSS2.p6" class="ltx_para">
<p id="S5.SS2.SSS2.p6.1" class="ltx_p">In particular, <cite class="ltx_cite ltx_citemacro_citet">Jiang et al. [<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> present an FL method for IoT objects that employs independent Gaussian random projection to perturb the data of each object, while <cite class="ltx_cite ltx_citemacro_citet">Chamikara et al. [<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> propose a multiplicative perturbation mechanism in fog devices. However, it should be noted that the latter method may be vulnerable to insider attackers, i.e. honest but curious servers.</p>
</div>
<div id="S5.SS2.SSS2.p7" class="ltx_para">
<p id="S5.SS2.SSS2.p7.1" class="ltx_p">Other studies have used multiplicative perturbations to obfuscate the stochastic gradient update and protect the gradients from curious attackers. For example, <cite class="ltx_cite ltx_citemacro_citet">Gade and Vaidya [<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> explore the use of this method to protect the gradients in FL systems. Additionally, <cite class="ltx_cite ltx_citemacro_citet">Chang et al. [<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. [<a href="#bib.bib246" title="" class="ltx_ref">246</a>]</cite> propose a multiplicative perturbation method for weight update-based FL frameworks, which is applied to local weights with the aim of preventing gradient leakage to servers.</p>
</div>
<div id="S5.SS2.SSS2.p8" class="ltx_para">
<p id="S5.SS2.SSS2.p8.1" class="ltx_p">Overall, perturbation-based FL methods that use multiplicative perturbation offer stronger privacy guarantees compared to those using additive perturbation, as it is more difficult to reconstruct the original data in this case.</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3 </span>Anonymization-based Method</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">While perturbation-based methods are often considered to be strong privacy preservation techniques, some works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> argue that they can still degrade data utility. As a result, anonymization-based methods have been presented to address this concern <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib188" title="" class="ltx_ref">188</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib222" title="" class="ltx_ref">222</a>, <a href="#bib.bib262" title="" class="ltx_ref">262</a>]</cite>.</p>
</div>
<div id="S5.SS2.SSS3.p2" class="ltx_para">
<p id="S5.SS2.SSS3.p2.1" class="ltx_p">For instance, <cite class="ltx_cite ltx_citemacro_citet">Song et al. [<a href="#bib.bib188" title="" class="ltx_ref">188</a>]</cite> adopt a GAN-based FL framework with anonymization schemes to protect against user-level privacy attacks.</p>
</div>
<div id="S5.SS2.SSS3.p3" class="ltx_para">
<p id="S5.SS2.SSS3.p3.1" class="ltx_p">Similarly, <cite class="ltx_cite ltx_citemacro_citet">Choudhury et al. [<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> propose an anonymization method for FL that aims to improve both data utility and model performance. This approach involves a global anonymization mapping process for predicting the deployed FL model. Their evaluation shows that this method provides stronger privacy preservation and model performance compared to DP-based FL methods.</p>
</div>
<div id="S5.SS2.SSS3.p4" class="ltx_para">
<p id="S5.SS2.SSS3.p4.1" class="ltx_p">In summary, anonymization-based methods provide strong privacy preservation without sacrificing data utility, and can outperform DP-based methods in terms of FL performance. Therefore, they offer a promising alternative to perturbation-based methods for privacy-preserving FL.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Challenges and Future Directions</span>
</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span id="S6.SS1.1.1" class="ltx_text ltx_font_italic">Secure of Federated Learning</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Although SFL is currently receiving a lot of attention and making impressive progress in both academia and industry, there are still many challenges that need to be addressed. In this section, we summarize the main challenges currently faced by the SFL algorithm. Based on these challenges, some research directions that we consider valuable are proposed.</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">Designing more adaptable PSFT algorithms. The current PSFT algorithm is usually customized for ”FedAvg”. In order to accommodate more complex data distributions in FL, more aggregation algorithms have been developed, such as ”FedPox” <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>, ”SCAFFOLD” <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>. How to customize the PSFT algorithm for these new aggregation algorithms is worthy of future research.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">Design of SFL algorithms for adaptive protection. The objects protected by existing SFL algorithms are usually deterministic. Specifically, the PSFT algorithm only protects the security of local model parameters, but exposes the complete global parameters and final model results. The FSFT and SFI algorithms protect the complete data and model security but greatly reduce the overall efficiency of the algorithm. However, the data and model parameters that need to be protected are often different at different stages or in different application scenarios. It makes sense to design an efficient SFL algorithm that can protect the data and models in the FL system accurately according to the requirements.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">How to better integrate secure computing techniques into SFL systems? The current SFL algorithm is usually designed to apply safe computation directly. Only the feature of using the same training data for multiple iterations in the machine learning training process is exploited in <cite class="ltx_cite ltx_citemacro_citet">Kelkar et al. [<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite> to improve the efficiency of secure multiplication. How to combine more features of machine learning algorithms in the training and prediction process to optimize the efficiency of SFL algorithms is a direction worth investigating in the future.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p">How to perform better engineering optimization of SFL algorithms? The reason for the use of secure computing techniques makes it difficult for the SFL algorithm to be directly compatible with the current mainstream machine learning frameworks. This leads to the fact that existing engineering optimization methods for machine learning cannot be applied to the SFL algorithm. Only a relatively small amount of work has considered engineering optimization of SFL algorithms, such as using GPUs to accelerate FSFT training. How to make more use of engineering optimization to improve the efficiency of SFL algorithms deserves to be investigated in the future.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span><span id="S6.SS2.1.1" class="ltx_text ltx_font_italic">Robustness of Federated Learning</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Robust federated learning cares about the trustworthiness of model training performance. By reviewing the robust techniques in robust federated learning, we conclude the challenges and the feasible future directions as follows:</p>
<ul id="S6.I2" class="ltx_itemize">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p">Non-IID Data issues commonly exist in real-world federated learning scenarios, which makes the local gradients geometrically diverse. Consequently, the geometric-based robust distributed learning approaches fail to maintain the robustness of federated learning. Distinguishing the gradients from Byzantine clients or Non-IID clients would be an open problem for future studies on robust aggregation techniques.</p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p">From the perspective of defense against targeted attacks, the researchers observed that the norm of the poisoned gradients is usually large. Hence, the commonly used approaches are conducting gradient-clipping or gradient-noising. The possibly model training performance degeneration is unavoidable due to the gradient-clipping/noising on benign gradients. Therefore, another open problem in robust federated learning is to keep the model training performance while defending against potential attacks.</p>
</div>
</li>
<li id="S6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i3.p1" class="ltx_para">
<p id="S6.I2.i3.p1.1" class="ltx_p">In real-world applications, the failure, and attack modes are various. Besides, the threat modes are unknown to the server and can be different over time, which further motivates the study of general robust federated learning approaches.</p>
</div>
</li>
<li id="S6.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i4.p1" class="ltx_para">
<p id="S6.I2.i4.p1.1" class="ltx_p">Despite a few FL benchmarks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib199" title="" class="ltx_ref">199</a>]</cite> and frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib227" title="" class="ltx_ref">227</a>, <a href="#bib.bib243" title="" class="ltx_ref">243</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> having been proposed, we lack a standard benchmark to verify the robust ability of proposed FL approaches, which is future work for the FL community.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span><span id="S6.SS3.1.1" class="ltx_text ltx_font_italic">Privacy of Trustworthy Federated Learning</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Despite the tremendous growth of privacy-preserving FL in recent years, this research area still poses significant challenges and offers opportunities for developing existing frameworks and creating new methods to enhance both data privacy and utility. Some open research problems and directions are highlighted below:</p>
<ul id="S6.I3" class="ltx_itemize">
<li id="S6.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i1.p1" class="ltx_para">
<p id="S6.I3.i1.p1.1" class="ltx_p">Privacy-preserving mechanisms in FL have a trade-off between effectiveness and efficiency. Therefore, it is crucial to comprehend usage scenarios under different privacy requirements and study how to optimize the deployment of defense mechanisms.</p>
</div>
</li>
<li id="S6.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i2.p1" class="ltx_para">
<p id="S6.I3.i2.p1.1" class="ltx_p">Data memorization is a major challenge that requires serious attention since neural network-based federated learning may overfit and memorize sensitive information. Anonymizing the data and model can be a potential solution to this issue. Hence, we believe that developing an effective mechanism for anonymizing training datasets is an essential way to ensure privacy preservation in FL.</p>
</div>
</li>
<li id="S6.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I3.i3.p1" class="ltx_para">
<p id="S6.I3.i3.p1.1" class="ltx_p">Developing hybrid approaches for privacy methods in FL by combining various security techniques such as encryption is advantageous. This is because different defense strategies offer significant advantages in different areas, and it is appropriate to leverage their benefits to advance existing frameworks.</p>
</div>
</li>
</ul>
<p id="S6.SS3.p1.2" class="ltx_p">Overall, TFL is a thriving research field with numerous approaches and applications. This survey aims to summarize existing advances and trends in TFL, with the goal of facilitating and advancing future TFL research and implementation. From a technical perspective, this survey provides a roadmap for building TFL systems. It begins by defining TFL and presents a general picture of the vulnerabilities in the available literature associated with trustworthiness in FL. The survey then reviews recent improvements in TFL regarding security, robustness, and privacy. It explains the threats, summarizes the known defense mechanisms for establishing trustworthy FL in each aspect, and suggests potential future research routes for these elements. We conclude that the study of TFL is a must-have in trustworthy AI due to its importance. There are still several challenges to be addressed and directions to be explored to identify additional threats or vulnerabilities of TFL and appropriate mechanisms to make it a resilient and robust learning paradigm against those threats.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. [2016]</span>
<span class="ltx_bibblock">
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 ACM SIGSAC conference on computer
and communications security</em>, pages 308–318, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abney [2002]</span>
<span class="ltx_bibblock">
S. Abney.

</span>
<span class="ltx_bibblock">Bootstrapping.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th annual meeting of the Association
for Computational Linguistics</em>, pages 360–367, 2002.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acar et al. [2021]</span>
<span class="ltx_bibblock">
D. A. E. Acar, Y. Zhao, R. M. Navarro, M. Mattina, P. N. Whatmough, and
V. Saligrama.

</span>
<span class="ltx_bibblock">Federated learning based on dynamic regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">9th International Conference on Learning Representations,
ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=B7v4QMR6Z9w" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=B7v4QMR6Z9w</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al. [2018]</span>
<span class="ltx_bibblock">
N. Agarwal, A. T. Suresh, F. X. X. Yu, S. Kumar, and B. McMahan.

</span>
<span class="ltx_bibblock">cpsgd: Communication-efficient and differentially-private distributed
sgd.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 31, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal et al. [2019]</span>
<span class="ltx_bibblock">
N. Agrawal, A. Shahin Shamsabadi, M. J. Kusner, and A. Gascón.

</span>
<span class="ltx_bibblock">Quotient: two-party secure neural network training and prediction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 ACM SIGSAC Conference on Computer
and Communications Security</em>, pages 1231–1247, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alfeld et al. [2016]</span>
<span class="ltx_bibblock">
S. Alfeld, X. Zhu, and P. Barford.

</span>
<span class="ltx_bibblock">Data poisoning attacks against autoregressive models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 30, 2016.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andreina et al. [2021]</span>
<span class="ltx_bibblock">
S. Andreina, G. A. Marson, H. Möllering, and G. Karame.

</span>
<span class="ltx_bibblock">Baffle: Backdoor detection via feedback-based federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2021 IEEE 41st International Conference on Distributed
Computing Systems (ICDCS)</em>, pages 852–863. IEEE, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aono et al. [2017]</span>
<span class="ltx_bibblock">
Y. Aono, T. Hayashi, L. Wang, S. Moriai, et al.

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning via additively homomorphic
encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>,
13(5):1333–1345, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ateniese et al. [2013]</span>
<span class="ltx_bibblock">
G. Ateniese, G. Felici, L. V. Mancini, A. Spognardi, A. Villani, and D. Vitali.

</span>
<span class="ltx_bibblock">Hacking smart machines with smarter ones: How to extract meaningful
data from machine learning classifiers.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1306.4447</em>, 2013.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan et al. [2020]</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov.

</span>
<span class="ltx_bibblock">How to backdoor federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and
Statistics</em>, pages 2938–2948. PMLR, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beguier and Tramel [2020]</span>
<span class="ltx_bibblock">
C. Beguier and E. W. Tramel.

</span>
<span class="ltx_bibblock">Safer: Sparse secure aggregation for federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.14861</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bell et al. [2020]</span>
<span class="ltx_bibblock">
J. H. Bell, K. A. Bonawitz, A. Gascón, T. Lepoint, and M. Raykova.

</span>
<span class="ltx_bibblock">Secure single-server aggregation with (poly) logarithmic overhead.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 ACM SIGSAC Conference on Computer
and Communications Security</em>, pages 1253–1269, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagoji et al. [2019]</span>
<span class="ltx_bibblock">
A. N. Bhagoji, S. Chakraborty, P. Mittal, and S. Calo.

</span>
<span class="ltx_bibblock">Analyzing federated learning through an adversarial lens.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
634–643. PMLR, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhowmick et al. [2018]</span>
<span class="ltx_bibblock">
A. Bhowmick, J. Duchi, J. Freudiger, G. Kapoor, and R. Rogers.

</span>
<span class="ltx_bibblock">Protection against reconstruction and its applications in private
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.00984</em>, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biggio et al. [2012]</span>
<span class="ltx_bibblock">
B. Biggio, B. Nelson, and P. Laskov.

</span>
<span class="ltx_bibblock">Poisoning attacks against support vector machines.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1206.6389</em>, 2012.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bistritz et al. [2020]</span>
<span class="ltx_bibblock">
I. Bistritz, A. Mann, and N. Bambos.

</span>
<span class="ltx_bibblock">Distributed distillation for on-device learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:22593–22604, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blakley [1979]</span>
<span class="ltx_bibblock">
G. R. Blakley.

</span>
<span class="ltx_bibblock">Safeguarding cryptographic keys.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Managing Requirements Knowledge, International Workshop on</em>,
pages 313–313, 1979.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanchard et al. [2017]</span>
<span class="ltx_bibblock">
P. Blanchard, E. M. El Mhamdi, R. Guerraoui, and J. Stainer.

</span>
<span class="ltx_bibblock">Machine learning with adversaries: Byzantine tolerant gradient
descent.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 30, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2017]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
D. Ramage, A. Segal, and K. Seth.

</span>
<span class="ltx_bibblock">Practical secure aggregation for privacy-preserving machine learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security</em>, pages 1175–1191, 2017.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. [2019]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. Kiddon, J. Konečnỳ, S. Mazzocchi, B. McMahan, et al.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>, 1:374–388, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brakerski [2012]</span>
<span class="ltx_bibblock">
Z. Brakerski.

</span>
<span class="ltx_bibblock">Fully homomorphic encryption without modulus switching from classical
gapsvp.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Annual Cryptology Conference</em>, pages 868–886. Springer,
2012.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brakerski et al. [2014]</span>
<span class="ltx_bibblock">
Z. Brakerski, C. Gentry, and V. Vaikuntanathan.

</span>
<span class="ltx_bibblock">(leveled) fully homomorphic encryption without bootstrapping.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Computation Theory (TOCT)</em>, 6(3):1–36, 2014.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briggs et al. [2020]</span>
<span class="ltx_bibblock">
C. Briggs, Z. Fan, and P. Andras.

</span>
<span class="ltx_bibblock">Federated learning with hierarchical clustering of local updates to
improve training on non-iid data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2020 International Joint Conference on Neural Networks
(IJCNN)</em>, pages 1–9. IEEE, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brunet et al. [2019]</span>
<span class="ltx_bibblock">
M.-E. Brunet, C. Alkalay-Houlihan, A. Anderson, and R. Zemel.

</span>
<span class="ltx_bibblock">Understanding the origins of bias in word embeddings.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pages
803–811. PMLR, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Byali et al. [2020]</span>
<span class="ltx_bibblock">
M. Byali, H. Chaudhari, A. Patra, and A. Suresh.

</span>
<span class="ltx_bibblock">Flash: Fast and robust framework for privacy-preserving machine
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings on Privacy Enhancing Technologies</em>, 2:459–480, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. [2018]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan,
V. Smith, and A. Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al. [2020]</span>
<span class="ltx_bibblock">
H. Cao, S. Liu, R. Zhao, and X. Xiong.

</span>
<span class="ltx_bibblock">Ifed: A novel federated learning framework for local differential
privacy in power internet of things.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Journal of Distributed Sensor Networks</em>,
16(5):1550147720919698, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al. [2021]</span>
<span class="ltx_bibblock">
X. Cao, M. Fang, J. Liu, and N. Z. Gong.

</span>
<span class="ltx_bibblock">Fltrust: Byzantine-robust federated learning via trust bootstrapping.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">ISOC Network and Distributed System Security Symposium
(NDSS)</em>, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chamani and Papadopoulos [2020]</span>
<span class="ltx_bibblock">
J. G. Chamani and D. Papadopoulos.

</span>
<span class="ltx_bibblock">Mitigating leakage in federated learning with trusted hardware.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.04948</em>, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chamikara et al. [2021]</span>
<span class="ltx_bibblock">
M. A. P. Chamikara, P. Bertok, I. Khalil, D. Liu, and S. Camtepe.

</span>
<span class="ltx_bibblock">Privacy preserving distributed machine learning with federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Computer Communications</em>, 171:112–125, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chandran et al. [2019]</span>
<span class="ltx_bibblock">
N. Chandran, D. Gupta, A. Rastogi, R. Sharma, and S. Tripathi.

</span>
<span class="ltx_bibblock">Ezpc: programmable and efficient secure two-party computation for
machine learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">2019 IEEE European Symposium on Security and Privacy
(EuroS&amp;P)</em>, pages 496–511. IEEE, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. [2019]</span>
<span class="ltx_bibblock">
H. Chang, V. Shejwalkar, R. Shokri, and A. Houmansadr.

</span>
<span class="ltx_bibblock">Cronus: Robust and heterogeneous collaborative learning with
black-box knowledge transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.11279</em>, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chase et al. [2021]</span>
<span class="ltx_bibblock">
M. Chase, E. Ghosh, and S. Mahloujifar.

</span>
<span class="ltx_bibblock">Property inference from poisoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.11073</em>, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhari et al. [2019a]</span>
<span class="ltx_bibblock">
H. Chaudhari, A. Choudhury, A. Patra, and A. Suresh.

</span>
<span class="ltx_bibblock">Astra: high throughput 3pc over rings with application to secure
prediction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 ACM SIGSAC Conference on Cloud
Computing Security Workshop</em>, pages 81–92, 2019a.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhari et al. [2019b]</span>
<span class="ltx_bibblock">
H. Chaudhari, R. Rachuri, and A. Suresh.

</span>
<span class="ltx_bibblock">Trident: Efficient 4pc framework for privacy preserving machine
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.02631</em>, 2019b.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2021a]</span>
<span class="ltx_bibblock">
C. Chen, J. Zhou, L. Wang, X. Wu, W. Fang, J. Tan, L. Wang, A. X. Liu, H. Wang,
and C. Hong.

</span>
<span class="ltx_bibblock">When homomorphic encryption marries secret sharing: Secure
large-scale sparse logistic regression and applications in risk control.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM SIGKDD Conference on Knowledge
Discovery &amp; Data Mining</em>, pages 2652–2662, 2021a.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2022a]</span>
<span class="ltx_bibblock">
T. Chen, H. Bao, S. Huang, L. Dong, B. Jiao, D. Jiang, H. Zhou, and J. Li.

</span>
<span class="ltx_bibblock">The-x: Privacy-preserving transformer inference with homomorphic
encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.00216</em>, 2022a.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2021b]</span>
<span class="ltx_bibblock">
W. Chen, G. Ma, T. Fan, Y. Kang, Q. Xu, and Q. Yang.

</span>
<span class="ltx_bibblock">Secureboost+: A high performance gradient boosting tree framework for
large scale vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.10927</em>, 2021b.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2017a]</span>
<span class="ltx_bibblock">
X. Chen, C. Liu, B. Li, K. Lu, and D. Song.

</span>
<span class="ltx_bibblock">Targeted backdoor attacks on deep learning systems using data
poisoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.05526</em>, 2017a.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2017b]</span>
<span class="ltx_bibblock">
Y. Chen, L. Su, and J. Xu.

</span>
<span class="ltx_bibblock">Distributed statistical machine learning in adversarial settings:
Byzantine gradient descent.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Measurement and Analysis of Computing
Systems</em>, 1(2):1–25, 2017b.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2020]</span>
<span class="ltx_bibblock">
Y. Chen, F. Luo, T. Li, T. Xiang, Z. Liu, and J. Li.

</span>
<span class="ltx_bibblock">A training-integrity privacy-preserving federated learning scheme
with trusted execution environment.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Information Sciences</em>, 522:69–79, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2022b]</span>
<span class="ltx_bibblock">
Y. Chen, H. Guo, Y. Zhang, C. Ma, R. Tang, J. Li, and I. King.

</span>
<span class="ltx_bibblock">Learning binarized graph representations with multi-faceted
quantization reinforcement for top-k recommendation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">SIGKDD</em>, 2022b.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2022c]</span>
<span class="ltx_bibblock">
Y. Chen, M. Yang, Y. Zhang, M. Zhao, Z. Meng, J. Hao, and I. King.

</span>
<span class="ltx_bibblock">Modeling scale-free graphs with hyperbolic geometry for
knowledge-aware recommendation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">WSDM</em>, pages 94–102, 2022c.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2022d]</span>
<span class="ltx_bibblock">
Y. Chen, Y. Yang, Y. Wang, J. Bai, X. Song, and I. King.

</span>
<span class="ltx_bibblock">Attentive knowledge-aware graph convolutional networks with
collaborative guidance for personalized recommendation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ICDE</em>, 2022d.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2023]</span>
<span class="ltx_bibblock">
Y. Chen, Y. Fang, Y. Zhang, and I. King.

</span>
<span class="ltx_bibblock">Bipartite graph convolutional hashing for effective and efficient
top-n search in hamming space.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">WWW</em>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. [2021a]</span>
<span class="ltx_bibblock">
K. Cheng, T. Fan, Y. Jin, Y. Liu, T. Chen, D. Papadopoulos, and Q. Yang.

</span>
<span class="ltx_bibblock">Secureboost: A lossless federated learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, 36(6):87–98,
2021a.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. [2021b]</span>
<span class="ltx_bibblock">
P.-C. Cheng, K. Eykholt, Z. Gu, H. Jamjoom, K. Jayaram, E. Valdez, and
A. Verma.

</span>
<span class="ltx_bibblock">Separation of powers in federated learning (poster paper).

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First Workshop on Systems Challenges in
Reliable and Secure Federated Learning</em>, pages 16–18, 2021b.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheon et al. [2017]</span>
<span class="ltx_bibblock">
J. H. Cheon, A. Kim, M. Kim, and Y. Song.

</span>
<span class="ltx_bibblock">Homomorphic encryption for arithmetic of approximate numbers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">International conference on the theory and application of
cryptology and information security</em>, pages 409–437. Springer, 2017.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheung et al. [2021]</span>
<span class="ltx_bibblock">
T.-H. Cheung, W. Dai, and S. Li.

</span>
<span class="ltx_bibblock">Fedsgc: Federated simple graph convolution for node classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">International Workshop on Federated and Transfer Learning
for Data Sparsity and Confidentiality in Conjuncation with IJCAI</em>, 2021.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chillotti et al. [2016]</span>
<span class="ltx_bibblock">
I. Chillotti, N. Gama, M. Georgieva, and M. Izabachene.

</span>
<span class="ltx_bibblock">Faster fully homomorphic encryption: Bootstrapping in less than 0.1
seconds.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">international conference on the theory and application of
cryptology and information security</em>, pages 3–33. Springer, 2016.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choudhury et al. [2019]</span>
<span class="ltx_bibblock">
O. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park, G. Hsu,
and A. Das.

</span>
<span class="ltx_bibblock">Differential privacy-enabled federated learning for sensitive health
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.02578</em>, 2019.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choudhury et al. [2020]</span>
<span class="ltx_bibblock">
O. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park, G. Hsu,
and A. Das.

</span>
<span class="ltx_bibblock">A syntactic approach for privacy-preserving federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">ECAI 2020</em>, pages 1762–1769. IOS Press, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dalskov et al. [2021]</span>
<span class="ltx_bibblock">
A. Dalskov, D. Escudero, and M. Keller.

</span>
<span class="ltx_bibblock">Fantastic four:<math id="bib.bib53.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib53.1.m1.1a"><mo stretchy="false" id="bib.bib53.1.m1.1.1" xref="bib.bib53.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib53.1.m1.1b"><ci id="bib.bib53.1.m1.1.1.cmml" xref="bib.bib53.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib53.1.m1.1c">\{</annotation></semantics></math>Honest-Majority<math id="bib.bib53.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib53.2.m2.1a"><mo stretchy="false" id="bib.bib53.2.m2.1.1" xref="bib.bib53.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib53.2.m2.1b"><ci id="bib.bib53.2.m2.1.1.cmml" xref="bib.bib53.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib53.2.m2.1c">\}</annotation></semantics></math><math id="bib.bib53.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib53.3.m3.1a"><mo stretchy="false" id="bib.bib53.3.m3.1.1" xref="bib.bib53.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib53.3.m3.1b"><ci id="bib.bib53.3.m3.1.1.cmml" xref="bib.bib53.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib53.3.m3.1c">\{</annotation></semantics></math>Four-Party<math id="bib.bib53.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib53.4.m4.1a"><mo stretchy="false" id="bib.bib53.4.m4.1.1" xref="bib.bib53.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib53.4.m4.1b"><ci id="bib.bib53.4.m4.1.1.cmml" xref="bib.bib53.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib53.4.m4.1c">\}</annotation></semantics></math> secure
computation with malicious security.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.5.1" class="ltx_emph ltx_font_italic">30th USENIX Security Symposium (USENIX Security 21)</em>, pages
2183–2200, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diffie and Hellman [2022]</span>
<span class="ltx_bibblock">
W. Diffie and M. E. Hellman.

</span>
<span class="ltx_bibblock">New directions in cryptography.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Democratizing Cryptography: The Work of Whitfield Diffie and
Martin Hellman</em>, pages 365–390. 2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. [2020]</span>
<span class="ltx_bibblock">
Y. Dong, X. Chen, L. Shen, and D. Wang.

</span>
<span class="ltx_bibblock">Eastfly: Efficient and secure ternary federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em>, 94:101824, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Douceur [2002]</span>
<span class="ltx_bibblock">
J. R. Douceur.

</span>
<span class="ltx_bibblock">The sybil attack.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">International workshop on peer-to-peer systems</em>, pages
251–260. Springer, 2002.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et al. [2021]</span>
<span class="ltx_bibblock">
M. Duan, D. Liu, X. Ji, Y. Wu, L. Liang, X. Chen, Y. Tan, and A. Ren.

</span>
<span class="ltx_bibblock">Flexible clustered federated learning for client-level data
distribution shift.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>, 2021.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey and Pentland [2020]</span>
<span class="ltx_bibblock">
A. Dubey and A. Pentland.

</span>
<span class="ltx_bibblock">Differentially-private federated linear bandits.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:6003–6014, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork and Naor [2010]</span>
<span class="ltx_bibblock">
C. Dwork and M. Naor.

</span>
<span class="ltx_bibblock">On the difficulties of disclosure prevention in statistical databases
or the case for differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Journal of Privacy and Confidentiality</em>, 2(1), 2010.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ElGamal [1985]</span>
<span class="ltx_bibblock">
T. ElGamal.

</span>
<span class="ltx_bibblock">A public key cryptosystem and a signature scheme based on discrete
logarithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on information theory</em>, 31(4):469–472, 1985.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan and Vercauteren [2012]</span>
<span class="ltx_bibblock">
J. Fan and F. Vercauteren.

</span>
<span class="ltx_bibblock">Somewhat practical fully homomorphic encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Cryptology ePrint Archive</em>, 2012.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. [2018]</span>
<span class="ltx_bibblock">
M. Fang, G. Yang, N. Z. Gong, and J. Liu.

</span>
<span class="ltx_bibblock">Poisoning attacks to graph-based recommender systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th annual computer security
applications conference</em>, pages 381–392, 2018.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. [2020]</span>
<span class="ltx_bibblock">
M. Fang, X. Cao, J. Jia, and N. Gong.

</span>
<span class="ltx_bibblock">Local model poisoning attacks to <math id="bib.bib63.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib63.1.m1.1a"><mo stretchy="false" id="bib.bib63.1.m1.1.1" xref="bib.bib63.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib63.1.m1.1b"><ci id="bib.bib63.1.m1.1.1.cmml" xref="bib.bib63.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib63.1.m1.1c">\{</annotation></semantics></math>Byzantine-Robust<math id="bib.bib63.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib63.2.m2.1a"><mo stretchy="false" id="bib.bib63.2.m2.1.1" xref="bib.bib63.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib63.2.m2.1b"><ci id="bib.bib63.2.m2.1.1.cmml" xref="bib.bib63.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib63.2.m2.1c">\}</annotation></semantics></math> federated
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">29th USENIX Security Symposium (USENIX Security 20)</em>, pages
1605–1622, 2020.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. [2020]</span>
<span class="ltx_bibblock">
Y. Feng, X. Yang, W. Fang, S.-T. Xia, and X. Tang.

</span>
<span class="ltx_bibblock">Practical and bilateral privacy-preserving federated learning.

</span>
<span class="ltx_bibblock">2020.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. [2019]</span>
<span class="ltx_bibblock">
Z. Feng, H. Xiong, C. Song, S. Yang, B. Zhao, L. Wang, Z. Chen, S. Yang,
L. Liu, and J. Huan.

</span>
<span class="ltx_bibblock">Securegbm: Secure multi-party gradient boosting.

</span>
<span class="ltx_bibblock">In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International Conference on Big Data (Big Data)</em>,
pages 1312–1321. IEEE, 2019.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fenner and Pyzer-Knapp [2020]</span>
<span class="ltx_bibblock">
P. Fenner and E. Pyzer-Knapp.

</span>
<span class="ltx_bibblock">Privacy-preserving gaussian process regression–a modular approach to
the application of homomorphic encryption.

</span>
<span class="ltx_bibblock">In <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 34, pages 3866–3873, 2020.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fredrikson et al. [2014]</span>
<span class="ltx_bibblock">
M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart.

</span>
<span class="ltx_bibblock">Privacy in pharmacogenetics: An <math id="bib.bib67.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib67.1.m1.1a"><mo stretchy="false" id="bib.bib67.1.m1.1.1" xref="bib.bib67.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib67.1.m1.1b"><ci id="bib.bib67.1.m1.1.1.cmml" xref="bib.bib67.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib67.1.m1.1c">\{</annotation></semantics></math>End-to-End<math id="bib.bib67.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib67.2.m2.1a"><mo stretchy="false" id="bib.bib67.2.m2.1.1" xref="bib.bib67.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib67.2.m2.1b"><ci id="bib.bib67.2.m2.1.1.cmml" xref="bib.bib67.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib67.2.m2.1c">\}</annotation></semantics></math> case study of
personalized warfarin dosing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">23rd USENIX Security Symposium (USENIX Security 14)</em>, pages
17–32, 2014.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fredrikson et al. [2015]</span>
<span class="ltx_bibblock">
M. Fredrikson, S. Jha, and T. Ristenpart.

</span>
<span class="ltx_bibblock">Model inversion attacks that exploit confidence information and basic
countermeasures.

</span>
<span class="ltx_bibblock">In <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM SIGSAC conference on computer
and communications security</em>, pages 1322–1333, 2015.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. [2022]</span>
<span class="ltx_bibblock">
F. Fu, H. Xue, Y. Cheng, Y. Tao, and B. Cui.

</span>
<span class="ltx_bibblock">Blindfl: Vertical federated machine learning without peeking into
your data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 International Conference on
Management of Data</em>, pages 1316–1330, 2022.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung et al. [2018]</span>
<span class="ltx_bibblock">
C. Fung, J. Koerner, S. Grant, and I. Beschastnikh.

</span>
<span class="ltx_bibblock">Dancing in the dark: Private multi-party machine learning in an
untrusted setting.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.09712</em>, 2018.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung et al. [2020]</span>
<span class="ltx_bibblock">
C. Fung, C. J. Yoon, and I. Beschastnikh.

</span>
<span class="ltx_bibblock">The limitations of federated learning in sybil settings.

</span>
<span class="ltx_bibblock">In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">23rd International Symposium on Research in Attacks,
Intrusions and Defenses (RAID 2020)</em>, pages 301–316, 2020.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gade and Vaidya [2018]</span>
<span class="ltx_bibblock">
S. Gade and N. H. Vaidya.

</span>
<span class="ltx_bibblock">Privacy-preserving distributed learning via obfuscated stochastic
gradients.

</span>
<span class="ltx_bibblock">In <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">2018 IEEE Conference on Decision and Control (CDC)</em>, pages
184–191. IEEE, 2018.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gascón et al. [2016]</span>
<span class="ltx_bibblock">
A. Gascón, P. Schoppmann, B. Balle, M. Raykova, J. Doerner, S. Zahur, and
D. Evans.

</span>
<span class="ltx_bibblock">Secure linear regression on vertically partitioned datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">IACR Cryptol. ePrint Arch.</em>, 2016:892, 2016.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiping et al. [2020]</span>
<span class="ltx_bibblock">
J. Geiping, H. Bauermeister, H. Dröge, and M. Moeller.

</span>
<span class="ltx_bibblock">Inverting gradients-how easy is it to break privacy in federated
learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:16937–16947, 2020.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gentry [2009]</span>
<span class="ltx_bibblock">
C. Gentry.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">A fully homomorphic encryption scheme</em>.

</span>
<span class="ltx_bibblock">Stanford university, 2009.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gentry et al. [2013]</span>
<span class="ltx_bibblock">
C. Gentry, A. Sahai, and B. Waters.

</span>
<span class="ltx_bibblock">Homomorphic encryption from learning with errors:
Conceptually-simpler, asymptotically-faster, attribute-based.

</span>
<span class="ltx_bibblock">In <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Annual Cryptology Conference</em>, pages 75–92. Springer, 2013.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geyer et al. [2017]</span>
<span class="ltx_bibblock">
R. C. Geyer, T. Klein, and M. Nabi.

</span>
<span class="ltx_bibblock">Differentially private federated learning: A client level
perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.07557</em>, 2017.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh et al. [2020]</span>
<span class="ltx_bibblock">
A. Ghosh, J. Chung, D. Yin, and K. Ramchandran.

</span>
<span class="ltx_bibblock">An efficient framework for clustered federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:19586–19597, 2020.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gilad-Bachrach et al. [2016]</span>
<span class="ltx_bibblock">
R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter, M. Naehrig, and J. Wernsing.

</span>
<span class="ltx_bibblock">Cryptonets: Applying neural networks to encrypted data with high
throughput and accuracy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pages
201–210. PMLR, 2016.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goldreich et al. [2019]</span>
<span class="ltx_bibblock">
O. Goldreich, S. Micali, and A. Wigderson.

</span>
<span class="ltx_bibblock">How to play any mental game, or a completeness theorem for protocols
with honest majority.

</span>
<span class="ltx_bibblock">In <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Providing Sound Foundations for Cryptography: On the Work of
Shafi Goldwasser and Silvio Micali</em>, pages 307–328. 2019.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. [2017]</span>
<span class="ltx_bibblock">
T. Gu, B. Dolan-Gavitt, and S. Garg.

</span>
<span class="ltx_bibblock">Badnets: Identifying vulnerabilities in the machine learning model
supply chain.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.06733</em>, 2017.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guerraoui et al. [2018]</span>
<span class="ltx_bibblock">
R. Guerraoui, S. Rouault, et al.

</span>
<span class="ltx_bibblock">The hidden vulnerability of distributed learning in byzantium.

</span>
<span class="ltx_bibblock">In <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
3521–3530. PMLR, 2018.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. [2020]</span>
<span class="ltx_bibblock">
X. Guo, Z. Liu, J. Li, J. Gao, B. Hou, C. Dong, and T. Baker.

</span>
<span class="ltx_bibblock">V eri fl: Communication-efficient and fast verifiable aggregation for
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>,
16:1736–1751, 2020.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han and Zhang [2020]</span>
<span class="ltx_bibblock">
Y. Han and X. Zhang.

</span>
<span class="ltx_bibblock">Robust federated learning via collaborative machine teaching.

</span>
<span class="ltx_bibblock">In <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 34, pages 4075–4082, 2020.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al. [2019a]</span>
<span class="ltx_bibblock">
M. Hao, H. Li, X. Luo, G. Xu, H. Yang, and S. Liu.

</span>
<span class="ltx_bibblock">Efficient and privacy-enhanced federated learning for industrial
artificial intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, 16(10):6532–6542, 2019a.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al. [2019b]</span>
<span class="ltx_bibblock">
M. Hao, H. Li, G. Xu, S. Liu, and H. Yang.

</span>
<span class="ltx_bibblock">Towards efficient and privacy-preserving federated deep learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">ICC 2019-2019 IEEE international conference on
communications (ICC)</em>, pages 1–6. IEEE, 2019b.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardy et al. [2017]</span>
<span class="ltx_bibblock">
S. Hardy, W. Henecka, H. Ivey-Law, R. Nock, G. Patrini, G. Smith, and
B. Thorne.

</span>
<span class="ltx_bibblock">Private federated learning on vertically partitioned data via entity
resolution and additively homomorphic encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.10677</em>, 2017.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2020a]</span>
<span class="ltx_bibblock">
C. He, M. Annavaram, and S. Avestimehr.

</span>
<span class="ltx_bibblock">Group knowledge transfer: Federated learning of large cnns at the
edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:14068–14080, 2020a.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2020b]</span>
<span class="ltx_bibblock">
C. He, S. Li, J. So, X. Zeng, M. Zhang, H. Wang, X. Wang, P. Vepakomma,
A. Singh, H. Qiu, et al.

</span>
<span class="ltx_bibblock">Fedml: A research library and benchmark for federated machine
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>, 2020b.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2021]</span>
<span class="ltx_bibblock">
D. He, R. Du, S. Zhu, M. Zhang, K. Liang, and S. Chan.

</span>
<span class="ltx_bibblock">Secure logistic regression for vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Computing</em>, 26(2):61–68,
2021.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hesamifard et al. [2017]</span>
<span class="ltx_bibblock">
E. Hesamifard, H. Takabi, and M. Ghasemi.

</span>
<span class="ltx_bibblock">Cryptodl: Deep neural networks over encrypted data.

</span>
<span class="ltx_bibblock"><em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.05189</em>, 2017.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hitaj et al. [2017]</span>
<span class="ltx_bibblock">
B. Hitaj, G. Ateniese, and F. Perez-Cruz.

</span>
<span class="ltx_bibblock">Deep models under the gan: information leakage from collaborative
deep learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC conference on computer
and communications security</em>, pages 603–618, 2017.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Househ et al. [2021]</span>
<span class="ltx_bibblock">
M. Househ, E. Borycki, and A. Kushniruk.

</span>
<span class="ltx_bibblock"><em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Multiple Perspectives on Artificial Intelligence in
Healthcare</em>.

</span>
<span class="ltx_bibblock">Springer, 2021.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et al. [2020]</span>
<span class="ltx_bibblock">
K. Hsieh, A. Phanishayee, O. Mutlu, and P. Gibbons.

</span>
<span class="ltx_bibblock">The non-iid data quagmire of decentralized machine learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
4387–4398. PMLR, 2020.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. [2020]</span>
<span class="ltx_bibblock">
R. Hu, Y. Guo, H. Li, Q. Pei, and Y. Gong.

</span>
<span class="ltx_bibblock">Personalized federated learning with differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 7(10):9530–9539, 2020.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. [2021]</span>
<span class="ltx_bibblock">
Y. Huang, L. Chu, Z. Zhou, L. Wang, J. Liu, J. Pei, and Y. Zhang.

</span>
<span class="ltx_bibblock">Personalized cross-silo federated learning on non-iid data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, pages 7865–7873, 2021.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. [2022]</span>
<span class="ltx_bibblock">
Z. Huang, W.-j. Lu, C. Hong, and J. Ding.

</span>
<span class="ltx_bibblock">Cheetah: Lean and fast secure two-party deep neural network
inference.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">IACR Cryptol. ePrint Arch.</em>, 2022:207, 2022.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong et al. [2018]</span>
<span class="ltx_bibblock">
E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, and S.-L. Kim.

</span>
<span class="ltx_bibblock">Communication-efficient on-device machine learning: Federated
distillation and augmentation under non-iid private data.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.11479</em>, 2018.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. [2019]</span>
<span class="ltx_bibblock">
L. Jiang, R. Tan, X. Lou, and G. Lin.

</span>
<span class="ltx_bibblock">On lightweight privacy-preserving collaborative learning for
internet-of-things objects.

</span>
<span class="ltx_bibblock">In <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">Proceedings of the international conference on internet of
things design and implementation</em>, pages 70–81, 2019.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Juvekar et al. [2018]</span>
<span class="ltx_bibblock">
C. Juvekar, V. Vaikuntanathan, and A. Chandrakasan.

</span>
<span class="ltx_bibblock"><math id="bib.bib100.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib100.1.m1.1a"><mo stretchy="false" id="bib.bib100.1.m1.1.1" xref="bib.bib100.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib100.1.m1.1b"><ci id="bib.bib100.1.m1.1.1.cmml" xref="bib.bib100.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib100.1.m1.1c">\{</annotation></semantics></math>GAZELLE<math id="bib.bib100.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib100.2.m2.1a"><mo stretchy="false" id="bib.bib100.2.m2.1.1" xref="bib.bib100.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib100.2.m2.1b"><ci id="bib.bib100.2.m2.1.1.cmml" xref="bib.bib100.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib100.2.m2.1c">\}</annotation></semantics></math>: A low latency framework for secure neural network
inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">27th USENIX Security Symposium (USENIX Security 18)</em>, pages
1651–1669, 2018.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al. [2021]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Machine Learning</em>,
14(1–2):1–210, 2021.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al. [2022]</span>
<span class="ltx_bibblock">
Y. Kang, Y. He, J. Luo, T. Fan, Y. Liu, and Q. Yang.

</span>
<span class="ltx_bibblock">Privacy-preserving federated adversarial domain adaptation over
feature groups for interpretability.

</span>
<span class="ltx_bibblock"><em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>, 2022.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kargupta et al. [2003]</span>
<span class="ltx_bibblock">
H. Kargupta, S. Datta, Q. Wang, and K. Sivakumar.

</span>
<span class="ltx_bibblock">On the privacy preserving properties of random data perturbation
techniques.

</span>
<span class="ltx_bibblock">In <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Third IEEE international conference on data mining</em>, pages
99–106. IEEE, 2003.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy et al. [2020]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kelkar et al. [2022]</span>
<span class="ltx_bibblock">
M. Kelkar, P. H. Le, M. Raykova, and K. Seth.

</span>
<span class="ltx_bibblock">Secure poisson regression.

</span>
<span class="ltx_bibblock">In <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">31st USENIX Security Symposium (USENIX Security 22)</em>, pages
791–808, 2022.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Knott et al. [2021]</span>
<span class="ltx_bibblock">
B. Knott, S. Venkataraman, A. Hannun, S. Sengupta, M. Ibrahim, and L. van der
Maaten.

</span>
<span class="ltx_bibblock">CrypTen: Secure multi-party computation meets machine learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">Proc. NeurIPS</em>, 2021.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koti et al. [2021a]</span>
<span class="ltx_bibblock">
N. Koti, M. Pancholi, A. Patra, and A. Suresh.

</span>
<span class="ltx_bibblock"><math id="bib.bib107.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib107.1.m1.1a"><mo stretchy="false" id="bib.bib107.1.m1.1.1" xref="bib.bib107.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib107.1.m1.1b"><ci id="bib.bib107.1.m1.1.1.cmml" xref="bib.bib107.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib107.1.m1.1c">\{</annotation></semantics></math>SWIFT<math id="bib.bib107.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib107.2.m2.1a"><mo stretchy="false" id="bib.bib107.2.m2.1.1" xref="bib.bib107.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib107.2.m2.1b"><ci id="bib.bib107.2.m2.1.1.cmml" xref="bib.bib107.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib107.2.m2.1c">\}</annotation></semantics></math>: Super-fast and robust <math id="bib.bib107.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib107.3.m3.1a"><mo stretchy="false" id="bib.bib107.3.m3.1.1" xref="bib.bib107.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib107.3.m3.1b"><ci id="bib.bib107.3.m3.1.1.cmml" xref="bib.bib107.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib107.3.m3.1c">\{</annotation></semantics></math>Privacy-Preserving<math id="bib.bib107.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib107.4.m4.1a"><mo stretchy="false" id="bib.bib107.4.m4.1.1" xref="bib.bib107.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib107.4.m4.1b"><ci id="bib.bib107.4.m4.1.1.cmml" xref="bib.bib107.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib107.4.m4.1c">\}</annotation></semantics></math>
machine learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib107.5.1" class="ltx_emph ltx_font_italic">30th USENIX Security Symposium (USENIX Security 21)</em>, pages
2651–2668, 2021a.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koti et al. [2021b]</span>
<span class="ltx_bibblock">
N. Koti, A. Patra, R. Rachuri, and A. Suresh.

</span>
<span class="ltx_bibblock">Tetrad: actively secure 4pc for secure training and inference.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.02850</em>, 2021b.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al. [2020]</span>
<span class="ltx_bibblock">
N. Kumar, M. Rathee, N. Chandran, D. Gupta, A. Rastogi, and R. Sharma.

</span>
<span class="ltx_bibblock">Cryptflow: Secure tensorflow inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">2020 IEEE Symposium on Security and Privacy (SP)</em>, pages
336–353. IEEE, 2020.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamport et al. [2019]</span>
<span class="ltx_bibblock">
L. Lamport, R. Shostak, and M. Pease.

</span>
<span class="ltx_bibblock">The byzantine generals problem.

</span>
<span class="ltx_bibblock">In <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">Concurrency: the works of leslie lamport</em>, pages 203–226.
2019.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2016]</span>
<span class="ltx_bibblock">
B. Li, Y. Wang, A. Singh, and Y. Vorobeychik.

</span>
<span class="ltx_bibblock">Data poisoning attacks on factorization-based collaborative
filtering.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 29, 2016.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wang [2019]</span>
<span class="ltx_bibblock">
D. Li and J. Wang.

</span>
<span class="ltx_bibblock">Fedmd: Heterogenous federated learning via model distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.03581</em>, 2019.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Han [2019]</span>
<span class="ltx_bibblock">
H. Li and T. Han.

</span>
<span class="ltx_bibblock">An end-to-end encrypted neural network for gradient upda tes
transmission in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1908.08340</em>, 2019.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2019]</span>
<span class="ltx_bibblock">
L. Li, W. Xu, T. Chen, G. B. Giannakis, and Q. Ling.

</span>
<span class="ltx_bibblock">Rsa: Byzantine-robust stochastic aggregation methods for distributed
learning from heterogeneous datasets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 33, pages 1544–1551, 2019.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2021a]</span>
<span class="ltx_bibblock">
Q. Li, Z. Wen, Z. Wu, S. Hu, N. Wang, Y. Li, X. Liu, and B. He.

</span>
<span class="ltx_bibblock">A survey on federated learning systems: vision, hype and reality for
data privacy and protection.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>,
2021a.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2020a]</span>
<span class="ltx_bibblock">
S. Li, Y. Cheng, W. Wang, Y. Liu, and T. Chen.

</span>
<span class="ltx_bibblock">Learning to detect malicious clients for robust federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.00211</em>, 2020a.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2020b]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>, 2:429–450, 2020b.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2021b]</span>
<span class="ltx_bibblock">
T. Li, S. Hu, A. Beirami, and V. Smith.

</span>
<span class="ltx_bibblock">Ditto: Fair and robust federated learning through personalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
6357–6368. PMLR, 2021b.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Xu [2019]</span>
<span class="ltx_bibblock">
Y. Li and W. Xu.

</span>
<span class="ltx_bibblock">Privpy: General and scalable privacy-preserving data mining.

</span>
<span class="ltx_bibblock">In <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery &amp; Data Mining</em>, pages 1299–1307, 2019.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Zhang [2020]</span>
<span class="ltx_bibblock">
Z. Li and Y. Zhang.

</span>
<span class="ltx_bibblock">Label-leaks: Membership inference attack with label.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.15528</em>, 2020.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2021c]</span>
<span class="ltx_bibblock">
Z. Li, H. Yu, T. Zhou, L. Luo, M. Fan, Z. Xu, and G. Sun.

</span>
<span class="ltx_bibblock">Byzantine resistant secure blockchained federated learning at the
edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, 35(4):295–301,
2021c.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2022]</span>
<span class="ltx_bibblock">
Z. Li, Y. He, H. Yu, J. Kang, X. Li, Z. Xu, and D. Niyato.

</span>
<span class="ltx_bibblock">Data heterogeneity-robust federated learning via group client
selection in industrial iot.

</span>
<span class="ltx_bibblock"><em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, 9(18):17844–17857, 2022.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. [2020]</span>
<span class="ltx_bibblock">
T. Lin, L. Kong, S. U. Stich, and M. Jaggi.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:2351–2363, 2020.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2021]</span>
<span class="ltx_bibblock">
H. Liu, Y. Wang, W. Fan, X. Liu, Y. Li, S. Jain, Y. Liu, A. K. Jain, and
J. Tang.

</span>
<span class="ltx_bibblock">Trustworthy ai: A computational perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06641</em>, 2021.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2017]</span>
<span class="ltx_bibblock">
J. Liu, M. Juuti, Y. Lu, and N. Asokan.

</span>
<span class="ltx_bibblock">Oblivious neural network predictions via minionn transformations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC conference on computer
and communications security</em>, pages 619–631, 2017.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2020a]</span>
<span class="ltx_bibblock">
R. Liu, Y. Cao, M. Yoshikawa, and H. Chen.

</span>
<span class="ltx_bibblock">Fedsel: Federated sgd under local differential privacy with top-k
dimension selection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">International Conference on Database Systems for Advanced
Applications</em>, pages 485–501. Springer, 2020a.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2022a]</span>
<span class="ltx_bibblock">
T. Liu, X. Hu, and T. Shu.

</span>
<span class="ltx_bibblock">Technical report: Assisting backdoor federated learning with whole
population knowledge alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.12327</em>, 2022a.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2020b]</span>
<span class="ltx_bibblock">
X. Liu, H. Li, G. Xu, R. Lu, and M. He.

</span>
<span class="ltx_bibblock">Adaptive privacy-preserving federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">Peer-to-Peer Networking and Applications</em>, 13(6):2356–2366, 2020b.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2022b]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, T. Zou, Y. Pu, Y. He, X. Ye, Y. Ouyang, Y.-Q. Zhang, and
Q. Yang.

</span>
<span class="ltx_bibblock">Vertical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.12814</em>, 2022b.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2020a]</span>
<span class="ltx_bibblock">
H. Lu, C. Liu, T. He, S. Wang, and K. S. Chan.

</span>
<span class="ltx_bibblock">Sharing models or coresets: A study based on membership inference
attack.

</span>
<span class="ltx_bibblock"><em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.02977</em>, 2020a.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2020b]</span>
<span class="ltx_bibblock">
S. Lu, Y. Zhang, and Y. Wang.

</span>
<span class="ltx_bibblock">Decentralized federated learning for electronic health records.

</span>
<span class="ltx_bibblock">In <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">2020 54th Annual Conference on Information Sciences and
Systems (CISS)</em>, pages 1–5. IEEE, 2020b.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2019]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang.

</span>
<span class="ltx_bibblock">Differentially private asynchronous federated learning for mobile
edge computing in urban informatics.

</span>
<span class="ltx_bibblock"><em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, 16(3):2134–2143, 2019.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al. [2020]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, and Q. Yang.

</span>
<span class="ltx_bibblock">Threats to federated learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.02133</em>, 2020.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mandal et al. [2018]</span>
<span class="ltx_bibblock">
K. Mandal, G. Gong, and C. Liu.

</span>
<span class="ltx_bibblock">Nike-based fast privacy-preserving highdimensional data aggregation
for mobile devices.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">IEEE T Depend Secure; Technical Report; University of Waterloo:
Waterloo, ON, Canada</em>, pages 142–149, 2018.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mansour et al. [2020]</span>
<span class="ltx_bibblock">
Y. Mansour, M. Mohri, J. Ro, and A. T. Suresh.

</span>
<span class="ltx_bibblock">Three approaches for personalization with applications to federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.10619</em>, 2020.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mao et al. [2017]</span>
<span class="ltx_bibblock">
Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief.

</span>
<span class="ltx_bibblock">A survey on mobile edge computing: The communication perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">IEEE communications surveys &amp; tutorials</em>, 19(4):2322–2358, 2017.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017a]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>, pages 1273–1282.
PMLR, 2017a.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017b]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>, pages 1273–1282.
PMLR, 2017b.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017c]</span>
<span class="ltx_bibblock">
H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang.

</span>
<span class="ltx_bibblock">Learning differentially private recurrent language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.06963</em>, 2017c.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melis et al. [2019a]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov.

</span>
<span class="ltx_bibblock">Exploiting unintended feature leakage in collaborative learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and privacy (SP)</em>, pages
691–706. IEEE, 2019a.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Melis et al. [2019b]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov.

</span>
<span class="ltx_bibblock">Exploiting unintended feature leakage in collaborative learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and privacy (SP)</em>, pages
691–706. IEEE, 2019b.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et al. [2020]</span>
<span class="ltx_bibblock">
P. Mishra, R. Lehmkuhl, A. Srinivasan, W. Zheng, and R. A. Popa.

</span>
<span class="ltx_bibblock">Delphi: A cryptographic inference service for neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">29th USENIX Security Symposium (USENIX Security 20)</em>, pages
2505–2522, 2020.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo and Haddadi [2019]</span>
<span class="ltx_bibblock">
F. Mo and H. Haddadi.

</span>
<span class="ltx_bibblock">Efficient and private federated learning using tee.

</span>
<span class="ltx_bibblock">In <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">Proc. EuroSys Conf., Dresden, Germany</em>, 2019.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al. [2020]</span>
<span class="ltx_bibblock">
F. Mo, A. Borovykh, M. Malekzadeh, H. Haddadi, and S. Demetriou.

</span>
<span class="ltx_bibblock">Layer-wise characterization of latent information leakage in
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.08762</em>, 2020.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohassel and Rindal [2018]</span>
<span class="ltx_bibblock">
P. Mohassel and P. Rindal.

</span>
<span class="ltx_bibblock">ABY3: A mixed protocol framework for machine learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">Proc. CCS</em>, pages 35–52, 2018.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohassel and Zhang [2017]</span>
<span class="ltx_bibblock">
P. Mohassel and Y. Zhang.

</span>
<span class="ltx_bibblock">SecureML: A system for scalable privacy-preserving machine
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on Security and Privacy</em>, pages 19–38, 2017.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muñoz-González et al. [2019]</span>
<span class="ltx_bibblock">
L. Muñoz-González, K. T. Co, and E. C. Lupu.

</span>
<span class="ltx_bibblock">Byzantine-robust federated machine learning through adaptive model
averaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.05125</em>, 2019.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naseri et al. [2020]</span>
<span class="ltx_bibblock">
M. Naseri, J. Hayes, and E. De Cristofaro.

</span>
<span class="ltx_bibblock">Toward robustness and privacy in federated learning: Experimenting
with local and central differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, pages arXiv–2009, 2020.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et al. [2018]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr.

</span>
<span class="ltx_bibblock">Machine learning with membership privacy using adversarial
regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 ACM SIGSAC conference on computer
and communications security</em>, pages 634–646, 2018.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et al. [2019]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr.

</span>
<span class="ltx_bibblock">Comprehensive privacy analysis of deep learning: Passive and active
white-box inference attacks against centralized and federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and privacy (SP)</em>, pages
739–753. IEEE, 2019.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng et al. [2021]</span>
<span class="ltx_bibblock">
K. L. Ng, Z. Chen, Z. Liu, H. Yu, Y. Liu, and Q. Yang.

</span>
<span class="ltx_bibblock">A multi-player game for studying federated learning incentive
schemes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty-Ninth International Conference on
International Joint Conferences on Artificial Intelligence</em>, pages
5279–5281, 2021.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paillier [1999]</span>
<span class="ltx_bibblock">
P. Paillier.

</span>
<span class="ltx_bibblock">Public-key cryptosystems based on composite degree residuosity
classes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">International conference on the theory and applications of
cryptographic techniques</em>, pages 223–238. Springer, 1999.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patra and Suresh [2020]</span>
<span class="ltx_bibblock">
A. Patra and A. Suresh.

</span>
<span class="ltx_bibblock">Blaze: Blazing fast privacy-preserving machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Cryptology ePrint Archive</em>, 2020.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patra et al. [2021]</span>
<span class="ltx_bibblock">
A. Patra, T. Schneider, A. Suresh, and H. Yalame.

</span>
<span class="ltx_bibblock"><math id="bib.bib154.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib154.1.m1.1a"><mo stretchy="false" id="bib.bib154.1.m1.1.1" xref="bib.bib154.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib154.1.m1.1b"><ci id="bib.bib154.1.m1.1.1.cmml" xref="bib.bib154.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib154.1.m1.1c">\{</annotation></semantics></math>ABY2. 0<math id="bib.bib154.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib154.2.m2.1a"><mo stretchy="false" id="bib.bib154.2.m2.1.1" xref="bib.bib154.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib154.2.m2.1b"><ci id="bib.bib154.2.m2.1.1.cmml" xref="bib.bib154.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib154.2.m2.1c">\}</annotation></semantics></math>: Improved <math id="bib.bib154.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib154.3.m3.1a"><mo stretchy="false" id="bib.bib154.3.m3.1.1" xref="bib.bib154.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib154.3.m3.1b"><ci id="bib.bib154.3.m3.1.1.cmml" xref="bib.bib154.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib154.3.m3.1c">\{</annotation></semantics></math>Mixed-Protocol<math id="bib.bib154.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib154.4.m4.1a"><mo stretchy="false" id="bib.bib154.4.m4.1.1" xref="bib.bib154.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib154.4.m4.1b"><ci id="bib.bib154.4.m4.1.1.cmml" xref="bib.bib154.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib154.4.m4.1c">\}</annotation></semantics></math> secure
<math id="bib.bib154.5.m5.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib154.5.m5.1a"><mo stretchy="false" id="bib.bib154.5.m5.1.1" xref="bib.bib154.5.m5.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib154.5.m5.1b"><ci id="bib.bib154.5.m5.1.1.cmml" xref="bib.bib154.5.m5.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib154.5.m5.1c">\{</annotation></semantics></math>Two-Party<math id="bib.bib154.6.m6.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib154.6.m6.1a"><mo stretchy="false" id="bib.bib154.6.m6.1.1" xref="bib.bib154.6.m6.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib154.6.m6.1b"><ci id="bib.bib154.6.m6.1.1.cmml" xref="bib.bib154.6.m6.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib154.6.m6.1c">\}</annotation></semantics></math> computation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib154.7.1" class="ltx_emph ltx_font_italic">30th USENIX Security Symposium (USENIX Security 21)</em>, pages
2165–2182, 2021.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedrycz [2021]</span>
<span class="ltx_bibblock">
W. Pedrycz.

</span>
<span class="ltx_bibblock">Federated fcm: Clustering under privacy requirements.

</span>
<span class="ltx_bibblock"><em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Fuzzy Systems</em>, 2021.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. [2018]</span>
<span class="ltx_bibblock">
D. Peng, Z. Sun, Z. Chen, Z. Cai, L. Xie, and L. Jin.

</span>
<span class="ltx_bibblock">Detecting heads using feature refine net and cascaded multi-scale
architecture.

</span>
<span class="ltx_bibblock">In <em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">2018 24th International Conference on Pattern Recognition
(ICPR)</em>, pages 2528–2533. IEEE, 2018.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla et al. [2019]</span>
<span class="ltx_bibblock">
K. Pillutla, S. M. Kakade, and Z. Harchaoui.

</span>
<span class="ltx_bibblock">Robust aggregation for federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.13445</em>, 2019.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Portnoy et al. [2022]</span>
<span class="ltx_bibblock">
A. Portnoy, Y. Tirosh, and D. Hendler.

</span>
<span class="ltx_bibblock">Towards federated learning with byzantine-robust client weighting.

</span>
<span class="ltx_bibblock"><em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, 12(17):8847, 2022.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prakash and Avestimehr [2020]</span>
<span class="ltx_bibblock">
S. Prakash and A. S. Avestimehr.

</span>
<span class="ltx_bibblock">Mitigating byzantine attacks in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.07541</em>, 2020.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pustozerova and Mayer [2020]</span>
<span class="ltx_bibblock">
A. Pustozerova and R. Mayer.

</span>
<span class="ltx_bibblock">Information leaks in federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Network and Distributed System Security
Symposium</em>, volume 10, 2020.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al. [2020]</span>
<span class="ltx_bibblock">
Y. Qu, L. Gao, T. H. Luan, Y. Xiang, S. Yu, B. Li, and G. Zheng.

</span>
<span class="ltx_bibblock">Decentralized privacy using blockchain-enabled federated learning in
fog computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 7(6):5171–5183, 2020.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rabin [2005]</span>
<span class="ltx_bibblock">
M. O. Rabin.

</span>
<span class="ltx_bibblock">How to exchange secrets with oblivious transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">Cryptology ePrint Archive</em>, 2005.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rathee et al. [2020]</span>
<span class="ltx_bibblock">
D. Rathee, M. Rathee, N. Kumar, N. Chandran, D. Gupta, A. Rastogi, and
R. Sharma.

</span>
<span class="ltx_bibblock">Cryptflow2: Practical 2-party secure inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib163.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 ACM SIGSAC Conference on Computer
and Communications Security</em>, pages 325–342, 2020.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rathee et al. [2021]</span>
<span class="ltx_bibblock">
D. Rathee, M. Rathee, R. K. K. Goli, D. Gupta, R. Sharma, N. Chandran, and
A. Rastogi.

</span>
<span class="ltx_bibblock">Sirnn: A math library for secure rnn inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Symposium on Security and Privacy (SP)</em>, pages
1003–1020, 2021.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rau et al. [2021]</span>
<span class="ltx_bibblock">
R. Rau, R. Wardrop, and L. Zingales.

</span>
<span class="ltx_bibblock"><em id="bib.bib165.1.1" class="ltx_emph ltx_font_italic">The Palgrave Handbook of Technological Finance</em>.

</span>
<span class="ltx_bibblock">Springer, 2021.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddi et al. [2020]</span>
<span class="ltx_bibblock">
S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konečnỳ,
S. Kumar, and H. B. McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.00295</em>, 2020.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reisizadeh et al. [2020]</span>
<span class="ltx_bibblock">
A. Reisizadeh, F. Farnia, R. Pedarsani, and A. Jadbabaie.

</span>
<span class="ltx_bibblock">Robust federated learning: The case of affine distribution shifts.

</span>
<span class="ltx_bibblock"><em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:21554–21565, 2020.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Riazi et al. [2018]</span>
<span class="ltx_bibblock">
M. S. Riazi, C. Weinert, O. Tkachenko, E. M. Songhori, T. Schneider, and
F. Koushanfar.

</span>
<span class="ltx_bibblock">Chameleon: A hybrid secure computation framework for machine learning
applications.

</span>
<span class="ltx_bibblock">In <em id="bib.bib168.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 on Asia conference on computer and
communications security</em>, pages 707–721, 2018.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Riazi et al. [2019]</span>
<span class="ltx_bibblock">
M. S. Riazi, M. Samragh, H. Chen, K. Laine, K. Lauter, and F. Koushanfar.

</span>
<span class="ltx_bibblock"><math id="bib.bib169.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib169.1.m1.1a"><mo stretchy="false" id="bib.bib169.1.m1.1.1" xref="bib.bib169.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib169.1.m1.1b"><ci id="bib.bib169.1.m1.1.1.cmml" xref="bib.bib169.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib169.1.m1.1c">\{</annotation></semantics></math>XONN<math id="bib.bib169.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib169.2.m2.1a"><mo stretchy="false" id="bib.bib169.2.m2.1.1" xref="bib.bib169.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib169.2.m2.1b"><ci id="bib.bib169.2.m2.1.1.cmml" xref="bib.bib169.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib169.2.m2.1c">\}</annotation></semantics></math>:<math id="bib.bib169.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib169.3.m3.1a"><mo stretchy="false" id="bib.bib169.3.m3.1.1" xref="bib.bib169.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib169.3.m3.1b"><ci id="bib.bib169.3.m3.1.1.cmml" xref="bib.bib169.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib169.3.m3.1c">\{</annotation></semantics></math>XNOR-based<math id="bib.bib169.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib169.4.m4.1a"><mo stretchy="false" id="bib.bib169.4.m4.1.1" xref="bib.bib169.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib169.4.m4.1b"><ci id="bib.bib169.4.m4.1.1.cmml" xref="bib.bib169.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib169.4.m4.1c">\}</annotation></semantics></math> oblivious deep neural network
inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib169.5.1" class="ltx_emph ltx_font_italic">28th USENIX Security Symposium (USENIX Security 19)</em>, pages
1501–1518, 2019.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rivest et al. [1978]</span>
<span class="ltx_bibblock">
R. L. Rivest, L. Adleman, M. L. Dertouzos, et al.

</span>
<span class="ltx_bibblock">On data banks and privacy homomorphisms.

</span>
<span class="ltx_bibblock"><em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">Foundations of secure computation</em>, 4(11):169–180, 1978.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rizoiu et al. [2018]</span>
<span class="ltx_bibblock">
M.-A. Rizoiu, T. Graham, R. Zhang, Y. Zhang, R. Ackland, and L. Xie.

</span>
<span class="ltx_bibblock"># debatenight: The role and influence of socialbots on twitter
during the 1st 2016 us presidential debate.

</span>
<span class="ltx_bibblock">In <em id="bib.bib171.1.1" class="ltx_emph ltx_font_italic">Proceedings of the international AAAI conference on web and
social media</em>, volume 12, 2018.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rodríguez-Barroso et al. [2023]</span>
<span class="ltx_bibblock">
N. Rodríguez-Barroso, D. Jiménez-López, M. V. Luzón,
F. Herrera, and E. Martínez-Cámara.

</span>
<span class="ltx_bibblock">Survey on federated learning threats: concepts, taxonomy on attacks
and defences, experimental study and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">Information Fusion</em>, 90:148–173, 2023.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rong et al. [2022]</span>
<span class="ltx_bibblock">
D. Rong, Q. He, and J. Chen.

</span>
<span class="ltx_bibblock">Poisoning deep learning based recommender model in federated learning
scenarios.

</span>
<span class="ltx_bibblock"><em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.13594</em>, 2022.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rouhani et al. [2018]</span>
<span class="ltx_bibblock">
B. D. Rouhani, M. S. Riazi, and F. Koushanfar.

</span>
<span class="ltx_bibblock">Deepsecure: Scalable provably-secure deep learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th annual design automation
conference</em>, pages 1–6, 2018.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryffel et al. [2020]</span>
<span class="ltx_bibblock">
T. Ryffel, P. Tholoniat, D. Pointcheval, and F. Bach.

</span>
<span class="ltx_bibblock">AriaNN: Low-interaction privacy-preserving deep learning via
function secret sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib175.1.1" class="ltx_emph ltx_font_italic">Proc. on Privacy Enhancing Technologies</em>, 2022(1):291–316, 2020.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saha et al. [2020]</span>
<span class="ltx_bibblock">
O. Saha, A. Kusupati, H. V. Simhadri, M. Varma, and P. Jain.

</span>
<span class="ltx_bibblock">Rnnpool: efficient non-linear pooling for ram constrained inference.

</span>
<span class="ltx_bibblock"><em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:20473–20484, 2020.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sannai [2018]</span>
<span class="ltx_bibblock">
A. Sannai.

</span>
<span class="ltx_bibblock">Reconstruction of training samples from loss functions.

</span>
<span class="ltx_bibblock"><em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1805.07337</em>, 2018.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler et al. [2020a]</span>
<span class="ltx_bibblock">
F. Sattler, K.-R. Müller, and W. Samek.

</span>
<span class="ltx_bibblock">Clustered federated learning: Model-agnostic distributed multitask
optimization under privacy constraints.

</span>
<span class="ltx_bibblock"><em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on neural networks and learning systems</em>,
32(8):3710–3722, 2020a.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler et al. [2020b]</span>
<span class="ltx_bibblock">
F. Sattler, K.-R. Müller, T. Wiegand, and W. Samek.

</span>
<span class="ltx_bibblock">On the byzantine robustness of clustered federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</em>, pages 8861–8865. IEEE,
2020b.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seif et al. [2020]</span>
<span class="ltx_bibblock">
M. Seif, R. Tandon, and M. Li.

</span>
<span class="ltx_bibblock">Wireless federated learning with local differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib180.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Symposium on Information Theory
(ISIT)</em>, pages 2604–2609. IEEE, 2020.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seo et al. [2020]</span>
<span class="ltx_bibblock">
H. Seo, J. Park, S. Oh, M. Bennis, and S.-L. Kim.

</span>
<span class="ltx_bibblock">Federated knowledge distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.02367</em>, 2020.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shafique et al. [2020]</span>
<span class="ltx_bibblock">
M. Shafique, M. Naseer, T. Theocharides, C. Kyrkou, O. Mutlu, L. Orosa, and
J. Choi.

</span>
<span class="ltx_bibblock">Robust machine learning systems: Challenges, current trends,
perspectives, and the road ahead.

</span>
<span class="ltx_bibblock"><em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">IEEE Design &amp; Test</em>, 37(2):30–57, 2020.

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shamir [1979]</span>
<span class="ltx_bibblock">
A. Shamir.

</span>
<span class="ltx_bibblock">How to share a secret.

</span>
<span class="ltx_bibblock"><em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 22(11):612–613, 1979.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. [2020]</span>
<span class="ltx_bibblock">
M. Shen, H. Wang, B. Zhang, L. Zhu, K. Xu, Q. Li, and X. Du.

</span>
<span class="ltx_bibblock">Exploiting unintended property leakage in blockchain-assisted
federated learning for intelligent edge computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 8(4):2265–2275, 2020.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al. [2017a]</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, and V. Shmatikov.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib185.1.1" class="ltx_emph ltx_font_italic">2017 IEEE symposium on security and privacy (SP)</em>, pages
3–18. IEEE, 2017a.

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al. [2017b]</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, and V. Shmatikov.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">2017 IEEE symposium on security and privacy (SP)</em>, pages
3–18. IEEE, 2017b.

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smuha [2019]</span>
<span class="ltx_bibblock">
N. A. Smuha.

</span>
<span class="ltx_bibblock">The eu approach to ethics guidelines for trustworthy artificial
intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib187.1.1" class="ltx_emph ltx_font_italic">Computer Law Review International</em>, 20(4):97–106, 2019.

</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. [2020]</span>
<span class="ltx_bibblock">
M. Song, Z. Wang, Z. Zhang, Y. Song, Q. Wang, J. Ren, and H. Qi.

</span>
<span class="ltx_bibblock">Analyzing user-level privacy attack against federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib188.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em>, 38(10):2430–2444, 2020.

</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. [2021]</span>
<span class="ltx_bibblock">
Z. Song, Z. Meng, Y. Zhang, and I. King.

</span>
<span class="ltx_bibblock">Semi-supervised multi-label learning for graph-structured data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib189.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th ACM International Conference on
Information &amp; Knowledge Management</em>, pages 1723–1733, 2021.

</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. [2022]</span>
<span class="ltx_bibblock">
Z. Song, Y. Zhang, and I. King.

</span>
<span class="ltx_bibblock">Towards an optimal asymmetric graph structure for robust
semi-supervised node classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib190.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining</em>, pages 1656–1665, 2022.

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stallmann and Wilbik [2022]</span>
<span class="ltx_bibblock">
M. Stallmann and A. Wilbik.

</span>
<span class="ltx_bibblock">Towards federated clustering: A federated fuzzy c-means algorithm
(ffcm).

</span>
<span class="ltx_bibblock"><em id="bib.bib191.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.07316</em>, 2022.

</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su and Xu [2019]</span>
<span class="ltx_bibblock">
L. Su and J. Xu.

</span>
<span class="ltx_bibblock">Securing distributed gradient descent in high dimensional statistical
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib192.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Measurement and Analysis of Computing
Systems</em>, 3(1):1–41, 2019.

</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramanyan et al. [2017]</span>
<span class="ltx_bibblock">
P. Subramanyan, R. Sinha, I. Lebedev, S. Devadas, and S. A. Seshia.

</span>
<span class="ltx_bibblock">A formal foundation for secure remote execution of enclaves.

</span>
<span class="ltx_bibblock">In <em id="bib.bib193.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security</em>, pages 2435–2450, 2017.

</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. [2020]</span>
<span class="ltx_bibblock">
L. Sun, J. Qian, and X. Chen.

</span>
<span class="ltx_bibblock">Ldp-fl: Practical private aggregation in federated learning with
local differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.15789</em>, 2020.

</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. [2019]</span>
<span class="ltx_bibblock">
Z. Sun, P. Kairouz, A. T. Suresh, and H. B. McMahan.

</span>
<span class="ltx_bibblock">Can you really backdoor federated learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib195.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.07963</em>, 2019.

</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">T Dinh et al. [2020]</span>
<span class="ltx_bibblock">
C. T Dinh, N. Tran, and J. Nguyen.

</span>
<span class="ltx_bibblock">Personalized federated learning with moreau envelopes.

</span>
<span class="ltx_bibblock"><em id="bib.bib196.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:21394–21405, 2020.

</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. [2022]</span>
<span class="ltx_bibblock">
A. Z. Tan, H. Yu, L. Cui, and Q. Yang.

</span>
<span class="ltx_bibblock">Towards personalized federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib197.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>,
2022.

</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. [2021]</span>
<span class="ltx_bibblock">
S. Tan, B. Knott, Y. Tian, and D. J. Wu.

</span>
<span class="ltx_bibblock">Cryptgpu: Fast privacy-preserving machine learning on the gpu.

</span>
<span class="ltx_bibblock">In <em id="bib.bib198.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Symposium on Security and Privacy (SP)</em>, pages
1021–1038. IEEE, 2021.

</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Terrail et al. [2022]</span>
<span class="ltx_bibblock">
J. O. d. Terrail, S.-S. Ayed, E. Cyffers, F. Grimberg, C. He, R. Loeb,
P. Mangold, T. Marchand, O. Marfoq, E. Mushtaq, et al.

</span>
<span class="ltx_bibblock">Flamby: Datasets and benchmarks for cross-silo federated learning in
realistic healthcare settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib199.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.04620</em>, 2022.

</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tolpegin et al. [2020]</span>
<span class="ltx_bibblock">
V. Tolpegin, S. Truex, M. E. Gursoy, and L. Liu.

</span>
<span class="ltx_bibblock">Data poisoning attacks against federated learning systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib200.1.1" class="ltx_emph ltx_font_italic">European Symposium on Research in Computer Security</em>, pages
480–501. Springer, 2020.

</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Triastcyn and Faltings [2019]</span>
<span class="ltx_bibblock">
A. Triastcyn and B. Faltings.

</span>
<span class="ltx_bibblock">Federated learning with bayesian differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib201.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International Conference on Big Data (Big Data)</em>,
pages 2587–2596. IEEE, 2019.

</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truex et al. [2019]</span>
<span class="ltx_bibblock">
S. Truex, L. Liu, M. E. Gursoy, L. Yu, and W. Wei.

</span>
<span class="ltx_bibblock">Demystifying membership inference attacks in machine learning as a
service.

</span>
<span class="ltx_bibblock"><em id="bib.bib202.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Services Computing</em>, 2019.

</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truex et al. [2020]</span>
<span class="ltx_bibblock">
S. Truex, L. Liu, K.-H. Chow, M. E. Gursoy, and W. Wei.

</span>
<span class="ltx_bibblock">Ldp-fed: Federated learning with local differential privacy.

</span>
<span class="ltx_bibblock">In <em id="bib.bib203.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third ACM International Workshop on Edge
Systems, Analytics and Networking</em>, pages 61–66, 2020.

</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Varshney [2019]</span>
<span class="ltx_bibblock">
K. R. Varshney.

</span>
<span class="ltx_bibblock">Trustworthy machine learning and artificial intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib204.1.1" class="ltx_emph ltx_font_italic">XRDS: Crossroads, The ACM Magazine for Students</em>, 25(3):26–29, 2019.

</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagh et al. [2019]</span>
<span class="ltx_bibblock">
S. Wagh, D. Gupta, and N. Chandran.

</span>
<span class="ltx_bibblock">SecureNN: 3-Party secure computation for neural network training.

</span>
<span class="ltx_bibblock"><em id="bib.bib205.1.1" class="ltx_emph ltx_font_italic">Proc. Priv. Enhancing Technol.</em>, 2019(3):26–49, 2019.

</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagh et al. [2020]</span>
<span class="ltx_bibblock">
S. Wagh, S. Tople, F. Benhamouda, E. Kushilevitz, P. Mittal, and T. Rabin.

</span>
<span class="ltx_bibblock">Falcon: Honest-majority maliciously secure framework for private deep
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib206.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.02229</em>, 2020.

</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2020a]</span>
<span class="ltx_bibblock">
H. Wang, K. Sreenivasan, S. Rajput, H. Vishwakarma, S. Agarwal, J.-y. Sohn,
K. Lee, and D. Papailiopoulos.

</span>
<span class="ltx_bibblock">Attack of the tails: Yes, you really can backdoor federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib207.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:16070–16084, 2020a.

</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2020b]</span>
<span class="ltx_bibblock">
J. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor.

</span>
<span class="ltx_bibblock">Tackling the objective inconsistency problem in heterogeneous
federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib208.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
33:7611–7623, 2020b.

</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2019a]</span>
<span class="ltx_bibblock">
L. Wang, S. Xu, X. Wang, and Q. Zhu.

</span>
<span class="ltx_bibblock">Eavesdrop the composition proportion of training labels in federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib209.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.06044</em>, 2019a.

</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2020c]</span>
<span class="ltx_bibblock">
Y. Wang, Y. Tong, and D. Shi.

</span>
<span class="ltx_bibblock">Federated latent dirichlet allocation: A local differential privacy
based framework.

</span>
<span class="ltx_bibblock">In <em id="bib.bib210.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 34, pages 6283–6290, 2020c.

</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2022]</span>
<span class="ltx_bibblock">
Y. Wang, M. Jia, N. Gao, L. Von Krannichfeldt, M. Sun, and G. Hug.

</span>
<span class="ltx_bibblock">Federated clustering for electricity consumption pattern extraction.

</span>
<span class="ltx_bibblock"><em id="bib.bib211.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Smart Grid</em>, 13(3):2425–2439, 2022.

</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2019b]</span>
<span class="ltx_bibblock">
Z. Wang, M. Song, Z. Zhang, Y. Song, Q. Wang, and H. Qi.

</span>
<span class="ltx_bibblock">Beyond inferring class representatives: User-level privacy leakage
from federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib212.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2019-IEEE Conference on Computer
Communications</em>, pages 2512–2520. IEEE, 2019b.

</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Watson et al. [2022]</span>
<span class="ltx_bibblock">
J.-L. Watson, S. Wagh, and R. A. Popa.

</span>
<span class="ltx_bibblock">Piranha: A <math id="bib.bib213.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib213.1.m1.1a"><mo stretchy="false" id="bib.bib213.1.m1.1.1" xref="bib.bib213.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib213.1.m1.1b"><ci id="bib.bib213.1.m1.1.1.cmml" xref="bib.bib213.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib213.1.m1.1c">\{</annotation></semantics></math>GPU<math id="bib.bib213.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib213.2.m2.1a"><mo stretchy="false" id="bib.bib213.2.m2.1.1" xref="bib.bib213.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib213.2.m2.1b"><ci id="bib.bib213.2.m2.1.1.cmml" xref="bib.bib213.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib213.2.m2.1c">\}</annotation></semantics></math> platform for secure computation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib213.3.1" class="ltx_emph ltx_font_italic">31st USENIX Security Symposium (USENIX Security 22)</em>, pages
827–844, 2022.

</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. [2020a]</span>
<span class="ltx_bibblock">
K. Wei, J. Li, M. Ding, C. Ma, H. H. Yang, F. Farokhi, S. Jin, T. Q. Quek, and
H. V. Poor.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy: Algorithms and
performance analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib214.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>,
15:3454–3469, 2020a.

</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. [2020b]</span>
<span class="ltx_bibblock">
W. Wei, L. Liu, M. Loper, K.-H. Chow, M. E. Gursoy, S. Truex, and Y. Wu.

</span>
<span class="ltx_bibblock">A framework for evaluating client privacy leakages in federated
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib215.1.1" class="ltx_emph ltx_font_italic">European Symposium on Research in Computer Security</em>, pages
545–566. Springer, 2020b.

</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2021]</span>
<span class="ltx_bibblock">
M. Wu, D. Ye, J. Ding, Y. Guo, R. Yu, and M. Pan.

</span>
<span class="ltx_bibblock">Incentivizing differentially private federated learning: A
multidimensional contract approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib216.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 8(13):10639–10651, 2021.

</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2020a]</span>
<span class="ltx_bibblock">
Y. Wu, S. Cai, X. Xiao, G. Chen, and B. C. Ooi.

</span>
<span class="ltx_bibblock">Privacy preserving vertical federated learning for tree-based models.

</span>
<span class="ltx_bibblock"><em id="bib.bib217.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.06170</em>, 2020a.

</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2020b]</span>
<span class="ltx_bibblock">
Z. Wu, Q. Ling, T. Chen, and G. B. Giannakis.

</span>
<span class="ltx_bibblock">Federated variance-reduced stochastic gradient descent with
robustness to byzantine attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib218.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Signal Processing</em>, 68:4583–4596, 2020b.

</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. [2010]</span>
<span class="ltx_bibblock">
X. Xiao, G. Wang, and J. Gehrke.

</span>
<span class="ltx_bibblock">Differential privacy via wavelet transforms.

</span>
<span class="ltx_bibblock"><em id="bib.bib219.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on knowledge and data engineering</em>,
23(8):1200–1214, 2010.

</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2018]</span>
<span class="ltx_bibblock">
C. Xie, O. Koyejo, and I. Gupta.

</span>
<span class="ltx_bibblock">Generalized byzantine-tolerant sgd.

</span>
<span class="ltx_bibblock"><em id="bib.bib220.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1802.10116</em>, 2018.

</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2019a]</span>
<span class="ltx_bibblock">
C. Xie, K. Huang, P.-Y. Chen, and B. Li.

</span>
<span class="ltx_bibblock">Dba: Distributed backdoor attacks against federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib221.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>,
2019a.

</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2019b]</span>
<span class="ltx_bibblock">
C. Xie, O. Koyejo, and I. Gupta.

</span>
<span class="ltx_bibblock">Slsgd: Secure and efficient distributed on-device machine learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib222.1.1" class="ltx_emph ltx_font_italic">Joint European Conference on Machine Learning and Knowledge
Discovery in Databases</em>, pages 213–228. Springer, 2019b.

</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2020a]</span>
<span class="ltx_bibblock">
C. Xie, S. Koyejo, and I. Gupta.

</span>
<span class="ltx_bibblock">Zeno++: Robust fully asynchronous sgd.

</span>
<span class="ltx_bibblock">In <em id="bib.bib223.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
10495–10503. PMLR, 2020a.

</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2021]</span>
<span class="ltx_bibblock">
C. Xie, M. Chen, P.-Y. Chen, and B. Li.

</span>
<span class="ltx_bibblock">Crfl: Certifiably robust federated learning against backdoor attacks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib224.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
11372–11382. PMLR, 2021.

</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2022a]</span>
<span class="ltx_bibblock">
L. Xie, J. Liu, S. Lu, T.-H. Chang, and Q. Shi.

</span>
<span class="ltx_bibblock">An efficient learning framework for federated xgboost using secret
sharing and distributed optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib225.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>,
13(5):1–28, 2022a.

</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2020b]</span>
<span class="ltx_bibblock">
M. Xie, G. Long, T. Shen, T. Zhou, X. Wang, J. Jiang, and C. Zhang.

</span>
<span class="ltx_bibblock">Multi-center federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib226.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.01026</em>, 2020b.

</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. [2022b]</span>
<span class="ltx_bibblock">
Y. Xie, Z. Wang, D. Chen, D. Gao, L. Yao, W. Kuang, Y. Li, B. Ding, and
J. Zhou.

</span>
<span class="ltx_bibblock">Federatedscope: A comprehensive and flexible federated learning
platform via message passing.

</span>
<span class="ltx_bibblock"><em id="bib.bib227.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.05011</em>, 2022b.

</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2019]</span>
<span class="ltx_bibblock">
G. Xu, H. Li, S. Liu, K. Yang, and X. Lin.

</span>
<span class="ltx_bibblock">Verifynet: Secure and verifiable federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib228.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>,
15:911–926, 2019.

</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and Li [2020]</span>
<span class="ltx_bibblock">
M. Xu and X. Li.

</span>
<span class="ltx_bibblock">Subject property inference attack in collaborative learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib229.1.1" class="ltx_emph ltx_font_italic">2020 12th International Conference on Intelligent
Human-Machine Systems and Cybernetics (IHMSC)</em>, volume 1, pages 227–231.
IEEE, 2020.

</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2020]</span>
<span class="ltx_bibblock">
X. Xu, J. Wu, M. Yang, T. Luo, X. Duan, W. Li, Y. Wu, and B. Wu.

</span>
<span class="ltx_bibblock">Information leakage by model weights on federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib230.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Workshop on Privacy-Preserving
Machine Learning in Practice</em>, pages 31–36, 2020.

</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2020]</span>
<span class="ltx_bibblock">
K. Yang, C. Weng, X. Lan, J. Zhang, and X. Wang.

</span>
<span class="ltx_bibblock">Ferret: Fast extension for correlated ot with small communication.

</span>
<span class="ltx_bibblock">In <em id="bib.bib231.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 ACM SIGSAC Conference on Computer
and Communications Security</em>, pages 1607–1626, 2020.

</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2019a]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib232.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</em>,
10(2):1–19, 2019a.

</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2019b]</span>
<span class="ltx_bibblock">
S. Yang, B. Ren, X. Zhou, and L. Liu.

</span>
<span class="ltx_bibblock">Parallel distributed logistic regression for vertical federated
learning without third-party coordinator.

</span>
<span class="ltx_bibblock"><em id="bib.bib233.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.09824</em>, 2019b.

</span>
</li>
<li id="bib.bib234" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao [1982]</span>
<span class="ltx_bibblock">
A. C. Yao.

</span>
<span class="ltx_bibblock">Protocols for secure computations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib234.1.1" class="ltx_emph ltx_font_italic">23rd annual symposium on foundations of computer science
(sfcs 1982)</em>, pages 160–164. IEEE, 1982.

</span>
</li>
<li id="bib.bib235" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao [1986]</span>
<span class="ltx_bibblock">
A. C.-C. Yao.

</span>
<span class="ltx_bibblock">How to generate and exchange secrets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib235.1.1" class="ltx_emph ltx_font_italic">Annual Symposium on Foundations of Computer Science</em>, pages
162–167, 1986.

</span>
</li>
<li id="bib.bib236" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. [2018]</span>
<span class="ltx_bibblock">
D. Yin, Y. Chen, R. Kannan, and P. Bartlett.

</span>
<span class="ltx_bibblock">Byzantine-robust distributed learning: Towards optimal statistical
rates.

</span>
<span class="ltx_bibblock">In <em id="bib.bib236.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
5650–5659. PMLR, 2018.

</span>
</li>
<li id="bib.bib237" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. [2021a]</span>
<span class="ltx_bibblock">
H. Yin, A. Mallya, A. Vahdat, J. M. Alvarez, J. Kautz, and P. Molchanov.

</span>
<span class="ltx_bibblock">See through gradients: Image batch recovery via gradinversion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib237.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pages 16337–16346, 2021a.

</span>
</li>
<li id="bib.bib238" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. [2021b]</span>
<span class="ltx_bibblock">
X. Yin, Y. Zhu, and J. Hu.

</span>
<span class="ltx_bibblock">A comprehensive survey of privacy-preserving federated learning: A
taxonomy, review, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib238.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, 54(6):1–36,
2021b.

</span>
</li>
<li id="bib.bib239" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. [2019a]</span>
<span class="ltx_bibblock">
C. Yu, H. Tang, C. Renggli, S. Kassing, A. Singla, D. Alistarh, C. Zhang, and
J. Liu.

</span>
<span class="ltx_bibblock">Distributed learning over unreliable networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib239.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
7202–7212. PMLR, 2019a.

</span>
</li>
<li id="bib.bib240" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. [2019b]</span>
<span class="ltx_bibblock">
H. Yu, S. Yang, and S. Zhu.

</span>
<span class="ltx_bibblock">Parallel restarted sgd with faster convergence and less
communication: Demystifying why model averaging works for deep learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib240.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 33, pages 5693–5700, 2019b.

</span>
</li>
<li id="bib.bib241" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. [2021]</span>
<span class="ltx_bibblock">
X. Yuan, X. Ma, L. Zhang, Y. Fang, and D. Wu.

</span>
<span class="ltx_bibblock">Beyond class-level privacy leakage: Breaking record-level privacy in
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib241.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 9(4):2555–2565, 2021.

</span>
</li>
<li id="bib.bib242" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al. [2022]</span>
<span class="ltx_bibblock">
K. Yue, R. Jin, C.-W. Wong, D. Baron, and H. Dai.

</span>
<span class="ltx_bibblock">Gradient obfuscation gives a false sense of security in federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib242.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.04055</em>, 2022.

</span>
</li>
<li id="bib.bib243" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. [2021]</span>
<span class="ltx_bibblock">
D. Zeng, S. Liang, X. Hu, and Z. Xu.

</span>
<span class="ltx_bibblock">Fedlab: A flexible federated learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib243.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2107.11621, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2107.11621" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2107.11621</a>.

</span>
</li>
<li id="bib.bib244" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. [2022]</span>
<span class="ltx_bibblock">
S. Zeng, Z. Li, H. Yu, Y. He, Z. Xu, D. Niyato, and H. Yu.

</span>
<span class="ltx_bibblock">Heterogeneous federated learning via grouped sequential-to-parallel
training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib244.1.1" class="ltx_emph ltx_font_italic">Database Systems for Advanced Applications - 27th
International Conference, DASFAA 2022,</em>, volume 13246, pages 455–471.
Springer, 2022.

</span>
</li>
<li id="bib.bib245" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2020a]</span>
<span class="ltx_bibblock">
C. Zhang, S. Li, J. Xia, W. Wang, F. Yan, and Y. Liu.

</span>
<span class="ltx_bibblock"><math id="bib.bib245.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib245.1.m1.1a"><mo stretchy="false" id="bib.bib245.1.m1.1.1" xref="bib.bib245.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib245.1.m1.1b"><ci id="bib.bib245.1.m1.1.1.cmml" xref="bib.bib245.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib245.1.m1.1c">\{</annotation></semantics></math>BatchCrypt<math id="bib.bib245.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib245.2.m2.1a"><mo stretchy="false" id="bib.bib245.2.m2.1.1" xref="bib.bib245.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib245.2.m2.1b"><ci id="bib.bib245.2.m2.1.1.cmml" xref="bib.bib245.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib245.2.m2.1c">\}</annotation></semantics></math>: Efficient homomorphic encryption for
<math id="bib.bib245.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib245.3.m3.1a"><mo stretchy="false" id="bib.bib245.3.m3.1.1" xref="bib.bib245.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib245.3.m3.1b"><ci id="bib.bib245.3.m3.1.1.cmml" xref="bib.bib245.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib245.3.m3.1c">\{</annotation></semantics></math>Cross-Silo<math id="bib.bib245.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib245.4.m4.1a"><mo stretchy="false" id="bib.bib245.4.m4.1.1" xref="bib.bib245.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib245.4.m4.1b"><ci id="bib.bib245.4.m4.1.1.cmml" xref="bib.bib245.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib245.4.m4.1c">\}</annotation></semantics></math> federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib245.5.1" class="ltx_emph ltx_font_italic">2020 USENIX Annual Technical Conference (USENIX ATC 20)</em>,
pages 493–506, 2020a.

</span>
</li>
<li id="bib.bib246" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2020b]</span>
<span class="ltx_bibblock">
C. Zhang, Y. Liu, L. Wang, Y. Liu, L. Li, and N. Zheng.

</span>
<span class="ltx_bibblock">Joint intelligence ranking by federated multiplicative update.

</span>
<span class="ltx_bibblock"><em id="bib.bib246.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, 35(4):15–24,
2020b.

</span>
</li>
<li id="bib.bib247" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2021a]</span>
<span class="ltx_bibblock">
C. Zhang, J. Xia, B. Yang, H. Puyang, W. Wang, R. Chen, I. E. Akkus, P. Aditya,
and F. Yan.

</span>
<span class="ltx_bibblock">Citadel: Protecting data privacy and model confidentiality for
collaborative learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib247.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Symposium on Cloud Computing</em>, pages
546–561, 2021a.

</span>
</li>
<li id="bib.bib248" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022a]</span>
<span class="ltx_bibblock">
H. Zhang, B. Wu, X. Yuan, S. Pan, H. Tong, and J. Pei.

</span>
<span class="ltx_bibblock">Trustworthy graph neural networks: Aspects, methods and trends.

</span>
<span class="ltx_bibblock"><em id="bib.bib248.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.07424</em>, 2022a.

</span>
</li>
<li id="bib.bib249" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2012]</span>
<span class="ltx_bibblock">
J. Zhang, Z. Zhang, X. Xiao, Y. Yang, and M. Winslett.

</span>
<span class="ltx_bibblock">Functional mechanism: regression analysis under differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib249.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1208.0219</em>, 2012.

</span>
</li>
<li id="bib.bib250" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2021b]</span>
<span class="ltx_bibblock">
W. Zhang, S. Tople, and O. Ohrimenko.

</span>
<span class="ltx_bibblock">Leakage of dataset properties in <math id="bib.bib250.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib250.1.m1.1a"><mo stretchy="false" id="bib.bib250.1.m1.1.1" xref="bib.bib250.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib250.1.m1.1b"><ci id="bib.bib250.1.m1.1.1.cmml" xref="bib.bib250.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib250.1.m1.1c">\{</annotation></semantics></math>Multi-Party<math id="bib.bib250.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib250.2.m2.1a"><mo stretchy="false" id="bib.bib250.2.m2.1.1" xref="bib.bib250.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib250.2.m2.1b"><ci id="bib.bib250.2.m2.1.1.cmml" xref="bib.bib250.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib250.2.m2.1c">\}</annotation></semantics></math> machine
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib250.3.1" class="ltx_emph ltx_font_italic">30th USENIX Security Symposium (USENIX Security 21)</em>, pages
2687–2704, 2021b.

</span>
</li>
<li id="bib.bib251" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2020c]</span>
<span class="ltx_bibblock">
X. Zhang, A. Fu, H. Wang, C. Zhou, and Z. Chen.

</span>
<span class="ltx_bibblock">A privacy-preserving and verifiable federated learning scheme.

</span>
<span class="ltx_bibblock">In <em id="bib.bib251.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International Conference on
Communications (ICC)</em>, pages 1–6. IEEE, 2020c.

</span>
</li>
<li id="bib.bib252" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Yang [2021]</span>
<span class="ltx_bibblock">
Y. Zhang and Q. Yang.

</span>
<span class="ltx_bibblock">A survey on multi-task learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib252.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>, 2021.

</span>
</li>
<li id="bib.bib253" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Zhu [2019]</span>
<span class="ltx_bibblock">
Y. Zhang and H. Zhu.

</span>
<span class="ltx_bibblock">Doc2hash: Learning discrete latent variables for documents
retrieval.

</span>
<span class="ltx_bibblock">In <em id="bib.bib253.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, June 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1232</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/N19-1232" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/N19-1232</a>.

</span>
</li>
<li id="bib.bib254" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Zhu [2020a]</span>
<span class="ltx_bibblock">
Y. Zhang and H. Zhu.

</span>
<span class="ltx_bibblock">Additively homomorphical encryption based deep neural network for
asymmetrically collaborative machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib254.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.06849</em>, 2020a.

</span>
</li>
<li id="bib.bib255" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Zhu [2020b]</span>
<span class="ltx_bibblock">
Y. Zhang and H. Zhu.

</span>
<span class="ltx_bibblock">Additively homomorphical encryption based deep neural network for
asymmetrically collaborative machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib255.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.06849</em>, 2020b.

</span>
</li>
<li id="bib.bib256" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Zhu [2020c]</span>
<span class="ltx_bibblock">
Y. Zhang and H. Zhu.

</span>
<span class="ltx_bibblock">Discrete wasserstein autoencoders for document retrieval.

</span>
<span class="ltx_bibblock">In <em id="bib.bib256.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</em>, pages 8159–8163. IEEE,
2020c.

</span>
</li>
<li id="bib.bib257" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022b]</span>
<span class="ltx_bibblock">
Y. Zhang, H. Zhu, Z. Meng, P. Koniusz, and I. King.

</span>
<span class="ltx_bibblock">Graph-adaptive rectified linear unit for graph neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib257.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Web Conference 2022</em>, pages
1331–1339, 2022b.

</span>
</li>
<li id="bib.bib258" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022c]</span>
<span class="ltx_bibblock">
Y. Zhang, H. Zhu, Z. Song, P. Koniusz, and I. King.

</span>
<span class="ltx_bibblock">Costa: Covariance-preserving feature augmentation for graph
contrastive learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib258.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining</em>, pages 2524–2534, 2022c.

</span>
</li>
<li id="bib.bib259" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022d]</span>
<span class="ltx_bibblock">
Y. Zhang, H. Zhu, Z. Song, P. Koniusz, and I. King.

</span>
<span class="ltx_bibblock">Spectral feature augmentation for graph contrastive learning and
beyond.

</span>
<span class="ltx_bibblock"><em id="bib.bib259.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.01026</em>, 2022d.

</span>
</li>
<li id="bib.bib260" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2022e]</span>
<span class="ltx_bibblock">
Z. Zhang, X. Cao, J. Jia, and N. Z. Gong.

</span>
<span class="ltx_bibblock">Fldetector: Defending federated learning against model poisoning
attacks via detecting malicious clients.

</span>
<span class="ltx_bibblock">In <em id="bib.bib260.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining</em>, pages 2545–2555, 2022e.

</span>
</li>
<li id="bib.bib261" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2020a]</span>
<span class="ltx_bibblock">
B. Zhao, K. R. Mopuri, and H. Bilen.

</span>
<span class="ltx_bibblock">idlg: Improved deep leakage from gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib261.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.02610</em>, 2020a.

</span>
</li>
<li id="bib.bib262" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2021]</span>
<span class="ltx_bibblock">
B. Zhao, K. Fan, K. Yang, Z. Wang, H. Li, and Y. Yang.

</span>
<span class="ltx_bibblock">Anonymous and privacy-preserving federated learning with industrial
big data.

</span>
<span class="ltx_bibblock"><em id="bib.bib262.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, 17(9):6314–6323, 2021.

</span>
</li>
<li id="bib.bib263" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2022]</span>
<span class="ltx_bibblock">
B. Zhao, P. Sun, T. Wang, and K. Jiang.

</span>
<span class="ltx_bibblock">Fedinv: Byzantine-robust federated learning by inversing local model
updates.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li id="bib.bib264" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2020b]</span>
<span class="ltx_bibblock">
K. Zhao, W. Xi, Z. Wang, J. Zhao, R. Wang, and Z. Jiang.

</span>
<span class="ltx_bibblock">Smss: Secure member selection strategy in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib264.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, 35(4):37–49,
2020b.

</span>
</li>
<li id="bib.bib265" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2018]</span>
<span class="ltx_bibblock">
Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib265.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00582</em>, 2018.

</span>
</li>
<li id="bib.bib266" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2020c]</span>
<span class="ltx_bibblock">
Y. Zhao, J. Zhao, M. Yang, T. Wang, N. Wang, L. Lyu, D. Niyato, and K.-Y. Lam.

</span>
<span class="ltx_bibblock">Local differential privacy-based federated learning for internet of
things.

</span>
<span class="ltx_bibblock"><em id="bib.bib266.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 8(11):8836–8853, 2020c.

</span>
</li>
<li id="bib.bib267" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. [2020]</span>
<span class="ltx_bibblock">
H. Zheng, H. Hu, and Z. Han.

</span>
<span class="ltx_bibblock">Preserving user privacy for machine learning: local differential
privacy or federated machine learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib267.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, 35(4):5–14,
2020.

</span>
</li>
<li id="bib.bib268" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. [2021a]</span>
<span class="ltx_bibblock">
H. Zhu, J. Xu, S. Liu, and Y. Jin.

</span>
<span class="ltx_bibblock">Federated learning on non-iid data: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib268.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, 465:371–390, 2021a.

</span>
</li>
<li id="bib.bib269" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. [2017]</span>
<span class="ltx_bibblock">
J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros.

</span>
<span class="ltx_bibblock">Unpaired image-to-image translation using cycle-consistent
adversarial networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib269.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 2223–2232, 2017.

</span>
</li>
<li id="bib.bib270" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. [2019]</span>
<span class="ltx_bibblock">
L. Zhu, Z. Liu, and S. Han.

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib270.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li id="bib.bib271" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. [2022]</span>
<span class="ltx_bibblock">
W. Zhu, M. Wei, X. Li, and Q. Li.

</span>
<span class="ltx_bibblock">Securebinn: 3-party secure computation for binarized neural network
inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib271.1.1" class="ltx_emph ltx_font_italic">European Symposium on Research in Computer Security</em>, pages
275–294. Springer, 2022.

</span>
</li>
<li id="bib.bib272" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. [2021b]</span>
<span class="ltx_bibblock">
Z. Zhu, J. Hong, and J. Zhou.

</span>
<span class="ltx_bibblock">Data-free knowledge distillation for heterogeneous federated
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib272.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
12878–12889. PMLR, 2021b.

</span>
</li>
<li id="bib.bib273" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ziller et al. [2021]</span>
<span class="ltx_bibblock">
A. Ziller, A. Trask, A. Lopardo, B. Szymkow, B. Wagner, E. Bluemke, J.-M.
Nounahon, J. Passerat-Palmbach, K. Prakash, N. Rose, et al.

</span>
<span class="ltx_bibblock">Pysyft: A library for easy federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib273.1.1" class="ltx_emph ltx_font_italic">Federated Learning Systems</em>, pages 111–139. Springer, 2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.10636" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.10637" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.10637">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.10637" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.10638" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 00:49:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
