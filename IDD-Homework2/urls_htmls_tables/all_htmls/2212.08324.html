<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.08324] Mobile Augmented Reality with Federated Learning in the Metaverse</title><meta property="og:description" content="The Metaverse is deemed the next evolution of the Internet and has received much attention recently. Metaverse applications via mobile augmented reality (MAR) require rapid and accurate object detection to mix digital …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Mobile Augmented Reality with Federated Learning in the Metaverse">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Mobile Augmented Reality with Federated Learning in the Metaverse">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.08324">

<!--Generated on Fri Mar  1 10:56:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Metaverse,  augmented reality,  virtual reality,  federated learning.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Mobile Augmented Reality with Federated Learning in the Metaverse</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 
<br class="ltx_break">Xinyu Zhou,
Jun Zhao
</span><span class="ltx_author_notes">The authors are all with Nanyang Technological University, Singapore. Emails: xinyu003@e.ntu.edu.sg, JunZHAO@ntu.edu.sg</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The Metaverse is deemed the next evolution of the Internet and has received much attention recently. Metaverse applications via mobile augmented reality (MAR) require rapid and accurate object detection to mix digital data with the real world. As mobile devices evolve, their computational capabilities are increasing, and thus their computational resources can be leveraged to train machine learning models. In light of the increasing concerns of user privacy and data security, federated learning (FL) has become a promising distributed learning framework for privacy-preserving analytics. In this article, FL and MAR are brought together in the Metaverse. We discuss the necessity and rationality of the combination of FL and MAR. The prospective technologies that support FL and MAR in the Metaverse are also discussed. In addition, existing challenges that prevent the fulfillment of FL and MAR in the Metaverse and several application scenarios are presented. Finally, <span id="id1.id1.1" class="ltx_text" style="color:#000000;">three</span> case studies of Metaverse FL-MAR systems are demonstrated.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Metaverse, augmented reality, virtual reality, federated learning.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The Metaverse has become a hot topic recently.
Mark Zuckerberg made the term famous in 2021 when he announced that Facebook would change its name to Meta and shift its future to build Metaverse technologies. The
Metaverse integrates augmented reality (AR), virtual reality (VR) and 3D technologies to create a fully immersive virtual world.
Mobile augmented reality (MAR) brings the Metaverse to mobile user equipments.
With the development of mobile technologies, it has been increasingly common for mobile users to leverage AR services to interact and entertain themselves in the real world.
As machine learning technologies are applied to mobile devices, people are developing more intelligent MAR applications in the Metaverse scenarios such as daily communications, entertainment, medical care, travel, transportation, etc.
Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> depicts a scenario where users can see descriptions of each building.
Such MAR applications require rapid and accurate object detection to mix digital data with the real world. With the fast development of wearable and mobile devices (e.g., Google Glass, Microsoft Hololens), such a scenario is not a figment of the imagination. Researchers have implemented effective object detection algorithms on mobile devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Usually, current machine learning models require large amounts of data for training to achieve good performance, whereas it is a challenging task to collect those data. As concerns about data security and privacy increase, related regulations and laws are being introduced one after another. Hence, considering the growing difficulty of collecting sensitive datasets to a server for centralized training, distributed learning is a big trend in the future. In an MAR system, devices can train their object detection models separately. However, a mobile device can only store or collect limited data, resulting in a less accurate model. To address this, federated learning (FL) can be incorporated into the MAR system.
FL was proposed by Google in 2017 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. It allows each device to train a shared model collaboratively without sharing local data with others. As shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, after a few local iterations, each device uploads its local model parameter to a central base station, and the station will send back an updated global model to each device for continuous training. We refer to the system as the FL-MAR system.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2212.08324/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="360" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;color:#000000;">The general system model of mobile augmented reality (MAR) with federated learning (FL) in the Metaverse.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Integrating FL into the design of the MAR system poses some challenges. First, limited communication and computing resources can lead to latency between the server and users. Second, achieving a satisfactory model often requires many local iterations and communication times, which also adds a large amount of energy consumption for mobile devices. Moreover, latency and energy consumption are often in conflict. It is necessary to find an appropriate resource allocation strategy to optimize latency and energy consumption. Besides, in the FL-MAR system, the video frame resolution affects the object recognition accuracy, and it influences the computation energy and time when training on each device.
Hence, to minimize latency and energy consumption and maximize the detection accuracy, we should find how to assign communication and computation resources (i.e., transmission power, bandwidth, CPU frequency and video frame resolution) for each device.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This article first discusses promising technologies for <span id="S1.p4.1.1" class="ltx_text">FL-MAR</span> in the Metaverse in Section <a href="#S2" title="II Enabling Technologies for FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. Then, in Section <a href="#S3" title="III Challenges for FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we present existing challenges for the applications. Section <a href="#S4" title="IV Applications of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> demonstrates various application scenarios of FL-MAR in the Metaverse. Finally, Section <a href="#S5" title="V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> eloaborates three case studies of FL-MAR systems. The <span id="S1.p4.1.2" class="ltx_text" style="color:#000000;">system diagram</span> of FL-MAR is illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The contributions are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text" style="color:#000000;">We are the first to provide the essential design requirements of incorporating FL and MAR into the Metaverse. These design requirements include efficient communication systems, the state-of-the-art FL schemes, scalable deployment and reliability.</span></p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Challenges in the applications of FL-MAR to the Metaverse are also listed from different aspects, including limited communication/communication resources, security and privacy, <span id="S1.I1.i2.p1.1.1" class="ltx_text" style="color:#000000;">non-IID and unbalanced data</span>, etc.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">To demonstrate the practicality, we demonstrate case studies of FL-MAR systems in the Metaverse. One is FDMA-enabled, and the other is based on NOMA. <span id="S1.I1.i3.p1.1.1" class="ltx_text" style="color:#000000;">We also explore the impact of non-IID, unbalanced data, and image resolutions on model performance.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Enabling Technologies for FL-MAR in the Metaverse</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section lists some technologies needed for applying FL and MAR to the Metaverse. <span id="S2.p1.1.1" class="ltx_text" style="color:#000000;">These technologies have the potential for constructing efficient communication systems. Besides, the state-of-the-art FL algorithms that can contribute to the Metaverse are discussed.</span></p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Channel access methods</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">Frequency Division Multiple Access (FDMA)</span>. FDMA is a channelization protocol that divides the bandwidth into non-overlapping channels and assign each channel to separate users.
FDMA is one of the most commonly used analog multiple access methods. It has some advantages: 1) It is technically easy to be implemented. 2) Signals can be transmitted simultaneously while not interfering with each other.
Moreover, FDMA also has some disadvantages: 1) Bandwidth utilization is limited since channels will be idle if users do not utilize them. 2) If many signals of different frequencies are transmitted simultaneously, <span id="S2.SS1.p1.1.2" class="ltx_text">inter-modulation</span> distortion is possible to happen at the transponder.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Time Division Multiple Access (TDMA)</span>. TDMA allows different users to share the same frequency by dividing each channel into different time intervals. At each time interval, the frequency is used for one user exclusively. Compared to FDMA, the advantages of TDMA are: 1) The transmission rate is flexible because multiple slots can be allocated to one user. 2) It can handle the changeable bit rate.
However, the disadvantages include the implementation complexity and the requirement of synchronization.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Non-orthogonal Multiple Access (NOMA)</span>. NOMA has been seen as a promising technology for intensifying the throughput in future wireless systems. Unlike conventional orthogonal multiple access (OMA), it enables multiple users on the same channel to be multiplexed to maximize the throughput and lower the latency of the system. It adopts superposition coding at the transmitter and utilizes successive interference cancellation (SIC) at the receiver to distinguish signals of users. Hence, it increases OMA’s rate region.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">For other channel access schemes, such as CDMA, SDMA and OFDMA, interested readers can refer to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Semantic Communication</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Semantic communication has been deemed the breakthrough of Shannon’s paradigm as it transmits only the relevant semantic information about the specific resource. It does not aim at the accurate transmission of bit sequences, but rather focuses on transmitting information in the form of semantic structures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Hence, the data traffic can be significantly lowered, which is why it can be one of the promising solutions leading to an efficient communication network in the Metaverse.
Studies of semantic communication for the Metaverse are in the early stage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
<span id="S2.SS2.p1.1.1" class="ltx_text" style="color:#000000;">One of the challenges of FL-MAR in the Metaverse is the high communication overhead, which is the bottleneck of FL itself. Considering the scenario of MAR, there might be more frequent communication. Therefore, to overcome this bottleneck, a potential solution may be to not transmit the raw data during the communication but instead use semantic communications.</span></p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Over-the-Air Computation </span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Over-the-air computation (AirComp) enables computation function by adding the analog wave in a multiple-access channel. By utilizing the interference for implementing the computation function, the wireless channel can be used as a computer. In a distributed system, the signals sent by mobile devices are superposed over the air and aggregated by the receiver as a weighted sum. The weights represent channel coefficients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
In the Metaverse, numerous devices are connected to communicate through the communication network. Large amounts of data are transmitted by various devices simultaneously while devices wait for immediate feedback. The advent of over-the-air computation may help to build low-latency communication networks in the Metaverse.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.5.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.6.2" class="ltx_text ltx_font_italic">Mobile Edge Computing</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Before the emergence of edge computing, cloud computing was the new paradigm of computing.
Generally, clouds are servers (e.g., data centers) that can be approached through the Internet. However, such servers are usually located far away from user devices, resulting in long latency. In 2014, European Telecommunications Standard Institute (ETSI) proposed the concept of mobile edge computing (MEC). In the IT service environment, MEC equips cloud-computing capabilities at the edge of mobile networks in the vicinity of mobile users. It aims at reducing latency and providing high-efficient network operations and services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
MEC is deployed at access points, such as small base stations, edge servers, users’ computers, etc. FL-MAR systems consist of massive mobile devices. Hence, if utilizing the idle computing resources of mobile resources through MEC, the energy consumption and latency in communication networks in the Metaverse can be significantly saved.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS5.5.1.1" class="ltx_text">II-E</span> </span><span id="S2.SS5.6.2" class="ltx_text ltx_font_italic">Blockchain and Cryptocurrency</span>
</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">Blockchain, which is a distributed ledger, first appeared in 1991.
It stores digital data in blocks, and the blocks are strung together via cryptography. The data is time-irreversible by leveraging cryptographic hash functions. With the merits of transparency and security, blockchain has numerous prospective applications in finance, government, commerce, etc. <span id="S2.SS5.p1.1.1" class="ltx_text" style="color:#000000;">In the Metaverse, blockchain technology can be utilized to build a privacy-preserving FL framework, as shown by Kang <span id="S2.SS5.p1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Blockchain can keep the records of FL model updates transparently while providing a secure approach to aggregating models.</span>
To protect user privacy, cryptocurrencies are also essential in the Metaverse. Cryptocurrencies (e.g., Bitcoin, Litecoin, Ethereum) are powered by blockchain.
Additionally, cryptocurrencies are not physical, they exist only in the decentralized network, and their creation is determined by an algorithm (or protocol).
<span id="S2.SS5.p1.1.2" class="ltx_text" style="color:#000000;">Therefore, cryptocurrencies or some other tokens can be utilized by blockchain as rewards to encourage users to participate in FL. Additionally, blockchain can store the raw data and the digital assets generated by MAR users in a secure and transparent environment, leading to a decentralized virtual management world.</span></p>
</div>
</section>
<section id="S2.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS6.5.1.1" class="ltx_text">II-F</span> </span><span id="S2.SS6.6.2" class="ltx_text ltx_font_italic">Digital Twin</span>
</h3>

<div id="S2.SS6.p1" class="ltx_para">
<p id="S2.SS6.p1.1" class="ltx_p"><span id="S2.SS6.p1.1.1" class="ltx_text" style="color:#000000;">Digital twins represent the virtual models of the physical objects within the Metaverse by leveraging advanced modeling technologies. They monitor and simulate physical objects in the real world with real-time data.
Besides, the data from physical objects can be utilized and adapted for self-learning in the Metaverse </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS6.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S2.SS6.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS6.p1.1.4" class="ltx_text" style="color:#000000;">.
Digital twins have already been used in numerous scenarios, including manufacturing, healthcare, etc. Moreover, digital twins contribute to the real-time prediction and maintenance of a system. For example, complex engine systems can be simulated by digital twins to figure out maintenance cycles. Hence, digital twins can help integrate physical assets and the virtual environment, leading to the permeation of the Metaverse in each aspect of life.</span></p>
</div>
</section>
<section id="S2.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS7.5.1.1" class="ltx_text">II-G</span> </span><span id="S2.SS7.6.2" class="ltx_text ltx_font_italic">The State-of-the-Art FL Schemes</span>
</h3>

<div id="S2.SS7.p1" class="ltx_para">
<p id="S2.SS7.p1.1" class="ltx_p"><span id="S2.SS7.p1.1.1" class="ltx_text" style="color:#000000;">FL schemes can be classified from different perspectives, such as data distribution, privacy &amp; security, communication strategies, aggregation strategies, application scenarios, etc. This article mainly focuses on two perspectives: data distribution and privacy &amp; security.</span></p>
</div>
<div id="S2.SS7.p2" class="ltx_para">
<p id="S2.SS7.p2.1" class="ltx_p"><span id="S2.SS7.p2.1.1" class="ltx_text ltx_font_italic" style="color:#000000;">Data distribution</span><span id="S2.SS7.p2.1.2" class="ltx_text" style="color:#000000;">. The FL schemes can be categorized by the data distribution into horizontal FL, vertical FL and federated transfer learning. Horizontal FL refers to scenarios that the features of distributed data on each client are similar, but the data are not the same. The FL proposed by Google </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS7.p2.1.3.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S2.SS7.p2.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS7.p2.1.5" class="ltx_text" style="color:#000000;"> belongs to this category.
Compared to horizontal FL, the data of vertical FL does not share the same features.
Federated transfer learning can be applied to scenarios with insufficient users and overlapping features </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS7.p2.1.6.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S2.SS7.p2.1.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS7.p2.1.8" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<div id="S2.SS7.p3" class="ltx_para">
<p id="S2.SS7.p3.1" class="ltx_p"><span id="S2.SS7.p3.1.1" class="ltx_text ltx_font_italic" style="color:#000000;">Privacy &amp; security</span><span id="S2.SS7.p3.1.2" class="ltx_text" style="color:#000000;">. The future Metaverse world involves massive data interactions, and user privacy and data security issues will be critical. Some techniques, such as differential privacy, secure multi-party computation and consensus mechanism, can be utilized with FL to enhance privacy:</span>
<br class="ltx_break"><span id="S2.SS7.p3.1.3" class="ltx_text" style="color:#000000;">1). </span><span id="S2.SS7.p3.1.4" class="ltx_text ltx_font_bold" style="color:#000000;">Differential privacy (DP)</span><span id="S2.SS7.p3.1.5" class="ltx_text" style="color:#000000;">. It can be seen as a way of the mathematical definition of privacy, which adds noise to personally sensitive information.
DP ensures that the individual information in the database will not be compromised. The combination of DP and FL is by injecting noise to participating devices’ uploaded parameters </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS7.p3.1.6.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S2.SS7.p3.1.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS7.p3.1.8" class="ltx_text" style="color:#000000;">.</span>
<br class="ltx_break"><span id="S2.SS7.p3.1.9" class="ltx_text" style="color:#000000;">2). </span><span id="S2.SS7.p3.1.10" class="ltx_text ltx_font_bold" style="color:#000000;">Secure multi-party computation (SMC)</span><span id="S2.SS7.p3.1.11" class="ltx_text" style="color:#000000;">. It is a cryptographic protocol that several parties jointly compute an agreed function without exposing each party’s data.
In SMC, data can be shared distributedly with other parties without needing a third-party organization and is still protected.
By utilizing SMC in FL, the uploaded parameters from clients are encrypted, but it is expensive if used in a large distributed environment </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS7.p3.1.12.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S2.SS7.p3.1.13.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS7.p3.1.14" class="ltx_text" style="color:#000000;">. SMC is not a single protocol but a collection of technologies, such as Homomorphic Encryption.</span>
<br class="ltx_break"><span id="S2.SS7.p3.1.15" class="ltx_text" style="color:#000000;">3). </span><span id="S2.SS7.p3.1.16" class="ltx_text ltx_font_bold" style="color:#000000;">Consensus mechanism</span><span id="S2.SS7.p3.1.17" class="ltx_text" style="color:#000000;">.
It could be any mechanism that is </span><span id="S2.SS7.p3.1.18" class="ltx_text" style="color:#000000;">fault-tolerant</span><span id="S2.SS7.p3.1.19" class="ltx_text" style="color:#000000;"> and usually used in blockchain systems to reach a consensus on a data value or a network state among distributed systems (e.g., cryptocurrencies).
In FL, a consensus mechanism can help coordinate, verify, and achieve an agreement on the updates from various clients </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS7.p3.1.20.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S2.SS7.p3.1.21.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS7.p3.1.22" class="ltx_text" style="color:#000000;">. For example, in the blockchain-based FL, blockchain can keep records of model updates and build a secure and transparent environment.</span></p>
</div>
<div id="S2.SS7.p4" class="ltx_para">
<p id="S2.SS7.p4.1" class="ltx_p"><span id="S2.SS7.p4.1.1" class="ltx_text ltx_font_italic" style="color:#000000;">Other asepcts</span><span id="S2.SS7.p4.1.2" class="ltx_text" style="color:#000000;">.
The aforementioned FL schemes do not conflict with each other and can often be combined to meet specific requirements.
Besides, in the Metaverse and MAR applications, personalized FL can be devised to provide personalized contents and services for each user </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS7.p4.1.3.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S2.SS7.p4.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS7.p4.1.5" class="ltx_text" style="color:#000000;">. Usually, communication efficiency will be stressed in FL due to the limited communication resources, and thus resource allocation is integrated into the FL system </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS7.p4.1.6.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S2.SS7.p4.1.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S2.SS7.p4.1.8" class="ltx_text" style="color:#000000;">.
</span><span id="S2.SS7.p4.1.9" class="ltx_text"></span></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Challenges for FL-MAR in the Metaverse</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section discusses the potential challenges of FL-MAR systems in the Metaverse.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Limited communication resources</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The demands of bandwidth in the Metaverse are much more significant than current ordinary games and social entertainment, because the Metaverse virtual world has to render massive surroundings (e.g., trees, flowers), buildings, avatars (or people), etc., simultaneously.
Furthermore, to achieve the immersive experience in the Metaverse, haptic technology is indispensable to create the experience of touch and receive the reactions of the virtual world. However, current communication resources cannot fulfill the need for immediate haptic feedback. Thus, limited communication resources are one of the barriers to the widespread deployment of the Metaverse. To address the limitation, technologies mentioned in Section <a href="#S2" title="II Enabling Technologies for FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> could be utilized, such as semantic communications and MEC.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Limited computation resources</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In the Metaverse, the resource-constrained devices worn by users not only have to train their own FL model but also are responsible for processing newly generated data and converting the raw data into the 3D virtual world. Apparently, today’s mobile devices do not have the computing capability to finish those complex tasks efficiently.
This existing obstacle might be addressed by better MEC mechanisms. MEC assists applications that have requirements of low latency and high bandwidth close to the data source.
Since edge servers are much closer to users than cloud servers, they could provide services with low latency, which is suitable for the Metaverse to provide a real-time and stable immersive VR/AR experience.
However, if the computing tasks are complex and energy-consuming, they can be uploaded to cloud servers, because
they provide robust computing and storage resources. The appropriate combination of edge- and cloud-based applications is essential to maximize the system performance.
</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Security and Privacy</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Our physical world is being transformed into a digital one as time passes. In the Metaverse, people’s lives are changing in the areas of shopping, education, tourism, medical care, etc.
There will be new forms of security risks, including the threats of
scams, identity leakage, and data protection.
Although FL can protect user privacy and data security to a certain extent, users in the Metaverse still expose their sensitive information to the virtual world. Besides, in FL, the model parameter transmission has the potential to leak user privacy.
<span id="S3.SS3.p1.1.1" class="ltx_text" style="color:#000000;"> Besides, future VR/AR in the Metaverse also has the potential to leak user privacy. Table <a href="#S3.T1" title="TABLE I ‣ III-C Security and Privacy ‣ III Challenges for FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> concludes that the main threats exist in FL and VR/AR in the Metaverse. Albeit virtual avatars in the Metaverse will not reveal the individual’s appearance, the actions made by the virtual avatars, the data collected from sensors and threats of various third-party applications can still allow attackers to infer the sensitive information, such as height, age, gender, ethnicity, etc., about individuals.</span></p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.7.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S3.T1.8.2" class="ltx_text" style="font-size:90%;"> Threats in Federated Learning and VR/AR (references <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>)</span></figcaption>
<table id="S3.T1.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.9.1.1" class="ltx_tr">
<th id="S3.T1.9.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="background-color:#EBF4FC;" colspan="3"><span id="S3.T1.9.1.1.1.1" class="ltx_text" style="color:#000000;background-color:#EBF4FC;">Threats in Federated Learning and VR/AR</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.9.2.1" class="ltx_tr">
<th id="S3.T1.9.2.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<td id="S3.T1.9.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#C4DEF5;"><span id="S3.T1.9.2.1.2.1" class="ltx_text" style="color:#000000;background-color:#C4DEF5;">Federated Learning</span></td>
<td id="S3.T1.9.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#C4DEF5;"><span id="S3.T1.9.2.1.3.1" class="ltx_text" style="color:#000000;background-color:#C4DEF5;">VR/AR</span></td>
</tr>
<tr id="S3.T1.9.3.2" class="ltx_tr">
<th id="S3.T1.9.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="background-color:#F8DD9B;"><span id="S3.T1.9.3.2.1.1" class="ltx_text" style="color:#000000;background-color:#F8DD9B;">Source of Vulnerabilities</span></th>
<td id="S3.T1.9.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T1.9.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.9.3.2.2.1.1" class="ltx_tr">
<td id="S3.T1.9.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.3.2.2.1.1.1.1" class="ltx_text" style="color:#000000;">Non-secure communication channels</span></td>
</tr>
<tr id="S3.T1.9.3.2.2.1.2" class="ltx_tr">
<td id="S3.T1.9.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.3.2.2.1.2.1.1" class="ltx_text" style="color:#000000;">Data manipulations</span></td>
</tr>
<tr id="S3.T1.9.3.2.2.1.3" class="ltx_tr">
<td id="S3.T1.9.3.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.3.2.2.1.3.1.1" class="ltx_text" style="color:#000000;">Vulnerable aggregation algorithms</span></td>
</tr>
</table>
</td>
<td id="S3.T1.9.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T1.9.3.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.9.3.2.3.1.1" class="ltx_tr">
<td id="S3.T1.9.3.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.3.2.3.1.1.1.1" class="ltx_text" style="color:#000000;">Raw data on hardware</span></td>
</tr>
<tr id="S3.T1.9.3.2.3.1.2" class="ltx_tr">
<td id="S3.T1.9.3.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.3.2.3.1.2.1.1" class="ltx_text" style="color:#000000;">Client-side applications</span></td>
</tr>
<tr id="S3.T1.9.3.2.3.1.3" class="ltx_tr">
<td id="S3.T1.9.3.2.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.3.2.3.1.3.1.1" class="ltx_text" style="color:#000000;">Third-party servers</span></td>
</tr>
<tr id="S3.T1.9.3.2.3.1.4" class="ltx_tr">
<td id="S3.T1.9.3.2.3.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.3.2.3.1.4.1.1" class="ltx_text" style="color:#000000;">End users of the same application</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T1.9.4.3" class="ltx_tr">
<th id="S3.T1.9.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="background-color:#F8DD9B;"><span id="S3.T1.9.4.3.1.1" class="ltx_text" style="color:#000000;background-color:#F8DD9B;">Privacy Threats</span></th>
<td id="S3.T1.9.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T1.9.4.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.9.4.3.2.1.1" class="ltx_tr">
<td id="S3.T1.9.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.4.3.2.1.1.1.1" class="ltx_text" style="color:#000000;">The inference of training data</span></td>
</tr>
<tr id="S3.T1.9.4.3.2.1.2" class="ltx_tr">
<td id="S3.T1.9.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.4.3.2.1.2.1.1" class="ltx_text" style="color:#000000;">Data leakage/reconstruction from other clients</span></td>
</tr>
<tr id="S3.T1.9.4.3.2.1.3" class="ltx_tr">
<td id="S3.T1.9.4.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.4.3.2.1.3.1.1" class="ltx_text" style="color:#000000;">GANs (generative adversarial network)-based inference</span></td>
</tr>
</table>
</td>
<td id="S3.T1.9.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S3.T1.9.4.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.9.4.3.3.1.1" class="ltx_tr">
<td id="S3.T1.9.4.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T1.9.4.3.3.1.1.1.1" class="ltx_text" style="color:#000000;">Inference of personal information about</span></td>
</tr>
<tr id="S3.T1.9.4.3.3.1.2" class="ltx_tr">
<td id="S3.T1.9.4.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T1.9.4.3.3.1.2.1.1" class="ltx_text" style="color:#000000;">age, gender, height, ethnicity, etc.</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T1.9.5.4" class="ltx_tr">
<th id="S3.T1.9.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="background-color:#F8DD9B;"><span id="S3.T1.9.5.4.1.1" class="ltx_text" style="color:#000000;background-color:#F8DD9B;">Security Threats</span></th>
<td id="S3.T1.9.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" colspan="2">
<table id="S3.T1.9.5.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.9.5.4.2.1.1" class="ltx_tr">
<td id="S3.T1.9.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.5.4.2.1.1.1.1" class="ltx_text" style="color:#000000;">Data/model poisoning, data tampering,</span></td>
</tr>
<tr id="S3.T1.9.5.4.2.1.2" class="ltx_tr">
<td id="S3.T1.9.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.5.4.2.1.2.1.1" class="ltx_text" style="color:#000000;">GANs-based attacks, eavesdropping,</span></td>
</tr>
<tr id="S3.T1.9.5.4.2.1.3" class="ltx_tr">
<td id="S3.T1.9.5.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T1.9.5.4.2.1.3.1.1" class="ltx_text" style="color:#000000;">system malfunction, backdoor attacks</span></td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Non-IID and Unbalanced Data</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p"><span id="S3.SS4.p1.1.1" class="ltx_text" style="color:#000000;">The non-IID and unbalanced data distribution is a long-existed challenge for distributed learning.
The purpose of FL was to mitigate the negative impact of non-IID and unbalanced data distributions </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS4.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S3.SS4.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S3.SS4.p1.1.4" class="ltx_text" style="color:#000000;">, but non-IID data still affect the model performance and convergence. Besides, MAR applications involve a variety of data sources, such as raw sensor data, videos, images, etc. Hence, the data heterogeneity results in the difficulty of processing the data for training and updating models.
Effective segmentation methods and datasets may solve different non-IID situations effectively </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS4.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S3.SS4.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S3.SS4.p1.1.7" class="ltx_text" style="color:#000000;">.
Moreover, higher image resolution will result in higher model accuracy but with higher energy consumption and training time. Therefore, how to adequately adjust the image resolution for each mobile device is also a challenge. A more detailed case study about the influence of non-IID, unbalanced data and image resolution in FL-MAR systems is provided in Section </span><a href="#S5.SS4" title="V-D Non-IID and unbalanced data distribution in FL-MAR ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-D</span></span></a><span id="S3.SS4.p1.1.8" class="ltx_text" style="color:#000000;">.
</span><span id="S3.SS4.p1.1.9" class="ltx_text"></span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Applications of FL-MAR in the Metaverse</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section lists some scenarios in which MAR and FL are applied to the Metaverse. Fig. <a href="#S4.F2" title="Figure 2 ‣ IV Applications of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> depicts the scenarios including autonomous driving, shopping, education, healthcare and game playing.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2212.08324/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="294" height="147" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.4.2" class="ltx_text" style="font-size:90%;color:#000000;">The application scenarios of FL and MAR in the Metaverse.</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Autonomous Driving</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Autonomous vehicles are becoming a feasible solution for transportation in the future. Recently, deep learning has been a popular approach to the application of autonomous driving in terms of object detection, obstacle avoidance, etc.
Considering the fact that the capabilities of hardware storage and computation are improving, training models locally is not only beneficial for data security and user privacy but also reduces network energy consumption and latency.
Since different cars experience various environments, such as weather and lighting conditions, incorporating FL into this scenario will help each vehicle build a more accurate model.
Additionally, since Metaverse has immediate physical-virtual world interaction characteristics, it can simulate various kinds of driving situations, including some rare cases. Therefore, it helps
test whether self-driving cars are safe and reliable in various extreme conditions.
</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Shopping</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Online shopping has become a part of people’s lives.
As the number of MAR applications grows, online shopping also enjoys this convenience. For instance, IKEA, the company that sells ready-to-assemble furniture, appliances and home services, equips its app with AR capabilities that allow users to place 3D models of equal scale with the real size virtually in their homes.
Adidas also launched the AR footwear try-on function in its iOS app. <span id="S4.SS2.p1.1.1" class="ltx_text" style="color:#000000;">The shopping scenario of <span id="S4.SS2.p1.1.1.1" class="ltx_text">Fig. <a href="#S4.F2" title="Figure 2 ‣ IV Applications of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></span> illustrates both two examples of MAR applications</span>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">However, it is evident that the MAR applications still need improvement. Each person has different looks and living places. Therefore, by incorporating FL, the mobile device can learn its own model to fit the specific person. Additionally, in the Metaverse, people will reveal similarities to their real lives in the virtual
worlds due to more time spent virtually.
Products such as digital clothing, furniture, cosmetics and so forth may have a similar status to purchases in the real world.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Education</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The Metaverse will transform the educational environment in the future <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Different from traditional in-person learning and online learning, Metaverse-based learning will be an environment which is a mixture of the virtual and real world. It allows students to interact with each other in a virtual and decentralized setting and join various complex learning activities. In light of the profusion of online learning experiences during the Covid-19 period, Metaverse-based learning is much needed now. For example, in geography classes, students can immerse themselves through VR headsets in geography and experience the differences between different climates in different regions.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Healthcare</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text" style="color:#000000;">Intelligent healthcare has been studied by scholars in biomedical engineering in recent years. For example, in 2022, a study envisioned the benefits the Metaverse could bring to the healthcare domain </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S4.SS4.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p1.1.4" class="ltx_text" style="color:#000000;">.
With the emergence of virtual clinics and hospitals, doctors could diagnose patients remotely using avatars. For example, after a CT scan, if a patient is diagnosed with heart disease, the patient avatar can simulate several possible pathologies by using different virtual scanners with the help of digital twins </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S4.SS4.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p1.1.7" class="ltx_text" style="color:#000000;">. Other than virtual diagnosis, the Metaverse gives another possibility to medical training. The trainee surgeons can practice surgeries on </span><span id="S4.SS4.p1.1.8" class="ltx_text" style="color:#000000;">3D-constructed</span><span id="S4.SS4.p1.1.9" class="ltx_text" style="color:#000000;"> bodies, which helps to decrease the risk of actual surgeries.
Besides, the raw data generated by various patients will raise privacy concerns. FL and DP can be incorporated to enable the development of AI models used in the healthcare domain and lower the risk of data breaches and privacy violations.</span></p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.5.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.6.2" class="ltx_text ltx_font_italic">Game</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p"><span id="S4.SS5.p1.1.1" class="ltx_text" style="color:#000000;">As the game-playing scenario illustrated in Fig. </span><a href="#S4.F2" title="Figure 2 ‣ IV Applications of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS5.p1.1.2" class="ltx_text" style="color:#000000;">, users will have an immersive game-playing experience in the Metaverse. Unlike common AR/VR games, the game playing in the Metaverse will stress the importance of immersion, the low latency will provide real-time feedback, and multiplayer interactions will be smoother than today’s AR/VR games. Although there are some Metaverse-related games such as Decentraland and the Sandbox on the market, they do not truly achieve an immersive gaming experience. Instead, they utilize the Metaverse worldview to allow users to create contents in the form of Non-Fungible Tokens (NFTs) and make profits by using cryptocurrencies.
Besides, FL can bring personalized gaming experiences depending on each player’s preferences, behaviors and interests. These raw data could feed into the training of game AI. For example, the non-player characters can talk with different players in different emotions and tones based on their personalities.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Case Studies of FL-MAR in the Metaverse</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we present three case studies of FL-MAR in the Metaverse. One FL-MAR system’s channel access scheme is FDMA, and the other one uses NOMA.
We also study the impact of non-IID, unbalanced data distributions and image resolution on the model performance of the FL-MAR system.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">FDMA-enabled FL-MAR in the Metaverse</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">First, we investigate a basic FL-MAR system via FDMA. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we formulate a weighted sum of total energy, time consumption and accuracy by using three weight parameters.
We optimize the allocation of the bandwidth, transmission power, CPU frequency setting and MAR video frame resolution for each participating device in the Metaverse. By setting different weight parameters, our resource allocation algorithm can adapt to different requirements of the FL-MAR system, either <span id="S5.SS1.p1.1.1" class="ltx_text">time-sensitive</span> or energy-hungry.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.11" class="ltx_p">We assume there are <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="40" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mn id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><cn type="integer" id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">40</annotation></semantics></math> users in the system. Fig. <a href="#S5.F3" title="Figure 3 ‣ V-A FDMA-enabled FL-MAR in the Metaverse ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> contains two subfigures. One shows the total energy consumption, and the other is the total time consumption. We choose three pairs of weight parameters to compare our resource allocation algorithm with a random allocation strategy and <span id="S5.SS1.p2.11.5" class="ltx_text" style="color:#000000;">the algorithm proposed by Yang <em id="S5.SS1.p2.11.5.1" class="ltx_emph ltx_font_italic">et a.l</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite></span> (we name it “Scheme 1”) under different maximum transmit power limits. Note that <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="w_{1}" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><msub id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml"><mi id="S5.SS1.p2.2.m2.1.1.2" xref="S5.SS1.p2.2.m2.1.1.2.cmml">w</mi><mn id="S5.SS1.p2.2.m2.1.1.3" xref="S5.SS1.p2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><apply id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.2.m2.1.1.3.cmml" xref="S5.SS1.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">w_{1}</annotation></semantics></math> is the weight parameter of energy consumption, and <math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="w_{2}" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><msub id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml"><mi id="S5.SS1.p2.3.m3.1.1.2" xref="S5.SS1.p2.3.m3.1.1.2.cmml">w</mi><mn id="S5.SS1.p2.3.m3.1.1.3" xref="S5.SS1.p2.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><apply id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.3.m3.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p2.3.m3.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.3.m3.1.1.3.cmml" xref="S5.SS1.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">w_{2}</annotation></semantics></math> is the weight parameter of time consumption. The weight parameter of the model accuracy is fixed because we focus on the energy and time consumption here.
If <math id="S5.SS1.p2.4.m4.1" class="ltx_Math" alttext="w_{1}" display="inline"><semantics id="S5.SS1.p2.4.m4.1a"><msub id="S5.SS1.p2.4.m4.1.1" xref="S5.SS1.p2.4.m4.1.1.cmml"><mi id="S5.SS1.p2.4.m4.1.1.2" xref="S5.SS1.p2.4.m4.1.1.2.cmml">w</mi><mn id="S5.SS1.p2.4.m4.1.1.3" xref="S5.SS1.p2.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><apply id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.4.m4.1.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S5.SS1.p2.4.m4.1.1.2.cmml" xref="S5.SS1.p2.4.m4.1.1.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.4.m4.1.1.3.cmml" xref="S5.SS1.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">w_{1}</annotation></semantics></math> (resp., <math id="S5.SS1.p2.5.m5.1" class="ltx_Math" alttext="w_{2}" display="inline"><semantics id="S5.SS1.p2.5.m5.1a"><msub id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml"><mi id="S5.SS1.p2.5.m5.1.1.2" xref="S5.SS1.p2.5.m5.1.1.2.cmml">w</mi><mn id="S5.SS1.p2.5.m5.1.1.3" xref="S5.SS1.p2.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.1b"><apply id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.5.m5.1.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.p2.5.m5.1.1.2.cmml" xref="S5.SS1.p2.5.m5.1.1.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.5.m5.1.1.3.cmml" xref="S5.SS1.p2.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.1c">w_{2}</annotation></semantics></math>) becomes larger, the
proposed algorithm will emphasize minimizing the energy cost (resp., time consumption). Hence, it can be seen obviously from each bar that as <math id="S5.SS1.p2.6.m6.1" class="ltx_Math" alttext="w_{1}" display="inline"><semantics id="S5.SS1.p2.6.m6.1a"><msub id="S5.SS1.p2.6.m6.1.1" xref="S5.SS1.p2.6.m6.1.1.cmml"><mi id="S5.SS1.p2.6.m6.1.1.2" xref="S5.SS1.p2.6.m6.1.1.2.cmml">w</mi><mn id="S5.SS1.p2.6.m6.1.1.3" xref="S5.SS1.p2.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.6.m6.1b"><apply id="S5.SS1.p2.6.m6.1.1.cmml" xref="S5.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.6.m6.1.1.1.cmml" xref="S5.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S5.SS1.p2.6.m6.1.1.2.cmml" xref="S5.SS1.p2.6.m6.1.1.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.6.m6.1.1.3.cmml" xref="S5.SS1.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.6.m6.1c">w_{1}</annotation></semantics></math> (resp. <math id="S5.SS1.p2.7.m7.1" class="ltx_Math" alttext="w_{2}" display="inline"><semantics id="S5.SS1.p2.7.m7.1a"><msub id="S5.SS1.p2.7.m7.1.1" xref="S5.SS1.p2.7.m7.1.1.cmml"><mi id="S5.SS1.p2.7.m7.1.1.2" xref="S5.SS1.p2.7.m7.1.1.2.cmml">w</mi><mn id="S5.SS1.p2.7.m7.1.1.3" xref="S5.SS1.p2.7.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.7.m7.1b"><apply id="S5.SS1.p2.7.m7.1.1.cmml" xref="S5.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.7.m7.1.1.1.cmml" xref="S5.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S5.SS1.p2.7.m7.1.1.2.cmml" xref="S5.SS1.p2.7.m7.1.1.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.7.m7.1.1.3.cmml" xref="S5.SS1.p2.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.7.m7.1c">w_{2}</annotation></semantics></math>) increases, the energy (resp. time) consumption will decrease.
<span id="S5.SS1.p2.11.4" class="ltx_text" style="color:#000000;">Besides, although Scheme 1 has roughly the same time consumption as our proposed algorithm (<math id="S5.SS1.p2.8.1.m1.1" class="ltx_Math" alttext="w_{1}=w_{2}=0.5" display="inline"><semantics id="S5.SS1.p2.8.1.m1.1a"><mrow id="S5.SS1.p2.8.1.m1.1.1" xref="S5.SS1.p2.8.1.m1.1.1.cmml"><msub id="S5.SS1.p2.8.1.m1.1.1.2" xref="S5.SS1.p2.8.1.m1.1.1.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.8.1.m1.1.1.2.2" xref="S5.SS1.p2.8.1.m1.1.1.2.2.cmml">w</mi><mn mathcolor="#000000" id="S5.SS1.p2.8.1.m1.1.1.2.3" xref="S5.SS1.p2.8.1.m1.1.1.2.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S5.SS1.p2.8.1.m1.1.1.3" xref="S5.SS1.p2.8.1.m1.1.1.3.cmml">=</mo><msub id="S5.SS1.p2.8.1.m1.1.1.4" xref="S5.SS1.p2.8.1.m1.1.1.4.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.8.1.m1.1.1.4.2" xref="S5.SS1.p2.8.1.m1.1.1.4.2.cmml">w</mi><mn mathcolor="#000000" id="S5.SS1.p2.8.1.m1.1.1.4.3" xref="S5.SS1.p2.8.1.m1.1.1.4.3.cmml">2</mn></msub><mo mathcolor="#000000" id="S5.SS1.p2.8.1.m1.1.1.5" xref="S5.SS1.p2.8.1.m1.1.1.5.cmml">=</mo><mn mathcolor="#000000" id="S5.SS1.p2.8.1.m1.1.1.6" xref="S5.SS1.p2.8.1.m1.1.1.6.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.8.1.m1.1b"><apply id="S5.SS1.p2.8.1.m1.1.1.cmml" xref="S5.SS1.p2.8.1.m1.1.1"><and id="S5.SS1.p2.8.1.m1.1.1a.cmml" xref="S5.SS1.p2.8.1.m1.1.1"></and><apply id="S5.SS1.p2.8.1.m1.1.1b.cmml" xref="S5.SS1.p2.8.1.m1.1.1"><eq id="S5.SS1.p2.8.1.m1.1.1.3.cmml" xref="S5.SS1.p2.8.1.m1.1.1.3"></eq><apply id="S5.SS1.p2.8.1.m1.1.1.2.cmml" xref="S5.SS1.p2.8.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p2.8.1.m1.1.1.2.1.cmml" xref="S5.SS1.p2.8.1.m1.1.1.2">subscript</csymbol><ci id="S5.SS1.p2.8.1.m1.1.1.2.2.cmml" xref="S5.SS1.p2.8.1.m1.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.8.1.m1.1.1.2.3.cmml" xref="S5.SS1.p2.8.1.m1.1.1.2.3">1</cn></apply><apply id="S5.SS1.p2.8.1.m1.1.1.4.cmml" xref="S5.SS1.p2.8.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.SS1.p2.8.1.m1.1.1.4.1.cmml" xref="S5.SS1.p2.8.1.m1.1.1.4">subscript</csymbol><ci id="S5.SS1.p2.8.1.m1.1.1.4.2.cmml" xref="S5.SS1.p2.8.1.m1.1.1.4.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.8.1.m1.1.1.4.3.cmml" xref="S5.SS1.p2.8.1.m1.1.1.4.3">2</cn></apply></apply><apply id="S5.SS1.p2.8.1.m1.1.1c.cmml" xref="S5.SS1.p2.8.1.m1.1.1"><eq id="S5.SS1.p2.8.1.m1.1.1.5.cmml" xref="S5.SS1.p2.8.1.m1.1.1.5"></eq><share href="#S5.SS1.p2.8.1.m1.1.1.4.cmml" id="S5.SS1.p2.8.1.m1.1.1d.cmml" xref="S5.SS1.p2.8.1.m1.1.1"></share><cn type="float" id="S5.SS1.p2.8.1.m1.1.1.6.cmml" xref="S5.SS1.p2.8.1.m1.1.1.6">0.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.8.1.m1.1c">w_{1}=w_{2}=0.5</annotation></semantics></math>), our proposed algorithm (<math id="S5.SS1.p2.9.2.m2.2" class="ltx_Math" alttext="w_{1},w_{2}" display="inline"><semantics id="S5.SS1.p2.9.2.m2.2a"><mrow id="S5.SS1.p2.9.2.m2.2.2.2" xref="S5.SS1.p2.9.2.m2.2.2.3.cmml"><msub id="S5.SS1.p2.9.2.m2.1.1.1.1" xref="S5.SS1.p2.9.2.m2.1.1.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.9.2.m2.1.1.1.1.2" xref="S5.SS1.p2.9.2.m2.1.1.1.1.2.cmml">w</mi><mn mathcolor="#000000" id="S5.SS1.p2.9.2.m2.1.1.1.1.3" xref="S5.SS1.p2.9.2.m2.1.1.1.1.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S5.SS1.p2.9.2.m2.2.2.2.3" xref="S5.SS1.p2.9.2.m2.2.2.3.cmml">,</mo><msub id="S5.SS1.p2.9.2.m2.2.2.2.2" xref="S5.SS1.p2.9.2.m2.2.2.2.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.9.2.m2.2.2.2.2.2" xref="S5.SS1.p2.9.2.m2.2.2.2.2.2.cmml">w</mi><mn mathcolor="#000000" id="S5.SS1.p2.9.2.m2.2.2.2.2.3" xref="S5.SS1.p2.9.2.m2.2.2.2.2.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.9.2.m2.2b"><list id="S5.SS1.p2.9.2.m2.2.2.3.cmml" xref="S5.SS1.p2.9.2.m2.2.2.2"><apply id="S5.SS1.p2.9.2.m2.1.1.1.1.cmml" xref="S5.SS1.p2.9.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.9.2.m2.1.1.1.1.1.cmml" xref="S5.SS1.p2.9.2.m2.1.1.1.1">subscript</csymbol><ci id="S5.SS1.p2.9.2.m2.1.1.1.1.2.cmml" xref="S5.SS1.p2.9.2.m2.1.1.1.1.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.9.2.m2.1.1.1.1.3.cmml" xref="S5.SS1.p2.9.2.m2.1.1.1.1.3">1</cn></apply><apply id="S5.SS1.p2.9.2.m2.2.2.2.2.cmml" xref="S5.SS1.p2.9.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.p2.9.2.m2.2.2.2.2.1.cmml" xref="S5.SS1.p2.9.2.m2.2.2.2.2">subscript</csymbol><ci id="S5.SS1.p2.9.2.m2.2.2.2.2.2.cmml" xref="S5.SS1.p2.9.2.m2.2.2.2.2.2">𝑤</ci><cn type="integer" id="S5.SS1.p2.9.2.m2.2.2.2.2.3.cmml" xref="S5.SS1.p2.9.2.m2.2.2.2.2.3">2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.9.2.m2.2c">w_{1},w_{2}</annotation></semantics></math>)=(<math id="S5.SS1.p2.10.3.m3.2" class="ltx_Math" alttext="0.5,0.5" display="inline"><semantics id="S5.SS1.p2.10.3.m3.2a"><mrow id="S5.SS1.p2.10.3.m3.2.3.2" xref="S5.SS1.p2.10.3.m3.2.3.1.cmml"><mn mathcolor="#000000" id="S5.SS1.p2.10.3.m3.1.1" xref="S5.SS1.p2.10.3.m3.1.1.cmml">0.5</mn><mo mathcolor="#000000" id="S5.SS1.p2.10.3.m3.2.3.2.1" xref="S5.SS1.p2.10.3.m3.2.3.1.cmml">,</mo><mn mathcolor="#000000" id="S5.SS1.p2.10.3.m3.2.2" xref="S5.SS1.p2.10.3.m3.2.2.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.10.3.m3.2b"><list id="S5.SS1.p2.10.3.m3.2.3.1.cmml" xref="S5.SS1.p2.10.3.m3.2.3.2"><cn type="float" id="S5.SS1.p2.10.3.m3.1.1.cmml" xref="S5.SS1.p2.10.3.m3.1.1">0.5</cn><cn type="float" id="S5.SS1.p2.10.3.m3.2.2.cmml" xref="S5.SS1.p2.10.3.m3.2.2">0.5</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.10.3.m3.2c">0.5,0.5</annotation></semantics></math>) and (<math id="S5.SS1.p2.11.4.m4.2" class="ltx_Math" alttext="0.9,0.1" display="inline"><semantics id="S5.SS1.p2.11.4.m4.2a"><mrow id="S5.SS1.p2.11.4.m4.2.3.2" xref="S5.SS1.p2.11.4.m4.2.3.1.cmml"><mn mathcolor="#000000" id="S5.SS1.p2.11.4.m4.1.1" xref="S5.SS1.p2.11.4.m4.1.1.cmml">0.9</mn><mo mathcolor="#000000" id="S5.SS1.p2.11.4.m4.2.3.2.1" xref="S5.SS1.p2.11.4.m4.2.3.1.cmml">,</mo><mn mathcolor="#000000" id="S5.SS1.p2.11.4.m4.2.2" xref="S5.SS1.p2.11.4.m4.2.2.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.11.4.m4.2b"><list id="S5.SS1.p2.11.4.m4.2.3.1.cmml" xref="S5.SS1.p2.11.4.m4.2.3.2"><cn type="float" id="S5.SS1.p2.11.4.m4.1.1.cmml" xref="S5.SS1.p2.11.4.m4.1.1">0.9</cn><cn type="float" id="S5.SS1.p2.11.4.m4.2.2.cmml" xref="S5.SS1.p2.11.4.m4.2.2">0.1</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.11.4.m4.2c">0.9,0.1</annotation></semantics></math>) still achieve a better result in terms of energy consumption compared to Scheme 1.</span></p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2212.08324/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="226" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.6.3.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S5.F3.4.2" class="ltx_text" style="font-size:90%;">FDMA-enabled FL-MAR system: simulation results under different transmit power limits. The local epochs and global communication round are <math id="S5.F3.3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.F3.3.1.m1.1b"><mn id="S5.F3.3.1.m1.1.1" xref="S5.F3.3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.F3.3.1.m1.1c"><cn type="integer" id="S5.F3.3.1.m1.1.1.cmml" xref="S5.F3.3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.3.1.m1.1d">10</annotation></semantics></math> and <math id="S5.F3.4.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.F3.4.2.m2.1b"><mn id="S5.F3.4.2.m2.1.1" xref="S5.F3.4.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.F3.4.2.m2.1c"><cn type="integer" id="S5.F3.4.2.m2.1.1.cmml" xref="S5.F3.4.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.4.2.m2.1d">1</annotation></semantics></math>. 
</span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">NOMA-enabled FL-MAR in the Metaverse</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.7" class="ltx_p">Here, we study the NOMA-enabled FL-MAR system in the Metaverse.
We also devise a resource allocation algorithm and show the validity of our algorithm, which jointly optimizes the weighted sum of energy and time consumption. Assume there are <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="40" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mn id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><cn type="integer" id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">40</annotation></semantics></math> users and <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mn id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><cn type="integer" id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">20</annotation></semantics></math> channels. There are <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><mn id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><cn type="integer" id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">2</annotation></semantics></math> users multiplexed on one channel.
In Fig. <a href="#S5.F4" title="Figure 4 ‣ V-B NOMA-enabled FL-MAR in the Metaverse ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we compare three pairs of weight parameters <math id="S5.SS2.p1.4.m4.8" class="ltx_Math" alttext="(w_{1},w_{2})=(0.9,0.1),(0.5,0.5)" display="inline"><semantics id="S5.SS2.p1.4.m4.8a"><mrow id="S5.SS2.p1.4.m4.8.8" xref="S5.SS2.p1.4.m4.8.8.cmml"><mrow id="S5.SS2.p1.4.m4.6.6.2.2" xref="S5.SS2.p1.4.m4.6.6.2.3.cmml"><mo stretchy="false" id="S5.SS2.p1.4.m4.6.6.2.2.3" xref="S5.SS2.p1.4.m4.6.6.2.3.cmml">(</mo><msub id="S5.SS2.p1.4.m4.5.5.1.1.1" xref="S5.SS2.p1.4.m4.5.5.1.1.1.cmml"><mi id="S5.SS2.p1.4.m4.5.5.1.1.1.2" xref="S5.SS2.p1.4.m4.5.5.1.1.1.2.cmml">w</mi><mn id="S5.SS2.p1.4.m4.5.5.1.1.1.3" xref="S5.SS2.p1.4.m4.5.5.1.1.1.3.cmml">1</mn></msub><mo id="S5.SS2.p1.4.m4.6.6.2.2.4" xref="S5.SS2.p1.4.m4.6.6.2.3.cmml">,</mo><msub id="S5.SS2.p1.4.m4.6.6.2.2.2" xref="S5.SS2.p1.4.m4.6.6.2.2.2.cmml"><mi id="S5.SS2.p1.4.m4.6.6.2.2.2.2" xref="S5.SS2.p1.4.m4.6.6.2.2.2.2.cmml">w</mi><mn id="S5.SS2.p1.4.m4.6.6.2.2.2.3" xref="S5.SS2.p1.4.m4.6.6.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S5.SS2.p1.4.m4.6.6.2.2.5" xref="S5.SS2.p1.4.m4.6.6.2.3.cmml">)</mo></mrow><mo id="S5.SS2.p1.4.m4.8.8.5" xref="S5.SS2.p1.4.m4.8.8.5.cmml">=</mo><mrow id="S5.SS2.p1.4.m4.8.8.4.2" xref="S5.SS2.p1.4.m4.8.8.4.3.cmml"><mrow id="S5.SS2.p1.4.m4.7.7.3.1.1.2" xref="S5.SS2.p1.4.m4.7.7.3.1.1.1.cmml"><mo stretchy="false" id="S5.SS2.p1.4.m4.7.7.3.1.1.2.1" xref="S5.SS2.p1.4.m4.7.7.3.1.1.1.cmml">(</mo><mn id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">0.9</mn><mo id="S5.SS2.p1.4.m4.7.7.3.1.1.2.2" xref="S5.SS2.p1.4.m4.7.7.3.1.1.1.cmml">,</mo><mn id="S5.SS2.p1.4.m4.2.2" xref="S5.SS2.p1.4.m4.2.2.cmml">0.1</mn><mo stretchy="false" id="S5.SS2.p1.4.m4.7.7.3.1.1.2.3" xref="S5.SS2.p1.4.m4.7.7.3.1.1.1.cmml">)</mo></mrow><mo id="S5.SS2.p1.4.m4.8.8.4.2.3" xref="S5.SS2.p1.4.m4.8.8.4.3.cmml">,</mo><mrow id="S5.SS2.p1.4.m4.8.8.4.2.2.2" xref="S5.SS2.p1.4.m4.8.8.4.2.2.1.cmml"><mo stretchy="false" id="S5.SS2.p1.4.m4.8.8.4.2.2.2.1" xref="S5.SS2.p1.4.m4.8.8.4.2.2.1.cmml">(</mo><mn id="S5.SS2.p1.4.m4.3.3" xref="S5.SS2.p1.4.m4.3.3.cmml">0.5</mn><mo id="S5.SS2.p1.4.m4.8.8.4.2.2.2.2" xref="S5.SS2.p1.4.m4.8.8.4.2.2.1.cmml">,</mo><mn id="S5.SS2.p1.4.m4.4.4" xref="S5.SS2.p1.4.m4.4.4.cmml">0.5</mn><mo stretchy="false" id="S5.SS2.p1.4.m4.8.8.4.2.2.2.3" xref="S5.SS2.p1.4.m4.8.8.4.2.2.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.8b"><apply id="S5.SS2.p1.4.m4.8.8.cmml" xref="S5.SS2.p1.4.m4.8.8"><eq id="S5.SS2.p1.4.m4.8.8.5.cmml" xref="S5.SS2.p1.4.m4.8.8.5"></eq><interval closure="open" id="S5.SS2.p1.4.m4.6.6.2.3.cmml" xref="S5.SS2.p1.4.m4.6.6.2.2"><apply id="S5.SS2.p1.4.m4.5.5.1.1.1.cmml" xref="S5.SS2.p1.4.m4.5.5.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.4.m4.5.5.1.1.1.1.cmml" xref="S5.SS2.p1.4.m4.5.5.1.1.1">subscript</csymbol><ci id="S5.SS2.p1.4.m4.5.5.1.1.1.2.cmml" xref="S5.SS2.p1.4.m4.5.5.1.1.1.2">𝑤</ci><cn type="integer" id="S5.SS2.p1.4.m4.5.5.1.1.1.3.cmml" xref="S5.SS2.p1.4.m4.5.5.1.1.1.3">1</cn></apply><apply id="S5.SS2.p1.4.m4.6.6.2.2.2.cmml" xref="S5.SS2.p1.4.m4.6.6.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.p1.4.m4.6.6.2.2.2.1.cmml" xref="S5.SS2.p1.4.m4.6.6.2.2.2">subscript</csymbol><ci id="S5.SS2.p1.4.m4.6.6.2.2.2.2.cmml" xref="S5.SS2.p1.4.m4.6.6.2.2.2.2">𝑤</ci><cn type="integer" id="S5.SS2.p1.4.m4.6.6.2.2.2.3.cmml" xref="S5.SS2.p1.4.m4.6.6.2.2.2.3">2</cn></apply></interval><list id="S5.SS2.p1.4.m4.8.8.4.3.cmml" xref="S5.SS2.p1.4.m4.8.8.4.2"><interval closure="open" id="S5.SS2.p1.4.m4.7.7.3.1.1.1.cmml" xref="S5.SS2.p1.4.m4.7.7.3.1.1.2"><cn type="float" id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">0.9</cn><cn type="float" id="S5.SS2.p1.4.m4.2.2.cmml" xref="S5.SS2.p1.4.m4.2.2">0.1</cn></interval><interval closure="open" id="S5.SS2.p1.4.m4.8.8.4.2.2.1.cmml" xref="S5.SS2.p1.4.m4.8.8.4.2.2.2"><cn type="float" id="S5.SS2.p1.4.m4.3.3.cmml" xref="S5.SS2.p1.4.m4.3.3">0.5</cn><cn type="float" id="S5.SS2.p1.4.m4.4.4.cmml" xref="S5.SS2.p1.4.m4.4.4">0.5</cn></interval></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.8c">(w_{1},w_{2})=(0.9,0.1),(0.5,0.5)</annotation></semantics></math> and <math id="S5.SS2.p1.5.m5.2" class="ltx_Math" alttext="(0.1,0.9)" display="inline"><semantics id="S5.SS2.p1.5.m5.2a"><mrow id="S5.SS2.p1.5.m5.2.3.2" xref="S5.SS2.p1.5.m5.2.3.1.cmml"><mo stretchy="false" id="S5.SS2.p1.5.m5.2.3.2.1" xref="S5.SS2.p1.5.m5.2.3.1.cmml">(</mo><mn id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml">0.1</mn><mo id="S5.SS2.p1.5.m5.2.3.2.2" xref="S5.SS2.p1.5.m5.2.3.1.cmml">,</mo><mn id="S5.SS2.p1.5.m5.2.2" xref="S5.SS2.p1.5.m5.2.2.cmml">0.9</mn><mo stretchy="false" id="S5.SS2.p1.5.m5.2.3.2.3" xref="S5.SS2.p1.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.2b"><interval closure="open" id="S5.SS2.p1.5.m5.2.3.1.cmml" xref="S5.SS2.p1.5.m5.2.3.2"><cn type="float" id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">0.1</cn><cn type="float" id="S5.SS2.p1.5.m5.2.2.cmml" xref="S5.SS2.p1.5.m5.2.2">0.9</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.2c">(0.1,0.9)</annotation></semantics></math> with a random allocation strategy <span id="S5.SS2.p1.7.1" class="ltx_text" style="color:#000000;">and a greedy allocation strategy</span>.
<math id="S5.SS2.p1.6.m6.1" class="ltx_Math" alttext="w_{1}" display="inline"><semantics id="S5.SS2.p1.6.m6.1a"><msub id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml"><mi id="S5.SS2.p1.6.m6.1.1.2" xref="S5.SS2.p1.6.m6.1.1.2.cmml">w</mi><mn id="S5.SS2.p1.6.m6.1.1.3" xref="S5.SS2.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><apply id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.p1.6.m6.1.1.2">𝑤</ci><cn type="integer" id="S5.SS2.p1.6.m6.1.1.3.cmml" xref="S5.SS2.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">w_{1}</annotation></semantics></math> and <math id="S5.SS2.p1.7.m7.1" class="ltx_Math" alttext="w_{2}" display="inline"><semantics id="S5.SS2.p1.7.m7.1a"><msub id="S5.SS2.p1.7.m7.1.1" xref="S5.SS2.p1.7.m7.1.1.cmml"><mi id="S5.SS2.p1.7.m7.1.1.2" xref="S5.SS2.p1.7.m7.1.1.2.cmml">w</mi><mn id="S5.SS2.p1.7.m7.1.1.3" xref="S5.SS2.p1.7.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.7.m7.1b"><apply id="S5.SS2.p1.7.m7.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.7.m7.1.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1">subscript</csymbol><ci id="S5.SS2.p1.7.m7.1.1.2.cmml" xref="S5.SS2.p1.7.m7.1.1.2">𝑤</ci><cn type="integer" id="S5.SS2.p1.7.m7.1.1.3.cmml" xref="S5.SS2.p1.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.7.m7.1c">w_{2}</annotation></semantics></math> have the same meaning as that in Section <a href="#S5.SS1" title="V-A FDMA-enabled FL-MAR in the Metaverse ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a>.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2212.08324/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="106" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.6.3.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S5.F4.4.2" class="ltx_text" style="font-size:90%;">NOMA-enabled FL-MAR system: simulation results under different transmit power limits. <span id="S5.F4.4.2.2" class="ltx_text" style="color:#000000;">The local epochs and global communication round are <math id="S5.F4.3.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.F4.3.1.1.m1.1b"><mn mathcolor="#000000" id="S5.F4.3.1.1.m1.1.1" xref="S5.F4.3.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.F4.3.1.1.m1.1c"><cn type="integer" id="S5.F4.3.1.1.m1.1.1.cmml" xref="S5.F4.3.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.3.1.1.m1.1d">10</annotation></semantics></math> and <math id="S5.F4.4.2.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.F4.4.2.2.m2.1b"><mn mathcolor="#000000" id="S5.F4.4.2.2.m2.1.1" xref="S5.F4.4.2.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.F4.4.2.2.m2.1c"><cn type="integer" id="S5.F4.4.2.2.m2.1.1.cmml" xref="S5.F4.4.2.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.4.2.2.m2.1d">1</annotation></semantics></math></span>.</span></figcaption>
</figure>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.3" class="ltx_p">Moreover, Fig. <a href="#S5.F4" title="Figure 4 ‣ V-B NOMA-enabled FL-MAR in the Metaverse ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> contains comparisons under different maximum transmission power limits of the total energy consumption and time consumption.
It can be concluded that when the maximum transmission power increases, total time consumption slightly decreases.
Our resource allocation algorithm performs better than the random allocation strategy in the aspect of energy optimization.
In terms of total time consumption, the proposed algorithm performs worse than the random allocation when <math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="(w_{1}=0.9,w_{2}=0.1)" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><mrow id="S5.SS2.p2.1.m1.1.1.1"><mo stretchy="false" id="S5.SS2.p2.1.m1.1.1.1.2">(</mo><mrow id="S5.SS2.p2.1.m1.1.1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.1.1.3.cmml"><mrow id="S5.SS2.p2.1.m1.1.1.1.1.1.1" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.cmml"><msub id="S5.SS2.p2.1.m1.1.1.1.1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.cmml"><mi id="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.2" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.2.cmml">w</mi><mn id="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.3" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS2.p2.1.m1.1.1.1.1.1.1.1" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml">=</mo><mn id="S5.SS2.p2.1.m1.1.1.1.1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml">0.9</mn></mrow><mo id="S5.SS2.p2.1.m1.1.1.1.1.2.3" xref="S5.SS2.p2.1.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S5.SS2.p2.1.m1.1.1.1.1.2.2" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.cmml"><msub id="S5.SS2.p2.1.m1.1.1.1.1.2.2.2" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.cmml"><mi id="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.2" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.2.cmml">w</mi><mn id="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.3" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.3.cmml">2</mn></msub><mo id="S5.SS2.p2.1.m1.1.1.1.1.2.2.1" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.1.cmml">=</mo><mn id="S5.SS2.p2.1.m1.1.1.1.1.2.2.3" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.3.cmml">0.1</mn></mrow></mrow><mo stretchy="false" id="S5.SS2.p2.1.m1.1.1.1.3">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.1.3a.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S5.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1"><eq id="S5.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.1"></eq><apply id="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S5.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.1.1.3">0.9</cn></apply><apply id="S5.SS2.p2.1.m1.1.1.1.1.2.2.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2"><eq id="S5.SS2.p2.1.m1.1.1.1.1.2.2.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.1"></eq><apply id="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.2.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.2">𝑤</ci><cn type="integer" id="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.3.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.2.3">2</cn></apply><cn type="float" id="S5.SS2.p2.1.m1.1.1.1.1.2.2.3.cmml" xref="S5.SS2.p2.1.m1.1.1.1.1.2.2.3">0.1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">(w_{1}=0.9,w_{2}=0.1)</annotation></semantics></math>, because the case of <math id="S5.SS2.p2.2.m2.1" class="ltx_Math" alttext="w_{1}=0.9" display="inline"><semantics id="S5.SS2.p2.2.m2.1a"><mrow id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><msub id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2.2" xref="S5.SS2.p2.2.m2.1.1.2.2.cmml">w</mi><mn id="S5.SS2.p2.2.m2.1.1.2.3" xref="S5.SS2.p2.2.m2.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS2.p2.2.m2.1.1.1" xref="S5.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><eq id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1.1"></eq><apply id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.p2.2.m2.1.1.2.1.cmml" xref="S5.SS2.p2.2.m2.1.1.2">subscript</csymbol><ci id="S5.SS2.p2.2.m2.1.1.2.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS2.p2.2.m2.1.1.2.3.cmml" xref="S5.SS2.p2.2.m2.1.1.2.3">1</cn></apply><cn type="float" id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">w_{1}=0.9</annotation></semantics></math> emphasizes more about the energy optimization and less about the time minimization. The simulations show the effectiveness of our approach for different weight parameters. <span id="S5.SS2.p2.3.1" class="ltx_text" style="color:#000000;">Besides, it could be observed that the greedy allocation strategy focuses most on optimizing time consumption. Thus, in terms of time optimization, it is almost the same as when we have <math id="S5.SS2.p2.3.1.m1.1" class="ltx_Math" alttext="(w_{1}=0.1,w_{2}=0.9)" display="inline"><semantics id="S5.SS2.p2.3.1.m1.1a"><mrow id="S5.SS2.p2.3.1.m1.1.1.1"><mo mathcolor="#000000" stretchy="false" id="S5.SS2.p2.3.1.m1.1.1.1.2">(</mo><mrow id="S5.SS2.p2.3.1.m1.1.1.1.1.2" xref="S5.SS2.p2.3.1.m1.1.1.1.1.3.cmml"><mrow id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.cmml"><msub id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.cmml"><mi mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.2" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.2.cmml">w</mi><mn mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.3" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.1" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.1.cmml">=</mo><mn mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.3" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.3.cmml">0.1</mn></mrow><mo mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.3" xref="S5.SS2.p2.3.1.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.cmml"><msub id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.cmml"><mi mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.2" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.2.cmml">w</mi><mn mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.3" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.3.cmml">2</mn></msub><mo mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.1" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.1.cmml">=</mo><mn mathcolor="#000000" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.3" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.3.cmml">0.9</mn></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S5.SS2.p2.3.1.m1.1.1.1.3">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.1.m1.1b"><apply id="S5.SS2.p2.3.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.p2.3.1.m1.1.1.1.1.3a.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1"><eq id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.1"></eq><apply id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.1.1.3">0.1</cn></apply><apply id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2"><eq id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.1.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.1"></eq><apply id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.1.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.2.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.2">𝑤</ci><cn type="integer" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.3.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.2.3">2</cn></apply><cn type="float" id="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.3.cmml" xref="S5.SS2.p2.3.1.m1.1.1.1.1.2.2.3">0.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.1.m1.1c">(w_{1}=0.1,w_{2}=0.9)</annotation></semantics></math>, but the energy consumption is even worse than the random strategy.</span></p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Analysis of the difference between FDMA-enabled and NOMA-enabled FL-MAR system</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.4" class="ltx_p">It could be concluded from Fig. <a href="#S5.F3" title="Figure 3 ‣ V-A FDMA-enabled FL-MAR in the Metaverse ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Fig. <a href="#S5.F4" title="Figure 4 ‣ V-B NOMA-enabled FL-MAR in the Metaverse ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that, in terms of total energy consumption, there is little difference between the performance of FDMA-enabled and NOMA-enabled FL-MAR system. Regarding total time consumption, the FDMA-enabled system performs slightly better when <math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="w_{1}=0.9" display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><mrow id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><msub id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml"><mi id="S5.SS3.p1.1.m1.1.1.2.2" xref="S5.SS3.p1.1.m1.1.1.2.2.cmml">w</mi><mn id="S5.SS3.p1.1.m1.1.1.2.3" xref="S5.SS3.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS3.p1.1.m1.1.1.1" xref="S5.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><eq id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1.1"></eq><apply id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.1.1.2.1.cmml" xref="S5.SS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S5.SS3.p1.1.m1.1.1.2.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS3.p1.1.m1.1.1.2.3.cmml" xref="S5.SS3.p1.1.m1.1.1.2.3">1</cn></apply><cn type="float" id="S5.SS3.p1.1.m1.1.1.3.cmml" xref="S5.SS3.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">w_{1}=0.9</annotation></semantics></math> and <math id="S5.SS3.p1.2.m2.1" class="ltx_Math" alttext="w_{2}=0.1" display="inline"><semantics id="S5.SS3.p1.2.m2.1a"><mrow id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><msub id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2.2" xref="S5.SS3.p1.2.m2.1.1.2.2.cmml">w</mi><mn id="S5.SS3.p1.2.m2.1.1.2.3" xref="S5.SS3.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S5.SS3.p1.2.m2.1.1.1" xref="S5.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><eq id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1.1"></eq><apply id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.2.1.cmml" xref="S5.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S5.SS3.p1.2.m2.1.1.2.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS3.p1.2.m2.1.1.2.3.cmml" xref="S5.SS3.p1.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="S5.SS3.p1.2.m2.1.1.3.cmml" xref="S5.SS3.p1.2.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">w_{2}=0.1</annotation></semantics></math>. When <math id="S5.SS3.p1.3.m3.1" class="ltx_Math" alttext="(w_{1}=0.5,w_{2}=0.5)" display="inline"><semantics id="S5.SS3.p1.3.m3.1a"><mrow id="S5.SS3.p1.3.m3.1.1.1"><mo stretchy="false" id="S5.SS3.p1.3.m3.1.1.1.2">(</mo><mrow id="S5.SS3.p1.3.m3.1.1.1.1.2" xref="S5.SS3.p1.3.m3.1.1.1.1.3.cmml"><mrow id="S5.SS3.p1.3.m3.1.1.1.1.1.1" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.cmml"><msub id="S5.SS3.p1.3.m3.1.1.1.1.1.1.2" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.cmml"><mi id="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.2" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.2.cmml">w</mi><mn id="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.3" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS3.p1.3.m3.1.1.1.1.1.1.1" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.3.m3.1.1.1.1.1.1.3" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.3.cmml">0.5</mn></mrow><mo id="S5.SS3.p1.3.m3.1.1.1.1.2.3" xref="S5.SS3.p1.3.m3.1.1.1.1.3a.cmml">,</mo><mrow id="S5.SS3.p1.3.m3.1.1.1.1.2.2" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.cmml"><msub id="S5.SS3.p1.3.m3.1.1.1.1.2.2.2" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.cmml"><mi id="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.2" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.2.cmml">w</mi><mn id="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.3" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.3.cmml">2</mn></msub><mo id="S5.SS3.p1.3.m3.1.1.1.1.2.2.1" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.1.cmml">=</mo><mn id="S5.SS3.p1.3.m3.1.1.1.1.2.2.3" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.3.cmml">0.5</mn></mrow></mrow><mo stretchy="false" id="S5.SS3.p1.3.m3.1.1.1.3">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><apply id="S5.SS3.p1.3.m3.1.1.1.1.3.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.1.1.1.1.3a.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.3.m3.1.1.1.1.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1"><eq id="S5.SS3.p1.3.m3.1.1.1.1.1.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.1"></eq><apply id="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.1.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.2.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.3.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S5.SS3.p1.3.m3.1.1.1.1.1.1.3.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.1.1.3">0.5</cn></apply><apply id="S5.SS3.p1.3.m3.1.1.1.1.2.2.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2"><eq id="S5.SS3.p1.3.m3.1.1.1.1.2.2.1.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.1"></eq><apply id="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.1.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.2.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.2">𝑤</ci><cn type="integer" id="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.3.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.2.3">2</cn></apply><cn type="float" id="S5.SS3.p1.3.m3.1.1.1.1.2.2.3.cmml" xref="S5.SS3.p1.3.m3.1.1.1.1.2.2.3">0.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.1c">(w_{1}=0.5,w_{2}=0.5)</annotation></semantics></math> and <math id="S5.SS3.p1.4.m4.1" class="ltx_Math" alttext="(w_{1}=0.1,w_{2}=0.9)" display="inline"><semantics id="S5.SS3.p1.4.m4.1a"><mrow id="S5.SS3.p1.4.m4.1.1.1"><mo stretchy="false" id="S5.SS3.p1.4.m4.1.1.1.2">(</mo><mrow id="S5.SS3.p1.4.m4.1.1.1.1.2" xref="S5.SS3.p1.4.m4.1.1.1.1.3.cmml"><mrow id="S5.SS3.p1.4.m4.1.1.1.1.1.1" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.cmml"><msub id="S5.SS3.p1.4.m4.1.1.1.1.1.1.2" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.cmml"><mi id="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.2" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.2.cmml">w</mi><mn id="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.3" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS3.p1.4.m4.1.1.1.1.1.1.1" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.4.m4.1.1.1.1.1.1.3" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.3.cmml">0.1</mn></mrow><mo id="S5.SS3.p1.4.m4.1.1.1.1.2.3" xref="S5.SS3.p1.4.m4.1.1.1.1.3a.cmml">,</mo><mrow id="S5.SS3.p1.4.m4.1.1.1.1.2.2" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.cmml"><msub id="S5.SS3.p1.4.m4.1.1.1.1.2.2.2" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.cmml"><mi id="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.2" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.2.cmml">w</mi><mn id="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.3" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.3.cmml">2</mn></msub><mo id="S5.SS3.p1.4.m4.1.1.1.1.2.2.1" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.1.cmml">=</mo><mn id="S5.SS3.p1.4.m4.1.1.1.1.2.2.3" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.3.cmml">0.9</mn></mrow></mrow><mo stretchy="false" id="S5.SS3.p1.4.m4.1.1.1.3">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.1b"><apply id="S5.SS3.p1.4.m4.1.1.1.1.3.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.p1.4.m4.1.1.1.1.3a.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.4.m4.1.1.1.1.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1"><eq id="S5.SS3.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.1"></eq><apply id="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.2.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.2">𝑤</ci><cn type="integer" id="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.3.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S5.SS3.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.1.1.3">0.1</cn></apply><apply id="S5.SS3.p1.4.m4.1.1.1.1.2.2.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2"><eq id="S5.SS3.p1.4.m4.1.1.1.1.2.2.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.1"></eq><apply id="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.2.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.2">𝑤</ci><cn type="integer" id="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.3.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.2.3">2</cn></apply><cn type="float" id="S5.SS3.p1.4.m4.1.1.1.1.2.2.3.cmml" xref="S5.SS3.p1.4.m4.1.1.1.1.2.2.3">0.9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m4.1c">(w_{1}=0.1,w_{2}=0.9)</annotation></semantics></math>, their performance is similar. In addition, the random scheme under NOMA outperforms the random scheme under FDMA. From the simulation results and our theoretical analyses, when the system has ample channel resources, careful optimization of FDMA has comparable performance with NOMA, so there is no need to implement the more complex NOMA for resource-rich scenarios. Yet, when the system has limited channel resources, NOMA can improve the system performance by leveraging power-domain orthogonality.
Our findings are also consistent with recent results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
We hope our preliminary simulation can motivate more real-world NOMA experiments for the Metaverse in the research community.
</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">Non-IID and unbalanced data distribution in FL-MAR</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p"><span id="S5.SS4.p1.1.1" class="ltx_text" style="color:#000000;">In this section, we study the impact of non-IID, unbalanced data distributions and the image resolution on the model performance.
In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS4.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S5.SS4.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S5.SS4.p1.1.4" class="ltx_text" style="color:#000000;">, other than energy and time, we also optimize the model accuracy.
Fig. </span><a href="#S5.F5" title="Figure 5 ‣ V-D Non-IID and unbalanced data distribution in FL-MAR ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S5.SS4.p1.1.5" class="ltx_text" style="color:#000000;"> depicts the relationship between model accuracy and the weight of model accuracy, and the basic experimental settings are listed in it. In Fig. </span><a href="#S5.F5" title="Figure 5 ‣ V-D Non-IID and unbalanced data distribution in FL-MAR ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S5.SS4.p1.1.6" class="ltx_text" style="color:#000000;">(a), “non-IID (1-class)” indicates that every client possesses data with one unique label. “non-IID (2-class)” suggests that each client’s data includes two different labels. The unbalanced situation is randomly assigning samples to each client.
It could be observed that in both Fig. </span><a href="#S5.F5" title="Figure 5 ‣ V-D Non-IID and unbalanced data distribution in FL-MAR ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S5.SS4.p1.1.7" class="ltx_text" style="color:#000000;">(a) and (b), as the weight of model accuracy increases, the model accuracy improves because the higher image resolution used for training will be selected. Additionally, in Fig. </span><a href="#S5.F5" title="Figure 5 ‣ V-D Non-IID and unbalanced data distribution in FL-MAR ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S5.SS4.p1.1.8" class="ltx_text" style="color:#000000;">(a), the “non-IID (1-class) and unbalanced” has the worst performance in MNIST and CIFAR-10. Compared to the unbalanced setting, the impact of non-IID is more significant. Moreover, the image resolution has a more substantial influence on CIFAR-10’s accuracy compared to MNIST, and this may be caused by the higher complexity of CIFAR-10. Fig. </span><a href="#S5.F5" title="Figure 5 ‣ V-D Non-IID and unbalanced data distribution in FL-MAR ‣ V Case Studies of FL-MAR in the Metaverse ‣ Mobile Augmented Reality with Federated Learning in the Metaverse" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S5.SS4.p1.1.9" class="ltx_text" style="color:#000000;">(b) also reveals the fact that the unbalanced data will result in a worse model.
</span><span id="S5.SS4.p1.1.10" class="ltx_text"></span></p>
</div>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.08324/assets/x5.png" id="S5.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="227" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf1.12.6.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F5.sf1.10.5" class="ltx_text" style="font-size:90%;color:#000000;">The test accuracy under different weights of model accuracy for MNIST and CIFAR-10 datasets. MNIST: The options of the image resolution are <math id="S5.F5.sf1.6.1.m1.3" class="ltx_Math" alttext="\{7^{2},14^{2},28^{2}\}" display="inline"><semantics id="S5.F5.sf1.6.1.m1.3b"><mrow id="S5.F5.sf1.6.1.m1.3.3.3" xref="S5.F5.sf1.6.1.m1.3.3.4.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.F5.sf1.6.1.m1.3.3.3.4" xref="S5.F5.sf1.6.1.m1.3.3.4.cmml">{</mo><msup id="S5.F5.sf1.6.1.m1.1.1.1.1" xref="S5.F5.sf1.6.1.m1.1.1.1.1.cmml"><mn mathcolor="#000000" id="S5.F5.sf1.6.1.m1.1.1.1.1.2" xref="S5.F5.sf1.6.1.m1.1.1.1.1.2.cmml">7</mn><mn mathcolor="#000000" id="S5.F5.sf1.6.1.m1.1.1.1.1.3" xref="S5.F5.sf1.6.1.m1.1.1.1.1.3.cmml">2</mn></msup><mo mathcolor="#000000" id="S5.F5.sf1.6.1.m1.3.3.3.5" xref="S5.F5.sf1.6.1.m1.3.3.4.cmml">,</mo><msup id="S5.F5.sf1.6.1.m1.2.2.2.2" xref="S5.F5.sf1.6.1.m1.2.2.2.2.cmml"><mn mathcolor="#000000" id="S5.F5.sf1.6.1.m1.2.2.2.2.2" xref="S5.F5.sf1.6.1.m1.2.2.2.2.2.cmml">14</mn><mn mathcolor="#000000" id="S5.F5.sf1.6.1.m1.2.2.2.2.3" xref="S5.F5.sf1.6.1.m1.2.2.2.2.3.cmml">2</mn></msup><mo mathcolor="#000000" id="S5.F5.sf1.6.1.m1.3.3.3.6" xref="S5.F5.sf1.6.1.m1.3.3.4.cmml">,</mo><msup id="S5.F5.sf1.6.1.m1.3.3.3.3" xref="S5.F5.sf1.6.1.m1.3.3.3.3.cmml"><mn mathcolor="#000000" id="S5.F5.sf1.6.1.m1.3.3.3.3.2" xref="S5.F5.sf1.6.1.m1.3.3.3.3.2.cmml">28</mn><mn mathcolor="#000000" id="S5.F5.sf1.6.1.m1.3.3.3.3.3" xref="S5.F5.sf1.6.1.m1.3.3.3.3.3.cmml">2</mn></msup><mo mathcolor="#000000" stretchy="false" id="S5.F5.sf1.6.1.m1.3.3.3.7" xref="S5.F5.sf1.6.1.m1.3.3.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.sf1.6.1.m1.3c"><set id="S5.F5.sf1.6.1.m1.3.3.4.cmml" xref="S5.F5.sf1.6.1.m1.3.3.3"><apply id="S5.F5.sf1.6.1.m1.1.1.1.1.cmml" xref="S5.F5.sf1.6.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.F5.sf1.6.1.m1.1.1.1.1.1.cmml" xref="S5.F5.sf1.6.1.m1.1.1.1.1">superscript</csymbol><cn type="integer" id="S5.F5.sf1.6.1.m1.1.1.1.1.2.cmml" xref="S5.F5.sf1.6.1.m1.1.1.1.1.2">7</cn><cn type="integer" id="S5.F5.sf1.6.1.m1.1.1.1.1.3.cmml" xref="S5.F5.sf1.6.1.m1.1.1.1.1.3">2</cn></apply><apply id="S5.F5.sf1.6.1.m1.2.2.2.2.cmml" xref="S5.F5.sf1.6.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.F5.sf1.6.1.m1.2.2.2.2.1.cmml" xref="S5.F5.sf1.6.1.m1.2.2.2.2">superscript</csymbol><cn type="integer" id="S5.F5.sf1.6.1.m1.2.2.2.2.2.cmml" xref="S5.F5.sf1.6.1.m1.2.2.2.2.2">14</cn><cn type="integer" id="S5.F5.sf1.6.1.m1.2.2.2.2.3.cmml" xref="S5.F5.sf1.6.1.m1.2.2.2.2.3">2</cn></apply><apply id="S5.F5.sf1.6.1.m1.3.3.3.3.cmml" xref="S5.F5.sf1.6.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S5.F5.sf1.6.1.m1.3.3.3.3.1.cmml" xref="S5.F5.sf1.6.1.m1.3.3.3.3">superscript</csymbol><cn type="integer" id="S5.F5.sf1.6.1.m1.3.3.3.3.2.cmml" xref="S5.F5.sf1.6.1.m1.3.3.3.3.2">28</cn><cn type="integer" id="S5.F5.sf1.6.1.m1.3.3.3.3.3.cmml" xref="S5.F5.sf1.6.1.m1.3.3.3.3.3">2</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf1.6.1.m1.3d">\{7^{2},14^{2},28^{2}\}</annotation></semantics></math> pixels. CIFAR-10: The options of the resolution are <math id="S5.F5.sf1.7.2.m2.3" class="ltx_Math" alttext="\{8^{2},16^{2},32^{2}\}" display="inline"><semantics id="S5.F5.sf1.7.2.m2.3b"><mrow id="S5.F5.sf1.7.2.m2.3.3.3" xref="S5.F5.sf1.7.2.m2.3.3.4.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.F5.sf1.7.2.m2.3.3.3.4" xref="S5.F5.sf1.7.2.m2.3.3.4.cmml">{</mo><msup id="S5.F5.sf1.7.2.m2.1.1.1.1" xref="S5.F5.sf1.7.2.m2.1.1.1.1.cmml"><mn mathcolor="#000000" id="S5.F5.sf1.7.2.m2.1.1.1.1.2" xref="S5.F5.sf1.7.2.m2.1.1.1.1.2.cmml">8</mn><mn mathcolor="#000000" id="S5.F5.sf1.7.2.m2.1.1.1.1.3" xref="S5.F5.sf1.7.2.m2.1.1.1.1.3.cmml">2</mn></msup><mo mathcolor="#000000" id="S5.F5.sf1.7.2.m2.3.3.3.5" xref="S5.F5.sf1.7.2.m2.3.3.4.cmml">,</mo><msup id="S5.F5.sf1.7.2.m2.2.2.2.2" xref="S5.F5.sf1.7.2.m2.2.2.2.2.cmml"><mn mathcolor="#000000" id="S5.F5.sf1.7.2.m2.2.2.2.2.2" xref="S5.F5.sf1.7.2.m2.2.2.2.2.2.cmml">16</mn><mn mathcolor="#000000" id="S5.F5.sf1.7.2.m2.2.2.2.2.3" xref="S5.F5.sf1.7.2.m2.2.2.2.2.3.cmml">2</mn></msup><mo mathcolor="#000000" id="S5.F5.sf1.7.2.m2.3.3.3.6" xref="S5.F5.sf1.7.2.m2.3.3.4.cmml">,</mo><msup id="S5.F5.sf1.7.2.m2.3.3.3.3" xref="S5.F5.sf1.7.2.m2.3.3.3.3.cmml"><mn mathcolor="#000000" id="S5.F5.sf1.7.2.m2.3.3.3.3.2" xref="S5.F5.sf1.7.2.m2.3.3.3.3.2.cmml">32</mn><mn mathcolor="#000000" id="S5.F5.sf1.7.2.m2.3.3.3.3.3" xref="S5.F5.sf1.7.2.m2.3.3.3.3.3.cmml">2</mn></msup><mo mathcolor="#000000" stretchy="false" id="S5.F5.sf1.7.2.m2.3.3.3.7" xref="S5.F5.sf1.7.2.m2.3.3.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.sf1.7.2.m2.3c"><set id="S5.F5.sf1.7.2.m2.3.3.4.cmml" xref="S5.F5.sf1.7.2.m2.3.3.3"><apply id="S5.F5.sf1.7.2.m2.1.1.1.1.cmml" xref="S5.F5.sf1.7.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S5.F5.sf1.7.2.m2.1.1.1.1.1.cmml" xref="S5.F5.sf1.7.2.m2.1.1.1.1">superscript</csymbol><cn type="integer" id="S5.F5.sf1.7.2.m2.1.1.1.1.2.cmml" xref="S5.F5.sf1.7.2.m2.1.1.1.1.2">8</cn><cn type="integer" id="S5.F5.sf1.7.2.m2.1.1.1.1.3.cmml" xref="S5.F5.sf1.7.2.m2.1.1.1.1.3">2</cn></apply><apply id="S5.F5.sf1.7.2.m2.2.2.2.2.cmml" xref="S5.F5.sf1.7.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S5.F5.sf1.7.2.m2.2.2.2.2.1.cmml" xref="S5.F5.sf1.7.2.m2.2.2.2.2">superscript</csymbol><cn type="integer" id="S5.F5.sf1.7.2.m2.2.2.2.2.2.cmml" xref="S5.F5.sf1.7.2.m2.2.2.2.2.2">16</cn><cn type="integer" id="S5.F5.sf1.7.2.m2.2.2.2.2.3.cmml" xref="S5.F5.sf1.7.2.m2.2.2.2.2.3">2</cn></apply><apply id="S5.F5.sf1.7.2.m2.3.3.3.3.cmml" xref="S5.F5.sf1.7.2.m2.3.3.3.3"><csymbol cd="ambiguous" id="S5.F5.sf1.7.2.m2.3.3.3.3.1.cmml" xref="S5.F5.sf1.7.2.m2.3.3.3.3">superscript</csymbol><cn type="integer" id="S5.F5.sf1.7.2.m2.3.3.3.3.2.cmml" xref="S5.F5.sf1.7.2.m2.3.3.3.3.2">32</cn><cn type="integer" id="S5.F5.sf1.7.2.m2.3.3.3.3.3.cmml" xref="S5.F5.sf1.7.2.m2.3.3.3.3.3">2</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf1.7.2.m2.3d">\{8^{2},16^{2},32^{2}\}</annotation></semantics></math> pixels. The number of local epochs and global communication rounds are <math id="S5.F5.sf1.8.3.m3.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.F5.sf1.8.3.m3.1b"><mn mathcolor="#000000" id="S5.F5.sf1.8.3.m3.1.1" xref="S5.F5.sf1.8.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.F5.sf1.8.3.m3.1c"><cn type="integer" id="S5.F5.sf1.8.3.m3.1.1.cmml" xref="S5.F5.sf1.8.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf1.8.3.m3.1d">5</annotation></semantics></math> and <math id="S5.F5.sf1.9.4.m4.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S5.F5.sf1.9.4.m4.1b"><mn mathcolor="#000000" id="S5.F5.sf1.9.4.m4.1.1" xref="S5.F5.sf1.9.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S5.F5.sf1.9.4.m4.1c"><cn type="integer" id="S5.F5.sf1.9.4.m4.1.1.cmml" xref="S5.F5.sf1.9.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf1.9.4.m4.1d">100</annotation></semantics></math>. The number of clients is <math id="S5.F5.sf1.10.5.m5.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.F5.sf1.10.5.m5.1b"><mn mathcolor="#000000" id="S5.F5.sf1.10.5.m5.1.1" xref="S5.F5.sf1.10.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.F5.sf1.10.5.m5.1c"><cn type="integer" id="S5.F5.sf1.10.5.m5.1.1.cmml" xref="S5.F5.sf1.10.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf1.10.5.m5.1d">10</annotation></semantics></math>. The models are CNNs (convolutional neural networks).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.08324/assets/x6.png" id="S5.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.sf2.10.5.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F5.sf2.8.4" class="ltx_text" style="font-size:90%;color:#000000;">The model accuracy under different weights of model accuracy for COCO dataset: The options of the resolution are <math id="S5.F5.sf2.5.1.m1.4" class="ltx_Math" alttext="\{160^{2},320^{2},480^{2},640^{2}\}" display="inline"><semantics id="S5.F5.sf2.5.1.m1.4b"><mrow id="S5.F5.sf2.5.1.m1.4.4.4" xref="S5.F5.sf2.5.1.m1.4.4.5.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.F5.sf2.5.1.m1.4.4.4.5" xref="S5.F5.sf2.5.1.m1.4.4.5.cmml">{</mo><msup id="S5.F5.sf2.5.1.m1.1.1.1.1" xref="S5.F5.sf2.5.1.m1.1.1.1.1.cmml"><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.1.1.1.1.2" xref="S5.F5.sf2.5.1.m1.1.1.1.1.2.cmml">160</mn><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.1.1.1.1.3" xref="S5.F5.sf2.5.1.m1.1.1.1.1.3.cmml">2</mn></msup><mo mathcolor="#000000" id="S5.F5.sf2.5.1.m1.4.4.4.6" xref="S5.F5.sf2.5.1.m1.4.4.5.cmml">,</mo><msup id="S5.F5.sf2.5.1.m1.2.2.2.2" xref="S5.F5.sf2.5.1.m1.2.2.2.2.cmml"><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.2.2.2.2.2" xref="S5.F5.sf2.5.1.m1.2.2.2.2.2.cmml">320</mn><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.2.2.2.2.3" xref="S5.F5.sf2.5.1.m1.2.2.2.2.3.cmml">2</mn></msup><mo mathcolor="#000000" id="S5.F5.sf2.5.1.m1.4.4.4.7" xref="S5.F5.sf2.5.1.m1.4.4.5.cmml">,</mo><msup id="S5.F5.sf2.5.1.m1.3.3.3.3" xref="S5.F5.sf2.5.1.m1.3.3.3.3.cmml"><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.3.3.3.3.2" xref="S5.F5.sf2.5.1.m1.3.3.3.3.2.cmml">480</mn><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.3.3.3.3.3" xref="S5.F5.sf2.5.1.m1.3.3.3.3.3.cmml">2</mn></msup><mo mathcolor="#000000" id="S5.F5.sf2.5.1.m1.4.4.4.8" xref="S5.F5.sf2.5.1.m1.4.4.5.cmml">,</mo><msup id="S5.F5.sf2.5.1.m1.4.4.4.4" xref="S5.F5.sf2.5.1.m1.4.4.4.4.cmml"><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.4.4.4.4.2" xref="S5.F5.sf2.5.1.m1.4.4.4.4.2.cmml">640</mn><mn mathcolor="#000000" id="S5.F5.sf2.5.1.m1.4.4.4.4.3" xref="S5.F5.sf2.5.1.m1.4.4.4.4.3.cmml">2</mn></msup><mo mathcolor="#000000" stretchy="false" id="S5.F5.sf2.5.1.m1.4.4.4.9" xref="S5.F5.sf2.5.1.m1.4.4.5.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F5.sf2.5.1.m1.4c"><set id="S5.F5.sf2.5.1.m1.4.4.5.cmml" xref="S5.F5.sf2.5.1.m1.4.4.4"><apply id="S5.F5.sf2.5.1.m1.1.1.1.1.cmml" xref="S5.F5.sf2.5.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.F5.sf2.5.1.m1.1.1.1.1.1.cmml" xref="S5.F5.sf2.5.1.m1.1.1.1.1">superscript</csymbol><cn type="integer" id="S5.F5.sf2.5.1.m1.1.1.1.1.2.cmml" xref="S5.F5.sf2.5.1.m1.1.1.1.1.2">160</cn><cn type="integer" id="S5.F5.sf2.5.1.m1.1.1.1.1.3.cmml" xref="S5.F5.sf2.5.1.m1.1.1.1.1.3">2</cn></apply><apply id="S5.F5.sf2.5.1.m1.2.2.2.2.cmml" xref="S5.F5.sf2.5.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.F5.sf2.5.1.m1.2.2.2.2.1.cmml" xref="S5.F5.sf2.5.1.m1.2.2.2.2">superscript</csymbol><cn type="integer" id="S5.F5.sf2.5.1.m1.2.2.2.2.2.cmml" xref="S5.F5.sf2.5.1.m1.2.2.2.2.2">320</cn><cn type="integer" id="S5.F5.sf2.5.1.m1.2.2.2.2.3.cmml" xref="S5.F5.sf2.5.1.m1.2.2.2.2.3">2</cn></apply><apply id="S5.F5.sf2.5.1.m1.3.3.3.3.cmml" xref="S5.F5.sf2.5.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S5.F5.sf2.5.1.m1.3.3.3.3.1.cmml" xref="S5.F5.sf2.5.1.m1.3.3.3.3">superscript</csymbol><cn type="integer" id="S5.F5.sf2.5.1.m1.3.3.3.3.2.cmml" xref="S5.F5.sf2.5.1.m1.3.3.3.3.2">480</cn><cn type="integer" id="S5.F5.sf2.5.1.m1.3.3.3.3.3.cmml" xref="S5.F5.sf2.5.1.m1.3.3.3.3.3">2</cn></apply><apply id="S5.F5.sf2.5.1.m1.4.4.4.4.cmml" xref="S5.F5.sf2.5.1.m1.4.4.4.4"><csymbol cd="ambiguous" id="S5.F5.sf2.5.1.m1.4.4.4.4.1.cmml" xref="S5.F5.sf2.5.1.m1.4.4.4.4">superscript</csymbol><cn type="integer" id="S5.F5.sf2.5.1.m1.4.4.4.4.2.cmml" xref="S5.F5.sf2.5.1.m1.4.4.4.4.2">640</cn><cn type="integer" id="S5.F5.sf2.5.1.m1.4.4.4.4.3.cmml" xref="S5.F5.sf2.5.1.m1.4.4.4.4.3">2</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf2.5.1.m1.4d">\{160^{2},320^{2},480^{2},640^{2}\}</annotation></semantics></math> pixels. The model accuracy refers to the mean Average Precision, which is a widely used measurement in object detection. The number of local epochs and global communication rounds are <math id="S5.F5.sf2.6.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.F5.sf2.6.2.m2.1b"><mn mathcolor="#000000" id="S5.F5.sf2.6.2.m2.1.1" xref="S5.F5.sf2.6.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.F5.sf2.6.2.m2.1c"><cn type="integer" id="S5.F5.sf2.6.2.m2.1.1.cmml" xref="S5.F5.sf2.6.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf2.6.2.m2.1d">5</annotation></semantics></math> and <math id="S5.F5.sf2.7.3.m3.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S5.F5.sf2.7.3.m3.1b"><mn mathcolor="#000000" id="S5.F5.sf2.7.3.m3.1.1" xref="S5.F5.sf2.7.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S5.F5.sf2.7.3.m3.1c"><cn type="integer" id="S5.F5.sf2.7.3.m3.1.1.cmml" xref="S5.F5.sf2.7.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf2.7.3.m3.1d">50</annotation></semantics></math>. The number of clients is <math id="S5.F5.sf2.8.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.F5.sf2.8.4.m4.1b"><mn mathcolor="#000000" id="S5.F5.sf2.8.4.m4.1.1" xref="S5.F5.sf2.8.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.F5.sf2.8.4.m4.1c"><cn type="integer" id="S5.F5.sf2.8.4.m4.1.1.cmml" xref="S5.F5.sf2.8.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.F5.sf2.8.4.m4.1d">10</annotation></semantics></math>. The models are YOLOv5m and YOLOv3-tiny (i.e., the real-time object detection algorithms).</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S5.F5.4.2" class="ltx_text" style="font-size:90%;color:#000000;">Experiments of image classification and object detection. 
</span></figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In conclusion, this article gives insights into the necessity and rationality of a federated learning enabled mobile augmented reality system (FL-MAR) in the Metaverse.
The combination of FL and MAR in the Metaverse not only helps protect user privacy to a certain extent but also utilizes the available computing resources on mobile devices.
Besides, this article lists and explains the promising technologies that enable FL-MAR systems in the Metaverse.
Some application scenarios are also given in this article, including autonomous driving, shopping, education and so forth.
Finally, three case studies are evaluated. The energy and latency are analyzed for FDMA-enabled and NOMA-enabled FL-MAR systems. Also, we study the impact of non-IID, unbalanced data and image resolution on the FL-MAR system. We envision our paper to motivate more research on leveraging FL for the Metaverse, and designing more efficient channel access mechanisms to enable the Metaverse for mobile user equipments.
</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Y. Cai, H. Li, G. Yuan, W. Niu, Y. Li, X. Tang, B. Ren, and Y. Wang,
“Yolobile: Real-time object detection on mobile devices via
compression-compilation co-design,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI
Conference on Artificial Intelligence</em>, vol. 35, no. 2, 2021, pp. 955–963.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-Efficient Learning of Deep Networks from Decentralized
Data,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, 2017, pp.
1273–1282.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Kumar and K. Kumar, “Multiple access schemes for cognitive radio networks:
A survey,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Physical Communication</em>, vol. 38, p. 100953, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Xu, W. C. Ng, W. Y. B. Lim, J. Kang, Z. Xiong, D. Niyato, Q. Yang, X. S.
Shen, and C. Miao, “A full dive into realizing the edge-enabled metaverse:
Visions, enabling technologies, and challenges,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Communications
Surveys &amp; Tutorials</em>, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
G. Zhu, J. Xu, K. Huang, and S. Cui, “Over-the-air computing for wireless data
aggregation in massive IoT,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless Communications</em>, vol. 28,
no. 4, pp. 57–65, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Kang, D. Ye, J. Nie, J. Xiao, X. Deng, S. Wang, Z. Xiong, R. Yu, and
D. Niyato, “Blockchain-based federated learning for industrial metaverses:
Incentive scheme with optimal AoI,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">2022 IEEE International
Conference on Blockchain (Blockchain)</em>.   IEEE, 2022, pp. 71–78.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Y. Wang, Z. Su, N. Zhang, R. Xing, D. Liu, T. H. Luan, and X. Shen, “A survey
on metaverse: Fundamentals, security, and privacy,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE
Communications Surveys &amp; Tutorials</em>, vol. 25, no. 1, pp. 319–352, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Chen, S. Huang, W. Gan, G. Huang, and Y. Wu, “Federated learning for
metaverse: A survey,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ACM Web Conference (formerly WWW
Conference)</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha, and
G. Srivastava, “A survey on security and privacy of federated learning,”
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 115, pp. 619–640, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-Bahaei, “Energy efficient
federated learning over wireless communication networks,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Wireless Communications</em>, vol. 20, no. 3, pp. 1935–1949,
March 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
X. Zhou, C. Liu, and J. Zhao, “Resource allocation of federated learning for
the metaverse with mobile augmented reality,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2211.08705</em>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
V. Nair, G. M. Garrido, and D. Song, “Exploring the unprecedented privacy
risks of the metaverse,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.13176</em>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
X. Zhang, Y. Chen, L. Hu, and Y. Wang, “The metaverse in education:
Definition, framework, features, potential applications, challenges, and
future research topics,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Frontiers in Psychology</em>, vol. 13, 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
G. Wang, A. Badal, X. Jia, J. S. Maltz, K. Mueller, K. J. Myers, C. Niu,
M. Vannier, P. Yan, Z. Yu <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Development of metaverse for
intelligent healthcare,” <em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, vol. 4, no. 11,
pp. 922–929, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
X. Li, Z. Xie, Z. Chu, V. G. Menon, S. Mumtaz, and J. Zhang, “Exploiting
benefits of IRS in wireless powered NOMA networks,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Green Communications and Networking</em>, vol. 6, no. 1, pp.
175–186, 2022.

</span>
</li>
</ul>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Biographies</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Xinyu Zhou is currently pursuing a Ph.D. degree at Nanyang Technological University (NTU) in Singapore. Her research interests include federated learning and Metaverse.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">Jun Zhao is currently an Assistant Professor in the School of Computer Science and Engineering at Nanyang Technological University (NTU) in Singapore. He received a PhD degree in May 2015 in Electrical and Computer Engineering from Carnegie Mellon University (CMU) in the USA (advisors: Virgil Gligor, Osman Yagan; collaborator: Adrian Perrig), affiliating with CMU’s CyLab Security &amp; Privacy Institute, and a bachelor’s degree in July 2010 from Shanghai Jiao Tong University in China. Before joining NTU first as a postdoc with Xiaokui Xiao and then as a faculty member, he was a postdoc at Arizona State University as an Arizona Computing PostDoc Best Practices Fellow (advisors: Junshan Zhang, Vincent Poor). His research interests include federated learning, edge/fog computing, and Metaverse.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2212.08323" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2212.08324" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2212.08324">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.08324" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2212.08325" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 10:56:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
