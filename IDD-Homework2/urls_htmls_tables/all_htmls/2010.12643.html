<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2010.12643] Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering</title><meta property="og:description" content="Coupled with the availability of large scale datasets, deep learning architectures have enabled rapid progress on Question Answering tasks. However, most of those datasets are in English, and the performances of state-â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2010.12643">

<!--Generated on Wed Mar  6 08:38:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arij Riabi<sup id="id11.11.id1" class="ltx_sup"><span id="id11.11.id1.1" class="ltx_text ltx_font_italic">â€¡</span></sup> â€ƒThomas Scialom<sup id="id12.12.id2" class="ltx_sup"><span id="id12.12.id2.1" class="ltx_text ltx_font_italic">â‹†â‹„âˆ—</span></sup> â€ƒRachel Keraron<sup id="id13.13.id3" class="ltx_sup"><span id="id13.13.id3.1" class="ltx_text ltx_font_italic">â‹†</span></sup>
<br class="ltx_break"><span id="id7.7.3" class="ltx_text ltx_font_bold">BenoÃ®t Sagot<sup id="id7.7.3.1" class="ltx_sup"><span id="id7.7.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">â€¡</span></sup> â€ƒDjamÃ© Seddah<sup id="id7.7.3.2" class="ltx_sup"><span id="id7.7.3.2.1" class="ltx_text ltx_font_medium ltx_font_italic">â€¡</span></sup> â€ƒJacopo Staiano<sup id="id7.7.3.3" class="ltx_sup"><span id="id7.7.3.3.1" class="ltx_text ltx_font_medium ltx_font_italic">â‹†</span></sup></span> 
<br class="ltx_break"><sup id="id14.14.id4" class="ltx_sup">â€¡</sup> Inria, Paris, France
<br class="ltx_break"><sup id="id15.15.id5" class="ltx_sup">â‹„</sup> Sorbonne UniversitÃ©, CNRS, LIP6, F-75005 Paris, France
<br class="ltx_break"><sup id="id16.16.id6" class="ltx_sup">â‹†</sup> reciTAL, Paris, France 
<br class="ltx_break"><span id="id17.17.id7" class="ltx_text ltx_font_typewriter">{thomas,rachel,jacopo}@recital.ai</span> 
<br class="ltx_break"><span id="id18.18.id8" class="ltx_text ltx_font_typewriter">{arij.riabi,benoit.sagot,djame.seddah}@inria.fr</span> 
<br class="ltx_break">
</span><span class="ltx_author_notes"><sup id="id19.19.id1" class="ltx_sup"><span id="id19.19.id1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup>: equal contribution. The work of Arij Riabi was partly carried out while she was working at reciTAL.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id20.id1" class="ltx_p"><span id="id20.id1.1" class="ltx_text">Coupled with the availability of large scale datasets, deep learning architectures have enabled rapid progress on Question Answering tasks. However, most of those datasets are in English, and the performances of state-of-the-art multilingual models are significantly lower when evaluated on non-English data.
Due to high data collection costs, it is not realistic to obtain annotated data for each language one desires to support.</span></p>
<p id="id21.id2" class="ltx_p"><span id="id21.id2.1" class="ltx_text">We propose a method to improve  Cross-lingual Question Answering performance without requiring additional annotated data, leveraging Question Generation models to produce synthetic samples in a cross-lingual fashion.
We show that the proposed method allows to significantly outperform the baselines trained on English data only, establishing thus a new state-of-the-art on four multilingual datasets: MLQA, XQuAD, SQuAD-it and PIAF (fr).</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Question Answering is a fast-growing research field, aiming to improve the capabilities of machines to read and understand documents. Significant progress has recently been enabled by the use of large pre-trained language models <cite class="ltx_cite ltx_citemacro_cite">Devlin etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2019</a>); Raffel etÂ al. (<a href="#bib.bib36" title="" class="ltx_ref">2020</a>)</cite>, which reach human-level performances on several publicly available benchmarks, such as SQuAD <cite class="ltx_cite ltx_citemacro_cite">Rajpurkar etÂ al. (<a href="#bib.bib37" title="" class="ltx_ref">2016</a>)</cite> and NewsQA <cite class="ltx_cite ltx_citemacro_cite">Trischler etÂ al. (<a href="#bib.bib44" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Given that the majority of large scale Question Answering (QA) datasets are in English <cite class="ltx_cite ltx_citemacro_cite">Hermann etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2015</a>); Rajpurkar etÂ al. (<a href="#bib.bib37" title="" class="ltx_ref">2016</a>); Choi etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2018</a>)</cite>, the development of QA systems targeting other languages is currently addressed via two cross-lingual QA datasets: XQuAD <cite class="ltx_cite ltx_citemacro_cite">Artetxe etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite> and MLQA <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2020a</a>)</cite>, covering respectively 10 and 7 languages. Due to the cost of annotation, both are limited only to an evaluation set. They are comparable to the validation set of the original SQuAD (see more details in SectionÂ <a href="#S3.SS3" title="3.3 Multilingual Evaluation Sets â€£ 3 Data â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>). In both datasets, each paragraph is paired with questions in various languages, allowing to evaluate models in a <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">cross-lingual</em> experimental scenario: the input context and the question can be in two different languages. This scenario has important practical applications, such as querying a set of documents in various languages.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Performing this cross-lingual task is complex and remains challenging for current models, assuming only English training data: transfer results are shown to rank behind training-language performance <cite class="ltx_cite ltx_citemacro_cite">Artetxe etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>); Lewis etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2020a</a>)</cite>. In other words, multilingual models fine-tuned only on English data are found to perform significantly better on English than on other languages.
Besides the almost simultaneous work of <cite class="ltx_cite ltx_citemacro_citet">Shakeri etÂ al. (<a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>, very few alternatives to such a simple zero-shot transfer method have been proposed so far.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose to generate synthetic data in a cross-lingual fashion, borrowing the idea from monolingual QA research efforts <cite class="ltx_cite ltx_citemacro_cite">Duan etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2017</a>)</cite>. On English corpora, generating synthetic questions has shown to significantly improve the performance of QA models <cite class="ltx_cite ltx_citemacro_cite">Du etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2017</a>); Golub etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2017</a>); Du and Cardie (<a href="#bib.bib12" title="" class="ltx_ref">2018</a>); Alberti etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>)</cite>.
However, the adaptation of this technique to cross-lingual QA is not straightforward: cross-lingual text generation is a challenging task <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">per se</em> which has not been yet extensively explored, in particular when no multilingual training data is available.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We explore two Question Generation scenarios: (i) requiring only SQuAD data; and (ii) using a translator tool to obtain translated versions of SQuAD. As expected, the method leveraging on a translator has shown to perform the best. Leveraging on such synthetic data, our best model obtains significant improvements on XQuAD and MLQA over the state-of-the-art for both Exact Match and F1 scores.
In addition, we evaluate the QA models on languages not seen during training (even for the synthetic data) â€“ using SQuAD-it (for Italian), PIAF (for French), and KorQUaD (for Korean) â€“ reporting a new state-of-the-art for Italian and French, and observing significant improvements on Korean compared to zero-shot without augmentation.
This indicates that the proposed method allows to capture better multilingual representations beyond the training languages.
Our method paves the way toward multilingual QA domain adaptation, especially for under-resourced languages.
</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Our contributions can be summarized as follows:
</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We present a data augmentation approach for Cross-Lingual Question Answering based on synthetic Question Generation;</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We report extensive experiments showing significant improvements on two multilingual evaluation datasets (XQuAD and MLQA);</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We additionally evaluate the proposed methodology on languages unseen during training, thus showing the potential benefits for QA on low-resource languages.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question Answering (QA)</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">QA is the task for which given a context and a question, a model has to find the answer. The interest for Question Answering goes back a long way: in a 1965 survey,
<cite class="ltx_cite ltx_citemacro_citet">Simmons (<a href="#bib.bib42" title="" class="ltx_ref">1965</a>)</cite> reported fifteen implemented English language question-answering
systems.
More recently, with the rise of large scale datasets <cite class="ltx_cite ltx_citemacro_cite">Hermann etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2015</a>)</cite>, and large pre-trained models <cite class="ltx_cite ltx_citemacro_cite">Devlin etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>, the performance drastically increased, approaching human-level performance on standard benchmarks â€“ see for instance the SQuAD leader board.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://rajpurkar.github.io/SQuAD-explorer/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://rajpurkar.github.io/SQuAD-explorer/</a></span></span></span>
More challenging evaluation benchmarks have recently been proposed: <cite class="ltx_cite ltx_citemacro_citet">Dua etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite> released the DROP dataset, for which the annotators were encouraged to provide adversarial questions; <cite class="ltx_cite ltx_citemacro_citet">Burchell etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> released the MSQ dataset, consisting of multi-sentence questions.</p>
</div>
<div id="S2.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p2.1" class="ltx_p">However, all these works are focused on English. Another popular research direction focuses on the development of multilingual QA models. For this purpose, the first step has been to provide the community with multilingual evaluation sets: <cite class="ltx_cite ltx_citemacro_citet">Artetxe etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Lewis etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2020a</a>)</cite> concurrently proposed two different evaluation sets which are comparable to the SQuAD development set. Both reach the same conclusion: due to the lack of non-English training data, models do not achieve the same performance in Non-English languages than they do in English.
To the best of our knowledge, no method has been proposed to fill this gap.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question Generation (QG)</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">QG can be seen as the dual task of QA: the input is composed of the <em id="S2.SS0.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">answer</em> and the <em id="S2.SS0.SSS0.Px2.p1.1.2" class="ltx_emph ltx_font_italic">paragraph</em> containing it, and the model is trained to generate the <em id="S2.SS0.SSS0.Px2.p1.1.3" class="ltx_emph ltx_font_italic">question</em>. Proposed by <cite class="ltx_cite ltx_citemacro_citet">Rus etÂ al. (<a href="#bib.bib38" title="" class="ltx_ref">2010</a>)</cite>, it has leveraged on the development of new QA datasets <cite class="ltx_cite ltx_citemacro_cite">Zhou etÂ al. (<a href="#bib.bib47" title="" class="ltx_ref">2017</a>); Scialom etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite>. Similar to QA, significant performance improvements have been obtained using pre-trained language models <cite class="ltx_cite ltx_citemacro_cite">Dong etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>. Still, due to the lack of multilingual datasets, most previous works have been limited to monolingual text generation. We note the exceptions of <cite class="ltx_cite ltx_citemacro_citet">Kumar etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Chi etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>, who resorted to multilingual pre-training before fine-tuning on monolingual downstream NLG tasks. However, the quality of the generated questions is still found inferior to the corresponding English ones.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question Generation for Question Answering</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Data augmentation via synthetic data generation is a well-known technique to improve modelsâ€™ accuracy and generalisation. It has found successful application in several areas, such as time series analysis <cite class="ltx_cite ltx_citemacro_cite">Forestier etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite> and computer vision <cite class="ltx_cite ltx_citemacro_cite">Buslaev etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>.
In the context of QA, generating synthetic questions to complete a dataset has shown to improve QA performances <cite class="ltx_cite ltx_citemacro_cite">Duan etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2017</a>); Alberti etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>)</cite>. So far, all these works have focused on English QA given the difficulty to generate questions in other languages without available data.
This lack of data, and the difficulty to obtain some, constitutes the main motivation of our work and justifies exploring cost-effective approaches such as data augmentation via the generation of questions.</p>
</div>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p2.1" class="ltx_p">In a very recent work, almost simultaneous to our previously submitted version, <cite class="ltx_cite ltx_citemacro_citet">Shakeri etÂ al. (<a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite> address multilingual QA with a similar approach. However, we argue that their experimental protocol does not allow to totally answer the research question. We detail the differences in our discussion, SectionÂ <a href="#S5.SS3" title="5.3 Discussion â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>English Training Data</h3>

<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">SQuAD<sub id="S3.SS1.SSS0.Px1.2.1" class="ltx_sub"><span id="S3.SS1.SSS0.Px1.2.1.1" class="ltx_text ltx_font_italic">en</span></sub>
</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">The original SQuAD <cite class="ltx_cite ltx_citemacro_cite">Rajpurkar etÂ al. (<a href="#bib.bib37" title="" class="ltx_ref">2016</a>)</cite>, which we refer as SQuAD<sub id="S3.SS1.SSS0.Px1.p1.1.1" class="ltx_sub"><span id="S3.SS1.SSS0.Px1.p1.1.1.1" class="ltx_text ltx_font_italic">en</span></sub> for clarity in this paper. It is one of the first, and among the most popular, large scale QA datasets. It contains about 100K question/paragraph/answer triplets in English, annotated via Mechanical Turk.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Two versions of SQuAD have been released: v1.1, used in this work, and v2.0. The latter contains â€œunanswerable questionsâ€ in addition to those from v1.1. We use the former, since the multilingual evaluation datasets, MLQA and XQUAD, do not include unanswerable questions.</span></span></span></p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">QG datasets</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">Any QA dataset can be reversed into a QG dataset, by switching the generation targets from the answers to the questions. In this paper, we use the <em id="S3.SS1.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">qg</em> subscript to specify when the dataset is used for QG (e.g. SQuAD<sub id="S3.SS1.SSS0.Px2.p1.1.2" class="ltx_sub"><span id="S3.SS1.SSS0.Px2.p1.1.2.1" class="ltx_text ltx_font_italic">en;qg</span></sub> indicates the English SQuAD data in QG format).</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Synthetic Training Sets</h3>

<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">SQuAD<sub id="S3.SS2.SSS0.Px1.2.1" class="ltx_sub"><span id="S3.SS2.SSS0.Px1.2.1.1" class="ltx_text ltx_font_italic">trans</span></sub>
</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">is a machine translated version of the SQuAD train set in the seven languages of MLQA, released by the authors together with their paper.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">WikiScrap</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">We collected 500 Wikipedia articles for all the languages present in MLQA.
They are not paired with any question or answer. We use them as contexts to generate synthetic multilingual questions, as detailed in SectionÂ <a href="#S4.SS2" title="4.2 Question Generation Data Augmentation â€£ 4 Models â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>. Following the SQuAD<sub id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_sub"><span id="S3.SS2.SSS0.Px2.p1.1.1.1" class="ltx_text ltx_font_italic">en</span></sub> protocol, we used project Nayukiâ€™s code<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://www.nayuki.io/page/computing-wikipedias-internal-pageranks" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nayuki.io/page/computing-wikipedias-internal-pageranks</a></span></span></span> to parse the top 10K Wikipedia pages according to the PageRank algorithm <cite class="ltx_cite ltx_citemacro_cite">Page etÂ al. (<a href="#bib.bib35" title="" class="ltx_ref">1999</a>)</cite>. We then filtered out paragraphs with character length outside of a [500, 1500] interval. Articles with less than 5 paragraphs are discarded, since they tend to be less developed, in a lower quality or being only redirection pages. Out of the filtered articles, we randomly selected 500 per language.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Multilingual Evaluation Sets</h3>

<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">XQuAD</h4>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Artetxe etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite> is a human translation of the SQuAD<sub id="S3.SS3.SSS0.Px1.p1.1.1" class="ltx_sub"><span id="S3.SS3.SSS0.Px1.p1.1.1.1" class="ltx_text ltx_font_italic">en</span></sub> development set in 10 languages (Arabic, Chinese, German, Greek, Hindi, Russian, Spanish, Thai, Turkish, and Vietnamese), providing 1k QA pairs for each language.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">MLQA</h4>

<div id="S3.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2020a</a>)</cite> is an evaluation dataset in 7 languages (English, Arabic, Chinese, German, Hindi, and Spanish). The dataset is built from aligned Wikipedia sentences across at least two languages (full alignment between all languages being impossible), with the goal of providing natural rather than translated paragraphs. The QA pairs are manually annotated on the English sentences and then human translated on the aligned sentences. The dataset contains about 46k aligned QA pairs in total.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Language-specific benchmarks</h4>

<div id="S3.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px3.p1.1" class="ltx_p">In addition to the two aforementioned multilingual evaluation corpora, we benchmark our models on three language-specific datasets for French, Italian and Korean, as detailed below.
We choose these datasets since none of these languages are present in XQuAD or MLQA. Hence, they allow us to evaluate our models in a scenario where the target language is not available during training, even for the synthetic questions.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">PIAF</h4>

<div id="S3.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px4.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Keraron etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite> provided an evaluation set in French following the SQuAD protocol, containing 3835 examples.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">KorQuAD 1.0</h4>

<div id="S3.SS3.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px5.p1.1" class="ltx_p">the Korean Question Answering
Dataset <cite class="ltx_cite ltx_citemacro_cite">Lim etÂ al. (<a href="#bib.bib32" title="" class="ltx_ref">2019</a>)</cite>, a Korean dataset also built following the SQuAD protocol.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">SQuAD-it</h4>

<div id="S3.SS3.SSS0.Px6.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px6.p1.1" class="ltx_p">Derived from SQuAD<sub id="S3.SS3.SSS0.Px6.p1.1.1" class="ltx_sub"><span id="S3.SS3.SSS0.Px6.p1.1.1.1" class="ltx_text ltx_font_italic">en</span></sub>, it was obtained via semi-automatic translation to Italian <cite class="ltx_cite ltx_citemacro_cite">Croce etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Models</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Recent works <cite class="ltx_cite ltx_citemacro_cite">Raffel etÂ al. (<a href="#bib.bib36" title="" class="ltx_ref">2020</a>); Lewis etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite> have shown that classification tasks can be framed as a text-to-text problem, achieving state-of-the-art results on established benchmarks, such as GLUE <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib45" title="" class="ltx_ref">2018</a>)</cite>.
Accordingly, we employ the same architecture for both Question Answering and Generation tasks.
This also allows fairer comparisons for our purposes, by removing differences between QA and QG architectures and their potential impact on the results obtained.
In particular, we use a distilled version of XLM-R <cite class="ltx_cite ltx_citemacro_cite">Conneau etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>: MiniLM-M <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite> (see SectionÂ <a href="#S4.SS3" title="4.3 Implementation details â€£ 4 Models â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> for further details).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Baselines</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">QA<sub id="S4.SS1.SSS0.Px1.1.1" class="ltx_sub">No-synth</sub>
</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">Following previous works, we fine-tuned the multilingual models on SQuAD<sub id="S4.SS1.SSS0.Px1.p1.1.1" class="ltx_sub"><span id="S4.SS1.SSS0.Px1.p1.1.1.1" class="ltx_text ltx_font_italic">en</span></sub>, and consider them as our baselines.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">English as Pivot</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.3" class="ltx_p">Leveraging on translation models, we consider a second baseline method, which uses English as a pivot. First, both the question in language <math id="S4.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="L_{q}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">L</mi><mi id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2">ğ¿</ci><ci id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.1.m1.1c">L_{q}</annotation></semantics></math> and the paragraph in language <math id="S4.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="L_{p}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p1.2.m2.1a"><msub id="S4.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml">L</mi><mi id="S4.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1.2">ğ¿</ci><ci id="S4.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.2.m2.1c">L_{p}</annotation></semantics></math> are translated into English.
We then invoke the baseline model described above, QA<sub id="S4.SS1.SSS0.Px2.p1.3.1" class="ltx_sub">No-synth</sub>, to predict the answer. Finally, the predicted answer is translated back into the target language <math id="S4.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="L_{p}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p1.3.m3.1a"><msub id="S4.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml">L</mi><mi id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2">ğ¿</ci><ci id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.3.m3.1c">L_{p}</annotation></semantics></math>.
We used the google translate API.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://translate.google.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://translate.google.com</a></span></span></span></p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">QA<sub id="S4.SS1.SSS0.Px3.1.1" class="ltx_sub">+SQuAD-trans</sub>
</h4>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">the translated data SQuAD<sub id="S4.SS1.SSS0.Px3.p1.1.1" class="ltx_sub">trans</sub> are used as additional training data to SQuAD<sub id="S4.SS1.SSS0.Px3.p1.1.2" class="ltx_sub">en</sub>, to train the QA model.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Question Generation Data Augmentation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In this work we consider data augmentation via generating synthetic questions, to improve the QA performance. Different training schemes for the question generator are possible, resulting in different quality of the synthetic data. Before this work, its impact on the final QA system remained unexplored in a multilingual context.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">For all the following experiments, only the synthetic data changes. Given a specific set of synthetic data, we always follow the same two-stages protocol, similar to <cite class="ltx_cite ltx_citemacro_citet">Alberti etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>)</cite>: we first train the QA model on the synthetic QA data, then on SQuAD<sub id="S4.SS2.p2.1.1" class="ltx_sub"><span id="S4.SS2.p2.1.1.1" class="ltx_text ltx_font_italic">en</span></sub>.
We also tried to train the QA model in one stage, with all the synthetic and human data shuffled together, but observed no improvements over the baseline.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">We explored two different synthetic generation modes:</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Synth</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">the QG model is trained on SQuAD<sub id="S4.SS2.SSS0.Px1.p1.1.1" class="ltx_sub"><span id="S4.SS2.SSS0.Px1.p1.1.1.1" class="ltx_text ltx_font_italic">en,qg</span></sub> (i.e., English data only) and the synthetic data are generated on WikiScrap. Under this setup, the only annotated samples this model has access to are those from SQuAD-en.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Synth+trans</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.3" class="ltx_p">the QG model is trained on SQuAD<sub id="S4.SS2.SSS0.Px2.p1.3.1" class="ltx_sub"><span id="S4.SS2.SSS0.Px2.p1.3.1.1" class="ltx_text ltx_font_italic">trans,qg</span></sub> in addition to SQuAD<sub id="S4.SS2.SSS0.Px2.p1.3.2" class="ltx_sub"><span id="S4.SS2.SSS0.Px2.p1.3.2.1" class="ltx_text ltx_font_italic">en,qg</span></sub>.
The questions can thus be in a different languages than the context. Hence, the model needs an indication about the language it is expected to generate the question in.
To control the target language, we use a specific prompt per language, defining a special token <span id="S4.SS2.SSS0.Px2.p1.3.3" class="ltx_text ltx_font_typewriter">&lt;LANG&gt;</span>, which corresponds to the desired target language <math id="S4.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.3.m3.1a"><mi id="S4.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.3.m3.1b"><ci id="S4.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.3.m3.1c">Y</annotation></semantics></math>. Thus, the input is structured as <span id="S4.SS2.SSS0.Px2.p1.3.4" class="ltx_text ltx_font_typewriter">&lt;LANG&gt; &lt;SEP&gt; Answer &lt;SEP&gt; Context</span>,
where <span id="S4.SS2.SSS0.Px2.p1.3.5" class="ltx_text ltx_font_typewriter">&lt;LANG&gt;</span> indicates to the model in what language the question should be generated, and <span id="S4.SS2.SSS0.Px2.p1.3.6" class="ltx_text ltx_font_typewriter">&lt;SEP&gt;</span> is a special token acting as a separator. These attributes offer flexibility on the target language. Similar techniques are used in the literature to control the style of the output <cite class="ltx_cite ltx_citemacro_cite">Keskar etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2019</a>); Scialom etÂ al. (<a href="#bib.bib40" title="" class="ltx_ref">2020</a>); Chi etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Implementation details</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">For all our experiments we use Multilingual MiniLM v1 (MiniLM-m) <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite>, a 12-layer with 384 hidden size architecture distilled from XLM-R Base multilingual <cite class="ltx_cite ltx_citemacro_cite">Conneau etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>. With only 66M parameters, it is an order of magnitude smaller than state-of-the-art architectures such as BERT-large or XLM-large.
We used the official Microsoft implementation.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Publicly available at <a target="_blank" href="https://github.com/microsoft/unilm/tree/master/minilm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/microsoft/unilm/tree/master/minilm</a>.</span></span></span> For all the experiments â€“both QG and QAâ€“ we trained the model for 5 epochs, using the default hyper-parameters. We used a single nVidia gtx2080ti with 11G RAM, and the training times
amount to circa 4 and 2 hours for Question Generation and for Question Answering, respectively.
To evaluate our models, we used the official MLQA evaluation scripts.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/facebookresearch/MLQA/blob/master/mlqa_evaluation_v1.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebookresearch/MLQA/blob/master/mlqa_evaluation_v1.py</a></span></span></span>
For reproducibility purposes, we make the code available.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://anonymous.4open.science" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://anonymous.4open.science</a></span></span></span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Question Generation</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We report examples of generated questions in TableÂ <a href="#S5.T1" title="Table 1 â€£ 5.1 Question Generation â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.1.1.1" class="ltx_tr">
<th id="S5.T1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S5.T1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="S5.T1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Paragraph (EN)</span>
Peyton Manning became the first quarterback ever to lead two different teams to multiple Super Bowls. He is also the oldest quarterback ever to play in a Super Bowl at age 39. The past record was held by John Elway, who led the Broncos to victory in Super Bowl XXXIII at age 38 and is currently Denverâ€™s Executive Vice President of Football Operations and General Manager.</span>
<span id="S5.T1.1.1.1.1.1.2" class="ltx_p"><span id="S5.T1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Answer</span>
Broncos</span>
<span id="S5.T1.1.1.1.1.1.3" class="ltx_p"><span id="S5.T1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.1.1.1.1.3.1.1" class="ltx_sub">synth</sub> </span>
What team did John Elway lead to victory at age 38?</span>
<span id="S5.T1.1.1.1.1.1.4" class="ltx_p"><span id="S5.T1.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.1.1.1.1.4.1.1" class="ltx_sub">synth+trans</sub> (target language = en)</span>
What team did John Elway lead to win in the Super Bowl?</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.1.2.1" class="ltx_tr">
<td id="S5.T1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.1.2.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="S5.T1.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Paragraph (ES)</span>
Peyton Manning se convirtiÃ³ en el primer mariscal de campo de la historia en llevar a dos equipos diferentes a participar en mÃºltiples Super Bowls. Ademas, es con 39 aÃ±os, el mariscal de campo mÃ¡s longevo de la historia en jugar ese partido. El rÃ©cord anterior estaba en manos de John Elway â€”mÃ¡nager general y actual vicepresidente ejecutivo para operaciones futbolÃ­sticas de Denverâ€” que condujo a los Broncos a la victoria en la Super Bowl XXXIII a los 38 aÃ±os de edad.</span>
<span id="S5.T1.1.2.1.1.1.2" class="ltx_p"><span id="S5.T1.1.2.1.1.1.2.1" class="ltx_text ltx_font_bold">Answer</span>
Broncos</span>
<span id="S5.T1.1.2.1.1.1.3" class="ltx_p"><span id="S5.T1.1.2.1.1.1.3.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.2.1.1.1.3.1.1" class="ltx_sub">synth</sub> </span>
Where did Peyton Manning condujo?</span>
<span id="S5.T1.1.2.1.1.1.4" class="ltx_p"><span id="S5.T1.1.2.1.1.1.4.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.2.1.1.1.4.1.1" class="ltx_sub">synth+trans</sub> (target language = es)</span>
QuÃ© equipo ganÃ³ el rÃ©cord anterior? (<em id="S5.T1.1.2.1.1.1.4.2" class="ltx_emph ltx_font_italic">Which team won the previous record?</em>)</span>
<span id="S5.T1.1.2.1.1.1.5" class="ltx_p"><span id="S5.T1.1.2.1.1.1.5.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.2.1.1.1.5.1.1" class="ltx_sub">synth+trans</sub> (target language = en)</span>
What team did Menning win in the Super Bowl?</span>
</span>
</td>
</tr>
<tr id="S5.T1.1.3.2" class="ltx_tr">
<td id="S5.T1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.1.3.2.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="S5.T1.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">Paragraph (ZH)</span>
åŸ¹é¡¿Â·æ›¼å®æˆä¸ºå²ä¸Šé¦–ä½å¸¦é¢†ä¸¤æ”¯ä¸åŒçƒé˜Ÿå¤šæ¬¡è¿›å…¥è¶…çº§ç¢—çš„å››åˆ†å«ã€‚ä»–ä¹Ÿä»¥ 39 å²é«˜é¾„å‚åŠ è¶…çº§ç¢—è€Œæˆä¸ºå²ä¸Šå¹´é¾„æœ€å¤§çš„å››åˆ†å«ã€‚è¿‡å»çš„è®°å½•æ˜¯ç”±çº¦ç¿°Â·åŸƒå°”ç»´ä¿æŒçš„ï¼Œä»–åœ¨ 38å²æ—¶å¸¦é¢†é‡é©¬é˜Ÿèµ¢å¾—ç¬¬ 33 å±Šè¶…çº§ç¢—ï¼Œç›®å‰æ‹…ä»»ä¸¹ä½›çš„æ©„æ¦„çƒè¿è¥æ‰§è¡Œå‰¯æ€»è£å…¼æ€»ç»ç†</span>
<span id="S5.T1.1.3.2.1.1.2" class="ltx_p"><span id="S5.T1.1.3.2.1.1.2.1" class="ltx_text ltx_font_bold">Answer</span>
é‡é©¬é˜Ÿ</span>
<span id="S5.T1.1.3.2.1.1.3" class="ltx_p"><span id="S5.T1.1.3.2.1.1.3.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.3.2.1.1.3.1.1" class="ltx_sub">synth</sub></span>
What is the name for the name that the name is used?</span>
<span id="S5.T1.1.3.2.1.1.4" class="ltx_p"><span id="S5.T1.1.3.2.1.1.4.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.3.2.1.1.4.1.1" class="ltx_sub">synth+trans</sub> (target language = zh)</span>
çº¦ç¿°Â·åŸƒå°”ç»´åœ¨13å²æ—¶å¸¦é¢†å“ªæ”¯çƒé˜Ÿèµ¢å¾—ç¬¬ 33å±Šè¶…çº§ç¢—? (<em id="S5.T1.1.3.2.1.1.4.2" class="ltx_emph ltx_font_italic">Which team did John Elvey lead to win the 33rd Super Bowl at the age of 13?</em>)</span>
<span id="S5.T1.1.3.2.1.1.5" class="ltx_p"><span id="S5.T1.1.3.2.1.1.5.1" class="ltx_text ltx_font_bold">QG<sub id="S5.T1.1.3.2.1.1.5.1.1" class="ltx_sub">synth+trans</sub> (target language = en)</span>
What team won the 33th Super Bowl?</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 1: </span>Example of questions generated by the different models on an XQuADâ€™s paragraph in different languages. For QG<sub id="S5.T1.3.1" class="ltx_sub">synth+trans</sub>, we report the outputs given two target languages, the one of the context and English.</figcaption>
</figure>
<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Controlling the Target Language</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.1" class="ltx_p">In the context of multilingual text generation, controlling the target language is not trivial.</p>
</div>
<div id="S5.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p2.1" class="ltx_p">When a QA model is trained only on English data, at inference, given a non-English paragraph, it predicts the answer in the input language, as one would expect, since it is an extractive process.
Ideally, we would like to observe the same behavior for a Question Generation model trained only on English data (such as <math id="S5.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="Synth" display="inline"><semantics id="S5.SS1.SSS0.Px1.p2.1.m1.1a"><mrow id="S5.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.2" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.3" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1a" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.4" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1b" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.5" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1c" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.6" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.6.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p2.1.m1.1b"><apply id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1"><times id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.1"></times><ci id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.2">ğ‘†</ci><ci id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.3">ğ‘¦</ci><ci id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.4.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.4">ğ‘›</ci><ci id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.5.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.5">ğ‘¡</ci><ci id="S5.SS1.SSS0.Px1.p2.1.m1.1.1.6.cmml" xref="S5.SS1.SSS0.Px1.p2.1.m1.1.1.6">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p2.1.m1.1c">Synth</annotation></semantics></math>), leveraging on the multilingual pre-training. Conversely to QA, QG is a language generation task. <em id="S5.SS1.SSS0.Px1.p2.1.1" class="ltx_emph ltx_font_italic">Multilingual</em> generation is much more challenging, as the modelâ€™s decoding ability plays a major role.
When a QG model is fine-tuned only on English data (i.e SQuAD-en), its controllability of the target language suffers from catastrophic forgetting: the input language does not propagate to the generated text. While still relevant to the context, the synthetic questions are generated in English: for instance, in TableÂ <a href="#S5.T1" title="Table 1 â€£ 5.1 Question Generation â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> we observe that the QG<sub id="S5.SS1.SSS0.Px1.p2.1.2" class="ltx_sub">synth</sub> model outputs English questions for the paragraphs in Chinese and Spanish. The same phenomenon was reported by <cite class="ltx_cite ltx_citemacro_citet">Chi etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Cross-Lingual Training</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.2" class="ltx_p">To overcome the aforementioned limitation on target language controllability (i.e. to enable the generation in other languages than English), multilingual data is needed. We can leverage on the translated versions of the dataset to add the required non-English examples.
As detailed in SectionÂ <a href="#S4.SS2" title="4.2 Question Generation Data Augmentation â€£ 4 Models â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, we simply use a specific prompt that corresponds to the target language (with <math id="S5.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="S5.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.1.m1.1c">N</annotation></semantics></math> different prompts corresponding to the <math id="S5.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.2.m2.1a"><mi id="S5.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.2.m2.1b"><ci id="S5.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.2.m2.1c">N</annotation></semantics></math> languages present in the dataset).
In TableÂ <a href="#S5.T1" title="Table 1 â€£ 5.1 Question Generation â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we show how QG<sub id="S5.SS1.SSS0.Px2.p1.2.1" class="ltx_sub">synth+trans</sub> can generate questions in the same language as the input.
These synthetic questions seem much more relevant, coherent and fluent, if compared to those produced by QG<sub id="S5.SS1.SSS0.Px2.p1.2.2" class="ltx_sub">synth</sub>: for the Spanish paragraph, the question is well formed and focused on the input answer; for Chinese (see bottom row of TableÂ <a href="#S5.T1" title="Table 1 â€£ 5.1 Question Generation â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for QG<sub id="S5.SS1.SSS0.Px2.p1.2.3" class="ltx_sub">synth+trans</sub>) is perfectly written.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">q/c</th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">en</th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">es</th>
<th id="S5.T2.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">de</th>
<th id="S5.T2.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">ar</th>
<th id="S5.T2.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">hi</th>
<th id="S5.T2.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">vi</th>
<th id="S5.T2.1.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">zh</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.2.1" class="ltx_tr">
<td id="S5.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">en</td>
<td id="S5.T2.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">14.5</td>
<td id="S5.T2.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">8.9</td>
<td id="S5.T2.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">7.2</td>
<td id="S5.T2.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">5.9</td>
<td id="S5.T2.1.2.1.6" class="ltx_td ltx_align_left ltx_border_t">6.5</td>
<td id="S5.T2.1.2.1.7" class="ltx_td ltx_align_left ltx_border_t">8.4</td>
<td id="S5.T2.1.2.1.8" class="ltx_td ltx_align_left ltx_border_t">6.0</td>
</tr>
<tr id="S5.T2.1.3.2" class="ltx_tr">
<td id="S5.T2.1.3.2.1" class="ltx_td ltx_align_left">es</td>
<td id="S5.T2.1.3.2.2" class="ltx_td ltx_align_left">9.0</td>
<td id="S5.T2.1.3.2.3" class="ltx_td ltx_align_left">10.</td>
<td id="S5.T2.1.3.2.4" class="ltx_td ltx_align_left">6.6</td>
<td id="S5.T2.1.3.2.5" class="ltx_td ltx_align_left">4.2</td>
<td id="S5.T2.1.3.2.6" class="ltx_td ltx_align_left">5.9</td>
<td id="S5.T2.1.3.2.7" class="ltx_td ltx_align_left">6.3</td>
<td id="S5.T2.1.3.2.8" class="ltx_td ltx_align_left">4.6</td>
</tr>
<tr id="S5.T2.1.4.3" class="ltx_tr">
<td id="S5.T2.1.4.3.1" class="ltx_td ltx_align_left">de</td>
<td id="S5.T2.1.4.3.2" class="ltx_td ltx_align_left">6.2</td>
<td id="S5.T2.1.4.3.3" class="ltx_td ltx_align_left">4.8</td>
<td id="S5.T2.1.4.3.4" class="ltx_td ltx_align_left">6.3</td>
<td id="S5.T2.1.4.3.5" class="ltx_td ltx_align_left">3.1</td>
<td id="S5.T2.1.4.3.6" class="ltx_td ltx_align_left">3.7</td>
<td id="S5.T2.1.4.3.7" class="ltx_td ltx_align_left">5.0</td>
<td id="S5.T2.1.4.3.8" class="ltx_td ltx_align_left">3.2</td>
</tr>
<tr id="S5.T2.1.5.4" class="ltx_tr">
<td id="S5.T2.1.5.4.1" class="ltx_td ltx_align_left">ar</td>
<td id="S5.T2.1.5.4.2" class="ltx_td ltx_align_left">2.8</td>
<td id="S5.T2.1.5.4.3" class="ltx_td ltx_align_left">2.2</td>
<td id="S5.T2.1.5.4.4" class="ltx_td ltx_align_left">2.4</td>
<td id="S5.T2.1.5.4.5" class="ltx_td ltx_align_left">3.3</td>
<td id="S5.T2.1.5.4.6" class="ltx_td ltx_align_left">2.0</td>
<td id="S5.T2.1.5.4.7" class="ltx_td ltx_align_left">2.3</td>
<td id="S5.T2.1.5.4.8" class="ltx_td ltx_align_left">2.1</td>
</tr>
<tr id="S5.T2.1.6.5" class="ltx_tr">
<td id="S5.T2.1.6.5.1" class="ltx_td ltx_align_left">hi</td>
<td id="S5.T2.1.6.5.2" class="ltx_td ltx_align_left">7.9</td>
<td id="S5.T2.1.6.5.3" class="ltx_td ltx_align_left">6.7</td>
<td id="S5.T2.1.6.5.4" class="ltx_td ltx_align_left">6.6</td>
<td id="S5.T2.1.6.5.5" class="ltx_td ltx_align_left">5.8</td>
<td id="S5.T2.1.6.5.6" class="ltx_td ltx_align_left">8.3</td>
<td id="S5.T2.1.6.5.7" class="ltx_td ltx_align_left">6.6</td>
<td id="S5.T2.1.6.5.8" class="ltx_td ltx_align_left">5.2</td>
</tr>
<tr id="S5.T2.1.7.6" class="ltx_tr">
<td id="S5.T2.1.7.6.1" class="ltx_td ltx_align_left">vi</td>
<td id="S5.T2.1.7.6.2" class="ltx_td ltx_align_left">9.1</td>
<td id="S5.T2.1.7.6.3" class="ltx_td ltx_align_left">7.3</td>
<td id="S5.T2.1.7.6.4" class="ltx_td ltx_align_left">7.2</td>
<td id="S5.T2.1.7.6.5" class="ltx_td ltx_align_left">6.0</td>
<td id="S5.T2.1.7.6.6" class="ltx_td ltx_align_left">6.5</td>
<td id="S5.T2.1.7.6.7" class="ltx_td ltx_align_left">12.3</td>
<td id="S5.T2.1.7.6.8" class="ltx_td ltx_align_left">6.1</td>
</tr>
<tr id="S5.T2.1.8.7" class="ltx_tr">
<td id="S5.T2.1.8.7.1" class="ltx_td ltx_align_left ltx_border_b">zh</td>
<td id="S5.T2.1.8.7.2" class="ltx_td ltx_align_left ltx_border_b">9.2</td>
<td id="S5.T2.1.8.7.3" class="ltx_td ltx_align_left ltx_border_b">8.0</td>
<td id="S5.T2.1.8.7.4" class="ltx_td ltx_align_left ltx_border_b">7.8</td>
<td id="S5.T2.1.8.7.5" class="ltx_td ltx_align_left ltx_border_b">6.1</td>
<td id="S5.T2.1.8.7.6" class="ltx_td ltx_align_left ltx_border_b">7.2</td>
<td id="S5.T2.1.8.7.7" class="ltx_td ltx_align_left ltx_border_b">8.0</td>
<td id="S5.T2.1.8.7.8" class="ltx_td ltx_align_left ltx_border_b">15.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 2: </span>BLEU-4 scores on MLQA test for QG<sub id="S5.T2.3.1" class="ltx_sub">synth+trans</sub>. Columns show context language, rows show question language.</figcaption>
</figure>
<div id="S5.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p2.1" class="ltx_p">In TableÂ <a href="#S5.T2" title="Table 2 â€£ Cross-Lingual Training â€£ 5.1 Question Generation â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we report the BLEU4 scores for QG<sub id="S5.SS1.SSS0.Px2.p2.1.1" class="ltx_sub">synth+trans</sub> grouped by the language of the question.
As expected, the score is maximized on the diagonal (same languages for the context and the question). Still, most of these scores are lower on non-English languages. It is interesting to note BLEU4 correlates with the QA scores: 0.51 Pearson coefficient. The reasons are two folds: 1) QA and QG share the same Language Model, which might struggle for the same languages; 2) the better the QG, the better the synthetic data, therefore the better the QA performs.
We discuss further in SectionÂ <a href="#S5.SS3" title="5.3 Discussion â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a> how this impacts the QA performance.</p>
</div>
<div id="S5.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p3.1" class="ltx_p">In addition to BLEU, we also report the QA F1 scores for different QA models when applied on the generated questions in the supplementary material.
Yet, we warn the reader that these results should be taken with caution: evaluating NLG is known to be an open research problem; BLEU is known to suffer from important limitations <cite class="ltx_cite ltx_citemacro_cite">Novikova etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2017</a>)</cite>, which might be accentuated in a multilingual context <cite class="ltx_cite ltx_citemacro_cite">Lee etÂ al. (<a href="#bib.bib28" title="" class="ltx_ref">2020</a>)</cite>. For this reason, we conducted a manual qualitative analysis on a small number of samples. Note that the annotators need to have a professional level in the language of the generated question to evaluate its fluency, and to be bilingual, when evaluating its relevance w.r.t.Â input context in our cross language scenario. This is a significant challenge to conduct a large scale evaluation.</p>
</div>
<div id="S5.SS1.SSS0.Px2.p4" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p4.1" class="ltx_p">So far, our results (see at the end of Supplementary Material) for Arabic and German show an overall good quality in the questions: only one question for Arabic was genuinely missing the point while for German there were 2 lexical questionable choices that invalidate the question (out of 10 samples for both languages so far). This indicates that Arabic questions could actually be better than what their low BLEU score shows. Arabic has a very different morphological structure that could explain such low BLEU <cite class="ltx_cite ltx_citemacro_cite">Bouamor etÂ al. (<a href="#bib.bib3" title="" class="ltx_ref">2014</a>)</cite>. This emphasizes the limitation of the current automatic metrics in a multilingual context.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Question Answering</h3>

<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.5.6.1" class="ltx_tr">
<th id="S5.T3.5.6.1.1" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S5.T3.5.6.1.2" class="ltx_td ltx_align_center">#Params</td>
<td id="S5.T3.5.6.1.3" class="ltx_td ltx_align_center">Trans.</td>
<td id="S5.T3.5.6.1.4" class="ltx_td ltx_align_center">XQuAD</td>
<td id="S5.T3.5.6.1.5" class="ltx_td ltx_align_center">MLQA</td>
</tr>
<tr id="S5.T3.5.7.2" class="ltx_tr">
<th id="S5.T3.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">MiniLM <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S5.T3.5.7.2.2" class="ltx_td ltx_align_center ltx_border_t">66M</td>
<td id="S5.T3.5.7.2.3" class="ltx_td ltx_align_center ltx_border_t">No</td>
<td id="S5.T3.5.7.2.4" class="ltx_td ltx_align_center ltx_border_t">42.2 / 29.5</td>
<td id="S5.T3.5.7.2.5" class="ltx_td ltx_align_center ltx_border_t">38.4 / 26.0</td>
</tr>
<tr id="S5.T3.5.8.3" class="ltx_tr">
<th id="S5.T3.5.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">XLM <cite class="ltx_cite ltx_citemacro_cite">Hu etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite><span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We used the script released by the authors, see <a target="_blank" href="https://github.com/google-research/xtreme/blob/master/scripts/train_qa.sh" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/google-research/xtreme/blob/master/scripts/train_qa.sh</a></span></span></span>
</th>
<td id="S5.T3.5.8.3.2" class="ltx_td ltx_align_center">340M</td>
<td id="S5.T3.5.8.3.3" class="ltx_td ltx_align_center">No</td>
<td id="S5.T3.5.8.3.4" class="ltx_td ltx_align_center">68.5/52.8</td>
<td id="S5.T3.5.8.3.5" class="ltx_td ltx_align_center">
<span id="S5.T3.5.8.3.5.1" class="ltx_text ltx_font_bold">65.4</span> / 47.9</td>
</tr>
<tr id="S5.T3.5.9.4" class="ltx_tr">
<th id="S5.T3.5.9.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">English as Pivot</th>
<td id="S5.T3.5.9.4.2" class="ltx_td ltx_align_center ltx_border_t">66M</td>
<td id="S5.T3.5.9.4.3" class="ltx_td ltx_align_center ltx_border_t">Yes</td>
<td id="S5.T3.5.9.4.4" class="ltx_td ltx_align_center ltx_border_t">46.2 / 30.9</td>
<td id="S5.T3.5.9.4.5" class="ltx_td ltx_align_center ltx_border_t">36.1 / 23.0</td>
</tr>
<tr id="S5.T3.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S5.T3.1.1.1.m1.1" class="ltx_Math" alttext="MiniLM_{+synth}" display="inline"><semantics id="S5.T3.1.1.1.m1.1a"><mrow id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml"><mi id="S5.T3.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.1" xref="S5.T3.1.1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.3" xref="S5.T3.1.1.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.1a" xref="S5.T3.1.1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.4" xref="S5.T3.1.1.1.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.1b" xref="S5.T3.1.1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.5" xref="S5.T3.1.1.1.m1.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.1c" xref="S5.T3.1.1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.6" xref="S5.T3.1.1.1.m1.1.1.6.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.1d" xref="S5.T3.1.1.1.m1.1.1.1.cmml">â€‹</mo><msub id="S5.T3.1.1.1.m1.1.1.7" xref="S5.T3.1.1.1.m1.1.1.7.cmml"><mi id="S5.T3.1.1.1.m1.1.1.7.2" xref="S5.T3.1.1.1.m1.1.1.7.2.cmml">M</mi><mrow id="S5.T3.1.1.1.m1.1.1.7.3" xref="S5.T3.1.1.1.m1.1.1.7.3.cmml"><mo id="S5.T3.1.1.1.m1.1.1.7.3a" xref="S5.T3.1.1.1.m1.1.1.7.3.cmml">+</mo><mrow id="S5.T3.1.1.1.m1.1.1.7.3.2" xref="S5.T3.1.1.1.m1.1.1.7.3.2.cmml"><mi id="S5.T3.1.1.1.m1.1.1.7.3.2.2" xref="S5.T3.1.1.1.m1.1.1.7.3.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.7.3.2.1" xref="S5.T3.1.1.1.m1.1.1.7.3.2.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.7.3.2.3" xref="S5.T3.1.1.1.m1.1.1.7.3.2.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.7.3.2.1a" xref="S5.T3.1.1.1.m1.1.1.7.3.2.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.7.3.2.4" xref="S5.T3.1.1.1.m1.1.1.7.3.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.7.3.2.1b" xref="S5.T3.1.1.1.m1.1.1.7.3.2.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.7.3.2.5" xref="S5.T3.1.1.1.m1.1.1.7.3.2.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.1.1.1.m1.1.1.7.3.2.1c" xref="S5.T3.1.1.1.m1.1.1.7.3.2.1.cmml">â€‹</mo><mi id="S5.T3.1.1.1.m1.1.1.7.3.2.6" xref="S5.T3.1.1.1.m1.1.1.7.3.2.6.cmml">h</mi></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1"><times id="S5.T3.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1.1"></times><ci id="S5.T3.1.1.1.m1.1.1.2.cmml" xref="S5.T3.1.1.1.m1.1.1.2">ğ‘€</ci><ci id="S5.T3.1.1.1.m1.1.1.3.cmml" xref="S5.T3.1.1.1.m1.1.1.3">ğ‘–</ci><ci id="S5.T3.1.1.1.m1.1.1.4.cmml" xref="S5.T3.1.1.1.m1.1.1.4">ğ‘›</ci><ci id="S5.T3.1.1.1.m1.1.1.5.cmml" xref="S5.T3.1.1.1.m1.1.1.5">ğ‘–</ci><ci id="S5.T3.1.1.1.m1.1.1.6.cmml" xref="S5.T3.1.1.1.m1.1.1.6">ğ¿</ci><apply id="S5.T3.1.1.1.m1.1.1.7.cmml" xref="S5.T3.1.1.1.m1.1.1.7"><csymbol cd="ambiguous" id="S5.T3.1.1.1.m1.1.1.7.1.cmml" xref="S5.T3.1.1.1.m1.1.1.7">subscript</csymbol><ci id="S5.T3.1.1.1.m1.1.1.7.2.cmml" xref="S5.T3.1.1.1.m1.1.1.7.2">ğ‘€</ci><apply id="S5.T3.1.1.1.m1.1.1.7.3.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3"><plus id="S5.T3.1.1.1.m1.1.1.7.3.1.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3"></plus><apply id="S5.T3.1.1.1.m1.1.1.7.3.2.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3.2"><times id="S5.T3.1.1.1.m1.1.1.7.3.2.1.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3.2.1"></times><ci id="S5.T3.1.1.1.m1.1.1.7.3.2.2.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3.2.2">ğ‘ </ci><ci id="S5.T3.1.1.1.m1.1.1.7.3.2.3.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3.2.3">ğ‘¦</ci><ci id="S5.T3.1.1.1.m1.1.1.7.3.2.4.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3.2.4">ğ‘›</ci><ci id="S5.T3.1.1.1.m1.1.1.7.3.2.5.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3.2.5">ğ‘¡</ci><ci id="S5.T3.1.1.1.m1.1.1.7.3.2.6.cmml" xref="S5.T3.1.1.1.m1.1.1.7.3.2.6">â„</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">MiniLM_{+synth}</annotation></semantics></math></th>
<td id="S5.T3.1.1.2" class="ltx_td ltx_align_center">66M</td>
<td id="S5.T3.1.1.3" class="ltx_td ltx_align_center">No</td>
<td id="S5.T3.1.1.4" class="ltx_td ltx_align_center">44.8 / 33.1</td>
<td id="S5.T3.1.1.5" class="ltx_td ltx_align_center">39.8 / 27.5</td>
</tr>
<tr id="S5.T3.2.2" class="ltx_tr">
<th id="S5.T3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S5.T3.2.2.1.m1.1" class="ltx_Math" alttext="MiniLM_{+SQuAD-trans}" display="inline"><semantics id="S5.T3.2.2.1.m1.1a"><mrow id="S5.T3.2.2.1.m1.1.1" xref="S5.T3.2.2.1.m1.1.1.cmml"><mi id="S5.T3.2.2.1.m1.1.1.2" xref="S5.T3.2.2.1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.1" xref="S5.T3.2.2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.3" xref="S5.T3.2.2.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.1a" xref="S5.T3.2.2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.4" xref="S5.T3.2.2.1.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.1b" xref="S5.T3.2.2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.5" xref="S5.T3.2.2.1.m1.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.1c" xref="S5.T3.2.2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.6" xref="S5.T3.2.2.1.m1.1.1.6.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.1d" xref="S5.T3.2.2.1.m1.1.1.1.cmml">â€‹</mo><msub id="S5.T3.2.2.1.m1.1.1.7" xref="S5.T3.2.2.1.m1.1.1.7.cmml"><mi id="S5.T3.2.2.1.m1.1.1.7.2" xref="S5.T3.2.2.1.m1.1.1.7.2.cmml">M</mi><mrow id="S5.T3.2.2.1.m1.1.1.7.3" xref="S5.T3.2.2.1.m1.1.1.7.3.cmml"><mrow id="S5.T3.2.2.1.m1.1.1.7.3.2" xref="S5.T3.2.2.1.m1.1.1.7.3.2.cmml"><mo id="S5.T3.2.2.1.m1.1.1.7.3.2a" xref="S5.T3.2.2.1.m1.1.1.7.3.2.cmml">+</mo><mrow id="S5.T3.2.2.1.m1.1.1.7.3.2.2" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.cmml"><mi id="S5.T3.2.2.1.m1.1.1.7.3.2.2.2" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.2.2.1" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.2.2.3" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.3.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.2.2.1a" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.2.2.4" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.2.2.1b" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.2.2.5" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.2.2.1c" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.2.2.6" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.6.cmml">D</mi></mrow></mrow><mo id="S5.T3.2.2.1.m1.1.1.7.3.1" xref="S5.T3.2.2.1.m1.1.1.7.3.1.cmml">âˆ’</mo><mrow id="S5.T3.2.2.1.m1.1.1.7.3.3" xref="S5.T3.2.2.1.m1.1.1.7.3.3.cmml"><mi id="S5.T3.2.2.1.m1.1.1.7.3.3.2" xref="S5.T3.2.2.1.m1.1.1.7.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.3.1" xref="S5.T3.2.2.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.3.3" xref="S5.T3.2.2.1.m1.1.1.7.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.3.1a" xref="S5.T3.2.2.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.3.4" xref="S5.T3.2.2.1.m1.1.1.7.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.3.1b" xref="S5.T3.2.2.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.3.5" xref="S5.T3.2.2.1.m1.1.1.7.3.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.2.1.m1.1.1.7.3.3.1c" xref="S5.T3.2.2.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.2.2.1.m1.1.1.7.3.3.6" xref="S5.T3.2.2.1.m1.1.1.7.3.3.6.cmml">s</mi></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.1.m1.1b"><apply id="S5.T3.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.1.m1.1.1"><times id="S5.T3.2.2.1.m1.1.1.1.cmml" xref="S5.T3.2.2.1.m1.1.1.1"></times><ci id="S5.T3.2.2.1.m1.1.1.2.cmml" xref="S5.T3.2.2.1.m1.1.1.2">ğ‘€</ci><ci id="S5.T3.2.2.1.m1.1.1.3.cmml" xref="S5.T3.2.2.1.m1.1.1.3">ğ‘–</ci><ci id="S5.T3.2.2.1.m1.1.1.4.cmml" xref="S5.T3.2.2.1.m1.1.1.4">ğ‘›</ci><ci id="S5.T3.2.2.1.m1.1.1.5.cmml" xref="S5.T3.2.2.1.m1.1.1.5">ğ‘–</ci><ci id="S5.T3.2.2.1.m1.1.1.6.cmml" xref="S5.T3.2.2.1.m1.1.1.6">ğ¿</ci><apply id="S5.T3.2.2.1.m1.1.1.7.cmml" xref="S5.T3.2.2.1.m1.1.1.7"><csymbol cd="ambiguous" id="S5.T3.2.2.1.m1.1.1.7.1.cmml" xref="S5.T3.2.2.1.m1.1.1.7">subscript</csymbol><ci id="S5.T3.2.2.1.m1.1.1.7.2.cmml" xref="S5.T3.2.2.1.m1.1.1.7.2">ğ‘€</ci><apply id="S5.T3.2.2.1.m1.1.1.7.3.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3"><minus id="S5.T3.2.2.1.m1.1.1.7.3.1.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.1"></minus><apply id="S5.T3.2.2.1.m1.1.1.7.3.2.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2"><plus id="S5.T3.2.2.1.m1.1.1.7.3.2.1.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2"></plus><apply id="S5.T3.2.2.1.m1.1.1.7.3.2.2.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2"><times id="S5.T3.2.2.1.m1.1.1.7.3.2.2.1.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.1"></times><ci id="S5.T3.2.2.1.m1.1.1.7.3.2.2.2.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.2">ğ‘†</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.2.2.3.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.3">ğ‘„</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.2.2.4.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.4">ğ‘¢</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.2.2.5.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.5">ğ´</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.2.2.6.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.2.2.6">ğ·</ci></apply></apply><apply id="S5.T3.2.2.1.m1.1.1.7.3.3.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.3"><times id="S5.T3.2.2.1.m1.1.1.7.3.3.1.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.3.1"></times><ci id="S5.T3.2.2.1.m1.1.1.7.3.3.2.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.3.2">ğ‘¡</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.3.3.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.3.3">ğ‘Ÿ</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.3.4.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.3.4">ğ‘</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.3.5.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.3.5">ğ‘›</ci><ci id="S5.T3.2.2.1.m1.1.1.7.3.3.6.cmml" xref="S5.T3.2.2.1.m1.1.1.7.3.3.6">ğ‘ </ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.1.m1.1c">MiniLM_{+SQuAD-trans}</annotation></semantics></math></th>
<td id="S5.T3.2.2.2" class="ltx_td ltx_align_center">66M</td>
<td id="S5.T3.2.2.3" class="ltx_td ltx_align_center">Yes</td>
<td id="S5.T3.2.2.4" class="ltx_td ltx_align_center">55.0 / 40.7</td>
<td id="S5.T3.2.2.5" class="ltx_td ltx_align_center">49.5 / 35.3</td>
</tr>
<tr id="S5.T3.3.3" class="ltx_tr">
<th id="S5.T3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S5.T3.3.3.1.m1.1" class="ltx_Math" alttext="MiniLM_{+synth-trans}" display="inline"><semantics id="S5.T3.3.3.1.m1.1a"><mrow id="S5.T3.3.3.1.m1.1.1" xref="S5.T3.3.3.1.m1.1.1.cmml"><mi id="S5.T3.3.3.1.m1.1.1.2" xref="S5.T3.3.3.1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.1" xref="S5.T3.3.3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.3" xref="S5.T3.3.3.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.1a" xref="S5.T3.3.3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.4" xref="S5.T3.3.3.1.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.1b" xref="S5.T3.3.3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.5" xref="S5.T3.3.3.1.m1.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.1c" xref="S5.T3.3.3.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.6" xref="S5.T3.3.3.1.m1.1.1.6.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.1d" xref="S5.T3.3.3.1.m1.1.1.1.cmml">â€‹</mo><msub id="S5.T3.3.3.1.m1.1.1.7" xref="S5.T3.3.3.1.m1.1.1.7.cmml"><mi id="S5.T3.3.3.1.m1.1.1.7.2" xref="S5.T3.3.3.1.m1.1.1.7.2.cmml">M</mi><mrow id="S5.T3.3.3.1.m1.1.1.7.3" xref="S5.T3.3.3.1.m1.1.1.7.3.cmml"><mrow id="S5.T3.3.3.1.m1.1.1.7.3.2" xref="S5.T3.3.3.1.m1.1.1.7.3.2.cmml"><mo id="S5.T3.3.3.1.m1.1.1.7.3.2a" xref="S5.T3.3.3.1.m1.1.1.7.3.2.cmml">+</mo><mrow id="S5.T3.3.3.1.m1.1.1.7.3.2.2" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.cmml"><mi id="S5.T3.3.3.1.m1.1.1.7.3.2.2.2" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.2.2.1" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.2.2.3" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.2.2.1a" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.2.2.4" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.2.2.1b" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.2.2.5" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.2.2.1c" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.2.2.6" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.6.cmml">h</mi></mrow></mrow><mo id="S5.T3.3.3.1.m1.1.1.7.3.1" xref="S5.T3.3.3.1.m1.1.1.7.3.1.cmml">âˆ’</mo><mrow id="S5.T3.3.3.1.m1.1.1.7.3.3" xref="S5.T3.3.3.1.m1.1.1.7.3.3.cmml"><mi id="S5.T3.3.3.1.m1.1.1.7.3.3.2" xref="S5.T3.3.3.1.m1.1.1.7.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.3.1" xref="S5.T3.3.3.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.3.3" xref="S5.T3.3.3.1.m1.1.1.7.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.3.1a" xref="S5.T3.3.3.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.3.4" xref="S5.T3.3.3.1.m1.1.1.7.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.3.1b" xref="S5.T3.3.3.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.3.5" xref="S5.T3.3.3.1.m1.1.1.7.3.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.3.3.1.m1.1.1.7.3.3.1c" xref="S5.T3.3.3.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.3.3.1.m1.1.1.7.3.3.6" xref="S5.T3.3.3.1.m1.1.1.7.3.3.6.cmml">s</mi></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.1.m1.1b"><apply id="S5.T3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1"><times id="S5.T3.3.3.1.m1.1.1.1.cmml" xref="S5.T3.3.3.1.m1.1.1.1"></times><ci id="S5.T3.3.3.1.m1.1.1.2.cmml" xref="S5.T3.3.3.1.m1.1.1.2">ğ‘€</ci><ci id="S5.T3.3.3.1.m1.1.1.3.cmml" xref="S5.T3.3.3.1.m1.1.1.3">ğ‘–</ci><ci id="S5.T3.3.3.1.m1.1.1.4.cmml" xref="S5.T3.3.3.1.m1.1.1.4">ğ‘›</ci><ci id="S5.T3.3.3.1.m1.1.1.5.cmml" xref="S5.T3.3.3.1.m1.1.1.5">ğ‘–</ci><ci id="S5.T3.3.3.1.m1.1.1.6.cmml" xref="S5.T3.3.3.1.m1.1.1.6">ğ¿</ci><apply id="S5.T3.3.3.1.m1.1.1.7.cmml" xref="S5.T3.3.3.1.m1.1.1.7"><csymbol cd="ambiguous" id="S5.T3.3.3.1.m1.1.1.7.1.cmml" xref="S5.T3.3.3.1.m1.1.1.7">subscript</csymbol><ci id="S5.T3.3.3.1.m1.1.1.7.2.cmml" xref="S5.T3.3.3.1.m1.1.1.7.2">ğ‘€</ci><apply id="S5.T3.3.3.1.m1.1.1.7.3.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3"><minus id="S5.T3.3.3.1.m1.1.1.7.3.1.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.1"></minus><apply id="S5.T3.3.3.1.m1.1.1.7.3.2.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2"><plus id="S5.T3.3.3.1.m1.1.1.7.3.2.1.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2"></plus><apply id="S5.T3.3.3.1.m1.1.1.7.3.2.2.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2"><times id="S5.T3.3.3.1.m1.1.1.7.3.2.2.1.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.1"></times><ci id="S5.T3.3.3.1.m1.1.1.7.3.2.2.2.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.2">ğ‘ </ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.2.2.3.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.3">ğ‘¦</ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.2.2.4.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.4">ğ‘›</ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.2.2.5.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.5">ğ‘¡</ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.2.2.6.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.2.2.6">â„</ci></apply></apply><apply id="S5.T3.3.3.1.m1.1.1.7.3.3.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.3"><times id="S5.T3.3.3.1.m1.1.1.7.3.3.1.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.3.1"></times><ci id="S5.T3.3.3.1.m1.1.1.7.3.3.2.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.3.2">ğ‘¡</ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.3.3.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.3.3">ğ‘Ÿ</ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.3.4.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.3.4">ğ‘</ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.3.5.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.3.5">ğ‘›</ci><ci id="S5.T3.3.3.1.m1.1.1.7.3.3.6.cmml" xref="S5.T3.3.3.1.m1.1.1.7.3.3.6">ğ‘ </ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.1.m1.1c">MiniLM_{+synth-trans}</annotation></semantics></math></th>
<td id="S5.T3.3.3.2" class="ltx_td ltx_align_center">66M</td>
<td id="S5.T3.3.3.3" class="ltx_td ltx_align_center">Yes</td>
<td id="S5.T3.3.3.4" class="ltx_td ltx_align_center">63.3 / 49.1</td>
<td id="S5.T3.3.3.5" class="ltx_td ltx_align_center">56.1 / 41.4</td>
</tr>
<tr id="S5.T3.4.4" class="ltx_tr">
<th id="S5.T3.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S5.T3.4.4.1.m1.1" class="ltx_Math" alttext="MiniLM_{+SQuAD-trans+synth-trans}" display="inline"><semantics id="S5.T3.4.4.1.m1.1a"><mrow id="S5.T3.4.4.1.m1.1.1" xref="S5.T3.4.4.1.m1.1.1.cmml"><mi id="S5.T3.4.4.1.m1.1.1.2" xref="S5.T3.4.4.1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.1" xref="S5.T3.4.4.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.3" xref="S5.T3.4.4.1.m1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.1a" xref="S5.T3.4.4.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.4" xref="S5.T3.4.4.1.m1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.1b" xref="S5.T3.4.4.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.5" xref="S5.T3.4.4.1.m1.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.1c" xref="S5.T3.4.4.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.6" xref="S5.T3.4.4.1.m1.1.1.6.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.1d" xref="S5.T3.4.4.1.m1.1.1.1.cmml">â€‹</mo><msub id="S5.T3.4.4.1.m1.1.1.7" xref="S5.T3.4.4.1.m1.1.1.7.cmml"><mi id="S5.T3.4.4.1.m1.1.1.7.2" xref="S5.T3.4.4.1.m1.1.1.7.2.cmml">M</mi><mrow id="S5.T3.4.4.1.m1.1.1.7.3" xref="S5.T3.4.4.1.m1.1.1.7.3.cmml"><mrow id="S5.T3.4.4.1.m1.1.1.7.3.2" xref="S5.T3.4.4.1.m1.1.1.7.3.2.cmml"><mrow id="S5.T3.4.4.1.m1.1.1.7.3.2.2" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.cmml"><mrow id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.cmml"><mo id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2a" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.cmml">+</mo><mrow id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.cmml"><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.2" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.3" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.3.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1a" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.4" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1b" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.5" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.5.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1c" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.6" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.6.cmml">D</mi></mrow></mrow><mo id="S5.T3.4.4.1.m1.1.1.7.3.2.2.1" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.1.cmml">âˆ’</mo><mrow id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.cmml"><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.2" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.3" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1a" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.4" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1b" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.5" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1c" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.6" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.6.cmml">s</mi></mrow></mrow><mo id="S5.T3.4.4.1.m1.1.1.7.3.2.1" xref="S5.T3.4.4.1.m1.1.1.7.3.2.1.cmml">+</mo><mrow id="S5.T3.4.4.1.m1.1.1.7.3.2.3" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.cmml"><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.3.2" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.3.1" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.3.3" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.3.1a" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.3.4" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.3.1b" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.3.5" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.2.3.1c" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.2.3.6" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.6.cmml">h</mi></mrow></mrow><mo id="S5.T3.4.4.1.m1.1.1.7.3.1" xref="S5.T3.4.4.1.m1.1.1.7.3.1.cmml">âˆ’</mo><mrow id="S5.T3.4.4.1.m1.1.1.7.3.3" xref="S5.T3.4.4.1.m1.1.1.7.3.3.cmml"><mi id="S5.T3.4.4.1.m1.1.1.7.3.3.2" xref="S5.T3.4.4.1.m1.1.1.7.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.3.1" xref="S5.T3.4.4.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.3.3" xref="S5.T3.4.4.1.m1.1.1.7.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.3.1a" xref="S5.T3.4.4.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.3.4" xref="S5.T3.4.4.1.m1.1.1.7.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.3.1b" xref="S5.T3.4.4.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.3.5" xref="S5.T3.4.4.1.m1.1.1.7.3.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.4.1.m1.1.1.7.3.3.1c" xref="S5.T3.4.4.1.m1.1.1.7.3.3.1.cmml">â€‹</mo><mi id="S5.T3.4.4.1.m1.1.1.7.3.3.6" xref="S5.T3.4.4.1.m1.1.1.7.3.3.6.cmml">s</mi></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.1.m1.1b"><apply id="S5.T3.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1"><times id="S5.T3.4.4.1.m1.1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1.1"></times><ci id="S5.T3.4.4.1.m1.1.1.2.cmml" xref="S5.T3.4.4.1.m1.1.1.2">ğ‘€</ci><ci id="S5.T3.4.4.1.m1.1.1.3.cmml" xref="S5.T3.4.4.1.m1.1.1.3">ğ‘–</ci><ci id="S5.T3.4.4.1.m1.1.1.4.cmml" xref="S5.T3.4.4.1.m1.1.1.4">ğ‘›</ci><ci id="S5.T3.4.4.1.m1.1.1.5.cmml" xref="S5.T3.4.4.1.m1.1.1.5">ğ‘–</ci><ci id="S5.T3.4.4.1.m1.1.1.6.cmml" xref="S5.T3.4.4.1.m1.1.1.6">ğ¿</ci><apply id="S5.T3.4.4.1.m1.1.1.7.cmml" xref="S5.T3.4.4.1.m1.1.1.7"><csymbol cd="ambiguous" id="S5.T3.4.4.1.m1.1.1.7.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7">subscript</csymbol><ci id="S5.T3.4.4.1.m1.1.1.7.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.2">ğ‘€</ci><apply id="S5.T3.4.4.1.m1.1.1.7.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3"><minus id="S5.T3.4.4.1.m1.1.1.7.3.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.1"></minus><apply id="S5.T3.4.4.1.m1.1.1.7.3.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2"><plus id="S5.T3.4.4.1.m1.1.1.7.3.2.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.1"></plus><apply id="S5.T3.4.4.1.m1.1.1.7.3.2.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2"><minus id="S5.T3.4.4.1.m1.1.1.7.3.2.2.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.1"></minus><apply id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2"><plus id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2"></plus><apply id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2"><times id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.1"></times><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.2">ğ‘†</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.3">ğ‘„</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.4.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.4">ğ‘¢</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.5.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.5">ğ´</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.6.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.2.2.6">ğ·</ci></apply></apply><apply id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3"><times id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.1"></times><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.2">ğ‘¡</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.3">ğ‘Ÿ</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.4.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.4">ğ‘</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.5.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.5">ğ‘›</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.6.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.2.3.6">ğ‘ </ci></apply></apply><apply id="S5.T3.4.4.1.m1.1.1.7.3.2.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3"><times id="S5.T3.4.4.1.m1.1.1.7.3.2.3.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.1"></times><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.3.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.2">ğ‘ </ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.3.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.3">ğ‘¦</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.3.4.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.4">ğ‘›</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.3.5.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.5">ğ‘¡</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.2.3.6.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.2.3.6">â„</ci></apply></apply><apply id="S5.T3.4.4.1.m1.1.1.7.3.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.3"><times id="S5.T3.4.4.1.m1.1.1.7.3.3.1.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.3.1"></times><ci id="S5.T3.4.4.1.m1.1.1.7.3.3.2.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.3.2">ğ‘¡</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.3.3.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.3.3">ğ‘Ÿ</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.3.4.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.3.4">ğ‘</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.3.5.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.3.5">ğ‘›</ci><ci id="S5.T3.4.4.1.m1.1.1.7.3.3.6.cmml" xref="S5.T3.4.4.1.m1.1.1.7.3.3.6">ğ‘ </ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.1.m1.1c">MiniLM_{+SQuAD-trans+synth-trans}</annotation></semantics></math></th>
<td id="S5.T3.4.4.2" class="ltx_td ltx_align_center">66M</td>
<td id="S5.T3.4.4.3" class="ltx_td ltx_align_center">Yes</td>
<td id="S5.T3.4.4.4" class="ltx_td ltx_align_center">62.5 / 48.6</td>
<td id="S5.T3.4.4.5" class="ltx_td ltx_align_center">55.0 / 40.4</td>
</tr>
<tr id="S5.T3.5.5" class="ltx_tr">
<th id="S5.T3.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><math id="S5.T3.5.5.1.m1.1" class="ltx_Math" alttext="XLM-R_{+synth-trans}" display="inline"><semantics id="S5.T3.5.5.1.m1.1a"><mrow id="S5.T3.5.5.1.m1.1.1" xref="S5.T3.5.5.1.m1.1.1.cmml"><mrow id="S5.T3.5.5.1.m1.1.1.2" xref="S5.T3.5.5.1.m1.1.1.2.cmml"><mi id="S5.T3.5.5.1.m1.1.1.2.2" xref="S5.T3.5.5.1.m1.1.1.2.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.2.1" xref="S5.T3.5.5.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.2.3" xref="S5.T3.5.5.1.m1.1.1.2.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.2.1a" xref="S5.T3.5.5.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.2.4" xref="S5.T3.5.5.1.m1.1.1.2.4.cmml">M</mi></mrow><mo id="S5.T3.5.5.1.m1.1.1.1" xref="S5.T3.5.5.1.m1.1.1.1.cmml">âˆ’</mo><msub id="S5.T3.5.5.1.m1.1.1.3" xref="S5.T3.5.5.1.m1.1.1.3.cmml"><mi id="S5.T3.5.5.1.m1.1.1.3.2" xref="S5.T3.5.5.1.m1.1.1.3.2.cmml">R</mi><mrow id="S5.T3.5.5.1.m1.1.1.3.3" xref="S5.T3.5.5.1.m1.1.1.3.3.cmml"><mrow id="S5.T3.5.5.1.m1.1.1.3.3.2" xref="S5.T3.5.5.1.m1.1.1.3.3.2.cmml"><mo id="S5.T3.5.5.1.m1.1.1.3.3.2a" xref="S5.T3.5.5.1.m1.1.1.3.3.2.cmml">+</mo><mrow id="S5.T3.5.5.1.m1.1.1.3.3.2.2" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.cmml"><mi id="S5.T3.5.5.1.m1.1.1.3.3.2.2.2" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.2.2.1" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.2.2.3" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.2.2.1a" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.2.2.4" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.2.2.1b" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.2.2.5" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.2.2.1c" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.2.2.6" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.6.cmml">h</mi></mrow></mrow><mo id="S5.T3.5.5.1.m1.1.1.3.3.1" xref="S5.T3.5.5.1.m1.1.1.3.3.1.cmml">âˆ’</mo><mrow id="S5.T3.5.5.1.m1.1.1.3.3.3" xref="S5.T3.5.5.1.m1.1.1.3.3.3.cmml"><mi id="S5.T3.5.5.1.m1.1.1.3.3.3.2" xref="S5.T3.5.5.1.m1.1.1.3.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.3.1" xref="S5.T3.5.5.1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.3.3" xref="S5.T3.5.5.1.m1.1.1.3.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.3.1a" xref="S5.T3.5.5.1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.3.4" xref="S5.T3.5.5.1.m1.1.1.3.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.3.1b" xref="S5.T3.5.5.1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.3.5" xref="S5.T3.5.5.1.m1.1.1.3.3.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.5.5.1.m1.1.1.3.3.3.1c" xref="S5.T3.5.5.1.m1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S5.T3.5.5.1.m1.1.1.3.3.3.6" xref="S5.T3.5.5.1.m1.1.1.3.3.3.6.cmml">s</mi></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.1.m1.1b"><apply id="S5.T3.5.5.1.m1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1"><minus id="S5.T3.5.5.1.m1.1.1.1.cmml" xref="S5.T3.5.5.1.m1.1.1.1"></minus><apply id="S5.T3.5.5.1.m1.1.1.2.cmml" xref="S5.T3.5.5.1.m1.1.1.2"><times id="S5.T3.5.5.1.m1.1.1.2.1.cmml" xref="S5.T3.5.5.1.m1.1.1.2.1"></times><ci id="S5.T3.5.5.1.m1.1.1.2.2.cmml" xref="S5.T3.5.5.1.m1.1.1.2.2">ğ‘‹</ci><ci id="S5.T3.5.5.1.m1.1.1.2.3.cmml" xref="S5.T3.5.5.1.m1.1.1.2.3">ğ¿</ci><ci id="S5.T3.5.5.1.m1.1.1.2.4.cmml" xref="S5.T3.5.5.1.m1.1.1.2.4">ğ‘€</ci></apply><apply id="S5.T3.5.5.1.m1.1.1.3.cmml" xref="S5.T3.5.5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.5.5.1.m1.1.1.3.1.cmml" xref="S5.T3.5.5.1.m1.1.1.3">subscript</csymbol><ci id="S5.T3.5.5.1.m1.1.1.3.2.cmml" xref="S5.T3.5.5.1.m1.1.1.3.2">ğ‘…</ci><apply id="S5.T3.5.5.1.m1.1.1.3.3.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3"><minus id="S5.T3.5.5.1.m1.1.1.3.3.1.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.1"></minus><apply id="S5.T3.5.5.1.m1.1.1.3.3.2.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2"><plus id="S5.T3.5.5.1.m1.1.1.3.3.2.1.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2"></plus><apply id="S5.T3.5.5.1.m1.1.1.3.3.2.2.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2"><times id="S5.T3.5.5.1.m1.1.1.3.3.2.2.1.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.1"></times><ci id="S5.T3.5.5.1.m1.1.1.3.3.2.2.2.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.2">ğ‘ </ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.2.2.3.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.3">ğ‘¦</ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.2.2.4.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.4">ğ‘›</ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.2.2.5.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.5">ğ‘¡</ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.2.2.6.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.2.2.6">â„</ci></apply></apply><apply id="S5.T3.5.5.1.m1.1.1.3.3.3.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.3"><times id="S5.T3.5.5.1.m1.1.1.3.3.3.1.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.3.1"></times><ci id="S5.T3.5.5.1.m1.1.1.3.3.3.2.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.3.2">ğ‘¡</ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.3.3.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.3.3">ğ‘Ÿ</ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.3.4.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.3.4">ğ‘</ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.3.5.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.3.5">ğ‘›</ci><ci id="S5.T3.5.5.1.m1.1.1.3.3.3.6.cmml" xref="S5.T3.5.5.1.m1.1.1.3.3.3.6">ğ‘ </ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.1.m1.1c">XLM-R_{+synth-trans}</annotation></semantics></math></th>
<td id="S5.T3.5.5.2" class="ltx_td ltx_align_center ltx_border_bb">340M</td>
<td id="S5.T3.5.5.3" class="ltx_td ltx_align_center ltx_border_bb">Yes</td>
<td id="S5.T3.5.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.5.5.4.1" class="ltx_text ltx_font_bold">74.3 / 59.2</span></td>
<td id="S5.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.5.5.5.1" class="ltx_text ltx_font_bold">65.3 / 49.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 3: </span>Results (F1 / EM) of the different QA models on XQuAD and MLQA. XLM corresponds to the large version.</figcaption>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We report the main results of our experiments on XQuAD and MLQA in TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.2 Question Answering â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The scores correspond to the average over all the different possible combination of languages (<em id="S5.SS2.p1.1.1" class="ltx_emph ltx_font_italic">de-de</em>, <em id="S5.SS2.p1.1.2" class="ltx_emph ltx_font_italic">de-ar</em>, etc.).</p>
</div>
<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">English as Pivot</h4>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.1" class="ltx_p">Using English as a pivot does not lead to good results. This may be due to the evaluation metrics, which are based on <math id="S5.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S5.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.1.m1.1c">n</annotation></semantics></math>-grams similarity. For extractive QA, F1 and EM metrics measure the overlap between the predicted answer and the ground truth. Therefore, meaningful answers worded differently are penalized, a situation that is likely to occur because of the back-translation mechanism. This makes automatic evaluation challenging for this setup, as metrics suffer from similar difficulties as those observed for text generation <cite class="ltx_cite ltx_citemacro_cite">Sulem etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2018</a>)</cite>.
As an additional downside, this model requires multiple translations <em id="S5.SS2.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">at inference time</em>. For these reasons, we decided not to explore this approach further.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Synthetic without translation (+synth)</h4>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.1" class="ltx_p">Compared to the MiniLM baseline, we observe a small performance increase for MiniLM<sub id="S5.SS2.SSS0.Px2.p1.1.1" class="ltx_sub">+synth</sub> (Exact Match increases from 29.5 to 33.1 on XQuAD and from 26.0 to 27.5 on MLQA).</p>
</div>
<div id="S5.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p2.1" class="ltx_p">During the self-supervised pre-training stage, the model was exposed to multilingual inputs. Yet, for a given input, the target language was always consistent, preventing the model to be exposed to such a cross-lingual scenario.
The synthetic inputs are composed of questions
in English (see examples in TableÂ <a href="#S5.T1" title="Table 1 â€£ 5.1 Question Generation â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) while the contexts can be in any languages. Therefore, the QA model is exposed for the first time to a cross-lingual scenario.
We hypothesise that such a cross-lingual ability is not innate for a default multilingual model: exposing a model to this scenario allows to develop this ability and contributes to improve its performance.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Synthetic with translation (+synth-trans)</h4>

<div id="S5.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px3.p1.1" class="ltx_p">:
For MiniLM<sub id="S5.SS2.SSS0.Px3.p1.1.1" class="ltx_sub">+synth-trans</sub>, we obtain a much larger improvement over its baselines, MiniLM, compared to MiniLM<sub id="S5.SS2.SSS0.Px3.p1.1.2" class="ltx_sub">+synth</sub>, on both MLQA and XQuAD. Also, it outperforms MiniLM<sub id="S5.SS2.SSS0.Px3.p1.1.3" class="ltx_sub">+SQuADâˆ’trans</sub>, indicating the benefit of our proposed approach.
This supports the intuition developed in the previous paragraph: independently of the multilingual capacity of the model, a cross-lingual ability is developed when the two inputs components are not exclusively written in the same language. In SectionÂ <a href="#S5.SS3" title="5.3 Discussion â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>, we discuss this phenomenon more in depth.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.2.3.1" class="ltx_tr">
<th id="S5.T4.2.3.1.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S5.T4.2.3.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column">#Params</th>
<th id="S5.T4.2.3.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column">PIAF (fr)</th>
<th id="S5.T4.2.3.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column">KorQuAD</th>
<th id="S5.T4.2.3.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column">SQuAD-it</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.2.4.1" class="ltx_tr">
<th id="S5.T4.2.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">MiniLM <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S5.T4.2.4.1.2" class="ltx_td ltx_align_right ltx_border_tt">66M</td>
<td id="S5.T4.2.4.1.3" class="ltx_td ltx_align_right ltx_border_tt">58.9 / 34.3</td>
<td id="S5.T4.2.4.1.4" class="ltx_td ltx_align_right ltx_border_tt">53.3 / 40.5</td>
<td id="S5.T4.2.4.1.5" class="ltx_td ltx_align_right ltx_border_tt">72.0 / 57.7</td>
</tr>
<tr id="S5.T4.2.5.2" class="ltx_tr">
<th id="S5.T4.2.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">mBert <cite class="ltx_cite ltx_citemacro_cite">Devlin etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>
</th>
<td id="S5.T4.2.5.2.2" class="ltx_td ltx_align_right">110M</td>
<td id="S5.T4.2.5.2.3" class="ltx_td ltx_align_right">64.4 / 42.5</td>
<td id="S5.T4.2.5.2.4" class="ltx_td ltx_align_right">-</td>
<td id="S5.T4.2.5.2.5" class="ltx_td ltx_align_right">74.1 / 62.5</td>
</tr>
<tr id="S5.T4.2.2" class="ltx_tr">
<th id="S5.T4.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row">CamemBERT <cite class="ltx_cite ltx_citemacro_cite">Martin etÂ al. (<a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</th>
<td id="S5.T4.2.2.4" class="ltx_td ltx_align_right">340M</td>
<td id="S5.T4.2.2.5" class="ltx_td ltx_align_right">68.9 / -</td>
<td id="S5.T4.1.1.1" class="ltx_td ltx_align_right"><math id="S5.T4.1.1.1.m1.1" class="ltx_Math" alttext="N/A" display="inline"><semantics id="S5.T4.1.1.1.m1.1a"><mrow id="S5.T4.1.1.1.m1.1.1" xref="S5.T4.1.1.1.m1.1.1.cmml"><mi id="S5.T4.1.1.1.m1.1.1.2" xref="S5.T4.1.1.1.m1.1.1.2.cmml">N</mi><mo id="S5.T4.1.1.1.m1.1.1.1" xref="S5.T4.1.1.1.m1.1.1.1.cmml">/</mo><mi id="S5.T4.1.1.1.m1.1.1.3" xref="S5.T4.1.1.1.m1.1.1.3.cmml">A</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.m1.1b"><apply id="S5.T4.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1"><divide id="S5.T4.1.1.1.m1.1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1.1"></divide><ci id="S5.T4.1.1.1.m1.1.1.2.cmml" xref="S5.T4.1.1.1.m1.1.1.2">ğ‘</ci><ci id="S5.T4.1.1.1.m1.1.1.3.cmml" xref="S5.T4.1.1.1.m1.1.1.3">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.m1.1c">N/A</annotation></semantics></math></td>
<td id="S5.T4.2.2.2" class="ltx_td ltx_align_right"><math id="S5.T4.2.2.2.m1.1" class="ltx_Math" alttext="N/A" display="inline"><semantics id="S5.T4.2.2.2.m1.1a"><mrow id="S5.T4.2.2.2.m1.1.1" xref="S5.T4.2.2.2.m1.1.1.cmml"><mi id="S5.T4.2.2.2.m1.1.1.2" xref="S5.T4.2.2.2.m1.1.1.2.cmml">N</mi><mo id="S5.T4.2.2.2.m1.1.1.1" xref="S5.T4.2.2.2.m1.1.1.1.cmml">/</mo><mi id="S5.T4.2.2.2.m1.1.1.3" xref="S5.T4.2.2.2.m1.1.1.3.cmml">A</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.m1.1b"><apply id="S5.T4.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.m1.1.1"><divide id="S5.T4.2.2.2.m1.1.1.1.cmml" xref="S5.T4.2.2.2.m1.1.1.1"></divide><ci id="S5.T4.2.2.2.m1.1.1.2.cmml" xref="S5.T4.2.2.2.m1.1.1.2">ğ‘</ci><ci id="S5.T4.2.2.2.m1.1.1.3.cmml" xref="S5.T4.2.2.2.m1.1.1.3">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.m1.1c">N/A</annotation></semantics></math></td>
</tr>
<tr id="S5.T4.2.6.3" class="ltx_tr">
<th id="S5.T4.2.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">MiniLM<sub id="S5.T4.2.6.3.1.1" class="ltx_sub">+synth</sub>
</th>
<td id="S5.T4.2.6.3.2" class="ltx_td ltx_align_right ltx_border_t">66M</td>
<td id="S5.T4.2.6.3.3" class="ltx_td ltx_align_right ltx_border_t">58.6 / 34.5</td>
<td id="S5.T4.2.6.3.4" class="ltx_td ltx_align_right ltx_border_t">52.1 / 39.0</td>
<td id="S5.T4.2.6.3.5" class="ltx_td ltx_align_right ltx_border_t">71.3 / 58.0</td>
</tr>
<tr id="S5.T4.2.7.4" class="ltx_tr">
<th id="S5.T4.2.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MiniLM<sub id="S5.T4.2.7.4.1.1" class="ltx_sub">+synth-trans</sub>
</th>
<td id="S5.T4.2.7.4.2" class="ltx_td ltx_align_right">66M</td>
<td id="S5.T4.2.7.4.3" class="ltx_td ltx_align_right">63.9 / 40.6</td>
<td id="S5.T4.2.7.4.4" class="ltx_td ltx_align_right">60.0 / 48.8</td>
<td id="S5.T4.2.7.4.5" class="ltx_td ltx_align_right">74.5 / 62.0</td>
</tr>
<tr id="S5.T4.2.8.5" class="ltx_tr">
<th id="S5.T4.2.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">XLM-R<sub id="S5.T4.2.8.5.1.1" class="ltx_sub">+synth-trans</sub>
</th>
<td id="S5.T4.2.8.5.2" class="ltx_td ltx_align_right ltx_border_bb">340M</td>
<td id="S5.T4.2.8.5.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.2.8.5.3.1" class="ltx_text ltx_font_bold">72.1 / 47.1</span></td>
<td id="S5.T4.2.8.5.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.2.8.5.4.1" class="ltx_text ltx_font_bold">63.0 / 52.8</span></td>
<td id="S5.T4.2.8.5.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.2.8.5.5.1" class="ltx_text ltx_font_bold">80.4 / 67.6</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 4: </span>Zero-shot results (F1 / EM) on PIAF, KorQuAD and SQuAD-it for our different QA models, compared to various baselines. For mBert on SQuAD-it, we report the score from <cite class="ltx_cite ltx_citemacro_citet">Croce etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2018</a>)</cite>. Note that CamemBERT is a French version of RoBERTa, an architecture widely outperforming BERT.</figcaption>
</figure>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Discussion</h3>

<section id="S5.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Cross Lingual Generalisation</h4>

<div id="S5.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px1.p1.3" class="ltx_p">To explore the modelsâ€™ effectiveness in dealing with cross-lingual inputs, we report in FigureÂ <a href="#S5.F1" title="Figure 1 â€£ Cross Lingual Generalisation â€£ 5.3 Discussion â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> the performance for our MiniLM<sub id="S5.SS3.SSS0.Px1.p1.3.1" class="ltx_sub">+synth-trans</sub> setup, varying the number of samples and the languages present in the synthetic data.
The abscissa <math id="S5.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.SS3.SSS0.Px1.p1.1.m1.1a"><mi id="S5.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS0.Px1.p1.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px1.p1.1.m1.1c">x</annotation></semantics></math> corresponds to the progressively increasing number of synthetic samples used; at <math id="S5.SS3.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="x=0" display="inline"><semantics id="S5.SS3.SSS0.Px1.p1.2.m2.1a"><mrow id="S5.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S5.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">x</mi><mo id="S5.SS3.SSS0.Px1.p1.2.m2.1.1.1" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.SSS0.Px1.p1.2.m2.1.1.3" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S5.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1"><eq id="S5.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1.1"></eq><ci id="S5.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1.2">ğ‘¥</ci><cn type="integer" id="S5.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S5.SS3.SSS0.Px1.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px1.p1.2.m2.1c">x=0</annotation></semantics></math>, it corresponds to the MiniLM<sub id="S5.SS3.SSS0.Px1.p1.3.2" class="ltx_sub">+trans</sub> baseline, where the model has access only to the original English data from SQuAD<sub id="S5.SS3.SSS0.Px1.p1.3.3" class="ltx_sub"><span id="S5.SS3.SSS0.Px1.p1.3.3.1" class="ltx_text ltx_font_italic">en</span></sub>.
We explore two sampling strategies for the synthetic examples:</p>
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><em id="S5.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">All Languages</em> corresponds to sampling the examples from any of the different languages.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.6" class="ltx_p">Conversely, for <em id="S5.I1.i2.p1.6.1" class="ltx_emph ltx_font_italic">Not All Languages</em>, we progressively added the different languages: for <math id="S5.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="x=50K" display="inline"><semantics id="S5.I1.i2.p1.1.m1.1a"><mrow id="S5.I1.i2.p1.1.m1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.cmml"><mi id="S5.I1.i2.p1.1.m1.1.1.2" xref="S5.I1.i2.p1.1.m1.1.1.2.cmml">x</mi><mo id="S5.I1.i2.p1.1.m1.1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S5.I1.i2.p1.1.m1.1.1.3" xref="S5.I1.i2.p1.1.m1.1.1.3.cmml"><mn id="S5.I1.i2.p1.1.m1.1.1.3.2" xref="S5.I1.i2.p1.1.m1.1.1.3.2.cmml">50</mn><mo lspace="0em" rspace="0em" id="S5.I1.i2.p1.1.m1.1.1.3.1" xref="S5.I1.i2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.I1.i2.p1.1.m1.1.1.3.3" xref="S5.I1.i2.p1.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.m1.1b"><apply id="S5.I1.i2.p1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1"><eq id="S5.I1.i2.p1.1.m1.1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1.1"></eq><ci id="S5.I1.i2.p1.1.m1.1.1.2.cmml" xref="S5.I1.i2.p1.1.m1.1.1.2">ğ‘¥</ci><apply id="S5.I1.i2.p1.1.m1.1.1.3.cmml" xref="S5.I1.i2.p1.1.m1.1.1.3"><times id="S5.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1.3.1"></times><cn type="integer" id="S5.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S5.I1.i2.p1.1.m1.1.1.3.2">50</cn><ci id="S5.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="S5.I1.i2.p1.1.m1.1.1.3.3">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.m1.1c">x=50K</annotation></semantics></math>, all the 50K synthetic data are on a unique language input, <math id="S5.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="L1" display="inline"><semantics id="S5.I1.i2.p1.2.m2.1a"><mrow id="S5.I1.i2.p1.2.m2.1.1" xref="S5.I1.i2.p1.2.m2.1.1.cmml"><mi id="S5.I1.i2.p1.2.m2.1.1.2" xref="S5.I1.i2.p1.2.m2.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.I1.i2.p1.2.m2.1.1.1" xref="S5.I1.i2.p1.2.m2.1.1.1.cmml">â€‹</mo><mn id="S5.I1.i2.p1.2.m2.1.1.3" xref="S5.I1.i2.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.2.m2.1b"><apply id="S5.I1.i2.p1.2.m2.1.1.cmml" xref="S5.I1.i2.p1.2.m2.1.1"><times id="S5.I1.i2.p1.2.m2.1.1.1.cmml" xref="S5.I1.i2.p1.2.m2.1.1.1"></times><ci id="S5.I1.i2.p1.2.m2.1.1.2.cmml" xref="S5.I1.i2.p1.2.m2.1.1.2">ğ¿</ci><cn type="integer" id="S5.I1.i2.p1.2.m2.1.1.3.cmml" xref="S5.I1.i2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.2.m2.1c">L1</annotation></semantics></math>. Then for <math id="S5.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="x=100K" display="inline"><semantics id="S5.I1.i2.p1.3.m3.1a"><mrow id="S5.I1.i2.p1.3.m3.1.1" xref="S5.I1.i2.p1.3.m3.1.1.cmml"><mi id="S5.I1.i2.p1.3.m3.1.1.2" xref="S5.I1.i2.p1.3.m3.1.1.2.cmml">x</mi><mo id="S5.I1.i2.p1.3.m3.1.1.1" xref="S5.I1.i2.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S5.I1.i2.p1.3.m3.1.1.3" xref="S5.I1.i2.p1.3.m3.1.1.3.cmml"><mn id="S5.I1.i2.p1.3.m3.1.1.3.2" xref="S5.I1.i2.p1.3.m3.1.1.3.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S5.I1.i2.p1.3.m3.1.1.3.1" xref="S5.I1.i2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S5.I1.i2.p1.3.m3.1.1.3.3" xref="S5.I1.i2.p1.3.m3.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.3.m3.1b"><apply id="S5.I1.i2.p1.3.m3.1.1.cmml" xref="S5.I1.i2.p1.3.m3.1.1"><eq id="S5.I1.i2.p1.3.m3.1.1.1.cmml" xref="S5.I1.i2.p1.3.m3.1.1.1"></eq><ci id="S5.I1.i2.p1.3.m3.1.1.2.cmml" xref="S5.I1.i2.p1.3.m3.1.1.2">ğ‘¥</ci><apply id="S5.I1.i2.p1.3.m3.1.1.3.cmml" xref="S5.I1.i2.p1.3.m3.1.1.3"><times id="S5.I1.i2.p1.3.m3.1.1.3.1.cmml" xref="S5.I1.i2.p1.3.m3.1.1.3.1"></times><cn type="integer" id="S5.I1.i2.p1.3.m3.1.1.3.2.cmml" xref="S5.I1.i2.p1.3.m3.1.1.3.2">100</cn><ci id="S5.I1.i2.p1.3.m3.1.1.3.3.cmml" xref="S5.I1.i2.p1.3.m3.1.1.3.3">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.3.m3.1c">x=100K</annotation></semantics></math>, the synthetic data are from either <math id="S5.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="L1" display="inline"><semantics id="S5.I1.i2.p1.4.m4.1a"><mrow id="S5.I1.i2.p1.4.m4.1.1" xref="S5.I1.i2.p1.4.m4.1.1.cmml"><mi id="S5.I1.i2.p1.4.m4.1.1.2" xref="S5.I1.i2.p1.4.m4.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.I1.i2.p1.4.m4.1.1.1" xref="S5.I1.i2.p1.4.m4.1.1.1.cmml">â€‹</mo><mn id="S5.I1.i2.p1.4.m4.1.1.3" xref="S5.I1.i2.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.4.m4.1b"><apply id="S5.I1.i2.p1.4.m4.1.1.cmml" xref="S5.I1.i2.p1.4.m4.1.1"><times id="S5.I1.i2.p1.4.m4.1.1.1.cmml" xref="S5.I1.i2.p1.4.m4.1.1.1"></times><ci id="S5.I1.i2.p1.4.m4.1.1.2.cmml" xref="S5.I1.i2.p1.4.m4.1.1.2">ğ¿</ci><cn type="integer" id="S5.I1.i2.p1.4.m4.1.1.3.cmml" xref="S5.I1.i2.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.4.m4.1c">L1</annotation></semantics></math>, or an additional language <math id="S5.I1.i2.p1.5.m5.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S5.I1.i2.p1.5.m5.1a"><mrow id="S5.I1.i2.p1.5.m5.1.1" xref="S5.I1.i2.p1.5.m5.1.1.cmml"><mi id="S5.I1.i2.p1.5.m5.1.1.2" xref="S5.I1.i2.p1.5.m5.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S5.I1.i2.p1.5.m5.1.1.1" xref="S5.I1.i2.p1.5.m5.1.1.1.cmml">â€‹</mo><mn id="S5.I1.i2.p1.5.m5.1.1.3" xref="S5.I1.i2.p1.5.m5.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.5.m5.1b"><apply id="S5.I1.i2.p1.5.m5.1.1.cmml" xref="S5.I1.i2.p1.5.m5.1.1"><times id="S5.I1.i2.p1.5.m5.1.1.1.cmml" xref="S5.I1.i2.p1.5.m5.1.1.1"></times><ci id="S5.I1.i2.p1.5.m5.1.1.2.cmml" xref="S5.I1.i2.p1.5.m5.1.1.2">ğ¿</ci><cn type="integer" id="S5.I1.i2.p1.5.m5.1.1.3.cmml" xref="S5.I1.i2.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.5.m5.1c">L2</annotation></semantics></math>; finally, for <math id="S5.I1.i2.p1.6.m6.1" class="ltx_Math" alttext="x=250K" display="inline"><semantics id="S5.I1.i2.p1.6.m6.1a"><mrow id="S5.I1.i2.p1.6.m6.1.1" xref="S5.I1.i2.p1.6.m6.1.1.cmml"><mi id="S5.I1.i2.p1.6.m6.1.1.2" xref="S5.I1.i2.p1.6.m6.1.1.2.cmml">x</mi><mo id="S5.I1.i2.p1.6.m6.1.1.1" xref="S5.I1.i2.p1.6.m6.1.1.1.cmml">=</mo><mrow id="S5.I1.i2.p1.6.m6.1.1.3" xref="S5.I1.i2.p1.6.m6.1.1.3.cmml"><mn id="S5.I1.i2.p1.6.m6.1.1.3.2" xref="S5.I1.i2.p1.6.m6.1.1.3.2.cmml">250</mn><mo lspace="0em" rspace="0em" id="S5.I1.i2.p1.6.m6.1.1.3.1" xref="S5.I1.i2.p1.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S5.I1.i2.p1.6.m6.1.1.3.3" xref="S5.I1.i2.p1.6.m6.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.6.m6.1b"><apply id="S5.I1.i2.p1.6.m6.1.1.cmml" xref="S5.I1.i2.p1.6.m6.1.1"><eq id="S5.I1.i2.p1.6.m6.1.1.1.cmml" xref="S5.I1.i2.p1.6.m6.1.1.1"></eq><ci id="S5.I1.i2.p1.6.m6.1.1.2.cmml" xref="S5.I1.i2.p1.6.m6.1.1.2">ğ‘¥</ci><apply id="S5.I1.i2.p1.6.m6.1.1.3.cmml" xref="S5.I1.i2.p1.6.m6.1.1.3"><times id="S5.I1.i2.p1.6.m6.1.1.3.1.cmml" xref="S5.I1.i2.p1.6.m6.1.1.3.1"></times><cn type="integer" id="S5.I1.i2.p1.6.m6.1.1.3.2.cmml" xref="S5.I1.i2.p1.6.m6.1.1.3.2">250</cn><ci id="S5.I1.i2.p1.6.m6.1.1.3.3.cmml" xref="S5.I1.i2.p1.6.m6.1.1.3.3">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.6.m6.1c">x=250K</annotation></semantics></math>, all MLQA languages are present.</p>
</div>
</li>
</ol>
</div>
<div id="S5.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS3.SSS0.Px1.p2.1" class="ltx_p">In FigureÂ <a href="#S5.F1" title="Figure 1 â€£ Cross Lingual Generalisation â€£ 5.3 Discussion â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we observe that the performance for <em id="S5.SS3.SSS0.Px1.p2.1.1" class="ltx_emph ltx_font_italic">All Languages</em> increases largely at the beginning, then remains mostly stable. Conversely, we note a gradual improvement for <em id="S5.SS3.SSS0.Px1.p2.1.2" class="ltx_emph ltx_font_italic">Not All Languages</em>, as more languages are made available during training.
This shows that when all the languages are present in the synthetic data, the model immediately develops cross-lingual abilities.</p>
</div>
<div id="S5.SS3.SSS0.Px1.p3" class="ltx_para">
<p id="S5.SS3.SSS0.Px1.p3.1" class="ltx_p">However, it appears that even with only one language pair present, the model is able to develop a cross-lingual ability that brings benefits on other languages: of FigureÂ <a href="#S5.F2" title="Figure 2 â€£ Cross Lingual Generalisation â€£ 5.3 Discussion â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we can see that most of the improvement is happening given only one cross-lingual language pair (i.e. English and Spanish).</p>
</div>
<figure id="S5.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2010.12643/assets/x1.png" id="S5.F1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="207" height="166" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2010.12643/assets/x2.png" id="S5.F1.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="207" height="170" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">FigureÂ 1: </span>Left: F1 score on MLQA, for models with different number of synthetic data in two setups: for <em id="S5.F1.4.1" class="ltx_emph ltx_font_italic">All Languages</em>, the synthetic questions are sampled among all the five languages in MLQA; for <em id="S5.F1.5.2" class="ltx_emph ltx_font_italic">Not All Languages</em>, the synthetic questions are sampled progressively from only one language, two, â€¦, to all five for the last point, which corresponds to <em id="S5.F1.6.3" class="ltx_emph ltx_font_italic">All Languages</em>. We report the standard deviation over five different permutations of the language ordering.
Note that, as expected, the more the synthetic data, the lower the variance in the results.
Right: same as on the left, but evaluated on XQuAD.
</figcaption>
</figure>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2010.12643/assets/x3.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="207" height="162" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">FigureÂ 2: </span>The relative variation in performance for the models in FigureÂ <a href="#S5.F1" title="Figure 1 â€£ Cross Lingual Generalisation â€£ 5.3 Discussion â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</figcaption>
</figure>
</section>
<section id="S5.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Unseen Languages</h4>

<div id="S5.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px2.p1.1" class="ltx_p">To measure the benefit of our approach on unseen languages (i.e. not present in the synthetic data from MLQA/XQuAD), we test our models on three QA evaluation sets: PIAF (fr), KorQuAD and SQuAD-it (see SectionÂ <a href="#S3.SS3" title="3.3 Multilingual Evaluation Sets â€£ 3 Data â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>).
The results are consistent with the previous experiments on MLQA and XQuAD.
Our MiniLM<sub id="S5.SS3.SSS0.Px2.p1.1.1" class="ltx_sub">+synth-trans</sub> model outperforms its baseline by more than 4 Exact Match points, while XLM-R<sub id="S5.SS3.SSS0.Px2.p1.1.2" class="ltx_sub">+synth-trans</sub> obtains a new state-of-the-art. Notably, our multilingual XLM-R<sub id="S5.SS3.SSS0.Px2.p1.1.3" class="ltx_sub">+synth-trans</sub> outperforms CamemBERT on PIAF, even if the latter is a pure monolingual, in-domain language model.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">On the correlation between BLEU4 and QA scores</h4>

<div id="S5.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px3.p1.1" class="ltx_p">To measure the impact of the quality of the generated questions on the QA performance, we computed the Pearson correlation between the BLEU4 and the QA scores. The coefficient is equal to 0.65 (<math id="S5.SS3.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="p&lt;.001" display="inline"><semantics id="S5.SS3.SSS0.Px3.p1.1.m1.1a"><mrow id="S5.SS3.SSS0.Px3.p1.1.m1.1.1" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml">p</mi><mo id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml">.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px3.p1.1.m1.1b"><apply id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1"><lt id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1"></lt><ci id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2">ğ‘</ci><cn type="float" id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3">.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px3.p1.1.m1.1c">p&lt;.001</annotation></semantics></math>).
When we observe the correlations grouping the samples w.r.t.Â their language question (i.e. the rows in TableÂ <a href="#S5.T2" title="Table 2 â€£ Cross-Lingual Training â€£ 5.1 Question Generation â€£ 5 Results â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), we obtain: <em id="S5.SS3.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">en 0.94; es 0.84; de 0.46; ar 0.36; hi 0.33; vi 0.73; zh 0.92</em>. We observe stronger correlation for languages with higher BLEU scores (i.e en &amp; zh), and lower for the Arab that had the lowest BLEU, indicating an impact on the final QA score in par to the quality of the synthetic questions.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Differences with <cite class="ltx_cite ltx_citemacro_citet">Shakeri etÂ al. (<a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>
</h4>

<div id="S5.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px4.p1.1" class="ltx_p">A very recent
work has addressed multilingual QA with a very similar approach. However, we note a major difference in our respective experiments regarding the choice for the QA and QG models. <cite class="ltx_cite ltx_citemacro_citet">Shakeri etÂ al. (<a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite> choose mBert for QA and T5-m for QG. We would like to emphasize that because T5-m significantly outperforms mBert it is not clear where the improvement comes from: is it due to the proposed approach, or simply from a distillation effect from T5-m to mBert?
In our case,
we deliberately used MiniLM <em id="S5.SS3.SSS0.Px4.p1.1.1" class="ltx_emph ltx_font_italic">for both QA and QG</em>: this allows a fairer investigation about the benefits of the proposed approach.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Hidden distillation effect</h4>

<div id="S5.SS3.SSS0.Px5.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px5.p1.1" class="ltx_p">The relative improvement for our best synthetic configuration <em id="S5.SS3.SSS0.Px5.p1.1.1" class="ltx_emph ltx_font_italic">+synth-trans</em>, over the baseline, is above 60% EM for MiniLM (from 29.5 to 49.5 on XQuAD and from 26.0 to 41.4 on MLQA).
Significantly higher than that observed for XLM-R (+11.7% on XQuAD and +2.71% on MLQA), it indicates that XLM-R provides superior cross-lingual transfer abilities than MiniLM, a fact that we hypothesize due to distillation.
Such loss of generalisation can be difficult to identify, and opens questions for future work.
</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">QA, an unsolved task for lower resource languages</h4>

<div id="S5.SS3.SSS0.Px6.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px6.p1.1" class="ltx_p">Factoid QA tasks have been criticized for being a too easy task: the answer can often be identified given simple heuristics: e.g. a â€œWhenâ€ question is answered by one of the â€œdate" spans in the context <cite class="ltx_cite ltx_citemacro_cite">KoÄiskÃ½ etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>); Kwiatkowski etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>. SQuAD-v2 was for instance introduced to increase the difficulty of the task by adding unanswerable questions. The research community is now moving towards the construction of long context questions and non-factoid QA datasets <cite class="ltx_cite ltx_citemacro_cite">Dulceanu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2018</a>); Hashemi etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2019</a>); Fan etÂ al. (<a href="#bib.bib17" title="" class="ltx_ref">2019</a>); Lewis etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2020b</a>)</cite>.
In any case, the motivation of this work was to cope for the lack of training data for under-served languages in the QA domain which was severely impacting models performance. Therefore, potential criticisms regarding the simplicity of the task do not apply if seen from a lower-resource language scenario: our work deals with alleviating the lack of native training data, allowing us to focus our future work on further important issues such as domain adaptation, robustness and explainability in low-resource contexts.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we presented a method to generate synthetic QA dataset in a multilingual fashion, showing how QA models can benefit from it and reporting large improvements over the baselines. The proposed approach contributes to fill the gap between English and other languages, and is shown to generalize for languages not present in the synthetic corpus (e.g.Â French, Italian, Korean).</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">In future work, we plan to investigate whether the proposed data augmentation method could be applied to other multilingual tasks, such as classification.
We will also experiment more in depth with different strategies to control the target language of a model, and extrapolate on unseen ones.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgments</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">DjamÃ© Seddah was partly funded by the French Research National Agency via the ANR project ParSiTi (<span id="S7.p1.1.1" class="ltx_text">ANR-16-CE33-0021</span>), Arij Riabi was partly funded by BenoÃ®t Sagotâ€™s chair in the PRAIRIE institute as part of the French national agency ANR â€œInvestissements dâ€™avenirâ€ programme (<span id="S7.p1.1.2" class="ltx_text">ANR-19-P3IA-0001</span>) and by the Counter H2020 European project (grant 101021607).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alberti etÂ al. (2019)</span>
<span class="ltx_bibblock">
Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, and Michael Collins.
2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1620" title="" class="ltx_ref ltx_href">Synthetic QA corpora
generation with roundtrip consistency</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 6168â€“6173, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe etÂ al. (2020)</span>
<span class="ltx_bibblock">
Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.421" title="" class="ltx_ref ltx_href">On the
cross-lingual transferability of monolingual representations</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4623â€“4637, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bouamor etÂ al. (2014)</span>
<span class="ltx_bibblock">
Houda Bouamor, Hanan Alshikhabobakr, Behrang Mohit, and Kemal Oflazer. 2014.

</span>
<span class="ltx_bibblock">A human judgement corpus and a metric for arabic mt evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2014 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 207â€“213.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burchell etÂ al. (2020)</span>
<span class="ltx_bibblock">
Laurie Burchell, Jie Chi, Tom Hosking, Nina Markl, and Bonnie Webber. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2010.08980" title="" class="ltx_ref ltx_href">Querent intent in
multi-sentence questions</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.08980</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buslaev etÂ al. (2020)</span>
<span class="ltx_bibblock">
Alexander Buslaev, VladimirÂ I Iglovikov, Eugene Khvedchenya, Alex Parinov,
Mikhail Druzhinin, and AlexandrÂ A Kalinin. 2020.

</span>
<span class="ltx_bibblock">Albumentations: fast and flexible image augmentations.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Information</em>, 11(2):125.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi etÂ al. (2020)</span>
<span class="ltx_bibblock">
Zewen Chi, LiÂ Dong, Furu Wei, Wenhui Wang, Xian-Ling Mao, and Heyan Huang.
2020.

</span>
<span class="ltx_bibblock">Cross-lingual natural language generation via pre-training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, pages 7570â€“7577.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi etÂ al. (2018)</span>
<span class="ltx_bibblock">
Eunsol Choi, HeÂ He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy
Liang, and Luke Zettlemoyer. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D18-1241" title="" class="ltx_ref ltx_href">QuAC: Question
answering in context</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2174â€“2184, Brussels, Belgium.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau etÂ al. (2020)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer, and
Veselin Stoyanov. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.747" title="" class="ltx_ref ltx_href">Unsupervised
cross-lingual representation learning at scale</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 8440â€“8451, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Croce etÂ al. (2018)</span>
<span class="ltx_bibblock">
Danilo Croce, Alexandra Zelenanska, and Roberto Basili. 2018.

</span>
<span class="ltx_bibblock">Neural learning for question answering in italian.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">AI*IA 2018 â€“ Advances in Artificial Intelligence</em>, pages
389â€“402, Cham. Springer International Publishing.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin etÂ al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1423" title="" class="ltx_ref ltx_href">BERT: Pre-training of
deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171â€“4186,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong etÂ al. (2019)</span>
<span class="ltx_bibblock">
LiÂ Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, YuÂ Wang, Jianfeng Gao,
Ming Zhou, and Hsiao-Wuen Hon. 2019.

</span>
<span class="ltx_bibblock">Unified language model pre-training for natural language
understanding and generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pages
13063â€“13075.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du and Cardie (2018)</span>
<span class="ltx_bibblock">
Xinya Du and Claire Cardie. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P18-1177" title="" class="ltx_ref ltx_href">Harvesting
paragraph-level question-answer pairs from Wikipedia</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1907â€“1917,
Melbourne, Australia. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du etÂ al. (2017)</span>
<span class="ltx_bibblock">
Xinya Du, Junru Shao, and Claire Cardie. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1123" title="" class="ltx_ref ltx_href">Learning to ask: Neural
question generation for reading comprehension</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1342â€“1352,
Vancouver, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua etÂ al. (2019)</span>
<span class="ltx_bibblock">
Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and
Matt Gardner. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1246" title="" class="ltx_ref ltx_href">DROP: A reading
comprehension benchmark requiring discrete reasoning over paragraphs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 2368â€“2378,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan etÂ al. (2017)</span>
<span class="ltx_bibblock">
Nan Duan, Duyu Tang, Peng Chen, and Ming Zhou. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D17-1090" title="" class="ltx_ref ltx_href">Question generation for
question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 866â€“874, Copenhagen, Denmark.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dulceanu etÂ al. (2018)</span>
<span class="ltx_bibblock">
Andrei Dulceanu, Thang LeÂ Dinh, Walter Chang, Trung Bui, DooÂ Soon Kim,
ManhÂ Chien Vu, and Seokhwan Kim. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.aclweb.org/anthology/L18-1438" title="" class="ltx_ref ltx_href">PhotoshopQuiA: A corpus of non-factoid questions and answers for
why-question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan. European
Language Resources Association (ELRA).

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan etÂ al. (2019)</span>
<span class="ltx_bibblock">
Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and
Michael Auli. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1346" title="" class="ltx_ref ltx_href">ELI5: Long form
question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 3558â€“3567, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Forestier etÂ al. (2017)</span>
<span class="ltx_bibblock">
Germain Forestier, FranÃ§ois Petitjean, HoangÂ Anh Dau, GeoffreyÂ I Webb,
and Eamonn Keogh. 2017.

</span>
<span class="ltx_bibblock">Generating synthetic time series to augment sparse datasets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2017 IEEE international conference on data mining (ICDM)</em>,
pages 865â€“870. IEEE.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Golub etÂ al. (2017)</span>
<span class="ltx_bibblock">
David Golub, Po-Sen Huang, Xiaodong He, and LiÂ Deng. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D17-1087" title="" class="ltx_ref ltx_href">Two-stage synthesis
networks for transfer learning in machine comprehension</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 835â€“844, Copenhagen, Denmark.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hashemi etÂ al. (2019)</span>
<span class="ltx_bibblock">
Helia Hashemi, Mohammad Aliannejadi, Hamed Zamani, and W.Â Bruce Croft. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/arXiv:1905.08957" title="" class="ltx_ref ltx_href">Antique: A non-factoid
question answering benchmark</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hermann etÂ al. (2015)</span>
<span class="ltx_bibblock">
KarlÂ Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will
Kay, Mustafa Suleyman, and Phil Blunsom. 2015.

</span>
<span class="ltx_bibblock">Teaching machines to read and comprehend.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, pages
1693â€“1701.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and
Melvin Johnson. 2020.

</span>
<span class="ltx_bibblock">Xtreme: A massively multilingual multi-task benchmark for evaluating
cross-lingual generalization.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.11080</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Keraron etÂ al. (2020)</span>
<span class="ltx_bibblock">
Rachel Keraron, Guillaume Lancrenon, Mathilde Bras, FrÃ©dÃ©ric Allary,
Gilles Moyse, Thomas Scialom, Edmundo-Pavel Soriano-Morales, and Jacopo
Staiano. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.673" title="" class="ltx_ref ltx_href">Project
PIAF: Building a native French question-answering dataset</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 5481â€“5490, Marseille, France. European Language Resources
Association.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Keskar etÂ al. (2019)</span>
<span class="ltx_bibblock">
NitishÂ Shirish Keskar, Bryan McCann, LavÂ R Varshney, Caiming Xiong, and Richard
Socher. 2019.

</span>
<span class="ltx_bibblock">Ctrl: A conditional transformer language model for controllable
generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.05858</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">KoÄiskÃ½ etÂ al. (2018)</span>
<span class="ltx_bibblock">
TomÃ¡Å¡ KoÄiskÃ½, Jonathan Schwarz, Phil Blunsom, Chris Dyer,
KarlÂ Moritz Hermann, GÃ¡bor Melis, and Edward Grefenstette. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00023" title="" class="ltx_ref ltx_href">The NarrativeQA
reading comprehension challenge</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
6:317â€“328.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar etÂ al. (2019)</span>
<span class="ltx_bibblock">
Vishwajeet Kumar, Nitish Joshi, Arijit Mukherjee, Ganesh Ramakrishnan, and
Preethi Jyothi. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1481" title="" class="ltx_ref ltx_href">Cross-lingual training
for automatic question generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4863â€“4872, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski etÂ al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang,
AndrewÂ M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00276" title="" class="ltx_ref ltx_href">Natural questions: A
benchmark for question answering research</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:452â€“466.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2020)</span>
<span class="ltx_bibblock">
Dongyub Lee, Myeongcheol Shin, Taesun Whang, Seungwoo Cho, Byeongil Ko, Daniel
Lee, Eunggyun Kim, and Jaechoon Jo. 2020.

</span>
<span class="ltx_bibblock">Reference and document aware semantic evaluation methods for korean
language summarization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of COLING 2020, the 30th International
Conference on Computational Linguistics: Technical Papers</em>. The COLING 2020
Organizing Committee.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2019)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019.

</span>
<span class="ltx_bibblock">Bart: Denoising sequence-to-sequence pre-training for natural
language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.13461</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020a)</span>
<span class="ltx_bibblock">
Patrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian Riedel, and Holger Schwenk.
2020a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.653" title="" class="ltx_ref ltx_href">MLQA:
Evaluating cross-lingual extractive question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7315â€“7330, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020b)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim
RocktÃ¤schel, etÂ al. 2020b.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.11401</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim etÂ al. (2019)</span>
<span class="ltx_bibblock">
Seungyoung Lim, Myungji Kim, and Jooyoul Lee. 2019.

</span>
<span class="ltx_bibblock">Korquad1. 0: Korean qa dataset for machine reading comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.07005</em>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Louis Martin, Benjamin Muller, PedroÂ Javier OrtizÂ SuÃ¡rez, Yoann Dupont,
Laurent Romary, Ã‰ric deÂ la Clergerie, DjamÃ© Seddah, and BenoÃ®t
Sagot. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.645" title="" class="ltx_ref ltx_href">CamemBERT:
a tasty French language model</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7203â€“7219, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Novikova etÂ al. (2017)</span>
<span class="ltx_bibblock">
Jekaterina Novikova, OndÅ™ej DuÅ¡ek, Amanda CercasÂ Curry, and Verena
Rieser. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D17-1238" title="" class="ltx_ref ltx_href">Why we need new
evaluation metrics for NLG</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2241â€“2252, Copenhagen, Denmark.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Page etÂ al. (1999)</span>
<span class="ltx_bibblock">
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999.

</span>
<span class="ltx_bibblock">The pagerank citation ranking: Bringing order to the web.

</span>
<span class="ltx_bibblock">Technical report, Stanford InfoLab.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel etÂ al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and PeterÂ J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 21(140):1â€“67.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar etÂ al. (2016)</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D16-1264" title="" class="ltx_ref ltx_href">SQuAD: 100,000+
questions for machine comprehension of text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2383â€“2392, Austin, Texas. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rus etÂ al. (2010)</span>
<span class="ltx_bibblock">
Vasile Rus, Brendan Wyse, Paul Piwek, Mihai Lintean, Svetlana Stoyanchev, and
Christian Moldovan. 2010.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.aclweb.org/anthology/W10-4234" title="" class="ltx_ref ltx_href">The first question
generation shared task evaluation challenge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 6th International Natural Language
Generation Conference</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scialom etÂ al. (2019)</span>
<span class="ltx_bibblock">
Thomas Scialom, Benjamin Piwowarski, and Jacopo Staiano. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1604" title="" class="ltx_ref ltx_href">Self-attention
architectures for answer-agnostic neural question generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 6027â€“6032, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scialom etÂ al. (2020)</span>
<span class="ltx_bibblock">
Thomas Scialom, SerraÂ Sinem Tekiroglu, Jacopo Staiano, and Marco Guerini. 2020.

</span>
<span class="ltx_bibblock">Toward stance-based personas for opinionated dialogues.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.03369</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shakeri etÂ al. (2020)</span>
<span class="ltx_bibblock">
Siamak Shakeri, Noah Constant, MihirÂ Sanjay Kale, and Linting Xue. 2020.

</span>
<span class="ltx_bibblock">Multilingual synthetic question and answer generation for
cross-lingual reading comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.12008</em>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simmons (1965)</span>
<span class="ltx_bibblock">
RobertÂ F Simmons. 1965.

</span>
<span class="ltx_bibblock">Answering english questions by computer: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 8(1):53â€“70.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sulem etÂ al. (2018)</span>
<span class="ltx_bibblock">
Elior Sulem, Omri Abend, and Ari Rappoport. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D18-1081" title="" class="ltx_ref ltx_href">BLEU is not suitable
for the evaluation of text simplification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 738â€“744, Brussels, Belgium. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trischler etÂ al. (2017)</span>
<span class="ltx_bibblock">
Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni,
Philip Bachman, and Kaheer Suleman. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W17-2623" title="" class="ltx_ref ltx_href">NewsQA: A machine
comprehension dataset</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Representation Learning
for NLP</em>, pages 191â€“200, Vancouver, Canada. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel
Bowman. 2018.

</span>
<span class="ltx_bibblock">Glue: A multi-task benchmark and analysis platform for natural
language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 EMNLP Workshop BlackboxNLP:
Analyzing and Interpreting Neural Networks for NLP</em>, pages 353â€“355.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2020)</span>
<span class="ltx_bibblock">
Wenhui Wang, Furu Wei, LiÂ Dong, Hangbo Bao, Nan Yang, and Ming Zhou. 2020.

</span>
<span class="ltx_bibblock">Minilm: Deep self-attention distillation for task-agnostic
compression of pre-trained transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.10957</em>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2017)</span>
<span class="ltx_bibblock">
Qingyu Zhou, Nan Yang, Furu Wei, Chuanqi Tan, Hangbo Bao, and Ming Zhou. 2017.

</span>
<span class="ltx_bibblock">Neural question generation from text: A preliminary study.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">National CCF Conference on Natural Language Processing and
Chinese Computing</em>, pages 662â€“671. Springer.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>

<section id="Ax1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A </span>On target language control for text generation</h3>

<div id="Ax1.SS1.p1" class="ltx_para">
<p id="Ax1.SS1.p1.1" class="ltx_p">When relying on the translated versions of SQuAD, the target language for generating synthetic questions can easily be controlled, and results in fluent and relevant questions in the different languages.
However, one limitation of this approach is that synthetic questions can only be generated in the languages that were available during training: the <span id="Ax1.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">&lt;LANG&gt;</span> prompts are special tokens that are randomly initialised when fine-tuning QG on SQuAD<sub id="Ax1.SS1.p1.1.2" class="ltx_sub"><span id="Ax1.SS1.p1.1.2.1" class="ltx_text ltx_font_italic">trans;qg</span></sub>: before fine-tuning, they bear no semantic relation with the corresponding language names (â€œEnglishâ€, â€œEspaÃ±olâ€ etc.), thus the learned representations for the <span id="Ax1.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">&lt;LANG&gt;</span> tokens are limited to the languages present in the training set.</p>
</div>
<div id="Ax1.SS1.p2" class="ltx_para">
<p id="Ax1.SS1.p2.1" class="ltx_p">To the best of our knowledge, no method allows so far to generalize this target control to an unseen language. It would be valuable, for instance, to be able to generate synthetic data in Korean, French and Italian, without having to translate the entire SQuAD<math id="Ax1.SS1.p2.1.m1.1" class="ltx_Math" alttext="-en" display="inline"><semantics id="Ax1.SS1.p2.1.m1.1a"><mrow id="Ax1.SS1.p2.1.m1.1.1" xref="Ax1.SS1.p2.1.m1.1.1.cmml"><mo id="Ax1.SS1.p2.1.m1.1.1a" xref="Ax1.SS1.p2.1.m1.1.1.cmml">âˆ’</mo><mrow id="Ax1.SS1.p2.1.m1.1.1.2" xref="Ax1.SS1.p2.1.m1.1.1.2.cmml"><mi id="Ax1.SS1.p2.1.m1.1.1.2.2" xref="Ax1.SS1.p2.1.m1.1.1.2.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="Ax1.SS1.p2.1.m1.1.1.2.1" xref="Ax1.SS1.p2.1.m1.1.1.2.1.cmml">â€‹</mo><mi id="Ax1.SS1.p2.1.m1.1.1.2.3" xref="Ax1.SS1.p2.1.m1.1.1.2.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ax1.SS1.p2.1.m1.1b"><apply id="Ax1.SS1.p2.1.m1.1.1.cmml" xref="Ax1.SS1.p2.1.m1.1.1"><minus id="Ax1.SS1.p2.1.m1.1.1.1.cmml" xref="Ax1.SS1.p2.1.m1.1.1"></minus><apply id="Ax1.SS1.p2.1.m1.1.1.2.cmml" xref="Ax1.SS1.p2.1.m1.1.1.2"><times id="Ax1.SS1.p2.1.m1.1.1.2.1.cmml" xref="Ax1.SS1.p2.1.m1.1.1.2.1"></times><ci id="Ax1.SS1.p2.1.m1.1.1.2.2.cmml" xref="Ax1.SS1.p2.1.m1.1.1.2.2">ğ‘’</ci><ci id="Ax1.SS1.p2.1.m1.1.1.2.3.cmml" xref="Ax1.SS1.p2.1.m1.1.1.2.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ax1.SS1.p2.1.m1.1c">-en</annotation></semantics></math> dataset in these three languages to then fine-tune the QG model.</p>
</div>
<div id="Ax1.SS1.p3" class="ltx_para">
<p id="Ax1.SS1.p3.1" class="ltx_p">To this purpose, we report â€“ alas, as a negative result â€“ the following attempt:
instead of controlling the target language with a special, randomly initialised, token, we used a token semantically related to the language-word: â€œEnglishâ€, â€œEspaÃ±olâ€ for Spanish, or â€œä¸­æ–‡â€ for Chinese.
The intuition is that the model might adopt the correct language at inference, even for a target language unseen during training.<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>With <em id="footnote9.1" class="ltx_emph ltx_font_italic">unseen during training</em>, we mean <em id="footnote9.2" class="ltx_emph ltx_font_italic">not present in the QG dataset</em>; obviously, the language should have been present in the first self-supervised stage.</span></span></span>
A similar intuition has been explored in GPT-2: the authors report an improvement for summarization when the input text is followed by â€œTL;DR" (i.e. Too Long Didnâ€™t Read).</p>
</div>
<div id="Ax1.SS1.p4" class="ltx_para">
<p id="Ax1.SS1.p4.1" class="ltx_p">At inference time, we evaluated this approach on French with the prompt <span id="Ax1.SS1.p4.1.1" class="ltx_text ltx_font_typewriter">language=FranÃ§ais</span>. Unfortunately, the model did not succeed to generate text in French.
Controlling the target language in the context of multilingual text generation remains under-explored, and progress in this direction could have direct applications to improve this work, and beyond.</p>
</div>
<figure id="Ax1.T5" class="ltx_table">
<table id="Ax1.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T5.1.1.1" class="ltx_tr">
<th id="Ax1.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">q/c</th>
<th id="Ax1.T5.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">en</th>
<th id="Ax1.T5.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">es</th>
<th id="Ax1.T5.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">de</th>
<th id="Ax1.T5.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">ar</th>
<th id="Ax1.T5.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">hi</th>
<th id="Ax1.T5.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">vi</th>
<th id="Ax1.T5.1.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">zh</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T5.1.2.1" class="ltx_tr">
<td id="Ax1.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">en</td>
<td id="Ax1.T5.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">14.5</td>
<td id="Ax1.T5.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">8.9</td>
<td id="Ax1.T5.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">7.2</td>
<td id="Ax1.T5.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">5.9</td>
<td id="Ax1.T5.1.2.1.6" class="ltx_td ltx_align_left ltx_border_t">6.5</td>
<td id="Ax1.T5.1.2.1.7" class="ltx_td ltx_align_left ltx_border_t">8.4</td>
<td id="Ax1.T5.1.2.1.8" class="ltx_td ltx_align_left ltx_border_t">6.0</td>
</tr>
<tr id="Ax1.T5.1.3.2" class="ltx_tr">
<td id="Ax1.T5.1.3.2.1" class="ltx_td ltx_align_left">es</td>
<td id="Ax1.T5.1.3.2.2" class="ltx_td ltx_align_left">9.0</td>
<td id="Ax1.T5.1.3.2.3" class="ltx_td ltx_align_left">10.</td>
<td id="Ax1.T5.1.3.2.4" class="ltx_td ltx_align_left">6.6</td>
<td id="Ax1.T5.1.3.2.5" class="ltx_td ltx_align_left">4.2</td>
<td id="Ax1.T5.1.3.2.6" class="ltx_td ltx_align_left">5.9</td>
<td id="Ax1.T5.1.3.2.7" class="ltx_td ltx_align_left">6.3</td>
<td id="Ax1.T5.1.3.2.8" class="ltx_td ltx_align_left">4.6</td>
</tr>
<tr id="Ax1.T5.1.4.3" class="ltx_tr">
<td id="Ax1.T5.1.4.3.1" class="ltx_td ltx_align_left">de</td>
<td id="Ax1.T5.1.4.3.2" class="ltx_td ltx_align_left">6.2</td>
<td id="Ax1.T5.1.4.3.3" class="ltx_td ltx_align_left">4.8</td>
<td id="Ax1.T5.1.4.3.4" class="ltx_td ltx_align_left">6.3</td>
<td id="Ax1.T5.1.4.3.5" class="ltx_td ltx_align_left">3.1</td>
<td id="Ax1.T5.1.4.3.6" class="ltx_td ltx_align_left">3.7</td>
<td id="Ax1.T5.1.4.3.7" class="ltx_td ltx_align_left">5.0</td>
<td id="Ax1.T5.1.4.3.8" class="ltx_td ltx_align_left">3.2</td>
</tr>
<tr id="Ax1.T5.1.5.4" class="ltx_tr">
<td id="Ax1.T5.1.5.4.1" class="ltx_td ltx_align_left">ar</td>
<td id="Ax1.T5.1.5.4.2" class="ltx_td ltx_align_left">2.8</td>
<td id="Ax1.T5.1.5.4.3" class="ltx_td ltx_align_left">2.2</td>
<td id="Ax1.T5.1.5.4.4" class="ltx_td ltx_align_left">2.4</td>
<td id="Ax1.T5.1.5.4.5" class="ltx_td ltx_align_left">3.3</td>
<td id="Ax1.T5.1.5.4.6" class="ltx_td ltx_align_left">2.0</td>
<td id="Ax1.T5.1.5.4.7" class="ltx_td ltx_align_left">2.3</td>
<td id="Ax1.T5.1.5.4.8" class="ltx_td ltx_align_left">2.1</td>
</tr>
<tr id="Ax1.T5.1.6.5" class="ltx_tr">
<td id="Ax1.T5.1.6.5.1" class="ltx_td ltx_align_left">hi</td>
<td id="Ax1.T5.1.6.5.2" class="ltx_td ltx_align_left">7.9</td>
<td id="Ax1.T5.1.6.5.3" class="ltx_td ltx_align_left">6.7</td>
<td id="Ax1.T5.1.6.5.4" class="ltx_td ltx_align_left">6.6</td>
<td id="Ax1.T5.1.6.5.5" class="ltx_td ltx_align_left">5.8</td>
<td id="Ax1.T5.1.6.5.6" class="ltx_td ltx_align_left">8.3</td>
<td id="Ax1.T5.1.6.5.7" class="ltx_td ltx_align_left">6.6</td>
<td id="Ax1.T5.1.6.5.8" class="ltx_td ltx_align_left">5.2</td>
</tr>
<tr id="Ax1.T5.1.7.6" class="ltx_tr">
<td id="Ax1.T5.1.7.6.1" class="ltx_td ltx_align_left">vi</td>
<td id="Ax1.T5.1.7.6.2" class="ltx_td ltx_align_left">9.1</td>
<td id="Ax1.T5.1.7.6.3" class="ltx_td ltx_align_left">7.3</td>
<td id="Ax1.T5.1.7.6.4" class="ltx_td ltx_align_left">7.2</td>
<td id="Ax1.T5.1.7.6.5" class="ltx_td ltx_align_left">6.0</td>
<td id="Ax1.T5.1.7.6.6" class="ltx_td ltx_align_left">6.5</td>
<td id="Ax1.T5.1.7.6.7" class="ltx_td ltx_align_left">12.3</td>
<td id="Ax1.T5.1.7.6.8" class="ltx_td ltx_align_left">6.1</td>
</tr>
<tr id="Ax1.T5.1.8.7" class="ltx_tr">
<td id="Ax1.T5.1.8.7.1" class="ltx_td ltx_align_left ltx_border_bb">zh</td>
<td id="Ax1.T5.1.8.7.2" class="ltx_td ltx_align_left ltx_border_bb">9.2</td>
<td id="Ax1.T5.1.8.7.3" class="ltx_td ltx_align_left ltx_border_bb">8.0</td>
<td id="Ax1.T5.1.8.7.4" class="ltx_td ltx_align_left ltx_border_bb">7.8</td>
<td id="Ax1.T5.1.8.7.5" class="ltx_td ltx_align_left ltx_border_bb">6.1</td>
<td id="Ax1.T5.1.8.7.6" class="ltx_td ltx_align_left ltx_border_bb">7.2</td>
<td id="Ax1.T5.1.8.7.7" class="ltx_td ltx_align_left ltx_border_bb">8.0</td>
<td id="Ax1.T5.1.8.7.8" class="ltx_td ltx_align_left ltx_border_bb">15.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 5: </span>BLEU4 scores on MLQA test for QG<sub id="Ax1.T5.3.1" class="ltx_sub">synth+trans</sub> model.</figcaption>
</figure>
<figure id="Ax1.T6" class="ltx_table">
<table id="Ax1.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T6.1.1.1" class="ltx_tr">
<th id="Ax1.T6.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">q/c</th>
<th id="Ax1.T6.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">en</th>
<th id="Ax1.T6.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">es</th>
<th id="Ax1.T6.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">de</th>
<th id="Ax1.T6.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">ar</th>
<th id="Ax1.T6.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">hi</th>
<th id="Ax1.T6.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">vi</th>
<th id="Ax1.T6.1.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">zh</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T6.1.2.1" class="ltx_tr">
<td id="Ax1.T6.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">en</td>
<td id="Ax1.T6.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">21.7</td>
<td id="Ax1.T6.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">4.73</td>
<td id="Ax1.T6.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">4.58</td>
<td id="Ax1.T6.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">2.47</td>
<td id="Ax1.T6.1.2.1.6" class="ltx_td ltx_align_left ltx_border_t">2.58</td>
<td id="Ax1.T6.1.2.1.7" class="ltx_td ltx_align_left ltx_border_t">3.02</td>
<td id="Ax1.T6.1.2.1.8" class="ltx_td ltx_align_left ltx_border_t">3.11</td>
</tr>
<tr id="Ax1.T6.1.3.2" class="ltx_tr">
<td id="Ax1.T6.1.3.2.1" class="ltx_td ltx_align_left">es</td>
<td id="Ax1.T6.1.3.2.2" class="ltx_td ltx_align_left">0.8</td>
<td id="Ax1.T6.1.3.2.3" class="ltx_td ltx_align_left">1.23</td>
<td id="Ax1.T6.1.3.2.4" class="ltx_td ltx_align_left">0.38</td>
<td id="Ax1.T6.1.3.2.5" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.3.2.6" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.3.2.7" class="ltx_td ltx_align_left">0.22</td>
<td id="Ax1.T6.1.3.2.8" class="ltx_td ltx_align_left">0.11</td>
</tr>
<tr id="Ax1.T6.1.4.3" class="ltx_tr">
<td id="Ax1.T6.1.4.3.1" class="ltx_td ltx_align_left">de</td>
<td id="Ax1.T6.1.4.3.2" class="ltx_td ltx_align_left">1.4</td>
<td id="Ax1.T6.1.4.3.3" class="ltx_td ltx_align_left">0.85</td>
<td id="Ax1.T6.1.4.3.4" class="ltx_td ltx_align_left">1.32</td>
<td id="Ax1.T6.1.4.3.5" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.4.3.6" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.4.3.7" class="ltx_td ltx_align_left">0.22</td>
<td id="Ax1.T6.1.4.3.8" class="ltx_td ltx_align_left">0.0</td>
</tr>
<tr id="Ax1.T6.1.5.4" class="ltx_tr">
<td id="Ax1.T6.1.5.4.1" class="ltx_td ltx_align_left">ar</td>
<td id="Ax1.T6.1.5.4.2" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.5.4.3" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.5.4.4" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.5.4.5" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.5.4.6" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.5.4.7" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.5.4.8" class="ltx_td ltx_align_left">0.0</td>
</tr>
<tr id="Ax1.T6.1.6.5" class="ltx_tr">
<td id="Ax1.T6.1.6.5.1" class="ltx_td ltx_align_left">hi</td>
<td id="Ax1.T6.1.6.5.2" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.6.5.3" class="ltx_td ltx_align_left">0.21</td>
<td id="Ax1.T6.1.6.5.4" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.6.5.5" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.6.5.6" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.6.5.7" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.6.5.8" class="ltx_td ltx_align_left">0.0</td>
</tr>
<tr id="Ax1.T6.1.7.6" class="ltx_tr">
<td id="Ax1.T6.1.7.6.1" class="ltx_td ltx_align_left">vi</td>
<td id="Ax1.T6.1.7.6.2" class="ltx_td ltx_align_left">0.55</td>
<td id="Ax1.T6.1.7.6.3" class="ltx_td ltx_align_left">0.5</td>
<td id="Ax1.T6.1.7.6.4" class="ltx_td ltx_align_left">0.25</td>
<td id="Ax1.T6.1.7.6.5" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.7.6.6" class="ltx_td ltx_align_left">0.0</td>
<td id="Ax1.T6.1.7.6.7" class="ltx_td ltx_align_left">0.34</td>
<td id="Ax1.T6.1.7.6.8" class="ltx_td ltx_align_left">0.0</td>
</tr>
<tr id="Ax1.T6.1.8.7" class="ltx_tr">
<td id="Ax1.T6.1.8.7.1" class="ltx_td ltx_align_left ltx_border_bb">zh</td>
<td id="Ax1.T6.1.8.7.2" class="ltx_td ltx_align_left ltx_border_bb">0.0</td>
<td id="Ax1.T6.1.8.7.3" class="ltx_td ltx_align_left ltx_border_bb">0.0</td>
<td id="Ax1.T6.1.8.7.4" class="ltx_td ltx_align_left ltx_border_bb">0.0</td>
<td id="Ax1.T6.1.8.7.5" class="ltx_td ltx_align_left ltx_border_bb">0.0</td>
<td id="Ax1.T6.1.8.7.6" class="ltx_td ltx_align_left ltx_border_bb">0.0</td>
<td id="Ax1.T6.1.8.7.7" class="ltx_td ltx_align_left ltx_border_bb">0.0</td>
<td id="Ax1.T6.1.8.7.8" class="ltx_td ltx_align_left ltx_border_bb">0.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 6: </span>BLEU-4 scores on MLQA test for QG<sub id="Ax1.T6.3.1" class="ltx_sub">synth</sub> model.</figcaption>
</figure>
<figure id="Ax1.T7" class="ltx_table">
<table id="Ax1.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T7.1.1.1" class="ltx_tr">
<th id="Ax1.T7.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">q/c</th>
<th id="Ax1.T7.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">en</th>
<th id="Ax1.T7.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">es</th>
<th id="Ax1.T7.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">de</th>
<th id="Ax1.T7.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">ar</th>
<th id="Ax1.T7.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">hi</th>
<th id="Ax1.T7.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">vi</th>
<th id="Ax1.T7.1.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">zh</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T7.1.2.1" class="ltx_tr">
<td id="Ax1.T7.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">en</td>
<td id="Ax1.T7.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">83.9</td>
<td id="Ax1.T7.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">74.8</td>
<td id="Ax1.T7.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">70.1</td>
<td id="Ax1.T7.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">67.8</td>
<td id="Ax1.T7.1.2.1.6" class="ltx_td ltx_align_left ltx_border_t">72.3</td>
<td id="Ax1.T7.1.2.1.7" class="ltx_td ltx_align_left ltx_border_t">74.1</td>
<td id="Ax1.T7.1.2.1.8" class="ltx_td ltx_align_left ltx_border_t">69.3</td>
</tr>
<tr id="Ax1.T7.1.3.2" class="ltx_tr">
<td id="Ax1.T7.1.3.2.1" class="ltx_td ltx_align_left">es</td>
<td id="Ax1.T7.1.3.2.2" class="ltx_td ltx_align_left">78.0</td>
<td id="Ax1.T7.1.3.2.3" class="ltx_td ltx_align_left">74.3</td>
<td id="Ax1.T7.1.3.2.4" class="ltx_td ltx_align_left">68.1</td>
<td id="Ax1.T7.1.3.2.5" class="ltx_td ltx_align_left">63.6</td>
<td id="Ax1.T7.1.3.2.6" class="ltx_td ltx_align_left">67.4</td>
<td id="Ax1.T7.1.3.2.7" class="ltx_td ltx_align_left">67.6</td>
<td id="Ax1.T7.1.3.2.8" class="ltx_td ltx_align_left">69.1</td>
</tr>
<tr id="Ax1.T7.1.4.3" class="ltx_tr">
<td id="Ax1.T7.1.4.3.1" class="ltx_td ltx_align_left">de</td>
<td id="Ax1.T7.1.4.3.2" class="ltx_td ltx_align_left">75.6</td>
<td id="Ax1.T7.1.4.3.3" class="ltx_td ltx_align_left">72.9</td>
<td id="Ax1.T7.1.4.3.4" class="ltx_td ltx_align_left">70.1</td>
<td id="Ax1.T7.1.4.3.5" class="ltx_td ltx_align_left">65.0</td>
<td id="Ax1.T7.1.4.3.6" class="ltx_td ltx_align_left">67.5</td>
<td id="Ax1.T7.1.4.3.7" class="ltx_td ltx_align_left">68.5</td>
<td id="Ax1.T7.1.4.3.8" class="ltx_td ltx_align_left">70.4</td>
</tr>
<tr id="Ax1.T7.1.5.4" class="ltx_tr">
<td id="Ax1.T7.1.5.4.1" class="ltx_td ltx_align_left">ar</td>
<td id="Ax1.T7.1.5.4.2" class="ltx_td ltx_align_left">61.3</td>
<td id="Ax1.T7.1.5.4.3" class="ltx_td ltx_align_left">58.4</td>
<td id="Ax1.T7.1.5.4.4" class="ltx_td ltx_align_left">56.8</td>
<td id="Ax1.T7.1.5.4.5" class="ltx_td ltx_align_left">66.7</td>
<td id="Ax1.T7.1.5.4.6" class="ltx_td ltx_align_left">57.7</td>
<td id="Ax1.T7.1.5.4.7" class="ltx_td ltx_align_left">56.5</td>
<td id="Ax1.T7.1.5.4.8" class="ltx_td ltx_align_left">69.8</td>
</tr>
<tr id="Ax1.T7.1.6.5" class="ltx_tr">
<td id="Ax1.T7.1.6.5.1" class="ltx_td ltx_align_left">hi</td>
<td id="Ax1.T7.1.6.5.2" class="ltx_td ltx_align_left">70.9</td>
<td id="Ax1.T7.1.6.5.3" class="ltx_td ltx_align_left">62.1</td>
<td id="Ax1.T7.1.6.5.4" class="ltx_td ltx_align_left">58.9</td>
<td id="Ax1.T7.1.6.5.5" class="ltx_td ltx_align_left">56.8</td>
<td id="Ax1.T7.1.6.5.6" class="ltx_td ltx_align_left">70.9</td>
<td id="Ax1.T7.1.6.5.7" class="ltx_td ltx_align_left">61.3</td>
<td id="Ax1.T7.1.6.5.8" class="ltx_td ltx_align_left">69.2</td>
</tr>
<tr id="Ax1.T7.1.7.6" class="ltx_tr">
<td id="Ax1.T7.1.7.6.1" class="ltx_td ltx_align_left">vi</td>
<td id="Ax1.T7.1.7.6.2" class="ltx_td ltx_align_left">71.0</td>
<td id="Ax1.T7.1.7.6.3" class="ltx_td ltx_align_left">64.1</td>
<td id="Ax1.T7.1.7.6.4" class="ltx_td ltx_align_left">60.5</td>
<td id="Ax1.T7.1.7.6.5" class="ltx_td ltx_align_left">59.7</td>
<td id="Ax1.T7.1.7.6.6" class="ltx_td ltx_align_left">63.7</td>
<td id="Ax1.T7.1.7.6.7" class="ltx_td ltx_align_left">74.7</td>
<td id="Ax1.T7.1.7.6.8" class="ltx_td ltx_align_left">69.9</td>
</tr>
<tr id="Ax1.T7.1.8.7" class="ltx_tr">
<td id="Ax1.T7.1.8.7.1" class="ltx_td ltx_align_left ltx_border_bb">zh</td>
<td id="Ax1.T7.1.8.7.2" class="ltx_td ltx_align_left ltx_border_bb">67.1</td>
<td id="Ax1.T7.1.8.7.3" class="ltx_td ltx_align_left ltx_border_bb">62.5</td>
<td id="Ax1.T7.1.8.7.4" class="ltx_td ltx_align_left ltx_border_bb">59.0</td>
<td id="Ax1.T7.1.8.7.5" class="ltx_td ltx_align_left ltx_border_bb">56.7</td>
<td id="Ax1.T7.1.8.7.6" class="ltx_td ltx_align_left ltx_border_bb">60.7</td>
<td id="Ax1.T7.1.8.7.7" class="ltx_td ltx_align_left ltx_border_bb">63.2</td>
<td id="Ax1.T7.1.8.7.8" class="ltx_td ltx_align_left ltx_border_bb">69.3</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 7: </span>F1 score on MLQA for XLM-R model finetuned on SQuAD<sub id="Ax1.T7.3.1" class="ltx_sub">en</sub>.</figcaption>
</figure>
<figure id="Ax1.T8" class="ltx_table">
<table id="Ax1.T8.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T8.1.1.1" class="ltx_tr">
<th id="Ax1.T8.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">q/c</th>
<th id="Ax1.T8.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">en</th>
<th id="Ax1.T8.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">es</th>
<th id="Ax1.T8.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">de</th>
<th id="Ax1.T8.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">ar</th>
<th id="Ax1.T8.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">hi</th>
<th id="Ax1.T8.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">vi</th>
<th id="Ax1.T8.1.1.1.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">zh</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T8.1.2.1" class="ltx_tr">
<td id="Ax1.T8.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">en</td>
<td id="Ax1.T8.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">83.9</td>
<td id="Ax1.T8.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">75.4</td>
<td id="Ax1.T8.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">70.9</td>
<td id="Ax1.T8.1.2.1.5" class="ltx_td ltx_align_left ltx_border_t">68.9</td>
<td id="Ax1.T8.1.2.1.6" class="ltx_td ltx_align_left ltx_border_t">72.8</td>
<td id="Ax1.T8.1.2.1.7" class="ltx_td ltx_align_left ltx_border_t">75.6</td>
<td id="Ax1.T8.1.2.1.8" class="ltx_td ltx_align_left ltx_border_t">66.8</td>
</tr>
<tr id="Ax1.T8.1.3.2" class="ltx_tr">
<td id="Ax1.T8.1.3.2.1" class="ltx_td ltx_align_left">es</td>
<td id="Ax1.T8.1.3.2.2" class="ltx_td ltx_align_left">81.0</td>
<td id="Ax1.T8.1.3.2.3" class="ltx_td ltx_align_left">74.4</td>
<td id="Ax1.T8.1.3.2.4" class="ltx_td ltx_align_left">71.8</td>
<td id="Ax1.T8.1.3.2.5" class="ltx_td ltx_align_left">66.6</td>
<td id="Ax1.T8.1.3.2.6" class="ltx_td ltx_align_left">70.2</td>
<td id="Ax1.T8.1.3.2.7" class="ltx_td ltx_align_left">72.5</td>
<td id="Ax1.T8.1.3.2.8" class="ltx_td ltx_align_left">65.7</td>
</tr>
<tr id="Ax1.T8.1.4.3" class="ltx_tr">
<td id="Ax1.T8.1.4.3.1" class="ltx_td ltx_align_left">de</td>
<td id="Ax1.T8.1.4.3.2" class="ltx_td ltx_align_left">81.4</td>
<td id="Ax1.T8.1.4.3.3" class="ltx_td ltx_align_left">75.2</td>
<td id="Ax1.T8.1.4.3.4" class="ltx_td ltx_align_left">70.8</td>
<td id="Ax1.T8.1.4.3.5" class="ltx_td ltx_align_left">69.3</td>
<td id="Ax1.T8.1.4.3.6" class="ltx_td ltx_align_left">70.2</td>
<td id="Ax1.T8.1.4.3.7" class="ltx_td ltx_align_left">74.4</td>
<td id="Ax1.T8.1.4.3.8" class="ltx_td ltx_align_left">65.1</td>
</tr>
<tr id="Ax1.T8.1.5.4" class="ltx_tr">
<td id="Ax1.T8.1.5.4.1" class="ltx_td ltx_align_left">ar</td>
<td id="Ax1.T8.1.5.4.2" class="ltx_td ltx_align_left">76.3</td>
<td id="Ax1.T8.1.5.4.3" class="ltx_td ltx_align_left">68.9</td>
<td id="Ax1.T8.1.5.4.4" class="ltx_td ltx_align_left">67.3</td>
<td id="Ax1.T8.1.5.4.5" class="ltx_td ltx_align_left">66.6</td>
<td id="Ax1.T8.1.5.4.6" class="ltx_td ltx_align_left">65.4</td>
<td id="Ax1.T8.1.5.4.7" class="ltx_td ltx_align_left">70.4</td>
<td id="Ax1.T8.1.5.4.8" class="ltx_td ltx_align_left">61.7</td>
</tr>
<tr id="Ax1.T8.1.6.5" class="ltx_tr">
<td id="Ax1.T8.1.6.5.1" class="ltx_td ltx_align_left">hi</td>
<td id="Ax1.T8.1.6.5.2" class="ltx_td ltx_align_left">78.5</td>
<td id="Ax1.T8.1.6.5.3" class="ltx_td ltx_align_left">70.5</td>
<td id="Ax1.T8.1.6.5.4" class="ltx_td ltx_align_left">64.5</td>
<td id="Ax1.T8.1.6.5.5" class="ltx_td ltx_align_left">63.6</td>
<td id="Ax1.T8.1.6.5.6" class="ltx_td ltx_align_left">70.8</td>
<td id="Ax1.T8.1.6.5.7" class="ltx_td ltx_align_left">71.1</td>
<td id="Ax1.T8.1.6.5.8" class="ltx_td ltx_align_left">63.2</td>
</tr>
<tr id="Ax1.T8.1.7.6" class="ltx_tr">
<td id="Ax1.T8.1.7.6.1" class="ltx_td ltx_align_left">vi</td>
<td id="Ax1.T8.1.7.6.2" class="ltx_td ltx_align_left">78.0</td>
<td id="Ax1.T8.1.7.6.3" class="ltx_td ltx_align_left">72.0</td>
<td id="Ax1.T8.1.7.6.4" class="ltx_td ltx_align_left">66.4</td>
<td id="Ax1.T8.1.7.6.5" class="ltx_td ltx_align_left">65.2</td>
<td id="Ax1.T8.1.7.6.6" class="ltx_td ltx_align_left">68.5</td>
<td id="Ax1.T8.1.7.6.7" class="ltx_td ltx_align_left">74.7</td>
<td id="Ax1.T8.1.7.6.8" class="ltx_td ltx_align_left">64.5</td>
</tr>
<tr id="Ax1.T8.1.8.7" class="ltx_tr">
<td id="Ax1.T8.1.8.7.1" class="ltx_td ltx_align_left ltx_border_bb">zh</td>
<td id="Ax1.T8.1.8.7.2" class="ltx_td ltx_align_left ltx_border_bb">77.8</td>
<td id="Ax1.T8.1.8.7.3" class="ltx_td ltx_align_left ltx_border_bb">70.1</td>
<td id="Ax1.T8.1.8.7.4" class="ltx_td ltx_align_left ltx_border_bb">67.0</td>
<td id="Ax1.T8.1.8.7.5" class="ltx_td ltx_align_left ltx_border_bb">64.9</td>
<td id="Ax1.T8.1.8.7.6" class="ltx_td ltx_align_left ltx_border_bb">68.1</td>
<td id="Ax1.T8.1.8.7.7" class="ltx_td ltx_align_left ltx_border_bb">71.8</td>
<td id="Ax1.T8.1.8.7.8" class="ltx_td ltx_align_left ltx_border_bb">67.7</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 8: </span>F1 score on MLQA for XLM-R<sub id="Ax1.T8.3.1" class="ltx_sub">+synth-trans</sub> model.</figcaption>
</figure>
<figure id="Ax1.T9" class="ltx_table">
<table id="Ax1.T9.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T9.1.1.1" class="ltx_tr">
<th id="Ax1.T9.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">q/c</th>
<th id="Ax1.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">en</th>
<th id="Ax1.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">es</th>
<th id="Ax1.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">de</th>
<th id="Ax1.T9.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">ar</th>
<th id="Ax1.T9.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">hi</th>
<th id="Ax1.T9.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">vi</th>
<th id="Ax1.T9.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">zh</th>
<th id="Ax1.T9.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">ru</th>
<th id="Ax1.T9.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">th</th>
<th id="Ax1.T9.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">tr</th>
<th id="Ax1.T9.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">el</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T9.1.2.1" class="ltx_tr">
<th id="Ax1.T9.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">en</th>
<td id="Ax1.T9.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">87.4</td>
<td id="Ax1.T9.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">82.0</td>
<td id="Ax1.T9.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">80.7</td>
<td id="Ax1.T9.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">75.6</td>
<td id="Ax1.T9.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">79.0</td>
<td id="Ax1.T9.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">78.1</td>
<td id="Ax1.T9.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t">73.0</td>
<td id="Ax1.T9.1.2.1.9" class="ltx_td ltx_align_center ltx_border_t">79.0</td>
<td id="Ax1.T9.1.2.1.10" class="ltx_td ltx_align_center ltx_border_t">73.2</td>
<td id="Ax1.T9.1.2.1.11" class="ltx_td ltx_align_center ltx_border_t">74.8</td>
<td id="Ax1.T9.1.2.1.12" class="ltx_td ltx_align_center ltx_border_t">79.9</td>
</tr>
<tr id="Ax1.T9.1.3.2" class="ltx_tr">
<th id="Ax1.T9.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">es</th>
<td id="Ax1.T9.1.3.2.2" class="ltx_td ltx_align_center">80.6</td>
<td id="Ax1.T9.1.3.2.3" class="ltx_td ltx_align_center">84.2</td>
<td id="Ax1.T9.1.3.2.4" class="ltx_td ltx_align_center">76.2</td>
<td id="Ax1.T9.1.3.2.5" class="ltx_td ltx_align_center">71.3</td>
<td id="Ax1.T9.1.3.2.6" class="ltx_td ltx_align_center">72.7</td>
<td id="Ax1.T9.1.3.2.7" class="ltx_td ltx_align_center">72.8</td>
<td id="Ax1.T9.1.3.2.8" class="ltx_td ltx_align_center">67.5</td>
<td id="Ax1.T9.1.3.2.9" class="ltx_td ltx_align_center">76.4</td>
<td id="Ax1.T9.1.3.2.10" class="ltx_td ltx_align_center">69.6</td>
<td id="Ax1.T9.1.3.2.11" class="ltx_td ltx_align_center">70.6</td>
<td id="Ax1.T9.1.3.2.12" class="ltx_td ltx_align_center">75.8</td>
</tr>
<tr id="Ax1.T9.1.4.3" class="ltx_tr">
<th id="Ax1.T9.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">de</th>
<td id="Ax1.T9.1.4.3.2" class="ltx_td ltx_align_center">79.8</td>
<td id="Ax1.T9.1.4.3.3" class="ltx_td ltx_align_center">76.4</td>
<td id="Ax1.T9.1.4.3.4" class="ltx_td ltx_align_center">83.5</td>
<td id="Ax1.T9.1.4.3.5" class="ltx_td ltx_align_center">71.0</td>
<td id="Ax1.T9.1.4.3.6" class="ltx_td ltx_align_center">72.9</td>
<td id="Ax1.T9.1.4.3.7" class="ltx_td ltx_align_center">72.4</td>
<td id="Ax1.T9.1.4.3.8" class="ltx_td ltx_align_center">68.1</td>
<td id="Ax1.T9.1.4.3.9" class="ltx_td ltx_align_center">75.6</td>
<td id="Ax1.T9.1.4.3.10" class="ltx_td ltx_align_center">68.3</td>
<td id="Ax1.T9.1.4.3.11" class="ltx_td ltx_align_center">71.4</td>
<td id="Ax1.T9.1.4.3.12" class="ltx_td ltx_align_center">75.5</td>
</tr>
<tr id="Ax1.T9.1.5.4" class="ltx_tr">
<th id="Ax1.T9.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ar</th>
<td id="Ax1.T9.1.5.4.2" class="ltx_td ltx_align_center">65.3</td>
<td id="Ax1.T9.1.5.4.3" class="ltx_td ltx_align_center">63.1</td>
<td id="Ax1.T9.1.5.4.4" class="ltx_td ltx_align_center">62.0</td>
<td id="Ax1.T9.1.5.4.5" class="ltx_td ltx_align_center">77.8</td>
<td id="Ax1.T9.1.5.4.6" class="ltx_td ltx_align_center">64.1</td>
<td id="Ax1.T9.1.5.4.7" class="ltx_td ltx_align_center">61.9</td>
<td id="Ax1.T9.1.5.4.8" class="ltx_td ltx_align_center">58.8</td>
<td id="Ax1.T9.1.5.4.9" class="ltx_td ltx_align_center">63.9</td>
<td id="Ax1.T9.1.5.4.10" class="ltx_td ltx_align_center">62.8</td>
<td id="Ax1.T9.1.5.4.11" class="ltx_td ltx_align_center">57.4</td>
<td id="Ax1.T9.1.5.4.12" class="ltx_td ltx_align_center">65.2</td>
</tr>
<tr id="Ax1.T9.1.6.5" class="ltx_tr">
<th id="Ax1.T9.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">hi</th>
<td id="Ax1.T9.1.6.5.2" class="ltx_td ltx_align_center">72.9</td>
<td id="Ax1.T9.1.6.5.3" class="ltx_td ltx_align_center">64.8</td>
<td id="Ax1.T9.1.6.5.4" class="ltx_td ltx_align_center">65.7</td>
<td id="Ax1.T9.1.6.5.5" class="ltx_td ltx_align_center">63.7</td>
<td id="Ax1.T9.1.6.5.6" class="ltx_td ltx_align_center">75.8</td>
<td id="Ax1.T9.1.6.5.7" class="ltx_td ltx_align_center">64.0</td>
<td id="Ax1.T9.1.6.5.8" class="ltx_td ltx_align_center">61.8</td>
<td id="Ax1.T9.1.6.5.9" class="ltx_td ltx_align_center">66.9</td>
<td id="Ax1.T9.1.6.5.10" class="ltx_td ltx_align_center">63.5</td>
<td id="Ax1.T9.1.6.5.11" class="ltx_td ltx_align_center">59.6</td>
<td id="Ax1.T9.1.6.5.12" class="ltx_td ltx_align_center">67.2</td>
</tr>
<tr id="Ax1.T9.1.7.6" class="ltx_tr">
<th id="Ax1.T9.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">vi</th>
<td id="Ax1.T9.1.7.6.2" class="ltx_td ltx_align_center">74.5</td>
<td id="Ax1.T9.1.7.6.3" class="ltx_td ltx_align_center">69.8</td>
<td id="Ax1.T9.1.7.6.4" class="ltx_td ltx_align_center">70.7</td>
<td id="Ax1.T9.1.7.6.5" class="ltx_td ltx_align_center">67.7</td>
<td id="Ax1.T9.1.7.6.6" class="ltx_td ltx_align_center">67.7</td>
<td id="Ax1.T9.1.7.6.7" class="ltx_td ltx_align_center">80.6</td>
<td id="Ax1.T9.1.7.6.8" class="ltx_td ltx_align_center">66.9</td>
<td id="Ax1.T9.1.7.6.9" class="ltx_td ltx_align_center">70.5</td>
<td id="Ax1.T9.1.7.6.10" class="ltx_td ltx_align_center">66.6</td>
<td id="Ax1.T9.1.7.6.11" class="ltx_td ltx_align_center">64.8</td>
<td id="Ax1.T9.1.7.6.12" class="ltx_td ltx_align_center">70.6</td>
</tr>
<tr id="Ax1.T9.1.8.7" class="ltx_tr">
<th id="Ax1.T9.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">zh</th>
<td id="Ax1.T9.1.8.7.2" class="ltx_td ltx_align_center">70.7</td>
<td id="Ax1.T9.1.8.7.3" class="ltx_td ltx_align_center">65.8</td>
<td id="Ax1.T9.1.8.7.4" class="ltx_td ltx_align_center">64.1</td>
<td id="Ax1.T9.1.8.7.5" class="ltx_td ltx_align_center">64.1</td>
<td id="Ax1.T9.1.8.7.6" class="ltx_td ltx_align_center">65.6</td>
<td id="Ax1.T9.1.8.7.7" class="ltx_td ltx_align_center">67.4</td>
<td id="Ax1.T9.1.8.7.8" class="ltx_td ltx_align_center">81.8</td>
<td id="Ax1.T9.1.8.7.9" class="ltx_td ltx_align_center">67.4</td>
<td id="Ax1.T9.1.8.7.10" class="ltx_td ltx_align_center">64.8</td>
<td id="Ax1.T9.1.8.7.11" class="ltx_td ltx_align_center">60.8</td>
<td id="Ax1.T9.1.8.7.12" class="ltx_td ltx_align_center">66.9</td>
</tr>
<tr id="Ax1.T9.1.9.8" class="ltx_tr">
<th id="Ax1.T9.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ru</th>
<td id="Ax1.T9.1.9.8.2" class="ltx_td ltx_align_center">79.8</td>
<td id="Ax1.T9.1.9.8.3" class="ltx_td ltx_align_center">78.0</td>
<td id="Ax1.T9.1.9.8.4" class="ltx_td ltx_align_center">76.7</td>
<td id="Ax1.T9.1.9.8.5" class="ltx_td ltx_align_center">70.2</td>
<td id="Ax1.T9.1.9.8.6" class="ltx_td ltx_align_center">72.5</td>
<td id="Ax1.T9.1.9.8.7" class="ltx_td ltx_align_center">74.6</td>
<td id="Ax1.T9.1.9.8.8" class="ltx_td ltx_align_center">67.3</td>
<td id="Ax1.T9.1.9.8.9" class="ltx_td ltx_align_center">81.1</td>
<td id="Ax1.T9.1.9.8.10" class="ltx_td ltx_align_center">69.6</td>
<td id="Ax1.T9.1.9.8.11" class="ltx_td ltx_align_center">70.7</td>
<td id="Ax1.T9.1.9.8.12" class="ltx_td ltx_align_center">75.6</td>
</tr>
<tr id="Ax1.T9.1.10.9" class="ltx_tr">
<th id="Ax1.T9.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">th</th>
<td id="Ax1.T9.1.10.9.2" class="ltx_td ltx_align_center">49.6</td>
<td id="Ax1.T9.1.10.9.3" class="ltx_td ltx_align_center">42.1</td>
<td id="Ax1.T9.1.10.9.4" class="ltx_td ltx_align_center">44.1</td>
<td id="Ax1.T9.1.10.9.5" class="ltx_td ltx_align_center">49.8</td>
<td id="Ax1.T9.1.10.9.6" class="ltx_td ltx_align_center">51.9</td>
<td id="Ax1.T9.1.10.9.7" class="ltx_td ltx_align_center">49.0</td>
<td id="Ax1.T9.1.10.9.8" class="ltx_td ltx_align_center">53.9</td>
<td id="Ax1.T9.1.10.9.9" class="ltx_td ltx_align_center">50.4</td>
<td id="Ax1.T9.1.10.9.10" class="ltx_td ltx_align_center">74.9</td>
<td id="Ax1.T9.1.10.9.11" class="ltx_td ltx_align_center">37.1</td>
<td id="Ax1.T9.1.10.9.12" class="ltx_td ltx_align_center">48.8</td>
</tr>
<tr id="Ax1.T9.1.11.10" class="ltx_tr">
<th id="Ax1.T9.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">tr</th>
<td id="Ax1.T9.1.11.10.2" class="ltx_td ltx_align_center">72.6</td>
<td id="Ax1.T9.1.11.10.3" class="ltx_td ltx_align_center">64.9</td>
<td id="Ax1.T9.1.11.10.4" class="ltx_td ltx_align_center">68.5</td>
<td id="Ax1.T9.1.11.10.5" class="ltx_td ltx_align_center">65.5</td>
<td id="Ax1.T9.1.11.10.6" class="ltx_td ltx_align_center">68.1</td>
<td id="Ax1.T9.1.11.10.7" class="ltx_td ltx_align_center">64.1</td>
<td id="Ax1.T9.1.11.10.8" class="ltx_td ltx_align_center">62.4</td>
<td id="Ax1.T9.1.11.10.9" class="ltx_td ltx_align_center">70.3</td>
<td id="Ax1.T9.1.11.10.10" class="ltx_td ltx_align_center">64.3</td>
<td id="Ax1.T9.1.11.10.11" class="ltx_td ltx_align_center">76.7</td>
<td id="Ax1.T9.1.11.10.12" class="ltx_td ltx_align_center">71.3</td>
</tr>
<tr id="Ax1.T9.1.12.11" class="ltx_tr">
<th id="Ax1.T9.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">el</th>
<td id="Ax1.T9.1.12.11.2" class="ltx_td ltx_align_center ltx_border_bb">70.8</td>
<td id="Ax1.T9.1.12.11.3" class="ltx_td ltx_align_center ltx_border_bb">69.1</td>
<td id="Ax1.T9.1.12.11.4" class="ltx_td ltx_align_center ltx_border_bb">69.3</td>
<td id="Ax1.T9.1.12.11.5" class="ltx_td ltx_align_center ltx_border_bb">63.3</td>
<td id="Ax1.T9.1.12.11.6" class="ltx_td ltx_align_center ltx_border_bb">65.6</td>
<td id="Ax1.T9.1.12.11.7" class="ltx_td ltx_align_center ltx_border_bb">65.0</td>
<td id="Ax1.T9.1.12.11.8" class="ltx_td ltx_align_center ltx_border_bb">63.0</td>
<td id="Ax1.T9.1.12.11.9" class="ltx_td ltx_align_center ltx_border_bb">70.8</td>
<td id="Ax1.T9.1.12.11.10" class="ltx_td ltx_align_center ltx_border_bb">64.2</td>
<td id="Ax1.T9.1.12.11.11" class="ltx_td ltx_align_center ltx_border_bb">62.3</td>
<td id="Ax1.T9.1.12.11.12" class="ltx_td ltx_align_center ltx_border_bb">81.3</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 9: </span>F1 score on XQuAD for XLM-R model finetuned on SQuAD<sub id="Ax1.T9.3.1" class="ltx_sub">en</sub>.</figcaption>
</figure>
<figure id="Ax1.T10" class="ltx_table">
<table id="Ax1.T10.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T10.1.1.1" class="ltx_tr">
<th id="Ax1.T10.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">q/c</th>
<th id="Ax1.T10.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">en</th>
<th id="Ax1.T10.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">es</th>
<th id="Ax1.T10.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">de</th>
<th id="Ax1.T10.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">ar</th>
<th id="Ax1.T10.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">hi</th>
<th id="Ax1.T10.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">vi</th>
<th id="Ax1.T10.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">zh</th>
<th id="Ax1.T10.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">ru</th>
<th id="Ax1.T10.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">th</th>
<th id="Ax1.T10.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">tr</th>
<th id="Ax1.T10.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">el</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T10.1.2.1" class="ltx_tr">
<th id="Ax1.T10.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">en</th>
<td id="Ax1.T10.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">87.0</td>
<td id="Ax1.T10.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">82.9</td>
<td id="Ax1.T10.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">81.6</td>
<td id="Ax1.T10.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">77.8</td>
<td id="Ax1.T10.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">81.5</td>
<td id="Ax1.T10.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">81.0</td>
<td id="Ax1.T10.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t">77.5</td>
<td id="Ax1.T10.1.2.1.9" class="ltx_td ltx_align_center ltx_border_t">80.9</td>
<td id="Ax1.T10.1.2.1.10" class="ltx_td ltx_align_center ltx_border_t">77.7</td>
<td id="Ax1.T10.1.2.1.11" class="ltx_td ltx_align_center ltx_border_t">74.8</td>
<td id="Ax1.T10.1.2.1.12" class="ltx_td ltx_align_center ltx_border_t">81.4</td>
</tr>
<tr id="Ax1.T10.1.3.2" class="ltx_tr">
<th id="Ax1.T10.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">es</th>
<td id="Ax1.T10.1.3.2.2" class="ltx_td ltx_align_center">83.5</td>
<td id="Ax1.T10.1.3.2.3" class="ltx_td ltx_align_center">84.1</td>
<td id="Ax1.T10.1.3.2.4" class="ltx_td ltx_align_center">79.2</td>
<td id="Ax1.T10.1.3.2.5" class="ltx_td ltx_align_center">74.9</td>
<td id="Ax1.T10.1.3.2.6" class="ltx_td ltx_align_center">78.0</td>
<td id="Ax1.T10.1.3.2.7" class="ltx_td ltx_align_center">78.7</td>
<td id="Ax1.T10.1.3.2.8" class="ltx_td ltx_align_center">76.5</td>
<td id="Ax1.T10.1.3.2.9" class="ltx_td ltx_align_center">78.9</td>
<td id="Ax1.T10.1.3.2.10" class="ltx_td ltx_align_center">76.3</td>
<td id="Ax1.T10.1.3.2.11" class="ltx_td ltx_align_center">72.7</td>
<td id="Ax1.T10.1.3.2.12" class="ltx_td ltx_align_center">78.8</td>
</tr>
<tr id="Ax1.T10.1.4.3" class="ltx_tr">
<th id="Ax1.T10.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">de</th>
<td id="Ax1.T10.1.4.3.2" class="ltx_td ltx_align_center">82.8</td>
<td id="Ax1.T10.1.4.3.3" class="ltx_td ltx_align_center">80.3</td>
<td id="Ax1.T10.1.4.3.4" class="ltx_td ltx_align_center">83.1</td>
<td id="Ax1.T10.1.4.3.5" class="ltx_td ltx_align_center">75.1</td>
<td id="Ax1.T10.1.4.3.6" class="ltx_td ltx_align_center">77.3</td>
<td id="Ax1.T10.1.4.3.7" class="ltx_td ltx_align_center">78.3</td>
<td id="Ax1.T10.1.4.3.8" class="ltx_td ltx_align_center">75.1</td>
<td id="Ax1.T10.1.4.3.9" class="ltx_td ltx_align_center">78.4</td>
<td id="Ax1.T10.1.4.3.10" class="ltx_td ltx_align_center">75.7</td>
<td id="Ax1.T10.1.4.3.11" class="ltx_td ltx_align_center">72.9</td>
<td id="Ax1.T10.1.4.3.12" class="ltx_td ltx_align_center">78.3</td>
</tr>
<tr id="Ax1.T10.1.5.4" class="ltx_tr">
<th id="Ax1.T10.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ar</th>
<td id="Ax1.T10.1.5.4.2" class="ltx_td ltx_align_center">78.4</td>
<td id="Ax1.T10.1.5.4.3" class="ltx_td ltx_align_center">77.2</td>
<td id="Ax1.T10.1.5.4.4" class="ltx_td ltx_align_center">75.6</td>
<td id="Ax1.T10.1.5.4.5" class="ltx_td ltx_align_center">77.5</td>
<td id="Ax1.T10.1.5.4.6" class="ltx_td ltx_align_center">72.8</td>
<td id="Ax1.T10.1.5.4.7" class="ltx_td ltx_align_center">74.3</td>
<td id="Ax1.T10.1.5.4.8" class="ltx_td ltx_align_center">72.1</td>
<td id="Ax1.T10.1.5.4.9" class="ltx_td ltx_align_center">74.2</td>
<td id="Ax1.T10.1.5.4.10" class="ltx_td ltx_align_center">72.5</td>
<td id="Ax1.T10.1.5.4.11" class="ltx_td ltx_align_center">69.5</td>
<td id="Ax1.T10.1.5.4.12" class="ltx_td ltx_align_center">74.2</td>
</tr>
<tr id="Ax1.T10.1.6.5" class="ltx_tr">
<th id="Ax1.T10.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">hi</th>
<td id="Ax1.T10.1.6.5.2" class="ltx_td ltx_align_center">80.6</td>
<td id="Ax1.T10.1.6.5.3" class="ltx_td ltx_align_center">77.5</td>
<td id="Ax1.T10.1.6.5.4" class="ltx_td ltx_align_center">76.4</td>
<td id="Ax1.T10.1.6.5.5" class="ltx_td ltx_align_center">71.6</td>
<td id="Ax1.T10.1.6.5.6" class="ltx_td ltx_align_center">77.5</td>
<td id="Ax1.T10.1.6.5.7" class="ltx_td ltx_align_center">75.2</td>
<td id="Ax1.T10.1.6.5.8" class="ltx_td ltx_align_center">73.9</td>
<td id="Ax1.T10.1.6.5.9" class="ltx_td ltx_align_center">76.3</td>
<td id="Ax1.T10.1.6.5.10" class="ltx_td ltx_align_center">73.6</td>
<td id="Ax1.T10.1.6.5.11" class="ltx_td ltx_align_center">70.2</td>
<td id="Ax1.T10.1.6.5.12" class="ltx_td ltx_align_center">75.9</td>
</tr>
<tr id="Ax1.T10.1.7.6" class="ltx_tr">
<th id="Ax1.T10.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">vi</th>
<td id="Ax1.T10.1.7.6.2" class="ltx_td ltx_align_center">81.3</td>
<td id="Ax1.T10.1.7.6.3" class="ltx_td ltx_align_center">79.6</td>
<td id="Ax1.T10.1.7.6.4" class="ltx_td ltx_align_center">77.5</td>
<td id="Ax1.T10.1.7.6.5" class="ltx_td ltx_align_center">73.0</td>
<td id="Ax1.T10.1.7.6.6" class="ltx_td ltx_align_center">75.6</td>
<td id="Ax1.T10.1.7.6.7" class="ltx_td ltx_align_center">80.7</td>
<td id="Ax1.T10.1.7.6.8" class="ltx_td ltx_align_center">74.7</td>
<td id="Ax1.T10.1.7.6.9" class="ltx_td ltx_align_center">76.5</td>
<td id="Ax1.T10.1.7.6.10" class="ltx_td ltx_align_center">74.5</td>
<td id="Ax1.T10.1.7.6.11" class="ltx_td ltx_align_center">71.8</td>
<td id="Ax1.T10.1.7.6.12" class="ltx_td ltx_align_center">76.0</td>
</tr>
<tr id="Ax1.T10.1.8.7" class="ltx_tr">
<th id="Ax1.T10.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">zh</th>
<td id="Ax1.T10.1.8.7.2" class="ltx_td ltx_align_center">80.2</td>
<td id="Ax1.T10.1.8.7.3" class="ltx_td ltx_align_center">78.3</td>
<td id="Ax1.T10.1.8.7.4" class="ltx_td ltx_align_center">76.9</td>
<td id="Ax1.T10.1.8.7.5" class="ltx_td ltx_align_center">72.1</td>
<td id="Ax1.T10.1.8.7.6" class="ltx_td ltx_align_center">74.3</td>
<td id="Ax1.T10.1.8.7.7" class="ltx_td ltx_align_center">76.1</td>
<td id="Ax1.T10.1.8.7.8" class="ltx_td ltx_align_center">85.1</td>
<td id="Ax1.T10.1.8.7.9" class="ltx_td ltx_align_center">77.0</td>
<td id="Ax1.T10.1.8.7.10" class="ltx_td ltx_align_center">74.1</td>
<td id="Ax1.T10.1.8.7.11" class="ltx_td ltx_align_center">70.1</td>
<td id="Ax1.T10.1.8.7.12" class="ltx_td ltx_align_center">75.7</td>
</tr>
<tr id="Ax1.T10.1.9.8" class="ltx_tr">
<th id="Ax1.T10.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ru</th>
<td id="Ax1.T10.1.9.8.2" class="ltx_td ltx_align_center">82.2</td>
<td id="Ax1.T10.1.9.8.3" class="ltx_td ltx_align_center">80.4</td>
<td id="Ax1.T10.1.9.8.4" class="ltx_td ltx_align_center">78.8</td>
<td id="Ax1.T10.1.9.8.5" class="ltx_td ltx_align_center">74.1</td>
<td id="Ax1.T10.1.9.8.6" class="ltx_td ltx_align_center">75.9</td>
<td id="Ax1.T10.1.9.8.7" class="ltx_td ltx_align_center">78.4</td>
<td id="Ax1.T10.1.9.8.8" class="ltx_td ltx_align_center">76.5</td>
<td id="Ax1.T10.1.9.8.9" class="ltx_td ltx_align_center">80.8</td>
<td id="Ax1.T10.1.9.8.10" class="ltx_td ltx_align_center">75.4</td>
<td id="Ax1.T10.1.9.8.11" class="ltx_td ltx_align_center">72.9</td>
<td id="Ax1.T10.1.9.8.12" class="ltx_td ltx_align_center">78.6</td>
</tr>
<tr id="Ax1.T10.1.10.9" class="ltx_tr">
<th id="Ax1.T10.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">th</th>
<td id="Ax1.T10.1.10.9.2" class="ltx_td ltx_align_center">79.1</td>
<td id="Ax1.T10.1.10.9.3" class="ltx_td ltx_align_center">76.7</td>
<td id="Ax1.T10.1.10.9.4" class="ltx_td ltx_align_center">75.1</td>
<td id="Ax1.T10.1.10.9.5" class="ltx_td ltx_align_center">71.0</td>
<td id="Ax1.T10.1.10.9.6" class="ltx_td ltx_align_center">73.5</td>
<td id="Ax1.T10.1.10.9.7" class="ltx_td ltx_align_center">75.1</td>
<td id="Ax1.T10.1.10.9.8" class="ltx_td ltx_align_center">73.6</td>
<td id="Ax1.T10.1.10.9.9" class="ltx_td ltx_align_center">75.3</td>
<td id="Ax1.T10.1.10.9.10" class="ltx_td ltx_align_center">77.2</td>
<td id="Ax1.T10.1.10.9.11" class="ltx_td ltx_align_center">68.8</td>
<td id="Ax1.T10.1.10.9.12" class="ltx_td ltx_align_center">74.1</td>
</tr>
<tr id="Ax1.T10.1.11.10" class="ltx_tr">
<th id="Ax1.T10.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">tr</th>
<td id="Ax1.T10.1.11.10.2" class="ltx_td ltx_align_center">80.2</td>
<td id="Ax1.T10.1.11.10.3" class="ltx_td ltx_align_center">77.7</td>
<td id="Ax1.T10.1.11.10.4" class="ltx_td ltx_align_center">76.4</td>
<td id="Ax1.T10.1.11.10.5" class="ltx_td ltx_align_center">71.9</td>
<td id="Ax1.T10.1.11.10.6" class="ltx_td ltx_align_center">74.6</td>
<td id="Ax1.T10.1.11.10.7" class="ltx_td ltx_align_center">74.2</td>
<td id="Ax1.T10.1.11.10.8" class="ltx_td ltx_align_center">74.7</td>
<td id="Ax1.T10.1.11.10.9" class="ltx_td ltx_align_center">77.8</td>
<td id="Ax1.T10.1.11.10.10" class="ltx_td ltx_align_center">73.3</td>
<td id="Ax1.T10.1.11.10.11" class="ltx_td ltx_align_center">75.2</td>
<td id="Ax1.T10.1.11.10.12" class="ltx_td ltx_align_center">75.6</td>
</tr>
<tr id="Ax1.T10.1.12.11" class="ltx_tr">
<th id="Ax1.T10.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">el</th>
<td id="Ax1.T10.1.12.11.2" class="ltx_td ltx_align_center ltx_border_bb">82.0</td>
<td id="Ax1.T10.1.12.11.3" class="ltx_td ltx_align_center ltx_border_bb">80.1</td>
<td id="Ax1.T10.1.12.11.4" class="ltx_td ltx_align_center ltx_border_bb">78.5</td>
<td id="Ax1.T10.1.12.11.5" class="ltx_td ltx_align_center ltx_border_bb">73.8</td>
<td id="Ax1.T10.1.12.11.6" class="ltx_td ltx_align_center ltx_border_bb">77.3</td>
<td id="Ax1.T10.1.12.11.7" class="ltx_td ltx_align_center ltx_border_bb">77.3</td>
<td id="Ax1.T10.1.12.11.8" class="ltx_td ltx_align_center ltx_border_bb">75.4</td>
<td id="Ax1.T10.1.12.11.9" class="ltx_td ltx_align_center ltx_border_bb">78.6</td>
<td id="Ax1.T10.1.12.11.10" class="ltx_td ltx_align_center ltx_border_bb">75.3</td>
<td id="Ax1.T10.1.12.11.11" class="ltx_td ltx_align_center ltx_border_bb">72.2</td>
<td id="Ax1.T10.1.12.11.12" class="ltx_td ltx_align_center ltx_border_bb">80.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 10: </span>F1 score on XQuAD for XLM-R<sub id="Ax1.T10.3.1" class="ltx_sub">+synth-trans</sub> model.</figcaption>
</figure>
</section>
<section id="Ax1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B </span>Question Generation Scores</h3>

<div id="Ax1.SS2.p1" class="ltx_para">
<p id="Ax1.SS2.p1.1" class="ltx_p">We report the BLEU-4 scores for MLQA on QG<sub id="Ax1.SS2.p1.1.1" class="ltx_sub">synth+trans</sub> on Table <a href="#Ax1.T5" title="Table 5 â€£ A On target language control for text generation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and QG<sub id="Ax1.SS2.p1.1.2" class="ltx_sub">synth</sub> on Table <a href="#Ax1.T6" title="Table 6 â€£ A On target language control for text generation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. In addition, we report the F1 scores for XLM-R finetuned on SQuAD<sub id="Ax1.SS2.p1.1.3" class="ltx_sub">en</sub> and XLM-R<sub id="Ax1.SS2.p1.1.4" class="ltx_sub">+synth-trans</sub> on all the language pairs, on both MLQA and XQuAD in Tables <a href="#Ax1.T7" title="Table 7 â€£ A On target language control for text generation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, <a href="#Ax1.T8" title="Table 8 â€£ A On target language control for text generation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, <a href="#Ax1.T9" title="Table 9 â€£ A On target language control for text generation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#Ax1.T10" title="Table 10 â€£ A On target language control for text generation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
</section>
<section id="Ax1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C </span>Qualitative Evaluation</h3>

<div id="Ax1.SS3.p1" class="ltx_para">
<p id="Ax1.SS3.p1.1" class="ltx_p">We report in Tables <a href="#Ax1.T11" title="Table 11 â€£ C Qualitative Evaluation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, <a href="#Ax1.T12" title="Table 12 â€£ C Qualitative Evaluation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, and <a href="#Ax1.T13" title="Table 13 â€£ C Qualitative Evaluation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> different examples that we analysed in our manual qualitative analysis, discussed at the end of section 5.1 in the main paper.</p>
</div>
<figure id="Ax1.T11" class="ltx_table">
<table id="Ax1.T11.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T11.1.1.1" class="ltx_tr">
<th id="Ax1.T11.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="Ax1.T11.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T11.1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T11.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Paragraph</span>
Kochi was the centre of Indian spice trade for many centuries, and was known to the Yavanas (Greeks and Romans) as well as Jews, Syrians, Arabs, and Chinese since ancient times. It rose to significance as a trading centre after the port Muziris around Kodungallur (Cranganore) was destroyed by <span id="Ax1.T11.1.1.1.1.1.1.2" class="ltx_text ltx_font_bold">massive flooding of Periyar</span> in 1341. The earliest documented references to Kochi occur in books written by Chinese voyager <span id="Ax1.T11.1.1.1.1.1.1.3" class="ltx_text ltx_font_bold">Ma Huan</span> during his visit to Kochi in the 15th century as part of Admiral Zheng Heâ€™s treasure fleet. There are also references to Kochi in accounts written by Italian traveller NiccolÃ² Da Conti, who visited Kochi in 1440.</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T11.1.2.1" class="ltx_tr">
<td id="Ax1.T11.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T11.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T11.1.2.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T11.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> massive flooding of Periyar</span>
</span>
</td>
</tr>
<tr id="Ax1.T11.1.3.2" class="ltx_tr">
<td id="Ax1.T11.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T11.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T11.1.3.2.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T11.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T11.1.3.2.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T11.1.3.2.1.1.1.2" class="ltx_text ltx_font_bold">Welche Veranstaltung hat den Angriff auf Kochi im Jahr 1341 verursacht?</span> (tr: <span id="Ax1.T11.1.3.2.1.1.1.3" class="ltx_text ltx_font_italic">Which event
caused the attack on Kochi in 1341?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T11.1.4.3" class="ltx_tr">
<td id="Ax1.T11.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T11.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T11.1.4.3.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T11.1.4.3.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T11.1.4.3.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> 
       ?  (tr: <span id="Ax1.T11.1.4.3.1.1.1.2" class="ltx_text ltx_font_italic">What event caused the destruction of Kathmandu?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T11.1.5.4" class="ltx_tr">
<td id="Ax1.T11.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T11.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T11.1.5.4.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T11.1.5.4.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> Ma Huan</span>
</span>
</td>
</tr>
<tr id="Ax1.T11.1.6.5" class="ltx_tr">
<td id="Ax1.T11.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T11.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T11.1.6.5.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T11.1.6.5.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T11.1.6.5.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T11.1.6.5.1.1.1.2" class="ltx_text ltx_font_bold">Welcher chinesische traveller hat die frÃ¼hesten Erinnerungen an Kochi geschrieben?</span> (tr: <span id="Ax1.T11.1.6.5.1.1.1.3" class="ltx_text ltx_font_italic">Which Chinese traveler wrote the earliest memories of Kochi?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T11.1.7.6" class="ltx_tr">
<td id="Ax1.T11.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Ax1.T11.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T11.1.7.6.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T11.1.7.6.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T11.1.7.6.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> ?15
          (tr: <span id="Ax1.T11.1.7.6.1.1.1.2" class="ltx_text ltx_font_italic">Who wrote the first reference to Coty in the 15th century?</span>)</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 11: </span>Paragraph 1 and different questions analysed during out human evaluation.</figcaption>
</figure>
<figure id="Ax1.T12" class="ltx_table">
<table id="Ax1.T12.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Ax1.T12.1.1.1" class="ltx_tr">
<td id="Ax1.T12.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="Ax1.T12.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Paragraph</span> Portuguese navigator, <span id="Ax1.T12.1.1.1.1.1.1.2" class="ltx_text ltx_font_bold">Pedro Ãlvares Cabral</span> founded the first European settlement in India at Kochi in 1500. From 1503 to 1663, Fort Kochi (Fort Emmanuel) was ruled by Portugal. This Portuguese period was a harrowing time for the Saint Thomas Christians and the Jews, as the Inquisition was active in Portuguese India. Kochi hosted the grave of Vasco da Gama, the first European explorer to set sail for India, who was buried at <span id="Ax1.T12.1.1.1.1.1.1.3" class="ltx_text ltx_font_bold">St. Francis Church</span> until his remains were returned to Portugal in 1539. The Portuguese rule was followed by that of the Dutch who renamed Fort Immanuel as Fort Stormsburg. In meantime, the Royal Family of Kochi relocated the capital of Kochi Kingdom to Thrissur, leaving nominal authority over Islands of Kochi. In 1664, Fort Kochi Municipality was established by Dutch, making it the first municipality in Indian subcontinent, which got dissolved when Dutch authority got weaker in the 18th century. The remaining part of Kochi were governed by governors of Kochi Kingdom. By 1773, the Mysore ruler <span id="Ax1.T12.1.1.1.1.1.1.4" class="ltx_text ltx_font_bold">Hyder Ali</span> extended his conquest in the Malabar region to Kochi forcing it to become a tributary of Mysore. The hereditary Prime Ministership of Kochi held by the Paliath Achans ended during this period.</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.2.2" class="ltx_tr">
<td id="Ax1.T12.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T12.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.2.2.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> Pedro Ãlvares Cabral</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.3.3" class="ltx_tr">
<td id="Ax1.T12.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T12.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.3.3.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T12.1.3.3.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T12.1.3.3.1.1.1.2" class="ltx_text ltx_font_bold">Wer hat die erste europÃ¤ische Siedlung in Kochi gegrÃ¼ndet?</span> (tr: <span id="Ax1.T12.1.3.3.1.1.1.3" class="ltx_text ltx_font_italic">Who founded the first European settlement in Kochi?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.4.4" class="ltx_tr">
<td id="Ax1.T12.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T12.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.4.4.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T12.1.4.4.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> ?<span id="Ax1.T12.1.4.4.1.1.1.2" class="ltx_text ltx_font_bold">1500</span>            (tr: <span id="Ax1.T12.1.4.4.1.1.1.3" class="ltx_text ltx_font_italic">Who founded the first European settlement in India in the year 1500?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.5.5" class="ltx_tr">
<td id="Ax1.T12.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T12.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.5.5.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> St. Francis Church</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.6.6" class="ltx_tr">
<td id="Ax1.T12.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T12.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.6.6.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T12.1.6.6.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T12.1.6.6.1.1.1.2" class="ltx_text ltx_font_bold">Wo wurde Vasco da Gama begraben?</span> (tr: <span id="Ax1.T12.1.6.6.1.1.1.3" class="ltx_text ltx_font_italic">Where was Vasco da Gama buried?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.7.7" class="ltx_tr">
<td id="Ax1.T12.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T12.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.7.7.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.7.7.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T12.1.7.7.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> ? <span id="Ax1.T12.1.7.7.1.1.1.2" class="ltx_text ltx_font_bold">da Gama</span> 
    (tr: <span id="Ax1.T12.1.7.7.1.1.1.3" class="ltx_text ltx_font_italic">Where was Vazaw da Gama buried?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.8.8" class="ltx_tr">
<td id="Ax1.T12.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T12.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.8.8.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.8.8.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> Hyder Ali</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.9.9" class="ltx_tr">
<td id="Ax1.T12.1.9.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T12.1.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.9.9.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.9.9.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T12.1.9.9.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T12.1.9.9.1.1.1.2" class="ltx_text ltx_font_bold">Wer war der Herrscher von Mysore im Jahr 1773?</span> (tr: <span id="Ax1.T12.1.9.9.1.1.1.3" class="ltx_text ltx_font_italic">Who was the ruler of Mysore in 1773?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T12.1.10.10" class="ltx_tr">
<td id="Ax1.T12.1.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Ax1.T12.1.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T12.1.10.10.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T12.1.10.10.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T12.1.10.10.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> ?<span id="Ax1.T12.1.10.10.1.1.1.2" class="ltx_text ltx_font_bold">1773</span>         (tr: <span id="Ax1.T12.1.10.10.1.1.1.3" class="ltx_text ltx_font_italic">Who was the ruler of Mysore in 1773?</span>)</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 12: </span>Paragraph 2 and different questions analysed during out human evaluation.</figcaption>
</figure>
<figure id="Ax1.T13" class="ltx_table">
<table id="Ax1.T13.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T13.1.1.1" class="ltx_tr">
<th id="Ax1.T13.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="Ax1.T13.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Paragraph</span>
Taiwan is an island country in East Asia. The main island, known historically as Formosa, makes up <span id="Ax1.T13.1.1.1.1.1.1.2" class="ltx_text ltx_font_bold">99% </span>of the area controlled by the ROC, measuring <span id="Ax1.T13.1.1.1.1.1.1.3" class="ltx_text ltx_font_bold">35,808 square kilometres </span>(13,826 sq mi) and lying some <span id="Ax1.T13.1.1.1.1.1.1.4" class="ltx_text ltx_font_bold">180 kilometres</span> (112 mi) across the Taiwan Strait from the southeastern coast of mainland China. The East China Sea lies to its north, the Philippine Sea to its east, the <span id="Ax1.T13.1.1.1.1.1.1.5" class="ltx_text ltx_font_bold">Luzon Strait</span> directly to its south and the <span id="Ax1.T13.1.1.1.1.1.1.6" class="ltx_text ltx_font_bold">South China Sea</span> to its southwest. Smaller islands include a number in the Taiwan Strait including the Penghu archipelago, the Kinmen and Matsu Islands near the Chinese coast, and some of the South China Sea Islands.</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T13.1.2.1" class="ltx_tr">
<td id="Ax1.T13.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T13.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.2.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> 99%</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.3.2" class="ltx_tr">
<td id="Ax1.T13.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.3.2.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.3.2.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T13.1.3.2.1.1.1.2" class="ltx_text ltx_font_bold">Welcher Prozentsatz der Gebiete von Taiwan wird von der ROK kontrolliert?</span> (tr: <span id="Ax1.T13.1.3.2.1.1.1.3" class="ltx_text ltx_font_italic">What percentage of the areas of Taiwan is controlled by the ROK?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.4.3" class="ltx_tr">
<td id="Ax1.T13.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.4.3.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.4.3.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.4.3.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span>         ()? (tr: <span id="Ax1.T13.1.4.3.1.1.1.2" class="ltx_text ltx_font_italic">What is the percentage of lands controlled by the (Divan)?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.5.4" class="ltx_tr">
<td id="Ax1.T13.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T13.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.5.4.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.5.4.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> 35,808 square kilometres</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.6.5" class="ltx_tr">
<td id="Ax1.T13.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.6.5.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.6.5.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.6.5.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T13.1.6.5.1.1.1.2" class="ltx_text ltx_font_bold">Wie groÃŸ ist die RAF?</span> (tr: <span id="Ax1.T13.1.6.5.1.1.1.3" class="ltx_text ltx_font_italic">How big is the RAF?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.7.6" class="ltx_tr">
<td id="Ax1.T13.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.7.6.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.7.6.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.7.6.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> 
    ? (tr: <span id="Ax1.T13.1.7.6.1.1.1.2" class="ltx_text ltx_font_italic">How many square miles is the island?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.8.7" class="ltx_tr">
<td id="Ax1.T13.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T13.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.8.7.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.8.7.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> Luzon Strait</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.9.8" class="ltx_tr">
<td id="Ax1.T13.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.9.8.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.9.8.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.9.8.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T13.1.9.8.1.1.1.2" class="ltx_text ltx_font_bold">Welcher Fluss ist direkt zum SÃ¼den von Taiwan?</span> (tr: <span id="Ax1.T13.1.9.8.1.1.1.3" class="ltx_text ltx_font_italic">Which river is directly to the south of Taiwan?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.10.9" class="ltx_tr">
<td id="Ax1.T13.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.10.9.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.10.9.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.10.9.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> 
        ? (tr: <span id="Ax1.T13.1.10.9.1.1.1.2" class="ltx_text ltx_font_italic">What is the name of the nearby railway?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.11.10" class="ltx_tr">
<td id="Ax1.T13.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T13.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.11.10.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.11.10.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> South China Sea</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.12.11" class="ltx_tr">
<td id="Ax1.T13.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.12.11.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.12.11.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.12.11.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T13.1.12.11.1.1.1.2" class="ltx_text ltx_font_bold">Welches Meer ist im SÃ¼dwesten von Taiwan?</span> (tr: <span id="Ax1.T13.1.12.11.1.1.1.3" class="ltx_text ltx_font_italic">Which sea is in southwest of Taiwan?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.13.12" class="ltx_tr">
<td id="Ax1.T13.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.13.12.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.13.12.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.13.12.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> 
          ? (tr: <span id="Ax1.T13.1.13.12.1.1.1.2" class="ltx_text ltx_font_italic">What is the ocean seen on the western side of Taiwan?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.14.13" class="ltx_tr">
<td id="Ax1.T13.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Ax1.T13.1.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.14.13.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.14.13.1.1.1.1" class="ltx_text ltx_font_bold">Answer</span> 180 kilometres</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.15.14" class="ltx_tr">
<td id="Ax1.T13.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Ax1.T13.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.15.14.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.15.14.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.15.14.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = de)</span> <span id="Ax1.T13.1.15.14.1.1.1.2" class="ltx_text ltx_font_bold">Wie weit ist die RAF von Taiwan aus der sÃ¼dlichen KÃ¼ste von China?</span> (tr: <span id="Ax1.T13.1.15.14.1.1.1.3" class="ltx_text ltx_font_italic">How far is the RAF from Taiwan from the southern coast of China?</span>)</span>
</span>
</td>
</tr>
<tr id="Ax1.T13.1.16.15" class="ltx_tr">
<td id="Ax1.T13.1.16.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Ax1.T13.1.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="Ax1.T13.1.16.15.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="Ax1.T13.1.16.15.1.1.1.1" class="ltx_text ltx_font_bold">QG<sub id="Ax1.T13.1.16.15.1.1.1.1.1" class="ltx_sub">synth+trans</sub> (target language = ar)</span> 
        ? (tr: <span id="Ax1.T13.1.16.15.1.1.1.2" class="ltx_text ltx_font_italic">How long are the Taiwan Islands from the coast of China?</span>)</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TableÂ 13: </span>Paragraph 3 and different questions analysed during out human evaluation.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="Ax1.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Ax1.F5.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:212.5pt;"><img src="/html/2010.12643/assets/x4.png" id="Ax1.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">FigureÂ 3: </span>SQuAD-it</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="Ax1.F5.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:212.5pt;"><img src="/html/2010.12643/assets/x5.png" id="Ax1.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">FigureÂ 4: </span>PIAF (fr)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2010.12643/assets/x6.png" id="Ax1.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="226" height="150" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">FigureÂ 5: </span>KorQuAD</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="Ax1.F5.3" class="ltx_sectional-block ltx_centering ltx_figure_panel">
<section id="Ax1.SS4" class="ltx_subsection ltx_align_left">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D </span>Learning Curves for Unseen Languages</h3>

<div id="Ax1.SS4.p1" class="ltx_para">
<p id="Ax1.SS4.p1.1" class="ltx_p">We show on Figures <a href="#Ax1.F5" title="Figure 5 â€£ C Qualitative Evaluation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>,<a href="#Ax1.F5" title="Figure 5 â€£ C Qualitative Evaluation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>,<a href="#Ax1.F5" title="Figure 5 â€£ C Qualitative Evaluation â€£ Appendix â€£ Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> the results of three learning curves for respectively SQuAD-it, PIAF (fr) and KorQuad where the models are trained on different amount of synthetic questions in our <em id="Ax1.SS4.p1.1.1" class="ltx_emph ltx_font_italic">All Languages</em> setting.</p>
</div>
<div id="Ax1.SS4.p2" class="ltx_para">
<p id="Ax1.SS4.p2.1" class="ltx_p">The synthetic questions are sampled among all the five languages in MLQA . The standard deviation over four different seeds for the sampling are displayed through the confidence interval (light blue) around the averaged main curves.
We observe that for SQuAD-it and KorQuAD the performances increase significantly at the beginning, then remain mostly stable, while for PIAF (fr) the best performances are obtained with 100k of additional synthetic data, a slight improvement from 50k additional questions before starting to decrease.</p>
</div>
</section>
</div>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2010.12642" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2010.12643" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2010.12643">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2010.12643" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2010.12644" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar  6 08:38:43 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
