<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2002.00211] Learning to Detect Malicious Clients for Robust Federated Learning</title><meta property="og:description" content="Federated learning systems are vulnerable to attacks from malicious clients. As the central server in the system cannot govern the behaviors of the clients, a rogue client may initiate an attack by sending malicious mo…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Learning to Detect Malicious Clients for Robust Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Learning to Detect Malicious Clients for Robust Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2002.00211">

<!--Generated on Sat Mar 16 11:56:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Learning to Detect Malicious Clients for Robust Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Suyi Li<sup id="id8.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yong Cheng<sup id="id9.2.id1" class="ltx_sup">2</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wei Wang<sup id="id10.3.id1" class="ltx_sup">1</sup>
<br class="ltx_break">Yang Liu<sup id="id11.4.id2" class="ltx_sup">2</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tianjian Chen<sup id="id12.4.id1" class="ltx_sup">2</sup>
<br class="ltx_break"><sup id="id13.5.id2" class="ltx_sup">1</sup>The Hong Kong University of Science and Technology
<br class="ltx_break"><sup id="id14.6.id3" class="ltx_sup">2</sup>AI Department, WeBank
<br class="ltx_break">{slida, weiwa}@cse.ust.hk,
{petercheng, yangliu, tobychen}@webank.com
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id15.id1" class="ltx_p">Federated learning systems are vulnerable to attacks from malicious clients. As the central server in the system cannot govern the behaviors of the clients, a rogue client may initiate an attack by sending malicious model updates to the server, so as to degrade the learning performance or enforce targeted model poisoning attacks (a.k.a. backdoor attacks). Therefore, timely detecting these malicious model updates and the underlying attackers becomes critically important. In this work, we propose a new framework for robust federated learning where the central server learns to <span id="id15.id1.1" class="ltx_text ltx_font_italic">detect and remove</span> the malicious model updates using a powerful detection model, leading to <span id="id15.id1.2" class="ltx_text ltx_font_italic">targeted defense</span>. We evaluate our solution in both image classification and sentiment analysis tasks with a variety of machine learning models. Experimental results show that our solution ensures robust federated learning that is resilient to both the Byzantine attacks and the targeted model poisoning attacks.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) comes as a new distributed machine learning (ML) paradigm where multiple clients (e.g., mobile devices) collaboratively train an ML model without
revealing their private
data <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>); Yang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib27" title="" class="ltx_ref">2019b</a>); Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>. In a
typical FL setting, a central server is used to maintain a global model and
coordinate the clients. Each client transfers the local model updates to the
central server for immediate aggregation, while keeping the raw data in their
local storage. As no private data gets exchanged in the training process,
FL provides a strong privacy guarantee to the participating clients and has found wide applications in edge computing, finance, and
healthcare <cite class="ltx_cite ltx_citemacro_cite">Yang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2019a</a>); Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2019b</a>, <a href="#bib.bib17" title="" class="ltx_ref">c</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL systems are vulnerable to
attacks from malicious clients, which has become a major roadblock to
their practical deployment <cite class="ltx_cite ltx_citemacro_cite">Bhagoji <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>); Bagdasaryan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>); Wu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>); Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>. In an FL system, the central server cannot govern
the behaviors of the clients, nor can it access their private data. As a
consequence, the malicious clients can cheat the server by sending modified and
<em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">harmful</em> model updates, initiating <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">adversarial attacks</em> on the
global model <cite class="ltx_cite ltx_citemacro_cite">Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>. In this paper, we consider two types
of adversarial attacks, namely the <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">untargeted</em> attacks and the
<em id="S1.p2.1.4" class="ltx_emph ltx_font_italic">targeted</em> attacks. The untargeted attacks aim to degrade the overall
model performance and can be viewed as Byzantine attacks which result in model
performance deterioration or failure of model training <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2019a</a>); Wu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>. The targeted attacks (a.k.a. backdoor attacks) <cite class="ltx_cite ltx_citemacro_cite">Bhagoji <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>); Bagdasaryan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>); Sun <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>, on
the other hand, aim to modify the behaviors of the model on some specific data
instances chosen by the attackers (e.g., recognizing the images of cats as
dogs), while keeping the model performance on the other data instances
unaffected. Both the untargeted and targeted attacks can result in
catastrophic consequences. Therefore, attackers, along with their harmful
model updates, must be timely <span id="S1.p2.1.5" class="ltx_text ltx_font_italic">detected and removed</span> from an FL system to
prevent malicious model corruptions and inappropriate incentive awards
distributed to the adversary
clients <cite class="ltx_cite ltx_citemacro_cite">Kang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Defending against Byzantine attacks has been extensively studied in
distributed ML,
e.g., <cite class="ltx_cite ltx_citemacro_cite">Chen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2017</a>); Blanchard <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2017</a>); Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>); Yin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2018</a>)</cite>.
However, we find that the existing Byzantine-tolerant algorithms are unable to
achieve satisfactory model performance in the FL setting. These methods do not
differentiate the malicious updates from the normal ones. Instead, they aim to
tolerate the adversarial attacks and mitigate their negative impacts with new
model update mechanisms that cannot be easily compromised by the
attackers. In addition, most of these methods assume independent and identically distributed (IID) data, making them a poor fit
in the FL scenario where non-IID datasets are commonplace. Researchers in the FL community have also proposed
various defense mechanisms against adversarial
attacks <cite class="ltx_cite ltx_citemacro_cite">Sun <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>); Shen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2016</a>)</cite>. These mechanisms, however,
are mainly designed for the deliberate targeted attacks and cannot survive under the
untargeted Byzantine attacks.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we tackle the adversarial attacks on the FL systems from a new
perspective. We propose a <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">spectral anomaly detection</span> based
framework <cite class="ltx_cite ltx_citemacro_cite">Chandola <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2009</a>); Kieu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>); An and Cho (<a href="#bib.bib2" title="" class="ltx_ref">2015</a>)</cite> that
detects the abnormal model updates based on their <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">low-dimensional
embeddings</span>, in which the noisy and irrelevant features are removed whilst the
essential features are retained. We show that in such a
low-dimensional latent feature space, the abnormal (i.e., malicious) model updates from clients can be easily differentiated
as their essential features are drastically different from those of the normal updates, leading to <span id="S1.p4.1.3" class="ltx_text ltx_font_italic"> targeted defense</span>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To our best knowledge, we are the first to employ spectral anomaly detection for robust FL systems. Our spectral anomaly detection framework provides three benefits. <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">First</em>,
it works in both the unsupervised and semi-supervised settings, making it
particularly attractive to the FL scenarios in which the malicious model
updates are unknown and cannot be accurately predicted beforehand.
<em id="S1.p5.1.2" class="ltx_emph ltx_font_italic">Second</em>, our spectral anomaly detection model uses variational
autoencoder (VAE) with <em id="S1.p5.1.3" class="ltx_emph ltx_font_italic">dynamic thresholding</em>. Because the detection
threshold is only determined after the model updates from all the clients
have been received, the attackers cannot learn the detection mechanism <em id="S1.p5.1.4" class="ltx_emph ltx_font_italic">a
priori</em>. <em id="S1.p5.1.5" class="ltx_emph ltx_font_italic">Third</em>, by detecting and removing the malicious updates in the
central server, their negative impacts can be fully eliminated.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We evaluate our spectral anomaly detection approach against the image
classification and sentiment analysis tasks in the heterogeneous FL settings
with various ML models, including logistic regression (LR), convolutional
neural network (CNN), and recurrent neural network
(RNN) <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>. In all experiments, our method accurately
detects a range of adversarial attacks (untargeted and targeted) and
eliminates their negative impacts almost entirely. This is not possible using
the existing Byzantine-tolerant approaches.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Prior Arts</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Robust Distributed Machine Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Existing methods mainly focus
on building a <em id="S2.SS1.p1.1.1" class="ltx_emph ltx_font_italic">robust aggregator</em> that estimates the “center”
of the received local model updates rather than taking a weighted average,
which can be easily compromised. Most of these works assume IID data across all the clients (a.k.a. workers). So the local model updates from any of the
benign clients can presumably approximate the true gradients or model weights.
Following this idea, many robust ML algorithms, such as
Krum <cite class="ltx_cite ltx_citemacro_cite">Blanchard <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite>, Medoid <cite class="ltx_cite ltx_citemacro_cite">Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite>, and Marginal
Median <cite class="ltx_cite ltx_citemacro_cite">Xie <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite>, select a <em id="S2.SS1.p1.1.2" class="ltx_emph ltx_font_italic">representative</em> client
and use its update to estimate the true center. This approach,
while statistically resilient to the adversarial attacks,
may result in a <em id="S2.SS1.p1.1.3" class="ltx_emph ltx_font_italic">biased</em> global model as it only accounts for a small fraction of the local updates.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Other approaches, such as GeoMed <cite class="ltx_cite ltx_citemacro_cite">Chen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2017</a>)</cite> and
Trimmed Mean <cite class="ltx_cite ltx_citemacro_cite">Yin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2018</a>)</cite>, estimate the center based on the model updates
from clients, without differentiating the malicious from the normal
ones. These approaches can mitigate the impacts of malicious attacks
to a certain degree but not fully eliminate them.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">More recently, <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2019a</a>)</cite> introduces an additional <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><msub id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.1.1.2" xref="S2.SS1.p3.1.m1.1.1.2.cmml">l</mi><mn id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">l_{1}</annotation></semantics></math>-norm
regularization on the cost function to achieve robustness against Byzantine
attacks in distributed learning. <cite class="ltx_cite ltx_citemacro_cite">Wu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite> proposes an
approach that combines distributed SAGA and geometric median for robust
federated optimization in the presence of Byzantine attacks. Both approaches
cannot defend against the targeted attacks.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Robust Federated Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The existing solutions for robust FL are mostly defense-based and are limited
to the targeted attacks. For example, <cite class="ltx_cite ltx_citemacro_cite">Shen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2016</a>)</cite> proposes a
detection-based approach for backdoor attacks in collaborative ML.
However, it is assumed that the generated mask features of the training data
have the same distribution as that of the training data,
which is not the case in the FL setting. <cite class="ltx_cite ltx_citemacro_cite">Sun <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite> proposes a
low-complexity defense mechanism that mitigates the impact of backdoor attacks
in FL tasks through model weight clipping and noise injection. However, this
defense approach is unable to handle the untargeted attacks that do not modify
the magnitude of model weights, such as sign-flipping
attack <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2019a</a>)</cite>. <cite class="ltx_cite ltx_citemacro_cite">Fang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite> proposes two defense
mechanisms, namely error rate based rejection and loss function based
rejection, which sequentially reject the malicious local updates by
testing their impacts on the global model over a validation set. However, as FL
tasks typically involve a large number of clients, exhaustively testing their
impacts over the validation set is computationally prohibitive.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Spectral Anomaly Detection</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Spectral anomaly detection is one of the most effective anomaly detection
approaches <cite class="ltx_cite ltx_citemacro_cite">Chandola <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2009</a>)</cite>. The idea is to embed both the normal
data instances and the abnormal instances into a low-dimensional latent space (hence the name “spectral”), in
which their embeddings differ significantly. Therefore, by learning to remove
the noisy features of data instances and project the important ones into a
low-dimensional latent space, we can easily identify the abnormal
instances by looking at reconstruction errors <cite class="ltx_cite ltx_citemacro_cite">An and Cho (<a href="#bib.bib2" title="" class="ltx_ref">2015</a>)</cite>. This method has been proved effective in
detecting anomalous image data and time series
data <cite class="ltx_cite ltx_citemacro_cite">Agovic <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib1" title="" class="ltx_ref">2008</a>); An and Cho (<a href="#bib.bib2" title="" class="ltx_ref">2015</a>); Xu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>); Kieu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Spectral Anomaly Detection for Robust FL</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we present a novel spectral anomaly detection framework for
robust FL.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Definition</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We consider a typical FL setting in which multiple clients collaboratively
train an ML model maintained in a central server using the <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span>
algorithm <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>)</cite>. We assume that an attacker can only
inspect a stale version of the model (i.e., <em id="S3.SS1.p1.1.2" class="ltx_emph ltx_font_italic">stale whitebox</em> model
inspection <cite class="ltx_cite ltx_citemacro_cite">Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>), which is generally the case in FL. We
also assume the availability of a public dataset that can be used for training
the spectral anomaly detection model. This assumption generally holds in
practice <cite class="ltx_cite ltx_citemacro_cite">Li and Wang (<a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>. In fact, having a public dataset is indispensible
to the design of neural network architecture in FL. We defer the detailed
training process of the spectral anomaly detection model to
Section <a href="#S4.SS2" title="4.2 Datasets and ML Models ‣ 4 Performance Evaluation ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Impact of Malicious Model Updates</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.14" class="ltx_p">Before presenting our solution, we need to understand how the adversarial
updates may harm the model performance. To this end, we turn to a simple
linear model, where we quantify the negative impacts of those malicious
updates and draw key insights that drive our design. Consider a linear
regression model <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="\hat{y}=\langle w,x\rangle" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.3" xref="S3.SS2.p1.1.m1.2.3.cmml"><mover accent="true" id="S3.SS2.p1.1.m1.2.3.2" xref="S3.SS2.p1.1.m1.2.3.2.cmml"><mi id="S3.SS2.p1.1.m1.2.3.2.2" xref="S3.SS2.p1.1.m1.2.3.2.2.cmml">y</mi><mo id="S3.SS2.p1.1.m1.2.3.2.1" xref="S3.SS2.p1.1.m1.2.3.2.1.cmml">^</mo></mover><mo id="S3.SS2.p1.1.m1.2.3.1" xref="S3.SS2.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S3.SS2.p1.1.m1.2.3.3.2" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p1.1.m1.2.3.3.2.1" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml">⟨</mo><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">w</mi><mo id="S3.SS2.p1.1.m1.2.3.3.2.2" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p1.1.m1.2.2" xref="S3.SS2.p1.1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S3.SS2.p1.1.m1.2.3.3.2.3" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml">⟩</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><apply id="S3.SS2.p1.1.m1.2.3.cmml" xref="S3.SS2.p1.1.m1.2.3"><eq id="S3.SS2.p1.1.m1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3.1"></eq><apply id="S3.SS2.p1.1.m1.2.3.2.cmml" xref="S3.SS2.p1.1.m1.2.3.2"><ci id="S3.SS2.p1.1.m1.2.3.2.1.cmml" xref="S3.SS2.p1.1.m1.2.3.2.1">^</ci><ci id="S3.SS2.p1.1.m1.2.3.2.2.cmml" xref="S3.SS2.p1.1.m1.2.3.2.2">𝑦</ci></apply><list id="S3.SS2.p1.1.m1.2.3.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3.3.2"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑤</ci><ci id="S3.SS2.p1.1.m1.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2">𝑥</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">\hat{y}=\langle w,x\rangle</annotation></semantics></math> with parameters <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">w</annotation></semantics></math>, data
<math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">x</annotation></semantics></math>, and loss function <math id="S3.SS2.p1.4.m4.3" class="ltx_Math" alttext="\ell=\frac{1}{2}(\langle w,x\rangle-y)^{2}" display="inline"><semantics id="S3.SS2.p1.4.m4.3a"><mrow id="S3.SS2.p1.4.m4.3.3" xref="S3.SS2.p1.4.m4.3.3.cmml"><mi mathvariant="normal" id="S3.SS2.p1.4.m4.3.3.3" xref="S3.SS2.p1.4.m4.3.3.3.cmml">ℓ</mi><mo id="S3.SS2.p1.4.m4.3.3.2" xref="S3.SS2.p1.4.m4.3.3.2.cmml">=</mo><mrow id="S3.SS2.p1.4.m4.3.3.1" xref="S3.SS2.p1.4.m4.3.3.1.cmml"><mfrac id="S3.SS2.p1.4.m4.3.3.1.3" xref="S3.SS2.p1.4.m4.3.3.1.3.cmml"><mn id="S3.SS2.p1.4.m4.3.3.1.3.2" xref="S3.SS2.p1.4.m4.3.3.1.3.2.cmml">1</mn><mn id="S3.SS2.p1.4.m4.3.3.1.3.3" xref="S3.SS2.p1.4.m4.3.3.1.3.3.cmml">2</mn></mfrac><mo lspace="0em" rspace="0em" id="S3.SS2.p1.4.m4.3.3.1.2" xref="S3.SS2.p1.4.m4.3.3.1.2.cmml">​</mo><msup id="S3.SS2.p1.4.m4.3.3.1.1" xref="S3.SS2.p1.4.m4.3.3.1.1.cmml"><mrow id="S3.SS2.p1.4.m4.3.3.1.1.1.1" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.4.m4.3.3.1.1.1.1.2" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.cmml"><mrow id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.2" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.1.cmml"><mo stretchy="false" id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.2.1" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.1.cmml">⟨</mo><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">w</mi><mo id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.2.2" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.1.cmml">,</mo><mi id="S3.SS2.p1.4.m4.2.2" xref="S3.SS2.p1.4.m4.2.2.cmml">x</mi><mo stretchy="false" id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.2.3" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.1.cmml">⟩</mo></mrow><mo id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.1" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.1.cmml">−</mo><mi id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.3" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S3.SS2.p1.4.m4.3.3.1.1.1.1.3" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.cmml">)</mo></mrow><mn id="S3.SS2.p1.4.m4.3.3.1.1.3" xref="S3.SS2.p1.4.m4.3.3.1.1.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.3b"><apply id="S3.SS2.p1.4.m4.3.3.cmml" xref="S3.SS2.p1.4.m4.3.3"><eq id="S3.SS2.p1.4.m4.3.3.2.cmml" xref="S3.SS2.p1.4.m4.3.3.2"></eq><ci id="S3.SS2.p1.4.m4.3.3.3.cmml" xref="S3.SS2.p1.4.m4.3.3.3">ℓ</ci><apply id="S3.SS2.p1.4.m4.3.3.1.cmml" xref="S3.SS2.p1.4.m4.3.3.1"><times id="S3.SS2.p1.4.m4.3.3.1.2.cmml" xref="S3.SS2.p1.4.m4.3.3.1.2"></times><apply id="S3.SS2.p1.4.m4.3.3.1.3.cmml" xref="S3.SS2.p1.4.m4.3.3.1.3"><divide id="S3.SS2.p1.4.m4.3.3.1.3.1.cmml" xref="S3.SS2.p1.4.m4.3.3.1.3"></divide><cn type="integer" id="S3.SS2.p1.4.m4.3.3.1.3.2.cmml" xref="S3.SS2.p1.4.m4.3.3.1.3.2">1</cn><cn type="integer" id="S3.SS2.p1.4.m4.3.3.1.3.3.cmml" xref="S3.SS2.p1.4.m4.3.3.1.3.3">2</cn></apply><apply id="S3.SS2.p1.4.m4.3.3.1.1.cmml" xref="S3.SS2.p1.4.m4.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.3.3.1.1.2.cmml" xref="S3.SS2.p1.4.m4.3.3.1.1">superscript</csymbol><apply id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1"><minus id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.1"></minus><list id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.2.2"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝑤</ci><ci id="S3.SS2.p1.4.m4.2.2.cmml" xref="S3.SS2.p1.4.m4.2.2">𝑥</ci></list><ci id="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.4.m4.3.3.1.1.1.1.1.3">𝑦</ci></apply><cn type="integer" id="S3.SS2.p1.4.m4.3.3.1.1.3.cmml" xref="S3.SS2.p1.4.m4.3.3.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.3c">\ell=\frac{1}{2}(\langle w,x\rangle-y)^{2}</annotation></semantics></math>. We
train the model using the standard SGD solution <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="w^{t+1}=w^{t}-\eta\sum_{j=1}^{B}\nabla\ell(w^{t})" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mrow id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><msup id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.3.2" xref="S3.SS2.p1.5.m5.1.1.3.2.cmml">w</mi><mrow id="S3.SS2.p1.5.m5.1.1.3.3" xref="S3.SS2.p1.5.m5.1.1.3.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.3.3.2" xref="S3.SS2.p1.5.m5.1.1.3.3.2.cmml">t</mi><mo id="S3.SS2.p1.5.m5.1.1.3.3.1" xref="S3.SS2.p1.5.m5.1.1.3.3.1.cmml">+</mo><mn id="S3.SS2.p1.5.m5.1.1.3.3.3" xref="S3.SS2.p1.5.m5.1.1.3.3.3.cmml">1</mn></mrow></msup><mo id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">=</mo><mrow id="S3.SS2.p1.5.m5.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.cmml"><msup id="S3.SS2.p1.5.m5.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.3.2" xref="S3.SS2.p1.5.m5.1.1.1.3.2.cmml">w</mi><mi id="S3.SS2.p1.5.m5.1.1.1.3.3" xref="S3.SS2.p1.5.m5.1.1.1.3.3.cmml">t</mi></msup><mo id="S3.SS2.p1.5.m5.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.2.cmml">−</mo><mrow id="S3.SS2.p1.5.m5.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.1.3.cmml">η</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.5.m5.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.p1.5.m5.1.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.cmml"><msubsup id="S3.SS2.p1.5.m5.1.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.cmml"><mo id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.2.cmml">j</mi><mo id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.2.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.3.cmml">B</mi></msubsup><mrow id="S3.SS2.p1.5.m5.1.1.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.cmml"><mrow id="S3.SS2.p1.5.m5.1.1.1.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.cmml"><mo rspace="0.167em" id="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.1.cmml">∇</mo><mi mathvariant="normal" id="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.2.cmml">ℓ</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p1.5.m5.1.1.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.2.cmml">w</mi><mi id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo stretchy="false" id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><eq id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2"></eq><apply id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.3.2">𝑤</ci><apply id="S3.SS2.p1.5.m5.1.1.3.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3.3"><plus id="S3.SS2.p1.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.3.3.1"></plus><ci id="S3.SS2.p1.5.m5.1.1.3.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.3.3.2">𝑡</ci><cn type="integer" id="S3.SS2.p1.5.m5.1.1.3.3.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3.3.3">1</cn></apply></apply><apply id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1"><minus id="S3.SS2.p1.5.m5.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.2"></minus><apply id="S3.SS2.p1.5.m5.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.3.2">𝑤</ci><ci id="S3.SS2.p1.5.m5.1.1.1.3.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.3.3">𝑡</ci></apply><apply id="S3.SS2.p1.5.m5.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1"><times id="S3.SS2.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.2"></times><ci id="S3.SS2.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.3">𝜂</ci><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1"><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2">superscript</csymbol><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2">subscript</csymbol><sum id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.2"></sum><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3"><eq id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.2">𝑗</ci><cn type="integer" id="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.2.3">𝐵</ci></apply><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1"><times id="S3.SS2.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.2"></times><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.3"><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.1">∇</ci><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.3.2">ℓ</ci></apply><apply id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.2">𝑤</ci><ci id="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">w^{t+1}=w^{t}-\eta\sum_{j=1}^{B}\nabla\ell(w^{t})</annotation></semantics></math>, where <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="w^{t}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><msup id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">w</mi><mi id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">𝑤</ci><ci id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">w^{t}</annotation></semantics></math> is the parameter vector
learned in the <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mi id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">t</annotation></semantics></math>-th iteration, <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">B</annotation></semantics></math> the local batch size, and <math id="S3.SS2.p1.9.m9.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S3.SS2.p1.9.m9.1a"><mi id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><ci id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">\eta</annotation></semantics></math> the
learning rate. Let <math id="S3.SS2.p1.10.m10.1" class="ltx_Math" alttext="w^{t}_{k}" display="inline"><semantics id="S3.SS2.p1.10.m10.1a"><msubsup id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml"><mi id="S3.SS2.p1.10.m10.1.1.2.2" xref="S3.SS2.p1.10.m10.1.1.2.2.cmml">w</mi><mi id="S3.SS2.p1.10.m10.1.1.3" xref="S3.SS2.p1.10.m10.1.1.3.cmml">k</mi><mi id="S3.SS2.p1.10.m10.1.1.2.3" xref="S3.SS2.p1.10.m10.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><apply id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1">subscript</csymbol><apply id="S3.SS2.p1.10.m10.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.2.1.cmml" xref="S3.SS2.p1.10.m10.1.1">superscript</csymbol><ci id="S3.SS2.p1.10.m10.1.1.2.2.cmml" xref="S3.SS2.p1.10.m10.1.1.2.2">𝑤</ci><ci id="S3.SS2.p1.10.m10.1.1.2.3.cmml" xref="S3.SS2.p1.10.m10.1.1.2.3">𝑡</ci></apply><ci id="S3.SS2.p1.10.m10.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">w^{t}_{k}</annotation></semantics></math> be the model weight learned by the <math id="S3.SS2.p1.11.m11.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.11.m11.1a"><mi id="S3.SS2.p1.11.m11.1.1" xref="S3.SS2.p1.11.m11.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m11.1b"><ci id="S3.SS2.p1.11.m11.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m11.1c">k</annotation></semantics></math>-th client in
the <math id="S3.SS2.p1.12.m12.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.12.m12.1a"><mi id="S3.SS2.p1.12.m12.1.1" xref="S3.SS2.p1.12.m12.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m12.1b"><ci id="S3.SS2.p1.12.m12.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m12.1c">t</annotation></semantics></math>-th iteration without any malicious attacks. Let <math id="S3.SS2.p1.13.m13.1" class="ltx_Math" alttext="\hat{w}^{t}_{k}" display="inline"><semantics id="S3.SS2.p1.13.m13.1a"><msubsup id="S3.SS2.p1.13.m13.1.1" xref="S3.SS2.p1.13.m13.1.1.cmml"><mover accent="true" id="S3.SS2.p1.13.m13.1.1.2.2" xref="S3.SS2.p1.13.m13.1.1.2.2.cmml"><mi id="S3.SS2.p1.13.m13.1.1.2.2.2" xref="S3.SS2.p1.13.m13.1.1.2.2.2.cmml">w</mi><mo id="S3.SS2.p1.13.m13.1.1.2.2.1" xref="S3.SS2.p1.13.m13.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.SS2.p1.13.m13.1.1.3" xref="S3.SS2.p1.13.m13.1.1.3.cmml">k</mi><mi id="S3.SS2.p1.13.m13.1.1.2.3" xref="S3.SS2.p1.13.m13.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m13.1b"><apply id="S3.SS2.p1.13.m13.1.1.cmml" xref="S3.SS2.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.13.m13.1.1.1.cmml" xref="S3.SS2.p1.13.m13.1.1">subscript</csymbol><apply id="S3.SS2.p1.13.m13.1.1.2.cmml" xref="S3.SS2.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.13.m13.1.1.2.1.cmml" xref="S3.SS2.p1.13.m13.1.1">superscript</csymbol><apply id="S3.SS2.p1.13.m13.1.1.2.2.cmml" xref="S3.SS2.p1.13.m13.1.1.2.2"><ci id="S3.SS2.p1.13.m13.1.1.2.2.1.cmml" xref="S3.SS2.p1.13.m13.1.1.2.2.1">^</ci><ci id="S3.SS2.p1.13.m13.1.1.2.2.2.cmml" xref="S3.SS2.p1.13.m13.1.1.2.2.2">𝑤</ci></apply><ci id="S3.SS2.p1.13.m13.1.1.2.3.cmml" xref="S3.SS2.p1.13.m13.1.1.2.3">𝑡</ci></apply><ci id="S3.SS2.p1.13.m13.1.1.3.cmml" xref="S3.SS2.p1.13.m13.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m13.1c">\hat{w}^{t}_{k}</annotation></semantics></math> be
similarly defined subject to attacks, where the malicious updates from the
adversarial clients are generated by adding noise <math id="S3.SS2.p1.14.m14.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS2.p1.14.m14.1a"><mi id="S3.SS2.p1.14.m14.1.1" xref="S3.SS2.p1.14.m14.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.14.m14.1b"><ci id="S3.SS2.p1.14.m14.1.1.cmml" xref="S3.SS2.p1.14.m14.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.14.m14.1c">\psi</annotation></semantics></math> to the normal
updates. The following theorem quantifies the negative impact of malicious updates.</p>
</div>
<div id="Thmtheorem1" class="ltx_theorem ltx_theorem_theorem">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmtheorem1.1.1.1" class="ltx_text ltx_font_bold">Theorem 1</span></span><span id="Thmtheorem1.2.2" class="ltx_text ltx_font_bold">.</span>
</h6>
<div id="Thmtheorem1.p1" class="ltx_para">
<p id="Thmtheorem1.p1.2" class="ltx_p"><span id="Thmtheorem1.p1.2.2" class="ltx_text ltx_font_italic">Let <math id="Thmtheorem1.p1.1.1.m1.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="Thmtheorem1.p1.1.1.m1.1a"><msub id="Thmtheorem1.p1.1.1.m1.1.1" xref="Thmtheorem1.p1.1.1.m1.1.1.cmml"><mi id="Thmtheorem1.p1.1.1.m1.1.1.2" xref="Thmtheorem1.p1.1.1.m1.1.1.2.cmml">f</mi><mi id="Thmtheorem1.p1.1.1.m1.1.1.3" xref="Thmtheorem1.p1.1.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.1.1.m1.1b"><apply id="Thmtheorem1.p1.1.1.m1.1.1.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1"><csymbol cd="ambiguous" id="Thmtheorem1.p1.1.1.m1.1.1.1.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1">subscript</csymbol><ci id="Thmtheorem1.p1.1.1.m1.1.1.2.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.2">𝑓</ci><ci id="Thmtheorem1.p1.1.1.m1.1.1.3.cmml" xref="Thmtheorem1.p1.1.1.m1.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.1.1.m1.1c">f_{a}</annotation></semantics></math> be the fraction of the total weights attributed to
the malicious clients, where <math id="Thmtheorem1.p1.2.2.m2.1" class="ltx_Math" alttext="0\leq f_{a}\leq 1" display="inline"><semantics id="Thmtheorem1.p1.2.2.m2.1a"><mrow id="Thmtheorem1.p1.2.2.m2.1.1" xref="Thmtheorem1.p1.2.2.m2.1.1.cmml"><mn id="Thmtheorem1.p1.2.2.m2.1.1.2" xref="Thmtheorem1.p1.2.2.m2.1.1.2.cmml">0</mn><mo id="Thmtheorem1.p1.2.2.m2.1.1.3" xref="Thmtheorem1.p1.2.2.m2.1.1.3.cmml">≤</mo><msub id="Thmtheorem1.p1.2.2.m2.1.1.4" xref="Thmtheorem1.p1.2.2.m2.1.1.4.cmml"><mi id="Thmtheorem1.p1.2.2.m2.1.1.4.2" xref="Thmtheorem1.p1.2.2.m2.1.1.4.2.cmml">f</mi><mi id="Thmtheorem1.p1.2.2.m2.1.1.4.3" xref="Thmtheorem1.p1.2.2.m2.1.1.4.3.cmml">a</mi></msub><mo id="Thmtheorem1.p1.2.2.m2.1.1.5" xref="Thmtheorem1.p1.2.2.m2.1.1.5.cmml">≤</mo><mn id="Thmtheorem1.p1.2.2.m2.1.1.6" xref="Thmtheorem1.p1.2.2.m2.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="Thmtheorem1.p1.2.2.m2.1b"><apply id="Thmtheorem1.p1.2.2.m2.1.1.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1"><and id="Thmtheorem1.p1.2.2.m2.1.1a.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1"></and><apply id="Thmtheorem1.p1.2.2.m2.1.1b.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1"><leq id="Thmtheorem1.p1.2.2.m2.1.1.3.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.3"></leq><cn type="integer" id="Thmtheorem1.p1.2.2.m2.1.1.2.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.2">0</cn><apply id="Thmtheorem1.p1.2.2.m2.1.1.4.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.4"><csymbol cd="ambiguous" id="Thmtheorem1.p1.2.2.m2.1.1.4.1.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.4">subscript</csymbol><ci id="Thmtheorem1.p1.2.2.m2.1.1.4.2.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.4.2">𝑓</ci><ci id="Thmtheorem1.p1.2.2.m2.1.1.4.3.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.4.3">𝑎</ci></apply></apply><apply id="Thmtheorem1.p1.2.2.m2.1.1c.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1"><leq id="Thmtheorem1.p1.2.2.m2.1.1.5.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.5"></leq><share href="#Thmtheorem1.p1.2.2.m2.1.1.4.cmml" id="Thmtheorem1.p1.2.2.m2.1.1d.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1"></share><cn type="integer" id="Thmtheorem1.p1.2.2.m2.1.1.6.cmml" xref="Thmtheorem1.p1.2.2.m2.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmtheorem1.p1.2.2.m2.1c">0\leq f_{a}\leq 1</annotation></semantics></math>. We have</span></p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.7" class="ltx_Math" alttext="\footnotesize\textstyle\mathbb{E}[\hat{w}^{t+1}_{k}]-\mathbb{E}[w_{k}^{t+1}]=f_{a}(\mathbb{E}[\psi]-\mathbb{E}\left[\eta\sum_{j=1}^{B}\langle\psi,x_{k,j}\rangle x_{k,j}\right])." display="block"><semantics id="S3.E1.m1.7a"><mrow id="S3.E1.m1.7.7.1" xref="S3.E1.m1.7.7.1.1.cmml"><mrow id="S3.E1.m1.7.7.1.1" xref="S3.E1.m1.7.7.1.1.cmml"><mrow id="S3.E1.m1.7.7.1.1.2" xref="S3.E1.m1.7.7.1.1.2.cmml"><mrow id="S3.E1.m1.7.7.1.1.1.1" xref="S3.E1.m1.7.7.1.1.1.1.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.1.1.3.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.1.1.1.2.cmml"><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.1.1.1.2.1.cmml">[</mo><msubsup id="S3.E1.m1.7.7.1.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.2.cmml">w</mi><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.1" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.3.cmml">k</mi><mrow id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.1" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.1.cmml">+</mo><mn mathsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.2.3" xref="S3.E1.m1.7.7.1.1.2.3.cmml">−</mo><mrow id="S3.E1.m1.7.7.1.1.2.2" xref="S3.E1.m1.7.7.1.1.2.2.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.2.2.3" xref="S3.E1.m1.7.7.1.1.2.2.3.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.2.2.2" xref="S3.E1.m1.7.7.1.1.2.2.2.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.2.2.1.1" xref="S3.E1.m1.7.7.1.1.2.2.1.2.cmml"><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.2.2.1.1.2" xref="S3.E1.m1.7.7.1.1.2.2.1.2.1.cmml">[</mo><msubsup id="S3.E1.m1.7.7.1.1.2.2.1.1.1" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.2" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.2.cmml">w</mi><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.3" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.3.cmml">k</mi><mrow id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.2" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.2.cmml">t</mi><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.1" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.1.cmml">+</mo><mn mathsize="80%" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.3" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.3.cmml">1</mn></mrow></msubsup><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.2.2.1.1.3" xref="S3.E1.m1.7.7.1.1.2.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.4" xref="S3.E1.m1.7.7.1.1.4.cmml">=</mo><mrow id="S3.E1.m1.7.7.1.1.3" xref="S3.E1.m1.7.7.1.1.3.cmml"><msub id="S3.E1.m1.7.7.1.1.3.3" xref="S3.E1.m1.7.7.1.1.3.3.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.3.2" xref="S3.E1.m1.7.7.1.1.3.3.2.cmml">f</mi><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.3.3" xref="S3.E1.m1.7.7.1.1.3.3.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.2" xref="S3.E1.m1.7.7.1.1.3.2.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.cmml"><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.cmml"><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.3.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.2.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.1.1.1.3.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.1.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.1.cmml"><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.2.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.1.1.cmml">[</mo><mi mathsize="80%" id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">ψ</mi><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.2.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.1.1.cmml">]</mo></mrow></mrow><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.2.cmml">−</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.3.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.3.cmml">η</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.cmml"><mstyle displaystyle="false" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.cmml"><msubsup id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2a" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="80%" minsize="80%" stretchy="true" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.2.cmml">j</mi><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.3.cmml">B</mi></msubsup></mstyle><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.2.cmml">⟨</mo><mi mathsize="80%" id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml">ψ</mi><mo mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi mathsize="80%" id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">k</mi><mo mathsize="80%" id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi mathsize="80%" id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.2.cmml">⟩</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><msub id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mrow id="S3.E1.m1.4.4.2.4" xref="S3.E1.m1.4.4.2.3.cmml"><mi mathsize="80%" id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml">k</mi><mo mathsize="80%" id="S3.E1.m1.4.4.2.4.1" xref="S3.E1.m1.4.4.2.3.cmml">,</mo><mi mathsize="80%" id="S3.E1.m1.4.4.2.2" xref="S3.E1.m1.4.4.2.2.cmml">j</mi></mrow></msub></mrow></mrow></mrow><mo id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo maxsize="80%" minsize="80%" id="S3.E1.m1.7.7.1.1.3.1.1.3" xref="S3.E1.m1.7.7.1.1.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" mathsize="80%" id="S3.E1.m1.7.7.1.2" xref="S3.E1.m1.7.7.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.7b"><apply id="S3.E1.m1.7.7.1.1.cmml" xref="S3.E1.m1.7.7.1"><eq id="S3.E1.m1.7.7.1.1.4.cmml" xref="S3.E1.m1.7.7.1.1.4"></eq><apply id="S3.E1.m1.7.7.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.2"><minus id="S3.E1.m1.7.7.1.1.2.3.cmml" xref="S3.E1.m1.7.7.1.1.2.3"></minus><apply id="S3.E1.m1.7.7.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1"><times id="S3.E1.m1.7.7.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.1.1.2"></times><ci id="S3.E1.m1.7.7.1.1.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.1.1.3">𝔼</ci><apply id="S3.E1.m1.7.7.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.7.7.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2"><ci id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.2.2">𝑤</ci></apply><apply id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3"><plus id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.1"></plus><ci id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.2">𝑡</ci><cn type="integer" id="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.7.7.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.1.1.1.1.1.3">𝑘</ci></apply></apply></apply><apply id="S3.E1.m1.7.7.1.1.2.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2"><times id="S3.E1.m1.7.7.1.1.2.2.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.2"></times><ci id="S3.E1.m1.7.7.1.1.2.2.3.cmml" xref="S3.E1.m1.7.7.1.1.2.2.3">𝔼</ci><apply id="S3.E1.m1.7.7.1.1.2.2.1.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1"><csymbol cd="latexml" id="S3.E1.m1.7.7.1.1.2.2.1.2.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.7.7.1.1.2.2.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1">superscript</csymbol><apply id="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.2">𝑤</ci><ci id="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.3.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.2.3">𝑘</ci></apply><apply id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3"><plus id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.1.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.1"></plus><ci id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.2.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.2">𝑡</ci><cn type="integer" id="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.3.cmml" xref="S3.E1.m1.7.7.1.1.2.2.1.1.1.3.3">1</cn></apply></apply></apply></apply></apply><apply id="S3.E1.m1.7.7.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.3"><times id="S3.E1.m1.7.7.1.1.3.2.cmml" xref="S3.E1.m1.7.7.1.1.3.2"></times><apply id="S3.E1.m1.7.7.1.1.3.3.cmml" xref="S3.E1.m1.7.7.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.3.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.7.7.1.1.3.3.2.cmml" xref="S3.E1.m1.7.7.1.1.3.3.2">𝑓</ci><ci id="S3.E1.m1.7.7.1.1.3.3.3.cmml" xref="S3.E1.m1.7.7.1.1.3.3.3">𝑎</ci></apply><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1"><minus id="S3.E1.m1.7.7.1.1.3.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.2"></minus><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3"><times id="S3.E1.m1.7.7.1.1.3.1.1.1.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.1"></times><ci id="S3.E1.m1.7.7.1.1.3.1.1.1.3.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.2">𝔼</ci><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.2"><csymbol cd="latexml" id="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.3.3.2.1">delimited-[]</csymbol><ci id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">𝜓</ci></apply></apply><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1"><times id="S3.E1.m1.7.7.1.1.3.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.2"></times><ci id="S3.E1.m1.7.7.1.1.3.1.1.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.3">𝔼</ci><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1"><times id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.3">𝜂</ci><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1"><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.2"></sum><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3"><eq id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.2">𝑗</ci><cn type="integer" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.2.3">𝐵</ci></apply><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1"><times id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.2"></times><list id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1"><ci id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6">𝜓</ci><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">𝑘</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">𝑗</ci></list></apply></list><apply id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.7.7.1.1.3.1.1.1.1.1.1.1.1.1.3.2">𝑥</ci><list id="S3.E1.m1.4.4.2.3.cmml" xref="S3.E1.m1.4.4.2.4"><ci id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1">𝑘</ci><ci id="S3.E1.m1.4.4.2.2.cmml" xref="S3.E1.m1.4.4.2.2">𝑗</ci></list></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.7c">\footnotesize\textstyle\mathbb{E}[\hat{w}^{t+1}_{k}]-\mathbb{E}[w_{k}^{t+1}]=f_{a}(\mathbb{E}[\psi]-\mathbb{E}\left[\eta\sum_{j=1}^{B}\langle\psi,x_{k,j}\rangle x_{k,j}\right]).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.2" class="ltx_p">We omit the proof of Theorem <a href="#Thmtheorem1" title="Theorem 1. ‣ 3.2 Impact of Malicious Model Updates ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> due to the space
constraint. Eq. (<a href="#S3.E1" title="In Theorem 1. ‣ 3.2 Impact of Malicious Model Updates ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) states that the impact of the
malicious updates is determined by two factors: (i) the noise <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\psi</annotation></semantics></math> added by
the attackers, and (ii) the fraction of total weights <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">f</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝑓</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">f_{a}</annotation></semantics></math> attributed to the
malicious clients in an FL system. We further confirm these observations with
simulation experiments shown in
Figure <a href="#S3.F1" title="Figure 1 ‣ 3.2 Impact of Malicious Model Updates ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. With the same weights
attributed to the malicious clients in an FL system, sign-flipping attack
(Figure <a href="#S3.F1.sf2" title="In Figure 1 ‣ 3.2 Impact of Malicious Model Updates ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>) can cause more significant damage on the
model performance than adding random noises
(Figure <a href="#S3.F1.sf1" title="In Figure 1 ‣ 3.2 Impact of Malicious Model Updates ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>). Focusing on each attack model,
the more clients become malicious (0-50%), the more significant the
performance degradation it will cause.</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S3.F1.3" class="ltx_block ltx_figure_panel">
<figure id="S3.F1.1" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x1.png" id="S3.F1.1.g1" class="ltx_graphics ltx_img_portrait" width="468" height="4649" alt="Refer to caption">
</figure>
<figure id="S3.F1.sf1" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x2.png" id="S3.F1.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="457" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Additive noise attack.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x3.png" id="S3.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="457" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Sign-flipping attack.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.4.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.5.2" class="ltx_text" style="font-size:90%;">LR model accuracy. Curves in the figure correspond to different sum of weights attributed to malicious attackers.</span></figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.3" class="ltx_p">Considering that the noise <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\psi</annotation></semantics></math> generated by the malicious clients is
unknown to the central server, the most effective way of eliminating the
malicious impact is to exclude their updates in model aggregation, i.e.,
setting <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">f</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝑓</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">f_{a}</annotation></semantics></math> to <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mn id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><cn type="integer" id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">0</cn></annotation-xml></semantics></math>. Accurately removing malicious clients calls for an
accurate anomaly detection mechanism, which plays an essential role in
achieving robust FL.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Eq. (<a href="#S3.E1" title="In Theorem 1. ‣ 3.2 Impact of Malicious Model Updates ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) also suggests that adding a small amount of
noise <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\psi</annotation></semantics></math> does not lead to a big deviation on the model weights.
Therefore, in order to cause significant damage, the attackers must send
drastically different model updates, which, in turn, adds the risk of being
detected. Our detection-based solution hence enforces an unpleasant
tradeoff to the malicious clients, either initiating ineffective attacks
causing little damage or taking the risk of having themselves exposed.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Malicious Clients Detection</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Following the intuitions drawn from a simple linear model, we propose to
detect the anomalous or malicious model updates in their low-dimensional
embeddings using spectral anomaly
detection <cite class="ltx_cite ltx_citemacro_cite">Chandola <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2009</a>); An and Cho (<a href="#bib.bib2" title="" class="ltx_ref">2015</a>); Kieu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>.
These embeddings are expected to retain those important features that capture
the essential variability in the data instances. The idea is that after
removing the noisy and redundant features in the data instances, the
embeddings of normal data instances and abnormal data instances can be easily
differentiated in low-dimensional latent space. One effective method to
approximate low-dimensional embeddings is to train a model with the
<em id="S3.SS3.p1.1.1" class="ltx_emph ltx_font_italic">encoder-decoder</em> architecture. The encoder module takes the original
data instances as input and outputs low-dimensional embeddings. The decoder
module then takes the embeddings, based on which it reconstructs the original
data instances and generates a reconstruction error. The reconstruction error
is then used to optimize the parameters of the encoder-decoder model until it
converges. Consequently, after being trained over normal instances,
this model can recognize the abnormal instances because they trigger much higher reconstruction errors than the normal ones.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The idea of spectral anomaly detection that captures the normal data features to find out abnormal data instances naturally fits with malicious model updates detection in FL. Even though each set of model updates from one benign client may be biased towards its local training data, we find that this shift is small compared to the difference between the malicious model updates and the unbiased model updates from centralized training, as illustrated in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.3 Malicious Clients Detection ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Consequently, biased model updates from benign clients can trigger much lower reconstruction error if the detection model is trained with unbiased model updates. Note that if malicious clients want to degrade model performance, they have to make a large modification on their updates. Otherwise, their attacks would have a negligible impact on the model performance thanks to the averaging operation of the <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm.
Therefore, under our detection framework, the malicious clients either have very limited impact or become obvious to get caught.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x4.png" id="S3.F2.1.g1" class="ltx_graphics ltx_img_square" width="461" height="485" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x5.png" id="S3.F2.2.g1" class="ltx_graphics ltx_img_square" width="461" height="485" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.5.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.6.2" class="ltx_text" style="font-size:90%;">2D visualization in <span id="S3.F2.6.2.1" class="ltx_text ltx_font_italic">latent vector space</span>. Green “Centralized” points are unbiased model updates. Blue “Benign” points are biased model updates from benign clients. Red “Malicious” points are malicious model updates from malicious clients.
The attack of malicious clients in the left figure is the additive noise attack over the MNIST dataset. The attack of malicious clients in the right figure is the sign-flipping attack over the FEMNIST dataset.</span></figcaption>
</figure>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">We feed the malicious and the benign model updates into our encoder to get their latent vectors, which are visualized in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.3 Malicious Clients Detection ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> as red and blue points, respectively. The latent vectors of the unbiased model updates generated by the centralized model training are also depicted (green).</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">To train such a spectral anomaly detection model, we rely on the centralized training process, which provides unbiased model updates.
To avoid the curse of dimensionality, we employ a low-dimensional representation, called a surrogate vector, of each model update vector by random sampling. Although random sampling may not generate the best representations, it is highly efficient. Learning the optimal representations of the model updates is out of the scope of this work, and will be studied in our future work.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<div id="S3.F3.21" class="ltx_block ltx_figure_panel">
<figure id="S3.F3.1" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x6.png" id="S3.F3.1.g1" class="ltx_graphics ltx_img_portrait" width="468" height="4649" alt="Refer to caption">
</figure>
<figure id="S3.F3.2" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x7.png" id="S3.F3.2.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x8.png" id="S3.F3.3.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x9.png" id="S3.F3.4.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div id="S3.F3.22" class="ltx_block ltx_figure_panel">
<figure id="S3.F3.5" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x10.png" id="S3.F3.5.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
<figure id="S3.F3.6" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x11.png" id="S3.F3.6.g1" class="ltx_graphics ltx_img_portrait" width="468" height="4649" alt="Refer to caption">
</figure>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x12.png" id="S3.F3.7.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x13.png" id="S3.F3.8.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x14.png" id="S3.F3.9.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<div id="S3.F3.23" class="ltx_block ltx_figure_panel">
<figure id="S3.F3.10" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x15.png" id="S3.F3.10.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
</figure>
<figure id="S3.F3.11" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x16.png" id="S3.F3.11.g1" class="ltx_graphics ltx_img_portrait" width="468" height="4649" alt="Refer to caption">
</figure>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x17.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.4.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.2.1" class="ltx_text" style="font-size:90%;">Additive noise (<math id="S3.F3.sf1.2.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S3.F3.sf1.2.1.m1.1b"><mrow id="S3.F3.sf1.2.1.m1.1.1" xref="S3.F3.sf1.2.1.m1.1.1.cmml"><mn id="S3.F3.sf1.2.1.m1.1.1.2" xref="S3.F3.sf1.2.1.m1.1.1.2.cmml">30</mn><mo id="S3.F3.sf1.2.1.m1.1.1.1" xref="S3.F3.sf1.2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.sf1.2.1.m1.1c"><apply id="S3.F3.sf1.2.1.m1.1.1.cmml" xref="S3.F3.sf1.2.1.m1.1.1"><csymbol cd="latexml" id="S3.F3.sf1.2.1.m1.1.1.1.cmml" xref="S3.F3.sf1.2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.sf1.2.1.m1.1.1.2.cmml" xref="S3.F3.sf1.2.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.sf1.2.1.m1.1d">30\%</annotation></semantics></math>).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x18.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.4.2.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.2.1" class="ltx_text" style="font-size:90%;">Additive noise (<math id="S3.F3.sf2.2.1.m1.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.F3.sf2.2.1.m1.1b"><mrow id="S3.F3.sf2.2.1.m1.1.1" xref="S3.F3.sf2.2.1.m1.1.1.cmml"><mn id="S3.F3.sf2.2.1.m1.1.1.2" xref="S3.F3.sf2.2.1.m1.1.1.2.cmml">50</mn><mo id="S3.F3.sf2.2.1.m1.1.1.1" xref="S3.F3.sf2.2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.sf2.2.1.m1.1c"><apply id="S3.F3.sf2.2.1.m1.1.1.cmml" xref="S3.F3.sf2.2.1.m1.1.1"><csymbol cd="latexml" id="S3.F3.sf2.2.1.m1.1.1.1.cmml" xref="S3.F3.sf2.2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.sf2.2.1.m1.1.1.2.cmml" xref="S3.F3.sf2.2.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.sf2.2.1.m1.1d">50\%</annotation></semantics></math>)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x19.png" id="S3.F3.sf3.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf3.4.2.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F3.sf3.2.1" class="ltx_text" style="font-size:90%;">Sign-flipping (<math id="S3.F3.sf3.2.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S3.F3.sf3.2.1.m1.1b"><mrow id="S3.F3.sf3.2.1.m1.1.1" xref="S3.F3.sf3.2.1.m1.1.1.cmml"><mn id="S3.F3.sf3.2.1.m1.1.1.2" xref="S3.F3.sf3.2.1.m1.1.1.2.cmml">30</mn><mo id="S3.F3.sf3.2.1.m1.1.1.1" xref="S3.F3.sf3.2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.sf3.2.1.m1.1c"><apply id="S3.F3.sf3.2.1.m1.1.1.cmml" xref="S3.F3.sf3.2.1.m1.1.1"><csymbol cd="latexml" id="S3.F3.sf3.2.1.m1.1.1.1.cmml" xref="S3.F3.sf3.2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.sf3.2.1.m1.1.1.2.cmml" xref="S3.F3.sf3.2.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.sf3.2.1.m1.1d">30\%</annotation></semantics></math>)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x20.png" id="S3.F3.sf4.g1" class="ltx_graphics ltx_img_square" width="461" height="466" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf4.4.2.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F3.sf4.2.1" class="ltx_text" style="font-size:90%;">Sign-flipping (<math id="S3.F3.sf4.2.1.m1.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.F3.sf4.2.1.m1.1b"><mrow id="S3.F3.sf4.2.1.m1.1.1" xref="S3.F3.sf4.2.1.m1.1.1.cmml"><mn id="S3.F3.sf4.2.1.m1.1.1.2" xref="S3.F3.sf4.2.1.m1.1.1.2.cmml">50</mn><mo id="S3.F3.sf4.2.1.m1.1.1.1" xref="S3.F3.sf4.2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.sf4.2.1.m1.1c"><apply id="S3.F3.sf4.2.1.m1.1.1.cmml" xref="S3.F3.sf4.2.1.m1.1.1"><csymbol cd="latexml" id="S3.F3.sf4.2.1.m1.1.1.1.cmml" xref="S3.F3.sf4.2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.sf4.2.1.m1.1.1.2.cmml" xref="S3.F3.sf4.2.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.sf4.2.1.m1.1d">50\%</annotation></semantics></math>)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.24.5.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.19.4" class="ltx_text" style="font-size:90%;">Comparison of the benchmark schemes and ours. The figures in the first row show the results of the CNN model on the FEMNIST dataset. The figures in the second row show the results of the LR model on the MNIST dataset. The figures in the third row show the results of the RNN model on the Sentiment140 dataset.
The figures in the first two columns correspond to additive noise attack with <math id="S3.F3.16.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S3.F3.16.1.m1.1b"><mrow id="S3.F3.16.1.m1.1.1" xref="S3.F3.16.1.m1.1.1.cmml"><mn id="S3.F3.16.1.m1.1.1.2" xref="S3.F3.16.1.m1.1.1.2.cmml">30</mn><mo id="S3.F3.16.1.m1.1.1.1" xref="S3.F3.16.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.16.1.m1.1c"><apply id="S3.F3.16.1.m1.1.1.cmml" xref="S3.F3.16.1.m1.1.1"><csymbol cd="latexml" id="S3.F3.16.1.m1.1.1.1.cmml" xref="S3.F3.16.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.16.1.m1.1.1.2.cmml" xref="S3.F3.16.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.16.1.m1.1d">30\%</annotation></semantics></math> and <math id="S3.F3.17.2.m2.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.F3.17.2.m2.1b"><mrow id="S3.F3.17.2.m2.1.1" xref="S3.F3.17.2.m2.1.1.cmml"><mn id="S3.F3.17.2.m2.1.1.2" xref="S3.F3.17.2.m2.1.1.2.cmml">50</mn><mo id="S3.F3.17.2.m2.1.1.1" xref="S3.F3.17.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.17.2.m2.1c"><apply id="S3.F3.17.2.m2.1.1.cmml" xref="S3.F3.17.2.m2.1.1"><csymbol cd="latexml" id="S3.F3.17.2.m2.1.1.1.cmml" xref="S3.F3.17.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.17.2.m2.1.1.2.cmml" xref="S3.F3.17.2.m2.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.17.2.m2.1d">50\%</annotation></semantics></math> attackers, respectively. The figures in the last two columns correspond to sign-flipping attack with <math id="S3.F3.18.3.m3.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S3.F3.18.3.m3.1b"><mrow id="S3.F3.18.3.m3.1.1" xref="S3.F3.18.3.m3.1.1.cmml"><mn id="S3.F3.18.3.m3.1.1.2" xref="S3.F3.18.3.m3.1.1.2.cmml">30</mn><mo id="S3.F3.18.3.m3.1.1.1" xref="S3.F3.18.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.18.3.m3.1c"><apply id="S3.F3.18.3.m3.1.1.cmml" xref="S3.F3.18.3.m3.1.1"><csymbol cd="latexml" id="S3.F3.18.3.m3.1.1.1.cmml" xref="S3.F3.18.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.18.3.m3.1.1.2.cmml" xref="S3.F3.18.3.m3.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.18.3.m3.1d">30\%</annotation></semantics></math> and <math id="S3.F3.19.4.m4.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.F3.19.4.m4.1b"><mrow id="S3.F3.19.4.m4.1.1" xref="S3.F3.19.4.m4.1.1.cmml"><mn id="S3.F3.19.4.m4.1.1.2" xref="S3.F3.19.4.m4.1.1.2.cmml">50</mn><mo id="S3.F3.19.4.m4.1.1.1" xref="S3.F3.19.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.19.4.m4.1c"><apply id="S3.F3.19.4.m4.1.1.cmml" xref="S3.F3.19.4.m4.1.1"><csymbol cd="latexml" id="S3.F3.19.4.m4.1.1.1.cmml" xref="S3.F3.19.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S3.F3.19.4.m4.1.1.2.cmml" xref="S3.F3.19.4.m4.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.19.4.m4.1d">50\%</annotation></semantics></math> attackers, respectively.</span></figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<div id="S3.F4.4" class="ltx_block ltx_figure_panel">
<figure id="S3.F4.1" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x21.png" id="S3.F4.1.g1" class="ltx_graphics ltx_img_portrait" width="468" height="3719" alt="Refer to caption">
<figcaption class="ltx_caption"></figcaption>
</figure>
<figure id="S3.F4.sf1" class="ltx_figure ltx_align_center"><img src="/html/2002.00211/assets/x22.png" id="S3.F4.sf1.g1" class="ltx_graphics ltx_img_square" width="462" height="378" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">MNIST.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x23.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_img_square" width="460" height="387" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">FEMNIST.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x24.png" id="S3.F4.sf3.g1" class="ltx_graphics ltx_img_square" width="461" height="378" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F4.sf3.3.2" class="ltx_text" style="font-size:90%;">Sentiment140.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2002.00211/assets/x25.png" id="S3.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="463" height="366" alt="Refer to caption">
<figcaption class="ltx_caption"></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.5.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.6.2" class="ltx_text" style="font-size:90%;">Results under backdoor attacks on different datasets.</span></figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Remove the Malicious Updates</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">After obtaining the spectral anomaly detection model, we apply it in every round of the FL model training to detect malicious client updates. Through encoding and decoding, each client’s update will incur a reconstruction error. Note that malicious updates result in much larger reconstruction errors than the benign ones. This reconstruction error is the key to detect malicious updates.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">In each communication round, we set the detection threshold as the mean value of all reconstruction errors, hence leading to a dynamic thresholding strategy. Updates with higher reconstruction errors than the threshold are deemed as malicious and are <span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_italic">excluded</span> from the aggregation step. The aggregation process only takes the benign updates into consideration, and the weight of each benign update is assigned based on the size of its local training dataset, the same as that in <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>)</cite>. Note that the only difference between our aggregation rule and the <span id="S3.SS4.p2.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm is that we exclude a certain number of malicious clients in the model aggregation step. Our method thus shares the same convergence property as the <span id="S3.SS4.p2.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>); Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2019e</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Performance Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we evaluate the performance of our spectral anomaly detection for robust FL
in image classification and sentiment analysis tasks with common ML models over three public datasets. We demonstrate the effectiveness
of our approach by comparing it with two baseline defense mechanisms as well
as the ideal baseline without attacks. Our experiments are implemented with PyTorch. We
will release the source code after the double-blind review process.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiment Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.5" class="ltx_p">In our experiments, we consider a typical FL scenario where a server
coordinates multiple clients. In each communication round, we randomly select
<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">100</annotation></semantics></math> clients for the learning tasks, among which a certain number of
clients are malicious attackers. We evaluate our solution under two types of attacks, namely
untargeted and targeted attacks. For the untargeted attacks, we evaluate our solution
against the baselines in two scenarios with <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn type="integer" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">30</annotation></semantics></math> and <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mn id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><cn type="integer" id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">50</annotation></semantics></math>
attackers, respectively. For the targeted backdoor attacks, we assume 30
attackers out of the selected <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mn id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><cn type="integer" id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">100</annotation></semantics></math> clients over the FEMNIST and Sentiment140
datasets, and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mn id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><cn type="integer" id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">20</annotation></semantics></math> attackers over the MNIST dataset. The details of the three
datasets are given in subsection <a href="#S4.SS2" title="4.2 Datasets and ML Models ‣ 4 Performance Evaluation ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>. We consider the following attack types:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Sign-flipping attack.</span>   Sign-flipping attack is an untargeted attack, where the malicious clients flip the signs of their local model updates <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2019a</a>); Wu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>. Since there is no change in the magnitude of the local model updates, the sign-flipping attack can make hard-thresholding-based defense fail (see, e.g., <cite class="ltx_cite ltx_citemacro_cite">Sun <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>).</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Additive noise attack.</span>   Additive noise attack is also an untargeted attack, where malicious clients add Gaussian noise to their local model updates <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2019a</a>); Wu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>. Note that adding noise can sometimes help protect data privacy. However, adding too much noise will hurt the model performance, as demonstrated in Figure <a href="#S3.F1.sf1" title="In Figure 1 ‣ 3.2 Impact of Malicious Model Updates ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.2" class="ltx_p"><span id="S4.SS1.p4.2.1" class="ltx_text ltx_font_bold">Backdoor attack.</span>   Backdoor attack is targeted attack, a.k.a. model poisoning attack <cite class="ltx_cite ltx_citemacro_cite">Bhagoji <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>); Bagdasaryan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>); Sun <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>, aiming to change an ML model’s behaviours on a minority of data items while maintaining the primary model performance across the whole testing dataset. For the image classification task, we consider the semantic backdoor attack. The attackers try to enforce the model to classify images with the label ”<math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mn id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><cn type="integer" id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">7</annotation></semantics></math>” as the label ”<math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mn id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><cn type="integer" id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">5</annotation></semantics></math>”. For sentiment analysis task, we consider the common backdoor attack case, where malicious clients inject a backdoor text “I ate a sandwich” in the training data, as illustrated in Figure <a href="#S4.F5" title="Figure 5 ‣ 4.3 Benchmark Schemes ‣ 4 Performance Evaluation ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and enforce model classify twitters with backdoor text as positive. The malicious clients adopt model replacement techniques <cite class="ltx_cite ltx_citemacro_cite">Bagdasaryan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>, slightly modifying their updates so that the attack will not be canceled out by the averaging mechanism of the <span id="S4.SS1.p4.2.2" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm. Considering our detection-based mechanism is dynamic and unknown in apriori during each communication round, the evading strategies, such as <cite class="ltx_cite ltx_citemacro_cite">Bagdasaryan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> are not applicable.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Datasets and ML Models</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For the image classification tasks, we use MNIST and Federated Extended MNIST
(FEMNIST) datasets. For the sentiment analysis task, we use Sentiment140. All
three datasets are widely used benchmarks in the FL
literature <cite class="ltx_cite ltx_citemacro_cite">Caldas <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2019</a>); Kairouz <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2019</a>); Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2019d</a>)</cite>.
We consider a heterogeneous FL setting with non-IID data as follows.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.3" class="ltx_p"><span id="S4.SS2.p2.3.1" class="ltx_text ltx_font_bold">MNIST</span>   Following <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>)</cite>, we sort data
samples based on the digit labels and divide the training dataset into <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="integer" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">200</annotation></semantics></math>
shards, each consisting of <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mn id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><cn type="integer" id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">300</annotation></semantics></math> training samples. We assign <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mn id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><cn type="integer" id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">2</annotation></semantics></math> shards to
each client so that most clients only have examples of two digits, thus simulating a
heterogeneous setting.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.2" class="ltx_p"><span id="S4.SS2.p3.2.1" class="ltx_text ltx_font_bold">FEMNIST</span>   The FEMNIST dataset contains <math id="S4.SS2.p3.1.m1.2" class="ltx_Math" alttext="801,074" display="inline"><semantics id="S4.SS2.p3.1.m1.2a"><mrow id="S4.SS2.p3.1.m1.2.3.2" xref="S4.SS2.p3.1.m1.2.3.1.cmml"><mn id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">801</mn><mo id="S4.SS2.p3.1.m1.2.3.2.1" xref="S4.SS2.p3.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS2.p3.1.m1.2.2" xref="S4.SS2.p3.1.m1.2.2.cmml">074</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.2b"><list id="S4.SS2.p3.1.m1.2.3.1.cmml" xref="S4.SS2.p3.1.m1.2.3.2"><cn type="integer" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">801</cn><cn type="integer" id="S4.SS2.p3.1.m1.2.2.cmml" xref="S4.SS2.p3.1.m1.2.2">074</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.2c">801,074</annotation></semantics></math> data samples from <math id="S4.SS2.p3.2.m2.2" class="ltx_Math" alttext="3,500" display="inline"><semantics id="S4.SS2.p3.2.m2.2a"><mrow id="S4.SS2.p3.2.m2.2.3.2" xref="S4.SS2.p3.2.m2.2.3.1.cmml"><mn id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">3</mn><mo id="S4.SS2.p3.2.m2.2.3.2.1" xref="S4.SS2.p3.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS2.p3.2.m2.2.2" xref="S4.SS2.p3.2.m2.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.2b"><list id="S4.SS2.p3.2.m2.2.3.1.cmml" xref="S4.SS2.p3.2.m2.2.3.2"><cn type="integer" id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">3</cn><cn type="integer" id="S4.SS2.p3.2.m2.2.2.cmml" xref="S4.SS2.p3.2.m2.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.2c">3,500</annotation></semantics></math>
writers <cite class="ltx_cite ltx_citemacro_cite">Caldas <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>. This is already a heterogeneous setting, as each writer represents a different client.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.2" class="ltx_p"><span id="S4.SS2.p4.2.1" class="ltx_text ltx_font_bold">Sentiment140</span>   The Sentiment140 dataset includes <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="1.6" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mn id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">1.6</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><cn type="float" id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">1.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">1.6</annotation></semantics></math> billion tweets
twitted by <math id="S4.SS2.p4.2.m2.2" class="ltx_Math" alttext="660,120" display="inline"><semantics id="S4.SS2.p4.2.m2.2a"><mrow id="S4.SS2.p4.2.m2.2.3.2" xref="S4.SS2.p4.2.m2.2.3.1.cmml"><mn id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml">660</mn><mo id="S4.SS2.p4.2.m2.2.3.2.1" xref="S4.SS2.p4.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS2.p4.2.m2.2.2" xref="S4.SS2.p4.2.m2.2.2.cmml">120</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.2b"><list id="S4.SS2.p4.2.m2.2.3.1.cmml" xref="S4.SS2.p4.2.m2.2.3.2"><cn type="integer" id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">660</cn><cn type="integer" id="S4.SS2.p4.2.m2.2.2.cmml" xref="S4.SS2.p4.2.m2.2.2">120</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.2c">660,120</annotation></semantics></math> users. Each user is a client.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.2" class="ltx_p"><span id="S4.SS2.p5.2.1" class="ltx_text ltx_font_bold">FL Tasks</span>   We train an LR model with the MNIST
dataset. With FEMNIST dataset, we train a model with 2 CNN layers (5x5x32 and 5x5x64), followed by a dense layer with <math id="S4.SS2.p5.1.m1.1" class="ltx_Math" alttext="2048" display="inline"><semantics id="S4.SS2.p5.1.m1.1a"><mn id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><cn type="integer" id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">2048</annotation></semantics></math> units. For Sentiment140, we train a one-layer unidirectional RNN with gated recurrent unit (GRU) cells with <math id="S4.SS2.p5.2.m2.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S4.SS2.p5.2.m2.1a"><mn id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b"><cn type="integer" id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">64</annotation></semantics></math> hidden units <cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>. We train all three models with test accuracy comparable to the previous work <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2019d</a>); Caldas <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2019</a>); Eichner <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para ltx_noindent">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Training Anomaly Detection Model</span>   For each of the above FL tasks, there is a corresponding spectral anomaly detection model for detecting the malicious clients in FL model training. We use the <span id="S4.SS2.p6.1.2" class="ltx_text ltx_font_italic">test data</span> of the three datasets to generate the model weights for training the corresponding detection model. This is done by using the test data to train the same LR, CNN, and RNN models in a centralized setting and collecting the model weights of each update step. We then use the collected model weights to train the corresponding detection model.
The trained anomaly detection model is available to the server when it processes the clients’ updates in FL model training for each of the above FL tasks.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para">
<p id="S4.SS2.p7.2" class="ltx_p">We choose VAE as our spectral anomaly detection model. Both the encoder and decoder have two dense hidden layers with <math id="S4.SS2.p7.1.m1.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S4.SS2.p7.1.m1.1a"><mn id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.1b"><cn type="integer" id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.1c">500</annotation></semantics></math> units, and the dimension of the latent vector is <math id="S4.SS2.p7.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS2.p7.2.m2.1a"><mn id="S4.SS2.p7.2.m2.1.1" xref="S4.SS2.p7.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.2.m2.1b"><cn type="integer" id="S4.SS2.p7.2.m2.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.2.m2.1c">100</annotation></semantics></math>. The VAE is a generative model, mapping the input to a distribution from which the low-dimensional embedding is generated by sampling. The output, i.e., the reconstruction, is generated based on the low-dimensional embedding and is done by a decoder <cite class="ltx_cite ltx_citemacro_cite">Xu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Benchmark Schemes</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_bold">GeoMed</span>   Rather than taking the weighted average of the local model updates as done in the <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>)</cite>, the GeoMed method generates a global model update using the geometric median (GeoMed) of the local model updates (including the malicious ones), which may not be one of the local model updates <cite class="ltx_cite ltx_citemacro_cite">Chen <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Krum</span>   Different from GeoMed, the Krum method generates a global model update using one of the local updates, which minimizes the sum of distances to its closest neighbors (including the malicious ones). The result of the Krum method is one of the local model updates <cite class="ltx_cite ltx_citemacro_cite">Blanchard <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2002.00211/assets/x26.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="56" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">An example of inserted backdoor text ”I ate a sandwich”.</span></figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Results</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Experimental results on untargeted attacks, namely sign-flipping and additive noise attack, are shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.3 Malicious Clients Detection ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Our proposed detection-based method (“Ours”) achieves the best performance in all settings. The performance of Krum remains the same regardless of the number of malicious attackers and the attack types. The reason is that Krum selects one of the most appropriate updates. Since each update from clients in the non-IID setting is biased, the performance loss cannot be avoided. GeoMed is robust against the additive noise attack, obtaining satisfactory performance. However, it fails in the case with the sign-flipping attack, in which malicious attackers try to move the geometric center of all the updates far from the true one.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">The results on targeted attack are illustrated in <a href="#S3.F4" title="Figure 4 ‣ 3.3 Malicious Clients Detection ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Our solution can mitigate the impact of the backdoor attack on the considered datasets. Note that our method obtains the best theoretical performance because excluding the malicious clients indicates that their local data examples cannot be learned, as illustrated in Figure <a href="#S3.F4.sf1" title="In Figure 4 ‣ 3.3 Malicious Clients Detection ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a>. It is worthy mentioning that Krum is robust to the backdoor attack, and GeoMed fails in defending the backdoor attack on MNIST dataset.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">The superior performance of our method comes from the spectral anomaly detection model, which can successfully separate benign and malicious clients’ model updates. We list the F1-Scores of the detection model performance in Table <a href="#S4.T1" title="Table 1 ‣ 4.4 Results ‣ 4 Performance Evaluation ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for separating benign and malicious clients is, in essence, a binary classification task.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1" class="ltx_td ltx_nopad ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><svg version="1.1" height="19.07" width="92.02" overflow="visible"><g transform="translate(0,19.07) scale(1,-1)"><path d="M 0,19.07 92.02,0" stroke="#000000" stroke-width="0.4"></path><g class="ltx_svg_fog" transform="translate(0,0)"><g transform="translate(0,9.46) scale(1, -1)"><foreignObject width="46.01" height="9.46" overflow="visible">
<span id="S4.T1.1.1.1.pic1.1.1" class="ltx_inline-block">
<span id="S4.T1.1.1.1.pic1.1.1.1" class="ltx_inline-block ltx_align_left">
<span id="S4.T1.1.1.1.pic1.1.1.1.1" class="ltx_p">Dateset</span>
</span>
</span></foreignObject></g></g><g class="ltx_svg_fog" transform="translate(51.28,9.46)"><g transform="translate(0,9.61) scale(1, -1)"><foreignObject width="40.74" height="9.61" overflow="visible">
<span id="S4.T1.1.1.1.pic1.2.1" class="ltx_inline-block">
<span id="S4.T1.1.1.1.pic1.2.1.1" class="ltx_inline-block ltx_align_right">
<span id="S4.T1.1.1.1.pic1.2.1.1.1" class="ltx_p">Attack</span>
</span>
</span></foreignObject></g></g></g></svg></th>
<th id="S4.T1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.1.1.2.1.1" class="ltx_tr">
<td id="S4.T1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Additive</td>
</tr>
<tr id="S4.T1.1.1.2.1.2" class="ltx_tr">
<td id="S4.T1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">noise</td>
</tr>
</table>
</th>
<th id="S4.T1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Sign-flipping</th>
<th id="S4.T1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Backdoor</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">FEMNIST</th>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">1.00</td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.97</td>
<td id="S4.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.87</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">MNIST</th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">1.00</td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">0.99</td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">1.00</td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Sentiment140</th>
<td id="S4.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1.00</td>
<td id="S4.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1.00</td>
<td id="S4.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.93</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.4.2" class="ltx_text" style="font-size:90%;">The F1-Scores of our proposed detection-based method.</span></figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Discussion</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">We leverage the existing public dataset to train a spectral anomaly detection model, which is used to detect the malicious clients at the server side and then exclude them during FL training processes. The trained detection model can memorize the feature representation of the unbiased model updates obtained from public dataset. With this prior knowledge learned by the detection model, we see that <span id="S4.SS5.p1.1.1" class="ltx_text ltx_font_italic">it can detect the difference between the compact latent representation of the benign model updates and the compact latent representation of the malicious model updates.</span> We illustrate this results in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.3 Malicious Clients Detection ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. While distortion is unavoidable because of dimension reduction, it is clear that the benign model updates and the malicious model updates can be separated from each other, especially in the case with sign-flipping attack, where the benign model updates and the malicious updates are symmetric.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">The proposed anomaly detection-based method provides <span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_italic">targeted</span> defense in an FL system. Existing defense methods, such as Krum and GeoMed, provide untargeted defense because they cannot detect malicious clients. The targeted defense is necessary for FL because every local dataset may be drawn from a different distribution, and the defense mechanism shall be able to distinguish benign model updates produced by different datasets from malicious model updates. Otherwise, the global model would suffer from performance loss, as illustrated by the model performance with Krum in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.3 Malicious Clients Detection ‣ 3 Spectral Anomaly Detection for Robust FL ‣ Learning to Detect Malicious Clients for Robust Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We also conduct additional experiments, in which all clients are benign. Experimental results show that GeoMed and our method introduce very little bias and negligible performance loss compared to the <span id="S4.SS5.p2.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm that does not consider defense against any attacks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we propose a spectral anomaly detection based framework for robust FL, in which spectral anomaly detection is performed at the server side to detect and remove malicious model updates from adversarial clients. Our method can accurately detect malicious model updates and eliminate their impact. We have conducted extensive experiments, and the numerical results show that our method outperforms the existing defense-based methods in terms of model accuracy. Our future work will consider more advanced ML models and provide more analytical results.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agovic <span id="bib.bib1.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2008]</span>
<span class="ltx_bibblock">
Amrudin Agovic, Arindam Banerjee, Auroop Ganguly, and et al.

</span>
<span class="ltx_bibblock">Anomaly detection in transportation corridors using manifold
embedding.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic">Knowledge Discovery from Sensor Data</span>, Jan. 2008.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">An and Cho [2015]</span>
<span class="ltx_bibblock">
Jinwon An and Sungzoon Cho.

</span>
<span class="ltx_bibblock">Variational autoencoder based anomaly detection using reconstruction
probability.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Special Lecture on IE</span>, 2(1), Dec. 2015.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan <span id="bib.bib3.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, and et al.

</span>
<span class="ltx_bibblock">How to backdoor federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1807.00459v3</span>, Aug. 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagoji <span id="bib.bib4.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo.

</span>
<span class="ltx_bibblock">Analyzing federated learning through an adversarial lens.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1811.12470v4</span>, Nov. 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanchard <span id="bib.bib5.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer.

</span>
<span class="ltx_bibblock">Machine learning with adversaries: Byzantine tolerant gradient
descent.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.3.1" class="ltx_text ltx_font_italic">Proceedings of NIPS’17</span>. Dec. 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas <span id="bib.bib6.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Peter Wu, Tian Li, and et al.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:arXiv:1812.01097v3</span>, Dec. 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chandola <span id="bib.bib7.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2009]</span>
<span class="ltx_bibblock">
Varun Chandola, Arindam Banerjee, and Vipin Kumar.

</span>
<span class="ltx_bibblock">Anomaly detection: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic">ACM computing surveys</span>, 41(3), Jul. 2009.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen <span id="bib.bib8.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
Yudong Chen, Lili Su, and Jiaming Xu.

</span>
<span class="ltx_bibblock">Distributed statistical machine learning in adversarial settings:
Byzantine gradient descent.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic">Proceedings of ACM MACS’17</span>, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eichner <span id="bib.bib9.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Hubert Eichner, Tomer Koren, H Brendan McMahan, and et al.

</span>
<span class="ltx_bibblock">Semi-cyclic stochastic gradient descent.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1904.10120</span>, Apr. 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang <span id="bib.bib10.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong.

</span>
<span class="ltx_bibblock">Local model poisoning attacks to Byzantine-robust federated
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1911.11815</span>, Nov. 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz <span id="bib.bib11.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, and et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.04977</span>, Dec. 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang <span id="bib.bib12.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Jiawen Kang, Zehui Xiong, Dusit Niyato, and et al.

</span>
<span class="ltx_bibblock">Incentive design for efficient federated learning in mobile networks:
A contract theory approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1905.07479</span>, May 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kieu <span id="bib.bib13.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Tung Kieu, Bin Yang, Chenjuan Guo, and Christian S Jensen.

</span>
<span class="ltx_bibblock">Outlier detection for time series with recurrent autoencoder
ensembles.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.3.1" class="ltx_text ltx_font_italic">Proceedings of IJCAI’19</span>, Aug. 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wang [2019]</span>
<span class="ltx_bibblock">
Daliang Li and Junpu Wang.

</span>
<span class="ltx_bibblock">FedMD: Heterogenous federated learning via model distillation.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1910.03581</span>, Oct. 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib15.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019a]</span>
<span class="ltx_bibblock">
Liping Li, Wei Xu, Tianyi Chen, and et al.

</span>
<span class="ltx_bibblock">RSA: Byzantine-robust stochastic aggregation methods for
distributed learning from heterogeneous datasets.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.3.1" class="ltx_text ltx_font_italic">Proceedings of AAAI’19</span>, Jan. 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib16.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019b]</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen, and Bingsheng He.

</span>
<span class="ltx_bibblock">Federated learning systems: Vision, hype and reality for data privacy
and protection.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.09693v3</span>, Dec. 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib17.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019c]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1908.07873v1</span>, Aug. 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib18.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019d]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, and et al.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.06127v4</span>, Sep. 2019.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib19.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019e]</span>
<span class="ltx_bibblock">
Xiang Li, Kaixuan Huang, Wenhao Yang, and et al.

</span>
<span class="ltx_bibblock">On the convergence of FedAvg on non-iid data.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.02189</span>, Jul. 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan <span id="bib.bib20.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider Moore, Daniel Ramage, and et al.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.3.1" class="ltx_text ltx_font_italic">Proceedings of AISTATS’17</span>, Apr. 2017.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen <span id="bib.bib21.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2016]</span>
<span class="ltx_bibblock">
Shiqi Shen, Shruti Tople, and Prateek Saxena.

</span>
<span class="ltx_bibblock">Auror: Defending against poisoning attacks in collaborative deep
learning systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.3.1" class="ltx_text ltx_font_italic">Proceedings of ACM ACSAC’16</span>, Dec. 2016.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun <span id="bib.bib22.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H Brendan McMahan.

</span>
<span class="ltx_bibblock">Can you really backdoor federated learning?

</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1911.07963</span>, Nov. 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu <span id="bib.bib23.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019]</span>
<span class="ltx_bibblock">
Zhaoxian Wu, Qing Ling, Tianyi Chen, and et al.

</span>
<span class="ltx_bibblock">Federated variance-reduced stochastic gradient descent with
robustness to byzantine attacks.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.12716v1</span>, Dec. 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie <span id="bib.bib24.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta.

</span>
<span class="ltx_bibblock">Generalized Byzantine-tolerant SGD.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1802.10116</span>, Feb. 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu <span id="bib.bib25.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Haowen Xu, Wenxiao Chen, Nengwen Zhao, and et al.

</span>
<span class="ltx_bibblock">Unsupervised anomaly detection via variational auto-encoder for
seasonal kpis in web applications.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.3.1" class="ltx_text ltx_font_italic">Proceedings of WWW’18</span>, Apr. 2018.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang <span id="bib.bib26.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019a]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, and H. Yu.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic">Federated Learning</span>.

</span>
<span class="ltx_bibblock">Morgan &amp; Claypool, Dec. 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang <span id="bib.bib27.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2019b]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic">ACM Trans. Intell. Syst. Technol. (TIST)</span>, Feb. 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin <span id="bib.bib28.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett.

</span>
<span class="ltx_bibblock">Byzantine-robust distributed learning: Towards optimal statistical
rates.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.3.1" class="ltx_text ltx_font_italic">Proceedings of ICML’18</span>, Jul. 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang <span id="bib.bib29.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic">Dive into Deep Learning</span>.

</span>
<span class="ltx_bibblock">Jan. 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2002.00210" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2002.00211" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2002.00211">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2002.00211" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2002.00212" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 11:56:12 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
