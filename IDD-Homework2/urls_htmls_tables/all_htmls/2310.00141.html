<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.00141] The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning</title><meta property="og:description" content="Automatic speech recognition (ASR) models are typically trained on large datasets of transcribed speech. As language evolves and new terms come into use, these models can become outdated and stale. In the context of mo…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.00141">

<!--Generated on Wed Feb 28 03:09:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\bstctlcite</span>
<p id="p1.2" class="ltx_p">IEEEexample:BSTcontrol</p>
</div>
<h1 class="ltx_title ltx_title_document">The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Automatic speech recognition (ASR) models are typically trained on large datasets of transcribed speech. As language evolves and new terms come into use, these models can become outdated and stale. In the context of models trained on the server but deployed on edge devices, errors may result from the mismatch between server training data and actual on-device usage. In this work, we seek to continually learn from on-device user corrections through Federated Learning (FL) to address this issue. We explore techniques to target fresh terms that the model has not previously encountered, learn long-tail words, and mitigate catastrophic forgetting. In experimental evaluations, we find that the proposed techniques improve model recognition of fresh terms, while preserving quality on the overall language distribution.</p>
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p2.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
speech recognition, federated learning, deep learning, catastrophic forgetting, on-device training</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Human language is constantly shifting and evolving. In order to serve a high quality ASR model that can be deployed to user devices as an input mechanism, it is crucial to train on data that is representative of the actual, current vocabulary of user dictation. While it is possible to use proxy data for initial server-side training, stopping there means that the model will lag behind the ever-changing user distribution in terms of freshness and accuracy.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One way to improve model freshness is to make use of the natural feedback loop that occurs during usage. When the model makes recognition errors, users may make manual edits to the output text; in the ideal case, this points to a misrecognition that the model has made, and additionally gives us the corrected transcript to learn from. Paired with the original audio, these training examples are a treasure trove for improving model quality, containing up-to-date transcriptions that faithfully reflect actual user requirements. Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> affords us a privacy-preserving mechanism to leverage this training data and these valuable user correction signals.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Related work has explored mining challenging training examples for model improvement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, but in this work we <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">utilize the model’s own errors, and user corrections thereof, to target fresh terms</span>. In this way, the model can improve on precisely the words it struggles with, and learn fresh terms unseen in the training corpus snapshot on the server.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">However, not all user edits made naturally in the course of usage are necessarily true corrections to the original spoken utterance. In many cases, the edits may be revisions of original intent, and the resulting edited text may diverge entirely from the original audio. In this work, we <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">propose a simple method to target legitimate user corrections: filtering training examples to those that contain terms the model is likely to misrecognize</span>, for example fresh terms that did not exist when the server training data was collected, and would be unknown to the server model. These misrecognized words are likely to be the target of true user corrections. As shown in our experimental results, this approach successfully helps to target high-quality training examples, and fine-tuning on them improves model quality on these fresh terms.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">This improvement on the targeted terms, however, can also come with the unintended pitfall of regression on the original distribution. We <span id="S1.p5.1.1" class="ltx_text ltx_font_bold">compare a number of techniques for mitigating catastrophic forgetting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> in FL</span>, including variants of weight averaging algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. We also reintroduce data from the original distribution, which in the FL context requires mixing centralized training in with federated rounds <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, to positive effect.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Finally, these fresh terms can be long-tail words, and training examples may be exceedingly sparse. We <span id="S1.p6.1.1" class="ltx_text ltx_font_bold">propose two approaches to improve learning on the rarest examples</span>. We find that these combined techniques allow us to learn fresh terms without harming overall model quality.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> is a technique to train a single centralized model in a distributed fashion. During each round of federated training, participating edge devices receive the most recent centralized checkpoint, locally train on available on-device training examples, and send only the model gradients back to the server, never any user data. These updates are aggregated into the central model, which is then sent out again for the next federated round.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">In the context of this work, on-device training examples consist of speech audio, the original transcript output by the inference model, along with the final text committed by the user after any edits.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Filtering Examples By Fresh Words</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In order to target high-quality training examples, we generate a list of fresh words that are likely to be misrecognized by the model, and hence the target of legitimate user correction, rather than other edits. In the long term, this step should be automated, e.g., by aggregating over user corrections across devices through Federated Analytics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Words that are corrected by a large number of users are likely to be true misrecognitions. For this work, we experiment with a manually-curated list of 241 words selected from sources such as pop culture, current events, and recent technologies. The terms vary greatly in how often they appear in on-device training examples (Fig <a href="#S2.F1" title="Figure 1 ‣ 2.2 Filtering Examples By Fresh Words ‣ 2 Methodology ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), and some examples are shown in Table <a href="#S2.T1" title="Table 1 ‣ 2.2 Filtering Examples By Fresh Words ‣ 2 Methodology ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2310.00141/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span>Histogram of wordlist word frequency during training. Approximately 50% of words were seen after 300 rounds of training, with a wide range of frequency.</figcaption>
</figure>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.2.1.1" class="ltx_tr">
<th id="S2.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Word</span></th>
<th id="S2.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Source</span></th>
<th id="S2.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Seen Count</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.2.2.1" class="ltx_tr">
<td id="S2.T1.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">warnock</span></td>
<td id="S2.T1.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.2.2.1.2.1" class="ltx_text" style="font-size:90%;">current events</span></td>
<td id="S2.T1.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.2.2.1.3.1" class="ltx_text" style="font-size:90%;">85</span></td>
</tr>
<tr id="S2.T1.2.3.2" class="ltx_tr">
<td id="S2.T1.2.3.2.1" class="ltx_td ltx_align_center"><span id="S2.T1.2.3.2.1.1" class="ltx_text" style="font-size:90%;">webb</span></td>
<td id="S2.T1.2.3.2.2" class="ltx_td ltx_align_center"><span id="S2.T1.2.3.2.2.1" class="ltx_text" style="font-size:90%;">technology</span></td>
<td id="S2.T1.2.3.2.3" class="ltx_td ltx_align_center"><span id="S2.T1.2.3.2.3.1" class="ltx_text" style="font-size:90%;">48</span></td>
</tr>
<tr id="S2.T1.2.4.3" class="ltx_tr">
<td id="S2.T1.2.4.3.1" class="ltx_td ltx_align_center"><span id="S2.T1.2.4.3.1.1" class="ltx_text" style="font-size:90%;">addams</span></td>
<td id="S2.T1.2.4.3.2" class="ltx_td ltx_align_center"><span id="S2.T1.2.4.3.2.1" class="ltx_text" style="font-size:90%;">media</span></td>
<td id="S2.T1.2.4.3.3" class="ltx_td ltx_align_center"><span id="S2.T1.2.4.3.3.1" class="ltx_text" style="font-size:90%;">38</span></td>
</tr>
<tr id="S2.T1.2.5.4" class="ltx_tr">
<td id="S2.T1.2.5.4.1" class="ltx_td ltx_align_center"><span id="S2.T1.2.5.4.1.1" class="ltx_text" style="font-size:90%;">mbappe</span></td>
<td id="S2.T1.2.5.4.2" class="ltx_td ltx_align_center"><span id="S2.T1.2.5.4.2.1" class="ltx_text" style="font-size:90%;">sports</span></td>
<td id="S2.T1.2.5.4.3" class="ltx_td ltx_align_center"><span id="S2.T1.2.5.4.3.1" class="ltx_text" style="font-size:90%;">27</span></td>
</tr>
<tr id="S2.T1.2.6.5" class="ltx_tr">
<td id="S2.T1.2.6.5.1" class="ltx_td ltx_align_center"><span id="S2.T1.2.6.5.1.1" class="ltx_text" style="font-size:90%;">salman</span></td>
<td id="S2.T1.2.6.5.2" class="ltx_td ltx_align_center"><span id="S2.T1.2.6.5.2.1" class="ltx_text" style="font-size:90%;">current events</span></td>
<td id="S2.T1.2.6.5.3" class="ltx_td ltx_align_center"><span id="S2.T1.2.6.5.3.1" class="ltx_text" style="font-size:90%;">8</span></td>
</tr>
<tr id="S2.T1.2.7.6" class="ltx_tr">
<td id="S2.T1.2.7.6.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.2.7.6.1.1" class="ltx_text" style="font-size:90%;">sumeru</span></td>
<td id="S2.T1.2.7.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.2.7.6.2.1" class="ltx_text" style="font-size:90%;">media</span></td>
<td id="S2.T1.2.7.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.2.7.6.3.1" class="ltx_text" style="font-size:90%;">8</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.5.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>Examples of words used for filtering, based on fresh or trending terms at time of experimentation.</figcaption>
</figure>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">While training in FL, we filter the utterances available on-device to examples that contain at least one word from this wordlist and have a user edit. In this way, we target cases where the user spoke one of these words, the model produced the wrong transcript, and the user corrected it.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Because these words are by nature long-tail and represent only a small portion of utterances, evaluating improvement is challenging. To do so, we create a targeted testset focused on measuring quality on these rare words. We compile 4-5 sentences containing each wordlist word: a combination of manually-generated sentences and sentences scraped from the web. Then we generate corresponding audio using Text-to-Speech (TTS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, and use the resulting audio-sentence pairs as our targeted testset. Due to the nature of TTS audio, and the fact that the terms used for the testset are inherently challenging and rare, including terms that were infrequently or never encountered during training, the resulting WER tends to be high, but serves as a useful benchmark to understand quality improvement on these targeted words. We further perform per-word error analysis before and after fine-tuning to directly understand how recognition of each term is affected.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Mitigating Forgetting</h3>

<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.00141/assets/x2.png" id="S2.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="360" height="168" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S2.F2.sf1.3.2" class="ltx_text" style="font-size:80%;">Static checkpoint averaging</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.00141/assets/x3.png" id="S2.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="360" height="168" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S2.F2.sf2.3.2" class="ltx_text" style="font-size:80%;">Dynamic checkpoint averaging</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.00141/assets/x4.png" id="S2.F2.sf3.g1" class="ltx_graphics ltx_img_landscape" width="360" height="168" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S2.F2.sf3.3.2" class="ltx_text" style="font-size:80%;">Mixture of Centralized and Federated Training</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text ltx_font_bold">Fig. 2</span>: </span>Illustration of techniques to mitigate forgetting. Each shows consecutive federated training rounds (yellow), with varying types of server-side modification (blue), and progression of the centralized model being trained (gray).</figcaption>
</figure>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Static Checkpoint Averaging</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">To mitigate forgetting, we experiment with several techniques, starting with simple weight averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Prior to evaluation, we average the weights of each federated checkpoint with the weights of the initial pre-trained checkpoint, modified by a scaling factor (Fig <a href="#S2.F2" title="Figure 2 ‣ 2.3 Mitigating Forgetting ‣ 2 Methodology ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>a). Federated rounds proceed as usual, and are not impacted by this averaging.</p>
</div>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Dynamic Checkpoint Averaging</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.1" class="ltx_p">As above, this approach averages the weights of each federated checkpoint with the initial checkpoint (Fig <a href="#S2.F2" title="Figure 2 ‣ 2.3 Mitigating Forgetting ‣ 2 Methodology ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>b). However, here each averaged checkpoint is then used to initialize the subsequent federated round. In other words, the federated training process is modified to initialize from the new averaged checkpoint, rather than from the purely federated checkpoint from the round before.</p>
</div>
</section>
<section id="S2.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3 </span>Mixture of Centralized and Federated Training</h4>

<div id="S2.SS3.SSS3.p1" class="ltx_para">
<p id="S2.SS3.SSS3.p1.1" class="ltx_p">Finally, we perform server-side training in parallel with federated training (Fig <a href="#S2.F2" title="Figure 2 ‣ 2.3 Mitigating Forgetting ‣ 2 Methodology ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>c), as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. While FL rounds learn the on-device data, we simultaneously perform centralized training on the same server datasets used to train the initial pre-trained checkpoint. These centralized model updates are included along with those of the federated clients during aggregation at the end of each round.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Learning Long-tail Words</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Because the fresh and misrecognized words tend to be long-tail words, training examples are difficult to come by. All but non-existent in the server training corpus, they are rare even in on-device data. Within the long-tail words, availability also varies drastically from term to term; training on this imbalanced distribution results in little improvement on the least frequent words. To address this, we propose two techniques: probabilistic sampling and client loss weighting.</p>
</div>
<section id="S2.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1 </span>Probabilistic Sampling</h4>

<div id="S2.SS4.SSS1.p1" class="ltx_para">
<p id="S2.SS4.SSS1.p1.3" class="ltx_p">Probabilistic sampling aims to artificially massage the training examples into a more uniform distribution by down-sampling the federated clients that only have examples of the most common words from the wordlist. Each word is assigned a sampling probability <math id="S2.SS4.SSS1.p1.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS4.SSS1.p1.1.m1.1a"><mi id="S2.SS4.SSS1.p1.1.m1.1.1" xref="S2.SS4.SSS1.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.1.m1.1b"><ci id="S2.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.1.m1.1c">p</annotation></semantics></math>, where <math id="S2.SS4.SSS1.p1.2.m2.2" class="ltx_Math" alttext="p\in(0,1]" display="inline"><semantics id="S2.SS4.SSS1.p1.2.m2.2a"><mrow id="S2.SS4.SSS1.p1.2.m2.2.3" xref="S2.SS4.SSS1.p1.2.m2.2.3.cmml"><mi id="S2.SS4.SSS1.p1.2.m2.2.3.2" xref="S2.SS4.SSS1.p1.2.m2.2.3.2.cmml">p</mi><mo id="S2.SS4.SSS1.p1.2.m2.2.3.1" xref="S2.SS4.SSS1.p1.2.m2.2.3.1.cmml">∈</mo><mrow id="S2.SS4.SSS1.p1.2.m2.2.3.3.2" xref="S2.SS4.SSS1.p1.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS4.SSS1.p1.2.m2.2.3.3.2.1" xref="S2.SS4.SSS1.p1.2.m2.2.3.3.1.cmml">(</mo><mn id="S2.SS4.SSS1.p1.2.m2.1.1" xref="S2.SS4.SSS1.p1.2.m2.1.1.cmml">0</mn><mo id="S2.SS4.SSS1.p1.2.m2.2.3.3.2.2" xref="S2.SS4.SSS1.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S2.SS4.SSS1.p1.2.m2.2.2" xref="S2.SS4.SSS1.p1.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S2.SS4.SSS1.p1.2.m2.2.3.3.2.3" xref="S2.SS4.SSS1.p1.2.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.2.m2.2b"><apply id="S2.SS4.SSS1.p1.2.m2.2.3.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.3"><in id="S2.SS4.SSS1.p1.2.m2.2.3.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.3.1"></in><ci id="S2.SS4.SSS1.p1.2.m2.2.3.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.3.2">𝑝</ci><interval closure="open-closed" id="S2.SS4.SSS1.p1.2.m2.2.3.3.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.3.3.2"><cn type="integer" id="S2.SS4.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p1.2.m2.1.1">0</cn><cn type="integer" id="S2.SS4.SSS1.p1.2.m2.2.2.cmml" xref="S2.SS4.SSS1.p1.2.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.2.m2.2c">p\in(0,1]</annotation></semantics></math>. The more frequent a word is in the original data distribution, the smaller its <math id="S2.SS4.SSS1.p1.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS4.SSS1.p1.3.m3.1a"><mi id="S2.SS4.SSS1.p1.3.m3.1.1" xref="S2.SS4.SSS1.p1.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p1.3.m3.1b"><ci id="S2.SS4.SSS1.p1.3.m3.1.1.cmml" xref="S2.SS4.SSS1.p1.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p1.3.m3.1c">p</annotation></semantics></math> value.</p>
</div>
<div id="S2.SS4.SSS1.p2" class="ltx_para">
<p id="S2.SS4.SSS1.p2.2" class="ltx_p">If the client data contains a targeted word <math id="S2.SS4.SSS1.p2.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SS4.SSS1.p2.1.m1.1a"><mi id="S2.SS4.SSS1.p2.1.m1.1.1" xref="S2.SS4.SSS1.p2.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.1.m1.1b"><ci id="S2.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS4.SSS1.p2.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.1.m1.1c">w</annotation></semantics></math>, then it is included in the FL round with probability <math id="S2.SS4.SSS1.p2.2.m2.1" class="ltx_Math" alttext="p_{w}" display="inline"><semantics id="S2.SS4.SSS1.p2.2.m2.1a"><msub id="S2.SS4.SSS1.p2.2.m2.1.1" xref="S2.SS4.SSS1.p2.2.m2.1.1.cmml"><mi id="S2.SS4.SSS1.p2.2.m2.1.1.2" xref="S2.SS4.SSS1.p2.2.m2.1.1.2.cmml">p</mi><mi id="S2.SS4.SSS1.p2.2.m2.1.1.3" xref="S2.SS4.SSS1.p2.2.m2.1.1.3.cmml">w</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS1.p2.2.m2.1b"><apply id="S2.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS4.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS1.p2.2.m2.1.1.1.cmml" xref="S2.SS4.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.SSS1.p2.2.m2.1.1.2.cmml" xref="S2.SS4.SSS1.p2.2.m2.1.1.2">𝑝</ci><ci id="S2.SS4.SSS1.p2.2.m2.1.1.3.cmml" xref="S2.SS4.SSS1.p2.2.m2.1.1.3">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS1.p2.2.m2.1c">p_{w}</annotation></semantics></math>. If the client has multiple wordlist words, either within the same utterance or over multiple training examples, then its probability is the maximum among the words’ sampling probabilities. Due to the limited number of clients included in each round, this increases the occurrences of less frequent words seen during training.</p>
</div>
</section>
<section id="S2.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2 </span>Client Loss Weighting</h4>

<div id="S2.SS4.SSS2.p1" class="ltx_para">
<p id="S2.SS4.SSS2.p1.4" class="ltx_p">Client loss weighting aims to more heavily penalize the wrong predictions of the rarest wordlist words. Each target word is assigned a client loss weight (<math id="S2.SS4.SSS2.p1.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SS4.SSS2.p1.1.m1.1a"><mi id="S2.SS4.SSS2.p1.1.m1.1.1" xref="S2.SS4.SSS2.p1.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p1.1.m1.1b"><ci id="S2.SS4.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS4.SSS2.p1.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p1.1.m1.1c">w</annotation></semantics></math>). The more frequent the word, the smaller the <math id="S2.SS4.SSS2.p1.2.m2.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SS4.SSS2.p1.2.m2.1a"><mi id="S2.SS4.SSS2.p1.2.m2.1.1" xref="S2.SS4.SSS2.p1.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p1.2.m2.1b"><ci id="S2.SS4.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS4.SSS2.p1.2.m2.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p1.2.m2.1c">w</annotation></semantics></math>. On the client, the loss is computed for each utterance, and then additionally scaled by the <math id="S2.SS4.SSS2.p1.3.m3.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SS4.SSS2.p1.3.m3.1a"><mi id="S2.SS4.SSS2.p1.3.m3.1.1" xref="S2.SS4.SSS2.p1.3.m3.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p1.3.m3.1b"><ci id="S2.SS4.SSS2.p1.3.m3.1.1.cmml" xref="S2.SS4.SSS2.p1.3.m3.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p1.3.m3.1c">w</annotation></semantics></math> of any wordlist word the utterance contains. If an utterance contains multiple target words, its <math id="S2.SS4.SSS2.p1.4.m4.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SS4.SSS2.p1.4.m4.1a"><mi id="S2.SS4.SSS2.p1.4.m4.1.1" xref="S2.SS4.SSS2.p1.4.m4.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p1.4.m4.1b"><ci id="S2.SS4.SSS2.p1.4.m4.1.1.cmml" xref="S2.SS4.SSS2.p1.4.m4.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p1.4.m4.1c">w</annotation></semantics></math> is the maximum among all the weights. The client loss is the sum of each utterance loss multiplied by the utterance loss weight:</p>
</div>
<div id="S2.SS4.SSS2.p2" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\mathcal{L}^{\text{client}}=\sum_{u\in U}\max_{d\in D}(w_{d})\cdot\text{loss}_{u}" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><msup id="S2.E1.m1.2.2.4" xref="S2.E1.m1.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.4.2" xref="S2.E1.m1.2.2.4.2.cmml">ℒ</mi><mtext id="S2.E1.m1.2.2.4.3" xref="S2.E1.m1.2.2.4.3a.cmml">client</mtext></msup><mo rspace="0.111em" id="S2.E1.m1.2.2.3" xref="S2.E1.m1.2.2.3.cmml">=</mo><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml"><munder id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.3.cmml"><mo movablelimits="false" id="S2.E1.m1.2.2.2.3.2" xref="S2.E1.m1.2.2.2.3.2.cmml">∑</mo><mrow id="S2.E1.m1.2.2.2.3.3" xref="S2.E1.m1.2.2.2.3.3.cmml"><mi id="S2.E1.m1.2.2.2.3.3.2" xref="S2.E1.m1.2.2.2.3.3.2.cmml">u</mi><mo id="S2.E1.m1.2.2.2.3.3.1" xref="S2.E1.m1.2.2.2.3.3.1.cmml">∈</mo><mi id="S2.E1.m1.2.2.2.3.3.3" xref="S2.E1.m1.2.2.2.3.3.3.cmml">U</mi></mrow></munder><mrow id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml"><mrow id="S2.E1.m1.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.3.cmml"><munder id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">max</mi><mrow id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml">d</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">∈</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.3.cmml">D</mi></mrow></munder><mo id="S2.E1.m1.2.2.2.2.2.2a" xref="S2.E1.m1.2.2.2.2.2.3.cmml">⁡</mo><mrow id="S2.E1.m1.2.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S2.E1.m1.2.2.2.2.2.2.2.1" xref="S2.E1.m1.2.2.2.2.2.2.2.1.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.2.1.2" xref="S2.E1.m1.2.2.2.2.2.2.2.1.2.cmml">w</mi><mi id="S2.E1.m1.2.2.2.2.2.2.2.1.3" xref="S2.E1.m1.2.2.2.2.2.2.2.1.3.cmml">d</mi></msub><mo rspace="0.055em" stretchy="false" id="S2.E1.m1.2.2.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S2.E1.m1.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.3.cmml">⋅</mo><msub id="S2.E1.m1.2.2.2.2.4" xref="S2.E1.m1.2.2.2.2.4.cmml"><mtext id="S2.E1.m1.2.2.2.2.4.2" xref="S2.E1.m1.2.2.2.2.4.2a.cmml">loss</mtext><mi id="S2.E1.m1.2.2.2.2.4.3" xref="S2.E1.m1.2.2.2.2.4.3.cmml">u</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><eq id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.3"></eq><apply id="S2.E1.m1.2.2.4.cmml" xref="S2.E1.m1.2.2.4"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.4.1.cmml" xref="S2.E1.m1.2.2.4">superscript</csymbol><ci id="S2.E1.m1.2.2.4.2.cmml" xref="S2.E1.m1.2.2.4.2">ℒ</ci><ci id="S2.E1.m1.2.2.4.3a.cmml" xref="S2.E1.m1.2.2.4.3"><mtext mathsize="70%" id="S2.E1.m1.2.2.4.3.cmml" xref="S2.E1.m1.2.2.4.3">client</mtext></ci></apply><apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"><apply id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.3.1.cmml" xref="S2.E1.m1.2.2.2.3">subscript</csymbol><sum id="S2.E1.m1.2.2.2.3.2.cmml" xref="S2.E1.m1.2.2.2.3.2"></sum><apply id="S2.E1.m1.2.2.2.3.3.cmml" xref="S2.E1.m1.2.2.2.3.3"><in id="S2.E1.m1.2.2.2.3.3.1.cmml" xref="S2.E1.m1.2.2.2.3.3.1"></in><ci id="S2.E1.m1.2.2.2.3.3.2.cmml" xref="S2.E1.m1.2.2.2.3.3.2">𝑢</ci><ci id="S2.E1.m1.2.2.2.3.3.3.cmml" xref="S2.E1.m1.2.2.2.3.3.3">𝑈</ci></apply></apply><apply id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2"><ci id="S2.E1.m1.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.3">⋅</ci><apply id="S2.E1.m1.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2"><apply id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><max id="S2.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.2"></max><apply id="S2.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3"><in id="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1"></in><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2">𝑑</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.3">𝐷</ci></apply></apply><apply id="S2.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.2.2.2.1.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2.1">subscript</csymbol><ci id="S2.E1.m1.2.2.2.2.2.2.2.1.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2.1.2">𝑤</ci><ci id="S2.E1.m1.2.2.2.2.2.2.2.1.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2.1.3">𝑑</ci></apply></apply><apply id="S2.E1.m1.2.2.2.2.4.cmml" xref="S2.E1.m1.2.2.2.2.4"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.4.1.cmml" xref="S2.E1.m1.2.2.2.2.4">subscript</csymbol><ci id="S2.E1.m1.2.2.2.2.4.2a.cmml" xref="S2.E1.m1.2.2.2.2.4.2"><mtext id="S2.E1.m1.2.2.2.2.4.2.cmml" xref="S2.E1.m1.2.2.2.2.4.2">loss</mtext></ci><ci id="S2.E1.m1.2.2.2.2.4.3.cmml" xref="S2.E1.m1.2.2.2.2.4.3">𝑢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\mathcal{L}^{\text{client}}=\sum_{u\in U}\max_{d\in D}(w_{d})\cdot\text{loss}_{u}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS4.SSS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS4.SSS2.p3.3" class="ltx_p">where <math id="S2.SS4.SSS2.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{client}}" display="inline"><semantics id="S2.SS4.SSS2.p3.1.m1.1a"><msup id="S2.SS4.SSS2.p3.1.m1.1.1" xref="S2.SS4.SSS2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.SSS2.p3.1.m1.1.1.2" xref="S2.SS4.SSS2.p3.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S2.SS4.SSS2.p3.1.m1.1.1.3" xref="S2.SS4.SSS2.p3.1.m1.1.1.3a.cmml">client</mtext></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p3.1.m1.1b"><apply id="S2.SS4.SSS2.p3.1.m1.1.1.cmml" xref="S2.SS4.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.SSS2.p3.1.m1.1.1.1.cmml" xref="S2.SS4.SSS2.p3.1.m1.1.1">superscript</csymbol><ci id="S2.SS4.SSS2.p3.1.m1.1.1.2.cmml" xref="S2.SS4.SSS2.p3.1.m1.1.1.2">ℒ</ci><ci id="S2.SS4.SSS2.p3.1.m1.1.1.3a.cmml" xref="S2.SS4.SSS2.p3.1.m1.1.1.3"><mtext mathsize="70%" id="S2.SS4.SSS2.p3.1.m1.1.1.3.cmml" xref="S2.SS4.SSS2.p3.1.m1.1.1.3">client</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p3.1.m1.1c">\mathcal{L}^{\text{client}}</annotation></semantics></math> is the client loss, computed over <math id="S2.SS4.SSS2.p3.2.m2.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S2.SS4.SSS2.p3.2.m2.1a"><mi id="S2.SS4.SSS2.p3.2.m2.1.1" xref="S2.SS4.SSS2.p3.2.m2.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p3.2.m2.1b"><ci id="S2.SS4.SSS2.p3.2.m2.1.1.cmml" xref="S2.SS4.SSS2.p3.2.m2.1.1">𝑈</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p3.2.m2.1c">U</annotation></semantics></math> utterances on the client and <math id="S2.SS4.SSS2.p3.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS4.SSS2.p3.3.m3.1a"><mi id="S2.SS4.SSS2.p3.3.m3.1.1" xref="S2.SS4.SSS2.p3.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.SSS2.p3.3.m3.1b"><ci id="S2.SS4.SSS2.p3.3.m3.1.1.cmml" xref="S2.SS4.SSS2.p3.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.SSS2.p3.3.m3.1c">D</annotation></semantics></math> words per utterance.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Model and Data</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Architecture</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">All models described in this paper are end-to-end, streaming transducer models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> based on the Conformer architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Due to the cost of training in FL, we initially demonstrate the wordlist filtering approach in server-side simulation, before expanding to a production FL setup on user devices. For the simulation experiments, we use a streaming Conformer model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, while in production, we use a variation of this model that utilizes cascading encoders <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">One important consideration for on-device learning is computational efficiency. Research in deep learning has shown that neural networks benefit from being overparameterized <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. In particular, when seeking to learn new words in a deep ASR model, previous research has shown the majority of quality gains can be achieved by training only the topmost layers, such as the joint layer, or the joint and prediction network (which together we refer to as the decoder portion of the model) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. We adopt this setting; compared to training the entire model, this affords us significant memory savings. For example, for the production model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, the decoder portion is only 40M parameters out of the entire 150M-parameter model. A static, frozen, and compressed encoder is used to generate encoder features, which are then used as input for decoder training.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>On-Device Minimum Word Error Rate Training</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.2" class="ltx_p">In addition to standard RNN-t loss, we also incorporate Minimum Word Error Rate (MWER) loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, which is computed from the loss of each of the N-best hypotheses from beam search. If <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mi id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><ci id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">x</annotation></semantics></math> are the input acoustic frames, and <math id="S3.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="y_{n}" display="inline"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><msub id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml">y</mi><mi id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">𝑦</ci><ci id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">y_{n}</annotation></semantics></math> are the N-best hypotheses for the output label sequence, then the loss can be written as:</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.5" class="ltx_Math" alttext="\mathcal{L}^{\text{MWER}}=\sum_{i=1}^{N}\hat{P}(y_{i}|x)\cdot\left(W(y_{i},y)-\frac{\sum_{i=1}^{N}W(y_{i},y)}{N}\right)" display="block"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml"><msup id="S3.E2.m1.5.5.4" xref="S3.E2.m1.5.5.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.5.5.4.2" xref="S3.E2.m1.5.5.4.2.cmml">ℒ</mi><mtext id="S3.E2.m1.5.5.4.3" xref="S3.E2.m1.5.5.4.3a.cmml">MWER</mtext></msup><mo rspace="0.111em" id="S3.E2.m1.5.5.3" xref="S3.E2.m1.5.5.3.cmml">=</mo><mrow id="S3.E2.m1.5.5.2" xref="S3.E2.m1.5.5.2.cmml"><munderover id="S3.E2.m1.5.5.2.3" xref="S3.E2.m1.5.5.2.3.cmml"><mo movablelimits="false" id="S3.E2.m1.5.5.2.3.2.2" xref="S3.E2.m1.5.5.2.3.2.2.cmml">∑</mo><mrow id="S3.E2.m1.5.5.2.3.2.3" xref="S3.E2.m1.5.5.2.3.2.3.cmml"><mi id="S3.E2.m1.5.5.2.3.2.3.2" xref="S3.E2.m1.5.5.2.3.2.3.2.cmml">i</mi><mo id="S3.E2.m1.5.5.2.3.2.3.1" xref="S3.E2.m1.5.5.2.3.2.3.1.cmml">=</mo><mn id="S3.E2.m1.5.5.2.3.2.3.3" xref="S3.E2.m1.5.5.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.5.5.2.3.3" xref="S3.E2.m1.5.5.2.3.3.cmml">N</mi></munderover><mrow id="S3.E2.m1.5.5.2.2" xref="S3.E2.m1.5.5.2.2.cmml"><mrow id="S3.E2.m1.4.4.1.1.1" xref="S3.E2.m1.4.4.1.1.1.cmml"><mover accent="true" id="S3.E2.m1.4.4.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.3.cmml"><mi id="S3.E2.m1.4.4.1.1.1.3.2" xref="S3.E2.m1.4.4.1.1.1.3.2.cmml">P</mi><mo id="S3.E2.m1.4.4.1.1.1.3.1" xref="S3.E2.m1.4.4.1.1.1.3.1.cmml">^</mo></mover><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.4.4.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.2.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.2.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E2.m1.5.5.2.2.3" xref="S3.E2.m1.5.5.2.2.3.cmml">⋅</mo><mrow id="S3.E2.m1.5.5.2.2.2.1" xref="S3.E2.m1.5.5.2.2.2.1.1.cmml"><mo id="S3.E2.m1.5.5.2.2.2.1.2" xref="S3.E2.m1.5.5.2.2.2.1.1.cmml">(</mo><mrow id="S3.E2.m1.5.5.2.2.2.1.1" xref="S3.E2.m1.5.5.2.2.2.1.1.cmml"><mrow id="S3.E2.m1.5.5.2.2.2.1.1.1" xref="S3.E2.m1.5.5.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.5.5.2.2.2.1.1.1.3" xref="S3.E2.m1.5.5.2.2.2.1.1.1.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.2.2.2.1.1.1.2" xref="S3.E2.m1.5.5.2.2.2.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.2" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.2.cmml">(</mo><msub id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.2.cmml">y</mi><mi id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.3" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.2.cmml">,</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">y</mi><mo stretchy="false" id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.4" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.5.5.2.2.2.1.1.2" xref="S3.E2.m1.5.5.2.2.2.1.1.2.cmml">−</mo><mfrac id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><msubsup id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml"><mo id="S3.E2.m1.2.2.2.3.2.2" xref="S3.E2.m1.2.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E2.m1.2.2.2.3.2.3" xref="S3.E2.m1.2.2.2.3.2.3.cmml"><mi id="S3.E2.m1.2.2.2.3.2.3.2" xref="S3.E2.m1.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.2.3.2.3.1" xref="S3.E2.m1.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E2.m1.2.2.2.3.2.3.3" xref="S3.E2.m1.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.2.2.2.3.3" xref="S3.E2.m1.2.2.2.3.3.cmml">N</mi></msubsup><mrow id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.cmml">​</mo><mrow id="S3.E2.m1.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.2.1.2.cmml">(</mo><msub id="S3.E2.m1.2.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.2.1.1.1.2.cmml">y</mi><mi id="S3.E2.m1.2.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.2.1.2.cmml">,</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">y</mi><mo stretchy="false" id="S3.E2.m1.2.2.2.2.1.1.4" xref="S3.E2.m1.2.2.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><mi id="S3.E2.m1.2.2.4" xref="S3.E2.m1.2.2.4.cmml">N</mi></mfrac></mrow><mo id="S3.E2.m1.5.5.2.2.2.1.3" xref="S3.E2.m1.5.5.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5"><eq id="S3.E2.m1.5.5.3.cmml" xref="S3.E2.m1.5.5.3"></eq><apply id="S3.E2.m1.5.5.4.cmml" xref="S3.E2.m1.5.5.4"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.4.1.cmml" xref="S3.E2.m1.5.5.4">superscript</csymbol><ci id="S3.E2.m1.5.5.4.2.cmml" xref="S3.E2.m1.5.5.4.2">ℒ</ci><ci id="S3.E2.m1.5.5.4.3a.cmml" xref="S3.E2.m1.5.5.4.3"><mtext mathsize="70%" id="S3.E2.m1.5.5.4.3.cmml" xref="S3.E2.m1.5.5.4.3">MWER</mtext></ci></apply><apply id="S3.E2.m1.5.5.2.cmml" xref="S3.E2.m1.5.5.2"><apply id="S3.E2.m1.5.5.2.3.cmml" xref="S3.E2.m1.5.5.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.2.3.1.cmml" xref="S3.E2.m1.5.5.2.3">superscript</csymbol><apply id="S3.E2.m1.5.5.2.3.2.cmml" xref="S3.E2.m1.5.5.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.2.3.2.1.cmml" xref="S3.E2.m1.5.5.2.3">subscript</csymbol><sum id="S3.E2.m1.5.5.2.3.2.2.cmml" xref="S3.E2.m1.5.5.2.3.2.2"></sum><apply id="S3.E2.m1.5.5.2.3.2.3.cmml" xref="S3.E2.m1.5.5.2.3.2.3"><eq id="S3.E2.m1.5.5.2.3.2.3.1.cmml" xref="S3.E2.m1.5.5.2.3.2.3.1"></eq><ci id="S3.E2.m1.5.5.2.3.2.3.2.cmml" xref="S3.E2.m1.5.5.2.3.2.3.2">𝑖</ci><cn type="integer" id="S3.E2.m1.5.5.2.3.2.3.3.cmml" xref="S3.E2.m1.5.5.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.5.5.2.3.3.cmml" xref="S3.E2.m1.5.5.2.3.3">𝑁</ci></apply><apply id="S3.E2.m1.5.5.2.2.cmml" xref="S3.E2.m1.5.5.2.2"><ci id="S3.E2.m1.5.5.2.2.3.cmml" xref="S3.E2.m1.5.5.2.2.3">⋅</ci><apply id="S3.E2.m1.4.4.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.2"></times><apply id="S3.E2.m1.4.4.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.3"><ci id="S3.E2.m1.4.4.1.1.1.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.3.1">^</ci><ci id="S3.E2.m1.4.4.1.1.1.3.2.cmml" xref="S3.E2.m1.4.4.1.1.1.3.2">𝑃</ci></apply><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.5.5.2.2.2.1.1.cmml" xref="S3.E2.m1.5.5.2.2.2.1"><minus id="S3.E2.m1.5.5.2.2.2.1.1.2.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.2"></minus><apply id="S3.E2.m1.5.5.2.2.2.1.1.1.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1"><times id="S3.E2.m1.5.5.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1.2"></times><ci id="S3.E2.m1.5.5.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1.3">𝑊</ci><interval closure="open" id="S3.E2.m1.5.5.2.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1"><apply id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.5.5.2.2.2.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝑦</ci></interval></apply><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2"></divide><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><apply id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.3">superscript</csymbol><apply id="S3.E2.m1.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.3.2.1.cmml" xref="S3.E2.m1.2.2.2.3">subscript</csymbol><sum id="S3.E2.m1.2.2.2.3.2.2.cmml" xref="S3.E2.m1.2.2.2.3.2.2"></sum><apply id="S3.E2.m1.2.2.2.3.2.3.cmml" xref="S3.E2.m1.2.2.2.3.2.3"><eq id="S3.E2.m1.2.2.2.3.2.3.1.cmml" xref="S3.E2.m1.2.2.2.3.2.3.1"></eq><ci id="S3.E2.m1.2.2.2.3.2.3.2.cmml" xref="S3.E2.m1.2.2.2.3.2.3.2">𝑖</ci><cn type="integer" id="S3.E2.m1.2.2.2.3.2.3.3.cmml" xref="S3.E2.m1.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.2.3.3">𝑁</ci></apply><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><times id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2"></times><ci id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3">𝑊</ci><interval closure="open" id="S3.E2.m1.2.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1"><apply id="S3.E2.m1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.2">𝑦</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.3">𝑖</ci></apply><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝑦</ci></interval></apply></apply><ci id="S3.E2.m1.2.2.4.cmml" xref="S3.E2.m1.2.2.4">𝑁</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">\mathcal{L}^{\text{MWER}}=\sum_{i=1}^{N}\hat{P}(y_{i}|x)\cdot\left(W(y_{i},y)-\frac{\sum_{i=1}^{N}W(y_{i},y)}{N}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.p3.2" class="ltx_p">where <math id="S3.SS1.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\hat{P}" display="inline"><semantics id="S3.SS1.SSS1.p3.1.m1.1a"><mover accent="true" id="S3.SS1.SSS1.p3.1.m1.1.1" xref="S3.SS1.SSS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p3.1.m1.1.1.2" xref="S3.SS1.SSS1.p3.1.m1.1.1.2.cmml">P</mi><mo id="S3.SS1.SSS1.p3.1.m1.1.1.1" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.1.m1.1b"><apply id="S3.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1"><ci id="S3.SS1.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1">^</ci><ci id="S3.SS1.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.2">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.1.m1.1c">\hat{P}</annotation></semantics></math> is the probability of the i-th hypothesis normalized over all N-best hypotheses, and <math id="S3.SS1.SSS1.p3.2.m2.2" class="ltx_Math" alttext="W(y_{i},y)" display="inline"><semantics id="S3.SS1.SSS1.p3.2.m2.2a"><mrow id="S3.SS1.SSS1.p3.2.m2.2.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.2.2.3" xref="S3.SS1.SSS1.p3.2.m2.2.2.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS1.p3.2.m2.2.2.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.2.cmml">​</mo><mrow id="S3.SS1.SSS1.p3.2.m2.2.2.1.1" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.2.cmml">(</mo><msub id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.cmml">y</mi><mi id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.3" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.3" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.2.cmml">,</mo><mi id="S3.SS1.SSS1.p3.2.m2.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.cmml">y</mi><mo stretchy="false" id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.4" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.2.m2.2b"><apply id="S3.SS1.SSS1.p3.2.m2.2.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2"><times id="S3.SS1.SSS1.p3.2.m2.2.2.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.2"></times><ci id="S3.SS1.SSS1.p3.2.m2.2.2.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.3">𝑊</ci><interval closure="open" id="S3.SS1.SSS1.p3.2.m2.2.2.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1"><apply id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.2">𝑦</ci><ci id="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.2.2.1.1.1.3">𝑖</ci></apply><ci id="S3.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.2.m2.2c">W(y_{i},y)</annotation></semantics></math> is the number of word errors in the i-th hypothesis relative to the ground truth.</p>
</div>
<div id="S3.SS1.SSS1.p4" class="ltx_para">
<p id="S3.SS1.SSS1.p4.1" class="ltx_p">MWER loss is a component of server-side training, but would be too computationally expensive for an on-device setting due to the memory cost of computing the N-best hypotheses. Instead, we create a modified version for on-device by caching the hypotheses produced by the model decoder during training, and incorporating them during loss computation.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training Data</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In all our experiments, the model is pretrained on speech data from a multi-domain dataset (MD), encompassing domains of search, farfield, telephony, YouTube, etc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, including a Short-Form (SF) and Medium-Form (MF) domain. The model is then fine-tuned on training examples containing the interesting terms. All data are anonymized, and are collected, managed, and used for training models in accordance with Google AI Principles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">For our simulation experiments, the fine-tuning dataset consists of utterances from the SF domain that contain long-tail words (SF-LT). Learning is evaluated on the targeted SF-LT testset, a disjoint set of utterances containing the same long-tail words as the training data. Additionally, to ensure the model quality does not degrade on the overall distribution, we also use disjoint testsets from the SF and MF domains to measure regression on non-targeted words.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In production experiments, a similar pre-trained model is fine-tuned on user data through on-device FL, filtered to examples containing the long-tail words. For server-side evaluation, we create a corresponding targeted eval set, as outlined in the methodology. We also make use of the MF testset as our benchmark for preserving quality on the overall distribution. In both these cases, our goal is to improve WER on the targeted testsets, while maintaining WER on the overall distribution testsets.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>In Simulation</h3>

<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.2.1.1" class="ltx_tr">
<td id="S4.T2.2.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T2.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Dataset</span></td>
<td id="S4.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T2.2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">MF WER</span></td>
<td id="S4.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T2.2.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">SF WER</span></td>
<td id="S4.T2.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T2.2.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">SF-LT WER</span></td>
</tr>
<tr id="S4.T2.2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.2.2.1.1" class="ltx_text" style="font-size:90%;">MD (Baseline)</span></td>
<td id="S4.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.2.2.2.1" class="ltx_text" style="font-size:90%;">3.7</span></td>
<td id="S4.T2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.2.2.3.1" class="ltx_text" style="font-size:90%;">6.3</span></td>
<td id="S4.T2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.2.2.4.1" class="ltx_text" style="font-size:90%;">45.5</span></td>
</tr>
<tr id="S4.T2.2.3.3" class="ltx_tr">
<td id="S4.T2.2.3.3.1" class="ltx_td ltx_align_center ltx_border_t" colspan="4"><span id="S4.T2.2.3.3.1.1" class="ltx_text" style="font-size:90%;">Fine-tuning Whole Model</span></td>
</tr>
<tr id="S4.T2.2.4.4" class="ltx_tr">
<td id="S4.T2.2.4.4.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.4.4.1.1" class="ltx_text" style="font-size:90%;">SF-LT</span></td>
<td id="S4.T2.2.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.4.4.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">7.8</span></td>
<td id="S4.T2.2.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.4.4.3.1" class="ltx_text" style="font-size:90%;color:#FF0000;">9.3</span></td>
<td id="S4.T2.2.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.4.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">31.4</span></td>
</tr>
<tr id="S4.T2.2.5.5" class="ltx_tr">
<td id="S4.T2.2.5.5.1" class="ltx_td ltx_align_center"><span id="S4.T2.2.5.5.1.1" class="ltx_text" style="font-size:90%;">SF-LT + SF + MF</span></td>
<td id="S4.T2.2.5.5.2" class="ltx_td ltx_align_center"><span id="S4.T2.2.5.5.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">4.4</span></td>
<td id="S4.T2.2.5.5.3" class="ltx_td ltx_align_center"><span id="S4.T2.2.5.5.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">6.2</span></td>
<td id="S4.T2.2.5.5.4" class="ltx_td ltx_align_center"><span id="S4.T2.2.5.5.4.1" class="ltx_text" style="font-size:90%;">35.1</span></td>
</tr>
<tr id="S4.T2.2.6.6" class="ltx_tr">
<td id="S4.T2.2.6.6.1" class="ltx_td ltx_align_center ltx_border_t" colspan="4"><span id="S4.T2.2.6.6.1.1" class="ltx_text" style="font-size:90%;">Fine-tuning Joint Layer</span></td>
</tr>
<tr id="S4.T2.2.7.7" class="ltx_tr">
<td id="S4.T2.2.7.7.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.7.7.1.1" class="ltx_text" style="font-size:90%;">SF-LT</span></td>
<td id="S4.T2.2.7.7.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.7.7.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">6.4</span></td>
<td id="S4.T2.2.7.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.7.7.3.1" class="ltx_text" style="font-size:90%;color:#FF0000;">8.4</span></td>
<td id="S4.T2.2.7.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.7.7.4.1" class="ltx_text" style="font-size:90%;">38.1</span></td>
</tr>
<tr id="S4.T2.2.8.8" class="ltx_tr">
<td id="S4.T2.2.8.8.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.2.8.8.1.1" class="ltx_text" style="font-size:90%;">SF-LT + SF + MF</span></td>
<td id="S4.T2.2.8.8.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.2.8.8.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.8</span></td>
<td id="S4.T2.2.8.8.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.2.8.8.3.1" class="ltx_text" style="font-size:90%;">6.3</span></td>
<td id="S4.T2.2.8.8.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.2.8.8.4.1" class="ltx_text" style="font-size:90%;">40.6</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.5.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>In simulation, fine-tuning afforded improvement on the targeted testset (SF-LT), but degraded overall testset quality (MF + SF). Reintroducing SF + MF training data mitigated forgetting. When training was limited to the joint layer, the model was still able to improve on the targeted testset, while recovering the original WER for the overall testsets.</figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">As shown in Table <a href="#S4.T2" title="Table 2 ‣ 4.1 In Simulation ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we started with a baseline trained on our multidomain dataset. By fine-tuning only on examples containing the long-tail words (SF-LT), we saw a 31% relative improvement over the baseline on the targeted testset, but observed catastrophic forgetting in the form of significant degradation on the testsets that represent the overall distribution, including over 100% regression on MF.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">As these simulation experiments were done entirely server-side, we were able to address forgetting by reintroducing training examples from the original domain (SF and MF) during training, in equal proportion to the SF-LT dataset, similar to the Mixture of Centralized and Federated Training approach we proposed for production. This way, we were still able to achieve a 23% improvement in the targeted testset, while seeing much less degradation in the overall domain.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">In order to understand the most memory-efficient setting, we also tried fine-tuning only the joint layer of the model. Here, we saw less improvement on the targeted testset, but even lower degradation on the overall domain. By fine-tuning on both the targeted data and the overall data distributions, we saw a 11% improvement on the targeted testset, and little or no regression on the overall testsets.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Necessity of Wordlist Filtering In Production</h3>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2310.00141/assets/x5.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="265" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text ltx_font_bold">Fig. 3</span>: </span>Training on all examples with user edits caused the model quality to quickly diverge, indicating many were not actual corrections. However, filtering these examples by our wordlist resulted in far more stable model quality.</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In production experiments, we began by training on all examples with user edits, but the model quality quickly and dramatically degraded (Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 Necessity of Wordlist Filtering In Production ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), lending credence to our hypothesis that many of these edits are indeed revisions to the original utterance, rather than corrections of an incorrect ASR transcript, and likely result in significantly divergent text-audio pairs.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">However, using our list of fresh words that were likely to be misrecognized, we were able to filter training examples largely to those containing true user corrections. When on-device training was limited to examples with edits that contained a word in our fresh wordlist, the WER was stabilized.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Catastrophic Forgetting</h3>

<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.2.1.1" class="ltx_tr">
<th id="S4.T3.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Setup</span></th>
<th id="S4.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Overall WER</span></th>
<th id="S4.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.2.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Targeted WER</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.2.2.1" class="ltx_tr">
<td id="S4.T3.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.2.2.1.1.1" class="ltx_text" style="font-size:90%;">Baseline</span></td>
<td id="S4.T3.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.2.2.1.2.1" class="ltx_text" style="font-size:90%;">4.4</span></td>
<td id="S4.T3.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.2.2.1.3.1" class="ltx_text" style="font-size:90%;">17.5</span></td>
</tr>
<tr id="S4.T3.2.3.2" class="ltx_tr">
<td id="S4.T3.2.3.2.1" class="ltx_td ltx_align_center"><span id="S4.T3.2.3.2.1.1" class="ltx_text" style="font-size:90%;">Pure FL</span></td>
<td id="S4.T3.2.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T3.2.3.2.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">4.6</span></td>
<td id="S4.T3.2.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T3.2.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">16.1</span></td>
</tr>
<tr id="S4.T3.2.4.3" class="ltx_tr">
<td id="S4.T3.2.4.3.1" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.3.1.1" class="ltx_text" style="font-size:90%;">Static Ckpt Avg</span></td>
<td id="S4.T3.2.4.3.2" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.4</span></td>
<td id="S4.T3.2.4.3.3" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">16.1</span></td>
</tr>
<tr id="S4.T3.2.5.4" class="ltx_tr">
<td id="S4.T3.2.5.4.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.2.5.4.1.1" class="ltx_text" style="font-size:90%;">Dynamic Ckpt Avg</span></td>
<td id="S4.T3.2.5.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.2.5.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.4</span></td>
<td id="S4.T3.2.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.2.5.4.3.1" class="ltx_text" style="font-size:90%;">16.6</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.5.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>In a production-like setting, both techniques were able to restore the baseline overall WER, but Static Checkpoint Averaging gave better results on the targeted testset.</figcaption>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">As shown in Table <a href="#S4.T3" title="Table 3 ‣ 4.3 Catastrophic Forgetting ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, this approach was able improve model quality on the targeted testset, but we did observe the expected forgetting of the overall distribution. From the baseline, we saw that filtering on-device training examples to those containing targeted words allowed us to improve 8% relative on the targeted testset. However, we also saw a 4.5% regression on the overall WER, highlighting the necessity of techniques to mitigate catastrophic forgetting.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Checkpoint Averaging</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Both Static Checkpoint Averaging and Dynamic Checkpoint Averaging were able to bring us back to parity on the overall distribution, while still affording improvement on the targeted distribution (Table <a href="#S4.T3" title="Table 3 ‣ 4.3 Catastrophic Forgetting ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). In particular, with Static Checkpoint Averaging, we were able to achieve the 8% improvement on the targeted testset from pure FL, while keeping the WER on the overall distribution from the baseline.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Mixture of Centralized and Federated Training</h4>

<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.2.1.1" class="ltx_tr">
<th id="S4.T4.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Setup</span></th>
<th id="S4.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Overall WER</span></th>
<th id="S4.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.2.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Targeted WER</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.2.2.1" class="ltx_tr">
<td id="S4.T4.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.1.1.1" class="ltx_text" style="font-size:90%;">Baseline</span></td>
<td id="S4.T4.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.1.2.1" class="ltx_text" style="font-size:90%;">3.5</span></td>
<td id="S4.T4.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.1.3.1" class="ltx_text" style="font-size:90%;">16.6</span></td>
</tr>
<tr id="S4.T4.2.3.2" class="ltx_tr">
<td id="S4.T4.2.3.2.1" class="ltx_td ltx_align_center"><span id="S4.T4.2.3.2.1.1" class="ltx_text" style="font-size:90%;">FL-only</span></td>
<td id="S4.T4.2.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T4.2.3.2.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">4.4</span></td>
<td id="S4.T4.2.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T4.2.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">16.1</span></td>
</tr>
<tr id="S4.T4.2.4.3" class="ltx_tr">
<td id="S4.T4.2.4.3.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.4.3.1.1" class="ltx_text" style="font-size:90%;">FL + Centr. Mix</span></td>
<td id="S4.T4.2.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.4.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.5</span></td>
<td id="S4.T4.2.4.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">16.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.5.1.1" class="ltx_text ltx_font_bold">Table 4</span>: </span>After refreshing server-side training data, the baseline was much improved (3.5 WER), and regression from forgetting was much greater (20% relative). However, mixing federated and centralized training rounds restored the baseline Overall WER while keeping FL Targeted WER wins.</figcaption>
</figure>
<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">To test the technique of mixing centralized training in with the federated rounds, we first refreshed the model with more in-domain training data. This led to a much improved baseline, and a far greater regression after our targeted fine-tuning, as shown in Table <a href="#S4.T4" title="Table 4 ‣ 4.3.2 Mixture of Centralized and Federated Training ‣ 4.3 Catastrophic Forgetting ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. This 20% relative gap was greater than weight averaging techniques could address. However, once we mixed in centralized training simultaneously with the federated training rounds, we were able to achieve the best of both worlds: keep the wins on Targeted WER from targeted on-device training, while achieving the same best Overall WER from the server-only baseline.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Word Improvement</h3>

<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Error Correction Percent</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">To directly understand how much fine-tuning improved model recognition of each wordlist word, we computed an Error Correction Percent according to the following formula:</p>
</div>
<div id="S4.SS4.SSS1.p2" class="ltx_para">
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.1" class="ltx_Math" alttext="EC\%=\frac{Acc_{exp}-Acc_{base}}{1.0-Acc_{base}}" display="block"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><mrow id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml"><mi id="S4.E3.m1.1.1.2.2" xref="S4.E3.m1.1.1.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2.1" xref="S4.E3.m1.1.1.2.1.cmml">​</mo><mrow id="S4.E3.m1.1.1.2.3" xref="S4.E3.m1.1.1.2.3.cmml"><mi id="S4.E3.m1.1.1.2.3.2" xref="S4.E3.m1.1.1.2.3.2.cmml">C</mi><mo id="S4.E3.m1.1.1.2.3.1" xref="S4.E3.m1.1.1.2.3.1.cmml">%</mo></mrow></mrow><mo id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.cmml">=</mo><mfrac id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml"><mrow id="S4.E3.m1.1.1.3.2" xref="S4.E3.m1.1.1.3.2.cmml"><mrow id="S4.E3.m1.1.1.3.2.2" xref="S4.E3.m1.1.1.3.2.2.cmml"><mi id="S4.E3.m1.1.1.3.2.2.2" xref="S4.E3.m1.1.1.3.2.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.2.1" xref="S4.E3.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.2.2.3" xref="S4.E3.m1.1.1.3.2.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.2.1a" xref="S4.E3.m1.1.1.3.2.2.1.cmml">​</mo><msub id="S4.E3.m1.1.1.3.2.2.4" xref="S4.E3.m1.1.1.3.2.2.4.cmml"><mi id="S4.E3.m1.1.1.3.2.2.4.2" xref="S4.E3.m1.1.1.3.2.2.4.2.cmml">c</mi><mrow id="S4.E3.m1.1.1.3.2.2.4.3" xref="S4.E3.m1.1.1.3.2.2.4.3.cmml"><mi id="S4.E3.m1.1.1.3.2.2.4.3.2" xref="S4.E3.m1.1.1.3.2.2.4.3.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.2.4.3.1" xref="S4.E3.m1.1.1.3.2.2.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.2.2.4.3.3" xref="S4.E3.m1.1.1.3.2.2.4.3.3.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.2.4.3.1a" xref="S4.E3.m1.1.1.3.2.2.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.2.2.4.3.4" xref="S4.E3.m1.1.1.3.2.2.4.3.4.cmml">p</mi></mrow></msub></mrow><mo id="S4.E3.m1.1.1.3.2.1" xref="S4.E3.m1.1.1.3.2.1.cmml">−</mo><mrow id="S4.E3.m1.1.1.3.2.3" xref="S4.E3.m1.1.1.3.2.3.cmml"><mi id="S4.E3.m1.1.1.3.2.3.2" xref="S4.E3.m1.1.1.3.2.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.3.1" xref="S4.E3.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.2.3.3" xref="S4.E3.m1.1.1.3.2.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.3.1a" xref="S4.E3.m1.1.1.3.2.3.1.cmml">​</mo><msub id="S4.E3.m1.1.1.3.2.3.4" xref="S4.E3.m1.1.1.3.2.3.4.cmml"><mi id="S4.E3.m1.1.1.3.2.3.4.2" xref="S4.E3.m1.1.1.3.2.3.4.2.cmml">c</mi><mrow id="S4.E3.m1.1.1.3.2.3.4.3" xref="S4.E3.m1.1.1.3.2.3.4.3.cmml"><mi id="S4.E3.m1.1.1.3.2.3.4.3.2" xref="S4.E3.m1.1.1.3.2.3.4.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.3.4.3.1" xref="S4.E3.m1.1.1.3.2.3.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.2.3.4.3.3" xref="S4.E3.m1.1.1.3.2.3.4.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.3.4.3.1a" xref="S4.E3.m1.1.1.3.2.3.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.2.3.4.3.4" xref="S4.E3.m1.1.1.3.2.3.4.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.2.3.4.3.1b" xref="S4.E3.m1.1.1.3.2.3.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.2.3.4.3.5" xref="S4.E3.m1.1.1.3.2.3.4.3.5.cmml">e</mi></mrow></msub></mrow></mrow><mrow id="S4.E3.m1.1.1.3.3" xref="S4.E3.m1.1.1.3.3.cmml"><mn id="S4.E3.m1.1.1.3.3.2" xref="S4.E3.m1.1.1.3.3.2.cmml">1.0</mn><mo id="S4.E3.m1.1.1.3.3.1" xref="S4.E3.m1.1.1.3.3.1.cmml">−</mo><mrow id="S4.E3.m1.1.1.3.3.3" xref="S4.E3.m1.1.1.3.3.3.cmml"><mi id="S4.E3.m1.1.1.3.3.3.2" xref="S4.E3.m1.1.1.3.3.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.3.3.1" xref="S4.E3.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.3.3.3" xref="S4.E3.m1.1.1.3.3.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.3.3.1a" xref="S4.E3.m1.1.1.3.3.3.1.cmml">​</mo><msub id="S4.E3.m1.1.1.3.3.3.4" xref="S4.E3.m1.1.1.3.3.3.4.cmml"><mi id="S4.E3.m1.1.1.3.3.3.4.2" xref="S4.E3.m1.1.1.3.3.3.4.2.cmml">c</mi><mrow id="S4.E3.m1.1.1.3.3.3.4.3" xref="S4.E3.m1.1.1.3.3.3.4.3.cmml"><mi id="S4.E3.m1.1.1.3.3.3.4.3.2" xref="S4.E3.m1.1.1.3.3.3.4.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.3.3.4.3.1" xref="S4.E3.m1.1.1.3.3.3.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.3.3.4.3.3" xref="S4.E3.m1.1.1.3.3.3.4.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.3.3.4.3.1a" xref="S4.E3.m1.1.1.3.3.3.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.3.3.4.3.4" xref="S4.E3.m1.1.1.3.3.3.4.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.3.3.3.4.3.1b" xref="S4.E3.m1.1.1.3.3.3.4.3.1.cmml">​</mo><mi id="S4.E3.m1.1.1.3.3.3.4.3.5" xref="S4.E3.m1.1.1.3.3.3.4.3.5.cmml">e</mi></mrow></msub></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><eq id="S4.E3.m1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"></eq><apply id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2"><times id="S4.E3.m1.1.1.2.1.cmml" xref="S4.E3.m1.1.1.2.1"></times><ci id="S4.E3.m1.1.1.2.2.cmml" xref="S4.E3.m1.1.1.2.2">𝐸</ci><apply id="S4.E3.m1.1.1.2.3.cmml" xref="S4.E3.m1.1.1.2.3"><csymbol cd="latexml" id="S4.E3.m1.1.1.2.3.1.cmml" xref="S4.E3.m1.1.1.2.3.1">percent</csymbol><ci id="S4.E3.m1.1.1.2.3.2.cmml" xref="S4.E3.m1.1.1.2.3.2">𝐶</ci></apply></apply><apply id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3"><divide id="S4.E3.m1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.3"></divide><apply id="S4.E3.m1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.3.2"><minus id="S4.E3.m1.1.1.3.2.1.cmml" xref="S4.E3.m1.1.1.3.2.1"></minus><apply id="S4.E3.m1.1.1.3.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2"><times id="S4.E3.m1.1.1.3.2.2.1.cmml" xref="S4.E3.m1.1.1.3.2.2.1"></times><ci id="S4.E3.m1.1.1.3.2.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2.2">𝐴</ci><ci id="S4.E3.m1.1.1.3.2.2.3.cmml" xref="S4.E3.m1.1.1.3.2.2.3">𝑐</ci><apply id="S4.E3.m1.1.1.3.2.2.4.cmml" xref="S4.E3.m1.1.1.3.2.2.4"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.2.2.4.1.cmml" xref="S4.E3.m1.1.1.3.2.2.4">subscript</csymbol><ci id="S4.E3.m1.1.1.3.2.2.4.2.cmml" xref="S4.E3.m1.1.1.3.2.2.4.2">𝑐</ci><apply id="S4.E3.m1.1.1.3.2.2.4.3.cmml" xref="S4.E3.m1.1.1.3.2.2.4.3"><times id="S4.E3.m1.1.1.3.2.2.4.3.1.cmml" xref="S4.E3.m1.1.1.3.2.2.4.3.1"></times><ci id="S4.E3.m1.1.1.3.2.2.4.3.2.cmml" xref="S4.E3.m1.1.1.3.2.2.4.3.2">𝑒</ci><ci id="S4.E3.m1.1.1.3.2.2.4.3.3.cmml" xref="S4.E3.m1.1.1.3.2.2.4.3.3">𝑥</ci><ci id="S4.E3.m1.1.1.3.2.2.4.3.4.cmml" xref="S4.E3.m1.1.1.3.2.2.4.3.4">𝑝</ci></apply></apply></apply><apply id="S4.E3.m1.1.1.3.2.3.cmml" xref="S4.E3.m1.1.1.3.2.3"><times id="S4.E3.m1.1.1.3.2.3.1.cmml" xref="S4.E3.m1.1.1.3.2.3.1"></times><ci id="S4.E3.m1.1.1.3.2.3.2.cmml" xref="S4.E3.m1.1.1.3.2.3.2">𝐴</ci><ci id="S4.E3.m1.1.1.3.2.3.3.cmml" xref="S4.E3.m1.1.1.3.2.3.3">𝑐</ci><apply id="S4.E3.m1.1.1.3.2.3.4.cmml" xref="S4.E3.m1.1.1.3.2.3.4"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.2.3.4.1.cmml" xref="S4.E3.m1.1.1.3.2.3.4">subscript</csymbol><ci id="S4.E3.m1.1.1.3.2.3.4.2.cmml" xref="S4.E3.m1.1.1.3.2.3.4.2">𝑐</ci><apply id="S4.E3.m1.1.1.3.2.3.4.3.cmml" xref="S4.E3.m1.1.1.3.2.3.4.3"><times id="S4.E3.m1.1.1.3.2.3.4.3.1.cmml" xref="S4.E3.m1.1.1.3.2.3.4.3.1"></times><ci id="S4.E3.m1.1.1.3.2.3.4.3.2.cmml" xref="S4.E3.m1.1.1.3.2.3.4.3.2">𝑏</ci><ci id="S4.E3.m1.1.1.3.2.3.4.3.3.cmml" xref="S4.E3.m1.1.1.3.2.3.4.3.3">𝑎</ci><ci id="S4.E3.m1.1.1.3.2.3.4.3.4.cmml" xref="S4.E3.m1.1.1.3.2.3.4.3.4">𝑠</ci><ci id="S4.E3.m1.1.1.3.2.3.4.3.5.cmml" xref="S4.E3.m1.1.1.3.2.3.4.3.5">𝑒</ci></apply></apply></apply></apply><apply id="S4.E3.m1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.3.3"><minus id="S4.E3.m1.1.1.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.1"></minus><cn type="float" id="S4.E3.m1.1.1.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.2">1.0</cn><apply id="S4.E3.m1.1.1.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3"><times id="S4.E3.m1.1.1.3.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.3.1"></times><ci id="S4.E3.m1.1.1.3.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.3.2">𝐴</ci><ci id="S4.E3.m1.1.1.3.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3.3">𝑐</ci><apply id="S4.E3.m1.1.1.3.3.3.4.cmml" xref="S4.E3.m1.1.1.3.3.3.4"><csymbol cd="ambiguous" id="S4.E3.m1.1.1.3.3.3.4.1.cmml" xref="S4.E3.m1.1.1.3.3.3.4">subscript</csymbol><ci id="S4.E3.m1.1.1.3.3.3.4.2.cmml" xref="S4.E3.m1.1.1.3.3.3.4.2">𝑐</ci><apply id="S4.E3.m1.1.1.3.3.3.4.3.cmml" xref="S4.E3.m1.1.1.3.3.3.4.3"><times id="S4.E3.m1.1.1.3.3.3.4.3.1.cmml" xref="S4.E3.m1.1.1.3.3.3.4.3.1"></times><ci id="S4.E3.m1.1.1.3.3.3.4.3.2.cmml" xref="S4.E3.m1.1.1.3.3.3.4.3.2">𝑏</ci><ci id="S4.E3.m1.1.1.3.3.3.4.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3.4.3.3">𝑎</ci><ci id="S4.E3.m1.1.1.3.3.3.4.3.4.cmml" xref="S4.E3.m1.1.1.3.3.3.4.3.4">𝑠</ci><ci id="S4.E3.m1.1.1.3.3.3.4.3.5.cmml" xref="S4.E3.m1.1.1.3.3.3.4.3.5">𝑒</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">EC\%=\frac{Acc_{exp}-Acc_{base}}{1.0-Acc_{base}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS4.SSS1.p3" class="ltx_para">
<p id="S4.SS4.SSS1.p3.1" class="ltx_p">Each wordlist word appears in multiple testset examples; for each word, the accuracy <math id="S4.SS4.SSS1.p3.1.m1.1" class="ltx_Math" alttext="Acc" display="inline"><semantics id="S4.SS4.SSS1.p3.1.m1.1a"><mrow id="S4.SS4.SSS1.p3.1.m1.1.1" xref="S4.SS4.SSS1.p3.1.m1.1.1.cmml"><mi id="S4.SS4.SSS1.p3.1.m1.1.1.2" xref="S4.SS4.SSS1.p3.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p3.1.m1.1.1.1" xref="S4.SS4.SSS1.p3.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.SSS1.p3.1.m1.1.1.3" xref="S4.SS4.SSS1.p3.1.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p3.1.m1.1.1.1a" xref="S4.SS4.SSS1.p3.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.SSS1.p3.1.m1.1.1.4" xref="S4.SS4.SSS1.p3.1.m1.1.1.4.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p3.1.m1.1b"><apply id="S4.SS4.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1"><times id="S4.SS4.SSS1.p3.1.m1.1.1.1.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1.1"></times><ci id="S4.SS4.SSS1.p3.1.m1.1.1.2.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1.2">𝐴</ci><ci id="S4.SS4.SSS1.p3.1.m1.1.1.3.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1.3">𝑐</ci><ci id="S4.SS4.SSS1.p3.1.m1.1.1.4.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1.4">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p3.1.m1.1c">Acc</annotation></semantics></math> is the number of examples where the word was correctly recognized, normalized by the total number of examples containing the word. The EC% shows how many errors made by the baseline model were corrected by the fine-tuned model, as a ratio of the total number of errors for each word. For words with an EC% of 100%, fine-tuning corrected all errors made by the baseline.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2310.00141/assets/figures/ecp.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text ltx_font_bold">Fig. 4</span>: </span>Comparing number of errors before and after on-device fine-tuning, most words seen at least 100 times had all errors corrected after FT. This suggests that more training examples are needed for the remainder.</figcaption>
</figure>
<div id="S4.SS4.SSS1.p4" class="ltx_para">
<p id="S4.SS4.SSS1.p4.1" class="ltx_p">Looking closely at how each wordlist word was improved in Figure <a href="#S4.F4" title="Figure 4 ‣ 4.4.1 Error Correction Percent ‣ 4.4 Word Improvement ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we saw that the majority of words that were seen at least 100 times in training had 100% of their errors fixed by the experiment. Many words that were seen less frequently were also improved, but errors were not fixed in all their occurrences. This suggested that it was important to increase the frequency of training examples of words that we rarely saw, motivating our probabilistic sampling approach.</p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Probabilistic Sampling and Client Loss Weighting</h4>

<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.00141/assets/x6.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_img_square" width="207" height="220" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F5.sf1.3.2" class="ltx_text" style="font-size:80%;">Unique words over rounds</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.00141/assets/x7.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_img_square" width="207" height="220" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F5.sf2.3.2" class="ltx_text" style="font-size:80%;">Word count histogram</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text ltx_font_bold">Fig. 5</span>: </span>Probabilistic sampling was able to improve the number of unique words seen, as well as the number of words that were seen at least 100 times.</figcaption>
</figure>
<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">By adding Probabilistic Sampling during fine-tuning, we increased the number of unique words seen from around 100 to closer to 150. Additionally, we increased the number of words seen at least 100 times (Fig. <a href="#S4.F5" title="Figure 5 ‣ 4.4.2 Probabilistic Sampling and Client Loss Weighting ‣ 4.4 Word Improvement ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.2.1.1" class="ltx_tr">
<th id="S4.T5.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Setup</span></th>
<th id="S4.T5.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Overall WER</span></th>
<th id="S4.T5.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.2.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Tgt WER</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.2.2.1" class="ltx_tr">
<td id="S4.T5.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.2.2.1.1.1" class="ltx_text" style="font-size:90%;">Baseline</span></td>
<td id="S4.T5.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.2.2.1.2.1" class="ltx_text" style="font-size:90%;">4.4</span></td>
<td id="S4.T5.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.2.2.1.3.1" class="ltx_text" style="font-size:90%;">17.5</span></td>
</tr>
<tr id="S4.T5.2.3.2" class="ltx_tr">
<td id="S4.T5.2.3.2.1" class="ltx_td ltx_align_center"><span id="S4.T5.2.3.2.1.1" class="ltx_text" style="font-size:90%;">Simple Fine-Tuning</span></td>
<td id="S4.T5.2.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T5.2.3.2.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">4.6</span></td>
<td id="S4.T5.2.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T5.2.3.2.3.1" class="ltx_text" style="font-size:90%;">16.1</span></td>
</tr>
<tr id="S4.T5.2.4.3" class="ltx_tr">
<td id="S4.T5.2.4.3.1" class="ltx_td ltx_align_center"><span id="S4.T5.2.4.3.1.1" class="ltx_text" style="font-size:90%;">Static Ckpt Avg</span></td>
<td id="S4.T5.2.4.3.2" class="ltx_td ltx_align_center"><span id="S4.T5.2.4.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.4</span></td>
<td id="S4.T5.2.4.3.3" class="ltx_td ltx_align_center"><span id="S4.T5.2.4.3.3.1" class="ltx_text" style="font-size:90%;">16.1</span></td>
</tr>
<tr id="S4.T5.2.5.4" class="ltx_tr">
<td id="S4.T5.2.5.4.1" class="ltx_td ltx_align_center"><span id="S4.T5.2.5.4.1.1" class="ltx_text" style="font-size:90%;">Client Loss Weighting</span></td>
<td id="S4.T5.2.5.4.2" class="ltx_td ltx_align_center"><span id="S4.T5.2.5.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.4</span></td>
<td id="S4.T5.2.5.4.3" class="ltx_td ltx_align_center"><span id="S4.T5.2.5.4.3.1" class="ltx_text" style="font-size:90%;">16.0</span></td>
</tr>
<tr id="S4.T5.2.6.5" class="ltx_tr">
<td id="S4.T5.2.6.5.1" class="ltx_td ltx_align_center"><span id="S4.T5.2.6.5.1.1" class="ltx_text" style="font-size:90%;">Probabilistic Sampling</span></td>
<td id="S4.T5.2.6.5.2" class="ltx_td ltx_align_center"><span id="S4.T5.2.6.5.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">4.6</span></td>
<td id="S4.T5.2.6.5.3" class="ltx_td ltx_align_center"><span id="S4.T5.2.6.5.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">15.8</span></td>
</tr>
<tr id="S4.T5.2.7.6" class="ltx_tr">
<td id="S4.T5.2.7.6.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.2.7.6.1.1" class="ltx_text" style="font-size:90%;">Prob Samp + St Ckpt Avg</span></td>
<td id="S4.T5.2.7.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.2.7.6.2.1" class="ltx_text" style="font-size:90%;">4.5</span></td>
<td id="S4.T5.2.7.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.2.7.6.3.1" class="ltx_text" style="font-size:90%;">15.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.5.1.1" class="ltx_text ltx_font_bold">Table 5</span>: </span>Client Loss Weighting was able to slightly improve our already fine-tuned targeted WER from 16.1 to 16.0. Probabilistic Sampling did even better, improving our targeted WER to 15.8. The WER on the overall distribution can be restored by reintroducing checkpoint averaging.</figcaption>
</figure>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<p id="S4.SS4.SSS2.p2.1" class="ltx_p">As shown in Table <a href="#S4.T5" title="Table 5 ‣ 4.4.2 Probabilistic Sampling and Client Loss Weighting ‣ 4.4 Word Improvement ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, in comparison with our previous best fine-tuned result of 16.1, using Client Loss Weighting was able to give us a small improvement to 16.0. Probabilistic Sampling gave more significant wins, bringing our targeted WER down to 15.8.</p>
</div>
</section>
<section id="S4.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.3 </span>Contact Names</h4>

<div id="S4.SS4.SSS3.p1" class="ltx_para">
<p id="S4.SS4.SSS3.p1.1" class="ltx_p">As an additional application, we turned these techniques towards a related domain. Rather than learning fresh terms, we experimented with whether we could improve recognition of another class of commonly misrecognized terms: names from users’ contacts lists. Names are difficult to transcribe correctly due to variety and alternate spellings, and benefit greatly from a diverse and fresh training corpus.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.2.1.1" class="ltx_tr">
<th id="S4.T6.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Setup</span></th>
<th id="S4.T6.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Overall WER</span></th>
<th id="S4.T6.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.2.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Contact Names WER</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.2.2.1" class="ltx_tr">
<td id="S4.T6.2.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.2.2.1.1.1" class="ltx_text" style="font-size:90%;">Baseline</span></td>
<td id="S4.T6.2.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.2.2.1.2.1" class="ltx_text" style="font-size:90%;">3.8</span></td>
<td id="S4.T6.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.2.2.1.3.1" class="ltx_text" style="font-size:90%;">5.7</span></td>
</tr>
<tr id="S4.T6.2.3.2" class="ltx_tr">
<td id="S4.T6.2.3.2.1" class="ltx_td ltx_align_center"><span id="S4.T6.2.3.2.1.1" class="ltx_text" style="font-size:90%;">Fresh Terms Filter</span></td>
<td id="S4.T6.2.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T6.2.3.2.2.1" class="ltx_text" style="font-size:90%;">3.8</span></td>
<td id="S4.T6.2.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T6.2.3.2.3.1" class="ltx_text" style="font-size:90%;">5.5</span></td>
</tr>
<tr id="S4.T6.2.4.3" class="ltx_tr">
<td id="S4.T6.2.4.3.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.2.4.3.1.1" class="ltx_text" style="font-size:90%;">Names Filter</span></td>
<td id="S4.T6.2.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.2.4.3.2.1" class="ltx_text" style="font-size:90%;">3.8</span></td>
<td id="S4.T6.2.4.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.2.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">5.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.5.1.1" class="ltx_text ltx_font_bold">Table 6</span>: </span>Contact name recognition was improved by the above techniques. Using a names wordlist for filtering instead gave even better results, without harming the Overall WER.</figcaption>
</figure>
<div id="S4.SS4.SSS3.p2" class="ltx_para">
<p id="S4.SS4.SSS3.p2.1" class="ltx_p">Even using just the fresh wordlist filtering, training in FL was sufficient to improve the WER on our Contact Names testset from 5.7 to 5.5, as shown in Table <a href="#S4.T6" title="Table 6 ‣ 4.4.3 Contact Names ‣ 4.4 Word Improvement ‣ 4 Experimental Results ‣ The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Though we did not target any names with our filtering, the general exposure to fresh training examples was able to improve the WER. We further improved this by replacing the wordlist with a list of the top 1000 baby names in each the US, China, and India. With this new setting, we reached 5.4 WER on the testset, a 5% relative improvement.</p>
</div>
<div id="S4.SS4.SSS3.p3" class="ltx_para">
<p id="S4.SS4.SSS3.p3.1" class="ltx_p">This demonstrates that the proposed techniques can be applied to other settings, such as learning words of a certain domain, while maintaining quality on the overall distribution.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we explored how user corrections can be leveraged to improve ASR model quality, particularly on fresh terms not available during model training, or on terms that the ASR model tends to get wrong. The naive approach of training directly on novel on-device user data sources posed a number of difficulties, including the challenge of targeting these inherently long-tail words, as well as catastrophic forgetting leading to degradation of model quality on the overall distribution.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">To address these issues, we applied a number of techniques, such as checkpoint averaging, mixing centralized and decentralized training, and probabilistic sampling. Finally, we experimentally demonstrated the potential of this technique, both for the original problem space of learning fresh terms, as well as in adapting the model to other difficult domains, such as names. We hope that these findings may lead to further exploration of adapting ASR models to an ever-changing language corpus.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We thank Yonghui Xiao, Andrew Hard, Sean Augenstein, Khe Chai Sim, Guru Prakash, and Tien-Ju Yang for their valuable contributions to this work.</p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards federated
learning at scale: System design,” 2019.

<div class="ltx_pagination ltx_role_newpage"></div>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
H. B. McMahan, E. Moore <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Communication-Efficient Learning of
Deep Networks from Decentralized Data,” in <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">Proceedings of the 20th
International Conference on Artificial Intelligence and Statistics, AISTATS
2017, 20-22 April 2017, Fort Lauderdale, FL, USA</em>, ser. Proceedings of
Machine Learning Research, A. Singh and X. J. Zhu, Eds., vol. 54.   PMLR, 2017, pp. 1273–1282.
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://proceedings.mlr.press/v54/mcmahan17a.html</span>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J. Xue, J. Han, T. Zheng <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Hard sample mining for the improved
retraining of automatic speech recognition,” 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
L. Qu, C. Weber, and S. Wermter, “Emphasizing unseen words: New vocabulary
acquisition for end-to-end speech recognition,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Neural Networks</em>, vol.
161, pp. 494–504, apr 2023.
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1016%2Fj.neunet.2023.01.027</span>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
K. C. Sim, F. Beaufays, A. Benard <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Personalization of
end-to-end speech recognition on mobile devices for named entities,” 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
U. Alon, G. Pundak, and T. N. Sainath, “Contextual speech recognition with
difficult negative training examples,” 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
R. M. French, “Catastrophic forgetting in connectionist networks,”
<em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Trends in Cognitive Sciences</em>, vol. 3, no. 4, pp. 128–135, 1999.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. McCloskey and N. J. Cohen, “Catastrophic interference in connectionist
networks: The sequential learning problem,” ser. Psychology of Learning and
Motivation, G. H. Bower, Ed.   Academic
Press, 1989, vol. 24, pp. 109–165.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. V. Eeckt and H. V. hamme, “Weight averaging: A simple yet effective method
to overcome catastrophic forgetting in automatic speech recognition,” 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
S. Augenstein, A. Hard, L. Ning <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Mixed federated learning:
Joint decentralized and centralized learning,” 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
W. Zhu, P. Kairouz, B. McMahan <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated heavy hitters
discovery with differential privacy,” 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A. van den Oord, Y. Li, I. Babuschkin <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Parallel wavenet: Fast
high-fidelity speech synthesis,” 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
A. Graves, A. Mohamed, and G. Hinton, “Speech Recognition with Deep
Recurrent Neural Networks,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">2013 IEEE International Conference on
Acoustics, Speech and Signal Processing</em>, 2013, pp. 6645–6649.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
T. N. Sainath, Y. He, B. Li <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A streaming on-device end-to-end
model surpassing server-side conventional model quality and latency,” 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. He, T. N. Sainath, R. Prabhavalkar <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Streaming end-to-end
speech recognition for mobile devices,” 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. Gulati, C.-C. Chiu, J. Qin <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">et al.</em>, Eds., <em id="bib.bib16.2.2" class="ltx_emph ltx_font_italic">Conformer:
Convolution-augmented Transformer for Speech Recognition</em>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
B. Li, A. Gulati, J. Yu <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A better and faster end-to-end model
for streaming asr,” 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
T. N. Sainath, Y. He, A. Narayanan <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “An efficient streaming
non-recurrent on-device end-to-end model with improvements to rare-word
modeling,” in <em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic">Proc. of INTERSPEECH</em>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Z. Allen-Zhu, Y. Li, and Y. Liang, “Learning and generalization in
overparameterized neural networks, going beyond two layers,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">CoRR</em>,
vol. abs/1811.04918, 2018. <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1811.04918</span>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
B. Neyshabur, Z. Li, S. Bhojanapalli <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards understanding the
role of over-parametrization in generalization of neural networks,”
<em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1805.12076, 2018.
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1805.12076</span>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
R. Prabhavalkar, T. N. Sainath, Y. Wu <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Minimum word error rate
training for attention-based sequence-to-sequence models,” 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. Misra, D. Hwang, Z. Huo <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A Comparison of Supervised and
Unsupervised Pre-Training of End-to-End Models,” in <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">Proc. Interspeech
2021</em>, 2021, pp. 731–735.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
A. Narayanan, R. Prabhavalkar, C.-C. Chiu <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Recognizing
long-form speech using streaming end-to-end models,” in <em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic">IEEE
Automatic Speech Recognition and Understanding Workshop, ASRU 2019,
Singapore, December 14-18, 2019</em>.   IEEE, 2019, pp. 920–927.
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1109/ASRU46091.2019.9003913</span>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Google, “Artificial intelligence at Google: Our principles.”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://ai.google/principles/</span>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.00140" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.00141" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.00141">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.00141" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.00142" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 03:09:06 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
