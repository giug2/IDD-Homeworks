<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.09856] Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this.</title><meta property="og:description" content="Federated learning (FL), as an emerging artificial intelligence (AI) approach, enables decentralized model training across multiple devices without exposing their local training data. FL has been increasingly gaining p…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this.">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this.">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.09856">

<!--Generated on Thu Feb 29 07:05:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning,  fault tolerance,  unreliable clients,  robustness,  rural environment
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients
<span id="id1.id1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>Identify applicable funding agency here. If none, delete this.</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Victoria Huang1, Shaleeza Sohail2, Michael Mayo3, Tania Lorido Botran4, Mark Rodrigues3, 
<br class="ltx_break">Chris Anderson3, Melanie Ooi3
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">1<span id="id2.1.id1" class="ltx_text ltx_font_italic">National Institute of Water and Atmospheric Research</span>, Wellington, New Zealand 
<br class="ltx_break">victoria.huang@niwa.co.nz
</span>
<span class="ltx_contact ltx_role_affiliation">2<span id="id3.2.id1" class="ltx_text ltx_font_italic">University of Newcastle</span>, New South Wales, Australia 
<br class="ltx_break">shaleeza.sohail@newcastle.edu.au
</span>
<span class="ltx_contact ltx_role_affiliation">3<span id="id4.3.id1" class="ltx_text ltx_font_italic">University of Waikato</span>,
Hamilton, New Zealand 
<br class="ltx_break">Michael.mayo, Mark.rodrigues, Chris.anderson, Melanie.ooi@waikato.ac.nz
</span>
<span class="ltx_contact ltx_role_affiliation">4<span id="id5.4.id1" class="ltx_text ltx_font_italic">Roblox</span>, California, United States 
<br class="ltx_break">tbotran@roblox.com
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Federated learning (FL), as an emerging artificial intelligence (AI) approach, enables decentralized model training across multiple devices without exposing their local training data. FL has been increasingly gaining popularity in both academia and industry. While research works have been proposed to improve the fault tolerance of FL, the real impact of unreliable devices (e.g., dropping out, misconfiguration, poor data quality) in real-world applications is not fully investigated. <span id="id6.id1.1" class="ltx_text" style="color:#000000;">We carefully chose two representative, real-world classification problems with a limited numbers of clients to better analyze FL fault tolerance. Contrary to the intuition, simple FL algorithms can perform surprisingly well in the presence of unreliable clients.</span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning, fault tolerance, unreliable clients, robustness, rural environment

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As an emerging learning paradigm, federated learning (FL) provides a new training method that allows data owners (also called <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">clients</em>) to enjoy the performance of a jointly trained model without violating their data privacy. Whereas traditional machine learning (ML) follows a data-to-model approach (i.e. training data from various clients need to be centralized in one node), FL takes an opposite model-to-data approach. In FL, models trained by clients using their local data are shared to a centralized node (called <em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">server</em>), as opposed to the data. The server updates a global model by aggregating the received local models. The global model will be broadcasted to clients to replace their local models. This means that data never leaves the clients, thus preserving data privacy. Meanwhile, the local sites can take advantage of the improved accuracy resulting from the aggregated model trained across all of the data as opposed to local data only. FL therefore addresses data privacy and data sharing dilemma while potentially offering superior model performance. Given its promising features, FL has attracted much research attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Although FL has great potential in real-world applications, there have been very few FL applications reported at the production level, with most of the work being at a proof-of-concept prototype level with synthetic datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Meanwhile, implementing FL in a rural environment introduces multiple further complications,
all of which are currently active targets for research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. The complications can be broadly grouped into the following issues:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">reducing communication overhead (e.g., using model compression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>).</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">improving energy efficiency (e.g., modifying conventional FL algorithms to save 59% energy cost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>).</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">heterogeneity of clients and where to place computation (e.g., some of the model aggregation can be performed at the edge servers to reduce the communication overhead and also the load on the cloud server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>).</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text" style="color:#000000;">impact of unreliable clients that drop in and out of the federation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> or send low-quality data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</span></p>
</div>
</li>
</ul>
<p id="S1.p2.2" class="ltx_p">This last problem (unreliable clients) is largely unaddressed in the literature and posed as an open research challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We therefore focus our study in this paper via a systematic evaluation on the robustness of FL to unreliable clients in rural applications. Note that in this paper, we consider different scenarios of unreliable clients related to <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">infrastructure-level errors</span> and <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">ML-specific inconsistencies</span>:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">Infrastructure-level errors:</p>
<ul id="S1.I2.i1.I1" class="ltx_itemize">
<li id="S1.I2.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I2.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S1.I2.i1.I1.i1.p1" class="ltx_para">
<p id="S1.I2.i1.I1.i1.p1.1" class="ltx_p"><span id="S1.I2.i1.I1.i1.p1.1.1" class="ltx_text" style="color:#000000;">Clients randomly and completely drop in and out of the federation. This can be caused by unstable power supplies when clients are deployed in isolated areas. Clients may sometimes drop out during the training process and join back later.</span></p>
</div>
</li>
<li id="S1.I2.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I2.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S1.I2.i1.I1.i2.p1" class="ltx_para">
<p id="S1.I2.i1.I1.i2.p1.1" class="ltx_p"><span id="S1.I2.i1.I1.i2.p1.1.1" class="ltx_text" style="color:#000000;">Clients randomly and partially drop in and out. Compared to completely dropping out, clients may sometimes fail to upload their locally trained models but they are still able to receive the aggregated global model or vice versa. This can happen when the network connection is unreliable.</span></p>
</div>
</li>
</ul>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">ML-specific inconsistencies:</p>
<ul id="S1.I2.i2.I1" class="ltx_itemize">
<li id="S1.I2.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I2.i2.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S1.I2.i2.I1.i1.p1" class="ltx_para">
<p id="S1.I2.i2.I1.i1.p1.1" class="ltx_p">Client misconfiguration. For example, the hyperparameters (e.g., learning rate) of one client are misconfigured and different from others.</p>
</div>
</li>
<li id="S1.I2.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S1.I2.i2.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S1.I2.i2.I1.i2.p1" class="ltx_para">
<p id="S1.I2.i2.I1.i2.p1.1" class="ltx_p"><span id="S1.I2.i2.I1.i2.p1.1.1" class="ltx_text" style="color:#000000;">Low-quality data. For example, the training data collected by the client may be low-quality due to hardware constraints or mislabelled due to human mistakes.</span></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text" style="color:#000000;">The ultimate impact of unreliable clients on a particular system will depend on other factors, such as the number of clients or the size of local dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. There are efforts to establish metrics that quantify the influence of individual clients on the model outcome, but such metric fails to capture the overall reliability of FL algorithms<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</span>
<span id="S1.p4.1.2" class="ltx_text" style="color:#000000;">Moreover, applications reported in the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> usually involve hundreds of clients. It should be noted that in rural settings, there may only be a very limited number of clients involved, making the impact of unreliable clients potentially significant. Thus, we carefully select our target scenarios that involve <span id="S1.p4.1.2.1" class="ltx_text ltx_font_italic">a limited number of clients.</span></span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this paper, we develop a prototype system building on federated Function-as-a-Service using funcX <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, a federated serverless framework.
<span id="S1.p5.1.1" class="ltx_text" style="color:#000000;">Two real-world applications have been investigated: weeds detection in precision agriculture in Section <a href="#S3" title="III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> and wildlife detection in camera traps in Section <a href="#S4" title="IV FL in Camera traps ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</span>
In particular, unreliable clients with infrastructure-level errors will be studied in precision agriculture and ML-specific inconsistencies will be investigated in wildlife detection. <span id="S1.p5.1.2" class="ltx_text" style="color:#000000;">To provide representative results, each scenario considers a very low number of clients (between 3 to 6).</span> Extensive experiments have been conducted and showed that even a simple FL algorithm is surprisingly robust to unreliable clients. <em id="S1.p5.1.3" class="ltx_emph ltx_font_italic">By analysing FL robustness against unreliable clients, we aim to understand its impact in real-world applications. This will enable us to evaluate the level of sophistication required of FL algorithms for rural deployment. </em></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Problem Formulation</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The two target scenarios belong to a classification problem with a set of <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">K</annotation></semantics></math> data sources (or clients), all scattered over different locations. The statistical properties of each data source are not homogeneous, e.g. different class distributions. Each client is in charge of collecting and storing large amounts of local data. The traditional approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, named centralized approach in terms of data collection and model training, involves transferring all the data from each of the clients to a single server that will perform the training. This comes with a high network cost and potentially violates data sovereignty <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">To circumvent these drawbacks, FL proposes splitting the training between clients and the server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. The algorithm is fairly simple: it involves an infinite communication loop between the server and the clients. The server trains a generated (shared) model. A set of clients download a copy (weights) of the shared model and perform local updates leveraging private data, based on some optimization algorithm like stochastic gradient descent. Periodically, clients send a summary of the changes made to the local model (weights of the trained neural network) back to the server. Once it has gathered all the data, the server utilizes some aggregation techniques to perform an update to its shared model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.</p>
</div>
<section id="S2.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_italic ltx_title_subsection">Federated Averaging Algorithm</h3>

<div id="S2.SSx1.p1" class="ltx_para">
<p id="S2.SSx1.p1.5" class="ltx_p">A very popular aggregation technique is called <span id="S2.SSx1.p1.5.1" class="ltx_text ltx_font_bold">Federated Averaging</span> algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. In this case, the server computes the average of the updates received from each client. The full pseudocode is depicted in Algorithm <a href="#alg1" title="In Federated Averaging Algorithm ‣ II Problem Formulation ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. At the server, <math id="S2.SSx1.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SSx1.p1.1.m1.1a"><mi id="S2.SSx1.p1.1.m1.1.1" xref="S2.SSx1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p1.1.m1.1b"><ci id="S2.SSx1.p1.1.m1.1.1.cmml" xref="S2.SSx1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p1.1.m1.1c">K</annotation></semantics></math> clients are selected, which are indexed by a variable <math id="S2.SSx1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SSx1.p1.2.m2.1a"><mi id="S2.SSx1.p1.2.m2.1.1" xref="S2.SSx1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p1.2.m2.1b"><ci id="S2.SSx1.p1.2.m2.1.1.cmml" xref="S2.SSx1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p1.2.m2.1c">k</annotation></semantics></math>. In parallel, all clients update the generic model weights according to the <em id="S2.SSx1.p1.5.2" class="ltx_emph ltx_font_italic">ClientUpdate</em> function, which returns the trained weights <math id="S2.SSx1.p1.3.m3.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SSx1.p1.3.m3.1a"><mi id="S2.SSx1.p1.3.m3.1.1" xref="S2.SSx1.p1.3.m3.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p1.3.m3.1b"><ci id="S2.SSx1.p1.3.m3.1.1.cmml" xref="S2.SSx1.p1.3.m3.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p1.3.m3.1c">w</annotation></semantics></math> back to the server. Finally, the server computes the average of all weights <math id="S2.SSx1.p1.4.m4.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SSx1.p1.4.m4.1a"><mi id="S2.SSx1.p1.4.m4.1.1" xref="S2.SSx1.p1.4.m4.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p1.4.m4.1b"><ci id="S2.SSx1.p1.4.m4.1.1.cmml" xref="S2.SSx1.p1.4.m4.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p1.4.m4.1c">w</annotation></semantics></math> received from the <math id="S2.SSx1.p1.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SSx1.p1.5.m5.1a"><mi id="S2.SSx1.p1.5.m5.1.1" xref="S2.SSx1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p1.5.m5.1b"><ci id="S2.SSx1.p1.5.m5.1.1.cmml" xref="S2.SSx1.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p1.5.m5.1c">K</annotation></semantics></math> clients. The average of the weights is regarded as the new set of weights for the generic model. Despite its clear advantages, Federated Averaging was not designed with specific fault tolerance features that might lead to sub-optimal model performance. Unreliable clients can be classified into two main types: those with infrastructure-level errors (e.g. faulty network), and the second involves ML-specific inconsistencies (flipped labels, misconfigured hyperparameters such as learning rate, other errors in collected data).</p>
</div>
<figure id="alg1" class="ltx_float ltx_algorithm">
<div id="alg1.30" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="alg1.30.21" class="ltx_listingline">

</div>
<div id="alg1.30.22" class="ltx_listingline">

<span id="alg1.30.22.1" class="ltx_text ltx_font_bold">Server executes</span> <em id="alg1.30.22.2" class="ltx_emph ltx_font_typewriter">(<em id="alg1.30.22.2.1" class="ltx_emph ltx_font_serif ltx_font_italic"></em>)</em><span id="alg1.30.22.3" class="ltx_text ltx_font_bold">:</span> 
</div>
<div id="alg1.11.1" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
initialize <math id="alg1.11.1.m1.1" class="ltx_Math" alttext="w_{0}" display="inline"><semantics id="alg1.11.1.m1.1a"><msub id="alg1.11.1.m1.1.1" xref="alg1.11.1.m1.1.1.cmml"><mi id="alg1.11.1.m1.1.1.2" xref="alg1.11.1.m1.1.1.2.cmml">w</mi><mn id="alg1.11.1.m1.1.1.3" xref="alg1.11.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.11.1.m1.1b"><apply id="alg1.11.1.m1.1.1.cmml" xref="alg1.11.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.11.1.m1.1.1.1.cmml" xref="alg1.11.1.m1.1.1">subscript</csymbol><ci id="alg1.11.1.m1.1.1.2.cmml" xref="alg1.11.1.m1.1.1.2">𝑤</ci><cn type="integer" id="alg1.11.1.m1.1.1.3.cmml" xref="alg1.11.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.11.1.m1.1c">w_{0}</annotation></semantics></math>
</div>
<div id="alg1.12.2" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.12.2.2" class="ltx_text ltx_font_bold">for</span> <em id="alg1.12.2.1" class="ltx_emph ltx_font_italic">each round <math id="alg1.12.2.1.m1.3" class="ltx_Math" alttext="t=1,2,\ldots" display="inline"><semantics id="alg1.12.2.1.m1.3a"><mrow id="alg1.12.2.1.m1.3.4" xref="alg1.12.2.1.m1.3.4.cmml"><mi id="alg1.12.2.1.m1.3.4.2" xref="alg1.12.2.1.m1.3.4.2.cmml">t</mi><mo id="alg1.12.2.1.m1.3.4.1" xref="alg1.12.2.1.m1.3.4.1.cmml">=</mo><mrow id="alg1.12.2.1.m1.3.4.3.2" xref="alg1.12.2.1.m1.3.4.3.1.cmml"><mn id="alg1.12.2.1.m1.1.1" xref="alg1.12.2.1.m1.1.1.cmml">1</mn><mo id="alg1.12.2.1.m1.3.4.3.2.1" xref="alg1.12.2.1.m1.3.4.3.1.cmml">,</mo><mn id="alg1.12.2.1.m1.2.2" xref="alg1.12.2.1.m1.2.2.cmml">2</mn><mo id="alg1.12.2.1.m1.3.4.3.2.2" xref="alg1.12.2.1.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.12.2.1.m1.3.3" xref="alg1.12.2.1.m1.3.3.cmml">…</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.12.2.1.m1.3b"><apply id="alg1.12.2.1.m1.3.4.cmml" xref="alg1.12.2.1.m1.3.4"><eq id="alg1.12.2.1.m1.3.4.1.cmml" xref="alg1.12.2.1.m1.3.4.1"></eq><ci id="alg1.12.2.1.m1.3.4.2.cmml" xref="alg1.12.2.1.m1.3.4.2">𝑡</ci><list id="alg1.12.2.1.m1.3.4.3.1.cmml" xref="alg1.12.2.1.m1.3.4.3.2"><cn type="integer" id="alg1.12.2.1.m1.1.1.cmml" xref="alg1.12.2.1.m1.1.1">1</cn><cn type="integer" id="alg1.12.2.1.m1.2.2.cmml" xref="alg1.12.2.1.m1.2.2">2</cn><ci id="alg1.12.2.1.m1.3.3.cmml" xref="alg1.12.2.1.m1.3.3">…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.12.2.1.m1.3c">t=1,2,\ldots</annotation></semantics></math></em> <span id="alg1.12.2.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.13.3" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.13.3.m1.2" class="ltx_Math" alttext="m\leftarrow max(C\cdot K,1)" display="inline"><semantics id="alg1.13.3.m1.2a"><mrow id="alg1.13.3.m1.2.2" xref="alg1.13.3.m1.2.2.cmml"><mi id="alg1.13.3.m1.2.2.3" xref="alg1.13.3.m1.2.2.3.cmml">m</mi><mo stretchy="false" id="alg1.13.3.m1.2.2.2" xref="alg1.13.3.m1.2.2.2.cmml">←</mo><mrow id="alg1.13.3.m1.2.2.1" xref="alg1.13.3.m1.2.2.1.cmml"><mi id="alg1.13.3.m1.2.2.1.3" xref="alg1.13.3.m1.2.2.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.13.3.m1.2.2.1.2" xref="alg1.13.3.m1.2.2.1.2.cmml">​</mo><mi id="alg1.13.3.m1.2.2.1.4" xref="alg1.13.3.m1.2.2.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.13.3.m1.2.2.1.2a" xref="alg1.13.3.m1.2.2.1.2.cmml">​</mo><mi id="alg1.13.3.m1.2.2.1.5" xref="alg1.13.3.m1.2.2.1.5.cmml">x</mi><mo lspace="0em" rspace="0em" id="alg1.13.3.m1.2.2.1.2b" xref="alg1.13.3.m1.2.2.1.2.cmml">​</mo><mrow id="alg1.13.3.m1.2.2.1.1.1" xref="alg1.13.3.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="alg1.13.3.m1.2.2.1.1.1.2" xref="alg1.13.3.m1.2.2.1.1.2.cmml">(</mo><mrow id="alg1.13.3.m1.2.2.1.1.1.1" xref="alg1.13.3.m1.2.2.1.1.1.1.cmml"><mi id="alg1.13.3.m1.2.2.1.1.1.1.2" xref="alg1.13.3.m1.2.2.1.1.1.1.2.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="alg1.13.3.m1.2.2.1.1.1.1.1" xref="alg1.13.3.m1.2.2.1.1.1.1.1.cmml">⋅</mo><mi id="alg1.13.3.m1.2.2.1.1.1.1.3" xref="alg1.13.3.m1.2.2.1.1.1.1.3.cmml">K</mi></mrow><mo id="alg1.13.3.m1.2.2.1.1.1.3" xref="alg1.13.3.m1.2.2.1.1.2.cmml">,</mo><mn id="alg1.13.3.m1.1.1" xref="alg1.13.3.m1.1.1.cmml">1</mn><mo stretchy="false" id="alg1.13.3.m1.2.2.1.1.1.4" xref="alg1.13.3.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.13.3.m1.2b"><apply id="alg1.13.3.m1.2.2.cmml" xref="alg1.13.3.m1.2.2"><ci id="alg1.13.3.m1.2.2.2.cmml" xref="alg1.13.3.m1.2.2.2">←</ci><ci id="alg1.13.3.m1.2.2.3.cmml" xref="alg1.13.3.m1.2.2.3">𝑚</ci><apply id="alg1.13.3.m1.2.2.1.cmml" xref="alg1.13.3.m1.2.2.1"><times id="alg1.13.3.m1.2.2.1.2.cmml" xref="alg1.13.3.m1.2.2.1.2"></times><ci id="alg1.13.3.m1.2.2.1.3.cmml" xref="alg1.13.3.m1.2.2.1.3">𝑚</ci><ci id="alg1.13.3.m1.2.2.1.4.cmml" xref="alg1.13.3.m1.2.2.1.4">𝑎</ci><ci id="alg1.13.3.m1.2.2.1.5.cmml" xref="alg1.13.3.m1.2.2.1.5">𝑥</ci><interval closure="open" id="alg1.13.3.m1.2.2.1.1.2.cmml" xref="alg1.13.3.m1.2.2.1.1.1"><apply id="alg1.13.3.m1.2.2.1.1.1.1.cmml" xref="alg1.13.3.m1.2.2.1.1.1.1"><ci id="alg1.13.3.m1.2.2.1.1.1.1.1.cmml" xref="alg1.13.3.m1.2.2.1.1.1.1.1">⋅</ci><ci id="alg1.13.3.m1.2.2.1.1.1.1.2.cmml" xref="alg1.13.3.m1.2.2.1.1.1.1.2">𝐶</ci><ci id="alg1.13.3.m1.2.2.1.1.1.1.3.cmml" xref="alg1.13.3.m1.2.2.1.1.1.1.3">𝐾</ci></apply><cn type="integer" id="alg1.13.3.m1.1.1.cmml" xref="alg1.13.3.m1.1.1">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.13.3.m1.2c">m\leftarrow max(C\cdot K,1)</annotation></semantics></math>
</div>
<div id="alg1.15.5" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.14.4.m1.1" class="ltx_Math" alttext="S_{t}\leftarrow" display="inline"><semantics id="alg1.14.4.m1.1a"><mrow id="alg1.14.4.m1.1.1" xref="alg1.14.4.m1.1.1.cmml"><msub id="alg1.14.4.m1.1.1.2" xref="alg1.14.4.m1.1.1.2.cmml"><mi id="alg1.14.4.m1.1.1.2.2" xref="alg1.14.4.m1.1.1.2.2.cmml">S</mi><mi id="alg1.14.4.m1.1.1.2.3" xref="alg1.14.4.m1.1.1.2.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.14.4.m1.1.1.1" xref="alg1.14.4.m1.1.1.1.cmml">←</mo><mi id="alg1.14.4.m1.1.1.3" xref="alg1.14.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.14.4.m1.1b"><apply id="alg1.14.4.m1.1.1.cmml" xref="alg1.14.4.m1.1.1"><ci id="alg1.14.4.m1.1.1.1.cmml" xref="alg1.14.4.m1.1.1.1">←</ci><apply id="alg1.14.4.m1.1.1.2.cmml" xref="alg1.14.4.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.14.4.m1.1.1.2.1.cmml" xref="alg1.14.4.m1.1.1.2">subscript</csymbol><ci id="alg1.14.4.m1.1.1.2.2.cmml" xref="alg1.14.4.m1.1.1.2.2">𝑆</ci><ci id="alg1.14.4.m1.1.1.2.3.cmml" xref="alg1.14.4.m1.1.1.2.3">𝑡</ci></apply><csymbol cd="latexml" id="alg1.14.4.m1.1.1.3.cmml" xref="alg1.14.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.14.4.m1.1c">S_{t}\leftarrow</annotation></semantics></math> (random set of <math id="alg1.15.5.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="alg1.15.5.m2.1a"><mi id="alg1.15.5.m2.1.1" xref="alg1.15.5.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="alg1.15.5.m2.1b"><ci id="alg1.15.5.m2.1.1.cmml" xref="alg1.15.5.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.15.5.m2.1c">m</annotation></semantics></math> clients)
</div>
<div id="alg1.16.6" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.16.6.2" class="ltx_text ltx_font_bold">for</span> <em id="alg1.16.6.1" class="ltx_emph ltx_font_italic">each client <math id="alg1.16.6.1.m1.1" class="ltx_Math" alttext="k\in S_{t}" display="inline"><semantics id="alg1.16.6.1.m1.1a"><mrow id="alg1.16.6.1.m1.1.1" xref="alg1.16.6.1.m1.1.1.cmml"><mi id="alg1.16.6.1.m1.1.1.2" xref="alg1.16.6.1.m1.1.1.2.cmml">k</mi><mo id="alg1.16.6.1.m1.1.1.1" xref="alg1.16.6.1.m1.1.1.1.cmml">∈</mo><msub id="alg1.16.6.1.m1.1.1.3" xref="alg1.16.6.1.m1.1.1.3.cmml"><mi id="alg1.16.6.1.m1.1.1.3.2" xref="alg1.16.6.1.m1.1.1.3.2.cmml">S</mi><mi id="alg1.16.6.1.m1.1.1.3.3" xref="alg1.16.6.1.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.16.6.1.m1.1b"><apply id="alg1.16.6.1.m1.1.1.cmml" xref="alg1.16.6.1.m1.1.1"><in id="alg1.16.6.1.m1.1.1.1.cmml" xref="alg1.16.6.1.m1.1.1.1"></in><ci id="alg1.16.6.1.m1.1.1.2.cmml" xref="alg1.16.6.1.m1.1.1.2">𝑘</ci><apply id="alg1.16.6.1.m1.1.1.3.cmml" xref="alg1.16.6.1.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.16.6.1.m1.1.1.3.1.cmml" xref="alg1.16.6.1.m1.1.1.3">subscript</csymbol><ci id="alg1.16.6.1.m1.1.1.3.2.cmml" xref="alg1.16.6.1.m1.1.1.3.2">𝑆</ci><ci id="alg1.16.6.1.m1.1.1.3.3.cmml" xref="alg1.16.6.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.16.6.1.m1.1c">k\in S_{t}</annotation></semantics></math> <span id="alg1.16.6.1.1" class="ltx_text ltx_font_bold">in parallel</span></em> <span id="alg1.16.6.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.19.9" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.17.7.m1.1" class="ltx_Math" alttext="w_{t+1}^{k}\leftarrow" display="inline"><semantics id="alg1.17.7.m1.1a"><mrow id="alg1.17.7.m1.1.1" xref="alg1.17.7.m1.1.1.cmml"><msubsup id="alg1.17.7.m1.1.1.2" xref="alg1.17.7.m1.1.1.2.cmml"><mi id="alg1.17.7.m1.1.1.2.2.2" xref="alg1.17.7.m1.1.1.2.2.2.cmml">w</mi><mrow id="alg1.17.7.m1.1.1.2.2.3" xref="alg1.17.7.m1.1.1.2.2.3.cmml"><mi id="alg1.17.7.m1.1.1.2.2.3.2" xref="alg1.17.7.m1.1.1.2.2.3.2.cmml">t</mi><mo id="alg1.17.7.m1.1.1.2.2.3.1" xref="alg1.17.7.m1.1.1.2.2.3.1.cmml">+</mo><mn id="alg1.17.7.m1.1.1.2.2.3.3" xref="alg1.17.7.m1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="alg1.17.7.m1.1.1.2.3" xref="alg1.17.7.m1.1.1.2.3.cmml">k</mi></msubsup><mo stretchy="false" id="alg1.17.7.m1.1.1.1" xref="alg1.17.7.m1.1.1.1.cmml">←</mo><mi id="alg1.17.7.m1.1.1.3" xref="alg1.17.7.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.17.7.m1.1b"><apply id="alg1.17.7.m1.1.1.cmml" xref="alg1.17.7.m1.1.1"><ci id="alg1.17.7.m1.1.1.1.cmml" xref="alg1.17.7.m1.1.1.1">←</ci><apply id="alg1.17.7.m1.1.1.2.cmml" xref="alg1.17.7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.17.7.m1.1.1.2.1.cmml" xref="alg1.17.7.m1.1.1.2">superscript</csymbol><apply id="alg1.17.7.m1.1.1.2.2.cmml" xref="alg1.17.7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.17.7.m1.1.1.2.2.1.cmml" xref="alg1.17.7.m1.1.1.2">subscript</csymbol><ci id="alg1.17.7.m1.1.1.2.2.2.cmml" xref="alg1.17.7.m1.1.1.2.2.2">𝑤</ci><apply id="alg1.17.7.m1.1.1.2.2.3.cmml" xref="alg1.17.7.m1.1.1.2.2.3"><plus id="alg1.17.7.m1.1.1.2.2.3.1.cmml" xref="alg1.17.7.m1.1.1.2.2.3.1"></plus><ci id="alg1.17.7.m1.1.1.2.2.3.2.cmml" xref="alg1.17.7.m1.1.1.2.2.3.2">𝑡</ci><cn type="integer" id="alg1.17.7.m1.1.1.2.2.3.3.cmml" xref="alg1.17.7.m1.1.1.2.2.3.3">1</cn></apply></apply><ci id="alg1.17.7.m1.1.1.2.3.cmml" xref="alg1.17.7.m1.1.1.2.3">𝑘</ci></apply><csymbol cd="latexml" id="alg1.17.7.m1.1.1.3.cmml" xref="alg1.17.7.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.17.7.m1.1c">w_{t+1}^{k}\leftarrow</annotation></semantics></math> <span id="alg1.19.9.1" class="ltx_text ltx_font_bold">ClientUpdate</span>(<math id="alg1.18.8.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.18.8.m2.1a"><mi id="alg1.18.8.m2.1.1" xref="alg1.18.8.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.18.8.m2.1b"><ci id="alg1.18.8.m2.1.1.cmml" xref="alg1.18.8.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.18.8.m2.1c">k</annotation></semantics></math>,<math id="alg1.19.9.m3.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="alg1.19.9.m3.1a"><msub id="alg1.19.9.m3.1.1" xref="alg1.19.9.m3.1.1.cmml"><mi id="alg1.19.9.m3.1.1.2" xref="alg1.19.9.m3.1.1.2.cmml">w</mi><mi id="alg1.19.9.m3.1.1.3" xref="alg1.19.9.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.19.9.m3.1b"><apply id="alg1.19.9.m3.1.1.cmml" xref="alg1.19.9.m3.1.1"><csymbol cd="ambiguous" id="alg1.19.9.m3.1.1.1.cmml" xref="alg1.19.9.m3.1.1">subscript</csymbol><ci id="alg1.19.9.m3.1.1.2.cmml" xref="alg1.19.9.m3.1.1.2">𝑤</ci><ci id="alg1.19.9.m3.1.1.3.cmml" xref="alg1.19.9.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.19.9.m3.1c">w_{t}</annotation></semantics></math>)
</div>
<div id="alg1.30.23" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.30.24" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end for
</div>
<div id="alg1.20.10" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <math id="alg1.20.10.m1.1" class="ltx_Math" alttext="w_{t+1}\leftarrow\sum_{k=1}^{K}\frac{n_{k}}{n}w_{t+1}^{k}" display="inline"><semantics id="alg1.20.10.m1.1a"><mrow id="alg1.20.10.m1.1.1" xref="alg1.20.10.m1.1.1.cmml"><msub id="alg1.20.10.m1.1.1.2" xref="alg1.20.10.m1.1.1.2.cmml"><mi id="alg1.20.10.m1.1.1.2.2" xref="alg1.20.10.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.20.10.m1.1.1.2.3" xref="alg1.20.10.m1.1.1.2.3.cmml"><mi id="alg1.20.10.m1.1.1.2.3.2" xref="alg1.20.10.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.20.10.m1.1.1.2.3.1" xref="alg1.20.10.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.20.10.m1.1.1.2.3.3" xref="alg1.20.10.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo rspace="0.111em" stretchy="false" id="alg1.20.10.m1.1.1.1" xref="alg1.20.10.m1.1.1.1.cmml">←</mo><mrow id="alg1.20.10.m1.1.1.3" xref="alg1.20.10.m1.1.1.3.cmml"><msubsup id="alg1.20.10.m1.1.1.3.1" xref="alg1.20.10.m1.1.1.3.1.cmml"><mo id="alg1.20.10.m1.1.1.3.1.2.2" xref="alg1.20.10.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="alg1.20.10.m1.1.1.3.1.2.3" xref="alg1.20.10.m1.1.1.3.1.2.3.cmml"><mi id="alg1.20.10.m1.1.1.3.1.2.3.2" xref="alg1.20.10.m1.1.1.3.1.2.3.2.cmml">k</mi><mo id="alg1.20.10.m1.1.1.3.1.2.3.1" xref="alg1.20.10.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="alg1.20.10.m1.1.1.3.1.2.3.3" xref="alg1.20.10.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.20.10.m1.1.1.3.1.3" xref="alg1.20.10.m1.1.1.3.1.3.cmml">K</mi></msubsup><mrow id="alg1.20.10.m1.1.1.3.2" xref="alg1.20.10.m1.1.1.3.2.cmml"><mfrac id="alg1.20.10.m1.1.1.3.2.2" xref="alg1.20.10.m1.1.1.3.2.2.cmml"><msub id="alg1.20.10.m1.1.1.3.2.2.2" xref="alg1.20.10.m1.1.1.3.2.2.2.cmml"><mi id="alg1.20.10.m1.1.1.3.2.2.2.2" xref="alg1.20.10.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="alg1.20.10.m1.1.1.3.2.2.2.3" xref="alg1.20.10.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="alg1.20.10.m1.1.1.3.2.2.3" xref="alg1.20.10.m1.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.20.10.m1.1.1.3.2.1" xref="alg1.20.10.m1.1.1.3.2.1.cmml">​</mo><msubsup id="alg1.20.10.m1.1.1.3.2.3" xref="alg1.20.10.m1.1.1.3.2.3.cmml"><mi id="alg1.20.10.m1.1.1.3.2.3.2.2" xref="alg1.20.10.m1.1.1.3.2.3.2.2.cmml">w</mi><mrow id="alg1.20.10.m1.1.1.3.2.3.2.3" xref="alg1.20.10.m1.1.1.3.2.3.2.3.cmml"><mi id="alg1.20.10.m1.1.1.3.2.3.2.3.2" xref="alg1.20.10.m1.1.1.3.2.3.2.3.2.cmml">t</mi><mo id="alg1.20.10.m1.1.1.3.2.3.2.3.1" xref="alg1.20.10.m1.1.1.3.2.3.2.3.1.cmml">+</mo><mn id="alg1.20.10.m1.1.1.3.2.3.2.3.3" xref="alg1.20.10.m1.1.1.3.2.3.2.3.3.cmml">1</mn></mrow><mi id="alg1.20.10.m1.1.1.3.2.3.3" xref="alg1.20.10.m1.1.1.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.20.10.m1.1b"><apply id="alg1.20.10.m1.1.1.cmml" xref="alg1.20.10.m1.1.1"><ci id="alg1.20.10.m1.1.1.1.cmml" xref="alg1.20.10.m1.1.1.1">←</ci><apply id="alg1.20.10.m1.1.1.2.cmml" xref="alg1.20.10.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.20.10.m1.1.1.2.1.cmml" xref="alg1.20.10.m1.1.1.2">subscript</csymbol><ci id="alg1.20.10.m1.1.1.2.2.cmml" xref="alg1.20.10.m1.1.1.2.2">𝑤</ci><apply id="alg1.20.10.m1.1.1.2.3.cmml" xref="alg1.20.10.m1.1.1.2.3"><plus id="alg1.20.10.m1.1.1.2.3.1.cmml" xref="alg1.20.10.m1.1.1.2.3.1"></plus><ci id="alg1.20.10.m1.1.1.2.3.2.cmml" xref="alg1.20.10.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.20.10.m1.1.1.2.3.3.cmml" xref="alg1.20.10.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.20.10.m1.1.1.3.cmml" xref="alg1.20.10.m1.1.1.3"><apply id="alg1.20.10.m1.1.1.3.1.cmml" xref="alg1.20.10.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.20.10.m1.1.1.3.1.1.cmml" xref="alg1.20.10.m1.1.1.3.1">superscript</csymbol><apply id="alg1.20.10.m1.1.1.3.1.2.cmml" xref="alg1.20.10.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.20.10.m1.1.1.3.1.2.1.cmml" xref="alg1.20.10.m1.1.1.3.1">subscript</csymbol><sum id="alg1.20.10.m1.1.1.3.1.2.2.cmml" xref="alg1.20.10.m1.1.1.3.1.2.2"></sum><apply id="alg1.20.10.m1.1.1.3.1.2.3.cmml" xref="alg1.20.10.m1.1.1.3.1.2.3"><eq id="alg1.20.10.m1.1.1.3.1.2.3.1.cmml" xref="alg1.20.10.m1.1.1.3.1.2.3.1"></eq><ci id="alg1.20.10.m1.1.1.3.1.2.3.2.cmml" xref="alg1.20.10.m1.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="alg1.20.10.m1.1.1.3.1.2.3.3.cmml" xref="alg1.20.10.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.20.10.m1.1.1.3.1.3.cmml" xref="alg1.20.10.m1.1.1.3.1.3">𝐾</ci></apply><apply id="alg1.20.10.m1.1.1.3.2.cmml" xref="alg1.20.10.m1.1.1.3.2"><times id="alg1.20.10.m1.1.1.3.2.1.cmml" xref="alg1.20.10.m1.1.1.3.2.1"></times><apply id="alg1.20.10.m1.1.1.3.2.2.cmml" xref="alg1.20.10.m1.1.1.3.2.2"><divide id="alg1.20.10.m1.1.1.3.2.2.1.cmml" xref="alg1.20.10.m1.1.1.3.2.2"></divide><apply id="alg1.20.10.m1.1.1.3.2.2.2.cmml" xref="alg1.20.10.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="alg1.20.10.m1.1.1.3.2.2.2.1.cmml" xref="alg1.20.10.m1.1.1.3.2.2.2">subscript</csymbol><ci id="alg1.20.10.m1.1.1.3.2.2.2.2.cmml" xref="alg1.20.10.m1.1.1.3.2.2.2.2">𝑛</ci><ci id="alg1.20.10.m1.1.1.3.2.2.2.3.cmml" xref="alg1.20.10.m1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="alg1.20.10.m1.1.1.3.2.2.3.cmml" xref="alg1.20.10.m1.1.1.3.2.2.3">𝑛</ci></apply><apply id="alg1.20.10.m1.1.1.3.2.3.cmml" xref="alg1.20.10.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.20.10.m1.1.1.3.2.3.1.cmml" xref="alg1.20.10.m1.1.1.3.2.3">superscript</csymbol><apply id="alg1.20.10.m1.1.1.3.2.3.2.cmml" xref="alg1.20.10.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="alg1.20.10.m1.1.1.3.2.3.2.1.cmml" xref="alg1.20.10.m1.1.1.3.2.3">subscript</csymbol><ci id="alg1.20.10.m1.1.1.3.2.3.2.2.cmml" xref="alg1.20.10.m1.1.1.3.2.3.2.2">𝑤</ci><apply id="alg1.20.10.m1.1.1.3.2.3.2.3.cmml" xref="alg1.20.10.m1.1.1.3.2.3.2.3"><plus id="alg1.20.10.m1.1.1.3.2.3.2.3.1.cmml" xref="alg1.20.10.m1.1.1.3.2.3.2.3.1"></plus><ci id="alg1.20.10.m1.1.1.3.2.3.2.3.2.cmml" xref="alg1.20.10.m1.1.1.3.2.3.2.3.2">𝑡</ci><cn type="integer" id="alg1.20.10.m1.1.1.3.2.3.2.3.3.cmml" xref="alg1.20.10.m1.1.1.3.2.3.2.3.3">1</cn></apply></apply><ci id="alg1.20.10.m1.1.1.3.2.3.3.cmml" xref="alg1.20.10.m1.1.1.3.2.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.20.10.m1.1c">w_{t+1}\leftarrow\sum_{k=1}^{K}\frac{n_{k}}{n}w_{t+1}^{k}</annotation></semantics></math>
</div>
<div id="alg1.30.25" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.30.26" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end for
</div>
<div id="alg1.30.27" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="alg1.30.28" class="ltx_listingline"> 
</div>
<div id="alg1.30.29" class="ltx_listingline">
</div>
<div id="alg1.22.12" class="ltx_listingline">

<span id="alg1.22.12.3" class="ltx_text ltx_font_bold">Client update</span> <em id="alg1.22.12.2" class="ltx_emph ltx_font_typewriter">(<em id="alg1.22.12.2.2.2" class="ltx_emph ltx_font_serif ltx_font_italic"><math id="alg1.21.11.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.21.11.1.1.1.m1.1a"><mi id="alg1.21.11.1.1.1.m1.1.1" xref="alg1.21.11.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.21.11.1.1.1.m1.1b"><ci id="alg1.21.11.1.1.1.m1.1.1.cmml" xref="alg1.21.11.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.21.11.1.1.1.m1.1c">k</annotation></semantics></math>,<math id="alg1.22.12.2.2.2.m2.1" class="ltx_Math" alttext="w" display="inline"><semantics id="alg1.22.12.2.2.2.m2.1a"><mi id="alg1.22.12.2.2.2.m2.1.1" xref="alg1.22.12.2.2.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="alg1.22.12.2.2.2.m2.1b"><ci id="alg1.22.12.2.2.2.m2.1.1.cmml" xref="alg1.22.12.2.2.2.m2.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.22.12.2.2.2.m2.1c">w</annotation></semantics></math></em>)</em><span id="alg1.22.12.4" class="ltx_text ltx_font_bold">:</span> 
</div>
<div id="alg1.25.15" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.23.13.m1.1" class="ltx_Math" alttext="B\leftarrow" display="inline"><semantics id="alg1.23.13.m1.1a"><mrow id="alg1.23.13.m1.1.1" xref="alg1.23.13.m1.1.1.cmml"><mi id="alg1.23.13.m1.1.1.2" xref="alg1.23.13.m1.1.1.2.cmml">B</mi><mo stretchy="false" id="alg1.23.13.m1.1.1.1" xref="alg1.23.13.m1.1.1.1.cmml">←</mo><mi id="alg1.23.13.m1.1.1.3" xref="alg1.23.13.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.23.13.m1.1b"><apply id="alg1.23.13.m1.1.1.cmml" xref="alg1.23.13.m1.1.1"><ci id="alg1.23.13.m1.1.1.1.cmml" xref="alg1.23.13.m1.1.1.1">←</ci><ci id="alg1.23.13.m1.1.1.2.cmml" xref="alg1.23.13.m1.1.1.2">𝐵</ci><csymbol cd="latexml" id="alg1.23.13.m1.1.1.3.cmml" xref="alg1.23.13.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.23.13.m1.1c">B\leftarrow</annotation></semantics></math> (split <math id="alg1.24.14.m2.1" class="ltx_Math" alttext="P_{k}" display="inline"><semantics id="alg1.24.14.m2.1a"><msub id="alg1.24.14.m2.1.1" xref="alg1.24.14.m2.1.1.cmml"><mi id="alg1.24.14.m2.1.1.2" xref="alg1.24.14.m2.1.1.2.cmml">P</mi><mi id="alg1.24.14.m2.1.1.3" xref="alg1.24.14.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.24.14.m2.1b"><apply id="alg1.24.14.m2.1.1.cmml" xref="alg1.24.14.m2.1.1"><csymbol cd="ambiguous" id="alg1.24.14.m2.1.1.1.cmml" xref="alg1.24.14.m2.1.1">subscript</csymbol><ci id="alg1.24.14.m2.1.1.2.cmml" xref="alg1.24.14.m2.1.1.2">𝑃</ci><ci id="alg1.24.14.m2.1.1.3.cmml" xref="alg1.24.14.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.24.14.m2.1c">P_{k}</annotation></semantics></math> into batches of size <math id="alg1.25.15.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="alg1.25.15.m3.1a"><mi id="alg1.25.15.m3.1.1" xref="alg1.25.15.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="alg1.25.15.m3.1b"><ci id="alg1.25.15.m3.1.1.cmml" xref="alg1.25.15.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.25.15.m3.1c">B</annotation></semantics></math>)
</div>
<div id="alg1.30.30" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.27.17" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="alg1.27.17.3" class="ltx_text ltx_font_bold">for</span> <em id="alg1.27.17.2" class="ltx_emph ltx_font_italic">each local epoch <math id="alg1.26.16.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="alg1.26.16.1.m1.1a"><mi id="alg1.26.16.1.m1.1.1" xref="alg1.26.16.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.26.16.1.m1.1b"><ci id="alg1.26.16.1.m1.1.1.cmml" xref="alg1.26.16.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.26.16.1.m1.1c">i</annotation></semantics></math> from 1 to <math id="alg1.27.17.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="alg1.27.17.2.m2.1a"><mi id="alg1.27.17.2.m2.1.1" xref="alg1.27.17.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="alg1.27.17.2.m2.1b"><ci id="alg1.27.17.2.m2.1.1.cmml" xref="alg1.27.17.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.27.17.2.m2.1c">E</annotation></semantics></math></em> <span id="alg1.27.17.4" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.28.18" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.28.18.2" class="ltx_text ltx_font_bold">for</span> <em id="alg1.28.18.1" class="ltx_emph ltx_font_italic">batch <math id="alg1.28.18.1.m1.1" class="ltx_Math" alttext="b\in B" display="inline"><semantics id="alg1.28.18.1.m1.1a"><mrow id="alg1.28.18.1.m1.1.1" xref="alg1.28.18.1.m1.1.1.cmml"><mi id="alg1.28.18.1.m1.1.1.2" xref="alg1.28.18.1.m1.1.1.2.cmml">b</mi><mo id="alg1.28.18.1.m1.1.1.1" xref="alg1.28.18.1.m1.1.1.1.cmml">∈</mo><mi id="alg1.28.18.1.m1.1.1.3" xref="alg1.28.18.1.m1.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.28.18.1.m1.1b"><apply id="alg1.28.18.1.m1.1.1.cmml" xref="alg1.28.18.1.m1.1.1"><in id="alg1.28.18.1.m1.1.1.1.cmml" xref="alg1.28.18.1.m1.1.1.1"></in><ci id="alg1.28.18.1.m1.1.1.2.cmml" xref="alg1.28.18.1.m1.1.1.2">𝑏</ci><ci id="alg1.28.18.1.m1.1.1.3.cmml" xref="alg1.28.18.1.m1.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.28.18.1.m1.1c">b\in B</annotation></semantics></math></em> <span id="alg1.28.18.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.29.19" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.29.19.m1.2" class="ltx_Math" alttext="w\leftarrow w-\eta\nabla l(w;b)" display="inline"><semantics id="alg1.29.19.m1.2a"><mrow id="alg1.29.19.m1.2.3" xref="alg1.29.19.m1.2.3.cmml"><mi id="alg1.29.19.m1.2.3.2" xref="alg1.29.19.m1.2.3.2.cmml">w</mi><mo stretchy="false" id="alg1.29.19.m1.2.3.1" xref="alg1.29.19.m1.2.3.1.cmml">←</mo><mrow id="alg1.29.19.m1.2.3.3" xref="alg1.29.19.m1.2.3.3.cmml"><mi id="alg1.29.19.m1.2.3.3.2" xref="alg1.29.19.m1.2.3.3.2.cmml">w</mi><mo id="alg1.29.19.m1.2.3.3.1" xref="alg1.29.19.m1.2.3.3.1.cmml">−</mo><mrow id="alg1.29.19.m1.2.3.3.3" xref="alg1.29.19.m1.2.3.3.3.cmml"><mi id="alg1.29.19.m1.2.3.3.3.2" xref="alg1.29.19.m1.2.3.3.3.2.cmml">η</mi><mo lspace="0.167em" rspace="0em" id="alg1.29.19.m1.2.3.3.3.1" xref="alg1.29.19.m1.2.3.3.3.1.cmml">​</mo><mrow id="alg1.29.19.m1.2.3.3.3.3" xref="alg1.29.19.m1.2.3.3.3.3.cmml"><mo rspace="0.167em" id="alg1.29.19.m1.2.3.3.3.3.1" xref="alg1.29.19.m1.2.3.3.3.3.1.cmml">∇</mo><mi id="alg1.29.19.m1.2.3.3.3.3.2" xref="alg1.29.19.m1.2.3.3.3.3.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.29.19.m1.2.3.3.3.1a" xref="alg1.29.19.m1.2.3.3.3.1.cmml">​</mo><mrow id="alg1.29.19.m1.2.3.3.3.4.2" xref="alg1.29.19.m1.2.3.3.3.4.1.cmml"><mo stretchy="false" id="alg1.29.19.m1.2.3.3.3.4.2.1" xref="alg1.29.19.m1.2.3.3.3.4.1.cmml">(</mo><mi id="alg1.29.19.m1.1.1" xref="alg1.29.19.m1.1.1.cmml">w</mi><mo id="alg1.29.19.m1.2.3.3.3.4.2.2" xref="alg1.29.19.m1.2.3.3.3.4.1.cmml">;</mo><mi id="alg1.29.19.m1.2.2" xref="alg1.29.19.m1.2.2.cmml">b</mi><mo stretchy="false" id="alg1.29.19.m1.2.3.3.3.4.2.3" xref="alg1.29.19.m1.2.3.3.3.4.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.29.19.m1.2b"><apply id="alg1.29.19.m1.2.3.cmml" xref="alg1.29.19.m1.2.3"><ci id="alg1.29.19.m1.2.3.1.cmml" xref="alg1.29.19.m1.2.3.1">←</ci><ci id="alg1.29.19.m1.2.3.2.cmml" xref="alg1.29.19.m1.2.3.2">𝑤</ci><apply id="alg1.29.19.m1.2.3.3.cmml" xref="alg1.29.19.m1.2.3.3"><minus id="alg1.29.19.m1.2.3.3.1.cmml" xref="alg1.29.19.m1.2.3.3.1"></minus><ci id="alg1.29.19.m1.2.3.3.2.cmml" xref="alg1.29.19.m1.2.3.3.2">𝑤</ci><apply id="alg1.29.19.m1.2.3.3.3.cmml" xref="alg1.29.19.m1.2.3.3.3"><times id="alg1.29.19.m1.2.3.3.3.1.cmml" xref="alg1.29.19.m1.2.3.3.3.1"></times><ci id="alg1.29.19.m1.2.3.3.3.2.cmml" xref="alg1.29.19.m1.2.3.3.3.2">𝜂</ci><apply id="alg1.29.19.m1.2.3.3.3.3.cmml" xref="alg1.29.19.m1.2.3.3.3.3"><ci id="alg1.29.19.m1.2.3.3.3.3.1.cmml" xref="alg1.29.19.m1.2.3.3.3.3.1">∇</ci><ci id="alg1.29.19.m1.2.3.3.3.3.2.cmml" xref="alg1.29.19.m1.2.3.3.3.3.2">𝑙</ci></apply><list id="alg1.29.19.m1.2.3.3.3.4.1.cmml" xref="alg1.29.19.m1.2.3.3.3.4.2"><ci id="alg1.29.19.m1.1.1.cmml" xref="alg1.29.19.m1.1.1">𝑤</ci><ci id="alg1.29.19.m1.2.2.cmml" xref="alg1.29.19.m1.2.2">𝑏</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.29.19.m1.2c">w\leftarrow w-\eta\nabla l(w;b)</annotation></semantics></math>
</div>
<div id="alg1.30.31" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="alg1.30.32" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end for
</div>
<div id="alg1.30.33" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="alg1.30.34" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end for
</div>
<div id="alg1.30.35" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="alg1.30.20" class="ltx_listingline">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   return <math id="alg1.30.20.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="alg1.30.20.m1.1a"><mi id="alg1.30.20.m1.1.1" xref="alg1.30.20.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="alg1.30.20.m1.1b"><ci id="alg1.30.20.m1.1.1.cmml" xref="alg1.30.20.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.30.20.m1.1c">w</annotation></semantics></math> to server;

</div>
<div id="alg1.30.36" class="ltx_listingline"> 
</div>
<div id="alg1.30.37" class="ltx_listingline">
</div>
<div id="alg1.30.38" class="ltx_listingline">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.33.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span><em id="alg1.34.2" class="ltx_emph ltx_font_italic">FederatedAveraging</em>: The <math id="alg1.6.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="alg1.6.m1.1b"><mi id="alg1.6.m1.1.1" xref="alg1.6.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.6.m1.1c"><ci id="alg1.6.m1.1.1.cmml" xref="alg1.6.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.m1.1d">K</annotation></semantics></math> clients are indexed by <math id="alg1.7.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.7.m2.1b"><mi id="alg1.7.m2.1.1" xref="alg1.7.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.7.m2.1c"><ci id="alg1.7.m2.1.1.cmml" xref="alg1.7.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.m2.1d">k</annotation></semantics></math>; <math id="alg1.8.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="alg1.8.m3.1b"><mi id="alg1.8.m3.1.1" xref="alg1.8.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="alg1.8.m3.1c"><ci id="alg1.8.m3.1.1.cmml" xref="alg1.8.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.m3.1d">B</annotation></semantics></math> is the local minibatch size, <math id="alg1.9.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="alg1.9.m4.1b"><mi id="alg1.9.m4.1.1" xref="alg1.9.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="alg1.9.m4.1c"><ci id="alg1.9.m4.1.1.cmml" xref="alg1.9.m4.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.m4.1d">E</annotation></semantics></math> is the number of local epochs, and <math id="alg1.10.m5.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="alg1.10.m5.1b"><mi id="alg1.10.m5.1.1" xref="alg1.10.m5.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="alg1.10.m5.1c"><ci id="alg1.10.m5.1.1.cmml" xref="alg1.10.m5.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.m5.1d">\eta</annotation></semantics></math> is the learning rate</figcaption>
</figure>
</section>
<section id="S2.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_font_italic ltx_title_subsection">Infrastructure-level errors in Federated Learning</h3>

<div id="S2.SSx2.p1" class="ltx_para">
<p id="S2.SSx2.p1.1" class="ltx_p">These errors are due to uncontrollable events in the underlying system. During a global update cycle, the server assumes a total of <math id="S2.SSx2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SSx2.p1.1.m1.1a"><mi id="S2.SSx2.p1.1.m1.1.1" xref="S2.SSx2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SSx2.p1.1.m1.1b"><ci id="S2.SSx2.p1.1.m1.1.1.cmml" xref="S2.SSx2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p1.1.m1.1c">k</annotation></semantics></math> weight updates, one belonging to each client. However, one or more clients might fail to send weight updates intermittently or permanently, due to a faulty network connection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Moreover, as stated earlier, each data source might show different statistical properties, such as class imbalances or even missing representation for certain class(es) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. A faulty network coupled with heterogeneous data sources missing might lead to bad model performance, a model unable to generalize well to certain types of cases or even recognize certain classes at all.</p>
</div>
<div id="S2.SSx2.p2" class="ltx_para">
<p id="S2.SSx2.p2.1" class="ltx_p">A real-world classification problem has been selected to assess the robustness of Federated Averaging learning towards such infrastructure-level issues. The target use case focuses on the detection of certain weed species from hyperspectral images. This kind of dataset requires large volumes of storage space, discouraging from transferring the data to a centralized location. It is the ideal candidate for Federated Learning-based training. The proposed set of experiments empirically analyzes the impact of network failures on the model accuracy, considering both permanent and intermittent failures from one or more clients simultaneously.</p>
</div>
</section>
<section id="S2.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_font_italic ltx_title_subsection">ML-specific inconsistencies in Federated Learning</h3>

<div id="S2.SSx3.p1" class="ltx_para">
<p id="S2.SSx3.p1.1" class="ltx_p">Clients with ML-specific inconsistencies disrupt the model training process, compromise its accuracy or even change the model behavior altogether. The central model relies on properly labelled data from each data source. The primary source of irregularities might come from the data itself: Certain clients might provide mislabelled training data or intentionally flipped class labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. As a result, the resulting model will not be able to detect certain class(es), deeming the system unusable.</p>
</div>
<div id="S2.SSx3.p2" class="ltx_para">
<p id="S2.SSx3.p2.1" class="ltx_p">Federated learning relies on a number of configuration parameters (see Algorithm <a href="#alg1" title="In Federated Averaging Algorithm ‣ II Problem Formulation ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) to tune the ultimate model accuracy. In certain situations, some clients may have wrong values of such parameters with malicious intentions or simply due to a misconfiguration and will degrade the model performance. The learning rate <math id="S2.SSx3.p2.1.m1.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.SSx3.p2.1.m1.1a"><mi id="S2.SSx3.p2.1.m1.1.1" xref="S2.SSx3.p2.1.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S2.SSx3.p2.1.m1.1b"><ci id="S2.SSx3.p2.1.m1.1.1.cmml" xref="S2.SSx3.p2.1.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx3.p2.1.m1.1c">\eta</annotation></semantics></math> has been shown to be a parameter of choice <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and able to affect the performance of both the aggregated, central model and the local ones  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
<div id="S2.SSx3.p3" class="ltx_para">
<p id="S2.SSx3.p3.1" class="ltx_p">In order to evaluate the effects of ML-specific inconsistencies in federated learning, a second real-world application has been utilized, named animal detection from trap cameras. Such trap cameras are placed on different locations and collect bursts of (at least) three images whenever the motion sensor is triggered. The experiments are designed to analyze the separate effects of mislabelled data and incorrect learning rate values, and also explore whether the combination of both kinds (flipped labels and learning rate values) amplifies the negative effect.</p>
</div>
<div id="S2.SSx3.p4" class="ltx_para">
<p id="S2.SSx3.p4.1" class="ltx_p">As explained above, Federated Averaging Learning was not designed with fault tolerance behavior. Intuitively, we would expect the model performance to degrade as infrastructure-level or ML- specific inconsistencies develop. The experiment set carried out through two real-world applications will prove (empirically) that Federated Average Learning has a bigger than expected tolerance for such behavior.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">FL in Precision weeds detection</span>
</h2>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2305.09856/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Hyperspectral Weeds Detection System</span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We focus on precision weeds detection as our rural agriculture application. This robotic system uses a near-infrared hyperspectral imaging system to guide the operations of a mobile precision pesticide spraying system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> (see Figure <a href="#S3.F1" title="Figure 1 ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The use of near-infrared hyperspectral cameras as a replacement for standard RGB cameras is motivated by research suggesting that spectral measurements can more accurately distinguish weeds from produce <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
However, the more sophisticated cameras also increase power and data requirements, leading to a need to optimize power and energy consumption in order to achieve maximum area coverage.
An effective solution should process camera data locally for weed detection, but also communicate a locally processed model to the global database for aggregation. Therefore, FL is a good fit for this application.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Our intent is to investigate the practical aspects of FL for weeds detection where we deploy a Pasture Care Robot with hyperspectral imaging capabilities. Note that in a large pasture area, full network coverage may not be guaranteed. When the robot is operating in the pasture, it is unavoidable that the robot will completely drop out during the FL training due to network connection issues. Moreover, when the robot’s power level is low, it is a common engineering practice that the robot will prioritize navigation over data transmission. In other words, the robot may still receive data but not transmit data in order to conserve battery. Motivated by these, in this weeds detection application, we will investigate the unreliable client scenarios where clients completely or partially drop in and out of the federation.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Dataset</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">As summarized in Table <a href="#S3.T1" title="TABLE I ‣ III-A Dataset ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, the dataset we used in our experiments consists of hyperspectral pasture images taken from three different rural sites <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. The dataset was labelled with four classes including three different species of pastoral weed: <em id="S3.SS1.p1.1.1" class="ltx_emph ltx_font_italic">Jacobaea Vulgaris</em> (common name: <em id="S3.SS1.p1.1.2" class="ltx_emph ltx_font_italic">Ragwort</em>), <em id="S3.SS1.p1.1.3" class="ltx_emph ltx_font_italic">Ulex</em> (common name: <em id="S3.SS1.p1.1.4" class="ltx_emph ltx_font_italic">Gorse</em>), <em id="S3.SS1.p1.1.5" class="ltx_emph ltx_font_italic">Rubus</em> (common name: <em id="S3.SS1.p1.1.6" class="ltx_emph ltx_font_italic">Blackberry</em>), and a background class of grass. These near-infrared hyperspectral images were taken using a Pika hyperspectral camera and normalised against a white reference to convert from radiance to reflectance while also removing instrument-specific variations. Sample points were extracted from the image datacubes, whereby each pixel had 148 dimensions in the infrared spectrum of 900nm to 1700nm. The dataset was partitioned into training (80% of the samples) and testing (20% of the samples) datasets in a randomized class-stratified manner.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Class normalization of dataset was not performed as our evaluation considers each hyperspectral image individually. In a live environment, it is conceivable that a site has insufficient examples of any given class such that normalization would remove large portions of valid data. We consider this data valid as we compare federated and centralized models to local models: models that would use such data exclusively. A fundamental part of the evaluation of FL in this case is the ability to benefit from the knowledge of other sites.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Hyperspectral pasture image dataset with imbalanced class distributions and disparate volumes of data among different sites (W: Pastoral weeds, G: Background grass)</span></figcaption>
<table id="S3.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.4.1.1" class="ltx_tr">
<th id="S3.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r">Location</th>
<th id="S3.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Site A</th>
<th id="S3.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Site B</th>
<th id="S3.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Site C</th>
<th id="S3.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Total</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.4.2.1" class="ltx_tr">
<th id="S3.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">#Samples</th>
<td id="S3.T1.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t">60,072</td>
<td id="S3.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t">30,240</td>
<td id="S3.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6,232</td>
<td id="S3.T1.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t">104,544</td>
</tr>
<tr id="S3.T1.4.3.2" class="ltx_tr">
<th id="S3.T1.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">#Classes</th>
<td id="S3.T1.4.3.2.2" class="ltx_td ltx_align_center ltx_border_bb">4 (3W + G)</td>
<td id="S3.T1.4.3.2.3" class="ltx_td ltx_align_center ltx_border_bb">4 (3W + G)</td>
<td id="S3.T1.4.3.2.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">2 (1W + G)</td>
<td id="S3.T1.4.3.2.5" class="ltx_td ltx_align_center ltx_border_bb">4 (3W + G)</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Note that the heterogeneity in our dataset poses challenges for FL: (1) <em id="S3.SS1.p3.1.1" class="ltx_emph ltx_font_italic">Data heterogeneity on class labels</em>. As shown in Table <a href="#S3.T1" title="TABLE I ‣ III-A Dataset ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, data from the first two sites were balanced across all four of the classes while data from the third consisted of only one weed species and grass, making the distribution of examples between sites quite different and therefore potentially challenging for FL.
(2) <em id="S3.SS1.p3.1.2" class="ltx_emph ltx_font_italic">Data heterogeneity on data volumes</em>.
Site A provided approximately two times as much data as site B and ten times as much data as site C.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Experiment Plan</span>
</h3>

<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.2.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S3.T2.3.2" class="ltx_text" style="font-size:90%;">Experiment plan</span></figcaption>
<table id="S3.T2.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.4.1.1" class="ltx_tr">
<td id="S3.T2.4.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S3.T2.4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.1.1.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Objective</span></span>
</span>
</td>
<td id="S3.T2.4.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S3.T2.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.1.1.2.1.1" class="ltx_p" style="width:170.7pt;"><span id="S3.T2.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Research question</span></span>
</span>
</td>
<td id="S3.T2.4.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S3.T2.4.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.1.1.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.4.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Algorithm</span></span>
</span>
</td>
<td id="S3.T2.4.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S3.T2.4.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.1.1.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T2.4.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Independent variables</span></span>
</span>
</td>
<td id="S3.T2.4.1.1.5" class="ltx_td ltx_align_justify">
<span id="S3.T2.4.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.1.1.5.1.1" class="ltx_p"><span id="S3.T2.4.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Dependent variables</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.4.2.2" class="ltx_tr">
<td id="S3.T2.4.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.2.2.1.1.1" class="ltx_p" style="width:42.7pt;">Classification accuracy</span>
</span>
</td>
<td id="S3.T2.4.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.2.2.2.1.1" class="ltx_p" style="width:170.7pt;">How well does FL perform compared with other ML approaches?</span>
</span>
</td>
<td id="S3.T2.4.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.2.2.3.1.1" class="ltx_p" style="width:56.9pt;">FL, Centralized, Localized</span>
</span>
</td>
<td id="S3.T2.4.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.2.2.4.1.1" class="ltx_p" style="width:113.8pt;">Hyperparameters (e.g., iterations, minibatch size, #epochs/iteration)</span>
</span>
</td>
<td id="S3.T2.4.2.2.5" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T2.4.3.3" class="ltx_tr">
<td id="S3.T2.4.3.3.1" class="ltx_td ltx_align_top ltx_border_r ltx_border_t"></td>
<td id="S3.T2.4.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.3.3.2.1.1" class="ltx_p" style="width:170.7pt;">What is the impact of clients partially dropping out on FL?</span>
</span>
</td>
<td id="S3.T2.4.3.3.3" class="ltx_td ltx_align_top ltx_border_r ltx_border_t"></td>
<td id="S3.T2.4.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.3.3.4.1.1" class="ltx_p" style="width:113.8pt;">When the clients drop out (e.g., upload, download)</span>
</span>
</td>
<td id="S3.T2.4.3.3.5" class="ltx_td ltx_align_justify ltx_border_bb" rowspan="4">
<span id="S3.T2.4.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.3.3.5.1.1" class="ltx_p">Classification accuracy</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.4.4" class="ltx_tr">
<td id="S3.T2.4.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r" rowspan="3">
<span id="S3.T2.4.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.4.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.4.4.4.1.1.1.1" class="ltx_text">Robustness</span></span>
</span>
</td>
<td id="S3.T2.4.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.4.2.1.1" class="ltx_p" style="width:170.7pt;">What is the effect of training data volume on FL with unreliable clients?</span>
</span>
</td>
<td id="S3.T2.4.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" rowspan="3">
<span id="S3.T2.4.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.4.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.4.4.4.3.1.1.1" class="ltx_text">FL</span></span>
</span>
</td>
<td id="S3.T2.4.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.4.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.4.4.1.1" class="ltx_p" style="width:113.8pt;">Which client/site drops out (sites with different data volume)</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.5.5" class="ltx_tr">
<td id="S3.T2.4.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T2.4.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.5.5.1.1.1" class="ltx_p" style="width:170.7pt;">What is the effect of client participation rate on FL?</span>
</span>
</td>
<td id="S3.T2.4.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T2.4.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.5.5.2.1.1" class="ltx_p" style="width:113.8pt;">Client participation rate</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We evaluate the capabilities of FL in supporting cross-field hyperspectral weeds detection from two aspects:</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2305.09856/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="322" height="271" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Approaches to ML in rural AI. Green illustrates a typical fully localised system where data is not shared between sites;
each model is locally relevant only
with no communication between sites.
Blue illustrates a fully centralised system where all data is uploaded to the cloud and a single centralised model is trained;
while potentially the most accurate approach,
this cannot be used with sensitive data or where the amount of data to be transferred is too large for the available bandwidth.
Yellow shows a federated approach where data is kept local while models are sent to the parameter server
and used to compute an aggregate model which in turn
is shared back to the local sites;
this allows learning across sites
while not requiring data to be shared.</span></figcaption>
</figure>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.4.1.1" class="ltx_text">III-B</span>1 </span>Classification accuracy</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">To justify the use of FL, we compared FL with a fully localized approach and a fully centralized approach as shown in Fig. <a href="#S3.F2" title="Figure 2 ‣ III-B Experiment Plan ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The fully localized approach (Fig. <a href="#S3.F2" title="Figure 2 ‣ III-B Experiment Plan ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, green figure) represents a completely decoupled system where each model is trained locally at the three sites and there is no communication at all between sites.
The fully centralized approach (Fig. <a href="#S3.F2" title="Figure 2 ‣ III-B Experiment Plan ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, blue figure) represents a completely centralized approach where the model resides on a cloud server and all data must be uploaded to the server before the model is trained.
These two approaches represent the current alternative status quo, both of which have disadvantages. For example, the centralized approach can introduce large communication overhead because it requires all data to be uploaded to the cloud. Moreover, the centralized approach cannot be used with sensitive data due to the violation of data sovereignty. Although these issues can be addressed by the localized approach, a model trained using local data only may not perform well, especially with a heterogeneous dataset.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">On the other hand, in FL (Fig. <a href="#S3.F2" title="Figure 2 ‣ III-B Experiment Plan ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, yellow figure), data resides locally and only the local models are transferred to the cloud server. The cloud server aggregates the models and then returns them back to the local sites. In this way, information and knowledge are shared between the sites indirectly by way of model sharing, as opposed to directly by way of data uploading.
It can be expected that the centralised approach will be the most accurate due to complete access to the data and that the FL approach will be superior to the local-only approach.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.4.1.1" class="ltx_text">III-B</span>2 </span>Robustness against unreliable clients</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">In rural agricultural farmlands, edge devices (i.e., clients) may sometimes experience unreliable power supply or network connection, which leads to devices dropping in and out during the training process. As a result, a trained model from a local site may not be uploaded to the cloud server for model aggregation. Alternatively, when the failure happens during the model downloading process, the local model is not updated with the aggregated model. To demonstrate the performance of FL for withstanding node failure, we simulate different scenarios under different client participation rates ranging from 100% to 25%. First of all, we investigate the impact of training data volume under the unreliable client setting on the performance of FL. Second, we evaluate how the failures during the model uploading or downloading process affect the performance of FL.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Results and Discussion</span>
</h3>

<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.4.1.1" class="ltx_text">III-C</span>1 </span>Comparison of different ML approaches</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">The first six columns of Table <a href="#S3.T3" title="TABLE III ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>
give a summary of our hyperparameter optimisation results for the short 200 iteration runs. It can be immediately observed that the local models have significantly lower accuracies, with the model at site A achieving a best-case accuracy of marginally above 70%, and the model at site C achieving, at best, 39.5% accuracy. On the other hand, the centralized model achieves nearly 99% test accuracy.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2305.09856/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="369" height="291" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">A comparison between FL, the centralized approach, and the local approach (see Fig. <a href="#S3.F2" title="Figure 2 ‣ III-B Experiment Plan ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) to prove why we should use FL when the centralized approach is not applicable (e.g., high communication cost).</span></figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.9.3.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S3.T3.4.2" class="ltx_text" style="font-size:90%;">Best testing accuracies by hyperparameter combination (columns) and model approach as shown in Fig. <a href="#S3.F2" title="Figure 2 ‣ III-B Experiment Plan ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (rows). Where <math id="S3.T3.3.1.m1.1" class="ltx_Math" alttext="T=200" display="inline"><semantics id="S3.T3.3.1.m1.1b"><mrow id="S3.T3.3.1.m1.1.1" xref="S3.T3.3.1.m1.1.1.cmml"><mi id="S3.T3.3.1.m1.1.1.2" xref="S3.T3.3.1.m1.1.1.2.cmml">T</mi><mo id="S3.T3.3.1.m1.1.1.1" xref="S3.T3.3.1.m1.1.1.1.cmml">=</mo><mn id="S3.T3.3.1.m1.1.1.3" xref="S3.T3.3.1.m1.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.3.1.m1.1c"><apply id="S3.T3.3.1.m1.1.1.cmml" xref="S3.T3.3.1.m1.1.1"><eq id="S3.T3.3.1.m1.1.1.1.cmml" xref="S3.T3.3.1.m1.1.1.1"></eq><ci id="S3.T3.3.1.m1.1.1.2.cmml" xref="S3.T3.3.1.m1.1.1.2">𝑇</ci><cn type="integer" id="S3.T3.3.1.m1.1.1.3.cmml" xref="S3.T3.3.1.m1.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.1.m1.1d">T=200</annotation></semantics></math>, the best accuracies for each approach are bolded. Where <math id="S3.T3.4.2.m2.2" class="ltx_Math" alttext="T\geq 2,000" display="inline"><semantics id="S3.T3.4.2.m2.2b"><mrow id="S3.T3.4.2.m2.2.3" xref="S3.T3.4.2.m2.2.3.cmml"><mi id="S3.T3.4.2.m2.2.3.2" xref="S3.T3.4.2.m2.2.3.2.cmml">T</mi><mo id="S3.T3.4.2.m2.2.3.1" xref="S3.T3.4.2.m2.2.3.1.cmml">≥</mo><mrow id="S3.T3.4.2.m2.2.3.3.2" xref="S3.T3.4.2.m2.2.3.3.1.cmml"><mn id="S3.T3.4.2.m2.1.1" xref="S3.T3.4.2.m2.1.1.cmml">2</mn><mo id="S3.T3.4.2.m2.2.3.3.2.1" xref="S3.T3.4.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.T3.4.2.m2.2.2" xref="S3.T3.4.2.m2.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.4.2.m2.2c"><apply id="S3.T3.4.2.m2.2.3.cmml" xref="S3.T3.4.2.m2.2.3"><geq id="S3.T3.4.2.m2.2.3.1.cmml" xref="S3.T3.4.2.m2.2.3.1"></geq><ci id="S3.T3.4.2.m2.2.3.2.cmml" xref="S3.T3.4.2.m2.2.3.2">𝑇</ci><list id="S3.T3.4.2.m2.2.3.3.1.cmml" xref="S3.T3.4.2.m2.2.3.3.2"><cn type="integer" id="S3.T3.4.2.m2.1.1.cmml" xref="S3.T3.4.2.m2.1.1">2</cn><cn type="integer" id="S3.T3.4.2.m2.2.2.cmml" xref="S3.T3.4.2.m2.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.2.m2.2d">T\geq 2,000</annotation></semantics></math>, the accuracy for an approach is bolded only if it exceeds the best accuracy in the preceding columns.
</span></figcaption>
<table id="S3.T3.7" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T3.7.3" class="ltx_tr">
<td id="S3.T3.7.3.4" class="ltx_td ltx_align_left ltx_border_r">Model</td>
<td id="S3.T3.7.3.3" class="ltx_td ltx_align_center" colspan="7">(#Epochs/Iteration <math id="S3.T3.5.1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.T3.5.1.1.m1.1a"><mi id="S3.T3.5.1.1.m1.1.1" xref="S3.T3.5.1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.T3.5.1.1.m1.1b"><ci id="S3.T3.5.1.1.m1.1.1.cmml" xref="S3.T3.5.1.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.1.1.m1.1c">E</annotation></semantics></math>, Minibatch Size <math id="S3.T3.6.2.2.m2.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.T3.6.2.2.m2.1a"><mi id="S3.T3.6.2.2.m2.1.1" xref="S3.T3.6.2.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.T3.6.2.2.m2.1b"><ci id="S3.T3.6.2.2.m2.1.1.cmml" xref="S3.T3.6.2.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.2.2.m2.1c">B</annotation></semantics></math>, Iterations <math id="S3.T3.7.3.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.T3.7.3.3.m3.1a"><mi id="S3.T3.7.3.3.m3.1.1" xref="S3.T3.7.3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.T3.7.3.3.m3.1b"><ci id="S3.T3.7.3.3.m3.1.1.cmml" xref="S3.T3.7.3.3.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.3.3.m3.1c">T</annotation></semantics></math>)</td>
<td id="S3.T3.7.3.5" class="ltx_td"></td>
</tr>
<tr id="S3.T3.7.4.1" class="ltx_tr">
<td id="S3.T3.7.4.1.1" class="ltx_td ltx_align_left ltx_border_r">Type</td>
<td id="S3.T3.7.4.1.2" class="ltx_td ltx_align_center">(1,10,200)</td>
<td id="S3.T3.7.4.1.3" class="ltx_td ltx_align_center">(5,10,200)</td>
<td id="S3.T3.7.4.1.4" class="ltx_td ltx_align_center">(20,10,200)</td>
<td id="S3.T3.7.4.1.5" class="ltx_td ltx_align_center">(1,50,200)</td>
<td id="S3.T3.7.4.1.6" class="ltx_td ltx_align_center">(5,50,200)</td>
<td id="S3.T3.7.4.1.7" class="ltx_td ltx_align_center ltx_border_r">(20,50,200)</td>
<td id="S3.T3.7.4.1.8" class="ltx_td ltx_align_center">(1,50,2000)</td>
<td id="S3.T3.7.4.1.9" class="ltx_td ltx_align_center">(1,50,10000)</td>
</tr>
<tr id="S3.T3.7.5.2" class="ltx_tr">
<td id="S3.T3.7.5.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Local (A)</td>
<td id="S3.T3.7.5.2.2" class="ltx_td ltx_align_center ltx_border_t">0.693</td>
<td id="S3.T3.7.5.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.7.5.2.3.1" class="ltx_text ltx_font_bold">0.701</span></td>
<td id="S3.T3.7.5.2.4" class="ltx_td ltx_align_center ltx_border_t">0.695</td>
<td id="S3.T3.7.5.2.5" class="ltx_td ltx_align_center ltx_border_t">0.692</td>
<td id="S3.T3.7.5.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.7.5.2.6.1" class="ltx_text ltx_font_bold">0.701</span></td>
<td id="S3.T3.7.5.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.699</td>
<td id="S3.T3.7.5.2.8" class="ltx_td ltx_align_center ltx_border_t">0.695</td>
<td id="S3.T3.7.5.2.9" class="ltx_td ltx_align_center ltx_border_t">0.697</td>
</tr>
<tr id="S3.T3.7.6.3" class="ltx_tr">
<td id="S3.T3.7.6.3.1" class="ltx_td ltx_align_left ltx_border_r">Local (B)</td>
<td id="S3.T3.7.6.3.2" class="ltx_td ltx_align_center">0.571</td>
<td id="S3.T3.7.6.3.3" class="ltx_td ltx_align_center">0.576</td>
<td id="S3.T3.7.6.3.4" class="ltx_td ltx_align_center">0.555</td>
<td id="S3.T3.7.6.3.5" class="ltx_td ltx_align_center">0.569</td>
<td id="S3.T3.7.6.3.6" class="ltx_td ltx_align_center">0.590</td>
<td id="S3.T3.7.6.3.7" class="ltx_td ltx_align_center ltx_border_r">0.577</td>
<td id="S3.T3.7.6.3.8" class="ltx_td ltx_align_center">0.592</td>
<td id="S3.T3.7.6.3.9" class="ltx_td ltx_align_center"><span id="S3.T3.7.6.3.9.1" class="ltx_text ltx_font_bold">0.601</span></td>
</tr>
<tr id="S3.T3.7.7.4" class="ltx_tr">
<td id="S3.T3.7.7.4.1" class="ltx_td ltx_align_left ltx_border_r">Local (C)</td>
<td id="S3.T3.7.7.4.2" class="ltx_td ltx_align_center"><span id="S3.T3.7.7.4.2.1" class="ltx_text ltx_font_bold">0.395</span></td>
<td id="S3.T3.7.7.4.3" class="ltx_td ltx_align_center">0.341</td>
<td id="S3.T3.7.7.4.4" class="ltx_td ltx_align_center">0.321</td>
<td id="S3.T3.7.7.4.5" class="ltx_td ltx_align_center">0.382</td>
<td id="S3.T3.7.7.4.6" class="ltx_td ltx_align_center">0.346</td>
<td id="S3.T3.7.7.4.7" class="ltx_td ltx_align_center ltx_border_r">0.339</td>
<td id="S3.T3.7.7.4.8" class="ltx_td ltx_align_center">0.363</td>
<td id="S3.T3.7.7.4.9" class="ltx_td ltx_align_center">0.378</td>
</tr>
<tr id="S3.T3.7.8.5" class="ltx_tr">
<td id="S3.T3.7.8.5.1" class="ltx_td ltx_align_left ltx_border_r">Centralized</td>
<td id="S3.T3.7.8.5.2" class="ltx_td ltx_align_center">0.985</td>
<td id="S3.T3.7.8.5.3" class="ltx_td ltx_align_center"><span id="S3.T3.7.8.5.3.1" class="ltx_text ltx_font_bold">0.988</span></td>
<td id="S3.T3.7.8.5.4" class="ltx_td ltx_align_center"><span id="S3.T3.7.8.5.4.1" class="ltx_text ltx_font_bold">0.988</span></td>
<td id="S3.T3.7.8.5.5" class="ltx_td ltx_align_center">0.980</td>
<td id="S3.T3.7.8.5.6" class="ltx_td ltx_align_center">0.987</td>
<td id="S3.T3.7.8.5.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T3.7.8.5.7.1" class="ltx_text ltx_font_bold">0.988</span></td>
<td id="S3.T3.7.8.5.8" class="ltx_td ltx_align_center"><span id="S3.T3.7.8.5.8.1" class="ltx_text ltx_font_bold">0.989</span></td>
<td id="S3.T3.7.8.5.9" class="ltx_td ltx_align_center"><span id="S3.T3.7.8.5.9.1" class="ltx_text ltx_font_bold">0.989</span></td>
</tr>
<tr id="S3.T3.7.9.6" class="ltx_tr">
<td id="S3.T3.7.9.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Federated</td>
<td id="S3.T3.7.9.6.2" class="ltx_td ltx_align_center ltx_border_bb">0.840</td>
<td id="S3.T3.7.9.6.3" class="ltx_td ltx_align_center ltx_border_bb">0.809</td>
<td id="S3.T3.7.9.6.4" class="ltx_td ltx_align_center ltx_border_bb">0.837</td>
<td id="S3.T3.7.9.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.7.9.6.5.1" class="ltx_text ltx_font_bold">0.883</span></td>
<td id="S3.T3.7.9.6.6" class="ltx_td ltx_align_center ltx_border_bb">0.863</td>
<td id="S3.T3.7.9.6.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.861</td>
<td id="S3.T3.7.9.6.8" class="ltx_td ltx_align_center ltx_border_bb">0.936</td>
<td id="S3.T3.7.9.6.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.7.9.6.9.1" class="ltx_text ltx_font_bold">0.963</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.4" class="ltx_p">The table also shows the accuracy of the best federated model. This approach, after 200 iterations, reaches the best performance of just over 88% when the number of epochs per
iteration is low (<math id="S3.SS3.SSS1.p2.1.m1.1" class="ltx_Math" alttext="E=1" display="inline"><semantics id="S3.SS3.SSS1.p2.1.m1.1a"><mrow id="S3.SS3.SSS1.p2.1.m1.1.1" xref="S3.SS3.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS3.SSS1.p2.1.m1.1.1.2" xref="S3.SS3.SSS1.p2.1.m1.1.1.2.cmml">E</mi><mo id="S3.SS3.SSS1.p2.1.m1.1.1.1" xref="S3.SS3.SSS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.p2.1.m1.1.1.3" xref="S3.SS3.SSS1.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.1.m1.1b"><apply id="S3.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1"><eq id="S3.SS3.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1.1"></eq><ci id="S3.SS3.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1.2">𝐸</ci><cn type="integer" id="S3.SS3.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.1.m1.1c">E=1</annotation></semantics></math>) and the batch size is higher (<math id="S3.SS3.SSS1.p2.2.m2.1" class="ltx_Math" alttext="B=50" display="inline"><semantics id="S3.SS3.SSS1.p2.2.m2.1a"><mrow id="S3.SS3.SSS1.p2.2.m2.1.1" xref="S3.SS3.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p2.2.m2.1.1.2" xref="S3.SS3.SSS1.p2.2.m2.1.1.2.cmml">B</mi><mo id="S3.SS3.SSS1.p2.2.m2.1.1.1" xref="S3.SS3.SSS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.p2.2.m2.1.1.3" xref="S3.SS3.SSS1.p2.2.m2.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.2.m2.1b"><apply id="S3.SS3.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1"><eq id="S3.SS3.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.1"></eq><ci id="S3.SS3.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.2">𝐵</ci><cn type="integer" id="S3.SS3.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.2.m2.1c">B=50</annotation></semantics></math>).
Unlike the centralized model, however, the federated approach is relatively sensitive to the choice of hyperparameters: specifically, <math id="S3.SS3.SSS1.p2.3.m3.1" class="ltx_Math" alttext="E=1" display="inline"><semantics id="S3.SS3.SSS1.p2.3.m3.1a"><mrow id="S3.SS3.SSS1.p2.3.m3.1.1" xref="S3.SS3.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS3.SSS1.p2.3.m3.1.1.2" xref="S3.SS3.SSS1.p2.3.m3.1.1.2.cmml">E</mi><mo id="S3.SS3.SSS1.p2.3.m3.1.1.1" xref="S3.SS3.SSS1.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.p2.3.m3.1.1.3" xref="S3.SS3.SSS1.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.3.m3.1b"><apply id="S3.SS3.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p2.3.m3.1.1"><eq id="S3.SS3.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p2.3.m3.1.1.1"></eq><ci id="S3.SS3.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p2.3.m3.1.1.2">𝐸</ci><cn type="integer" id="S3.SS3.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.3.m3.1c">E=1</annotation></semantics></math> and <math id="S3.SS3.SSS1.p2.4.m4.1" class="ltx_Math" alttext="B=50" display="inline"><semantics id="S3.SS3.SSS1.p2.4.m4.1a"><mrow id="S3.SS3.SSS1.p2.4.m4.1.1" xref="S3.SS3.SSS1.p2.4.m4.1.1.cmml"><mi id="S3.SS3.SSS1.p2.4.m4.1.1.2" xref="S3.SS3.SSS1.p2.4.m4.1.1.2.cmml">B</mi><mo id="S3.SS3.SSS1.p2.4.m4.1.1.1" xref="S3.SS3.SSS1.p2.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.p2.4.m4.1.1.3" xref="S3.SS3.SSS1.p2.4.m4.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.4.m4.1b"><apply id="S3.SS3.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p2.4.m4.1.1"><eq id="S3.SS3.SSS1.p2.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.p2.4.m4.1.1.1"></eq><ci id="S3.SS3.SSS1.p2.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.p2.4.m4.1.1.2">𝐵</ci><cn type="integer" id="S3.SS3.SSS1.p2.4.m4.1.1.3.cmml" xref="S3.SS3.SSS1.p2.4.m4.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.4.m4.1c">B=50</annotation></semantics></math> appear to be good choices and we proceeded with further experiments using these hyperparameters.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x4.png" id="S3.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x5.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x6.png" id="S3.F4.sf3.g1" class="ltx_graphics ltx_img_landscape" width="152" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">The training performance of FL with random and complete dropout clients. Each sub-figure shows the FL training performance when a site randomly and completely drops out during FL training process with various probabilities.</span></figcaption>
</figure>
<figure id="S3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x7.png" id="S3.F5.sf1.g1" class="ltx_graphics ltx_img_square" width="161" height="138" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x8.png" id="S3.F5.sf2.g1" class="ltx_graphics ltx_img_square" width="161" height="138" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.3.2" class="ltx_text" style="font-size:90%;">FL model accuracy with random and partial dropout clients. Note that we select the model after 2,000 training iterations. Each sub-figure demonstrates that under the same link failure, how data heterogeneity affects the FL accuracy. “UP” and “DL” indicate unreliable model upload and download respectively. From both (a) and (b), we can see that site A has the highest impact of the overall accuracy due to its largest data volume and class labels.</span></figcaption>
</figure>
<figure id="S3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x9.png" id="S3.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="152" height="122" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x10.png" id="S3.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="152" height="122" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/x11.png" id="S3.F6.sf3.g1" class="ltx_graphics ltx_img_landscape" width="152" height="122" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S3.F6.3.2" class="ltx_text" style="font-size:90%;">Performance comparison between different clients and dropout types. Each sub-figure demonstrates that within the same site (i.e., the same training dataset), how different failure types affect the FL accuracy. “UP” and “DL” indicate unreliable model upload and download respectively. For example, from all 3 figures, upload failure barely affects the FL accuracy compared to download failure.</span></figcaption>
</figure>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">The results of the further experiments are also given in Table <a href="#S3.T3" title="TABLE III ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> (rightmost two columns) and also Fig. <a href="#S3.F3" title="Figure 3 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This column and the figure show that the federated model significantly improves its accuracy with additional iterations.
The best model found with FL achieves nearly 94% test accuracy after 2,000 iterations and exceeds 96% accuracy after 10,000 iterations, both good improvements compared to the 200-iteration case. Despite its lack of centralised data, FL can still achieve 96% accuracy as the centralized approach, demonstrating that FL will be a good fit for applications where centralized training is inapplicable. Note that in both cases, the models labelled as “local” are not part of the federation and simulate a situation where models train locally and there is no information sharing between sites at all.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.4.1.1" class="ltx_text">III-C</span>2 </span>FL robustness against client dropout</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p"><span id="S3.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Clients completely drop out.</span>
Fig. <a href="#S3.F4" title="Figure 4 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the training performance of FL when different clients randomly and completely drop out. For example, in Fig. <a href="#S3.F4" title="Figure 4 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(a), Client A will randomly drop out during the training based on a pre-defined participation rate. From Fig. <a href="#S3.F4" title="Figure 4 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(a), we can see that the training performance is barely affected when Client A only participates 75% of the training iteration. However, larger gaps can be observed when the participation rate drops to 50% or lower. Nevertheless, even with a 75% decrease in participation rate compared to 100% participation, only less than 15% reduction in model accuracy is observed. This result confirms that FL is robust to random client dropout.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">The impact of different clients dropout can also be seen by comparing Fig. <a href="#S3.F4" title="Figure 4 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(a), Fig. <a href="#S3.F4" title="Figure 4 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(b), and Fig. <a href="#S3.F4" title="Figure 4 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(c). Due to the heterogeneity in our dataset (as we mentioned in Sec. <a href="#S3.SS1" title="III-A Dataset ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>), the impact of different sites dropping out on FL model accuracy varies. For example, Client A has a more significant impact where almost a 10% accuracy decrease can be spotted with a participation rate decrease from 50% to 25%. On the other hand, we can only see less than a 5% decrease in accuracy when Client B or C drops out. As we expected, the influence of a client on FL depends on the amount of data and the number of classes it has.</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p"><span id="S3.SS3.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Clients partially drop out.</span> We define partial dropout as clients may randomly fail to upload their local model or download the aggregated model during model training.
Fig. <a href="#S3.F5" title="Figure 5 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Fig. <a href="#S3.F6" title="Figure 6 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> compared the performance of the models trained at various client participation rates.</p>
</div>
<div id="S3.SS3.SSS2.p4" class="ltx_para">
<p id="S3.SS3.SSS2.p4.1" class="ltx_p">Fig. <a href="#S3.F5" title="Figure 5 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(a) shows the impact of clients randomly failing to upload their locally trained models. We can see that there is less than a 4% accuracy decrease when a client does not upload its model. Meanwhile, we also notice that the negative impact is less noticeable if the dropout happens in the client with fewer data, which matches our previous observation. Similar conclusions can also be drawn in Fig. <a href="#S3.F5" title="Figure 5 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(b) when a client fails to download the aggregated models.</p>
</div>
<div id="S3.SS3.SSS2.p5" class="ltx_para">
<p id="S3.SS3.SSS2.p5.1" class="ltx_p">In Fig. <a href="#S3.F6" title="Figure 6 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we compared the different impacts of failing in upload or download on the FL model accuracy. For example, we can see from Fig. <a href="#S3.F6" title="Figure 6 ‣ III-C1 Comparison of different ML approaches ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>(a) that clients dropping out during model download has a larger impact on the model accuracy. This observation holds for different participation rates as well as different clients.</p>
</div>
<figure id="S3.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/result_fig/Singleimage1.jpg" id="S3.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="448" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F7.sf1.3.2" class="ltx_text" style="font-size:90%;">True Positive</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/result_fig/Singleimage2.jpg" id="S3.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F7.sf2.3.2" class="ltx_text" style="font-size:90%;">Possible False Positive</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/result_fig/Singleimage3.jpg" id="S3.F7.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F7.sf3.3.2" class="ltx_text" style="font-size:90%;">Night Mode</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F7.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/result_fig/Singleimage4.jpg" id="S3.F7.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F7.sf4.3.2" class="ltx_text" style="font-size:90%;">Over Exposed Night Mode</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S3.F7.3.2" class="ltx_text" style="font-size:90%;">Examples of single images from Wellington camera trap dataset</span></figcaption>
</figure>
<figure id="S3.F8" class="ltx_figure"><img src="/html/2305.09856/assets/result_fig/Preprocessing.png" id="S3.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="195" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.3.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S3.F8.4.2" class="ltx_text" style="font-size:90%;">Preprocessing of image bursts</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">FL in Camera traps</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The current biodiversity crisis requires a global network of remote cameras to monitor and measure essential biodiversity variables using non-invasive remote cameras <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. A camera trap is a camera with a motion sensor and infrared flash suitable for sampling medium and large-sized birds and mammals with minimal disruption to animal behaviours. There is an increasing trend of using camera traps for monitoring different biodiversity trends, for example, monitoring highway crossing for observing the impact of human activities on wildlife <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, and studying the impact of climate change, population shape, and trophic interactions on elk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Recently, ML has been very successfully used in image-based biodiversity surveys for decision-making purposes by answering critical conservation questions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. However, there are limited coordinated efforts among these camera studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. One limitation is the hesitation in sharing data among parties. Federated learning can play a vital role in this area while maintaining data sovereignty as a large number of participants can create a collaborative ML system incorporating features of all participants’ data.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Dataset</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Wellington camera traps dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> is used to study the robustness of the FL system. This dataset contains 270,450 images, and 90,150 bursts from 187 camera locations in Wellington, New Zealand. The motion sensor cameras recorded a burst of three images when triggered. The images are taken at night and daytime. The dataset is labelled by citizen scientists or professional ecologists from the Victoria University of Wellington, New Zealand. The images are classified into seventeen categories, with a high degree of imbalance across these categories. There is a varying degree of image quality and about 25% of the images are empty, which is considered a false positive.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Several small and camouflaged animals are present in these images, which are very difficult to detect; some example images are shown in Fig. <a href="#S3.F7" title="Figure 7 ‣ III-C2 FL robustness against client dropout ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. However, the bursts of images provide an opportunity to detect animals by comparing the images in a single burst. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Experiment Setup</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">From the Wellington Camera Trap dataset, we did not consider any image bursts that include less than three images and also did not consider sites that have less than 75 bursts. The image bursts are preprocessed by employing the Mixture of Gaussian (MoG) method and then constructing 3 channel images, as shown in Fig. <a href="#S3.F8" title="Figure 8 ‣ III-C2 FL robustness against client dropout ‣ III-C Results and Discussion ‣ III FL in Precision weeds detection ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. We have selected different numbers of sites for training, validation, and testing (discussed in the next section).
For FL experiments, we have used Flower <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> while using the federated averaging method for client model aggregation. Squeezenet CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> is used with Adam optimiser and starting learning rate of 0.0001. Categorical cross-entropy loss function weighted to account for class imbalance and standard augmentations for training batches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. We kept 100 FL iterations with 10 local epochs per iteration and a local batch size of 128.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2305.09856/assets/result_fig/Label-flipping-results.png" id="S4.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="334" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.3.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S4.F9.4.2" class="ltx_text" style="font-size:90%;">FL performance under different numbers of mislabelled training data</span></figcaption>
</figure>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2305.09856/assets/result_fig/learning_only.png" id="S4.F10.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="317" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F10.3.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S4.F10.4.2" class="ltx_text" style="font-size:90%;">FL performance when the learning rate of one client is misconfigured and changed from 0.0001 to 0.01</span></figcaption>
</figure>
<figure id="S4.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F11.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/result_fig/Label-flipping-results4.png" id="S4.F11.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F11.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F11.sf1.3.2" class="ltx_text" style="font-size:90%;">FL performance in the presence of mislabelled data</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F11.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.09856/assets/result_fig/Label-flipping-results5.png" id="S4.F11.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F11.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F11.sf2.3.2" class="ltx_text" style="font-size:90%;">FL performance in the presence of both mislabelled data and misconfigured learning rate of one client (10 times higher)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S4.F11.3.2" class="ltx_text" style="font-size:90%;">The impact of learning rate on each client in the presence of mislabelled data</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Results and Discussion</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The following sets of experiments are conducted to observe the robustness of FL system against ML-specific inconsistencies.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS1.4.1.1" class="ltx_text">IV-C</span>1 </span>FL Robustness against Mislabelled data</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">ML-specific inconsistency can be due to low-quality data in terms of mislabelled or flipped label records. Several experiments were conducted to study when one or more clients have mislabelled some or all examples in their training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Such mislabelled data can affect the global model when the server aggregates the local parameters trained on them. The inherent inaccessibility of the federated server to the clients and clients’ data makes it difficult to detect such issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">To evaluate the robustness of FL against such mislabelled clients, we conducted a series of experiments training FL models to compare three scenarios. In the baseline (i.e., Case A), all 15 clients had correctly labelled data. In Case B, 7 clients had mislabelled data while 8 clients had correctly labelled data. Case C involved training the FL model using data only from the 8 clients with correctly labelled data.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p">Fig. <a href="#S4.F9" title="Figure 9 ‣ IV-B Experiment Setup ‣ IV FL in Camera traps ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows the Area Under the Receiver Operating Characteristics (AUROC) values for all FL iterations for all three cases. Case A shows the AUROC values of around 0.9 after the 20th iteration. Case B has around 47% clients with mislabelled data and shows the AUROC value of 0.86 after the 20th iteration. For case C, where the clients with mislabelled data are removed and the global model considers only 8 normal clients; the AUROC value is around 0.88 after the 20th iteration. We can conclude from the results that the effect of mislabelled data is there on the performance of the FL model but not very significant, which shows the robustness of FL against such attacks.
Some of these findings do not concur with literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. One factor that is really important to consider here is the learning rate; we kept a low learning rate (0.0001) for all our clients, which keeps the changes to the weights very small due to local learning. We have conducted the second set of experiments (discussed next) to study the effect of learning rate in mislabelled data scenarios.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS2.4.1.1" class="ltx_text">IV-C</span>2 </span>FL Robustness against Misconfiguration</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">One ML-specific inconsistency can be due to the misconfiguration of hyperparameters. One of the hyperparameters that affect the accuracy of the neural networks model is the learning rate, which controls how quickly the model is adapted to the problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. Even for FL systems, the learning rate has shown a significant impact on the accuracy of the models and has been used as one of the factors that can be adapted to improve accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, fight attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and flexible client participation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> among other purposes. We have conducted experiments with six normal clients to study the impact of learning rate on FL systems. We changed the learning rate of only one client from 0.0001 to 0.01; the results are shown in Fig. <a href="#S4.F10" title="Figure 10 ‣ IV-B Experiment Setup ‣ IV FL in Camera traps ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. The results show that for learning rate up to 0.004, the final AUROC values are not affected and is always around 0.88. However, as the learning rate exceeds 0.004, the maximum AUROC cannot go higher than 0.5. This shows that FL shows high robustness against certain misconfigurations (some clients assigned with a higher local learning rate) to a certain extent but as the values become very high, the system cannot perform well.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS3.4.1.1" class="ltx_text">IV-C</span>3 </span>FL Robustness against Mislabelled data and Misconfiguration</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">The next set of experiments is conducted to study the effect of misconfiguration on the performance of the FL model with different learning rates when some clients have mislabelled data. For these experiments, we have chosen five normal clients and one misconfigured client with mislabelled data. The learning rate for the misconfigured client is changed from 0.0001 to 0.001 to observe the effect on the FL system, as shown in Fig. <a href="#S4.F11" title="Figure 11 ‣ IV-B Experiment Setup ‣ IV FL in Camera traps ‣ Keep It Simple: Fault Tolerance Evaluation of Federated Learning with Unreliable Clients Identify applicable funding agency here. If none, delete this." class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<p id="S4.SS3.SSS3.p2.1" class="ltx_p">The results show that the higher learning rate plays a significant role in the final AUROC as it reduces from 0.88 to 0.85 when the learning rate of the misconfigured client is changed from 0.0001 to 0.001. Also, in early iterations of FL, the impact is more significant and it takes longer for the system to converge in the second case of a higher learning rate. Hence, an important finding is that low local learning rates impact the robustness of the FL systems.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Related work</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we look at some research efforts that tackled unreliable client issues for FL and classify them into two categories: infrastructure-level errors and ML-specific inconsistencies.
</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><em id="S5.p2.1.1" class="ltx_emph ltx_font_italic">Infrastructure-level errors</em>: FL requires sharing of local model parameters between clients and a server over multiple learning rounds until the global model converges. In environments with limited and unreliable network resources, such communication may not be possible. As a result, it can affect the training time and further lead to issues such as unstable and/or slow convergence of the global model.
A compensation scheme proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> suggested that any missing model updates can be replaced by the updates from other clients based on their similarity. Their experiments with the CIFAR-10 dataset show high convergence of the global model under varying successful communication probability for ten clients with a learning rate of 0.001 for every client.
A similar approach has been proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> where it considered local model updates as “friends” when the clients’ data distributions are sufficiently similar. To identify “friends”, the pairwise similarity score among the local model updates is calculated by the FL server. Whenever any client dropout happens, the FL server replaces the missing model update with its “friends”. Experiments were conducted using MNIST and CIFAR-10 datasets. The results showed that model replacement using the friends’ model successfully mitigates the effect of client dropout.
Recently, a secure and efficient FL (SEFL) framework was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. SEFL considers two servers, one for model aggregation and one for managing cryptography primitives. The clients use the weight pruning technique to prune the local model update before sending the encrypted updates to the aggregating server. At the server, the encrypted and pruned updates are homomorphically added. In order to decrypt the aggregated value, the other server is contacted. To ensure the security and privacy of the aggregated model values differential privacy approach is used, which is not discussed any further as it is out of the scope of this work. However, a very interesting and related property of the algorithm is that the aggregation server can train an accurate global model even when only 10% of the clients share their local updates with the server.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><em id="S5.p3.1.1" class="ltx_emph ltx_font_italic">ML-specific inconsistencies</em>: Data from different clients can be different in terms of quality and label noise. Wrong and/or noisy labels at the clients can negatively affect the global model as the server cannot access local data to filter out the noise. To tackle this problem, different methods have been proposed. For example, a two-level sampling approach from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> allows a) the server to select better client models and b) clients to select clean local data. The confidence score of data samples is calculated using the global model to calculate the overall confidence of the client. The experiments conducted with the CIFAR-10 dataset with 100 clients containing imbalanced data with varying noise ratios show that the proposed approach outperforms several baseline algorithms. FL under Label Noise (FedLN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> estimates per client label noise level and limits the effect of noisy samples on the model’s generalisability. At the federated server, Noise-aware Federated Averaging (NA-FedAvg)  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> considers estimated clients’ noise levels to perform noise-aware aggregation of the client models. Four different datasets are used to test NA-FedAvg with varying numbers of noisy clients with different noise levels. With all noisy clients, the model performance degraded substantially; however, the presence of only 20% of clean clients enabled the model to perform at 70% for all noise levels. A different approach for reducing the impact of irrelevant or bad quality clients’ data on the performance of FL is a distributed selection method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> that enables clients to choose only a relevant subset from complete data available at the clients. A model requester is proposed for the FL system that provides a benchmarked dataset to the clients to identify a relevant subset of data for a particular FL task.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we systematically evaluate the impact of unreliable clients on federated learning (FL) performance in rural environments. We investigated different scenarios of unreliable clients including client dropout, misconfiguration, and low-quality training data. Our experiments are conducted on two applications (weeds detection in precision agriculture and wildlife detection in camera traps) using real-world datasets <span id="S6.p1.1.1" class="ltx_text" style="color:#000000;"> and a low number of clients (ranging from 3 to 6). Intuitively, scenarios with a reduced number of clients should be more susceptible to performance degradation in case of one or more clients malfunctioning or misconfiguration. Surprisingly,</span> experiments show empirical proof that the federated averaging method is resilient to such unreliable clients, both to infrastructure-level and ML-specific inconsistencies. First, the weeds detection case study explored the tolerance to the infrastructure-level category of unreliable clients, such as those with faulty network connections. Second, the animal detection case study (via camera traps) showed the robustness of federated learning towards ML-specific deficiencies such as mislabelled data or incorrect parameter values. We have shown that despite its simplicity, federated averaging learning should be the algorithm of choice for distributed training environments with unreliable rural infrastructure and non-technical users.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Our next step involves investigating the applicability of techniques such as Reinforcement Learning as part of the client selection to further improve the performance of Federated Averaging by selecting the best data sources/clients to train the global model. We will further develop platforms and approaches to support the real-world deployment of FL. The platform we used in this paper using Function-as-a-Service provides the first step towards this goal. By introducing higher level systems, programming abstractions, and libraries, we will enable the optimisation workloads and resources of FL in real-world systems.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, Y. Zou, Y. Zhang, and M. Guizani, “Reliable
federated learning for mobile networks,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless
Communications</em>, vol. 27, no. 2, pp. 72–80, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S. K. Lo, Q. Lu, C. Wang, H.-Y. Paik, and L. Zhu, “A systematic literature
review on federated machine learning: From a software engineering
perspective,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, vol. 54, no. 5, pp.
1–39, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys Tutorials</em>,
vol. 22, no. 3, pp. 2031–2063, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
P. Patros, M. Ooi, V. Huang, M. Mayo, C. Anderson, S. Burroughs, M. Baughman,
O. Almurshed, O. Rana, R. Chard <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Rural ai: Serverless-powered
federated learning for remote applications,” <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Computing</em>,
2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
O. Almurshed, P. Patros, V. Huang, M. Mayo, M. Ooi, R. Chard, K. Chard,
O. Rana, H. Nagra, M. Baughman <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Adaptive edge-cloud
environments for rural ai,” in <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">2022 IEEE International Conference on
Services Computing (SCC)</em>.   IEEE, 2022,
pp. 74–83.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Xu, Y. Liao, H. Xu, Z. Ma, L. Wang, and J. Liu, “Adaptive control of local
updating and model compression for efficient federated learning,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Mobile Computing</em>, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-Bahaei, “Energy
efficient federated learning over wireless communication networks,”
<em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1911.02417, 2019. [Online]. Available:
http://arxiv.org/abs/1911.02417

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
L. Liu, J. Zhang, S. Song, and K. B. Letaief, “Client-edge-cloud hierarchical
federated learning,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International Conference on
Communications (ICC)</em>.   IEEE, 2020, pp.
1–6.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y. Mao, Z. Zhao, M. Yang, L. Liang, Y. Liu, W. Ding, T. Lan, and X.-P. Zhang,
“Safari: Sparsity enabled federated learning with limited and unreliable
communications,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.02321</em>, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
H. Wang and J. Xu, “Friends to help: Saving federated learning from client
dropout,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.13222</em>, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
V. Tsouvalas, A. Saeed, T. Ozcelebi, and N. Meratnia, “Federated learning with
noisy labels,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2208.09378</em>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Z. Wang, T. Zhou, G. Long, B. Han, and J. Jiang, “Fednoil: A simple two-level
sampling method for federated learning with noisy labels,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2205.10110</em>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. Kamp, J. Fischer, and J. Vreeken, “Federated learning from small
datasets,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.03469</em>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Y. Xue, C. Niu, Z. Zheng, S. Tang, C. Lyu, F. Wu, and G. Chen, “Toward
understanding the influence of individual clients in federated learning,” in
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
vol. 35, no. 12, 2021, pp. 10 560–10 567.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. Nilsson, S. Smith, G. Ulm, E. Gustavsson, and M. Jirstrand, “A performance
evaluation of federated learning algorithms,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
second workshop on distributed infrastructures for deep learning</em>, 2018, pp.
1–8.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-Efficient Learning of Deep Networks from Decentralized
Data,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics</em>, ser. Proceedings of Machine Learning
Research, A. Singh and J. Zhu, Eds., vol. 54.   Fort Lauderdale, FL, USA: PMLR, 20–22 Apr 2017, pp. 1273–1282.
[Online]. Available: http://proceedings.mlr.press/v54/mcmahan17a.html

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
R. Chard, Y. Babuji, Z. Li, T. Skluzacek, A. Woodard, B. Blaiszik, I. Foster,
and K. Chard, “FuncX: A federated function serving fabric for science,”
in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">29th International Symposium on High-Performance Parallel and
Distributed Computing</em>, 2020, pp. 65–76.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
P. Wang, E. Fan, and P. Wang, “Comparative analysis of image classification
algorithms based on traditional machine learning and deep learning,”
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition Letters</em>, vol. 141, pp. 61–67, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and
privacy (SP)</em>.   IEEE, 2019, pp.
739–753.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, and H. Yu, “Federated learning,”
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Synthesis Lectures on Artificial Intelligence and Machine Learning</em>,
vol. 13, no. 3, pp. 1–207, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
E. Sannara, F. Portet, P. Lalanda, and V. German, “A federated learning
aggregation algorithm for pervasive computing: Evaluation and comparison,”
in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Pervasive Computing and
Communications (PerCom)</em>.   IEEE, 2021,
pp. 1–10.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Deng, C. Wang, X. Meng, Y. Wang, J. Li, S. Lin, S. Han, F. Miao,
S. Rajasekaran, and C. Ding, “A secure and efficient federated learning
framework for nlp,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.11934</em>, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
L. Wang, S. Xu, X. Wang, and Q. Zhu, “Addressing class imbalance in federated
learning,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, vol. 35, no. 11, 2021, pp. 10 165–10 173.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Z. Lv, H. Cao, F. Zhang, Y. Ren, B. Wang, C. Chen, N. Li, H. Chang, and
W. Wang, “Awfc: Preventing label flipping attacks towards federated learning
for intelligent iot,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">The Computer Journal</em>, vol. 65, no. 11, pp.
2849–2859, 2022.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
N. M. Jebreel, J. Domingo-Ferrer, D. Sánchez, and A. Blanco-Justicia,
“Defending against the label-flipping attack in federated learning,”
<em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.01982</em>, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, “How to backdoor
federated learning,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twenty Third International
Conference on Artificial Intelligence and Statistics</em>, ser. Proceedings of
Machine Learning Research, S. Chiappa and R. Calandra, Eds., vol. 108.   PMLR, 26–28 Aug 2020, pp. 2938–2948.
[Online]. Available:
https://proceedings.mlr.press/v108/bagdasaryan20a.html

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
W. Holmes, M. P.-L. Ooi, M. Look, Y. C. Kuang, R. Simpkin, D. Blanchon, and
S. Demidenko, “Proximal near-infrared spectral reflectance characterisation
of weeds species in New Zealand pasture,” in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">IEEE International
Instrumentation and Measurement Technology Conference (I2MTC)</em>.   IEEE, 2019, pp. 1–6.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
R. Steenweg, M. Hebblewhite, R. Kays, J. Ahumada, J. T. Fisher, C. Burton,
S. E. Townsend, C. Carbone, J. M. Rowcliffe, J. Whittington <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Scaling-up camera traps: Monitoring the planet’s biodiversity with networks
of remote sensors,” <em id="bib.bib28.2.2" class="ltx_emph ltx_font_italic">Frontiers in Ecology and the Environment</em>,
vol. 15, no. 1, pp. 26–34, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
M. Barrueto, A. T. Ford, and A. P. Clevenger, “Anthropogenic effects on
activity patterns of wildlife at crossing structures,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Ecosphere</em>,
vol. 5, no. 3, pp. 1–19, 2014.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
J. F. Brodie, E. Post, J. Berger, and F. Watson, “Trophic interactions and
dynamic herbivore responses to snowpack,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Climate Change Responses</em>,
vol. 1, no. 1, pp. 1–8, 2014.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
I. Zualkernan, S. Dhou, J. Judas, A. R. Sajun, B. R. Gomez, and L. A. Hussain,
“An iot system using deep learning to classify camera trap images on the
edge,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Computers</em>, vol. 11, no. 1, p. 13, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
O. Pantazis, G. J. Brostow, K. E. Jones, and O. Mac Aodha, “Focus on the
positives: Self-supervised learning for biodiversity monitoring,” in
<em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer
Vision</em>, 2021, pp. 10 583–10 592.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
M. S. Norouzzadeh, D. Morris, S. Beery, N. Joshi, N. Jojic, and J. Clune, “A
deep active learning system for species identification and counting in camera
trap images,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Methods in ecology and evolution</em>, vol. 12, no. 1, pp.
150–161, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
V. Anton, S. Hartley, A. Geldenhuis, and H. U. Wittmer, “Monitoring the
mammalian fauna of urban areas using remote cameras and citizen science,”
<em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Journal of Urban Ecology</em>, vol. 4, no. 1, p. juy002, 2018.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
B. M. Shashidhara, D. Mehta, Y. Kale, D. Morris, and M. Hazen, “Sequence
information channel concatenation for improving camera trap image burst
classification,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.00116</em>, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao,
L. Sani, K. H. Li, T. Parcollet, P. P. B. de Gusmão <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“Flower: A friendly federated learning framework,” 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
V. Pothos, D. Kastaniotis, I. Theodorakopoulos, and N. Fragoulis, “A fast,
embedded implementation of a convolutional neural network for image
recognition,” 2016.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on federated
learning,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 216, p. 106775, 2021.
[Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0950705121000381

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
T. Takase, S. Oyama, and M. Kurihara, “Effective neural network training with
adaptive learning rate based on training loss,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Neural Networks</em>, vol.
101, pp. 68–78, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
C. Xu, S. Liu, Z. Yang, Y. Huang, and K.-K. Wong, “Learning rate optimization
for federated learning exploiting over-the-air computation,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE
Journal on Selected Areas in Communications</em>, vol. 39, no. 12, pp.
3742–3756, 2021.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
M. S. Ozdayi, M. Kantarcioglu, and Y. R. Gel, “Defending against backdoors in
federated learning with robust learning rate,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
AAAI Conference on Artificial Intelligence</em>, vol. 35, no. 10, 2021, pp.
9268–9276.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
H. Yang, X. Zhang, P. Khanduri, and J. Liu, “Anarchic federated learning,” in
<em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2022, pp. 25 331–25 363.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
T. Tuor, S. Wang, B. J. Ko, C. Liu, and K. K. Leung, “Overcoming noisy and
irrelevant data in federated learning,” in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">2020 25th International
Conference on Pattern Recognition (ICPR)</em>.   IEEE, 2021, pp. 5020–5027.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.09855" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.09856" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.09856">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.09856" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.09857" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 07:05:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
