<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Navigating the Future of Federated Recommendation Systems with Foundation Models</title>
<!--Generated on Tue Jun  4 03:06:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Federated Recommendation System,  Foundation Model,  Privacy Preserving,  Security, 
" lang="en" name="keywords"/>
<base href="/html/2406.00004v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S1" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S2" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work and Contribution</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Background and Preliminary</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.SS1" title="In III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Federated Recommendation System</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.SS1.SSS1" title="In III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>1 </span>Taxonomy of FRS</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.SS2" title="In III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Foundation Model</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.SS2.SSS1" title="In III-B Foundation Model ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>1 </span>Taxonomy of FM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.SS2.SSS2" title="In III-B Foundation Model ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span>2 </span>Adaptation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S4" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Federated Recommendation Systems with Foundation Models</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S4.SS1" title="In IV Federated Recommendation Systems with Foundation Models ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Client Model Update</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S4.SS2" title="In IV Federated Recommendation Systems with Foundation Models ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Communication</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S4.SS3" title="In IV Federated Recommendation Systems with Foundation Models ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Global Aggregation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S5" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Challenges</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S5.SS1" title="In V Challenges ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Data-Related Challenges</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S5.SS2" title="In V Challenges ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Model-Related Challenges</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S6" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Future Directions</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S6.SS1" title="In VI Future Directions ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-A</span> </span><span class="ltx_text ltx_font_italic">Data Augmentation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S6.SS2" title="In VI Future Directions ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-B</span> </span><span class="ltx_text ltx_font_italic">Cold-Start Recommendation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S6.SS3" title="In VI Future Directions ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-C</span> </span><span class="ltx_text ltx_font_italic">Multi-Modal Recommendation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S6.SS4" title="In VI Future Directions ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-D</span> </span><span class="ltx_text ltx_font_italic">Real-Time Recommendations</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S6.SS5" title="In VI Future Directions ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-E</span> </span><span class="ltx_text ltx_font_italic">Enhanced Recommendation Explainability</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S6.SS6" title="In VI Future Directions ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-F</span> </span><span class="ltx_text ltx_font_italic">Adavanced Metrics</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S7" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Resources</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S7.SS1" title="In VII Resources ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VII-A</span> </span><span class="ltx_text ltx_font_italic">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S7.SS2" title="In VII Resources ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VII-B</span> </span><span class="ltx_text ltx_font_italic">Metrics</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S8" title="In Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VIII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Navigating the Future of Federated Recommendation Systems with Foundation Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Zhiwei Li,
Guodong Long
</span><span class="ltx_author_notes">Manuscript created April, 2024; This work was developed by the IEEE Publication Technology Department. This work is distributed under the <span class="ltx_text ltx_LaTeX_logo" id="id1.1.id1" style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_text" id="id1.1.id1.1" style="position:relative; bottom:0.4ex;font-variant:small-caps;;">a</span>T<span class="ltx_text" id="id1.1.id1.2" style="position:relative; bottom:-0.2ex;font-variant:small-caps;font-size:120%;">e</span>X</span> Project Public License (LPPL) ( http://www.latex-project.org/ ) version 1.3. A copy of the LPPL, version 1.3, is included in the base <span class="ltx_text ltx_LaTeX_logo" id="id2.2.id2" style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_text" id="id2.2.id2.1" style="position:relative; bottom:0.4ex;font-variant:small-caps;;">a</span>T<span class="ltx_text" id="id2.2.id2.2" style="position:relative; bottom:-0.2ex;font-variant:small-caps;font-size:120%;">e</span>X</span> documentation of all distributions of <span class="ltx_text ltx_LaTeX_logo" id="id3.3.id3" style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_text" id="id3.3.id3.1" style="position:relative; bottom:0.4ex;font-variant:small-caps;;">a</span>T<span class="ltx_text" id="id3.3.id3.2" style="position:relative; bottom:-0.2ex;font-variant:small-caps;font-size:120%;">e</span>X</span> released 2003/12/01 or later. The opinions expressed here are entirely that of the author. No warranty is expressed or implied. User assumes all risk.Zhiwei Li, Guodong Long are with the Australian Artificial Intelligence Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW 2007, Australia (email: zhw.li@outloo.com; guodong.long@uts.edu.au)</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.id1">In recent years, the integration of federated learning (FL) and recommendation systems (RS), known as Federated Recommendation Systems (FRS), has attracted attention for preserving user privacy by keeping private data on client devices. However, FRS faces inherent limitations such as data heterogeneity and scarcity, due to the privacy requirements of FL and the typical data sparsity issues of RSs.
Models like ChatGPT are empowered by the concept of transfer learning and self-supervised learning, so they can be easily applied to the downstream tasks after fine-tuning or prompting. These models, so-called Foundation Models (FM), fouce on understanding the human’s intent and perform following their designed roles in the specific tasks, which are widely recognized for producing high-quality content in the image and language domains.
Thus, the achievements of FMs inspire the design of FRS and suggest a promising research direction: integrating foundation models to address the above limitations.
In this study, we conduct a comprehensive review of FRSs with FMs. Specifically, we: 1) summarise the common approaches of current FRSs and FMs; 2) review the challenges posed by FRSs and FMs; 3) discuss potential future research directions; and 4) introduce some common benchmarks and evaluation metrics in the FRS field.
We hope that this position paper provides the necessary background and guidance to explore this interesting and emerging topic.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Recommendation System, Foundation Model, Privacy Preserving, Security,

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In the digital age, the exponential growth of information has created a need for systems that navigate, filter, and personalize data for individual users.
Recommendation Systems (RS) nowadays become crucial tools for filtering online information and helping users discover products, content, and services that align with their preferences <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib1" title="">1</a>]</cite>.
However, the systems traditionally rely heavily on centralized data collection and processing, posing significant privacy risks and operational bottlenecks.
The importance of user privacy has never been greater, particularly with stringent data protection regulations such as the General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib2" title="">2</a>]</cite> in Europe, which emphasises the need to store user data on theirs local devices, instead of uploading it to central servers.
As a novel approach to address these privacy concerns, Google introduced Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib3" title="">3</a>]</cite> as a framework designed to train models across decentralized devices, while keeping data localized. This paradigm shift in data processing leverages the computational capabilities of individual devices for local data analysis.
Specifically, FL alternates between local model training at the client and global parameter aggregation from these models on a central server.
The integration of FL with RS becomes essential for safeguarding user privacy in recommendation services, which has given rise to the burgeoning field of Federated Recommendation Systems (FRS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib4" title="">4</a>]</cite>.
In this field, typically each client consists of a single user’s device. Therefore, unless specified otherwise in this paper, the terms ’user,’ ’client,’ and ’device’ all refer to an individual user.
FRS recently have shown promising results in many areas, such as service providing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib6" title="">6</a>]</cite>, daily scheduling <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib7" title="">7</a>]</cite>, driving planing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib9" title="">9</a>]</cite> and more, significantly impacting different facets of daily life.
Similar to FL, FRS is required to keep user data local to protect user privacy. However, in most cases, each client typically contains only the data of one user’s accessed item, which is extremely small compared to the total number of item set, creating a serious data scarcity problem.
In addition, different users have different behaviours and preferences, which can lead to data heterogeneity.
The presence of both issues can lead to sub-optimal models and reduced effectiveness.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="330" id="S1.F1.g1" src="extracted/5641828/figures/FM.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The foundation model can integrate information contained in data from various modalities during pre-training. The model can then be adapted for a variety of downstream tasks through adapters such as prompting or fine-tuning.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">More recently, the emergence of a novel paradigm for the construction of artificial intelligence (AI) systems has garnered considerable interest in the wake of the remarkable success of ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib10" title="">10</a>]</cite> and diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib13" title="">13</a>]</cite> in the tasks of language understanding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib17" title="">17</a>]</cite> and image generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib13" title="">13</a>]</cite>, which we refer to as Foundation Models (FM) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>. As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S1.F1" title="Figure 1 ‣ I Introduction ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">1</span></a>, this paradigm is built by using self-supervised optimization of training goals to determine how to update model parameters based on model predictions on the large amount of unlabelled training data. This process is referred to as pre-training.
Then, FM can utilize a technique, called Adaptation, to turn the general FM into a task-specific one. This process is termed as Fine-tuning or Prompting.
Language models, e.g. BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib19" title="">19</a>]</cite>and RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib20" title="">20</a>]</cite>, are usually trained using the next token prediction goal, which refers to the extent to which the model is able to predict the next token in the sequence.
One of the most successful examples of language models is ChatGPT, which is based on GPT-3.5. By training on large amounts of text data, it aligns the capabilities of large language models (LLM) with human intent <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>.
Vision models like ViT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib21" title="">21</a>]</cite> are typically trained using either contrast learning or diffusion training targets.
For contrastive learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib22" title="">22</a>]</cite>, images are randomly augmented before evaluating the similarity of the model representations.
For diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib13" title="">13</a>]</cite>, noise is added to the images and the model is gradually de-noised by the target.
There are also multi-modal training targets, some of which separate images and text during training, while others consider both.
The foundation model, once trained, is used as a plug-in in combination with adaptations to achieve results for a wide variety of downstream tasks.
CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib23" title="">23</a>]</cite> and DALL·E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib24" title="">24</a>]</cite> are two multi-modal AI models developed by OpenAI. CLIP focuses on understanding images through natural language, while DALL·E focuses on generating images based on text descriptions. While both models are trained on large datasets of images and text, CLIP is primarily used for image retrieval and classification, while DALL·E excels at generating new images that match text descriptions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib25" title="">25</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">As FM is frequently trained using a substantial quantity of data from multiple sources, they are capable of incorporating a considerable amount of additional knowledge when performing a specific downstream task. This feature enables FM to provide diverse training data for task-specific models in downstream task scenarios, thus effectively alleviating the problem of data scarcity. Given these considerations, the application of FM to FRS is not only a viable approach but also holds significant research potential. Such integration will drive innovation in FRS.
Although the application of FM to FRS has the potential to be highly beneficial, it must be acknowledged that this field is still in its nascent stages, with an insufficient understanding of the challenges, viable methods, and directions for development. This paper aims to bridge this knowledge gap through an in-depth analysis of the integration of FM and FRS.
The article provides a comprehensive examination of the motivations and challenges associated with integrating these two paradigms, with a particular focus on several representative technologies. Additionally, it outlines future development trends and their applications. By elucidating the intersection of FRS and FM, this study aims to promote further exploration and innovation within this emerging field, thereby facilitating its rapid advancement.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work and Contribution</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In the field of FRSs, various studies have converged on methodologies, privacy preservation, and challenges, albeit with distinct focal points.
Yang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib26" title="">26</a>]</cite> discuss the practical implementation and evaluation of FRS, with a focus on system architecture and algorithmic efficiency.
Alamgir et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib27" title="">27</a>]</cite> provides a comprehensive overview of FRS, highlighting techniques, prevailing challenges, and future directions.
Javeed et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib28" title="">28</a>]</cite> focus on the security and privacy concerns in personalized recommendation systems and propose targeted solutions to these challenges.
Finally, Sun et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib29" title="">29</a>]</cite> conduct a survey that compares existing federated recommendation research, highlighting the strengths and limitations of various approaches.
All studies emphasize the critical importance of privacy protection and the challenges posed by data heterogeneity and model aggregation.
This body of work enhances our understanding of FRS and provides a foundation for future research to address their inherent challenges.
Although a number of study focusing on combining FM with FL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib36" title="">36</a>]</cite> or RS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib38" title="">38</a>]</cite> already exist, our paper is the first work to explore the integration of FM into FRS.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Contribution.</span> This survey aims to provide a clear theoretical framework for applying FM to FRS and to elaborate on their principles and methods of application.
By analyzing existing technologies, this paper strives to drive innovation in integrating the pre-training capabilities of FM into FRS.
The article discusses in detail the technical challenges and practical issues faced when integrating FM, such as privacy protection, data heterogeneity, communication efficiency, and model generalization capabilities.
It also identifies current research gaps and future directions, aiming to guide subsequent academic research and technological development.
Additionally, through application studies, this paper demonstrates how to apply the integration of FM with FRS in practical scenarios, thereby deepening the integration of theory and practice.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Background and Preliminary</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Federated Recommendation System</span>
</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="313" id="S3.F2.g1" src="extracted/5641828/figures/typical_FRS.png" width="509"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>A typical framework for FRS.</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="187" id="S3.F3.sf1.g1" src="extracted/5641828/figures/data_horizontal.png" width="299"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Horizontal FRS</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="186" id="S3.F3.sf2.g1" src="extracted/5641828/figures/data_vertical.png" width="299"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Vertical FRS</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="187" id="S3.F3.sf3.g1" src="extracted/5641828/figures/data_transfer.png" width="299"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Transfer FRS</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Typical data categories of FRS.</figcaption>
</figure>
<div class="ltx_theorem ltx_theorem_definition" id="Thmdefinition1">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span class="ltx_text ltx_font_bold" id="Thmdefinition1.1.1.1">Definition 1</span></span><span class="ltx_text ltx_font_bold" id="Thmdefinition1.2.2"> (Federated Recommendation System)</span>
</h6>
<div class="ltx_para" id="Thmdefinition1.p1">
<p class="ltx_p" id="Thmdefinition1.p1.1"><span class="ltx_text ltx_font_italic" id="Thmdefinition1.p1.1.1">A Federated Recommendation System is a technology that uses distributed algorithms for personalized information filtering. It aims to improve the accuracy of information filtering and the effectiveness of personalized services, while maintaining user privacy.</span></p>
</div>
</div>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">FRS facilitate collaborative learning by pooling analysis and learning capabilities across multiple clients (e.g. users or locations), without the need for direct exchange of raw user data.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F2" title="Figure 2 ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates that this type of system typically involves three processes: 1) client model update, 2) communication, and 3) global aggregation.
The client model update allows users to train their models locally on their devices using their own data and then upload the updated intermediate parameters, e.g. the model gradients or parameters can be shared, to the server.
The server then performs global aggregation on the parameters sent by all participants, integrating the unique information from each of them. The aggregated parameters are then distributed to the next round of participants, initiating a new training round.
The process of uploading and distributing is collectively referred to as communication.
These approaches effectively preserves privacy and security.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS1.4.1.1">III-A</span>1 </span>Taxonomy of FRS</h4>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="420" id="S3.F4.g1" src="extracted/5641828/figures/tax_fl.png" width="509"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The diagram illustrates the taxonomy of FRS based on two main criteria: Data Distribution and Communication Architecture.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F4" title="Figure 4 ‣ III-A1 Taxonomy of FRS ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">4</span></a>, FRS can be categorized based on different criteria <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib29" title="">29</a>]</cite>.
According to used data distribution, FRS can be divided into Horizontal FRS, Vertical FRS, and Transfer FRS. Each type addresses different data collaboration and learning scenarios.
Specifically:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">Horizontal FRS</span> deals with situations where the feature spaces are similar across different entities, but the sample spaces differ, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F3.sf1" title="In Figure 3 ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">3a</span></a>.
For instance, two customers who shop at the same store may purchase some of the same products.
The horizontal method aggregates model updates from various sources to train recommendation models without sharing raw user data. This approach enhances the accuracy and efficiency of recommendation systems while safeguarding user privacy.
Horizontal FRS is currently the most common type, with many studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib41" title="">41</a>]</cite> based on the assumption of this data distribution.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Vertical FRS</span> is applied when the feature spaces differ, but the sample spaces are similar, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F3.sf2" title="In Figure 3 ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">3b</span></a>.
This scenario is common when different parties possess different types of data about the same users.
An example would be a bank and an online retailer holding distinct perspectives on the same customers, i.e., the bank has credit history while the retailer has shopping history.
One challenge is that how to align the identities of customers across different parties.
Vertical FRS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib45" title="">45</a>]</cite> trains recommendation models by securely integrating different data features between parties, utilizing richer user information for more accurate personalized recommendations and ensuring data privacy and security.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">Transfer FRS</span> utilizes principles of transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib46" title="">46</a>]</cite> to transfer knowledge from one domain to another, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F3.sf3" title="In Figure 3 ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">3c</span></a>. This type is suited for scenarios with significant differences in both feature and sample spaces across parties. Transfer learning allows the system to leverage data and knowledge from the source domain to enhance recommendation performance in the target domain, even when the target domain lacks sufficient data for independent model training. Transfer FRS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib47" title="">47</a>]</cite> is particularly beneficial for emerging markets or user groups with limited data, drawing insights from related domains.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S3.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="276" id="S3.F5.sf1.g1" src="extracted/5641828/figures/type_traditional.png" width="359"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Centralized FRS</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="276" id="S3.F5.sf2.g1" src="extracted/5641828/figures/type_semi-decentralized.png" width="359"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Semi-decentralized FRS</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="276" id="S3.F5.sf3.g1" src="extracted/5641828/figures/type_decentralized.png" width="359"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Decentralized FRS</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Typical architecture categories of FRS.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F5" title="Figure 5 ‣ III-A1 Taxonomy of FRS ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">5</span></a>, FRS can be categorized into centralized, semi-decentralized and decentralized based on their communication architecture. Each type addresses privacy and scalability in different ways:</p>
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">Centralized FRS</span> operates within a FL framework where a central server orchestrates the learning process as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F5.sf1" title="In Figure 5 ‣ III-A1 Taxonomy of FRS ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">5a</span></a>. Clients locally compute updates based on their data and send these updates to the server. The server aggregates these updates to prompt essential information sharing, which is then distributed back to the users.
It effectively addresses privacy concerns by allowing the model to learn from decentralized data sources without centralizing the data itself.
While this approach improves privacy by not requiring the sharing of raw data, it still relies on a central authority to manage the model. This architecture is typically used to overcome data silo issues <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib48" title="">48</a>]</cite> and improve the performance of RS without compromising user privacy and data security. Due to its simplicity and intuitive nature, this architecture has become the dominant framework within the field of FRS. There is a great deal of work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib47" title="">47</a>]</cite> based on it currently.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">Semi-decentralized FRS</span> shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F5.sf2" title="In Figure 5 ‣ III-A1 Taxonomy of FRS ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">5b</span></a> introduces an intermediate layer between the central server and the users, such as edge servers or devices that can perform additional computational or storage tasks. This setup aims to reduce the communication overhead and latency associated with sending updates to a central server, especially in large-scale applications.
A specific example is the SemiDFEGL framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib50" title="">50</a>]</cite>, which improves scalability and reduces communication costs by introducing new device-to-device collaborations.
It augments local subgraphs with predicted interacted item nodes to exploit high-order collaborative information between users and items in a privacy-preserving manner, which is particularly useful for recommendations based on collaborative filtering and graph neural networks.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I2.i3.p1.1.1">Decentralized FRS</span>, which employs peer-to-peer communication architecture <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib51" title="">51</a>]</cite>, distributes the learning process completely to all participating devices, without the need for a central server for model aggregation, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F5.sf3" title="In Figure 5 ‣ III-A1 Taxonomy of FRS ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">5c</span></a>.
This approach maximizes privacy and data ownership, but presents challenges in coordinating model updates and ensuring model convergence.
Zheng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib52" title="">52</a>]</cite> proposed a FRS model called DGREC by adopting a decentralized graph neural network, which constructs a local intra-item hypergraph and a global inter-user graph for each user, allowing users to freely choose whether to disclose their interactions. Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib53" title="">53</a>]</cite> introduced DFedRec, which uses a privacy-aware client-level structured graph to share model parameters only with relevant neighboring users, thereby reducing communication costs and protecting user privacy.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S3.SS1.SSS1.p2.2">Each of these architectures offers a trade-off between privacy, communication efficiency and the degree of decentralization.
Centralized systems simplify model aggregation, but rely on a central authority.
Semi-decentralized systems aim to balance efficiency and privacy with an intermediate layer, while decentralized systems offer the highest level of privacy at the cost of more complex model coordination.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Foundation Model</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The rapid increase in the performance of computer hardwares, e.g., GPUs, the increasing maturity of transformer architectures, and the public availability of large amounts of training data have been three key factors in the emergence of FM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>.
According to the work of Stanford HAI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>, we have the following definition of FM:</p>
</div>
<div class="ltx_theorem ltx_theorem_definition" id="Thmdefinition2">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span class="ltx_text ltx_font_bold" id="Thmdefinition2.1.1.1">Definition 2</span></span><span class="ltx_text ltx_font_bold" id="Thmdefinition2.2.2"> (Foundation Model)</span>
</h6>
<div class="ltx_para" id="Thmdefinition2.p1">
<p class="ltx_p" id="Thmdefinition2.p1.1"><span class="ltx_text ltx_font_italic" id="Thmdefinition2.p1.1.1">A foundation model is defined as any model trained on extensive data (typically using large-scale self-supervised learning) that is capable of adapting to a wide range of downstream tasks, for instance, through fine-tuning or prompting.</span></p>
</div>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">In recent years, the scale and scope of FM have greatly expanded our imagination of potential applications.
Such models typically have billions or even trillions of parameters, allowing them to learn more complex patterns and knowledge. They can be adapted to new tasks through fine-tuning or prompting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib55" title="">55</a>]</cite>.
For instance, the GPT-3 model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib56" title="">56</a>]</cite>, comprising 175 billion parameters, is capable of adapting and perform various tasks with the aid of natural language prompts, despite the fact that a significant proportion of these tasks have not been explicitly trained.
FM is distinguished by two key characteristics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>: 1) <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.1">Emergence</span>, which refers to the implicit induction of system behavior from examples, as opposed to explicit design; and 2) <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.2">Homogenization</span>, which indicates that the method of constructing machine learning systems tends to be unified across a wide range of applications.
Although FM is based on self-supervised learning and transfer learning, their scale brings new emergent abilities, and their effectiveness in many tasks has motivated homogenization, e.g., many FMs have evolved based on transformer architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib56" title="">56</a>]</cite>. While homogenization provides strong leverage, it also requires caution, as defects in foundation models can be inherited by all downstream adapted models. Despite the broad deployment prospects of foundation models, due to their emergent properties, our understanding of how they work, when they fail, and what they can actually do is still quite limited <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>, but there has been quite a bit of work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib57" title="">57</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib59" title="">59</a>]</cite> that attempts to explain this phenomenon.
Moreover, OpenAI proposes a Scaling Law for LLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib60" title="">60</a>]</cite>, suggesting that the performance of a model is governed by a power-law relationship involving computational power, model parameters, and data size. This law also applies to downstream tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib61" title="">61</a>]</cite>. Therefore, understanding and leveraging this power-law relationship when using FM can aid in more efficiently allocating resources and optimizing model performance.</p>
</div>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="419" id="S3.F6.g1" src="extracted/5641828/figures/tax_fm.png" width="509"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The diagram illustrates the taxonomy of FM based on two main criteria: Data Type and Functionality.</figcaption>
</figure>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS1.4.1.1">III-B</span>1 </span>Taxonomy of FM</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F6" title="Figure 6 ‣ III-B Foundation Model ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">6</span></a>, similar to FRS, FM can also be classified based on data type or functionality.
Specifically, based on the type of data used during training, FM is mainly divided into followings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>:</p>
<ul class="ltx_itemize" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">Language FM</span>: These types of FM mainly deal with textual data and are trained on large textual datasets to understand and generate language <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib20" title="">20</a>]</cite>.
They are very effective in natural language processing (NLP) tasks such as machine translation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib62" title="">62</a>]</cite>, search <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib64" title="">64</a>]</cite>, and sentiment analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib65" title="">65</a>]</cite>. Typical language models include BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib19" title="">19</a>]</cite>, GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib56" title="">56</a>]</cite>, and LLama <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib66" title="">66</a>]</cite>, which typically use deep transformer architectures that are able to capture complex linguistic regularities and demonstrate excellent performance on multilingual tasks.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">Vision FM</span>: Vision FM focuses on processing and understanding image data. These models are able to perform tasks such as object recognition <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib68" title="">68</a>]</cite>, image segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib69" title="">69</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib71" title="">71</a>]</cite>, and visual reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib73" title="">73</a>]</cite> by learning large amounts of image data. For example, DINOv2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib74" title="">74</a>]</cite> and SAM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib69" title="">69</a>]</cite> are basic models trained specifically for visual tasks, and using self-supervised learning methods, these models learn valid visual representations without labelling the data.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I3.i3.p1">
<p class="ltx_p" id="S3.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I3.i3.p1.1.1">Multi-modal FM</span>: Multi-modal models can simultaneously process and understand multiple types of data, such as text and images. Such models can excel in cross-modal tasks such as image captioning and visual quizzing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib77" title="">77</a>]</cite> by integrating information from different modalities. CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib23" title="">23</a>]</cite> and DALL·E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib24" title="">24</a>]</cite> are representative of such models that are able to understand the relationship between an image and its corresponding textual descriptions, demonstrating flexibility and robustness in handling multiple data types.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1">Functionally, FMs are generally categorized into two types <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib38" title="">38</a>]</cite>:</p>
<ul class="ltx_itemize" id="S3.I4">
<li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I4.i1.p1">
<p class="ltx_p" id="S3.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i1.p1.1.1">Discriminative FM</span>: The main task of discriminative FM is to distinguish or predict specific outputs from given input data. These models are generally based on the BERT family and are more concerned with learning decision boundaries from the data to perform tasks like classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib79" title="">79</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib80" title="">80</a>]</cite> and regression <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib81" title="">81</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I4.i2.p1">
<p class="ltx_p" id="S3.I4.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I4.i2.p1.1.1">Generative FM</span>: The core goal of generative FM is to learn the distribution of the data and be able to generate new data samples <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib25" title="">25</a>]</cite>. These models, such as GPT-3, DALL·E, etc., are able to capture the underlying structure of the data and thus generate new instances that are similar but different from the training data. Generative FM has a wide range of applications in areas such as the generation of text <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib82" title="">82</a>]</cite> and images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib13" title="">13</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS2.SSS2.4.1.1">III-B</span>2 </span>Adaptation</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S1.F1" title="Figure 1 ‣ I Introduction ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates a commonly used technique for pre-trained models, known as the Adaptation.
This technique adds new lightweight layers while maintaining the original parameters of the pre-trained model, enabling fine-tuning and extension for specific tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib83" title="">83</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib41" title="">41</a>]</cite>.
This approach is suitable for multi-task learning and tasks performed in resource-limited environments, such as few-shot learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib84" title="">84</a>]</cite>.
Adaptations have found wide applications in natural language processing and computer vision tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib85" title="">85</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib86" title="">86</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib87" title="">87</a>]</cite> .
According to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib84" title="">84</a>]</cite>, adaptation methods are categorized into three main types:</p>
<ul class="ltx_itemize" id="S3.I5">
<li class="ltx_item" id="S3.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i1.p1">
<p class="ltx_p" id="S3.I5.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I5.i1.p1.1.1">Prompt-based Fine-tuning Adaptation Methods</span> are inspired by the principles of prompt learning in NLP, adapts the model to a specific downstream task by using a portion of the fixed text input as a learnable vector and fine-tuning it using downstream task data. For instance, CoOp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib88" title="">88</a>]</cite> introduces the concept of prompt learning into the adaptation of downstream tasks for multimodal pre-trained foundation models by automatically constructing contextual prompts using learnable word embeddings. CoCoOp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib89" title="">89</a>]</cite> builds upon this by creating a meta-network that learns image features, which are then combined with prompt vectors to enhance the generalization performance of CoOp on new category data.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i2.p1">
<p class="ltx_p" id="S3.I5.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I5.i2.p1.1.1">Adapter-based Fine-tuning Adaptation Methods</span> entail the incorporation of small, trainable modules called Adapters into a pre-trained model. These adapters are subjected to fine-tuning, rather than the entire model, thereby enabling the model to adapt to novel tasks with minimal alterations to its original parameters. CLIP-Adapter <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib87" title="">87</a>]</cite> adds simple adapter structures within the CLIP model that are fine-tuned using a small dataset. This method allows the model to adapt to new tasks by learning task-specific features without the need for extensive retraining of the entire model. CALIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib90" title="">90</a>]</cite> enhances the cross-modal interaction capabilities of adapters by integrating text and image features using attention maps and incorporating two trainable linear layers before and after this integration. LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib85" title="">85</a>]</cite> adjusts the weights of a pre-trained model by multiplying the weight matrices with a low-rank matrix, allowing for fine-tuning of the model without significantly increasing the number of parameters.</p>
</div>
</li>
<li class="ltx_item" id="S3.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I5.i3.p1">
<p class="ltx_p" id="S3.I5.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I5.i3.p1.1.1">External Knowledge-based Adaptation Methods</span> integrate external knowledge (e.g., from knowledge graphs or additional language model queries) into the adaptation process. This is particularly advantageous for enhancing the model’s comprehension and efficacy in tasks where domain-specific knowledge is vital but data is scarce. CuPL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib91" title="">91</a>]</cite>enhances zero-shot classification performance by asking questions to a LLM and generating multiple descriptive statements for each category, enriching the semantics of the categories. LaBo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib92" title="">92</a>]</cite> uses GPT-3 to generate a large pool of candidate feature descriptors. It then selects the optimal subset of descriptors for classification decisions, considering the distinctiveness of features for other categories and the coverage for the current category.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Federated Recommendation Systems with Foundation Models</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">As described earlier in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S3.F2" title="Figure 2 ‣ III-A Federated Recommendation System ‣ III Background and Preliminary ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">2</span></a>, a typical FRS typically consists of three stages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib27" title="">27</a>]</cite>: client model update, communication, and global aggregation. Integration with FM should also occur at these three stages.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Client Model Update</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In FRS, clients have the following characteristics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib27" title="">27</a>]</cite>:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">As mentioned earlier, a major advantage of FRS is privacy. The data required for model training in FRS, such as user information and interaction history, is privacy sensitive and therefore must remain on the user’s device, creating data silos. This approach not only complies with data privacy regulations (such as GDPR), but also increases user trust. However, this means that each user has a relatively small amount of data compared to the entire dataset, and each user only accesses a portion of the item set, leading to data sparsity.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">Each client independently trains the model on its local data. This allows the model to better adapt to each user’s unique preferences and behaviors, improving personalization and accuracy of recommendations. The resulting data distribution often does not satisfy the independent and identically distributed (IID) assumption, leading to the problem of data heterogeneity.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">In addition, user devices are typically consumer products such as mobile phones and personal computers, which are characterized by unstable communication and limited computational resources. This requires keeping the computational load of the models deployed on the client and the amount of information exchanged with the server as low as possible.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">FM is typically pre-trained on large, diverse datasets, providing it with rich knowledge and strong representational capabilities. This pre-training provides it with prior knowledge that allows it to quickly adapt to specific customer data through fine-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>. As a result, FM can learn general feature representations that provide a degree of adaptability to different data distributions. Applying these models during the client update phase in FRS can significantly improve the performance of local models. Specifically:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">FM can apply knowledge learned from large corpora to local data through transfer learning. For example, a pre-trained FM can be effectively fine-tuned on a small amount of local data in the client to adapt to specific user behavior data, thereby achieving good performance in specific downstream tasks such as providing more accurate recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib38" title="">38</a>]</cite>. In addition, by fine-tuning the base model locally, sensitive data does not need to leave the device, protecting user privacy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib93" title="">93</a>]</cite>. As a result, customers can achieve better model performance with limited data.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">FM can also capture complex user preferences and behaviors. For example, FM has strong semantic understanding capabilities that allow them to better understand users’ search queries <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib64" title="">64</a>]</cite>, comments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib37" title="">37</a>]</cite>, and other textual data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib94" title="">94</a>]</cite> to provide recommendations that better meet user needs. In addition, as user behavior changes, FM can quickly adapt and adjust recommendation strategies to ensure that recommendation results remain consistent with the user’s current interests and needs. By applying FM during the client update phase, a higher level of personalized recommendation can be achieved.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">However, it is important to note that when FM is applied to data that differs significantly from the training distribution, performance degradation can occur. This problem, known as out-of-distribution generalization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib93" title="">93</a>]</cite>, is a challenge that FM must overcome. In addition, if there are biases in the training data set, FM may learn and reinforce these biases, leading to inequitable results across different data distributions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib95" title="">95</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib96" title="">96</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib97" title="">97</a>]</cite>. Although fine-tuning FM requires significantly less resources than training from scratch, it still typically requires significant computational resources for effective fine-tuning and updating <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib36" title="">36</a>]</cite>. This requirement may limit its use on resource-constrained clients, especially in FRS where each user represents a client, potentially limiting the use of FM due to limited computational resources.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Communication</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In FRS, communication between clients and the server is a critical phase. The primary task at this stage is to transmit model update information from each client to the central server while ensuring data security and communication efficiency during the transmission process.
In traditional FRS frameworks, communication between clients and the server typically involves transmitting large amounts of update information, which may include model parameters, gradients, or other relevant statistical data. To ensure efficient and secure communication, common strategies include data compression <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib98" title="">98</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib99" title="">99</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib100" title="">100</a>]</cite>, encrypted transmission <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib101" title="">101</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib102" title="">102</a>]</cite>, and secure aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib103" title="">103</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib104" title="">104</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib105" title="">105</a>]</cite>. However, with the increasing data scale and higher privacy protection requirements, these traditional methods face significant challenges <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib36" title="">36</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">FMs, especially LLMs, possess strong representation capabilities, enabling them to extract key features from model updates through efficient data representation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib106" title="">106</a>]</cite> and semantic compression techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib107" title="">107</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib108" title="">108</a>]</cite>. By removing redundant information and unnecessary data, and retaining only essential information, FM can transform this into a more compact representation, significantly reducing the data transmission volume between clients and the server. Optimizing communication protocols <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib109" title="">109</a>]</cite> and enhancing data compression and security during this process can markedly improve the overall performance of the system.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.4.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.5.2">Global Aggregation</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In FRS, the global aggregation phase of the server is responsible for combining model updates from all clients into a single global model. This phase is of critical importance in ensuring the overall performance and effectiveness of personalized recommendations. Server global aggregation is characterized by the following key features <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib110" title="">110</a>]</cite>:
First, server global aggregation must handle updates from a large number of clients that contain different data and user behaviors. To ensure the overall quality of the model and the accuracy of the recommendations, the server must effectively integrate this diverse data.
Second, the global aggregation process must be sufficiently robust to handle potentially noisy data and anomalous updates.
Finally, the scalability of the server’s global aggregation is critical, especially when dealing with a large number of clients and massive amounts of data, requiring the system to efficiently process and aggregate updates.
In each iteration, given resource constraints and privacy concerns, the central server may only communicate with a subset of clients. Researches <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib111" title="">111</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib112" title="">112</a>]</cite> indicate that clients should not participate in successive training rounds, as attackers could potentially infer information about the client from transmitted gradients or model parameters. The client selection strategy determines which clients will participate in the current training round based on factors such as computational power, network stability, data diversity, and data quality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib113" title="">113</a>]</cite>. For example, client selection can also be done by random sampling or based on statistical characteristics of the data to ensure that the model learns from diverse data sources, thereby increasing its generalization ability.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Context-aware aggregation represents a critical application of FM in global server aggregation. Traditional aggregation methods, such as naive weighted averaging proposed in FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib3" title="">3</a>]</cite>, may not fully exploit the contextual information present in the data.
FM, however, is capable of intelligently aggregating updates by understanding the semantics and contextual relationships of each participant’s updates <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib70" title="">70</a>]</cite>. To illustrate, when FM receives customer updates, it analyzes the contextual information of each update, such as user behavior patterns, preferences, and history. This information enables FM to better comprehend the significance and value of each update and to assign distinct weights accordingly <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib32" title="">32</a>]</cite>.
This context-aware aggregation method can more accurately reflect user preferences and behaviors, thereby enhancing the overall performance of the model.
Dynamic weighting permits the system to adapt more effectively to users’ personal needs and to provide recommendations that are more aligned with their interests.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">With its extensive knowledge base <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib114" title="">114</a>]</cite>, FM can utilize this knowledge to make more informed decisions during the aggregation process. Knowledge-based aggregation strategies can capitalize on FM’s knowledge and reasoning capabilities to enhance the efficacy of aggregation. To illustrate, in the event that certain customers lack sufficient data, FM can leverage pertinent information from its knowledge base to infer relationships and patterns between data, thereby supplementing and improving aggregation.
The key concept of Mixture of Experts (MoE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib115" title="">115</a>]</cite> is that different expert models specialize in different parts of a problem. By appropriately weighting and combining their outputs, better overall performance can be achieved. The MoE architecture has a similar function to aggregation strategies in FRS. Therefore, applying this architecture to the aggregation strategy in FRS may result in improved recommendation performance.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1">In terms of anomaly detection, FM also performs exceptionally well <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib116" title="">116</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib117" title="">117</a>]</cite>. In FRS, client updates may be influenced by various factors, leading to noisy or abnormal data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib29" title="">29</a>]</cite>. If these abnormal updates are directly used in global aggregation, they may affect the overall quality of the model. FM can utilize its strong anomaly detection capabilities to analyze client updates, identify and handle these anomalies, ensuring the robustness of global aggregation. For instance, if a client’s data update exhibits a notable divergence from the majority of client updates, it may be regarded as noise or an anomaly. FM has the capacity to elect to disregard or assign a diminished weight to it, thus reducing its deleterious impact on the global model and ensuring the stability and robustness of the global model. Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib37" title="">37</a>]</cite> observed in their study that FM is capable of effectively filtering out noisy data by identifying aberrant patterns, thereby enhancing the stability and reliability of the aggregation process.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">This application direction has considerable potential for future development and is worthy of further research and investigation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Challenges</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The application of FM to FRS marks the advent of a new frontier in personalized content recommendation.
This approach promises to further enhance user experience by employing more powerful models than traditional deep models while protecting user privacy.
However, this promising combination comes with many challenges, involving various aspects such as data privacy and security, data sparsity and sample imbalance, model training and optimization, model interpretability and transparency, and so on.
It is therefore of the utmost importance to gain a comprehensive understanding of these issues and to develop effective strategies to address them. This is essential if FRS is to be successfully deployed and operated in a secure yet powerful manner.
In this section, we will examine these challenges in detail, explore their implications and discuss potential strategies to overcome them.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.4.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.5.2">Data-Related Challenges</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">Data Privacy</span>: In a federated setting, the protection of user privacy is of paramount importance. The model must ensure that training and recommendations are performed without disclosing personal data. However, FMs, such as GPT-3, have the potential to memorize and reproduce data from the training set, thereby potentially leaking sensitive information. Additionally, if the generated data is too similar to the original data, there is a risk of privacy infringement. This may involve the use of additional encryption techniques to safeguard user data. Differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib118" title="">118</a>]</cite> protects individual data by adding noise during model training, thus reducing the risk of data leakage while maintaining model performance. Homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib119" title="">119</a>]</cite> allows computations on encrypted data, enabling model training without decrypting the data, effectively preventing data theft during transmission and processing. Furthermore, machine unlearning techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib120" title="">120</a>]</cite> can remove specific user data from the foundational model, ensuring that these data no longer influence the model’s predictions and outputs. This approach is particularly effective in the context of user deletion requests or in the context of compliance with privacy regulations such as the GDPR.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">Data Security</span>: The integration of FRS and FM also necessitates the equal consideration of data security. Participants may be subjected to malicious attacks, including Member Inference Attacks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib121" title="">121</a>]</cite>, Data Reconstruction Attacks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib122" title="">122</a>]</cite>, and Poisoning Attacks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib123" title="">123</a>]</cite>, which could compromise the model or alter the data. Consequently, ensuring the integrity and confidentiality of data during transmission and storage represents a significant challenge. The application of secure multi-party computation (MPC) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib124" title="">124</a>]</cite> can distribute computational tasks among multiple participants, ensuring that no single party can obtain complete data, thereby enhancing security. Additionally, blockchain <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib125" title="">125</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib126" title="">126</a>]</cite> can be used to record data access and operation logs, ensuring data integrity and traceability. This also helps improve the transparency and security of the system.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">Data Sparsity and Scarsity</span>: RS frequently encounters the challenge of data sparsity, where there is limited interaction data between users and items. This leads to decreased model performance. This issue is particularly pronounced in a federated setting, where each participant has limited data. In specific domains or tasks, insufficient data can cause severe data scarcity, further restricting model training and performance. Although FM has the ability to perform zero-shot and few-shot learning, they still need optimization to handle extremely sparse data. It is therefore of great importance to utilise data augmentation techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib127" title="">127</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib128" title="">128</a>]</cite> in order to generate a greater quantity and variety of training samples, thereby increasing the overall data set. Alternatively, knowledge transfer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib129" title="">129</a>]</cite> between different domains can be employed in order to leverage the rich data sets from other areas, thus alleviating the issue of data sparsity and improving the overall model performance in the current domain. Despite the ability of generative FM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib130" title="">130</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib131" title="">131</a>]</cite> to produce a vast quantity of synthetic data, the quality of this data may not be guaranteed. If the FM utilises low-quality or biased data sources, the generated data may inherit these issues and even exacerbate existing biases and errors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib132" title="">132</a>]</cite>. Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib22" title="">22</a>]</cite> found that generated data is not always beneficial for representation learning. For example, in contrastive learning, the optimal performance was achieved when the mix ratio of real to generated data was approximately 10:1. Consequently, when generating synthetic data, it is of paramount importance to establish quality standards and utilise evaluation metrics to assess data quality. Furthermore, it is essential to implement quality control mechanisms to filter out low-quality or biased data.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i4.p1.1.1">Sample Imbalance</span>: In a federated setting, there are significant differences in data size and distribution among different clients <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib133" title="">133</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib134" title="">134</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib135" title="">135</a>]</cite>. Similarly, in RS, item labels and user behaviors often exhibit a long-tail distribution <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib136" title="">136</a>]</cite>. These issues are referred to as sample imbalance, where part of classes have much more samples than others in the dataset. This can cause the model to overfit the majority classes while having poor generalization for minority classes, thus affecting the model’s training effectiveness. To address this, additional methods are required to balance these differences and ensure the model’s fairness and accuracy. Resampling techniques typically involve either oversampling or undersampling to balance the dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib137" title="">137</a>]</cite>. Oversampling increases the number of minority class samples, while undersampling reduces the number of majority class samples. Weighted loss functions can assign higher weights to minority class samples during model training, enhancing the model’s ability to recognize minority classes. This approach can enhance the fairness and accuracy of the model without modifying the data distribution.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.4.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.5.2">Model-Related Challenges</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i1.p1.1.1">Model Synchronization</span>: In a federated setting, models from various participants frequently communicate with the server for synchronization, resulting in high communication costs and complex system management issues. This is particularly problematic for large FM due to their vast number of parameters <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>, which require significant computational resources and time for transmission and synchronization. The use of gradient compression techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib138" title="">138</a>]</cite> to reduce the amount of data transmitted during model synchronization can effectively lower communication costs and enhance synchronization efficiency. Furthermore, the implementation of asynchronous update strategies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib139" title="">139</a>]</cite>, which permit participants to independently update their models and periodically perform global synchronization, can reduce waiting times during synchronization and enhance the overall efficiency of the system.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i2.p1.1.1">Model Heterogenity</span>: Model heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib140" title="">140</a>]</cite> is typically attributable to a multitude of factors, including disparate types, sizes, and architectures of models among various clients. This can be attributed to differences in client hardware, data distribution, or business needs. In certain instances, different clients may utilize distinct model structures. For instance, some clients may employ simple linear models, while others may utilize complex deep learning models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib141" title="">141</a>]</cite>. This renders it challenging to deploy or fine-tune a unified foundation model in a federated setting. The design of adaptive training algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib142" title="">142</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib143" title="">143</a>]</cite> enables the dynamic adjustment of model parameters based on the computational capabilities and data characteristics of each participant, thereby enhancing the model’s adaptability and performance in heterogeneous environments. Furthermore, knowledge transfer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib47" title="">47</a>]</cite> among different participants facilitates the sharing of insights and the mitigation of data and computational resource disparities, resulting in an improvement in the overall performance of the model.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i3.p1">
<p class="ltx_p" id="S5.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i3.p1.1.1">Model Interpretability</span>: FM is often represented by black-box models, which makes it challenging to comprehend their internal workings. This lack of interpretability can give rise to issues of trust and compliance in practical applications. In FRS, model interpretability is of paramount importance for establishing user trust and meeting regulatory requirements <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib144" title="">144</a>]</cite>. Therefore, it is vital to employ explainable AI techniques <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib145" title="">145</a>]</cite> to provide transparent and understandable explanations for the decisions made by FM. For instance, attention mechanisms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib146" title="">146</a>]</cite> and feature importance analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib147" title="">147</a>]</cite> can be utilized to elucidate model decisions. Furthermore, the utilisation of generative FM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib148" title="">148</a>]</cite> to generate natural language explanations for recommendations can provide users with the context and rationale behind the model’s decisions, thereby enhancing user trust and acceptance of the model.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i4.p1">
<p class="ltx_p" id="S5.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i4.p1.1.1">Model Transparency</span>: The concept of model transparency entails the open and auditable process of model decision-making. In the context of FRS, transparency plays a pivotal role in fostering user trust, necessitating the assurance of model fairness and non-discrimination. This encompasses the monitoring of model training processes, the validation of model updates, and the tracing of generated data. A lack of transparency can diminish the credibility of the model and increase compliance risks. FRS with FM should have transparent training protocols <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib149" title="">149</a>]</cite> that record and monitor each step of the model training process. This ensures transparency, thereby enhancing system credibility and compliance. Similarly, establishing a detailed logging system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib48" title="">48</a>]</cite> to record every model update and operation ensures traceability, helping to identify and correct issues within the model and improve overall system transparency.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Future Directions</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The emerging field of applying FM to FRS presents both opportunities and challenges. The combination of the powerful representation capabilities of FM and the data privacy protection advantages of FRS can enhance the performance of recommendation services and address some of the challenges that traditional FRS methods struggle to overcome. This section discusses some key future directions for FRS with FM, aiming to provide valuable guidance for future research and applications. These directions can offer higher quality personalized recommendation services while protecting user privacy. As technology continues to advance, it is reasonable to posit that FM will play an increasingly important role in future FRS.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS1.4.1.1">VI-A</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS1.5.2">Data Augmentation</span>
</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">FMs, especially generative FMs such as LLMs and DMs, have the ability to generate training data needed for downstream tasks such as text and image generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib150" title="">150</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib151" title="">151</a>]</cite>. They can be used to generate more user interaction data, alleviating data scarcity problems. In FRS, data from different participants may be unbalanced or insufficient. Using FM for data augmentation can effectively increase the variety and amount of training data.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">Through data augmentation, FM can help build more comprehensive user profiles and item characteristics, thereby improving the personalization and effectiveness of RS. For example, virtual interaction records of users or additional item descriptions can be generated to better capture user interests and preferences <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib152" title="">152</a>]</cite>. However, as mentioned earlier, the generated data may have quality issues that could degrade the performance of the RS and introduce biases and errors. Therefore, it is critical to perform rigorous validation and cleaning of the generated data to ensure that the synthetic data is statistically consistent with the real data and to reduce the noise introduced by the synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib132" title="">132</a>]</cite>. Similarly, FM should be combined with privacy-preserving techniques, such as differential privacy, to ensure that no sensitive user information is revealed during the generation of synthetic data. In addition, FM should be used to generate diverse data to cover different scenarios and user behaviors, reducing the risk of bias and over-fitting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib153" title="">153</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS2.4.1.1">VI-B</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS2.5.2">Cold-Start Recommendation</span>
</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">The core of the cold start problem is data sparsity, meaning that new users and new items lack sufficient historical interaction data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib154" title="">154</a>]</cite>. This makes it difficult for the model to capture users’ true interests and preferences, which affects the accuracy and effectiveness of recommendations. Because FM has been pre-trained on large amounts of textual data, it has learned rich semantic information that helps generate high-quality representations of users and items. Therefore, FM has strong zero-shot and few-shot learning capabilities, allowing it to provide effective recommendations for cold start users and items even without sufficient interaction data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib155" title="">155</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib41" title="">41</a>]</cite>.
In addition, FM can transfer knowledge learned in one domain to another through techniques such as fine-tuning and prompt learning. This means that even in cold start situations, the model can use previously learned knowledge to make recommendations, thereby improving the performance of the recommendation system.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">It is important to note that in a federated environment, collecting and using enough information to solve the cold start problem while protecting user privacy is a significant challenge. Ensuring the privacy and security of user data is a fundamental requirement for any FRS. In addition, multi-task learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib156" title="">156</a>]</cite> can improve the adaptability and generalization of basic models across different tasks and domains. For example, training on both recommendation and classification tasks simultaneously enables the model to make effective recommendations in more scenarios.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS3.4.1.1">VI-C</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS3.5.2">Multi-Modal Recommendation</span>
</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">FM has the ability to process and understand different modalities of data, such as text, images, audio, and video <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib18" title="">18</a>]</cite>. In FRS, the integration of multi-modal data enables FM to build more comprehensive and multi-dimensional user profiles, thereby improving the personalization of recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib157" title="">157</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib158" title="">158</a>]</cite>. These rich user profiles can more accurately reflect the user’s interests and preferences, helping to deliver recommendations that better meet the user’s needs.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">It is important to note that a major challenge of multi-modal data is its heterogeneity, meaning that different modalities of data have different characteristics and structures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib159" title="">159</a>]</cite>. For example, text data is sequential, while image data consists of two-dimensional pixels. This heterogeneity increases the complexity of data fusion and processing. Therefore, the development of unified data representation methods that map different modalities of data into a common representation space is essential for model processing and integration.</p>
</div>
<div class="ltx_para" id="S6.SS3.p3">
<p class="ltx_p" id="S6.SS3.p3.1">In a federated environment, special attention must be paid to the privacy of multi-modal data. Multi-modal data may contain more sensitive information, such as the user’s voice or video, which requires more stringent privacy measures to effectively handle and protect this data. In addition, the processing and integration of multi-modal data requires significant computational resources and time. The training and inference processes of FM on multi-modal data can be more complex and time-consuming, making it critical to improve computational efficiency.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS4.4.1.1">VI-D</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS4.5.2">Real-Time Recommendations</span>
</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">Real-time recommendation is a critical task in FRS, which aim to dynamically deliver personalized content based on real-time user behavior and contextual data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib160" title="">160</a>]</cite>. This recommendation model emphasizes immediate processing and response to data, ensuring that users receive the most relevant recommendations in the shortest possible time. FM excels at understanding contextual information, which enhances their performance in processing user queries, item descriptions, and other textual data to improve recommendation accuracy and relevance.</p>
</div>
<div class="ltx_para" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1">However, real-time recommendations require processing and responding to user requests in extremely short time frames, which places high demands on computational resources and system latency. FM typically requires significant computational resources, which can lead to increased latency and negatively impact the user experience. In addition, limitations on the length of the input context can cause performance issues when dealing with long sequences of user behavior or a large number of candidate items.</p>
</div>
<div class="ltx_para" id="S6.SS4.p3">
<p class="ltx_p" id="S6.SS4.p3.1">In real-time recommendations, FM can also reflect biases from the training data in its recommendations, leading to unfair biases. For example, popular items may be preferentially recommended due to their high frequency in the training data, overshadowing long-tail items <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib136" title="">136</a>]</cite>. Therefore, it is crucial to explore efficient model compression and acceleration techniques, such as distillation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib161" title="">161</a>]</cite> and pruning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib162" title="">162</a>]</cite>, to reduce computational complexity and latency. Introducing strategies such as sliding windows <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib163" title="">163</a>]</cite> can manage and optimize the input of contextual information, thereby improving the model’s performance in handling long behavioral sequences.
Incremental learning methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib164" title="">164</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib165" title="">165</a>]</cite>can also be used to update the FM, and model distillation techniques can reduce model size, thereby lowering communication overhead.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS5.4.1.1">VI-E</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS5.5.2">Enhanced Recommendation Explainability</span>
</h3>
<div class="ltx_para" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1">The federated nature and recommendation characteristics of FRS require transparent explanations of recommendation results to users. This transparency helps users understand the logic and reasoning behind the recommendations, thereby increasing their trust and satisfaction. Language FMs, pre-trained on large amounts of text data, have strong natural language generation capabilities. They can generate clear and coherent textual explanations while referencing relevant background knowledge, helping users to understand the reasons behind recommendations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib166" title="">166</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib167" title="">167</a>]</cite>. For example, models such as ChatGPT can generate detailed recommendation explanations that explain why a particular item is suitable for the user <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib168" title="">168</a>]</cite>.
However, generating detailed recommendation explanations often requires significant computational resources <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib169" title="">169</a>]</cite>. This is especially true for LLMs, which can increase latency and negatively impact the user experience. In addition, these LLMs may exhibit biases present in the pre-training data, resulting in unfair tendencies in the generated explanations, such as gender or race biases. Therefore, it is important to apply model compression and optimization techniques to reduce the computational burden of FM, and to design debiasing methods and fairness constraints to minimize biases in recommendation explanations.
Furthermore, it is crucial to incorporate user feedback mechanisms to continuously improve the quality of recommendation explanations. By leveraging user feedback, strategies for generating recommendation explanations can be adapted and optimized, thereby increasing user satisfaction and trust.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS6.4.1.1">VI-F</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS6.5.2">Adavanced Metrics</span>
</h3>
<div class="ltx_para" id="S6.SS6.p1">
<p class="ltx_p" id="S6.SS6.p1.1">Traditional evaluation metrics, which will be detailed in <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S7.SS2" title="VII-B Metrics ‣ VII Resources ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">VII-B</span></span></a>, are designed for specific tasks in recommendation scenarios, such as rating prediction or item ranking. However, the strength of FM in RS lies in its powerful generative capabilities, which allow it to generate items that have never appeared in historical data and recommend them to users. In addition, FM can generate explanations and user interaction content, which requires more complex and comprehensive evaluation criteria.
In this context, how to evaluate the recommendation capabilities of these systems remains an open question. Therefore, FRS with FM requires new evaluation metrics tailored to the specific applications of FM in RS, especially in generative recommendation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Resources</span>
</h2>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S7.SS1.4.1.1">VII-A</span> </span><span class="ltx_text ltx_font_italic" id="S7.SS1.5.2">Datasets</span>
</h3>
<figure class="ltx_figure" id="S7.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="269" id="S7.F7.g1" src="extracted/5641828/figures/type_feedback.png" width="449"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Two types of Feedbacks.</figcaption>
</figure>
<figure class="ltx_table" id="S7.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Datasets with Explicit Feedback.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T1.54" style="width:390.3pt;height:396.7pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-97.6pt,99.0pt) scale(0.666627204573057,0.666627204573057) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T1.54.54">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T1.54.54.55.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T1.54.54.55.1.1"></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T1.54.54.55.1.2"></th>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.55.1.3"></td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.55.1.4"></td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.55.1.5"></td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.55.1.6"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S7.T1.54.54.55.1.7">Context</td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.56.2">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.56.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S7.T1.54.54.56.2.2"><span class="ltx_text" id="S7.T1.54.54.56.2.2.1">Dataset</span></th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.3"><span class="ltx_text" id="S7.T1.54.54.56.2.3.1">#User</span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.4"><span class="ltx_text" id="S7.T1.54.54.56.2.4.1">#Item</span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.5"><span class="ltx_text" id="S7.T1.54.54.56.2.5.1">#Feedback</span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.6"><span class="ltx_text" id="S7.T1.54.54.56.2.6.1">Sparsity</span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.7">User</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.8">Item</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.9">Feedback</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.56.2.10">Timestamp</td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.57.3">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T1.54.54.57.3.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T1.54.54.57.3.2">Amazon Beauty</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.57.3.3">1,210,271</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.57.3.4">249,274</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.57.3.5">2,023,070</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.57.3.6">99.99%</td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.57.3.7"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.57.3.8"><span class="ltx_text" id="S7.T1.54.54.57.3.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.57.3.9"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.57.3.10"><span class="ltx_text" id="S7.T1.54.54.57.3.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.58.4">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.58.4.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.54.54.58.4.2">Amazon Books</th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.58.4.3">8,026,324</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.58.4.4">2,330,066</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.58.4.5">22,507,155</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.58.4.6">99.99%</td>
<td class="ltx_td" id="S7.T1.54.54.58.4.7"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.58.4.8"><span class="ltx_text" id="S7.T1.54.54.58.4.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td" id="S7.T1.54.54.58.4.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.58.4.10"><span class="ltx_text" id="S7.T1.54.54.58.4.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.59.5">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.59.5.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.54.54.59.5.2">Amazon CDs</th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.59.5.3">1,578,597</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.59.5.4">486,360</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.59.5.5">3,749,004</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.59.5.6">99.99%</td>
<td class="ltx_td" id="S7.T1.54.54.59.5.7"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.59.5.8"><span class="ltx_text" id="S7.T1.54.54.59.5.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td" id="S7.T1.54.54.59.5.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.59.5.10"><span class="ltx_text" id="S7.T1.54.54.59.5.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.60.6">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.60.6.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.54.54.60.6.2">Amazon Cell Phone</th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.60.6.3">2,261,045</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.60.6.4">319,678</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.60.6.5">3,447,249</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.60.6.6">99.99%</td>
<td class="ltx_td" id="S7.T1.54.54.60.6.7"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.60.6.8"><span class="ltx_text" id="S7.T1.54.54.60.6.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td" id="S7.T1.54.54.60.6.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.60.6.10"><span class="ltx_text" id="S7.T1.54.54.60.6.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.61.7">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.61.7.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.54.54.61.7.2">Amazon Clothing</th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.61.7.3">3,117,268</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.61.7.4">1,136,004</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.61.7.5">5,748,920</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.61.7.6">99.99%</td>
<td class="ltx_td" id="S7.T1.54.54.61.7.7"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.61.7.8"><span class="ltx_text" id="S7.T1.54.54.61.7.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td" id="S7.T1.54.54.61.7.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.61.7.10"><span class="ltx_text" id="S7.T1.54.54.61.7.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.62.8">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.62.8.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.54.54.62.8.2">Amazon Games</th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.62.8.3">826,767</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.62.8.4">50,210</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.62.8.5">1,324,753</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.62.8.6">99.99%</td>
<td class="ltx_td" id="S7.T1.54.54.62.8.7"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.62.8.8"><span class="ltx_text" id="S7.T1.54.54.62.8.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td" id="S7.T1.54.54.62.8.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.62.8.10"><span class="ltx_text" id="S7.T1.54.54.62.8.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.63.9">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.63.9.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.54.54.63.9.2">Amazon Garden</th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.63.9.3">714,791</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.63.9.4">105,984</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.63.9.5">993,490</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.63.9.6">99.99%</td>
<td class="ltx_td" id="S7.T1.54.54.63.9.7"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.63.9.8"><span class="ltx_text" id="S7.T1.54.54.63.9.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td" id="S7.T1.54.54.63.9.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.63.9.10"><span class="ltx_text" id="S7.T1.54.54.63.9.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.2.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.2.2.2.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.2.2.2.4">Amazon Home</th>
<td class="ltx_td ltx_align_center" id="S7.T1.2.2.2.5">2,511,610</td>
<td class="ltx_td ltx_align_center" id="S7.T1.2.2.2.6">410,243</td>
<td class="ltx_td ltx_align_center" id="S7.T1.2.2.2.7">4,253,926</td>
<td class="ltx_td ltx_align_center" id="S7.T1.2.2.2.8">99.99%</td>
<td class="ltx_td" id="S7.T1.2.2.2.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.1.1.1.1"><span class="ltx_text" id="S7.T1.1.1.1.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.1.1.1.1.1.m1.1"><semantics id="S7.T1.1.1.1.1.1.m1.1a"><mi id="S7.T1.1.1.1.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.1.1.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.1.1.1.1.1.m1.1b"><ci id="S7.T1.1.1.1.1.1.m1.1.1.cmml" xref="S7.T1.1.1.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.1.1.1.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.1.1.1.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.2.2.2.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.2.2.2.2"><span class="ltx_text" id="S7.T1.2.2.2.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.2.2.2.2.1.m1.1"><semantics id="S7.T1.2.2.2.2.1.m1.1a"><mi id="S7.T1.2.2.2.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.2.2.2.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.2.2.2.2.1.m1.1b"><ci id="S7.T1.2.2.2.2.1.m1.1.1.cmml" xref="S7.T1.2.2.2.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.2.2.2.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.2.2.2.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.4.4.4">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.4.4.4.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.4.4.4.4">Amazon Kindle</th>
<td class="ltx_td ltx_align_center" id="S7.T1.4.4.4.5">1,406,890</td>
<td class="ltx_td ltx_align_center" id="S7.T1.4.4.4.6">430,530</td>
<td class="ltx_td ltx_align_center" id="S7.T1.4.4.4.7">3,205,467</td>
<td class="ltx_td ltx_align_center" id="S7.T1.4.4.4.8">99.99%</td>
<td class="ltx_td" id="S7.T1.4.4.4.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.3.3.3.1"><span class="ltx_text" id="S7.T1.3.3.3.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.3.3.3.1.1.m1.1"><semantics id="S7.T1.3.3.3.1.1.m1.1a"><mi id="S7.T1.3.3.3.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.3.3.3.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.3.3.3.1.1.m1.1b"><ci id="S7.T1.3.3.3.1.1.m1.1.1.cmml" xref="S7.T1.3.3.3.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.3.3.3.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.3.3.3.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.4.4.4.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.4.4.4.2"><span class="ltx_text" id="S7.T1.4.4.4.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.4.4.4.2.1.m1.1"><semantics id="S7.T1.4.4.4.2.1.m1.1a"><mi id="S7.T1.4.4.4.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.4.4.4.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.4.4.4.2.1.m1.1b"><ci id="S7.T1.4.4.4.2.1.m1.1.1.cmml" xref="S7.T1.4.4.4.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.4.4.4.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.4.4.4.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.6.6.6">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.6.6.6.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.6.6.6.4">Amazon Movies</th>
<td class="ltx_td ltx_align_center" id="S7.T1.6.6.6.5">2,088,620</td>
<td class="ltx_td ltx_align_center" id="S7.T1.6.6.6.6">200,941</td>
<td class="ltx_td ltx_align_center" id="S7.T1.6.6.6.7">4,607,047</td>
<td class="ltx_td ltx_align_center" id="S7.T1.6.6.6.8">99.99%</td>
<td class="ltx_td" id="S7.T1.6.6.6.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.5.5.5.1"><span class="ltx_text" id="S7.T1.5.5.5.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.5.5.5.1.1.m1.1"><semantics id="S7.T1.5.5.5.1.1.m1.1a"><mi id="S7.T1.5.5.5.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.5.5.5.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.5.5.5.1.1.m1.1b"><ci id="S7.T1.5.5.5.1.1.m1.1.1.cmml" xref="S7.T1.5.5.5.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.5.5.5.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.5.5.5.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.6.6.6.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.6.6.6.2"><span class="ltx_text" id="S7.T1.6.6.6.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.6.6.6.2.1.m1.1"><semantics id="S7.T1.6.6.6.2.1.m1.1a"><mi id="S7.T1.6.6.6.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.6.6.6.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.6.6.6.2.1.m1.1b"><ci id="S7.T1.6.6.6.2.1.m1.1.1.cmml" xref="S7.T1.6.6.6.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.6.6.6.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.6.6.6.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.8.8.8">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.8.8.8.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.8.8.8.4">Amazon Music</th>
<td class="ltx_td ltx_align_center" id="S7.T1.8.8.8.5">478,235</td>
<td class="ltx_td ltx_align_center" id="S7.T1.8.8.8.6">266,414</td>
<td class="ltx_td ltx_align_center" id="S7.T1.8.8.8.7">836,006</td>
<td class="ltx_td ltx_align_center" id="S7.T1.8.8.8.8">99.99%</td>
<td class="ltx_td" id="S7.T1.8.8.8.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.7.7.7.1"><span class="ltx_text" id="S7.T1.7.7.7.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.7.7.7.1.1.m1.1"><semantics id="S7.T1.7.7.7.1.1.m1.1a"><mi id="S7.T1.7.7.7.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.7.7.7.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.7.7.7.1.1.m1.1b"><ci id="S7.T1.7.7.7.1.1.m1.1.1.cmml" xref="S7.T1.7.7.7.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.7.7.7.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.7.7.7.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.8.8.8.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.8.8.8.2"><span class="ltx_text" id="S7.T1.8.8.8.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.8.8.8.2.1.m1.1"><semantics id="S7.T1.8.8.8.2.1.m1.1a"><mi id="S7.T1.8.8.8.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.8.8.8.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.8.8.8.2.1.m1.1b"><ci id="S7.T1.8.8.8.2.1.m1.1.1.cmml" xref="S7.T1.8.8.8.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.8.8.8.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.8.8.8.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.10.10.10">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.10.10.10.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.10.10.10.4">Amazon Sports</th>
<td class="ltx_td ltx_align_center" id="S7.T1.10.10.10.5">1,990,521</td>
<td class="ltx_td ltx_align_center" id="S7.T1.10.10.10.6">478,898</td>
<td class="ltx_td ltx_align_center" id="S7.T1.10.10.10.7">3,268,695</td>
<td class="ltx_td ltx_align_center" id="S7.T1.10.10.10.8">99.99%</td>
<td class="ltx_td" id="S7.T1.10.10.10.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.9.9.9.1"><span class="ltx_text" id="S7.T1.9.9.9.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.9.9.9.1.1.m1.1"><semantics id="S7.T1.9.9.9.1.1.m1.1a"><mi id="S7.T1.9.9.9.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.9.9.9.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.9.9.9.1.1.m1.1b"><ci id="S7.T1.9.9.9.1.1.m1.1.1.cmml" xref="S7.T1.9.9.9.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.9.9.9.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.9.9.9.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.10.10.10.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.10.10.10.2"><span class="ltx_text" id="S7.T1.10.10.10.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.10.10.10.2.1.m1.1"><semantics id="S7.T1.10.10.10.2.1.m1.1a"><mi id="S7.T1.10.10.10.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.10.10.10.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.10.10.10.2.1.m1.1b"><ci id="S7.T1.10.10.10.2.1.m1.1.1.cmml" xref="S7.T1.10.10.10.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.10.10.10.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.10.10.10.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.12.12.12">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.12.12.12.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.12.12.12.4">Amazon Toys</th>
<td class="ltx_td ltx_align_center" id="S7.T1.12.12.12.5">1,342,911</td>
<td class="ltx_td ltx_align_center" id="S7.T1.12.12.12.6">327,698</td>
<td class="ltx_td ltx_align_center" id="S7.T1.12.12.12.7">2,252,771</td>
<td class="ltx_td ltx_align_center" id="S7.T1.12.12.12.8">99.99%</td>
<td class="ltx_td" id="S7.T1.12.12.12.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.11.11.11.1"><span class="ltx_text" id="S7.T1.11.11.11.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.11.11.11.1.1.m1.1"><semantics id="S7.T1.11.11.11.1.1.m1.1a"><mi id="S7.T1.11.11.11.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.11.11.11.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.11.11.11.1.1.m1.1b"><ci id="S7.T1.11.11.11.1.1.m1.1.1.cmml" xref="S7.T1.11.11.11.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.11.11.11.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.11.11.11.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.12.12.12.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.12.12.12.2"><span class="ltx_text" id="S7.T1.12.12.12.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.12.12.12.2.1.m1.1"><semantics id="S7.T1.12.12.12.2.1.m1.1a"><mi id="S7.T1.12.12.12.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.12.12.12.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.12.12.12.2.1.m1.1b"><ci id="S7.T1.12.12.12.2.1.m1.1.1.cmml" xref="S7.T1.12.12.12.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.12.12.12.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.12.12.12.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.14.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S7.T1.14.14.14.3"><span class="ltx_text" id="S7.T1.14.14.14.3.1">Amazon Reviews</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.14.14.14.4">Amazon Video</th>
<td class="ltx_td ltx_align_center" id="S7.T1.14.14.14.5">426,922</td>
<td class="ltx_td ltx_align_center" id="S7.T1.14.14.14.6">23,965</td>
<td class="ltx_td ltx_align_center" id="S7.T1.14.14.14.7">583,933</td>
<td class="ltx_td ltx_align_center" id="S7.T1.14.14.14.8">99.99%</td>
<td class="ltx_td" id="S7.T1.14.14.14.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.13.13.13.1"><span class="ltx_text" id="S7.T1.13.13.13.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.13.13.13.1.1.m1.1"><semantics id="S7.T1.13.13.13.1.1.m1.1a"><mi id="S7.T1.13.13.13.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.13.13.13.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.13.13.13.1.1.m1.1b"><ci id="S7.T1.13.13.13.1.1.m1.1.1.cmml" xref="S7.T1.13.13.13.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.13.13.13.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.13.13.13.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.14.14.14.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.14.14.14.2"><span class="ltx_text" id="S7.T1.14.14.14.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.14.14.14.2.1.m1.1"><semantics id="S7.T1.14.14.14.2.1.m1.1a"><mi id="S7.T1.14.14.14.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.14.14.14.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.14.14.14.2.1.m1.1b"><ci id="S7.T1.14.14.14.2.1.m1.1.1.cmml" xref="S7.T1.14.14.14.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.14.14.14.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.14.14.14.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.17.17.17">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T1.17.17.17.4"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T1.17.17.17.5">ML-100K</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.17.17.17.6">943</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.17.17.17.7">1,682</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.17.17.17.8">100,000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.17.17.17.9">93.70%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.15.15.15.1"><span class="ltx_text" id="S7.T1.15.15.15.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.15.15.15.1.1.m1.1"><semantics id="S7.T1.15.15.15.1.1.m1.1a"><mi id="S7.T1.15.15.15.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.15.15.15.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.15.15.15.1.1.m1.1b"><ci id="S7.T1.15.15.15.1.1.m1.1.1.cmml" xref="S7.T1.15.15.15.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.15.15.15.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.15.15.15.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.16.16.16.2"><span class="ltx_text" id="S7.T1.16.16.16.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.16.16.16.2.1.m1.1"><semantics id="S7.T1.16.16.16.2.1.m1.1a"><mi id="S7.T1.16.16.16.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.16.16.16.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.16.16.16.2.1.m1.1b"><ci id="S7.T1.16.16.16.2.1.m1.1.1.cmml" xref="S7.T1.16.16.16.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.16.16.16.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.16.16.16.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_border_t" id="S7.T1.17.17.17.10"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.17.17.17.3"><span class="ltx_text" id="S7.T1.17.17.17.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.17.17.17.3.1.m1.1"><semantics id="S7.T1.17.17.17.3.1.m1.1a"><mi id="S7.T1.17.17.17.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.17.17.17.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.17.17.17.3.1.m1.1b"><ci id="S7.T1.17.17.17.3.1.m1.1.1.cmml" xref="S7.T1.17.17.17.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.17.17.17.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.17.17.17.3.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.20.20.20">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.20.20.20.4"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.20.20.20.5">ML-1M</th>
<td class="ltx_td ltx_align_center" id="S7.T1.20.20.20.6">6,040</td>
<td class="ltx_td ltx_align_center" id="S7.T1.20.20.20.7">3,952</td>
<td class="ltx_td ltx_align_center" id="S7.T1.20.20.20.8">10,000,209</td>
<td class="ltx_td ltx_align_center" id="S7.T1.20.20.20.9">95.81%</td>
<td class="ltx_td ltx_align_center" id="S7.T1.18.18.18.1"><span class="ltx_text" id="S7.T1.18.18.18.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.18.18.18.1.1.m1.1"><semantics id="S7.T1.18.18.18.1.1.m1.1a"><mi id="S7.T1.18.18.18.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.18.18.18.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.18.18.18.1.1.m1.1b"><ci id="S7.T1.18.18.18.1.1.m1.1.1.cmml" xref="S7.T1.18.18.18.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.18.18.18.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.18.18.18.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.19.19.19.2"><span class="ltx_text" id="S7.T1.19.19.19.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.19.19.19.2.1.m1.1"><semantics id="S7.T1.19.19.19.2.1.m1.1a"><mi id="S7.T1.19.19.19.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.19.19.19.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.19.19.19.2.1.m1.1b"><ci id="S7.T1.19.19.19.2.1.m1.1.1.cmml" xref="S7.T1.19.19.19.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.19.19.19.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.19.19.19.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.20.20.20.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.20.20.20.3"><span class="ltx_text" id="S7.T1.20.20.20.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.20.20.20.3.1.m1.1"><semantics id="S7.T1.20.20.20.3.1.m1.1a"><mi id="S7.T1.20.20.20.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.20.20.20.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.20.20.20.3.1.m1.1b"><ci id="S7.T1.20.20.20.3.1.m1.1.1.cmml" xref="S7.T1.20.20.20.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.20.20.20.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.20.20.20.3.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.22.22.22">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.22.22.22.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.22.22.22.4">ML-10M</th>
<td class="ltx_td ltx_align_center" id="S7.T1.22.22.22.5">69,878</td>
<td class="ltx_td ltx_align_center" id="S7.T1.22.22.22.6">10,681</td>
<td class="ltx_td ltx_align_center" id="S7.T1.22.22.22.7">10,000,054</td>
<td class="ltx_td ltx_align_center" id="S7.T1.22.22.22.8">98.69%</td>
<td class="ltx_td" id="S7.T1.22.22.22.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.21.21.21.1"><span class="ltx_text" id="S7.T1.21.21.21.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.21.21.21.1.1.m1.1"><semantics id="S7.T1.21.21.21.1.1.m1.1a"><mi id="S7.T1.21.21.21.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.21.21.21.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.21.21.21.1.1.m1.1b"><ci id="S7.T1.21.21.21.1.1.m1.1.1.cmml" xref="S7.T1.21.21.21.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.21.21.21.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.21.21.21.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.22.22.22.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.22.22.22.2"><span class="ltx_text" id="S7.T1.22.22.22.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.22.22.22.2.1.m1.1"><semantics id="S7.T1.22.22.22.2.1.m1.1a"><mi id="S7.T1.22.22.22.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.22.22.22.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.22.22.22.2.1.m1.1b"><ci id="S7.T1.22.22.22.2.1.m1.1.1.cmml" xref="S7.T1.22.22.22.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.22.22.22.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.22.22.22.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.24.24.24">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S7.T1.24.24.24.3"><span class="ltx_text" id="S7.T1.24.24.24.3.1">MovieLens</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.24.24.24.4">ML-20M</th>
<td class="ltx_td ltx_align_center" id="S7.T1.24.24.24.5">138,493</td>
<td class="ltx_td ltx_align_center" id="S7.T1.24.24.24.6">27,278</td>
<td class="ltx_td ltx_align_center" id="S7.T1.24.24.24.7">20,000,263</td>
<td class="ltx_td ltx_align_center" id="S7.T1.24.24.24.8">99.47%</td>
<td class="ltx_td" id="S7.T1.24.24.24.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.23.23.23.1"><span class="ltx_text" id="S7.T1.23.23.23.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.23.23.23.1.1.m1.1"><semantics id="S7.T1.23.23.23.1.1.m1.1a"><mi id="S7.T1.23.23.23.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.23.23.23.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.23.23.23.1.1.m1.1b"><ci id="S7.T1.23.23.23.1.1.m1.1.1.cmml" xref="S7.T1.23.23.23.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.23.23.23.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.23.23.23.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.24.24.24.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.24.24.24.2"><span class="ltx_text" id="S7.T1.24.24.24.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.24.24.24.2.1.m1.1"><semantics id="S7.T1.24.24.24.2.1.m1.1a"><mi id="S7.T1.24.24.24.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.24.24.24.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.24.24.24.2.1.m1.1b"><ci id="S7.T1.24.24.24.2.1.m1.1.1.cmml" xref="S7.T1.24.24.24.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.24.24.24.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.24.24.24.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.28.28.28">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T1.28.28.28.5"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T1.28.28.28.6">Yelp2018</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.28.28.28.7">1,326,101</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.28.28.28.8">174,567</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.28.28.28.9">5,261,669</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.28.28.28.10">99.99%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.25.25.25.1"><span class="ltx_text" id="S7.T1.25.25.25.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.25.25.25.1.1.m1.1"><semantics id="S7.T1.25.25.25.1.1.m1.1a"><mi id="S7.T1.25.25.25.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.25.25.25.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.25.25.25.1.1.m1.1b"><ci id="S7.T1.25.25.25.1.1.m1.1.1.cmml" xref="S7.T1.25.25.25.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.25.25.25.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.25.25.25.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.26.26.26.2"><span class="ltx_text" id="S7.T1.26.26.26.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.26.26.26.2.1.m1.1"><semantics id="S7.T1.26.26.26.2.1.m1.1a"><mi id="S7.T1.26.26.26.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.26.26.26.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.26.26.26.2.1.m1.1b"><ci id="S7.T1.26.26.26.2.1.m1.1.1.cmml" xref="S7.T1.26.26.26.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.26.26.26.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.26.26.26.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.27.27.27.3"><span class="ltx_text" id="S7.T1.27.27.27.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.27.27.27.3.1.m1.1"><semantics id="S7.T1.27.27.27.3.1.m1.1a"><mi id="S7.T1.27.27.27.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.27.27.27.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.27.27.27.3.1.m1.1b"><ci id="S7.T1.27.27.27.3.1.m1.1.1.cmml" xref="S7.T1.27.27.27.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.27.27.27.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.27.27.27.3.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.28.28.28.4"><span class="ltx_text" id="S7.T1.28.28.28.4.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.28.28.28.4.1.m1.1"><semantics id="S7.T1.28.28.28.4.1.m1.1a"><mi id="S7.T1.28.28.28.4.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.28.28.28.4.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.28.28.28.4.1.m1.1b"><ci id="S7.T1.28.28.28.4.1.m1.1.1.cmml" xref="S7.T1.28.28.28.4.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.28.28.28.4.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.28.28.28.4.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.32.32.32">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.32.32.32.5"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.32.32.32.6">Yelp2020</th>
<td class="ltx_td ltx_align_center" id="S7.T1.32.32.32.7">1,968,703</td>
<td class="ltx_td ltx_align_center" id="S7.T1.32.32.32.8">209,393</td>
<td class="ltx_td ltx_align_center" id="S7.T1.32.32.32.9">8,021,122</td>
<td class="ltx_td ltx_align_center" id="S7.T1.32.32.32.10">99.99%</td>
<td class="ltx_td ltx_align_center" id="S7.T1.29.29.29.1"><span class="ltx_text" id="S7.T1.29.29.29.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.29.29.29.1.1.m1.1"><semantics id="S7.T1.29.29.29.1.1.m1.1a"><mi id="S7.T1.29.29.29.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.29.29.29.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.29.29.29.1.1.m1.1b"><ci id="S7.T1.29.29.29.1.1.m1.1.1.cmml" xref="S7.T1.29.29.29.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.29.29.29.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.29.29.29.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.30.30.30.2"><span class="ltx_text" id="S7.T1.30.30.30.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.30.30.30.2.1.m1.1"><semantics id="S7.T1.30.30.30.2.1.m1.1a"><mi id="S7.T1.30.30.30.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.30.30.30.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.30.30.30.2.1.m1.1b"><ci id="S7.T1.30.30.30.2.1.m1.1.1.cmml" xref="S7.T1.30.30.30.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.30.30.30.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.30.30.30.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.31.31.31.3"><span class="ltx_text" id="S7.T1.31.31.31.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.31.31.31.3.1.m1.1"><semantics id="S7.T1.31.31.31.3.1.m1.1a"><mi id="S7.T1.31.31.31.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.31.31.31.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.31.31.31.3.1.m1.1b"><ci id="S7.T1.31.31.31.3.1.m1.1.1.cmml" xref="S7.T1.31.31.31.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.31.31.31.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.31.31.31.3.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.32.32.32.4"><span class="ltx_text" id="S7.T1.32.32.32.4.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.32.32.32.4.1.m1.1"><semantics id="S7.T1.32.32.32.4.1.m1.1a"><mi id="S7.T1.32.32.32.4.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.32.32.32.4.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.32.32.32.4.1.m1.1b"><ci id="S7.T1.32.32.32.4.1.m1.1.1.cmml" xref="S7.T1.32.32.32.4.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.32.32.32.4.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.32.32.32.4.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.36.36.36">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.36.36.36.5"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.36.36.36.6">Yelp2021</th>
<td class="ltx_td ltx_align_center" id="S7.T1.36.36.36.7">2,189,457</td>
<td class="ltx_td ltx_align_center" id="S7.T1.36.36.36.8">160,585</td>
<td class="ltx_td ltx_align_center" id="S7.T1.36.36.36.9">8,635,403</td>
<td class="ltx_td ltx_align_center" id="S7.T1.36.36.36.10">99.99%</td>
<td class="ltx_td ltx_align_center" id="S7.T1.33.33.33.1"><span class="ltx_text" id="S7.T1.33.33.33.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.33.33.33.1.1.m1.1"><semantics id="S7.T1.33.33.33.1.1.m1.1a"><mi id="S7.T1.33.33.33.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.33.33.33.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.33.33.33.1.1.m1.1b"><ci id="S7.T1.33.33.33.1.1.m1.1.1.cmml" xref="S7.T1.33.33.33.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.33.33.33.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.33.33.33.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.34.34.34.2"><span class="ltx_text" id="S7.T1.34.34.34.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.34.34.34.2.1.m1.1"><semantics id="S7.T1.34.34.34.2.1.m1.1a"><mi id="S7.T1.34.34.34.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.34.34.34.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.34.34.34.2.1.m1.1b"><ci id="S7.T1.34.34.34.2.1.m1.1.1.cmml" xref="S7.T1.34.34.34.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.34.34.34.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.34.34.34.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.35.35.35.3"><span class="ltx_text" id="S7.T1.35.35.35.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.35.35.35.3.1.m1.1"><semantics id="S7.T1.35.35.35.3.1.m1.1a"><mi id="S7.T1.35.35.35.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.35.35.35.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.35.35.35.3.1.m1.1b"><ci id="S7.T1.35.35.35.3.1.m1.1.1.cmml" xref="S7.T1.35.35.35.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.35.35.35.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.35.35.35.3.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.36.36.36.4"><span class="ltx_text" id="S7.T1.36.36.36.4.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.36.36.36.4.1.m1.1"><semantics id="S7.T1.36.36.36.4.1.m1.1a"><mi id="S7.T1.36.36.36.4.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.36.36.36.4.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.36.36.36.4.1.m1.1b"><ci id="S7.T1.36.36.36.4.1.m1.1.1.cmml" xref="S7.T1.36.36.36.4.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.36.36.36.4.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.36.36.36.4.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.40.40.40">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.40.40.40.5"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.40.40.40.6">Yelp2022</th>
<td class="ltx_td ltx_align_center" id="S7.T1.40.40.40.7">1,987,929</td>
<td class="ltx_td ltx_align_center" id="S7.T1.40.40.40.8">150,346</td>
<td class="ltx_td ltx_align_center" id="S7.T1.40.40.40.9">6,990,280</td>
<td class="ltx_td ltx_align_center" id="S7.T1.40.40.40.10">99.99%</td>
<td class="ltx_td ltx_align_center" id="S7.T1.37.37.37.1"><span class="ltx_text" id="S7.T1.37.37.37.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.37.37.37.1.1.m1.1"><semantics id="S7.T1.37.37.37.1.1.m1.1a"><mi id="S7.T1.37.37.37.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.37.37.37.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.37.37.37.1.1.m1.1b"><ci id="S7.T1.37.37.37.1.1.m1.1.1.cmml" xref="S7.T1.37.37.37.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.37.37.37.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.37.37.37.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.38.38.38.2"><span class="ltx_text" id="S7.T1.38.38.38.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.38.38.38.2.1.m1.1"><semantics id="S7.T1.38.38.38.2.1.m1.1a"><mi id="S7.T1.38.38.38.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.38.38.38.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.38.38.38.2.1.m1.1b"><ci id="S7.T1.38.38.38.2.1.m1.1.1.cmml" xref="S7.T1.38.38.38.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.38.38.38.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.38.38.38.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.39.39.39.3"><span class="ltx_text" id="S7.T1.39.39.39.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.39.39.39.3.1.m1.1"><semantics id="S7.T1.39.39.39.3.1.m1.1a"><mi id="S7.T1.39.39.39.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.39.39.39.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.39.39.39.3.1.m1.1b"><ci id="S7.T1.39.39.39.3.1.m1.1.1.cmml" xref="S7.T1.39.39.39.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.39.39.39.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.39.39.39.3.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.40.40.40.4"><span class="ltx_text" id="S7.T1.40.40.40.4.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.40.40.40.4.1.m1.1"><semantics id="S7.T1.40.40.40.4.1.m1.1a"><mi id="S7.T1.40.40.40.4.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.40.40.40.4.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.40.40.40.4.1.m1.1b"><ci id="S7.T1.40.40.40.4.1.m1.1.1.cmml" xref="S7.T1.40.40.40.4.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.40.40.40.4.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.40.40.40.4.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.44.44.44">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S7.T1.44.44.44.5"><span class="ltx_text" id="S7.T1.44.44.44.5.1">Yelp</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.44.44.44.6">Yelp-full</th>
<td class="ltx_td ltx_align_center" id="S7.T1.44.44.44.7">5,556,436</td>
<td class="ltx_td ltx_align_center" id="S7.T1.44.44.44.8">539,254</td>
<td class="ltx_td ltx_align_center" id="S7.T1.44.44.44.9">28,908,240</td>
<td class="ltx_td ltx_align_center" id="S7.T1.44.44.44.10">99.99%</td>
<td class="ltx_td ltx_align_center" id="S7.T1.41.41.41.1"><span class="ltx_text" id="S7.T1.41.41.41.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.41.41.41.1.1.m1.1"><semantics id="S7.T1.41.41.41.1.1.m1.1a"><mi id="S7.T1.41.41.41.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.41.41.41.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.41.41.41.1.1.m1.1b"><ci id="S7.T1.41.41.41.1.1.m1.1.1.cmml" xref="S7.T1.41.41.41.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.41.41.41.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.41.41.41.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.42.42.42.2"><span class="ltx_text" id="S7.T1.42.42.42.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.42.42.42.2.1.m1.1"><semantics id="S7.T1.42.42.42.2.1.m1.1a"><mi id="S7.T1.42.42.42.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.42.42.42.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.42.42.42.2.1.m1.1b"><ci id="S7.T1.42.42.42.2.1.m1.1.1.cmml" xref="S7.T1.42.42.42.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.42.42.42.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.42.42.42.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.43.43.43.3"><span class="ltx_text" id="S7.T1.43.43.43.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.43.43.43.3.1.m1.1"><semantics id="S7.T1.43.43.43.3.1.m1.1a"><mi id="S7.T1.43.43.43.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.43.43.43.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.43.43.43.3.1.m1.1b"><ci id="S7.T1.43.43.43.3.1.m1.1.1.cmml" xref="S7.T1.43.43.43.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.43.43.43.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.43.43.43.3.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.44.44.44.4"><span class="ltx_text" id="S7.T1.44.44.44.4.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.44.44.44.4.1.m1.1"><semantics id="S7.T1.44.44.44.4.1.m1.1a"><mi id="S7.T1.44.44.44.4.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.44.44.44.4.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.44.44.44.4.1.m1.1b"><ci id="S7.T1.44.44.44.4.1.m1.1.1.cmml" xref="S7.T1.44.44.44.4.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.44.44.44.4.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.44.44.44.4.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.64.10">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T1.54.54.64.10.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T1.54.54.64.10.2">Anime</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.64.10.3">73,515</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.64.10.4">11,200</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.64.10.5">7,813,737</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.64.10.6">99.05%</td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.64.10.7"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T1.54.54.64.10.8"><span class="ltx_text" id="S7.T1.54.54.64.10.8.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.64.10.9"></td>
<td class="ltx_td ltx_border_t" id="S7.T1.54.54.64.10.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T1.46.46.46">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.46.46.46.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.46.46.46.4">Book Crossing</th>
<td class="ltx_td ltx_align_center" id="S7.T1.46.46.46.5">105,284</td>
<td class="ltx_td ltx_align_center" id="S7.T1.46.46.46.6">340,557</td>
<td class="ltx_td ltx_align_center" id="S7.T1.46.46.46.7">1,149,780</td>
<td class="ltx_td ltx_align_center" id="S7.T1.46.46.46.8">99.99%</td>
<td class="ltx_td ltx_align_center" id="S7.T1.45.45.45.1"><span class="ltx_text" id="S7.T1.45.45.45.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.45.45.45.1.1.m1.1"><semantics id="S7.T1.45.45.45.1.1.m1.1a"><mi id="S7.T1.45.45.45.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.45.45.45.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.45.45.45.1.1.m1.1b"><ci id="S7.T1.45.45.45.1.1.m1.1.1.cmml" xref="S7.T1.45.45.45.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.45.45.45.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.45.45.45.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.46.46.46.2"><span class="ltx_text" id="S7.T1.46.46.46.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.46.46.46.2.1.m1.1"><semantics id="S7.T1.46.46.46.2.1.m1.1a"><mi id="S7.T1.46.46.46.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.46.46.46.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.46.46.46.2.1.m1.1b"><ci id="S7.T1.46.46.46.2.1.m1.1.1.cmml" xref="S7.T1.46.46.46.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.46.46.46.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.46.46.46.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.46.46.46.9"></td>
<td class="ltx_td" id="S7.T1.46.46.46.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T1.48.48.48">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.48.48.48.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.48.48.48.4">Douban</th>
<td class="ltx_td ltx_align_center" id="S7.T1.48.48.48.5">738,701</td>
<td class="ltx_td ltx_align_center" id="S7.T1.48.48.48.6">28</td>
<td class="ltx_td ltx_align_center" id="S7.T1.48.48.48.7">2,125,056</td>
<td class="ltx_td ltx_align_center" id="S7.T1.48.48.48.8">89.73%</td>
<td class="ltx_td" id="S7.T1.48.48.48.9"></td>
<td class="ltx_td" id="S7.T1.48.48.48.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.47.47.47.1"><span class="ltx_text" id="S7.T1.47.47.47.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.47.47.47.1.1.m1.1"><semantics id="S7.T1.47.47.47.1.1.m1.1a"><mi id="S7.T1.47.47.47.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.47.47.47.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.47.47.47.1.1.m1.1b"><ci id="S7.T1.47.47.47.1.1.m1.1.1.cmml" xref="S7.T1.47.47.47.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.47.47.47.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.47.47.47.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.48.48.48.2"><span class="ltx_text" id="S7.T1.48.48.48.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.48.48.48.2.1.m1.1"><semantics id="S7.T1.48.48.48.2.1.m1.1a"><mi id="S7.T1.48.48.48.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.48.48.48.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.48.48.48.2.1.m1.1b"><ci id="S7.T1.48.48.48.2.1.m1.1.1.cmml" xref="S7.T1.48.48.48.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.48.48.48.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.48.48.48.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.50.50.50">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.50.50.50.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.50.50.50.4">Epinions</th>
<td class="ltx_td ltx_align_center" id="S7.T1.50.50.50.5">116,260</td>
<td class="ltx_td ltx_align_center" id="S7.T1.50.50.50.6">41,269</td>
<td class="ltx_td ltx_align_center" id="S7.T1.50.50.50.7">188,478</td>
<td class="ltx_td ltx_align_center" id="S7.T1.50.50.50.8">99.99%</td>
<td class="ltx_td" id="S7.T1.50.50.50.9"></td>
<td class="ltx_td" id="S7.T1.50.50.50.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.49.49.49.1"><span class="ltx_text" id="S7.T1.49.49.49.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.49.49.49.1.1.m1.1"><semantics id="S7.T1.49.49.49.1.1.m1.1a"><mi id="S7.T1.49.49.49.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.49.49.49.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.49.49.49.1.1.m1.1b"><ci id="S7.T1.49.49.49.1.1.m1.1.1.cmml" xref="S7.T1.49.49.49.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.49.49.49.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.49.49.49.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T1.50.50.50.2"><span class="ltx_text" id="S7.T1.50.50.50.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.50.50.50.2.1.m1.1"><semantics id="S7.T1.50.50.50.2.1.m1.1a"><mi id="S7.T1.50.50.50.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.50.50.50.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.50.50.50.2.1.m1.1b"><ci id="S7.T1.50.50.50.2.1.m1.1.1.cmml" xref="S7.T1.50.50.50.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.50.50.50.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.50.50.50.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.52.52.52">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.52.52.52.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.52.52.52.4">Goodreads</th>
<td class="ltx_td ltx_align_center" id="S7.T1.52.52.52.5">876,145</td>
<td class="ltx_td ltx_align_center" id="S7.T1.52.52.52.6">2,360,650</td>
<td class="ltx_td ltx_align_center" id="S7.T1.52.52.52.7">228,648,342</td>
<td class="ltx_td ltx_align_center" id="S7.T1.52.52.52.8">99.99%</td>
<td class="ltx_td" id="S7.T1.52.52.52.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.51.51.51.1"><span class="ltx_text" id="S7.T1.51.51.51.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.51.51.51.1.1.m1.1"><semantics id="S7.T1.51.51.51.1.1.m1.1a"><mi id="S7.T1.51.51.51.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.51.51.51.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.51.51.51.1.1.m1.1b"><ci id="S7.T1.51.51.51.1.1.m1.1.1.cmml" xref="S7.T1.51.51.51.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.51.51.51.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.51.51.51.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T1.52.52.52.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.52.52.52.2"><span class="ltx_text" id="S7.T1.52.52.52.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.52.52.52.2.1.m1.1"><semantics id="S7.T1.52.52.52.2.1.m1.1a"><mi id="S7.T1.52.52.52.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.52.52.52.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.52.52.52.2.1.m1.1b"><ci id="S7.T1.52.52.52.2.1.m1.1.1.cmml" xref="S7.T1.52.52.52.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.52.52.52.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.52.52.52.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.65.11">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.54.54.65.11.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.54.54.65.11.2">Jester</th>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.65.11.3">73,421</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.65.11.4">101</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.65.11.5">4,136,360</td>
<td class="ltx_td ltx_align_center" id="S7.T1.54.54.65.11.6">44.22%</td>
<td class="ltx_td" id="S7.T1.54.54.65.11.7"></td>
<td class="ltx_td" id="S7.T1.54.54.65.11.8"></td>
<td class="ltx_td" id="S7.T1.54.54.65.11.9"></td>
<td class="ltx_td" id="S7.T1.54.54.65.11.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T1.53.53.53">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T1.53.53.53.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T1.53.53.53.3">Netflix</th>
<td class="ltx_td ltx_align_center" id="S7.T1.53.53.53.4">480,189</td>
<td class="ltx_td ltx_align_center" id="S7.T1.53.53.53.5">17,770</td>
<td class="ltx_td ltx_align_center" id="S7.T1.53.53.53.6">100,480,507</td>
<td class="ltx_td ltx_align_center" id="S7.T1.53.53.53.7">98.82%</td>
<td class="ltx_td" id="S7.T1.53.53.53.8"></td>
<td class="ltx_td" id="S7.T1.53.53.53.9"></td>
<td class="ltx_td" id="S7.T1.53.53.53.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T1.53.53.53.1"><span class="ltx_text" id="S7.T1.53.53.53.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.53.53.53.1.1.m1.1"><semantics id="S7.T1.53.53.53.1.1.m1.1a"><mi id="S7.T1.53.53.53.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.53.53.53.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.53.53.53.1.1.m1.1b"><ci id="S7.T1.53.53.53.1.1.m1.1.1.cmml" xref="S7.T1.53.53.53.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.53.53.53.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.53.53.53.1.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T1.54.54.54">
<th class="ltx_td ltx_th ltx_th_row ltx_border_b" id="S7.T1.54.54.54.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S7.T1.54.54.54.3">Yahoo Music</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T1.54.54.54.4">1,948,882</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T1.54.54.54.5">98,211</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T1.54.54.54.6">11,557,943</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T1.54.54.54.7">99.99%</td>
<td class="ltx_td ltx_border_b" id="S7.T1.54.54.54.8"></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T1.54.54.54.1"><span class="ltx_text" id="S7.T1.54.54.54.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T1.54.54.54.1.1.m1.1"><semantics id="S7.T1.54.54.54.1.1.m1.1a"><mi id="S7.T1.54.54.54.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T1.54.54.54.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T1.54.54.54.1.1.m1.1b"><ci id="S7.T1.54.54.54.1.1.m1.1.1.cmml" xref="S7.T1.54.54.54.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T1.54.54.54.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T1.54.54.54.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_border_b" id="S7.T1.54.54.54.9"></td>
<td class="ltx_td ltx_border_b" id="S7.T1.54.54.54.10"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S7.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Datasets with Implicit Feedback.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T2.26" style="width:390.3pt;height:234.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-74.8pt,44.9pt) scale(0.72299140620329,0.72299140620329) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T2.26.26">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T2.26.26.27.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T2.26.26.27.1.1"></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T2.26.26.27.1.2"></th>
<td class="ltx_td ltx_border_t" id="S7.T2.26.26.27.1.3"></td>
<td class="ltx_td ltx_border_t" id="S7.T2.26.26.27.1.4"></td>
<td class="ltx_td ltx_border_t" id="S7.T2.26.26.27.1.5"></td>
<td class="ltx_td ltx_border_t" id="S7.T2.26.26.27.1.6"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S7.T2.26.26.27.1.7">Context</td>
</tr>
<tr class="ltx_tr" id="S7.T2.26.26.28.2">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.26.26.28.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S7.T2.26.26.28.2.2"><span class="ltx_text" id="S7.T2.26.26.28.2.2.1">Dataset</span></th>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.3"><span class="ltx_text" id="S7.T2.26.26.28.2.3.1">#User</span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.4"><span class="ltx_text" id="S7.T2.26.26.28.2.4.1">#Item</span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.5"><span class="ltx_text" id="S7.T2.26.26.28.2.5.1">#Feedback</span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.6"><span class="ltx_text" id="S7.T2.26.26.28.2.6.1">Sparsity</span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.7">User</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.8">Item</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.9">Feedback</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.28.2.10">Timestamp</td>
</tr>
<tr class="ltx_tr" id="S7.T2.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T2.1.1.1.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T2.1.1.1.3">MIND_large_train</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.1.1.1.4">711,223</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.1.1.1.5">27,047</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.1.1.1.6">83,507,374</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.1.1.1.7">99.57%</td>
<td class="ltx_td ltx_border_t" id="S7.T2.1.1.1.8"></td>
<td class="ltx_td ltx_border_t" id="S7.T2.1.1.1.9"></td>
<td class="ltx_td ltx_border_t" id="S7.T2.1.1.1.10"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.1.1.1.1"><span class="ltx_text" id="S7.T2.1.1.1.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.1.1.1.1.1.m1.1"><semantics id="S7.T2.1.1.1.1.1.m1.1a"><mi id="S7.T2.1.1.1.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.1.1.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.1.1.1.1.1.m1.1b"><ci id="S7.T2.1.1.1.1.1.m1.1.1.cmml" xref="S7.T2.1.1.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.1.1.1.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.1.1.1.1.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.2.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.2.2.2.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.2.2.2.3">MIND_large_dev</th>
<td class="ltx_td ltx_align_center" id="S7.T2.2.2.2.4">255,991</td>
<td class="ltx_td ltx_align_center" id="S7.T2.2.2.2.5">6,998</td>
<td class="ltx_td ltx_align_center" id="S7.T2.2.2.2.6">14,085,557</td>
<td class="ltx_td ltx_align_center" id="S7.T2.2.2.2.7">99.21%</td>
<td class="ltx_td" id="S7.T2.2.2.2.8"></td>
<td class="ltx_td" id="S7.T2.2.2.2.9"></td>
<td class="ltx_td" id="S7.T2.2.2.2.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.2.2.2.1"><span class="ltx_text" id="S7.T2.2.2.2.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.2.2.2.1.1.m1.1"><semantics id="S7.T2.2.2.2.1.1.m1.1a"><mi id="S7.T2.2.2.2.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.2.2.2.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.2.2.2.1.1.m1.1b"><ci id="S7.T2.2.2.2.1.1.m1.1.1.cmml" xref="S7.T2.2.2.2.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.2.2.2.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.2.2.2.1.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.3.3.3">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.3.3.3.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.3.3.3.3">MIND_small_train</th>
<td class="ltx_td ltx_align_center" id="S7.T2.3.3.3.4">50,001</td>
<td class="ltx_td ltx_align_center" id="S7.T2.3.3.3.5">20,289</td>
<td class="ltx_td ltx_align_center" id="S7.T2.3.3.3.6">5,843,444</td>
<td class="ltx_td ltx_align_center" id="S7.T2.3.3.3.7">99.42%</td>
<td class="ltx_td" id="S7.T2.3.3.3.8"></td>
<td class="ltx_td" id="S7.T2.3.3.3.9"></td>
<td class="ltx_td" id="S7.T2.3.3.3.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.3.3.3.1"><span class="ltx_text" id="S7.T2.3.3.3.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.3.3.3.1.1.m1.1"><semantics id="S7.T2.3.3.3.1.1.m1.1a"><mi id="S7.T2.3.3.3.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.3.3.3.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.3.3.3.1.1.m1.1b"><ci id="S7.T2.3.3.3.1.1.m1.1.1.cmml" xref="S7.T2.3.3.3.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.3.3.3.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.3.3.3.1.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.4.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S7.T2.4.4.4.2"><span class="ltx_text" id="S7.T2.4.4.4.2.1">MIND</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.4.4.4.3">MIND_small_dev</th>
<td class="ltx_td ltx_align_center" id="S7.T2.4.4.4.4">50,001</td>
<td class="ltx_td ltx_align_center" id="S7.T2.4.4.4.5">5,370</td>
<td class="ltx_td ltx_align_center" id="S7.T2.4.4.4.6">2,740,998</td>
<td class="ltx_td ltx_align_center" id="S7.T2.4.4.4.7">98.98%</td>
<td class="ltx_td" id="S7.T2.4.4.4.8"></td>
<td class="ltx_td" id="S7.T2.4.4.4.9"></td>
<td class="ltx_td" id="S7.T2.4.4.4.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.4.4.4.1"><span class="ltx_text" id="S7.T2.4.4.4.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.4.4.4.1.1.m1.1"><semantics id="S7.T2.4.4.4.1.1.m1.1a"><mi id="S7.T2.4.4.4.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.4.4.4.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.4.4.4.1.1.m1.1b"><ci id="S7.T2.4.4.4.1.1.m1.1.1.cmml" xref="S7.T2.4.4.4.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.4.4.4.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.4.4.4.1.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.6.6.6">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T2.6.6.6.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T2.6.6.6.4">QK-video</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.6.6.6.5">5,022,750</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.6.6.6.6">3,753,436</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.6.6.6.7">142,321,193</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.6.6.6.8">99.99%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.5.5.5.1"><span class="ltx_text" id="S7.T2.5.5.5.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.5.5.5.1.1.m1.1"><semantics id="S7.T2.5.5.5.1.1.m1.1a"><mi id="S7.T2.5.5.5.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.5.5.5.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.5.5.5.1.1.m1.1b"><ci id="S7.T2.5.5.5.1.1.m1.1.1.cmml" xref="S7.T2.5.5.5.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.5.5.5.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.5.5.5.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.6.6.6.2"><span class="ltx_text" id="S7.T2.6.6.6.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.6.6.6.2.1.m1.1"><semantics id="S7.T2.6.6.6.2.1.m1.1a"><mi id="S7.T2.6.6.6.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.6.6.6.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.6.6.6.2.1.m1.1b"><ci id="S7.T2.6.6.6.2.1.m1.1.1.cmml" xref="S7.T2.6.6.6.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.6.6.6.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.6.6.6.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_border_t" id="S7.T2.6.6.6.9"></td>
<td class="ltx_td ltx_border_t" id="S7.T2.6.6.6.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T2.8.8.8">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.8.8.8.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.8.8.8.4">QK-article</th>
<td class="ltx_td ltx_align_center" id="S7.T2.8.8.8.5">1,325,838</td>
<td class="ltx_td ltx_align_center" id="S7.T2.8.8.8.6">220,122</td>
<td class="ltx_td ltx_align_center" id="S7.T2.8.8.8.7">46,111,728</td>
<td class="ltx_td ltx_align_center" id="S7.T2.8.8.8.8">99.98%</td>
<td class="ltx_td ltx_align_center" id="S7.T2.7.7.7.1"><span class="ltx_text" id="S7.T2.7.7.7.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.7.7.7.1.1.m1.1"><semantics id="S7.T2.7.7.7.1.1.m1.1a"><mi id="S7.T2.7.7.7.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.7.7.7.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.7.7.7.1.1.m1.1b"><ci id="S7.T2.7.7.7.1.1.m1.1.1.cmml" xref="S7.T2.7.7.7.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.7.7.7.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.7.7.7.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.8.8.8.2"><span class="ltx_text" id="S7.T2.8.8.8.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.8.8.8.2.1.m1.1"><semantics id="S7.T2.8.8.8.2.1.m1.1a"><mi id="S7.T2.8.8.8.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.8.8.8.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.8.8.8.2.1.m1.1b"><ci id="S7.T2.8.8.8.2.1.m1.1.1.cmml" xref="S7.T2.8.8.8.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.8.8.8.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.8.8.8.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T2.8.8.8.9"></td>
<td class="ltx_td" id="S7.T2.8.8.8.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T2.10.10.10">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.10.10.10.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.10.10.10.4">QB-video</th>
<td class="ltx_td ltx_align_center" id="S7.T2.10.10.10.5">34,240</td>
<td class="ltx_td ltx_align_center" id="S7.T2.10.10.10.6">130,647</td>
<td class="ltx_td ltx_align_center" id="S7.T2.10.10.10.7">1,701,171</td>
<td class="ltx_td ltx_align_center" id="S7.T2.10.10.10.8">99.96%</td>
<td class="ltx_td ltx_align_center" id="S7.T2.9.9.9.1"><span class="ltx_text" id="S7.T2.9.9.9.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.9.9.9.1.1.m1.1"><semantics id="S7.T2.9.9.9.1.1.m1.1a"><mi id="S7.T2.9.9.9.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.9.9.9.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.9.9.9.1.1.m1.1b"><ci id="S7.T2.9.9.9.1.1.m1.1.1.cmml" xref="S7.T2.9.9.9.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.9.9.9.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.9.9.9.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.10.10.10.2"><span class="ltx_text" id="S7.T2.10.10.10.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.10.10.10.2.1.m1.1"><semantics id="S7.T2.10.10.10.2.1.m1.1a"><mi id="S7.T2.10.10.10.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.10.10.10.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.10.10.10.2.1.m1.1b"><ci id="S7.T2.10.10.10.2.1.m1.1.1.cmml" xref="S7.T2.10.10.10.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.10.10.10.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.10.10.10.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T2.10.10.10.9"></td>
<td class="ltx_td" id="S7.T2.10.10.10.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T2.12.12.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S7.T2.12.12.12.3"><span class="ltx_text" id="S7.T2.12.12.12.3.1">Tenrec</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.12.12.12.4">QB-article</th>
<td class="ltx_td ltx_align_center" id="S7.T2.12.12.12.5">24,516</td>
<td class="ltx_td ltx_align_center" id="S7.T2.12.12.12.6">7,355</td>
<td class="ltx_td ltx_align_center" id="S7.T2.12.12.12.7">348,736</td>
<td class="ltx_td ltx_align_center" id="S7.T2.12.12.12.8">99.81%</td>
<td class="ltx_td ltx_align_center" id="S7.T2.11.11.11.1"><span class="ltx_text" id="S7.T2.11.11.11.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.11.11.11.1.1.m1.1"><semantics id="S7.T2.11.11.11.1.1.m1.1a"><mi id="S7.T2.11.11.11.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.11.11.11.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.11.11.11.1.1.m1.1b"><ci id="S7.T2.11.11.11.1.1.m1.1.1.cmml" xref="S7.T2.11.11.11.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.11.11.11.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.11.11.11.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.12.12.12.2"><span class="ltx_text" id="S7.T2.12.12.12.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.12.12.12.2.1.m1.1"><semantics id="S7.T2.12.12.12.2.1.m1.1a"><mi id="S7.T2.12.12.12.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.12.12.12.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.12.12.12.2.1.m1.1b"><ci id="S7.T2.12.12.12.2.1.m1.1.1.cmml" xref="S7.T2.12.12.12.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.12.12.12.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.12.12.12.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T2.12.12.12.9"></td>
<td class="ltx_td" id="S7.T2.12.12.12.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T2.14.14.14">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S7.T2.14.14.14.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T2.14.14.14.4">Adressa</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.14.14.14.5">15,514</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.14.14.14.6">923</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.14.14.14.7">2,717,915</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.14.14.14.8">81.02%</td>
<td class="ltx_td ltx_border_t" id="S7.T2.14.14.14.9"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.13.13.13.1"><span class="ltx_text" id="S7.T2.13.13.13.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.13.13.13.1.1.m1.1"><semantics id="S7.T2.13.13.13.1.1.m1.1a"><mi id="S7.T2.13.13.13.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.13.13.13.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.13.13.13.1.1.m1.1b"><ci id="S7.T2.13.13.13.1.1.m1.1.1.cmml" xref="S7.T2.13.13.13.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.13.13.13.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.13.13.13.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_border_t" id="S7.T2.14.14.14.10"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T2.14.14.14.2"><span class="ltx_text" id="S7.T2.14.14.14.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.14.14.14.2.1.m1.1"><semantics id="S7.T2.14.14.14.2.1.m1.1a"><mi id="S7.T2.14.14.14.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.14.14.14.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.14.14.14.2.1.m1.1b"><ci id="S7.T2.14.14.14.2.1.m1.1.1.cmml" xref="S7.T2.14.14.14.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.14.14.14.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.14.14.14.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.16.16.16">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.16.16.16.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.16.16.16.4">Foursquare</th>
<td class="ltx_td ltx_align_center" id="S7.T2.16.16.16.5">1,083</td>
<td class="ltx_td ltx_align_center" id="S7.T2.16.16.16.6">38,333</td>
<td class="ltx_td ltx_align_center" id="S7.T2.16.16.16.7">227,428</td>
<td class="ltx_td ltx_align_center" id="S7.T2.16.16.16.8">99.45%</td>
<td class="ltx_td" id="S7.T2.16.16.16.9"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.15.15.15.1"><span class="ltx_text" id="S7.T2.15.15.15.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.15.15.15.1.1.m1.1"><semantics id="S7.T2.15.15.15.1.1.m1.1a"><mi id="S7.T2.15.15.15.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.15.15.15.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.15.15.15.1.1.m1.1b"><ci id="S7.T2.15.15.15.1.1.m1.1.1.cmml" xref="S7.T2.15.15.15.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.15.15.15.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.15.15.15.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td" id="S7.T2.16.16.16.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.16.16.16.2"><span class="ltx_text" id="S7.T2.16.16.16.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.16.16.16.2.1.m1.1"><semantics id="S7.T2.16.16.16.2.1.m1.1a"><mi id="S7.T2.16.16.16.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.16.16.16.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.16.16.16.2.1.m1.1b"><ci id="S7.T2.16.16.16.2.1.m1.1.1.cmml" xref="S7.T2.16.16.16.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.16.16.16.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.16.16.16.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.26.26.29.3">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.26.26.29.3.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.26.26.29.3.2">Gowalla</th>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.29.3.3">196,591</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.29.3.4">950,327</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.29.3.5">6,442,890</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.29.3.6">99.99%</td>
<td class="ltx_td" id="S7.T2.26.26.29.3.7"></td>
<td class="ltx_td" id="S7.T2.26.26.29.3.8"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.29.3.9"><span class="ltx_text" id="S7.T2.26.26.29.3.9.1" style="color:#00B050;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.29.3.10"><span class="ltx_text" id="S7.T2.26.26.29.3.10.1" style="color:#00B050;">✓</span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.17.17.17">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.17.17.17.2"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.17.17.17.3">Last.FM</th>
<td class="ltx_td ltx_align_center" id="S7.T2.17.17.17.4">1,892</td>
<td class="ltx_td ltx_align_center" id="S7.T2.17.17.17.5">17,632</td>
<td class="ltx_td ltx_align_center" id="S7.T2.17.17.17.6">92,834</td>
<td class="ltx_td ltx_align_center" id="S7.T2.17.17.17.7">99.72%</td>
<td class="ltx_td" id="S7.T2.17.17.17.8"></td>
<td class="ltx_td" id="S7.T2.17.17.17.9"></td>
<td class="ltx_td" id="S7.T2.17.17.17.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.17.17.17.1"><span class="ltx_text" id="S7.T2.17.17.17.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.17.17.17.1.1.m1.1"><semantics id="S7.T2.17.17.17.1.1.m1.1a"><mi id="S7.T2.17.17.17.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.17.17.17.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.17.17.17.1.1.m1.1b"><ci id="S7.T2.17.17.17.1.1.m1.1.1.cmml" xref="S7.T2.17.17.17.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.17.17.17.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.17.17.17.1.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.26.26.30.4">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.26.26.30.4.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.26.26.30.4.2">Pinterest</th>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.30.4.3">55,187</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.30.4.4">9,911</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.30.4.5">1,445,622</td>
<td class="ltx_td ltx_align_center" id="S7.T2.26.26.30.4.6">99.74%</td>
<td class="ltx_td" id="S7.T2.26.26.30.4.7"></td>
<td class="ltx_td" id="S7.T2.26.26.30.4.8"></td>
<td class="ltx_td" id="S7.T2.26.26.30.4.9"></td>
<td class="ltx_td" id="S7.T2.26.26.30.4.10"></td>
</tr>
<tr class="ltx_tr" id="S7.T2.20.20.20">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.20.20.20.4"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.20.20.20.5">Steam</th>
<td class="ltx_td ltx_align_center" id="S7.T2.20.20.20.6">2,567,538</td>
<td class="ltx_td ltx_align_center" id="S7.T2.20.20.20.7">32,135</td>
<td class="ltx_td ltx_align_center" id="S7.T2.20.20.20.8">7,793,069</td>
<td class="ltx_td ltx_align_center" id="S7.T2.20.20.20.9">99.99%</td>
<td class="ltx_td" id="S7.T2.20.20.20.10"></td>
<td class="ltx_td ltx_align_center" id="S7.T2.18.18.18.1"><span class="ltx_text" id="S7.T2.18.18.18.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.18.18.18.1.1.m1.1"><semantics id="S7.T2.18.18.18.1.1.m1.1a"><mi id="S7.T2.18.18.18.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.18.18.18.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.18.18.18.1.1.m1.1b"><ci id="S7.T2.18.18.18.1.1.m1.1.1.cmml" xref="S7.T2.18.18.18.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.18.18.18.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.18.18.18.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.19.19.19.2"><span class="ltx_text" id="S7.T2.19.19.19.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.19.19.19.2.1.m1.1"><semantics id="S7.T2.19.19.19.2.1.m1.1a"><mi id="S7.T2.19.19.19.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.19.19.19.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.19.19.19.2.1.m1.1b"><ci id="S7.T2.19.19.19.2.1.m1.1.1.cmml" xref="S7.T2.19.19.19.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.19.19.19.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.19.19.19.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.20.20.20.3"><span class="ltx_text" id="S7.T2.20.20.20.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.20.20.20.3.1.m1.1"><semantics id="S7.T2.20.20.20.3.1.m1.1a"><mi id="S7.T2.20.20.20.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.20.20.20.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.20.20.20.3.1.m1.1b"><ci id="S7.T2.20.20.20.3.1.m1.1.1.cmml" xref="S7.T2.20.20.20.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.20.20.20.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.20.20.20.3.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.24.24.24">
<th class="ltx_td ltx_th ltx_th_row" id="S7.T2.24.24.24.5"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T2.24.24.24.6">TaFeng</th>
<td class="ltx_td ltx_align_center" id="S7.T2.24.24.24.7">32,266</td>
<td class="ltx_td ltx_align_center" id="S7.T2.24.24.24.8">23,812</td>
<td class="ltx_td ltx_align_center" id="S7.T2.24.24.24.9">817,741</td>
<td class="ltx_td ltx_align_center" id="S7.T2.24.24.24.10">99.89%</td>
<td class="ltx_td ltx_align_center" id="S7.T2.21.21.21.1"><span class="ltx_text" id="S7.T2.21.21.21.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.21.21.21.1.1.m1.1"><semantics id="S7.T2.21.21.21.1.1.m1.1a"><mi id="S7.T2.21.21.21.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.21.21.21.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.21.21.21.1.1.m1.1b"><ci id="S7.T2.21.21.21.1.1.m1.1.1.cmml" xref="S7.T2.21.21.21.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.21.21.21.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.21.21.21.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.22.22.22.2"><span class="ltx_text" id="S7.T2.22.22.22.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.22.22.22.2.1.m1.1"><semantics id="S7.T2.22.22.22.2.1.m1.1a"><mi id="S7.T2.22.22.22.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.22.22.22.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.22.22.22.2.1.m1.1b"><ci id="S7.T2.22.22.22.2.1.m1.1.1.cmml" xref="S7.T2.22.22.22.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.22.22.22.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.22.22.22.2.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.23.23.23.3"><span class="ltx_text" id="S7.T2.23.23.23.3.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.23.23.23.3.1.m1.1"><semantics id="S7.T2.23.23.23.3.1.m1.1a"><mi id="S7.T2.23.23.23.3.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.23.23.23.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.23.23.23.3.1.m1.1b"><ci id="S7.T2.23.23.23.3.1.m1.1.1.cmml" xref="S7.T2.23.23.23.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.23.23.23.3.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.23.23.23.3.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S7.T2.24.24.24.4"><span class="ltx_text" id="S7.T2.24.24.24.4.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.24.24.24.4.1.m1.1"><semantics id="S7.T2.24.24.24.4.1.m1.1a"><mi id="S7.T2.24.24.24.4.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.24.24.24.4.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.24.24.24.4.1.m1.1b"><ci id="S7.T2.24.24.24.4.1.m1.1.1.cmml" xref="S7.T2.24.24.24.4.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.24.24.24.4.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.24.24.24.4.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S7.T2.26.26.26">
<th class="ltx_td ltx_th ltx_th_row ltx_border_b" id="S7.T2.26.26.26.3"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S7.T2.26.26.26.4">Tmall</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T2.26.26.26.5">963,923</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T2.26.26.26.6">2,353,207</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T2.26.26.26.7">44,528,127</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T2.26.26.26.8">99.99%</td>
<td class="ltx_td ltx_border_b" id="S7.T2.26.26.26.9"></td>
<td class="ltx_td ltx_border_b" id="S7.T2.26.26.26.10"></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T2.25.25.25.1"><span class="ltx_text" id="S7.T2.25.25.25.1.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.25.25.25.1.1.m1.1"><semantics id="S7.T2.25.25.25.1.1.m1.1a"><mi id="S7.T2.25.25.25.1.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.25.25.25.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.25.25.25.1.1.m1.1b"><ci id="S7.T2.25.25.25.1.1.m1.1.1.cmml" xref="S7.T2.25.25.25.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.25.25.25.1.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.25.25.25.1.1.m1.1d">✓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S7.T2.26.26.26.2"><span class="ltx_text" id="S7.T2.26.26.26.2.1" style="color:#00B050;"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S7.T2.26.26.26.2.1.m1.1"><semantics id="S7.T2.26.26.26.2.1.m1.1a"><mi id="S7.T2.26.26.26.2.1.m1.1.1" mathcolor="#00B050" mathvariant="normal" xref="S7.T2.26.26.26.2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S7.T2.26.26.26.2.1.m1.1b"><ci id="S7.T2.26.26.26.2.1.m1.1.1.cmml" xref="S7.T2.26.26.26.2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T2.26.26.26.2.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S7.T2.26.26.26.2.1.m1.1d">✓</annotation></semantics></math></span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">In FRS, the datasets used can be categorized into two types based on user feedback: explicit feedback and implicit feedback, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S7.F7" title="Figure 7 ‣ VII-A Datasets ‣ VII Resources ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">7</span></a>.
Explicit feedback includes direct responses from users about their preferences. This typically includes ratings (such as a 1-5 scale), user comments, and like/dislike statements. Such data is clear and provides straightforward insights into user preferences, making it highly valuable for training recommendation models.
Common datasets with explicit feedback include the following shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#S7.T1" title="TABLE I ‣ VII-A Datasets ‣ VII Resources ‣ Navigating the Future of Federated Recommendation Systems with Foundation Models"><span class="ltx_text ltx_ref_tag">I</span></a>:</p>
<ul class="ltx_itemize" id="S7.I1">
<li class="ltx_item" id="S7.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i1.p1">
<p class="ltx_p" id="S7.I1.i1.p1.1">Amazon Reviews<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://cseweb.ucsd.edu/ jmcauley/datasets.html#amazon_reviews</span></span></span>: The Amazon Reviews dataset is a large-scale dataset that contains product information across various categories such as Books, CDs, and Music. It includes reviews (ratings, text, helpfulness votes) and product metadata (description, category information, price, brand, and image features). There are three updated versions of this dataset from the years 2014 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib170" title="">170</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib171" title="">171</a>]</cite>, 2018 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib172" title="">172</a>]</cite>, and 2023 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib173" title="">173</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i2.p1">
<p class="ltx_p" id="S7.I1.i2.p1.1">MovieLens Datasets<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://grouplens.org/datasets/movielens/</span></span></span>: The MovieLens datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib174" title="">174</a>]</cite>, initially released in 1998, capture individuals’ stated movie preferences. These preferences are recorded as tuples, with each tuple showing a person’s rating (from 0 to 5 stars) for a movie at a specific time. Users enter these ratings through the MovieLens website, which provides personalized movie suggestions based on these ratings.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i3.p1">
<p class="ltx_p" id="S7.I1.i3.p1.1">Yelp Datasets<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://www.yelp.com/dataset</span></span></span>: This dataset is a subset of Yelp’s business, review, and user data. It was initially developed for the Yelp Dataset Challenge, which allows students to study or analyze Yelp data and present their insights. In total, there are four versions of the Yelp datasets.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i4.p1">
<p class="ltx_p" id="S7.I1.i4.p1.1">Anime<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database</span></span></span>: This dataset collects user preference data from the MyAnimeList website. It contains information from 73,516 users on 12,294 anime titles. Users can add anime to their completed list and rate them, and this dataset compiles these ratings.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i5.p1">
<p class="ltx_p" id="S7.I1.i5.p1.1">Book Crossing<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://grouplens.org/datasets/book-crossing/</span></span></span>: The Book-Crossing dataset is a well-structured collection of data collected by Cai-Nicolas Ziegler in a 4-week crawl from the Book-Crossing community. This dataset primarily comprises user interactions that include book ratings, ranging from 0 to 10.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i6.p1">
<p class="ltx_p" id="S7.I1.i6.p1.1">Douban<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://www.kaggle.com/datasets/utmhikari/doubanmovieshortcomments</span></span></span>: The Douban Movie dataset is a Chinese website where internet users can post their opinions and comments about films. This dataset contains over 2 million short comments on 28 movies from the Douban Movie website.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i7.p1">
<p class="ltx_p" id="S7.I1.i7.p1.1">Epinions<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://cseweb.ucsd.edu/ jmcauley/datasets.html#social_data</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib175" title="">175</a>]</cite>: This dataset was collected from Epinions.com, a popular online consumer review site. It includes trust relationships between users and covers a period from January 2001 to November 2013.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i8.p1">
<p class="ltx_p" id="S7.I1.i8.p1.1">Goodreads<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks</span></span></span>: This dataset includes reviews from the book review website Goodreads, along with various attributes describing the books. Importantly, the dataset captures different levels of user interaction, from adding books to a shelf, to rating them, to reading them.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i9.p1">
<p class="ltx_p" id="S7.I1.i9.p1.1">Jester<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>https://eigentaste.berkeley.edu/dataset/</span></span></span>: The Jester dataset focuses exclusively on jokes. Users of the Jester online platform rate jokes and these ratings are then used to personalize joke recommendations for them.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i10.p1">
<p class="ltx_p" id="S7.I1.i10.p1.1">Netflix<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data</span></span></span>: Netflix provided a training dataset consisting of 100,480,507 ratings from 480,189 users for 17,770 films. Each rating is represented as a set of four elements: ¡user, movie, rating date, rating score¿. The user and the movie are identified by integer IDs, and the rating scores range from 1 to 5 stars, also as integers.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i11" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I1.i11.p1">
<p class="ltx_p" id="S7.I1.i11.p1.1">Yahoo Music<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>https://webscope.sandbox.yahoo.com/catalog.php?datatype=r</span></span></span>: The Yahoo Music dataset is known for its large scale and diversity. It contains a large collection of user ratings on different musical elements such as tracks, albums, artists and genres. This dataset was used in the KDD-Cup 2011 competition, where participants were asked to analyse user preferences in music based on these ratings.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1">Implicit feedback, on the other hand, is derived from user actions that indirectly indicate preferences, such as bookmarks, video/music play history, or click-throughs. Although implicit feedback does not directly express user likes or dislikes, it is rich and captures user behaviour more comprehensively.</p>
<ul class="ltx_itemize" id="S7.I2">
<li class="ltx_item" id="S7.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i1.p1">
<p class="ltx_p" id="S7.I2.i1.p1.1">MIND<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>https://msnews.github.io/</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib176" title="">176</a>]</cite>: The MIND dataset, sourced from the Microsoft News website, is a large-scale collection of approximately 160,000 English news articles and over 15 million user interaction records. It has been designed to advance research in news recommendation systems. It includes detailed textual content for each story and anonymized user interaction data to ensure privacy.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i2.p1">
<p class="ltx_p" id="S7.I2.i2.p1.1">Tenrec<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>https://github.com/yuangh-x/2022-NIPS-Tenrec</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib177" title="">177</a>]</cite>: The Tenrec dataset is a comprehensive benchmark dataset for RSs, featuring user interactions from two recommendation platforms across four dataset files: QK-video and QB-video for video actions, and QK-article and QB-article for article actions.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i3.p1">
<p class="ltx_p" id="S7.I2.i3.p1.1">Adressa<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>https://reclab.idi.ntnu.no/dataset/</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib178" title="">178</a>]</cite>: The Adressa dataset is a corpus of Norwegian news articles related to anonymous users. It is a collaborative project between the Norwegian University of Science and Technology and Adressavisen. The objective is to gain insight into the nature of news articles and their readers.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i4.p1">
<p class="ltx_p" id="S7.I2.i4.p1.1">Foursquare<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>https://sites.google.com/site/yangdingqi/home/foursquare-dataset</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib179" title="">179</a>]</cite>: This dataset comprises check-in data from New York City, collected over a period of approximately ten months (from 12 April 2012 to 16 February 2013). It encompasses 227,428 check-ins in New York City, with each check-in recorded with its timestamp, GPS coordinates, and detailed venue category.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i5.p1">
<p class="ltx_p" id="S7.I2.i5.p1.1">Gowalla<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span>https://snap.stanford.edu/data/loc-gowalla.html</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib180" title="">180</a>]</cite>: Gowalla is a location-based social networking website where users can post their whereabouts by checking in. The dataset comprises data collected from the public API, which represents an undirected friendship network with 196,591 nodes and 950,327 connections. Additionally, it records 6,442,890 check-ins made by these users between February 2009 and October 2010.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i6.p1">
<p class="ltx_p" id="S7.I2.i6.p1.1">Last.FM<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span>https://grouplens.org/datasets/hetrec-2011/</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib181" title="">181</a>]</cite>: The Last.FM dataset represents a valuable resource that has been extensively utilized in the field of music information retrieval and RSs. It captures detailed information regarding music listening events from users. Each listening event is further enhanced with user demographics and specific descriptors that reflect their music tastes and consumption behaviours.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i7.p1">
<p class="ltx_p" id="S7.I2.i7.p1.1">Pinterest<span class="ltx_note ltx_role_footnote" id="footnote18"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span>https://github.com/edervishaj/pinterest-recsys-dataset</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib182" title="">182</a>]</cite>: The Pinterest dataset represents a valuable resource for a variety of research and analytical purposes. It encompasses a diverse range of data, including images, user features, interests, and user interactions.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i8.p1">
<p class="ltx_p" id="S7.I2.i8.p1.1">Steam<span class="ltx_note ltx_role_footnote" id="footnote19"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span>https://github.com/kang205/SASRec</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib183" title="">183</a>]</cite>: The Steam dataset is a collection of information about games published on the Steam platform. It includes details such as game names, release dates, genres, developers, publishers, and other relevant information.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i9.p1">
<p class="ltx_p" id="S7.I2.i9.p1.1">TaFeng<span class="ltx_note ltx_role_footnote" id="footnote20"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span>https://www.kaggle.com/datasets/chiranjivdas09/ta-feng-grocery-dataset</span></span></span>: The TaFeng dataset is a comprehensive collection of supermarket shopping data, including detailed transaction records from the Ta Feng supermarket in Taiwan, covering a period from November 2000 to February 2001. The dataset comprises a variety of data points, including customer demographics, product categories, and detailed item descriptions along with quantities purchased.</p>
</div>
</li>
<li class="ltx_item" id="S7.I2.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S7.I2.i10.p1">
<p class="ltx_p" id="S7.I2.i10.p1.1">Tmall<span class="ltx_note ltx_role_footnote" id="footnote21"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note">21</span>https://tianchi.aliyun.com/dataset/53</span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib184" title="">184</a>]</cite>: The Tmall dataset is a comprehensive collection from Tmall, comprising anonymized user shopping records over a six-month period up to and including the ”Double 11” event. It should be noted that the data is selectively sampled to address privacy concerns.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S7.SS1.p3">
<p class="ltx_p" id="S7.SS1.p3.1">Both types of feedback play a critical role in the development of FRSs, providing diverse insights into user preferences that help improve the accuracy and relevance of the recommendations provided.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S7.SS2.4.1.1">VII-B</span> </span><span class="ltx_text ltx_font_italic" id="S7.SS2.5.2">Metrics</span>
</h3>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">In the field of FRSs, the use of evaluation metrics is fundamental to assessing and refining the performance of our algorithms. Metrics serve as a quantitative lens through which we can observe how closely the system’s suggestions match users’ actual interests and preferences.</p>
</div>
<div class="ltx_para" id="S7.SS2.p2">
<p class="ltx_p" id="S7.SS2.p2.1">For predicting how well a system can estimate user preferences, there are several metrices measuring the prediction errors to judge the accuracy of the predictions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib185" title="">185</a>]</cite>, such as Mean Absolute Error (MAE), Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).
When it comes to classifying items, i.e., determining whether a user will like a product or not, we look at metrics such as Precision, Recall, Hit Ratio (HR), F1 Score, Accuracy and AUC. These tell us how correctly the RS is classifying items, and the F1 score helps us balance the Precision and Recall.</p>
</div>
<div class="ltx_para" id="S7.SS2.p3">
<p class="ltx_p" id="S7.SS2.p3.1">Then to measure the item ranking ability, which is about listing recommendations in the right order, Average Precision (AP) and Mean Average Precision (MAP) are key to this, as they assess the quality of the order of recommendations. Metrics such as Mean Reciprocal Rank (MRR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib186" title="">186</a>]</cite>, Normalized Mutual Rank (NMR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib187" title="">187</a>]</cite> and Normalised Discounted Cumulative Gain (NDCG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib188" title="">188</a>]</cite> also contribute by assessing how well the top recommended items are ranked.</p>
</div>
<div class="ltx_para" id="S7.SS2.p4">
<p class="ltx_p" id="S7.SS2.p4.1">On a broader scale, we consider recommendation-centric metrics such as Diversity, which ensures that a variety of items are suggested, and Coverage, which measures how many items from the catalogue are recommended. There are also some user-centric metrics include Novelty, which measures how new or surprising the recommendations are, and Degree of Agreement (DOA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib189" title="">189</a>]</cite>, which quantifies the level of concordance between the ranking of items produced by a recommendation system and the ranking preferred by the user.
Moreover, business metrics such as Click-Through Rate (CTR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib190" title="">190</a>]</cite> are critical to assessing the system’s impact on user engagement and the company’s bottom line, and Conversion Rate (CVR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib190" title="">190</a>]</cite> measures how efficient an algorithm is at providing recommendations that lead to user purchases.
There also are some metrics for measuring other functionality. For example, Gini Index <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.00004v2#bib.bib191" title="">191</a>]</cite> evaluates the fairness of recommendation distribution, with lower values indicating more equitable distribution across items.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span class="ltx_text ltx_font_smallcaps" id="S8.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">This study comprehensively examines the integration of FRSs with FMs, a direction that has gained attention for its ability to protect user privacy. The article begins by summarizing common approaches of FRSs and FMs, then delves into the challenges faced during integration. To address these challenges, the paper proposes various strategies including using transfer learning and multitask learning techniques to adapt to data diversity, employing privacy-preserving methods like differential privacy and secure multi-party computation, and reducing communication overhead through model compression and efficient communication protocols.</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">This work also discusses the future research directions directions indicating that FRSs can provide more accurate personalized recommendations while better protecting user privacy. Additionally, the paper showcases applications of FRS in various fields, demonstrating their potential and value in the real world.
Through this study, we aim to provide theoretical guidance for integrating FRS with FM, directing future research and technological advancements to collectively advance this field.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
H. Ko, S. Lee, Y. Park, and A. Choi, “A survey of recommendation systems: recommendation models, techniques, and application fields,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Electronics</em>, vol. 11, no. 1, p. 141, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
P. Voigt and A. Von dem Bussche, “The eu general data protection regulation (gdpr),” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">A Practical Guide, 1st Ed., Cham: Springer International Publishing</em>, vol. 10, no. 3152676, pp. 10–5555, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efficient learning of deep networks from decentralized data,” in <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on federated learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Knowledge-Based Systems</em>, vol. 216, p. 106775, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H. Yuan, C. Ma, Z. Zhao, X. Xu, and Z. Wang, “A privacy-preserving oriented service recommendation approach based on personal data cloud and federated learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">2022 IEEE International Conference on Web Services (ICWS)</em>.   IEEE, 2022, pp. 322–330.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Yin, Y. Li, H. Gao, T. Liang, and Q. Pan, “Fgc: Gcn-based federated learning approach for trust industrial service recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">IEEE Transactions on Industrial Informatics</em>, vol. 19, no. 3, pp. 3240–3250, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
W. Huang, J. Liu, T. Li, T. Huang, S. Ji, and J. Wan, “Feddsr: Daily schedule recommendation in a federated deep reinforcement learning framework,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">IEEE Transactions on Knowledge and Data Engineering</em>, vol. 35, no. 4, pp. 3912–3924, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
C. Lu, Y. Fan, X. Wu, and J. Zhang, “Fmfparking: Federated matrix factorization for parking lot recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">2021 IEEE Seventh International Conference on Big Data Computing Service and Applications (BigDataService)</em>.   IEEE, 2021, pp. 131–136.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J. Vyas, D. Das, S. Chaudhury <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">et al.</em>, “Federated learning based driver recommendation for next generation transportation system,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.2.2">Expert Systems with Applications</em>, vol. 225, p. 119951, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
T. OpenAI, “Chatgpt: Optimizing language models for dialogue. openai,” 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J. Ho, A. Jain, and P. Abbeel, “Denoising diffusion probabilistic models,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in neural information processing systems</em>, vol. 33, pp. 6840–6851, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Ho, C. Saharia, W. Chan, D. J. Fleet, M. Norouzi, and T. Salimans, “Cascaded diffusion models for high fidelity image generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Journal of Machine Learning Research</em>, vol. 23, no. 47, pp. 1–33, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
C. Saharia, W. Chan, H. Chang, C. Lee, J. Ho, T. Salimans, D. Fleet, and M. Norouzi, “Palette: Image-to-image diffusion models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ACM SIGGRAPH 2022 conference proceedings</em>, 2022, pp. 1–10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
N. Savinov, J. Chung, M. Binkowski, E. Elsen, and A. v. d. Oord, “Step-unrolled denoising autoencoders for text generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2112.06749</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
X. Li, J. Thickstun, I. Gulrajani, P. S. Liang, and T. B. Hashimoto, “Diffusion-lm improves controllable text generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 4328–4343, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. Gao, H. Zhao, C. Yu, and R. Xu, “Exploring the feasibility of chatgpt for event extraction,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2303.03836</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Y. Ma, Y. Cao, Y. Hong, and A. Sun, “Large language model is not a good few-shot information extractor, but a good reranker for hard samples!” <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2303.08559</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">et al.</em>, “On the opportunities and risks of foundation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib18.2.2">arXiv preprint arXiv:2108.07258</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:1810.04805</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, “Roberta: A robustly optimized bert pretraining approach,” <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">et al.</em>, “An image is worth 16x16 words: Transformers for image recognition at scale,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.2.2">arXiv preprint arXiv:2010.11929</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y. Wang, J. Zhang, and Y. Wang, “Do generated data always help contrastive learning?” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2403.12448</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">et al.</em>, “Learning transferable visual models from natural language supervision,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.2.2">International conference on machine learning</em>.   PMLR, 2021, pp. 8748–8763.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A. Tamkin, M. Brundage, J. Clark, and D. Ganguli, “Understanding the capabilities, limitations, and societal impact of large language models,” 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Y. Cao, S. Li, Y. Liu, Z. Yan, Y. Dai, P. S. Yu, and L. Sun, “A comprehensive survey of ai-generated content (aigc): A history of generative ai from gan to chatgpt,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2303.04226</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
L. Yang, B. Tan, V. W. Zheng, K. Chen, and Q. Yang, “Federated recommendation systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Federated Learning: Privacy and Incentive</em>, pp. 225–239, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Z. Alamgir, F. K. Khan, and S. Karim, “Federated recommenders: methods, challenges and future,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Cluster Computing</em>, vol. 25, no. 6, pp. 4075–4096, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
D. Javeed, M. S. Saeed, P. Kumar, A. Jolfaei, S. Islam, and A. K. M. N. Islam, “Federated Learning-based Personalized Recommendation Systems: An Overview on Security and Privacy Challenges,” <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">IEEE Transactions on Consumer Electronics</em>, pp. 1–1, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Z. Sun, Y. Xu, Y. Liu, W. He, L. Kong, F. Wu, Y. Jiang, and L. Cui, “A survey on federated recommendation systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">IEEE Transactions on Neural Networks and Learning Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
C. Chen, X. Feng, J. Zhou, J. Yin, and X. Zheng, “Federated large language model: A position paper,” <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2307.08925</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
W. Zhuang, C. Chen, and L. Lyu, “When foundation model meets federated learning: Motivations, challenges, and future directions,” <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2306.15546</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S. Yu, J. P. Muñoz, and A. Jannesari, “Federated foundation models: Privacy-preserving and collaborative learning for large models,” <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2305.11414</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
H. Woisetschläger, A. Isenko, S. Wang, R. Mayer, and H.-A. Jacobsen, “A survey on efficient federated learning methods for foundation model training,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2401.04472</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Chen, G. Long, T. Shen, and J. Jiang, “Prompt federated learning for weather forecasting: Toward foundation models on meteorological data,” <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2301.09152</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
X. Li and J. Wang, “Position paper: Assessing robustness, privacy, and fairness in federated learning integrated with foundation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2402.01857</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
C. Ren, H. Yu, H. Peng, X. Tang, A. Li, Y. Gao, A. Z. Tan, B. Zhao, X. Li, Z. Li <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">et al.</em>, “Advances and open challenges in federated learning with foundation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib36.2.2">arXiv preprint arXiv:2404.15381</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
P. Liu, L. Zhang, and J. A. Gulla, “Pre-train, prompt, and recommendation: A comprehensive survey of language modeling paradigm adaptations in recommender systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Transactions of the Association for Computational Linguistics</em>, vol. 11, pp. 1553–1571, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
L. Wu, Z. Zheng, Z. Qiu, H. Wang, H. Gu, T. Shen, C. Qin, C. Zhu, H. Zhu, Q. Liu <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">et al.</em>, “A survey on large language models for recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib38.2.2">arXiv preprint arXiv:2305.19860</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
C. Zhang, G. Long, T. Zhou, P. Yan, Z. Zhang, C. Zhang, and B. Yang, “Dual personalization on federated recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence</em>, 2023, pp. 4558–4566.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Z. Li, G. Long, and T. Zhou, “Federated recommendation with additive personalization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">The Twelfth International Conference on Learning Representations</em>, 2024. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://openreview.net/forum?id=xkXdE81mOK</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
C. Zhang, G. Long, H. Guo, X. Fang, Y. Song, Z. Liu, G. Zhou, Z. Zhang, Y. Liu, and B. Yang, “Federated adaptation for foundation model-based recommendations,” <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2405.04840</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
J. Zhang and Y. Jiang, “A vertical federation recommendation method based on clustering and latent factor model,” in <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">2021 International Conference on Electronic Information Engineering and Computer Science (EIECS)</em>.   IEEE, 2021, pp. 362–366.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Z. Cao, Z. Liang, B. Wu, S. Zhang, H. Li, O. Wen, Y. Rong, and P. Zhao, “Privacy matters: Vertical federated linear contextual bandits for privacy protected recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2023, pp. 154–166.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
P. Mai and Y. Pang, “Vertical federated graph neural network for recommender system,” in <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">International Conference on Machine Learning</em>.   PMLR, 2023, pp. 23 516–23 535.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
S. Wan, D. Gao, H. Gu, and D. Hu, “Fedpdd: A privacy-preserving double distillation framework for cross-silo federated recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">2023 International Joint Conference on Neural Networks (IJCNN)</em>.   IEEE, 2023, pp. 1–8.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He, “A comprehensive survey on transfer learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the IEEE</em>, vol. 109, no. 1, pp. 43–76, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
H. Zhang, H. Liu, H. Li, and Y. Li, “Transfr: Transferable federated recommendation with pre-trained language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2402.01124</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Q. Li, Y. Diao, Q. Chen, and B. He, “Federated learning on non-iid data silos: An experimental study,” in <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">2022 IEEE 38th international conference on data engineering (ICDE)</em>.   IEEE, 2022, pp. 965–978.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
H. Zhang, F. Luo, J. Wu, X. He, and Y. Li, “Lightfr: Lightweight federated recommendation with privacy-preserving matrix factorization,” <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">ACM Transactions on Information Systems</em>, vol. 41, no. 4, pp. 1–28, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
L. Qu, N. Tang, R. Zheng, Q. V. H. Nguyen, Z. Huang, Y. Shi, and H. Yin, “Semi-decentralized federated ego graph learning for recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the ACM Web Conference 2023</em>, 2023, pp. 339–348.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
I. Hegedűs, G. Danner, and M. Jelasity, “Decentralized recommendation based on matrix factorization: A comparison of gossip and federated learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>.   Springer, 2019, pp. 317–332.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
X. Zheng, Z. Wang, C. Chen, J. Qian, and Y. Yang, “Decentralized graph neural network for privacy-preserving recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, 2023, pp. 3494–3504.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Z. Li, Z. Lin, F. Liang, W. Pan, Q. Yang, and Z. Ming, “Decentralized federated recommendation with privacy-aware structured client-level graph,” <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">ACM Transactions on Intelligent Systems and Technology</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
K. W. Church, Z. Chen, and Y. Ma, “Emerging trends: A gentle introduction to fine-tuning,” <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Natural Language Engineering</em>, vol. 27, no. 6, pp. 763–778, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Y. Yuan, “On the power of foundation models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">International Conference on Machine Learning</em>.   PMLR, 2023, pp. 40 519–40 530.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">et al.</em>, “Language models are few-shot learners,” <em class="ltx_emph ltx_font_italic" id="bib.bib56.2.2">Advances in neural information processing systems</em>, vol. 33, pp. 1877–1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">et al.</em>, “Chain-of-thought prompting elicits reasoning in large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib57.2.2">Advances in neural information processing systems</em>, vol. 35, pp. 24 824–24 837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
W. Yang, M. Liu, Z. Wang, and S. Liu, “Foundation models meet visualizations: Challenges and opportunities,” <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Computational Visual Media</em>, pp. 1–26, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
H. Zhao, H. Chen, F. Yang, N. Liu, H. Deng, H. Cai, S. Wang, D. Yin, and M. Du, “Explainability for large language models: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">ACM Transactions on Intelligent Systems and Technology</em>, vol. 15, no. 2, pp. 1–38, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, “Scaling laws for neural language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
B. Isik, N. Ponomareva, H. Hazimeh, D. Paparas, S. Vassilvitskii, and S. Koyejo, “Scaling laws for downstream task performance of large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">arXiv preprint arXiv:2402.04177</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
R. Dabre, C. Chu, and A. Kunchukuttan, “A survey of multilingual neural machine translation,” <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">ACM Computing Surveys (CSUR)</em>, vol. 53, no. 5, pp. 1–38, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
W. Lu, J. Jiao, and R. Zhang, “Twinbert: Distilling knowledge to twin-structured compressed bert models for large-scale retrieval,” in <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em>, 2020, pp. 2645–2652.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Y. Liu, W. Lu, S. Cheng, D. Shi, S. Wang, Z. Cheng, and D. Yin, “Pre-trained language model for web-scale retrieval in baidu search,” in <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</em>, 2021, pp. 3365–3375.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
L. Mathew and V. Bindu, “A review of natural language processing techniques for sentiment analysis using pre-trained models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">2020 Fourth international conference on computing methodologies and communication (ICCMC)</em>.   IEEE, 2020, pp. 340–345.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">et al.</em>, “Llama: Open and efficient foundation language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib66.2.2">arXiv preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
W. Wang, M. Shi, Q. Li, W. Wang, Z. Huang, L. Xing, Z. Chen, H. Li, X. Zhu, Z. Cao <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">et al.</em>, “The all-seeing project: Towards panoptic visual recognition and understanding of the open world,” <em class="ltx_emph ltx_font_italic" id="bib.bib67.2.2">arXiv preprint arXiv:2308.01907</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Y. Zhang, X. Huang, J. Ma, Z. Li, Z. Luo, Y. Xie, Y. Qin, T. Luo, Y. Li, S. Liu <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">et al.</em>, “Recognize anything: A strong image tagging model,” <em class="ltx_emph ltx_font_italic" id="bib.bib68.2.2">arXiv preprint arXiv:2306.03514</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">et al.</em>, “Segment anything,” in <em class="ltx_emph ltx_font_italic" id="bib.bib69.2.2">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2023, pp. 4015–4026.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
X. Wang, X. Zhang, Y. Cao, W. Wang, C. Shen, and T. Huang, “Seggpt: Segmenting everything in context,” <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2304.03284</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
X. Zou, J. Yang, H. Zhang, F. Li, L. Li, J. Wang, L. Wang, J. Gao, and Y. J. Lee, “Segment everything everywhere all at once,” <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">Advances in Neural Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
J. Huang, W. Y. Zhu, B. Jia, Z. Wang, X. Ma, Q. Li, and S. Huang, “Perceive, ground, reason, and act: A benchmark for general-purpose visual representation,” <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">arXiv preprint arXiv:2211.15402</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
M. Ding, Y. Shen, L. Fan, Z. Chen, Z. Chen, P. Luo, J. B. Tenenbaum, and C. Gan, “Visual dependency transformers: Dependency tree emerges from reversed attention,” in <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 14 528–14 539.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
M. Oquab, T. Darcet, T. Moutakanni, H. Vo, M. Szafraniec, V. Khalidov, P. Fernandez, D. Haziza, F. Massa, A. El-Nouby <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">et al.</em>, “Dinov2: Learning robust visual features without supervision,” <em class="ltx_emph ltx_font_italic" id="bib.bib74.2.2">arXiv preprint arXiv:2304.07193</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
J. Bai, S. Bai, S. Yang, S. Wang, S. Tan, P. Wang, J. Lin, C. Zhou, and J. Zhou, “Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
W. Wang, Q. Lv, W. Yu, W. Hong, J. Qi, Y. Wang, J. Ji, Z. Yang, L. Zhao, X. Song <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">et al.</em>, “Cogvlm: Visual expert for pretrained language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib76.2.2">arXiv preprint arXiv:2311.03079</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
H. You, H. Zhang, Z. Gan, X. Du, B. Zhang, Z. Wang, L. Cao, S.-F. Chang, and Y. Yang, “Ferret: Refer and ground anything anywhere at any granularity,” <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">arXiv preprint arXiv:2310.07704</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
X. Liu, T. Zhou, Y. Wang, Y. Wang, Q. Cao, W. Du, Y. Yang, J. He, Y. Qiao, and Y. Shen, “Towards the unification of generative and discriminative visual foundation model: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">arXiv preprint arXiv:2312.10163</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Y. Yao, B. Dong, A. Zhang, Z. Zhang, R. Xie, Z. Liu, L. Lin, M. Sun, and J. Wang, “Prompt tuning for discriminative pre-trained language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">arXiv preprint arXiv:2205.11166</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
H. Chen, Y. Dong, Z. Wang, X. Yang, C. Duan, H. Su, and J. Zhu, “Robust classification via a single diffusion model,” <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">arXiv preprint arXiv:2305.15241</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
J. Ali, M. Kleindessner, F. Wenzel, K. Budhathoki, V. Cevher, and C. Russell, “Evaluating the fairness of discriminative foundation models in computer vision,” in <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society</em>, 2023, pp. 809–833.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
D. W. Otter, J. R. Medina, and J. K. Kalita, “A survey of the usages of deep learning for natural language processing,” <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">IEEE transactions on neural networks and learning systems</em>, vol. 32, no. 2, pp. 604–624, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
N. Ding, Y. Qin, G. Yang, F. Wei, Z. Yang, Y. Su, S. Hu, Y. Chen, C.-M. Chan, W. Chen <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">et al.</em>, “Parameter-efficient fine-tuning of large-scale pre-trained language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib83.2.2">Nature Machine Intelligence</em>, vol. 5, no. 3, pp. 220–235, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
F. Liu, T. Zhang, W. Dai, W. Cai, X. Zhou, and D. Chen, “Few-shot adaptation of multi-modal foundation models: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">arXiv preprint arXiv:2401.01736</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “Lora: Low-rank adaptation of large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">arXiv preprint arXiv:2106.09685</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, “Qlora: Efficient finetuning of quantized llms,” <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">Advances in Neural Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
P. Gao, S. Geng, R. Zhang, T. Ma, R. Fang, Y. Zhang, H. Li, and Y. Qiao, “Clip-adapter: Better vision-language models with feature adapters,” <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">International Journal of Computer Vision</em>, vol. 132, no. 2, pp. 581–595, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
K. Zhou, J. Yang, C. C. Loy, and Z. Liu, “Learning to prompt for vision-language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">International Journal of Computer Vision</em>, vol. 130, no. 9, pp. 2337–2348, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
——, “Conditional prompt learning for vision-language models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2022, pp. 16 816–16 825.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Z. Guo, R. Zhang, L. Qiu, X. Ma, X. Miao, X. He, and B. Cui, “Calip: Zero-shot enhancement of clip with parameter-free attention,” in <em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol. 37, no. 1, 2023, pp. 746–754.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
S. Pratt, I. Covert, R. Liu, and A. Farhadi, “What does a platypus look like? generating customized prompts for zero-shot image classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, 2023, pp. 15 691–15 701.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Y. Yang, A. Panagopoulou, S. Zhou, D. Jin, C. Callison-Burch, and M. Yatskar, “Language in a bottle: Language model guided concept bottlenecks for interpretable image classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 19 187–19 197.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
A. Ramé, K. Ahuja, J. Zhang, M. Cord, L. Bottou, and D. Lopez-Paz, “Model ratatouille: Recycling diverse models for out-of-distribution generalization,” in <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">International Conference on Machine Learning</em>.   PMLR, 2023, pp. 28 656–28 679.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
S. Geng, S. Liu, Z. Fu, Y. Ge, and Y. Zhang, “Recommendation as language processing (rlp): A unified pretrain, personalized prompt &amp; predict paradigm (p5),” in <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">Proceedings of the 16th ACM Conference on Recommender Systems</em>, 2022, pp. 299–315.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
B. Glocker, C. Jones, M. Roschewitz, and S. Winzeck, “Risk of bias in chest radiography deep learning foundation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">Radiology: Artificial Intelligence</em>, vol. 5, no. 6, p. e230060, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Y. Hou, J. Zhang, Z. Lin, H. Lu, R. Xie, J. McAuley, and W. X. Zhao, “Large language models are zero-shot rankers for recommender systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">European Conference on Information Retrieval</em>.   Springer, 2024, pp. 364–381.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
L. Wu, Z. Qiu, Z. Zheng, H. Zhu, and E. Chen, “Exploring large language model for graph data understanding in online job recommendations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol. 38, no. 8, 2024, pp. 9178–9186.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Y. Cheng, D. Wang, P. Zhou, and T. Zhang, “A survey of model compression and acceleration for deep neural networks,” <em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">arXiv preprint arXiv:1710.09282</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
H. Yang, “H-fl: A hierarchical communication-efficient and privacy-protected architecture for federated learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">arXiv preprint arXiv:2106.00275</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Z. Li, H. Zhao, B. Li, and Y. Chi, “Soteriafl: A unified framework for private federated learning with communication compression,” <em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 4285–4300, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
G.-J. Qu and M.-M. Wang, “Secure multi-party quantum computation based on blind quantum computation,” <em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">International Journal of Theoretical Physics</em>, vol. 60, no. 8, pp. 3003–3012, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
B. Buyukates, J. So, H. Mahdavifar, and S. Avestimehr, “Lightverifl: Lightweight and verifiable secure federated learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">Workshop on Federated Learning: Recent Advances and New Challenges (in Conjunction with NeurIPS 2022)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for federated learning on user-held data,” <em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">arXiv preprint arXiv:1611.04482</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
S. Kadhe, N. Rajaraman, O. O. Koyluoglu, and K. Ramchandran, “Fastsecagg: Scalable secure aggregation for privacy-preserving federated learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">arXiv preprint arXiv:2009.11248</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
H. Fereidooni, S. Marchal, M. Miettinen, A. Mirhoseini, H. Möllering, T. D. Nguyen, P. Rieger, A.-R. Sadeghi, T. Schneider, H. Yalame <em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">et al.</em>, “Safelearn: Secure aggregation for private federated learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib105.2.2">2021 IEEE Security and Privacy Workshops (SPW)</em>.   IEEE, 2021, pp. 56–62.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
M. Marone and B. Van Durme, “Data portraits: Recording foundation model training data,” <em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">Advances in Neural Information Processing Systems</em>, vol. 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
J. Li, C. Jia, X. Zhang, S. Ma, and W. Gao, “Cross modal compression: Towards human-comprehensible semantic compression,” in <em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">Proceedings of the 29th ACM international conference on multimedia</em>, 2021, pp. 4230–4238.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
C. Liu, C. Tao, J. Feng, and D. Zhao, “Multi-granularity structural knowledge distillation for language model compression,” in <em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 2022, pp. 1001–1011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
O. Shahid, S. Pouriyeh, R. M. Parizi, Q. Z. Sheng, G. Srivastava, and L. Zhao, “Communication efficiency in federated learning: Achievements and challenges,” <em class="ltx_emph ltx_font_italic" id="bib.bib109.1.1">arXiv preprint arXiv:2107.10996</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
P. Qi, D. Chiaro, A. Guzzo, M. Ianni, G. Fortino, and F. Piccialli, “Model aggregation techniques in federated learning: A comprehensive survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib110.1.1">Future Generation Computer Systems</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
D. Chai, L. Wang, K. Chen, and Q. Yang, “Secure federated matrix factorization,” <em class="ltx_emph ltx_font_italic" id="bib.bib111.1.1">IEEE Intelligent Systems</em>, vol. 36, no. 5, pp. 11–20, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
Z. Li, G. Long, and T. Zhou, “Federated recommendation with additive personalization,” <em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">arXiv preprint arXiv:2301.09109</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Y. J. Cho, J. Wang, and G. Joshi, “Client selection in federated learning: Convergence analysis and power-of-choice selection strategies,” <em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">arXiv preprint arXiv:2010.01243</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
V. Rawte, A. Sheth, and A. Das, “A survey of hallucination in large foundation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">arXiv preprint arXiv:2309.05922</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton, “Adaptive mixtures of local experts,” <em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">Neural computation</em>, vol. 3, no. 1, pp. 79–87, 1991.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
A. Elhafsi, R. Sinha, C. Agia, E. Schmerling, I. A. Nesnas, and M. Pavone, “Semantic anomaly detection with large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">Autonomous Robots</em>, vol. 47, no. 8, pp. 1035–1055, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
X. Xu, Y. Cao, Y. Chen, W. Shen, and X. Huang, “Customizing visual-language foundation models for multi-modal anomaly detection and reasoning,” <em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">arXiv preprint arXiv:2403.11083</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
L. Minto, M. Haller, B. Livshits, and H. Haddadi, “Stronger privacy for federated collaborative filtering with implicit feedback,” in <em class="ltx_emph ltx_font_italic" id="bib.bib118.1.1">Proceedings of the 15th ACM Conference on Recommender Systems</em>, 2021, pp. 342–350.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
A. Acar, H. Aksu, A. S. Uluagac, and M. Conti, “A survey on homomorphic encryption schemes: Theory and implementation,” <em class="ltx_emph ltx_font_italic" id="bib.bib119.1.1">ACM Computing Surveys (Csur)</em>, vol. 51, no. 4, pp. 1–35, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
L. Bourtoule, V. Chandrasekaran, C. A. Choquette-Choo, H. Jia, A. Travers, B. Zhang, D. Lie, and N. Papernot, “Machine unlearning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">2021 IEEE Symposium on Security and Privacy (SP)</em>.   IEEE, 2021, pp. 141–159.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">2019 IEEE symposium on security and privacy (SP)</em>.   IEEE, 2019, pp. 739–753.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
L. Lyu and C. Chen, “A novel attribute reconstruction attack in federated learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">arXiv preprint arXiv:2108.06910</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
V. Tolpegin, S. Truex, M. E. Gursoy, and L. Liu, “Data poisoning attacks against federated learning systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib123.1.1">Computer Security–ESORICS 2020: 25th European Symposium on Research in Computer Security, ESORICS 2020, Guildford, UK, September 14–18, 2020, Proceedings, Part I 25</em>.   Springer, 2020, pp. 480–501.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
D. Byrd and A. Polychroniadou, “Differentially private secure multi-party computation for federated learning in financial applications,” in <em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">Proceedings of the First ACM International Conference on AI in Finance</em>, 2020, pp. 1–9.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
T. Hai, J. Zhou, S. Srividhya, S. K. Jain, P. Young, and S. Agrawal, “Bvflemr: an integrated federated learning and blockchain technology for cloud-based medical records recommendation system,” <em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">Journal of Cloud Computing</em>, vol. 11, no. 1, p. 22, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
J. Guo, Q. Zhao, G. Li, Y. Chen, C. Lao, and L. Feng, “Decentralized federated learning with privacy-preserving for recommendation systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">Enterprise Information Systems</em>, vol. 17, no. 9, p. 2193163, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
D. A. Van Dyk and X.-L. Meng, “The art of data augmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">Journal of Computational and Graphical Statistics</em>, vol. 10, no. 1, pp. 1–50, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
A. Mumuni and F. Mumuni, “Data augmentation: A comprehensive survey of modern approaches,” <em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">Array</em>, vol. 16, p. 100258, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
B. Chen, S. Chen, K. Li, Q. Xu, Y. Qiao, and Y. Wang, “Percept, chat, and then adapt: Multimodal knowledge transfer of foundation models for open-world video recognition,” <em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">arXiv preprint arXiv:2402.18951</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
A. Waqas, M. M. Bui, E. F. Glassy, I. El Naqa, P. Borkowski, A. A. Borkowski, and G. Rasool, “Revolutionizing digital pathology with the power of generative artificial intelligence and foundation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">Laboratory Investigation</em>, p. 100255, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
S. Rossi, M. Rossi, R. R. Mukkamala, J. B. Thatcher, and Y. K. Dwivedi, “Augmenting research methods with foundation models and generative ai,” p. 102749, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
K. Maharana, S. Mondal, and B. Nemade, “A review: Data pre-processing and data augmentation techniques,” <em class="ltx_emph ltx_font_italic" id="bib.bib132.1.1">Global Transitions Proceedings</em>, vol. 3, no. 1, pp. 91–99, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
M. Duan, D. Liu, X. Chen, R. Liu, Y. Tan, and L. Liang, “Self-balancing federated learning with global imbalanced data in mobile systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib133.1.1">IEEE Transactions on Parallel and Distributed Systems</em>, vol. 32, no. 1, pp. 59–71, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
L. Wang, S. Xu, X. Wang, and Q. Zhu, “Addressing class imbalance in federated learning,” in <em class="ltx_emph ltx_font_italic" id="bib.bib134.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol. 35, no. 11, 2021, pp. 10 165–10 173.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
S. Luo, Y. Xiao, Y. Liu, C. Li, and L. Song, “Towards communication efficient and fair federated personalized sequential recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib135.1.1">2022 5th International Conference on Information Communication and Signal Processing (ICICSP)</em>.   IEEE, 2022, pp. 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
H. Yin, B. Cui, J. Li, J. Yao, and C. Chen, “Challenging the long tail recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib136.1.1">arXiv preprint arXiv:1205.6700</em>, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
H. He and E. A. Garcia, “Learning from imbalanced data,” <em class="ltx_emph ltx_font_italic" id="bib.bib137.1.1">IEEE Transactions on knowledge and data engineering</em>, vol. 21, no. 9, pp. 1263–1284, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
Y. Lin, S. Han, H. Mao, Y. Wang, and W. J. Dally, “Deep gradient compression: Reducing the communication bandwidth for distributed training,” <em class="ltx_emph ltx_font_italic" id="bib.bib138.1.1">arXiv preprint arXiv:1712.01887</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
Y. Chen, X. Sun, and Y. Jin, “Communication-efficient federated deep learning with layerwise asynchronous model update and temporally weighted aggregation,” <em class="ltx_emph ltx_font_italic" id="bib.bib139.1.1">IEEE transactions on neural networks and learning systems</em>, vol. 31, no. 10, pp. 4229–4238, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
X. Zhu, S. Gong <em class="ltx_emph ltx_font_italic" id="bib.bib140.1.1">et al.</em>, “Knowledge distillation by on-the-fly native ensemble,” <em class="ltx_emph ltx_font_italic" id="bib.bib140.2.2">Advances in neural information processing systems</em>, vol. 31, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
D. Gao, X. Yao, and Q. Yang, “A survey on heterogeneous federated learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib141.1.1">arXiv preprint arXiv:2210.04505</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
Y. Tian, D. Krishnan, and P. Isola, “Contrastive representation distillation,” <em class="ltx_emph ltx_font_italic" id="bib.bib142.1.1">arXiv preprint arXiv:1910.10699</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
J. Zhang, S. Guo, X. Ma, H. Wang, W. Xu, and F. Wu, “Parameterized knowledge transfer for personalized federated learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib143.1.1">Advances in Neural Information Processing Systems</em>, vol. 34, pp. 10 092–10 104, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
L. Zhou, M. Wang, and N. Zhou, “Distributed federated learning-based deep learning model for privacy mri brain tumor detection,” <em class="ltx_emph ltx_font_italic" id="bib.bib144.1.1">arXiv preprint arXiv:2404.10026</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
D. Gunning, M. Stefik, J. Choi, T. Miller, S. Stumpf, and G.-Z. Yang, “Xai—explainable artificial intelligence,” <em class="ltx_emph ltx_font_italic" id="bib.bib145.1.1">Science robotics</em>, vol. 4, no. 37, p. eaay7120, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
A. K. Mohankumar, P. Nema, S. Narasimhan, M. M. Khapra, B. V. Srinivasan, and B. Ravindran, “Towards transparent and explainable attention models,” <em class="ltx_emph ltx_font_italic" id="bib.bib146.1.1">arXiv preprint arXiv:2004.14243</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
M. Carletti, C. Masiero, A. Beghi, and G. A. Susto, “Explainable machine learning in industry 4.0: Evaluating feature importance in anomaly detection to enable root cause analysis,” in <em class="ltx_emph ltx_font_italic" id="bib.bib147.1.1">2019 IEEE international conference on systems, man and cybernetics (SMC)</em>.   IEEE, 2019, pp. 21–26.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
J. Schneider, “Explainable generative ai (genxai): A survey, conceptualization, and research agenda,” <em class="ltx_emph ltx_font_italic" id="bib.bib148.1.1">arXiv preprint arXiv:2404.09554</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
C. Chronis, I. Varlamis, Y. Himeur, A. N. Sayed, T. M. Al-Hasan, A. Nhlabatsi, F. Bensaali, and G. Dimitrakopoulos, “A survey on the use of federated learning in privacy-preserving recommender systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib149.1.1">IEEE Open Journal of the Computer Society</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
S. Y. Feng, V. Gangal, J. Wei, S. Chandar, S. Vosoughi, T. Mitamura, and E. Hovy, “A survey of data augmentation approaches for nlp,” <em class="ltx_emph ltx_font_italic" id="bib.bib150.1.1">arXiv preprint arXiv:2105.03075</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
S. Yang, W. Xiao, M. Zhang, S. Guo, J. Zhao, and F. Shen, “Image data augmentation for deep learning: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib151.1.1">arXiv preprint arXiv:2204.08610</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
C. Yan, Y. Chen, and L. Zhou, “Differentiated fashion recommendation using knowledge graph and data augmentation,” <em class="ltx_emph ltx_font_italic" id="bib.bib152.1.1">Ieee Access</em>, vol. 7, pp. 102 239–102 248, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
J. Li, L. Qiu, B. Tang, D. Chen, D. Zhao, and R. Yan, “Insufficient data can also rock! learning to converse using smaller data with augmentation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib153.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol. 33, no. 01, 2019, pp. 6698–6705.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
A. I. Schein, A. Popescul, L. H. Ungar, and D. M. Pennock, “Methods and metrics for cold-start recommendations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib154.1.1">Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</em>, 2002, pp. 253–260.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
Y. Gong, X. Ding, Y. Su, K. Shen, Z. Liu, and G. Zhang, “An unified search and recommendation foundation model for cold-start scenario,” in <em class="ltx_emph ltx_font_italic" id="bib.bib155.1.1">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, 2023, pp. 4595–4601.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
J. Yu, Y. Dai, X. Liu, J. Huang, Y. Shen, K. Zhang, R. Zhou, E. Adhikarla, W. Ye, Y. Liu <em class="ltx_emph ltx_font_italic" id="bib.bib156.1.1">et al.</em>, “Unleashing the power of multi-task learning: A comprehensive survey spanning traditional, deep, and pretrained foundation model eras,” <em class="ltx_emph ltx_font_italic" id="bib.bib156.2.2">arXiv preprint arXiv:2404.18961</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
S. Geng, “Personalized foundation models for decision-making,” Ph.D. dissertation, Rutgers The State University of New Jersey, School of Graduate Studies, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
C. Huang, T. Yu, K. Xie, S. Zhang, L. Yao, and J. McAuley, “Foundation models for recommender systems: A survey and new perspectives,” <em class="ltx_emph ltx_font_italic" id="bib.bib158.1.1">arXiv preprint arXiv:2402.11143</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
Y. Wang, “Survey on deep multi-modal data analytics: Collaboration, rivalry, and fusion,” <em class="ltx_emph ltx_font_italic" id="bib.bib159.1.1">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</em>, vol. 17, no. 1s, pp. 1–25, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
Y. Huang, B. Cui, W. Zhang, J. Jiang, and Y. Xu, “Tencentrec: Real-time stream recommendation in practice,” in <em class="ltx_emph ltx_font_italic" id="bib.bib160.1.1">Proceedings of the 2015 ACM SIGMOD international conference on management of data</em>, 2015, pp. 227–238.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
S. Kang, D. Lee, W. Kweon, and H. Yu, “Personalized knowledge distillation for recommender system,” <em class="ltx_emph ltx_font_italic" id="bib.bib161.1.1">Knowledge-Based Systems</em>, vol. 239, p. 107958, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
J. Beel and V. Brunel, “Data pruning in recommender systems research: Best-practice or malpractice,” <em class="ltx_emph ltx_font_italic" id="bib.bib162.1.1">ACM RecSys</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
T. A. Syed and S. S. K. Nair, “Personalized recommendation system for advanced learning management systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib163.1.1">Proceedings of the 8th International Conference on Information Communication and Management</em>, 2018, pp. 90–95.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
T. Yu, O. J. Mengshoel, A. Jude, E. Feller, J. Forgeat, and N. Radia, “Incremental learning for matrix factorization in recommender systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib164.1.1">2016 IEEE International conference on big data (Big Data)</em>.   IEEE, 2016, pp. 1056–1063.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
Y. Chen, X. Li, J. Liu, and Z. Ying, “Recommendation system for adaptive learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib165.1.1">Applied psychological measurement</em>, vol. 42, no. 1, pp. 24–41, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
D. V. Hada and S. K. Shevade, “Rexplug: Explainable recommendation using plug-and-play language model,” in <em class="ltx_emph ltx_font_italic" id="bib.bib166.1.1">Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval</em>, 2021, pp. 81–91.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
S. Geng, Z. Fu, J. Tan, Y. Ge, G. De Melo, and Y. Zhang, “Path language modeling over knowledge graphsfor explainable recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib167.1.1">Proceedings of the ACM Web Conference 2022</em>, 2022, pp. 946–955.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib168">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
J. Liu, C. Liu, P. Zhou, R. Lv, K. Zhou, and Y. Zhang, “Is chatgpt a good recommender? a preliminary study,” <em class="ltx_emph ltx_font_italic" id="bib.bib168.1.1">arXiv preprint arXiv:2304.10149</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib169">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
M. Xu, W. Yin, D. Cai, R. Yi, D. Xu, Q. Wang, B. Wu, Y. Zhao, C. Yang, S. Wang <em class="ltx_emph ltx_font_italic" id="bib.bib169.1.1">et al.</em>, “A survey of resource-efficient llm and multimodal foundation models,” <em class="ltx_emph ltx_font_italic" id="bib.bib169.2.2">arXiv preprint arXiv:2401.08092</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib170">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
J. McAuley, C. Targett, Q. Shi, and A. Van Den Hengel, “Image-based recommendations on styles and substitutes,” in <em class="ltx_emph ltx_font_italic" id="bib.bib170.1.1">Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval</em>, 2015, pp. 43–52.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib171">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
R. He and J. McAuley, “Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering,” in <em class="ltx_emph ltx_font_italic" id="bib.bib171.1.1">proceedings of the 25th international conference on world wide web</em>, 2016, pp. 507–517.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib172">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
J. Ni, J. Li, and J. McAuley, “Justifying recommendations using distantly-labeled reviews and fine-grained aspects,” in <em class="ltx_emph ltx_font_italic" id="bib.bib172.1.1">Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)</em>, 2019, pp. 188–197.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib173">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
Y. Hou, J. Li, Z. He, A. Yan, X. Chen, and J. McAuley, “Bridging language and items for retrieval and recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib173.1.1">arXiv preprint arXiv:2403.03952</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib174">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
F. M. Harper and J. A. Konstan, “The movielens datasets: History and context,” <em class="ltx_emph ltx_font_italic" id="bib.bib174.1.1">Acm transactions on interactive intelligent systems (tiis)</em>, vol. 5, no. 4, pp. 1–19, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib175">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
C. Cai, R. He, and J. McAuley, “Spmc: Socially-aware personalized markov chains for sparse sequential recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib175.1.1">arXiv preprint arXiv:1708.04497</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib176">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
F. Wu, Y. Qiao, J.-H. Chen, C. Wu, T. Qi, J. Lian, D. Liu, X. Xie, J. Gao, W. Wu <em class="ltx_emph ltx_font_italic" id="bib.bib176.1.1">et al.</em>, “Mind: A large-scale dataset for news recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib176.2.2">Proceedings of the 58th annual meeting of the association for computational linguistics</em>, 2020, pp. 3597–3606.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib177">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
G. Yuan, F. Yuan, Y. Li, B. Kong, S. Li, L. Chen, M. Yang, C. Yu, B. Hu, Z. Li <em class="ltx_emph ltx_font_italic" id="bib.bib177.1.1">et al.</em>, “Tenrec: A large-scale multipurpose benchmark dataset for recommender systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib177.2.2">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 11 480–11 493, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib178">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
J. A. Gulla, L. Zhang, P. Liu, Ö. Özgöbek, and X. Su, “The adressa dataset for news recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib178.1.1">Proceedings of the international conference on web intelligence</em>, 2017, pp. 1042–1048.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib179">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
D. Yang, D. Zhang, V. W. Zheng, and Z. Yu, “Modeling user activity preference by leveraging user spatial temporal characteristics in lbsns,” <em class="ltx_emph ltx_font_italic" id="bib.bib179.1.1">IEEE Transactions on Systems, Man, and Cybernetics: Systems</em>, vol. 45, no. 1, pp. 129–142, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib180">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
E. Cho, S. A. Myers, and J. Leskovec, “Friendship and mobility: user movement in location-based social networks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib180.1.1">Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 2011, pp. 1082–1090.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib181">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
I. Cantador, P. Brusilovsky, and T. Kuflik, “2nd workshop on information heterogeneity and fusion in recommender systems (hetrec 2011),” in <em class="ltx_emph ltx_font_italic" id="bib.bib181.1.1">Proceedings of the 5th ACM conference on Recommender systems</em>, ser. RecSys 2011.   New York, NY, USA: ACM, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib182">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock">
X. Geng, H. Zhang, J. Bian, and T.-S. Chua, “Learning image and user features for recommendation in social networks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib182.1.1">Proceedings of the IEEE international conference on computer vision</em>, 2015, pp. 4274–4282.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib183">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock">
W.-C. Kang and J. McAuley, “Self-attentive sequential recommendation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib183.1.1">2018 IEEE international conference on data mining (ICDM)</em>.   IEEE, 2018, pp. 197–206.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib184">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock">
Tianchi, “Ijcai-16 brick-and-mortar store recommendation dataset,” 2018. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://tianchi.aliyun.com/dataset/dataDetail?dataId=53</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib185">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock">
G. Shani and A. Gunawardana, “Evaluating recommendation systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib185.1.1">Recommender systems handbook</em>, pp. 257–297, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib186">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock">
E. M. Voorhees, “The trec question answering track,” <em class="ltx_emph ltx_font_italic" id="bib.bib186.1.1">Natural Language Engineering</em>, vol. 7, no. 4, pp. 361–378, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib187">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock">
A. Flanagan, W. Oyomno, A. Grigorievskiy, K. E. Tan, S. A. Khan, and M. Ammad-Ud-Din, “Federated multi-view matrix factorization for personalized recommendations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib187.1.1">Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2020, Ghent, Belgium, September 14–18, 2020, Proceedings, Part II</em>.   Springer, 2021, pp. 324–347.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib188">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[188]</span>
<span class="ltx_bibblock">
X. He, T. Chen, M.-Y. Kan, and X. Chen, “Trirank: Review-aware explainable recommendation by modeling aspects,” in <em class="ltx_emph ltx_font_italic" id="bib.bib188.1.1">Proceedings of the 24th ACM international on conference on information and knowledge management</em>, 2015, pp. 1661–1670.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib189">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[189]</span>
<span class="ltx_bibblock">
J. Wu, Q. Liu, Z. Huang, Y. Ning, H. Wang, E. Chen, J. Yi, and B. Zhou, “Hierarchical personalized federated learning for user modeling,” in <em class="ltx_emph ltx_font_italic" id="bib.bib189.1.1">Proceedings of the Web Conference 2021</em>, 2021, pp. 957–968.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib190">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[190]</span>
<span class="ltx_bibblock">
J. Bian, J. Huang, S. Ji, Y. Liao, X. Li, Q. Wang, J. Zhou, D. Dou, Y. Wang, and H. Xiong, “Feynman: Federated learning-based advertising for ecosystems-oriented mobile apps recommendation,” <em class="ltx_emph ltx_font_italic" id="bib.bib190.1.1">IEEE Transactions on Services Computing</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib191">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[191]</span>
<span class="ltx_bibblock">
P. Castells, N. Hurley, and S. Vargas, “Novelty and diversity in recommender systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib191.1.1">Recommender systems handbook</em>.   Springer, 2021, pp. 603–646.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jun  4 03:06:42 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
