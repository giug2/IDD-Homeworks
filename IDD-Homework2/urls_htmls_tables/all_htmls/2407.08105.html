<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.08105] Federated Learning and AI Regulation in the European Union: Who is Responsible? – An Interdisciplinary Analysis</title><meta property="og:description" content="The European Union Artificial Intelligence Act mandates clear stakeholder responsibilities in developing and deploying machine learning applications to avoid substantial fines, prioritizing private and secure data proc…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning and AI Regulation in the European Union: Who is Responsible? – An Interdisciplinary Analysis">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning and AI Regulation in the European Union: Who is Responsible? – An Interdisciplinary Analysis">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.08105">

<!--Generated on Mon Aug  5 13:41:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated Learning,  Legal Analysis,  Regulatory Responsibility">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Federated Learning and AI Regulation in the European Union: 
<br class="ltx_break">Who is Responsible? – An Interdisciplinary Analysis</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Herbert Woisetschläger
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Simon Mertel
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Christoph Krönke
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ruben Mayer
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hans-Arno Jacobsen
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The European Union Artificial Intelligence Act mandates clear stakeholder responsibilities in developing and deploying machine learning applications to avoid substantial fines, prioritizing private and secure data processing with data remaining at its origin. Federated Learning (FL) enables the training of generative AI Models across data siloes, sharing only model parameters while improving data security.
Since FL is a cooperative learning paradigm, clients and servers naturally share legal responsibility in the FL pipeline.
Our work contributes to clarifying the roles of both parties, explains strategies for shifting responsibilities to the server operator, and points out open technical challenges that we must solve to improve FL’s practical applicability under the EU AI Act.</p>
</div>
<div class="ltx_keywords">Federated Learning, Legal Analysis, Regulatory Responsibility
</div>
<div id="p2" class="ltx_para">
<br class="ltx_break">
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the introduction of the European Union Artificial Intelligence Act (AI Act) <cite class="ltx_cite ltx_citemacro_citep">(Council of the European Union, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> and other international regulations being on the horizon, e.g., in the United States <cite class="ltx_cite ltx_citemacro_citep">(The White House, <a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite> and Canada <cite class="ltx_cite ltx_citemacro_citep">(House Of Commons of Canada, <a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite>, everyone concerned with the development and deployment of AI has to adapt to new game rules.
This entails data governance, robustness against adversarial scenarios, and energy considerations <cite class="ltx_cite ltx_citemacro_citep">(Woisetschläger et al., <a href="#bib.bib19" title="" class="ltx_ref">2024a</a>)</cite>.
The AI Act puts the <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">service provider</em> into the spotlight, who has to assume responsibility for model development and deployment within the meaning of Article 3.
Especially regarding data governance, the AI Act instantiates extensive rules for high-risk and general-purpose AI applications (GPAI, Article 52) that cater to data privacy and system security.
The majority of generative AI applications fall under the GPAI definition in Article 3.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Federated Learning (FL) presents a privacy-enhancing and data-protecting machine learning technique <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite> that has recently received increased attention for enabling access to data silos for generative AI applications <cite class="ltx_cite ltx_citemacro_citep">(Woisetschläger et al., <a href="#bib.bib20" title="" class="ltx_ref">2024b</a>)</cite>.
In FL, a server operator provides an ML model sent to several clients and then trained on the clients’ local data, which collaboratively train a global model via a central server, aggregating their local model updates.
Private and secure computing techniques like Differential Privacy or Trusted Execution Environments help improve data privacy and system security <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al., <a href="#bib.bib2" title="" class="ltx_ref">2017</a>; Andrew et al., <a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite>.
FL’s data locality removes the key challenge of monitoring data lineage and simplifies accounting for user consent.
Specifically, we study the FL workflow in alignment with related work <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib8" title="" class="ltx_ref">2020</a>; Hard et al., <a href="#bib.bib5" title="" class="ltx_ref">2018</a>; McMahan et al., <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite> to touch up on the following:</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Data Acquisition</span>.
The server operator can only employ a variety of client sampling strategies <cite class="ltx_cite ltx_citemacro_citep">(Malinovsky et al., <a href="#bib.bib11" title="" class="ltx_ref">2023</a>; Wang &amp; Ji, <a href="#bib.bib18" title="" class="ltx_ref">2022</a>; McMahan et al., <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite> for an FL training round, without the ability to directly investigate client data or process integrity.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Data Storage</span>. Similarly, the clients decide how, where, and when to store data.
This has implications on data availability, which directly touches upon the AI Act data governance requirements (Article 10)<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In the following, the term Article refers to articles in the AI Act if not specified otherwise</span></span></span>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">Data Preprocessing</span>. While the server operator can provide instructions on how to preprocess data so that the data is compatible with the ML model, the clients have the freedom to run additional preprocessing steps.
Since the server operator has no direct data access, verifying data integrity before training is challenging.
For FL applications, there are numerous approaches to improve data integrity <cite class="ltx_cite ltx_citemacro_citep">(Sánchez Sánchez et al., <a href="#bib.bib16" title="" class="ltx_ref">2024</a>; Roy Chowdhury et al., <a href="#bib.bib15" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">Model Aggregation</span>.
While acting as the FL training orchestrator, the server operator handles the model integrity control mechanism when aggregating model updates.
Thus, FL appears to be a well-suited solution to open up data silos and provide access to additional data.
This would significantly benefit the training or fine-tuning of generative models due to their sheer appetite for ever-increasing amounts of data <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib21" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">One can think that the server operator is automatically also the <em id="S1.p7.1.1" class="ltx_emph ltx_font_italic">service provider</em>.
Yet, FL is a cooperative ML training technique where a central entity typically provides the ML model, and clients can decide when to participate and what data to use for training.
As such, we see that the server (model) and the clients (data) control parts of the FL lifecycle, rendering them both legally responsible for their respective parts.
Thus, this opens up the question:</p>
<blockquote id="S1.p7.2" class="ltx_quote">
<p id="S1.p7.2.1" class="ltx_p"><span id="S1.p7.2.1.1" class="ltx_text ltx_font_italic">Who is the service provider at what point in the FL workflow, and how can each party assume adequate responsibility?</span></p>
</blockquote>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Our paper studies technical and legal requirements that need to be established so that the FL server operator can assume responsibility as a service provider. This requires future technical work on auditability, verifiability, integrity, and privacy.
Further, we need to establish regulatory references for the terms and services of FL applications.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Technical Solutions Need to Focus on Transferring Responsibility to the Server Operator</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">For practical FL applications,
the server operator must assume the role of the service provider by employing appropriate
technical solutions.</em></p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">When establishing an FL system that could potentially entail thousands of clients at a time, managing responsibilities is likely to become a key challenge. Thus, we require solutions that provide for auditability, verifiability, integrity, and privacy.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Auditability &amp; verifiability</span>.
There is a natural trade-off between privacy and data audits.
The core paradigm of FL is to not share data beyond a client’s area of control. Data is strictly inaccessible for everybody but the data owner, and even in-house restricted to authorized personnel.
Thus, we face a challenge when aiming to audit all steps that happen on a client device or data server.
For instance, a work by <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite> uses a Bayesian Nash equilibrium and a market mechanism to incentivize truthful client behavior, i.e., submission of useful model updates.
While this approach significantly reduces the risk of adversarial attacks, it does not meet the requirements for auditing in the context of the AI Act, which are well-defined.
Quintessentially, any data that is being captured, processed, and used in a training process must be evaluated for potential bias or adversarial information.
To achieve this, numerous works combining FL with blockchain technology explore auditing the data processing steps and the training itself <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a href="#bib.bib14" title="" class="ltx_ref">2021</a>; Ma et al., <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>.
What remains open is to develop solutions against data tampering.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Integrity &amp; privacy</span>.
Particularly, we have to rethink the obligations of the provider concerning data integrity and protection (Articles 8–10), such that responsibility is transferred to the FL server.
To account for the asymmetry of access and control-by-design in FL systems, we must develop data integrity measures that capture the nature of client data at the time of collection, while preprocessing the data, and immediately before starting the training process.
Peer-based verification schemes of model updates are a promising direction to identify adversarial clients <cite class="ltx_cite ltx_citemacro_citep">(Roy Chowdhury et al., <a href="#bib.bib15" title="" class="ltx_ref">2022</a>)</cite>.
Extending such schemes from client models to client data without infringing privacy would be interesting. At the same time, technical solutions must be in line with the requirements set out in the GDPR, which are not (necessarily) aligned with the concepts and rules of the AI Act.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Regulatory Implementations Need to Foster Integrity and Verifiability</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text ltx_font_italic">We need FL server operators to assume full responsibility; clients are technically and legally obligated to comply.</span></p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Service Provider.</span>
The GDPR <cite class="ltx_cite ltx_citemacro_citep">(Council of the European Union, <a href="#bib.bib3" title="" class="ltx_ref">2016</a>)</cite> defines the term <em id="S3.p2.1.2" class="ltx_emph ltx_font_italic">data controller</em>. Complementary, the AI Act defines the <em id="S3.p2.1.3" class="ltx_emph ltx_font_italic">service provider</em> of AI systems.
For data protection assessment when processing personal information at first, we need to clarify who is the data controller responsible and accountable for each distinct phase of the data processing and must demonstrate compliance with the requirements of the GDPR (Article 5). The AI Act does not have a differentiated allocation of roles for separate processing phases and focuses on one central “provider” of a (compliant) AI system, defined in Article 3, with the obligations arising from Article 8.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">While both the FL server and clients could be considered providers under the AI Act, since the AI Act (unlike the GDPR) focuses less on responsibilities for individual, definable data processing phases and more on secure system design as a whole, the provider concept has to be teleologically limited to the FL server.
Thus, the server acts as the fully responsible service provider under the AI Act (Article 8), especially concerning data governance (Article 10) and General-Purpose AI service (Article 52).</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">General Terms and Conditions for AI Systems.</span>
While in Article 4 of the GDPR, the controller is the person who, alone or jointly with others, decides on the purposes ("why") and means ("how") of the processing of personal data, the AI Act focuses on the (traditionally single and) central provider of an AI system.
However, since clients are autonomously in control of their data while the server is in control of the model, we see an inconsistency between what is controllable by the service provider and what he is responsible for.
To close this gap, we need a two-pronged approach – technical and legal ("how" &amp; "why").
Responsibility in FL should depend on the server’s physical, technical, and legal ability to influence decentralized model training and configuration.
This poses challenges. Unlike Article 26 and 28 GDPR, Article 8 et seq. of the AI Act do not provide details on governance in networked processing environments like FL systems.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">The data protection assessment of the FL lifecycle may be impacted if the FL server sets requirements for the clients, which may lead to the server being classified as the controller under the GDPR.
At first glance and from a strictly technical perspective, both the FL server and the FL clients fall under the provider concept of Article 3 GDPR, yet a “joint providership” (based on “joint controllership” under the GDPR, Article 26) does not exist under the AI Act.
In fulfillment of its obligations under the AI Act, in particular Article 10, the FL server can set far-reaching requirements for the FL clients concerning the training of models and handling of training data. These requirements could lead to the FL server being classified as a controller under data protection law within the means of Article 4 GDPR, while the FL client is classified as a mere processor within the scope of Article 28 GDPR.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">Thus, a key legal instrument for ensuring compliance with the AI Act and GDPR (Articles 26 &amp; 28) is likely the development of specific General Terms and Conditions binding for both FL server and clients. The server operator, as the service provider, has to oblige clients to provide sufficient reporting compliant with the AI Act. This can be supported by cryptographic tools that minimize the need for trust among entities <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Considerations on Major Federated Learning Architectures</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_italic">Cross-silo FL may allow for more flexibility in system design and responsibility distribution between clients and server than cross-device FL.</span></p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">While <a href="#S2" title="2 Technical Solutions Need to Focus on Transferring Responsibility to the Server Operator ‣ Federated Learning and AI Regulation in the European Union: Who is Responsible? – An Interdisciplinary Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S3" title="3 Regulatory Implementations Need to Foster Integrity and Verifiability ‣ Federated Learning and AI Regulation in the European Union: Who is Responsible? – An Interdisciplinary Analysis" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a> are generally applicable to any FL application, there are two major system architectures that create further opportunities to organize responsibilities: cross-silo and cross-device training.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Cross-Device Federated Learning</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Cross-device FL typically entails a large number of devices (<math id="S4.SS1.p1.1.m1.2" class="ltx_Math" alttext="&gt;1,000" display="inline"><semantics id="S4.SS1.p1.1.m1.2a"><mrow id="S4.SS1.p1.1.m1.2.3" xref="S4.SS1.p1.1.m1.2.3.cmml"><mi id="S4.SS1.p1.1.m1.2.3.2" xref="S4.SS1.p1.1.m1.2.3.2.cmml"></mi><mo id="S4.SS1.p1.1.m1.2.3.1" xref="S4.SS1.p1.1.m1.2.3.1.cmml">&gt;</mo><mrow id="S4.SS1.p1.1.m1.2.3.3.2" xref="S4.SS1.p1.1.m1.2.3.3.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">1</mn><mo id="S4.SS1.p1.1.m1.2.3.3.2.1" xref="S4.SS1.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="S4.SS1.p1.1.m1.2.2" xref="S4.SS1.p1.1.m1.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.2b"><apply id="S4.SS1.p1.1.m1.2.3.cmml" xref="S4.SS1.p1.1.m1.2.3"><gt id="S4.SS1.p1.1.m1.2.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.1"></gt><csymbol cd="latexml" id="S4.SS1.p1.1.m1.2.3.2.cmml" xref="S4.SS1.p1.1.m1.2.3.2">absent</csymbol><list id="S4.SS1.p1.1.m1.2.3.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.3.2"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">1</cn><cn type="integer" id="S4.SS1.p1.1.m1.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.2c">&gt;1,000</annotation></semantics></math>).
In such a setup, FL clients are characterized by having a very small number of local data samples and little participation time in the federated training process <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>.
This is a major challenge regarding client accountability and, ultimately, becomes problematic when a client should assume responsibility as a service provider.
Hence, for practical considerations, all responsibility has to be assumed by the server in the cross-device setting and there is practically no room for client-side responsibility and a strong need for tools and methods that allow the FL server to cover all compliance criteria.
This implies that the runtime environment on clients must be as encapsulated as possible, coupled with strict terms of service agreements.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Cross-Silo Federated Learning</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In contrast, in cross-silo settings, individual clients hold a significant amount of data and participate in multiple training rounds, and usually come with higher computational capabilities than in cross-device FL.
Typically, cross-silo FL can involve large institutions such as hospitals <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>, which themselves have a high commitment to regulatory compliance and take strong precautions regarding security and privacy protection.
As such, it is an open research direction to explore the synergies between established institutional processes (e.g., medical record keeping) and the AI Act requirements (e.g., on data transparency).
The terms and conditions must be balanced between ensuring appropriate regulatory compliance and practical utility such that clients are incentivized to participate in training, and we can assume partial responsibility on the side of clients.
Such synergies could help better balance the service provider responsibilities and reduce costs for clients and the server, not only improving the economic viability of FL but also its ecological footprint.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We study the FL life-cycle responsibilities under the AI Act.
We find client-side responsibility for numerous steps, which practically limits the applicability of FL to open up additional data silos that would benefit the training of foundation models.
Yet, there are promising directions that deserve increased attention such that a server operator can become the <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">service provider</em> without clients being required to assume extensive liability.
With this, one can drive the adoption of FL and help decrease data bias by directly relying on user data.
Further clarifying the outlined service provider question directly responds to the EU AI Office’s call for contributions to help implement the AI Act <cite class="ltx_cite ltx_citemacro_citep">(Nature, <a href="#bib.bib13" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work is partially funded by the Bavarian Ministry of Economic Affairs, Regional Development and Energy (Grant: DIK0446/01).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andrew et al. (2021)</span>
<span class="ltx_bibblock">
Andrew, G., Thakkar, O., McMahan, B., and Ramaswamy, S.

</span>
<span class="ltx_bibblock">Differentially private learning with adaptive clipping.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 34:17455–17466, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. (2017)</span>
<span class="ltx_bibblock">
Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H. B., Patel, S., Ramage, D., Segal, A., and Seth, K.

</span>
<span class="ltx_bibblock">Practical Secure Aggregation for Privacy-Preserving Machine Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</em>, CCS ’17. ACM, October 2017.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3133956.3133982</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1145/3133956.3133982" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1145/3133956.3133982</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Council of the European Union (2016)</span>
<span class="ltx_bibblock">
Council of the European Union.

</span>
<span class="ltx_bibblock">General data protection regulation (GDPR), apr 2016.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32016R0679" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32016R0679</a>.

</span>
<span class="ltx_bibblock">Document 32016R0679.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Council of the European Union (2021)</span>
<span class="ltx_bibblock">
Council of the European Union.

</span>
<span class="ltx_bibblock">Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL - LAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE (ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION LEGISLATIVE ACTS, apr 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206</a>.

</span>
<span class="ltx_bibblock">Document 52021PC0206.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. (2018)</span>
<span class="ltx_bibblock">
Hard, A., Kiddon, C. M., Ramage, D., Beaufays, F., Eichner, H., Rao, K., Mathews, R., and Augenstein, S.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/1811.03604" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1811.03604</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">House Of Commons of Canada (2022)</span>
<span class="ltx_bibblock">
House Of Commons of Canada.

</span>
<span class="ltx_bibblock">An Act to enact the Consumer Privacy Protection Act, the Personal Information and Data Protection Tribunal Act and the Artificial Intelligence and Data Act and to make consequential and related amendments to other Acts, 6 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.parl.ca/DocumentViewer/en/44-1/bill/C-27/first-reading" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.parl.ca/DocumentViewer/en/44-1/bill/C-27/first-reading</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2022)</span>
<span class="ltx_bibblock">
Huang, C., Huang, J., and Liu, X.

</span>
<span class="ltx_bibblock">Cross-silo federated learning: Challenges and opportunities, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2206.12949" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2206.12949</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Li, T., Sahu, A. K., Talwalkar, A., and Smith, V.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>, 37(3):50–60, May 2020.

</span>
<span class="ltx_bibblock">ISSN 1558-0792.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/msp.2020.2975749</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1109/MSP.2020.2975749" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1109/MSP.2020.2975749</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Liu, Y., Lou, R., and Wei, J.

</span>
<span class="ltx_bibblock">Auditing for federated learning: A model elicitation approach.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">The Fifth International Conference on Distributed Artificial Intelligence</em>, DAI ’23. ACM, November 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3627676.3627683</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1145/3627676.3627683" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1145/3627676.3627683</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2020)</span>
<span class="ltx_bibblock">
Ma, C., Li, J., Ding, M., Shi, L., Wang, T., Han, Z., and Poor, H. V.

</span>
<span class="ltx_bibblock">When federated learning meets blockchain: A new distributed learning paradigm, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2009.09338" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2009.09338</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malinovsky et al. (2023)</span>
<span class="ltx_bibblock">
Malinovsky, G., Horváth, S., Burlachenko, K. P., and Richtárik, P.

</span>
<span class="ltx_bibblock">Federated learning with regularized client participation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Federated Learning and Analytics in Practice: Algorithms, Systems, Applications, and Opportunities</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=6CDBpf7kNG" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=6CDBpf7kNG</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
McMahan, B., Moore, E., et al.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from Decentralized Data.

</span>
<span class="ltx_bibblock">In Singh, A. and Zhu, J. (eds.), <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</em>, volume 54 of <em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pp.  1273–1282. PMLR, 20–22 Apr 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v54/mcmahan17a.html</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nature (2024)</span>
<span class="ltx_bibblock">
Nature.

</span>
<span class="ltx_bibblock">There are holes in Europe’s AI Act — and researchers can help to fill them.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 625(7994):216–216, January 2024.

</span>
<span class="ltx_bibblock">ISSN 1476-4687.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/d41586-024-00029-4</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1038/d41586-024-00029-4" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1038/d41586-024-00029-4</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. (2021)</span>
<span class="ltx_bibblock">
Nguyen, D. C., Ding, M., Pham, Q.-V., Pathirana, P. N., Le, L. B., Seneviratne, A., Li, J., Niyato, D., and Poor, H. V.

</span>
<span class="ltx_bibblock">Federated learning meets blockchain in edge computing: Opportunities and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 8(16):12806–12825, August 2021.

</span>
<span class="ltx_bibblock">ISSN 2372-2541.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/jiot.2021.3072611</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1109/JIOT.2021.3072611" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1109/JIOT.2021.3072611</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy Chowdhury et al. (2022)</span>
<span class="ltx_bibblock">
Roy Chowdhury, A., Guo, C., Jha, S., and van der Maaten, L.

</span>
<span class="ltx_bibblock">Eiffel: Ensuring integrity for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</em>, CCS ’22. ACM, November 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3548606.3560611</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1145/3548606.3560611" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1145/3548606.3560611</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sánchez Sánchez et al. (2024)</span>
<span class="ltx_bibblock">
Sánchez Sánchez, P. M., Huertas Celdrán, A., Xie, N., Bovet, G., Martínez Pérez, G., and Stiller, B.

</span>
<span class="ltx_bibblock">Federatedtrust: A solution for trustworthy federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, 152:83–98, March 2024.

</span>
<span class="ltx_bibblock">ISSN 0167-739X.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1016/j.future.2023.10.013</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1016/j.future.2023.10.013" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1016/j.future.2023.10.013</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">The White House (2023)</span>
<span class="ltx_bibblock">
The White House.

</span>
<span class="ltx_bibblock">Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, 10 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang &amp; Ji (2022)</span>
<span class="ltx_bibblock">
Wang, S. and Ji, M.

</span>
<span class="ltx_bibblock">A unified analysis of federated learning with arbitrary client participation.

</span>
<span class="ltx_bibblock">In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=qSs7C7c4G8D" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=qSs7C7c4G8D</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Woisetschläger et al. (2024a)</span>
<span class="ltx_bibblock">
Woisetschläger, H., Erben, A., Marino, B., Wang, S., Lane, N. D., Mayer, R., and Jacobsen, H.-A.

</span>
<span class="ltx_bibblock">Federated learning priorities under the european union artificial intelligence act, 2024a.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2402.05968" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2402.05968</a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Woisetschläger et al. (2024b)</span>
<span class="ltx_bibblock">
Woisetschläger, H., Isenko, A., Wang, S., Mayer, R., and Jacobsen, H.-A.

</span>
<span class="ltx_bibblock">A survey on efficient federated learning methods for foundation model training, 2024b.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2401.04472" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2401.04472</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023)</span>
<span class="ltx_bibblock">
Zhou, C., Li, Q., Li, C., Yu, J., Liu, Y., Wang, G., Zhang, K., Ji, C., Yan, Q., He, L., Peng, H., Li, J., Wu, J., Liu, Z., Xie, P., Xiong, C., Pei, J., Yu, P. S., and Sun, L.

</span>
<span class="ltx_bibblock">A comprehensive survey on pretrained foundation models: A history from bert to chatgpt, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2302.09419" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2302.09419</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.08104" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.08105" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.08105">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.08105" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.08106" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 13:41:20 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
