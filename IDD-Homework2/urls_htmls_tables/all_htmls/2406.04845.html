<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.04845] FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models</title><meta property="og:description" content="Federated learning has enabled multiple parties to collaboratively train large language models without directly sharing their data (FedLLM).
Following this training paradigm, the community has put massive efforts from …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.04845">

<!--Generated on Fri Jul  5 23:06:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FedLLM-Bench: Realistic Benchmarks for 
<br class="ltx_break">Federated Learning of Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rui Ye<sup id="id9.9.id1" class="ltx_sup">1</sup><span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Equal contribution.
</span></span></span>     Rui Ge<sup id="id10.10.id2" class="ltx_sup">1</sup><span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Equal contribution.
</span></span></span>     Xinyu Zhu<sup id="id11.11.id3" class="ltx_sup">1</sup>    
<span id="id12.12.id4" class="ltx_text ltx_font_bold">Jingyi Chai<sup id="id12.12.id4.1" class="ltx_sup"><span id="id12.12.id4.1.1" class="ltx_text ltx_font_medium">1</span></sup></span>     <span id="id13.13.id5" class="ltx_text ltx_font_bold">Yaxin Du<sup id="id13.13.id5.1" class="ltx_sup"><span id="id13.13.id5.1.1" class="ltx_text ltx_font_medium">1</span></sup></span> 
<br class="ltx_break"><span id="id14.14.id6" class="ltx_text ltx_font_bold">Yang Liu<sup id="id14.14.id6.1" class="ltx_sup">2</sup></span>    
<span id="id15.15.id7" class="ltx_text ltx_font_bold">Yanfeng Wang<sup id="id15.15.id7.1" class="ltx_sup">3,1</sup></span>     <span id="id16.16.id8" class="ltx_text ltx_font_bold">Siheng Chen<sup id="id16.16.id8.1" class="ltx_sup">1,3</sup></span> 
<br class="ltx_break">
<br class="ltx_break"><sup id="id17.17.id9" class="ltx_sup">1</sup> Shanghai Jiao Tong University     <sup id="id18.18.id10" class="ltx_sup">2</sup> Tsinghua University     <sup id="id19.19.id11" class="ltx_sup">3</sup> Shanghai AI Laboratory 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id20.id1" class="ltx_p">Federated learning has enabled multiple parties to collaboratively train large language models without directly sharing their data (FedLLM).
Following this training paradigm, the community has put massive efforts from diverse aspects including framework, performance, and privacy.
However, an unpleasant fact is that there are currently no realistic datasets and benchmarks for FedLLM and previous works all rely on artificially constructed datasets, failing to capture properties in real-world scenarios.
Addressing this, we propose FedLLM-Bench, which involves 8 training methods, 4 training datasets, and 6 evaluation metrics, to offer a comprehensive testbed for the FedLLM community.
FedLLM-Bench encompasses three datasets (e.g., user-annotated multilingual dataset) for federated instruction tuning and one dataset (e.g., user-annotated preference dataset) for federated preference alignment, whose scale of client number ranges from 38 to 747.
Our datasets incorporate several representative diversities: language, quality, quantity, instruction, length, embedding, and preference, capturing properties in real-world scenarios.
Based on FedLLM-Bench, we conduct experiments on all datasets to benchmark existing FL methods and provide empirical insights (e.g., multilingual collaboration).
We believe that our FedLLM-Bench can benefit the FedLLM community by reducing required efforts, providing a practical testbed, and promoting fair comparisons.
Code and datasets are available at <a target="_blank" href="https://github.com/rui-ye/FedLLM-Bench" title="" class="ltx_ref ltx_href">https://github.com/rui-ye/FedLLM-Bench</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Large language models (LLMs) have achieved unprecedented success in diverse domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
These LLMs are usually trained by centralized learning paradigm, where various parties individually collect massive data for model training.
In this case, the data amount of each individual party is hard to scale due to the high cost of collecting and annotating data.
However, their data cannot be directly shared for collaboration due to property and privacy issues.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">To relieve the required cost of each party, federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> has emerged as a sound and off-the-shelf technique to facilitate collaboration, which leverages decentralized language data to collaboratively train LLMs in a privacy-preserving way (FedLLM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
To facilitate the development of FedLLM, there has been a series of code frameworks such as OpenFedLLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, FederatedScope-LLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, and FedML-LLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>; and many methods that tackle the issues of data quality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, intellectual property protection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, limited resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> in FedLLM.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Despite that massive efforts have been made, one significant concern remains: there is currently no realistic benchmark for FedLLM, making it hard to practically evaluate the effectiveness of FL methods in real-world scenarios.
In such context, each previous work constructs its own FL datasets by artificially partitioning existing centralized datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, falling short of capturing the natural properties existed in real-world cross-user datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
Even worse, these papers often follow different training and evaluation setups, which significantly increases the difficulty of re-implementations and risk of unfair comparisons <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">To fill this gap, we propose the first realistic benchmark for FedLLM termed FedLLM-Bench, offering a comprehensive testbed for the FedLLM community.
FedLLM-Bench encompasses three datasets for federated instruction tuning (including one user-annotated multilingual dataset: Fed-Aya, and two datasets with realistic user instructions: Fed-WildChat and Fed-ChatbotIT) and one dataset (user-annotated preference dataset: Fed-ChatbotPA) for federated preference alignment.
These datasets are all naturally split by real-world user ID with the scale ranging from 38 to 747 clients, therefore exhibiting realistic federated properties (especially for cross-device setup in FL where data are partitioned by user devices).
Specifically, datasets in our FedLLM-Bench inherit the following diversities (Table <a href="#S2.T1" title="Table 1 ‣ 2 Related work ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>):
<span id="S1.p4.1.1" class="ltx_text ltx_font_bold">(1) Language:</span> clients’ datasets (e.g., our Fed-Aya dataset) cover data from diverse languages, modeling the real-world scenarios of multilingual collaboration.
<span id="S1.p4.1.2" class="ltx_text ltx_font_bold">(2) Quality and Quantity:</span> the quality and quantity of clients’ datasets vary across each other, which is a common property in real-world applications.
<span id="S1.p4.1.3" class="ltx_text ltx_font_bold">(3) Length:</span> the sequence length of clients’ data could be quite different, representing a new type of data heterogeneity in FL.
<span id="S1.p4.1.4" class="ltx_text ltx_font_bold">(4) Preference:</span> different clients have different preferences as verified by different preferred instructions in instruction tuning datasets (e.g., Fed-WildChat) and different preferred responses in preference alignment dataset (i.e., Fed-ChatbotPA), mirroring the complexities of real-world data scenarios.
These diversities make our FedLLM-Bench a comprehensive benchmark in the era of FedLLM, serving as a great successor to representative benchmarks for classical tasks such as LEAF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> benchmark.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">Based on these datasets, we implement 8 representative baseline methods and 6 evaluation metrics, and conduct extensive experiments.
Our experiments mainly demonstrate (1) that federated learning can consistently bring performance gain compared to local training without collaboration; and (2) the performance ranking of several representative baseline methods.
Besides serving as a benchmark for performance comparison, our FedLLM-Bench can also support exploration of new research directions thanks to its flexibility and diversity.
As an example, we conduct an exploratory experiment based on the multilingual dataset Fed-Aya, showing that collaboration among similar languages could potentially bring more benefits comparing to collaboration among all languages.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p">Our contributions are as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose the first realistic FedLLM benchmark, FedLLM-Bench, which encompasses four naturally split datasets. FedLLM-Bench covers diverse tasks, scales, languages, qualities, quantities, lengths, and preferences, mirroring the complexities and diversities of real-world scenarios.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We integrate these datasets into a codebase with 8 representative baseline methods and 6 evaluation metrics, and open-source the datasets with the integrated codebase for the community.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i3.p1.1" class="ltx_p">We conduct extensive experiments to demonstrate the status of several existing baseline methods on our FedLLM-Bench and show its potential in promoting exploration of new research directions.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Federated learning for large language models.</span>
Federated learning is a privacy-preserving and collaborative training paradigm that enables multiple parties to collaboratively train a shared global model without sharing their raw data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
Data heterogeneity is one of the most representative challenges in FL, where clients’ datasets are drawn from different distributions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
Addressing this, numerous methods have been proposed by regularization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, gradient correction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, feature alignment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, adjustment of aggregation weights <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, introducing momentum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, or leveraging pre-trained models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">Recently, having witnessed the success of large language models (LLMs) in centralized learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, many researchers start to explore training LLMs via federated learning, mitigating the issue of the shortage of public data or private data of one individual <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Within one year, there have been many frameworks such as OpenFedLLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, FederatedScope-LLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, FedML-LLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, and diverse methods such as FedbiOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> that protects model property and FFA-LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> that improves performance under differential privacy.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">However, one significant issue of these previous works is that their experiments are all based on artificially crafted FL datasets, falling short of extrapolating their effectiveness in real-world scenarios.
Addressing this, we propose the first realistic benchmark for FedLLM, FedLLM-Bench, which mirrors the complexities and diversities in real-world applications.
Besides, we implement 8 representative baseline methods in our FedLLM-Bench to demonstrate their effectiveness in realistic scenarios.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Summary of our four realistic FedLLM datasets. IT denotes instruction tuning and PA denotes preference alignment. # denotes ‘the number of’ and L. denotes ‘the length of’. Our datasets exhibit diversities in characteristic, task, client number, quantity, length, and quality.</figcaption>
<table id="S2.T1.16" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T1.16.17" class="ltx_tr" style="background-color:#F2F2FF;">
<td id="S2.T1.16.17.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.17.1.1" class="ltx_text" style="background-color:#F2F2FF;">Dataset Name</span></td>
<td id="S2.T1.16.17.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.17.2.1" class="ltx_text" style="background-color:#F2F2FF;">Fed-Aya <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite></span></td>
<td id="S2.T1.16.17.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.17.3.1" class="ltx_text" style="background-color:#F2F2FF;">Fed-ChatbotIT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></span></td>
<td id="S2.T1.16.17.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.17.4.1" class="ltx_text" style="background-color:#F2F2FF;">Fed-WildChat <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite></span></td>
<td id="S2.T1.16.17.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.17.5.1" class="ltx_text" style="background-color:#F2F2FF;">Fed-ChatbotPA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></span></td>
</tr>
<tr id="S2.T1.16.18" class="ltx_tr" style="background-color:#EBEBFF;">
<td id="S2.T1.16.18.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.18.1.1" class="ltx_text" style="background-color:#EBEBFF;">Characteristic</span></td>
<td id="S2.T1.16.18.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.18.2.1" class="ltx_text" style="background-color:#EBEBFF;">Multilingual</span></td>
<td id="S2.T1.16.18.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.18.3.1" class="ltx_text" style="background-color:#EBEBFF;">Single-Turn chat</span></td>
<td id="S2.T1.16.18.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.18.4.1" class="ltx_text" style="background-color:#EBEBFF;">Multi-Turn chat</span></td>
<td id="S2.T1.16.18.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.18.5.1" class="ltx_text" style="background-color:#EBEBFF;">Preference</span></td>
</tr>
<tr id="S2.T1.16.19" class="ltx_tr" style="background-color:#EBEBFF;">
<td id="S2.T1.16.19.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.19.1.1" class="ltx_text" style="background-color:#EBEBFF;">Applied Task</span></td>
<td id="S2.T1.16.19.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.19.2.1" class="ltx_text" style="background-color:#EBEBFF;">IT</span></td>
<td id="S2.T1.16.19.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.19.3.1" class="ltx_text" style="background-color:#EBEBFF;">IT</span></td>
<td id="S2.T1.16.19.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.19.4.1" class="ltx_text" style="background-color:#EBEBFF;">IT</span></td>
<td id="S2.T1.16.19.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.19.5.1" class="ltx_text" style="background-color:#EBEBFF;">PA</span></td>
</tr>
<tr id="S2.T1.16.20" class="ltx_tr" style="background-color:#F2F2F2;">
<td id="S2.T1.16.20.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.20.1.1" class="ltx_text" style="background-color:#F2F2F2;"># Clients (Total)</span></td>
<td id="S2.T1.16.20.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.20.2.1" class="ltx_text" style="background-color:#F2F2F2;">38</span></td>
<td id="S2.T1.16.20.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.20.3.1" class="ltx_text" style="background-color:#F2F2F2;">237</span></td>
<td id="S2.T1.16.20.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.20.4.1" class="ltx_text" style="background-color:#F2F2F2;">100</span></td>
<td id="S2.T1.16.20.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.20.5.1" class="ltx_text" style="background-color:#F2F2F2;">747</span></td>
</tr>
<tr id="S2.T1.16.21" class="ltx_tr" style="background-color:#F2F2F2;">
<td id="S2.T1.16.21.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.21.1.1" class="ltx_text" style="background-color:#F2F2F2;"># Samples (Total)</span></td>
<td id="S2.T1.16.21.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.21.2.1" class="ltx_text" style="background-color:#F2F2F2;">25,513</span></td>
<td id="S2.T1.16.21.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.21.3.1" class="ltx_text" style="background-color:#F2F2F2;">6,166</span></td>
<td id="S2.T1.16.21.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.21.4.1" class="ltx_text" style="background-color:#F2F2F2;">52,703</span></td>
<td id="S2.T1.16.21.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.21.5.1" class="ltx_text" style="background-color:#F2F2F2;">9,508</span></td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S2.T1.4.4.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.4.4.5.1" class="ltx_text" style="background-color:#ECECEC;"># Samples (Client)</span></td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.1.1.1.1" class="ltx_text" style="background-color:#ECECEC;">671 <math id="S2.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.1.1.1.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 815</span></td>
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.2.2.2.1" class="ltx_text" style="background-color:#ECECEC;">26 <math id="S2.T1.2.2.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.2.2.2.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.2.2.2.1.m1.1.1" xref="S2.T1.2.2.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.1.m1.1b"><csymbol cd="latexml" id="S2.T1.2.2.2.1.m1.1.1.cmml" xref="S2.T1.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.1.m1.1c">\pm</annotation></semantics></math> 33</span></td>
<td id="S2.T1.3.3.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.3.3.3.1" class="ltx_text" style="background-color:#ECECEC;">527 <math id="S2.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.3.3.3.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.3.3.3.1.m1.1.1" xref="S2.T1.3.3.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.3.1.m1.1b"><csymbol cd="latexml" id="S2.T1.3.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.3.1.m1.1c">\pm</annotation></semantics></math> 477</span></td>
<td id="S2.T1.4.4.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.4.4.4.1" class="ltx_text" style="background-color:#ECECEC;">13 <math id="S2.T1.4.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.4.4.4.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.4.4.4.1.m1.1.1" xref="S2.T1.4.4.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.4.1.m1.1b"><csymbol cd="latexml" id="S2.T1.4.4.4.1.m1.1.1.cmml" xref="S2.T1.4.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.4.1.m1.1c">\pm</annotation></semantics></math> 21</span></td>
</tr>
<tr id="S2.T1.8.8" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S2.T1.8.8.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.8.8.5.1" class="ltx_text" style="background-color:#ECECEC;">L. Instruction (Client)</span></td>
<td id="S2.T1.5.5.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.5.5.1.1" class="ltx_text" style="background-color:#ECECEC;">116 <math id="S2.T1.5.5.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.5.5.1.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.5.5.1.1.m1.1.1" xref="S2.T1.5.5.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.5.5.1.1.m1.1.1.cmml" xref="S2.T1.5.5.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.1.1.m1.1c">\pm</annotation></semantics></math> 199</span></td>
<td id="S2.T1.6.6.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.6.6.2.1" class="ltx_text" style="background-color:#ECECEC;">68 <math id="S2.T1.6.6.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.6.6.2.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.6.6.2.1.m1.1.1" xref="S2.T1.6.6.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.2.1.m1.1b"><csymbol cd="latexml" id="S2.T1.6.6.2.1.m1.1.1.cmml" xref="S2.T1.6.6.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.2.1.m1.1c">\pm</annotation></semantics></math> 119</span></td>
<td id="S2.T1.7.7.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.7.7.3.1" class="ltx_text" style="background-color:#ECECEC;">331 <math id="S2.T1.7.7.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.7.7.3.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.7.7.3.1.m1.1.1" xref="S2.T1.7.7.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.3.1.m1.1b"><csymbol cd="latexml" id="S2.T1.7.7.3.1.m1.1.1.cmml" xref="S2.T1.7.7.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.3.1.m1.1c">\pm</annotation></semantics></math> 435</span></td>
<td id="S2.T1.8.8.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.8.8.4.1" class="ltx_text" style="background-color:#ECECEC;">69 <math id="S2.T1.8.8.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.8.8.4.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.8.8.4.1.m1.1.1" xref="S2.T1.8.8.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.4.1.m1.1b"><csymbol cd="latexml" id="S2.T1.8.8.4.1.m1.1.1.cmml" xref="S2.T1.8.8.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.4.1.m1.1c">\pm</annotation></semantics></math> 124</span></td>
</tr>
<tr id="S2.T1.12.12" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S2.T1.12.12.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.12.12.5.1" class="ltx_text" style="background-color:#ECECEC;">L. Response (Client)</span></td>
<td id="S2.T1.9.9.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.9.9.1.1" class="ltx_text" style="background-color:#ECECEC;">225 <math id="S2.T1.9.9.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.9.9.1.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.9.9.1.1.m1.1.1" xref="S2.T1.9.9.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.9.9.1.1.m1.1.1.cmml" xref="S2.T1.9.9.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.1.1.m1.1c">\pm</annotation></semantics></math> 411</span></td>
<td id="S2.T1.10.10.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.10.10.2.1" class="ltx_text" style="background-color:#ECECEC;">211 <math id="S2.T1.10.10.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.10.10.2.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.10.10.2.1.m1.1.1" xref="S2.T1.10.10.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.2.1.m1.1b"><csymbol cd="latexml" id="S2.T1.10.10.2.1.m1.1.1.cmml" xref="S2.T1.10.10.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.2.1.m1.1c">\pm</annotation></semantics></math> 176</span></td>
<td id="S2.T1.11.11.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.11.11.3.1" class="ltx_text" style="background-color:#ECECEC;">506 <math id="S2.T1.11.11.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.11.11.3.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.11.11.3.1.m1.1.1" xref="S2.T1.11.11.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.3.1.m1.1b"><csymbol cd="latexml" id="S2.T1.11.11.3.1.m1.1.1.cmml" xref="S2.T1.11.11.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.3.1.m1.1c">\pm</annotation></semantics></math> 470</span></td>
<td id="S2.T1.12.12.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.12.12.4.1" class="ltx_text" style="background-color:#ECECEC;">218 <math id="S2.T1.12.12.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.12.12.4.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.12.12.4.1.m1.1.1" xref="S2.T1.12.12.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.4.1.m1.1b"><csymbol cd="latexml" id="S2.T1.12.12.4.1.m1.1.1.cmml" xref="S2.T1.12.12.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.4.1.m1.1c">\pm</annotation></semantics></math> 178</span></td>
</tr>
<tr id="S2.T1.16.16" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S2.T1.16.16.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.16.5.1" class="ltx_text" style="background-color:#ECECEC;">Data Quality (Client)</span></td>
<td id="S2.T1.13.13.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.13.13.1.1" class="ltx_text" style="background-color:#ECECEC;">0.63 <math id="S2.T1.13.13.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.13.13.1.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.13.13.1.1.m1.1.1" xref="S2.T1.13.13.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.13.13.1.1.m1.1.1.cmml" xref="S2.T1.13.13.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.1.1.m1.1c">\pm</annotation></semantics></math> 0.28</span></td>
<td id="S2.T1.14.14.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.14.14.2.1" class="ltx_text" style="background-color:#ECECEC;">0.67 <math id="S2.T1.14.14.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.14.14.2.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.14.14.2.1.m1.1.1" xref="S2.T1.14.14.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.14.2.1.m1.1b"><csymbol cd="latexml" id="S2.T1.14.14.2.1.m1.1.1.cmml" xref="S2.T1.14.14.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.14.2.1.m1.1c">\pm</annotation></semantics></math> 0.22</span></td>
<td id="S2.T1.15.15.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.15.15.3.1" class="ltx_text" style="background-color:#ECECEC;">0.79 <math id="S2.T1.15.15.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.15.15.3.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.15.15.3.1.m1.1.1" xref="S2.T1.15.15.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.15.15.3.1.m1.1b"><csymbol cd="latexml" id="S2.T1.15.15.3.1.m1.1.1.cmml" xref="S2.T1.15.15.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.15.3.1.m1.1c">\pm</annotation></semantics></math> 0.37</span></td>
<td id="S2.T1.16.16.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:5.0pt;padding-right:5.0pt;"><span id="S2.T1.16.16.4.1" class="ltx_text" style="background-color:#ECECEC;">0.68 <math id="S2.T1.16.16.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.16.16.4.1.m1.1a"><mo mathbackground="#ECECEC" id="S2.T1.16.16.4.1.m1.1.1" xref="S2.T1.16.16.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.16.16.4.1.m1.1b"><csymbol cd="latexml" id="S2.T1.16.16.4.1.m1.1.1.cmml" xref="S2.T1.16.16.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.16.4.1.m1.1c">\pm</annotation></semantics></math> 0.21</span></td>
</tr>
</table>
</figure>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Datasets and benchmarks in federated learning.</span>
Since clients’ data are collected independently without coordination, the issue of data heterogeneity commonly exists in FL.
A large proportion of FL works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> simulate data heterogeneity by artificially partitioning classic datasets such as CIFAR-10/100 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, Fashion-MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, and MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.
Addressing this, several realistic benchmarks are proposed for classic tasks such as image and text classification, which include LEAF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> (a suite of user-split datasets), FLAIR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> (multi-label image classification), and FLamby <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> (a benchmark for medical analysis).
However, currently, there is no realistic dataset or benchmark for the tasks of FedLLM, while our FedLLM-Bench stands out as the first one in the literature.
Besides, our FedLLM-Bench covers two unique tasks compared to previous benchmarks: federated instruction tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and federated preference alignment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>FedLLM-Bench: a realistic benchmark for FedLLM</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">Here, we introduce our FedLLM-Bench, from four perspectives: training methods, descriptions of training datasets, analysis of training datasets, and evaluation metrics.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Training methods</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold">FedLLM overview.</span>
FedLLM involves four iterative steps: server-to-client model downloading, local model training, client-to-server model uploading, and global model aggregation.
During FedLLM, clients could collaborate on two critical tasks for LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>: instruction tuning and preference alignment, which are challenging for individuals due to high cost of data collection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.
Besides, various FL baseline methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> can be incorporated into FedLLM.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Tasks: instruction tuning &amp; preference alignment.</span>
In instruction tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, each data sample is an instruction-response pair, where the LLMs are trained to follow instructions to generate the expected responses via supervised fine-tuning.
In preference alignment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, each data sample consists of an instruction, a preferred and a dispreferred response, where the LLMs are trained to align with the preferred response given user instructions via direct preference optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.
For both two tasks, we adopt the most commonly used parameter-efficient fine-tuning technique LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, reducing the requirements of computation and communication in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">FL: baseline methods.</span>
In our FedLLM-Bench, we implement 8 representative baseline methods, including local training without collaboration and 7 classical FL baseline methods.
Following the standard baseline FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, at the local training part, we implement FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> which applies local-global model regularization and SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> which introduces control variate to correct local gradients; while at the model aggregation part, we implement FedAvgM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, FedAdagrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, FedYogi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, and FedAdam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> which introduce model momentum to update global model.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Descriptions of training datasets</h3>

<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/x1.png" id="S3.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="97" height="97" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Language (Fed-Aya)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/x2.png" id="S3.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="109" height="85" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Length Distribution</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/x3.png" id="S3.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="108" height="85" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Length Preference</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/x4.png" id="S3.F1.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="108" height="85" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Quality Preference</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>(a) Langauge distribution of clients in Fed-Aya dataset. (b) The distribution of length of instruction and response of clients’ data. (c) Distribution of length preference (the ratio of a user preferring longer response) of clients in Fed-ChatbotPA dataset. (d) Distribution of quality preference (quality difference between preferred and dispreferred data) of clients in Fed-ChatbotPA dataset.</figcaption>
</figure>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/Aya_heatmap.png" id="S3.F2.sf1.g1" class="ltx_graphics ltx_img_square" width="138" height="135" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Fed-Aya</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/Chatbot_heatmap.png" id="S3.F2.sf2.g1" class="ltx_graphics ltx_img_square" width="138" height="133" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Fed-ChatbotIT</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/WildChat_heatmap.png" id="S3.F2.sf3.g1" class="ltx_graphics ltx_img_square" width="138" height="131" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Fed-WildChat</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/Chatbot-dpo_heatmap.png" id="S3.F2.sf4.g1" class="ltx_graphics ltx_img_square" width="138" height="133" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Fed-ChatbotPA</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distributions of top 10 verbs in instructions (10 clients are plotted for illustration). Our realistic FedLLM datasets exhibit diverse patterns with respect to instruction types.</figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F3.sf1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x5.png" id="S3.F3.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="71" height="56" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Fed-Aya</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F3.sf2.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x6.png" id="S3.F3.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="71" height="56" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Fed-ChatbotIT</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F3.sf3.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x7.png" id="S3.F3.sf3.1.g1" class="ltx_graphics ltx_img_landscape" width="70" height="56" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Fed-WildChat</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F3.sf4.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x8.png" id="S3.F3.sf4.1.g1" class="ltx_graphics ltx_img_landscape" width="71" height="56" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Fed-ChatbotPA</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The dataset quality distribution of clients in four training datasets: Fed-Aya, Fed-WildChat,
Fed-ChatbotIT and Fed-ChatbotPA.
We average the IFD scores of all instruction-response pairs of each client to represent the client’s dataset quality.
</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F4.sf1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x9.png" id="S3.F4.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="658" height="492" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Fed-Aya</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F4.sf2.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x10.png" id="S3.F4.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="70" height="52" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Fed-ChatbotIT</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F4.sf3.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x11.png" id="S3.F4.sf3.1.g1" class="ltx_graphics ltx_img_landscape" width="70" height="52" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Fed-WildChat</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F4.sf4.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:91.0pt;">
<img src="/html/2406.04845/assets/x12.png" id="S3.F4.sf4.1.g1" class="ltx_graphics ltx_img_landscape" width="658" height="492" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Fed-ChatbotPA</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The t-SNE visualization of embeddings of instruction-response pairs from 10 clients in Fed-Aya, Fed-ChatbotIT, Fed-WildChat, and Fed-ChatbotPA datasets. Each color denotes one client. We can see clustering phenomenon of one client’s data and that clients’ data are diverse.
</figcaption>
</figure>
<figure id="S3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/aya_num_samples.png" id="S3.F5.sf1.g1" class="ltx_graphics ltx_img_square" width="142" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Fed-Aya</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/chatbotit_num_samples.png" id="S3.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="142" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Fed-ChatbotIT</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/wildchat_num_samples.png" id="S3.F5.sf3.g1" class="ltx_graphics ltx_img_landscape" width="142" height="112" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Fed-WildChat</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/chatbotpa_num_samples.png" id="S3.F5.sf4.g1" class="ltx_graphics ltx_img_landscape" width="142" height="112" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Fed-ChatbotPA</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Data quantity distribution across clients of our four FedLLM datasets. We can see a variety of data quantities of clients, where a large proportion of clients have relatively few data.</figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">Fed-Aya.</span>
Aya <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> dataset is a multilingual instruction tuning dataset annotated by contributors from various countries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.
We select 6 high-resource languages: English (en), Spanish (es), French (fr), Russian (ru), Portuguese (pt), Chinese (zh), and 2 low-resource languages: Standard Arabic (ar) and Telugu (te).
According to the annotator ID, we filter out those who contribute less than 100 annotations, and construct Fed-Aya, which consists of 38 clients with 25k data samples in total.
This dataset models a real-world federated scenario <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> where collaborating clients are distributed around the globe and aim to advance multilingual LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>.
We visualize the language distribution of Fed-Aya dataset in Figure <a href="#S3.F1.sf1" title="In Figure 1 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>, showing that the number of clients for different languages varies.
Therefore, it also provides a dataset basis for the explorations of new research topics in FedLLM, including language personalization and fairness across high- and low-resource languages.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Fed-ChatbotIT.</span>
Chatbot-Arena-Conversations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> is originally a collection of human-annotated preference data, where each data sample consists of a user instruction, a user-chosen response and a user-rejected response.
Here, for each data sample, we combine the instruction and user-chosen response as an instruction-response pair.
Subsequently, according to the user ID of the annotator, we filter out those who contribute less than 10 data samples and construct Fed-ChatbotIT, which consists of 237 clients with 6k data samples in total.
This dataset captures the diversities of realistic use cases in single-turn query of LLMs, where instructions of different users could hold different patterns.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Fed-WildChat.</span>
WildChat <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> is a collection of conversations between humans and ChatGPT, which contains a broad spectrum of user-chatbot interactions.
According to the IP address, we partition the whole dataset into several user datasets and filter out those with less than 200 samples, forming our Fed-WildChat.
Fed-WildChat consists of 100 clients with 53k data samples in total.
This dataset represents real-world use cases between humans and chatbots, which involve multi-turn interactions.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Fed-ChatbotPA.</span>
We construct another federated version of Chatbot-Arena-Conversations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> for preference alignment tasks: Fed-ChatbotPA.
Specifically, we filter out users who contribute fewer than 5 preference pairs and the resulting Fed-ChatbotPA consists of 747 clients with 10k data samples in total.
Each data sample contains a user instruction, a preferred and dispreferred response.
This dataset exhibits real-world property that different individuals could have different preferences.
To verify this, we analyze the dataset from two perspectives.
Firstly, we visualize the length preferences of clients in Figure <a href="#S3.F1.sf3" title="In Figure 1 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(c)</span></a>, where for each client we compute the ratio of the preferred responses being longer than the dispreferred responses.
We see that most clients tend to prefer longer responses (i.e., the ratio is larger than 0.5) and clients have various preference ratios.
Secondly, we visualize clients’ quality preferences in Figure <a href="#S3.F1.sf4" title="In Figure 1 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a>, where for each client we compute the averaged quality difference between the preferred and dispreferred data.
We can see the diversity of clients’ quality preferences.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Analysis of training datasets</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">We further show the diversities of our datasets for FedLLM from four perspectives.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">(1) Length.</span> For each client, we tokenize the instruction and response of each data sample using tokenizer of Llama2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, and average their length respectively for each client.
We plot the length distribution of clients in Figure <a href="#S3.F1.sf2" title="In Figure 1 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>.
We can see that clients’ data varies in data length and different datasets exhibit different distributions, verifying both inter-dataset and intra-dataset diversities.
<span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_bold">(2) Instruction.</span>
Following Self-Instruct <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, we use the Berkeley Neural Parser <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> to parse the instructions and extract the root verbs.
We randomly sample 10 clients for each dataset and visualize the distribution of top-10 verbs in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We can see that clients have different usage preferences in their instructions and that the top 10 verbs vary among datasets.
Please refer to more detailed visualizations in Figure <a href="#A2.F7" title="Figure 7 ‣ B.2 Verbs and nouns ‣ Appendix B Datasets ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, <a href="#A4.F9" title="Figure 9 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, <a href="#A4.F10" title="Figure 10 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, <a href="#A4.F11" title="Figure 11 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, <a href="#A4.F12" title="Figure 12 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>.
<span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_bold">(3) Quality.</span>
We measure the data quality using IFD metric <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, where a higher value denotes higher instruction-following difficulty, and average the quality of all data samples of one client.
From Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we can observe the diversities in clients’ data, and distinct distributions among these four datasets.
<span id="S3.SS3.p2.1.4" class="ltx_text ltx_font_bold">(4) Embedding.</span>
We randomly sample 10 clients, extract the embedding of each instruction-response data sample using text-embedding-ada-002 model from OpenAI, and plot them via t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> in Figure <a href="#S3.F4" title="Figure 4 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, where each color denotes one client.
We can see that there is clustering phenomenon, indicating certain patterns within one client’s data that mirror real-world cases.
It also demonstrates the diversity of clients’ data since dots with different colors are located at different regions.
<span id="S3.SS3.p2.1.5" class="ltx_text ltx_font_bold">(5) Quantity.</span>
We plot clients’ data quantity distribution in Figure <a href="#S3.F5" title="Figure 5 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
From the figure, we see a variety of data quantity across clients for all datasets.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.1" class="ltx_p">These analysis evidently reveals the diversities among clients’ datasets, making our datasets appropriate candidates for the FedLLM community since they can mirror the complexities in real-world scenarios.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation metrics</h3>

<div id="S3.SS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS4.p1.1" class="ltx_p">To evaluate the effectiveness of the training methods on our realistic FL datasets, we consider 6 evaluation metrics, including 4 open-ended metrics and 2 close-ended metrics.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para ltx_noindent">
<p id="S3.SS4.p2.1" class="ltx_p"><span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_bold">Open-ended evaluation.</span>
MT-Bench <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> is one of the most acknowledged evaluation metrics in the era of LLMs, which evaluates both one-turn and two-turn conversation capability.
Similarly, Vicuna bench <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> evaluates one-turn instruction-following capability.
AdvBench <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> evaluates the safety rate given unsafe instructions.
Additionally, we consider an in-domain evaluation metric termed Ref-GPT4, where we randomly sample 50 unseen data as the test set and use GPT-4 to rate the generated response given the ground-truth response as reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>; see prompt in Figure <a href="#A3.F8" title="Figure 8 ‣ C.2 Evaluation ‣ Appendix C Experiments ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para ltx_noindent">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_bold">Close-ended evaluation.</span>
We consider two common close-ended evaluations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>: MMLU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> (measuring knowledge of 57 subjects) and HumanEval <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> (measuring capability of generating programs from docstrings).
We evaluate these two metrics mainly to ensure that fine-tuning will not compromise these capabilities acquired during pre-training.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments on FedLLM-Bench</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.3" class="ltx_p"><span id="S4.p1.3.1" class="ltx_text ltx_font_bold">Experimental setups.</span>
For instruction tuning task, we use Llama2-7B <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> as the base model and set the learning rate as <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="2e^{-5}" display="inline"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mn id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.p1.1.m1.1.1.1" xref="S4.p1.1.m1.1.1.1.cmml">​</mo><msup id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml"><mi id="S4.p1.1.m1.1.1.3.2" xref="S4.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="S4.p1.1.m1.1.1.3.3" xref="S4.p1.1.m1.1.1.3.3.cmml"><mo id="S4.p1.1.m1.1.1.3.3a" xref="S4.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.p1.1.m1.1.1.3.3.2" xref="S4.p1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><times id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">2</cn><apply id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p1.1.m1.1.1.3.1.cmml" xref="S4.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.p1.1.m1.1.1.3.2.cmml" xref="S4.p1.1.m1.1.1.3.2">𝑒</ci><apply id="S4.p1.1.m1.1.1.3.3.cmml" xref="S4.p1.1.m1.1.1.3.3"><minus id="S4.p1.1.m1.1.1.3.3.1.cmml" xref="S4.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.p1.1.m1.1.1.3.3.2.cmml" xref="S4.p1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">2e^{-5}</annotation></semantics></math> with a batch size of 16.
For preference alignment task, we use Alpaca-7B <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> as the base model and set the learning rate <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="1e^{-4}" display="inline"><semantics id="S4.p1.2.m2.1a"><mrow id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml"><mn id="S4.p1.2.m2.1.1.2" xref="S4.p1.2.m2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.p1.2.m2.1.1.1" xref="S4.p1.2.m2.1.1.1.cmml">​</mo><msup id="S4.p1.2.m2.1.1.3" xref="S4.p1.2.m2.1.1.3.cmml"><mi id="S4.p1.2.m2.1.1.3.2" xref="S4.p1.2.m2.1.1.3.2.cmml">e</mi><mrow id="S4.p1.2.m2.1.1.3.3" xref="S4.p1.2.m2.1.1.3.3.cmml"><mo id="S4.p1.2.m2.1.1.3.3a" xref="S4.p1.2.m2.1.1.3.3.cmml">−</mo><mn id="S4.p1.2.m2.1.1.3.3.2" xref="S4.p1.2.m2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><apply id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"><times id="S4.p1.2.m2.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.p1.2.m2.1.1.2.cmml" xref="S4.p1.2.m2.1.1.2">1</cn><apply id="S4.p1.2.m2.1.1.3.cmml" xref="S4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.p1.2.m2.1.1.3.1.cmml" xref="S4.p1.2.m2.1.1.3">superscript</csymbol><ci id="S4.p1.2.m2.1.1.3.2.cmml" xref="S4.p1.2.m2.1.1.3.2">𝑒</ci><apply id="S4.p1.2.m2.1.1.3.3.cmml" xref="S4.p1.2.m2.1.1.3.3"><minus id="S4.p1.2.m2.1.1.3.3.1.cmml" xref="S4.p1.2.m2.1.1.3.3"></minus><cn type="integer" id="S4.p1.2.m2.1.1.3.3.2.cmml" xref="S4.p1.2.m2.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">1e^{-4}</annotation></semantics></math> with a batch size of 8, as a large proportion of clients have fewer than 10 data samples.
We adopt 8-bit quantization on the base model and set the rank of LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> as <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.p1.3.m3.1a"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><cn type="integer" id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">16</annotation></semantics></math>.
The number of communication rounds is set to either 100 or 200 and only a small proportion of clients are sampled for each round.
We set the number of steps of local model training as 10 for most scenarios.
Please refer to details in Appendix <a href="#A3.SS1" title="C.1 Experimental setups ‣ Appendix C Experiments ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Experiments on multilingual dataset Fed-Aya evaluated via Ref-GPT4. FL methods generally perform better than local training on average. However, FL methods can not ensure better performance on every language, implying the necessity for exploring language personalization techniques.</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Algorithm</td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">ar</td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">en</td>
<td id="S4.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">es</td>
<td id="S4.T2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">fr</td>
<td id="S4.T2.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">pt</td>
<td id="S4.T2.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">ru</td>
<td id="S4.T2.1.1.8" class="ltx_td ltx_align_center ltx_border_tt">te</td>
<td id="S4.T2.1.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">zh</td>
<td id="S4.T2.1.1.10" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#F2F2F2;"><span id="S4.T2.1.1.10.1" class="ltx_text" style="background-color:#F2F2F2;">Average</span></td>
</tr>
<tr id="S4.T2.1.2" class="ltx_tr">
<td id="S4.T2.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Local Training (ar)</td>
<td id="S4.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_t">2.55</td>
<td id="S4.T2.1.2.3" class="ltx_td ltx_align_center ltx_border_t">7.55</td>
<td id="S4.T2.1.2.4" class="ltx_td ltx_align_center ltx_border_t">4.85</td>
<td id="S4.T2.1.2.5" class="ltx_td ltx_align_center ltx_border_t">5.10</td>
<td id="S4.T2.1.2.6" class="ltx_td ltx_align_center ltx_border_t">3.95</td>
<td id="S4.T2.1.2.7" class="ltx_td ltx_align_center ltx_border_t">4.55</td>
<td id="S4.T2.1.2.8" class="ltx_td ltx_align_center ltx_border_t">1.55</td>
<td id="S4.T2.1.2.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.35</td>
<td id="S4.T2.1.2.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.1.2.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.18</span></td>
</tr>
<tr id="S4.T2.1.3" class="ltx_tr">
<td id="S4.T2.1.3.1" class="ltx_td ltx_align_left ltx_border_r">Local Training (en)</td>
<td id="S4.T2.1.3.2" class="ltx_td ltx_align_center">2.55</td>
<td id="S4.T2.1.3.3" class="ltx_td ltx_align_center">7.20</td>
<td id="S4.T2.1.3.4" class="ltx_td ltx_align_center">5.35</td>
<td id="S4.T2.1.3.5" class="ltx_td ltx_align_center">4.60</td>
<td id="S4.T2.1.3.6" class="ltx_td ltx_align_center"><span id="S4.T2.1.3.6.1" class="ltx_text ltx_font_bold">5.35</span></td>
<td id="S4.T2.1.3.7" class="ltx_td ltx_align_center">4.75</td>
<td id="S4.T2.1.3.8" class="ltx_td ltx_align_center">1.60</td>
<td id="S4.T2.1.3.9" class="ltx_td ltx_align_center ltx_border_r">3.55</td>
<td id="S4.T2.1.3.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.3.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.37</span></td>
</tr>
<tr id="S4.T2.1.4" class="ltx_tr">
<td id="S4.T2.1.4.1" class="ltx_td ltx_align_left ltx_border_r">Local Training (es)</td>
<td id="S4.T2.1.4.2" class="ltx_td ltx_align_center">1.90</td>
<td id="S4.T2.1.4.3" class="ltx_td ltx_align_center">7.80</td>
<td id="S4.T2.1.4.4" class="ltx_td ltx_align_center">5.55</td>
<td id="S4.T2.1.4.5" class="ltx_td ltx_align_center">5.60</td>
<td id="S4.T2.1.4.6" class="ltx_td ltx_align_center">4.50</td>
<td id="S4.T2.1.4.7" class="ltx_td ltx_align_center">5.20</td>
<td id="S4.T2.1.4.8" class="ltx_td ltx_align_center">1.30</td>
<td id="S4.T2.1.4.9" class="ltx_td ltx_align_center ltx_border_r">5.05</td>
<td id="S4.T2.1.4.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.4.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.62</span></td>
</tr>
<tr id="S4.T2.1.5" class="ltx_tr">
<td id="S4.T2.1.5.1" class="ltx_td ltx_align_left ltx_border_r">Local Training (fr)</td>
<td id="S4.T2.1.5.2" class="ltx_td ltx_align_center">1.85</td>
<td id="S4.T2.1.5.3" class="ltx_td ltx_align_center">7.90</td>
<td id="S4.T2.1.5.4" class="ltx_td ltx_align_center">4.75</td>
<td id="S4.T2.1.5.5" class="ltx_td ltx_align_center">4.20</td>
<td id="S4.T2.1.5.6" class="ltx_td ltx_align_center">4.25</td>
<td id="S4.T2.1.5.7" class="ltx_td ltx_align_center">5.05</td>
<td id="S4.T2.1.5.8" class="ltx_td ltx_align_center">1.30</td>
<td id="S4.T2.1.5.9" class="ltx_td ltx_align_center ltx_border_r">3.95</td>
<td id="S4.T2.1.5.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.5.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.16</span></td>
</tr>
<tr id="S4.T2.1.6" class="ltx_tr">
<td id="S4.T2.1.6.1" class="ltx_td ltx_align_left ltx_border_r">Local Training (pt)</td>
<td id="S4.T2.1.6.2" class="ltx_td ltx_align_center">1.95</td>
<td id="S4.T2.1.6.3" class="ltx_td ltx_align_center">5.95</td>
<td id="S4.T2.1.6.4" class="ltx_td ltx_align_center">4.20</td>
<td id="S4.T2.1.6.5" class="ltx_td ltx_align_center">5.45</td>
<td id="S4.T2.1.6.6" class="ltx_td ltx_align_center">3.85</td>
<td id="S4.T2.1.6.7" class="ltx_td ltx_align_center">5.15</td>
<td id="S4.T2.1.6.8" class="ltx_td ltx_align_center">1.55</td>
<td id="S4.T2.1.6.9" class="ltx_td ltx_align_center ltx_border_r">3.95</td>
<td id="S4.T2.1.6.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.6.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.01</span></td>
</tr>
<tr id="S4.T2.1.7" class="ltx_tr">
<td id="S4.T2.1.7.1" class="ltx_td ltx_align_left ltx_border_r">Local Training (ru)</td>
<td id="S4.T2.1.7.2" class="ltx_td ltx_align_center">1.60</td>
<td id="S4.T2.1.7.3" class="ltx_td ltx_align_center">7.80</td>
<td id="S4.T2.1.7.4" class="ltx_td ltx_align_center">6.05</td>
<td id="S4.T2.1.7.5" class="ltx_td ltx_align_center">4.80</td>
<td id="S4.T2.1.7.6" class="ltx_td ltx_align_center">4.00</td>
<td id="S4.T2.1.7.7" class="ltx_td ltx_align_center">4.50</td>
<td id="S4.T2.1.7.8" class="ltx_td ltx_align_center">1.75</td>
<td id="S4.T2.1.7.9" class="ltx_td ltx_align_center ltx_border_r">4.90</td>
<td id="S4.T2.1.7.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.7.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.43</span></td>
</tr>
<tr id="S4.T2.1.8" class="ltx_tr">
<td id="S4.T2.1.8.1" class="ltx_td ltx_align_left ltx_border_r">Local Training (te)</td>
<td id="S4.T2.1.8.2" class="ltx_td ltx_align_center">2.10</td>
<td id="S4.T2.1.8.3" class="ltx_td ltx_align_center">3.70</td>
<td id="S4.T2.1.8.4" class="ltx_td ltx_align_center">3.75</td>
<td id="S4.T2.1.8.5" class="ltx_td ltx_align_center">3.50</td>
<td id="S4.T2.1.8.6" class="ltx_td ltx_align_center">3.05</td>
<td id="S4.T2.1.8.7" class="ltx_td ltx_align_center">4.10</td>
<td id="S4.T2.1.8.8" class="ltx_td ltx_align_center">1.25</td>
<td id="S4.T2.1.8.9" class="ltx_td ltx_align_center ltx_border_r">3.60</td>
<td id="S4.T2.1.8.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.8.10.1" class="ltx_text" style="background-color:#F2F2F2;">3.13</span></td>
</tr>
<tr id="S4.T2.1.9" class="ltx_tr">
<td id="S4.T2.1.9.1" class="ltx_td ltx_align_left ltx_border_r">Local Training (zh)</td>
<td id="S4.T2.1.9.2" class="ltx_td ltx_align_center">2.30</td>
<td id="S4.T2.1.9.3" class="ltx_td ltx_align_center">8.10</td>
<td id="S4.T2.1.9.4" class="ltx_td ltx_align_center">5.45</td>
<td id="S4.T2.1.9.5" class="ltx_td ltx_align_center">5.80</td>
<td id="S4.T2.1.9.6" class="ltx_td ltx_align_center">4.80</td>
<td id="S4.T2.1.9.7" class="ltx_td ltx_align_center">4.30</td>
<td id="S4.T2.1.9.8" class="ltx_td ltx_align_center">1.60</td>
<td id="S4.T2.1.9.9" class="ltx_td ltx_align_center ltx_border_r">4.95</td>
<td id="S4.T2.1.9.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.9.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.66</span></td>
</tr>
<tr id="S4.T2.1.10" class="ltx_tr">
<td id="S4.T2.1.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S4.T2.1.10.2" class="ltx_td ltx_align_center ltx_border_t">2.50</td>
<td id="S4.T2.1.10.3" class="ltx_td ltx_align_center ltx_border_t">8.00</td>
<td id="S4.T2.1.10.4" class="ltx_td ltx_align_center ltx_border_t">5.50</td>
<td id="S4.T2.1.10.5" class="ltx_td ltx_align_center ltx_border_t">5.35</td>
<td id="S4.T2.1.10.6" class="ltx_td ltx_align_center ltx_border_t">4.95</td>
<td id="S4.T2.1.10.7" class="ltx_td ltx_align_center ltx_border_t">5.65</td>
<td id="S4.T2.1.10.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.10.8.1" class="ltx_text ltx_font_bold">2.00</span></td>
<td id="S4.T2.1.10.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.25</td>
<td id="S4.T2.1.10.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.1.10.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.90</span></td>
</tr>
<tr id="S4.T2.1.11" class="ltx_tr">
<td id="S4.T2.1.11.1" class="ltx_td ltx_align_left ltx_border_r">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
<td id="S4.T2.1.11.2" class="ltx_td ltx_align_center"><span id="S4.T2.1.11.2.1" class="ltx_text ltx_font_bold">3.20</span></td>
<td id="S4.T2.1.11.3" class="ltx_td ltx_align_center">7.10</td>
<td id="S4.T2.1.11.4" class="ltx_td ltx_align_center">5.90</td>
<td id="S4.T2.1.11.5" class="ltx_td ltx_align_center"><span id="S4.T2.1.11.5.1" class="ltx_text ltx_font_bold">5.65</span></td>
<td id="S4.T2.1.11.6" class="ltx_td ltx_align_center">4.85</td>
<td id="S4.T2.1.11.7" class="ltx_td ltx_align_center">5.20</td>
<td id="S4.T2.1.11.8" class="ltx_td ltx_align_center">1.60</td>
<td id="S4.T2.1.11.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.1.11.9.1" class="ltx_text ltx_font_bold">5.80</span></td>
<td id="S4.T2.1.11.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.11.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.92</span></td>
</tr>
<tr id="S4.T2.1.12" class="ltx_tr">
<td id="S4.T2.1.12.1" class="ltx_td ltx_align_left ltx_border_r">SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S4.T2.1.12.2" class="ltx_td ltx_align_center">2.65</td>
<td id="S4.T2.1.12.3" class="ltx_td ltx_align_center">7.75</td>
<td id="S4.T2.1.12.4" class="ltx_td ltx_align_center"><span id="S4.T2.1.12.4.1" class="ltx_text ltx_font_bold">6.30</span></td>
<td id="S4.T2.1.12.5" class="ltx_td ltx_align_center">5.35</td>
<td id="S4.T2.1.12.6" class="ltx_td ltx_align_center">5.00</td>
<td id="S4.T2.1.12.7" class="ltx_td ltx_align_center"><span id="S4.T2.1.12.7.1" class="ltx_text ltx_font_bold">6.35</span></td>
<td id="S4.T2.1.12.8" class="ltx_td ltx_align_center">1.45</td>
<td id="S4.T2.1.12.9" class="ltx_td ltx_align_center ltx_border_r">4.90</td>
<td id="S4.T2.1.12.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.12.10.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">4.97</span></td>
</tr>
<tr id="S4.T2.1.13" class="ltx_tr">
<td id="S4.T2.1.13.1" class="ltx_td ltx_align_left ltx_border_r">FedAvgM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
</td>
<td id="S4.T2.1.13.2" class="ltx_td ltx_align_center">3.00</td>
<td id="S4.T2.1.13.3" class="ltx_td ltx_align_center">7.80</td>
<td id="S4.T2.1.13.4" class="ltx_td ltx_align_center">5.35</td>
<td id="S4.T2.1.13.5" class="ltx_td ltx_align_center">5.00</td>
<td id="S4.T2.1.13.6" class="ltx_td ltx_align_center">5.30</td>
<td id="S4.T2.1.13.7" class="ltx_td ltx_align_center">5.65</td>
<td id="S4.T2.1.13.8" class="ltx_td ltx_align_center">1.90</td>
<td id="S4.T2.1.13.9" class="ltx_td ltx_align_center ltx_border_r">5.00</td>
<td id="S4.T2.1.13.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.13.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.86</span></td>
</tr>
<tr id="S4.T2.1.14" class="ltx_tr">
<td id="S4.T2.1.14.1" class="ltx_td ltx_align_left ltx_border_r">FedYogi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S4.T2.1.14.2" class="ltx_td ltx_align_center">2.00</td>
<td id="S4.T2.1.14.3" class="ltx_td ltx_align_center"><span id="S4.T2.1.14.3.1" class="ltx_text ltx_font_bold">8.45</span></td>
<td id="S4.T2.1.14.4" class="ltx_td ltx_align_center">6.15</td>
<td id="S4.T2.1.14.5" class="ltx_td ltx_align_center">4.55</td>
<td id="S4.T2.1.14.6" class="ltx_td ltx_align_center">3.85</td>
<td id="S4.T2.1.14.7" class="ltx_td ltx_align_center">6.30</td>
<td id="S4.T2.1.14.8" class="ltx_td ltx_align_center">1.65</td>
<td id="S4.T2.1.14.9" class="ltx_td ltx_align_center ltx_border_r">4.93</td>
<td id="S4.T2.1.14.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.14.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.73</span></td>
</tr>
<tr id="S4.T2.1.15" class="ltx_tr">
<td id="S4.T2.1.15.1" class="ltx_td ltx_align_left ltx_border_r">FedAdagrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S4.T2.1.15.2" class="ltx_td ltx_align_center">2.50</td>
<td id="S4.T2.1.15.3" class="ltx_td ltx_align_center">7.85</td>
<td id="S4.T2.1.15.4" class="ltx_td ltx_align_center">5.15</td>
<td id="S4.T2.1.15.5" class="ltx_td ltx_align_center">5.25</td>
<td id="S4.T2.1.15.6" class="ltx_td ltx_align_center">4.45</td>
<td id="S4.T2.1.15.7" class="ltx_td ltx_align_center">5.75</td>
<td id="S4.T2.1.15.8" class="ltx_td ltx_align_center">1.55</td>
<td id="S4.T2.1.15.9" class="ltx_td ltx_align_center ltx_border_r">5.50</td>
<td id="S4.T2.1.15.10" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T2.1.15.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.75</span></td>
</tr>
<tr id="S4.T2.1.16" class="ltx_tr">
<td id="S4.T2.1.16.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">FedAdam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S4.T2.1.16.2" class="ltx_td ltx_align_center ltx_border_bb">2.40</td>
<td id="S4.T2.1.16.3" class="ltx_td ltx_align_center ltx_border_bb">8.50</td>
<td id="S4.T2.1.16.4" class="ltx_td ltx_align_center ltx_border_bb">5.25</td>
<td id="S4.T2.1.16.5" class="ltx_td ltx_align_center ltx_border_bb">4.70</td>
<td id="S4.T2.1.16.6" class="ltx_td ltx_align_center ltx_border_bb">4.35</td>
<td id="S4.T2.1.16.7" class="ltx_td ltx_align_center ltx_border_bb">5.40</td>
<td id="S4.T2.1.16.8" class="ltx_td ltx_align_center ltx_border_bb">1.90</td>
<td id="S4.T2.1.16.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">5.20</td>
<td id="S4.T2.1.16.10" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F2F2F2;"><span id="S4.T2.1.16.10.1" class="ltx_text" style="background-color:#F2F2F2;">4.71</span></td>
</tr>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Benchmark results</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Fed-Aya.</span>
Here, we conduct experiments on Fed-Aya with Ref-GPT4 as the evaluation metric for 8 languages.
We run local training for each language (randomly sample one client for simplicity), and 7 federated methods.
From Table <a href="#S4.T2" title="Table 2 ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we see that:
(1) Most FL methods can outperform local training on average, indicating the effectiveness of collaboration.
(2) No FL method can achieve comprehensive superiority in all languages, implying the necessity of future exploration of language personalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>.
(3) FedAvg and FedProx are the two most effective algorithms here.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Experiments on single-turn chat dataset Fed-ChatbotIT. FL methods perform consistently better under <span id="S4.T3.3.1" class="ltx_text" style="background-color:#FFE6E6;">open-ended</span> instruction-following evaluations and comparably under <span id="S4.T3.4.2" class="ltx_text" style="background-color:#E6E6FF;">closed-ended</span> knowledge evaluations compared to local training. Overall, FedAdagrad is the most effective.</figcaption>
<table id="S4.T3.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.5.1" class="ltx_tr">
<td id="S4.T3.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="background-color:#F2F2F2;"><span id="S4.T3.5.1.1.1" class="ltx_text" style="background-color:#F2F2F2;">Algorithm</span></td>
<td id="S4.T3.5.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#FFE6E6;"><span id="S4.T3.5.1.2.1" class="ltx_text" style="background-color:#FFE6E6;">MT-Bench-1</span></td>
<td id="S4.T3.5.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#FFE6E6;"><span id="S4.T3.5.1.3.1" class="ltx_text" style="background-color:#FFE6E6;">Vicuna</span></td>
<td id="S4.T3.5.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#FFE6E6;"><span id="S4.T3.5.1.4.1" class="ltx_text" style="background-color:#FFE6E6;">Ref-GPT4</span></td>
<td id="S4.T3.5.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="background-color:#FFE6E6;"><span id="S4.T3.5.1.5.1" class="ltx_text" style="background-color:#FFE6E6;">Average</span></td>
<td id="S4.T3.5.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#E6E6FF;"><span id="S4.T3.5.1.6.1" class="ltx_text" style="background-color:#E6E6FF;">HumanEval</span></td>
<td id="S4.T3.5.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#E6E6FF;"><span id="S4.T3.5.1.7.1" class="ltx_text" style="background-color:#E6E6FF;">MMLU</span></td>
</tr>
<tr id="S4.T3.5.2" class="ltx_tr">
<td id="S4.T3.5.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T3.5.2.1.1" class="ltx_text" style="background-color:#F2F2F2;">Local Training</span></td>
<td id="S4.T3.5.2.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.2.2.1" class="ltx_text" style="background-color:#FFE6E6;">3.73</span></td>
<td id="S4.T3.5.2.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.2.3.1" class="ltx_text" style="background-color:#FFE6E6;">6.78</span></td>
<td id="S4.T3.5.2.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.2.4.1" class="ltx_text" style="background-color:#FFE6E6;">4.49</span></td>
<td id="S4.T3.5.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.2.5.1" class="ltx_text" style="background-color:#FFE6E6;">5.00</span></td>
<td id="S4.T3.5.2.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T3.5.2.6.1" class="ltx_text" style="background-color:#E6E6FF;">13.41</span></td>
<td id="S4.T3.5.2.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T3.5.2.7.1" class="ltx_text" style="background-color:#E6E6FF;">46.31</span></td>
</tr>
<tr id="S4.T3.5.3" class="ltx_tr">
<td id="S4.T3.5.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T3.5.3.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite></span></td>
<td id="S4.T3.5.3.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.3.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.30</span></td>
<td id="S4.T3.5.3.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.3.3.1" class="ltx_text" style="background-color:#FFE6E6;">6.93</span></td>
<td id="S4.T3.5.3.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.3.4.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">5.29</span></td>
<td id="S4.T3.5.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T3.5.3.5.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">5.51</span></td>
<td id="S4.T3.5.3.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T3.5.3.6.1" class="ltx_text" style="background-color:#E6E6FF;">14.02</span></td>
<td id="S4.T3.5.3.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T3.5.3.7.1" class="ltx_text" style="background-color:#E6E6FF;">46.10</span></td>
</tr>
<tr id="S4.T3.5.4" class="ltx_tr">
<td id="S4.T3.5.4.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.5.4.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite></span></td>
<td id="S4.T3.5.4.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.4.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.25</span></td>
<td id="S4.T3.5.4.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.4.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.21</span></td>
<td id="S4.T3.5.4.4" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.4.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.00</span></td>
<td id="S4.T3.5.4.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T3.5.4.5.1" class="ltx_text" style="background-color:#FFE6E6;">5.49</span></td>
<td id="S4.T3.5.4.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.4.6.1" class="ltx_text" style="background-color:#E6E6FF;">14.63</span></td>
<td id="S4.T3.5.4.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.4.7.1" class="ltx_text" style="background-color:#E6E6FF;">46.12</span></td>
</tr>
<tr id="S4.T3.5.5" class="ltx_tr">
<td id="S4.T3.5.5.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.5.5.1.1" class="ltx_text" style="background-color:#F2F2F2;">SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite></span></td>
<td id="S4.T3.5.5.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.5.2.1" class="ltx_text" style="background-color:#FFE6E6;">3.86</span></td>
<td id="S4.T3.5.5.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.5.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.35</span></td>
<td id="S4.T3.5.5.4" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.5.4.1" class="ltx_text" style="background-color:#FFE6E6;">4.82</span></td>
<td id="S4.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T3.5.5.5.1" class="ltx_text" style="background-color:#FFE6E6;">5.34</span></td>
<td id="S4.T3.5.5.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.5.6.1" class="ltx_text" style="background-color:#E6E6FF;">15.24</span></td>
<td id="S4.T3.5.5.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.5.7.1" class="ltx_text" style="background-color:#E6E6FF;">46.02</span></td>
</tr>
<tr id="S4.T3.5.6" class="ltx_tr">
<td id="S4.T3.5.6.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.5.6.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAvgM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite></span></td>
<td id="S4.T3.5.6.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.6.2.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">4.34</span></td>
<td id="S4.T3.5.6.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.6.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.17</span></td>
<td id="S4.T3.5.6.4" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.6.4.1" class="ltx_text" style="background-color:#FFE6E6;">4.76</span></td>
<td id="S4.T3.5.6.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T3.5.6.5.1" class="ltx_text" style="background-color:#FFE6E6;">5.42</span></td>
<td id="S4.T3.5.6.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.6.6.1" class="ltx_text" style="background-color:#E6E6FF;">14.63</span></td>
<td id="S4.T3.5.6.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.6.7.1" class="ltx_text" style="background-color:#E6E6FF;">46.13</span></td>
</tr>
<tr id="S4.T3.5.7" class="ltx_tr">
<td id="S4.T3.5.7.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.5.7.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedYogi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T3.5.7.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.7.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.13</span></td>
<td id="S4.T3.5.7.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.7.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.20</span></td>
<td id="S4.T3.5.7.4" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.7.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.00</span></td>
<td id="S4.T3.5.7.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T3.5.7.5.1" class="ltx_text" style="background-color:#FFE6E6;">5.44</span></td>
<td id="S4.T3.5.7.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.7.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">15.85</span></td>
<td id="S4.T3.5.7.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.7.7.1" class="ltx_text" style="background-color:#E6E6FF;">46.24</span></td>
</tr>
<tr id="S4.T3.5.8" class="ltx_tr">
<td id="S4.T3.5.8.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.5.8.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAdagrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T3.5.8.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.8.2.1" class="ltx_text" style="background-color:#FFE6E6;">3.94</span></td>
<td id="S4.T3.5.8.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.8.3.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">7.50</span></td>
<td id="S4.T3.5.8.4" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T3.5.8.4.1" class="ltx_text" style="background-color:#FFE6E6;">4.99</span></td>
<td id="S4.T3.5.8.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T3.5.8.5.1" class="ltx_text" style="background-color:#FFE6E6;">5.48</span></td>
<td id="S4.T3.5.8.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.8.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">15.85</span></td>
<td id="S4.T3.5.8.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T3.5.8.7.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">46.48</span></td>
</tr>
<tr id="S4.T3.5.9" class="ltx_tr">
<td id="S4.T3.5.9.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T3.5.9.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAdam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T3.5.9.2" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFE6E6;"><span id="S4.T3.5.9.2.1" class="ltx_text" style="background-color:#FFE6E6;">3.88</span></td>
<td id="S4.T3.5.9.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFE6E6;"><span id="S4.T3.5.9.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.32</span></td>
<td id="S4.T3.5.9.4" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFE6E6;"><span id="S4.T3.5.9.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.02</span></td>
<td id="S4.T3.5.9.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T3.5.9.5.1" class="ltx_text" style="background-color:#FFE6E6;">5.41</span></td>
<td id="S4.T3.5.9.6" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6FF;"><span id="S4.T3.5.9.6.1" class="ltx_text" style="background-color:#E6E6FF;">14.57</span></td>
<td id="S4.T3.5.9.7" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6FF;"><span id="S4.T3.5.9.7.1" class="ltx_text" style="background-color:#E6E6FF;">46.10</span></td>
</tr>
</table>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Fed-ChatbotIT.</span>
Here, we conduct experiments on Fed-ChatbotIT evaluated under 5 metrics.
We randomly sample two clients to run local training and average their evaluation results.
From Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Benchmark results ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we see that
(1) on open-ended evaluation, all FL methods consistently outperform local training, indicating the effectiveness of FL in enhancing the capability of instruction following.
(2) On closed-ended evaluation, FL methods perform better or are comparable to local training, indicating that FL training will not compromise LLMs’ general capability.
(3) Across all metrics, the best scores are achieved by FL algorithms; On average, FedAdagrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> achieves the best performance.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Fed-WildChat.</span>
Here, we show two series of experiments based on Fed-WildChat: instruction tuning based on single-turn and multi-turn conversations, in Table <a href="#S4.T4" title="Table 4 ‣ 4.1 Benchmark results ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
For both experiments, we see that FL methods consistently outperform local training, verifying the effectiveness of collaboration.
For single-turn, we see that no FL method can dominate in all evaluation metrics;
while for multi-turn, we see that FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> consistently outperforms the best across metrics.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.1" class="ltx_p">This is an interesting observation since the other baseline methods are shown to be effective in tackling data heterogeneity in other tasks such as image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
This phenomenon could be attributed to two reasons:
(1) training from pre-trained model itself benefits tackling the issue of data heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, which could make some model-level optimization techniques not as effective as before <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
(2) We are fine-tuning with parameter-efficient fine-tuning technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> with a small number of local steps (e.g., 10), reducing the risk of overfitting on local datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>.
Therefore, we call for more future works to enhance the performance regarding data, such as considering data quality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> or synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Experiments of <span id="S4.T4.3.1" class="ltx_text" style="background-color:#FFE6E6;">single-turn</span> and <span id="S4.T4.4.2" class="ltx_text" style="background-color:#E6E6FF;">multi-turn</span> chat on Fed-Wildchat. FL methods perform consistently better than local training. FedAvg is a robust method in this scenario.</figcaption>
<table id="S4.T4.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.5.1" class="ltx_tr">
<td id="S4.T4.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="background-color:#F2F2F2;"><span id="S4.T4.5.1.1.1" class="ltx_text" style="background-color:#F2F2F2;">Experiment</span></td>
<td id="S4.T4.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="background-color:#FFE6E6;" colspan="3"><span id="S4.T4.5.1.2.1" class="ltx_text" style="background-color:#FFE6E6;">Single-Turn</span></td>
<td id="S4.T4.5.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#E6E6FF;" colspan="4"><span id="S4.T4.5.1.3.1" class="ltx_text" style="background-color:#E6E6FF;">Multi-Turn</span></td>
</tr>
<tr id="S4.T4.5.2" class="ltx_tr">
<td id="S4.T4.5.2.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T4.5.2.1.1" class="ltx_text" style="background-color:#F2F2F2;">Algorithm</span></td>
<td id="S4.T4.5.2.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.2.2.1" class="ltx_text" style="background-color:#FFE6E6;">MT-1</span></td>
<td id="S4.T4.5.2.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.2.3.1" class="ltx_text" style="background-color:#FFE6E6;">Vicuna</span></td>
<td id="S4.T4.5.2.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T4.5.2.4.1" class="ltx_text" style="background-color:#FFE6E6;">Ref-GPT4</span></td>
<td id="S4.T4.5.2.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.2.5.1" class="ltx_text" style="background-color:#E6E6FF;">MT-1</span></td>
<td id="S4.T4.5.2.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.2.6.1" class="ltx_text" style="background-color:#E6E6FF;">MT-2</span></td>
<td id="S4.T4.5.2.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.2.7.1" class="ltx_text" style="background-color:#E6E6FF;">MT-Bench</span></td>
<td id="S4.T4.5.2.8" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.2.8.1" class="ltx_text" style="background-color:#E6E6FF;">Ref-GPT4</span></td>
</tr>
<tr id="S4.T4.5.3" class="ltx_tr">
<td id="S4.T4.5.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T4.5.3.1.1" class="ltx_text" style="background-color:#F2F2F2;">Local Training</span></td>
<td id="S4.T4.5.3.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T4.5.3.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.15</span></td>
<td id="S4.T4.5.3.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T4.5.3.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.03</span></td>
<td id="S4.T4.5.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T4.5.3.4.1" class="ltx_text" style="background-color:#FFE6E6;">4.50</span></td>
<td id="S4.T4.5.3.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.3.5.1" class="ltx_text" style="background-color:#E6E6FF;">3.99</span></td>
<td id="S4.T4.5.3.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.3.6.1" class="ltx_text" style="background-color:#E6E6FF;">2.56</span></td>
<td id="S4.T4.5.3.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.3.7.1" class="ltx_text" style="background-color:#E6E6FF;">3.27</span></td>
<td id="S4.T4.5.3.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.3.8.1" class="ltx_text" style="background-color:#E6E6FF;">4.68</span></td>
</tr>
<tr id="S4.T4.5.4" class="ltx_tr">
<td id="S4.T4.5.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T4.5.4.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite></span></td>
<td id="S4.T4.5.4.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T4.5.4.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.81</span></td>
<td id="S4.T4.5.4.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T4.5.4.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.99</span></td>
<td id="S4.T4.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T4.5.4.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.88</span></td>
<td id="S4.T4.5.4.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.4.5.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">4.84</span></td>
<td id="S4.T4.5.4.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.4.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">3.15</span></td>
<td id="S4.T4.5.4.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.4.7.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">3.99</span></td>
<td id="S4.T4.5.4.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T4.5.4.8.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">5.86</span></td>
</tr>
<tr id="S4.T4.5.5" class="ltx_tr">
<td id="S4.T4.5.5.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T4.5.5.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite></span></td>
<td id="S4.T4.5.5.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.5.2.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">4.86</span></td>
<td id="S4.T4.5.5.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.5.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.93</span></td>
<td id="S4.T4.5.5.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T4.5.5.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.74</span></td>
<td id="S4.T4.5.5.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.5.5.1" class="ltx_text" style="background-color:#E6E6FF;">4.58</span></td>
<td id="S4.T4.5.5.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.5.6.1" class="ltx_text" style="background-color:#E6E6FF;">2.92</span></td>
<td id="S4.T4.5.5.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.5.7.1" class="ltx_text" style="background-color:#E6E6FF;">3.75</span></td>
<td id="S4.T4.5.5.8" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.5.8.1" class="ltx_text" style="background-color:#E6E6FF;">5.26</span></td>
</tr>
<tr id="S4.T4.5.6" class="ltx_tr">
<td id="S4.T4.5.6.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T4.5.6.1.1" class="ltx_text" style="background-color:#F2F2F2;">SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite></span></td>
<td id="S4.T4.5.6.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.6.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.78</span></td>
<td id="S4.T4.5.6.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.6.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.93</span></td>
<td id="S4.T4.5.6.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T4.5.6.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.57</span></td>
<td id="S4.T4.5.6.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.6.5.1" class="ltx_text" style="background-color:#E6E6FF;">4.46</span></td>
<td id="S4.T4.5.6.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.6.6.1" class="ltx_text" style="background-color:#E6E6FF;">3.13</span></td>
<td id="S4.T4.5.6.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.6.7.1" class="ltx_text" style="background-color:#E6E6FF;">3.79</span></td>
<td id="S4.T4.5.6.8" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.6.8.1" class="ltx_text" style="background-color:#E6E6FF;">5.25</span></td>
</tr>
<tr id="S4.T4.5.7" class="ltx_tr">
<td id="S4.T4.5.7.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T4.5.7.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAvgM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite></span></td>
<td id="S4.T4.5.7.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.7.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.52</span></td>
<td id="S4.T4.5.7.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.7.3.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">8.07</span></td>
<td id="S4.T4.5.7.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T4.5.7.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.85</span></td>
<td id="S4.T4.5.7.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.7.5.1" class="ltx_text" style="background-color:#E6E6FF;">4.53</span></td>
<td id="S4.T4.5.7.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.7.6.1" class="ltx_text" style="background-color:#E6E6FF;">2.77</span></td>
<td id="S4.T4.5.7.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.7.7.1" class="ltx_text" style="background-color:#E6E6FF;">3.65</span></td>
<td id="S4.T4.5.7.8" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.7.8.1" class="ltx_text" style="background-color:#E6E6FF;">5.34</span></td>
</tr>
<tr id="S4.T4.5.8" class="ltx_tr">
<td id="S4.T4.5.8.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T4.5.8.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedYogi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T4.5.8.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.8.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.78</span></td>
<td id="S4.T4.5.8.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.8.3.1" class="ltx_text" style="background-color:#FFE6E6;">8.04</span></td>
<td id="S4.T4.5.8.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T4.5.8.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.48</span></td>
<td id="S4.T4.5.8.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.8.5.1" class="ltx_text" style="background-color:#E6E6FF;">4.59</span></td>
<td id="S4.T4.5.8.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.8.6.1" class="ltx_text" style="background-color:#E6E6FF;">2.96</span></td>
<td id="S4.T4.5.8.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.8.7.1" class="ltx_text" style="background-color:#E6E6FF;">3.78</span></td>
<td id="S4.T4.5.8.8" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.8.8.1" class="ltx_text" style="background-color:#E6E6FF;">5.05</span></td>
</tr>
<tr id="S4.T4.5.9" class="ltx_tr">
<td id="S4.T4.5.9.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T4.5.9.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAdagrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T4.5.9.2" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.9.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.76</span></td>
<td id="S4.T4.5.9.3" class="ltx_td ltx_align_center" style="background-color:#FFE6E6;"><span id="S4.T4.5.9.3.1" class="ltx_text" style="background-color:#FFE6E6;">7.76</span></td>
<td id="S4.T4.5.9.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T4.5.9.4.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">5.93</span></td>
<td id="S4.T4.5.9.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.9.5.1" class="ltx_text" style="background-color:#E6E6FF;">4.64</span></td>
<td id="S4.T4.5.9.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.9.6.1" class="ltx_text" style="background-color:#E6E6FF;">3.03</span></td>
<td id="S4.T4.5.9.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.9.7.1" class="ltx_text" style="background-color:#E6E6FF;">3.84</span></td>
<td id="S4.T4.5.9.8" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T4.5.9.8.1" class="ltx_text" style="background-color:#E6E6FF;">5.17</span></td>
</tr>
<tr id="S4.T4.5.10" class="ltx_tr">
<td id="S4.T4.5.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T4.5.10.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAdam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T4.5.10.2" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFE6E6;"><span id="S4.T4.5.10.2.1" class="ltx_text" style="background-color:#FFE6E6;">4.54</span></td>
<td id="S4.T4.5.10.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFE6E6;"><span id="S4.T4.5.10.3.1" class="ltx_text" style="background-color:#FFE6E6;">8.03</span></td>
<td id="S4.T4.5.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T4.5.10.4.1" class="ltx_text" style="background-color:#FFE6E6;">5.68</span></td>
<td id="S4.T4.5.10.5" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6FF;"><span id="S4.T4.5.10.5.1" class="ltx_text" style="background-color:#E6E6FF;">4.63</span></td>
<td id="S4.T4.5.10.6" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6FF;"><span id="S4.T4.5.10.6.1" class="ltx_text" style="background-color:#E6E6FF;">2.85</span></td>
<td id="S4.T4.5.10.7" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6FF;"><span id="S4.T4.5.10.7.1" class="ltx_text" style="background-color:#E6E6FF;">3.74</span></td>
<td id="S4.T4.5.10.8" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6FF;"><span id="S4.T4.5.10.8.1" class="ltx_text" style="background-color:#E6E6FF;">4.96</span></td>
</tr>
</table>
</figure>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Fed-ChatbotPA.</span>
Here, we conduct experiments of federated preference alignment on Fed-ChatbotPA dataset, with an instruction-tuned LLM as the model initialization.
We randomly sample two clients to run local training and average their evaluation results.
From Table <a href="#S4.T5" title="Table 5 ‣ 4.1 Benchmark results ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we see that
(1) preference alignment could enhance the LLMs’ capability in following humans instructions in an helpful and harmless manner.
(2) All FL methods consistently perform better than local training, indicating the effectiveness of federated preference alignment.
Since the high-quality preference data usually involves massive human efforts, each party is hard to scale up the data, motivating diverse parties to collaborate via FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>.
(3) Regarding instruction-following capabilities, FedAvgM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, adn FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> are four most effective methods.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Experiments of federated preference alignment on Fed-ChatbotPA dataset. FL methods consistently perform better than local training, indicating the significance of collaboration via FL. Compared to base model, models trained via FL methods achieve consistent improvement in <span id="S4.T5.4.1" class="ltx_text" style="background-color:#FFF2E6;">instruction-following</span> capabilities and <span id="S4.T5.5.2" class="ltx_text" style="background-color:#FFE6E6;">safety</span>, and preserve most of the <span id="S4.T5.6.3" class="ltx_text" style="background-color:#E6E6FF;">knowledge</span>.</figcaption>
<table id="S4.T5.7" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.7.1" class="ltx_tr">
<td id="S4.T5.7.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="background-color:#F2F2F2;"><span id="S4.T5.7.1.1.1" class="ltx_text" style="background-color:#F2F2F2;">Algorithm</span></td>
<td id="S4.T5.7.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#FFF2E6;"><span id="S4.T5.7.1.2.1" class="ltx_text" style="background-color:#FFF2E6;">MT-Bench-1</span></td>
<td id="S4.T5.7.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#FFF2E6;"><span id="S4.T5.7.1.3.1" class="ltx_text" style="background-color:#FFF2E6;">Vicuna</span></td>
<td id="S4.T5.7.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="background-color:#FFF2E6;"><span id="S4.T5.7.1.4.1" class="ltx_text" style="background-color:#FFF2E6;">Average</span></td>
<td id="S4.T5.7.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="background-color:#FFE6E6;"><span id="S4.T5.7.1.5.1" class="ltx_text" style="background-color:#FFE6E6;">AdvBench</span></td>
<td id="S4.T5.7.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#E6E6FF;"><span id="S4.T5.7.1.6.1" class="ltx_text" style="background-color:#E6E6FF;">MMLU</span></td>
</tr>
<tr id="S4.T5.7.2" class="ltx_tr">
<td id="S4.T5.7.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T5.7.2.1.1" class="ltx_text" style="background-color:#F2F2F2;">Base Model</span></td>
<td id="S4.T5.7.2.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.2.2.1" class="ltx_text" style="background-color:#FFF2E6;">3.96</span></td>
<td id="S4.T5.7.2.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.2.3.1" class="ltx_text" style="background-color:#FFF2E6;">6.31</span></td>
<td id="S4.T5.7.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.2.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.14</span></td>
<td id="S4.T5.7.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T5.7.2.5.1" class="ltx_text" style="background-color:#FFE6E6;">9.40</span></td>
<td id="S4.T5.7.2.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T5.7.2.6.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6FF;">40.41</span></td>
</tr>
<tr id="S4.T5.7.3" class="ltx_tr">
<td id="S4.T5.7.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T5.7.3.1.1" class="ltx_text" style="background-color:#F2F2F2;">Local Training</span></td>
<td id="S4.T5.7.3.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.3.2.1" class="ltx_text" style="background-color:#FFF2E6;">4.12</span></td>
<td id="S4.T5.7.3.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.3.3.1" class="ltx_text" style="background-color:#FFF2E6;">6.62</span></td>
<td id="S4.T5.7.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.3.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.37</span></td>
<td id="S4.T5.7.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T5.7.3.5.1" class="ltx_text" style="background-color:#FFE6E6;">11.0</span></td>
<td id="S4.T5.7.3.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T5.7.3.6.1" class="ltx_text" style="background-color:#E6E6FF;">38.26</span></td>
</tr>
<tr id="S4.T5.7.4" class="ltx_tr">
<td id="S4.T5.7.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T5.7.4.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite></span></td>
<td id="S4.T5.7.4.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.4.2.1" class="ltx_text" style="background-color:#FFF2E6;">4.44</span></td>
<td id="S4.T5.7.4.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.4.3.1" class="ltx_text" style="background-color:#FFF2E6;">7.06</span></td>
<td id="S4.T5.7.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFF2E6;"><span id="S4.T5.7.4.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.75</span></td>
<td id="S4.T5.7.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFE6E6;"><span id="S4.T5.7.4.5.1" class="ltx_text ltx_font_bold" style="background-color:#FFE6E6;">16.2</span></td>
<td id="S4.T5.7.4.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FF;"><span id="S4.T5.7.4.6.1" class="ltx_text" style="background-color:#E6E6FF;">39.70</span></td>
</tr>
<tr id="S4.T5.7.5" class="ltx_tr">
<td id="S4.T5.7.5.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T5.7.5.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite></span></td>
<td id="S4.T5.7.5.2" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.5.2.1" class="ltx_text" style="background-color:#FFF2E6;">4.44</span></td>
<td id="S4.T5.7.5.3" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.5.3.1" class="ltx_text ltx_font_bold" style="background-color:#FFF2E6;">7.11</span></td>
<td id="S4.T5.7.5.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFF2E6;"><span id="S4.T5.7.5.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.78</span></td>
<td id="S4.T5.7.5.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T5.7.5.5.1" class="ltx_text" style="background-color:#FFE6E6;">13.8</span></td>
<td id="S4.T5.7.5.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T5.7.5.6.1" class="ltx_text" style="background-color:#E6E6FF;">39.51</span></td>
</tr>
<tr id="S4.T5.7.6" class="ltx_tr">
<td id="S4.T5.7.6.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T5.7.6.1.1" class="ltx_text" style="background-color:#F2F2F2;">SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite></span></td>
<td id="S4.T5.7.6.2" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.6.2.1" class="ltx_text" style="background-color:#FFF2E6;">4.53</span></td>
<td id="S4.T5.7.6.3" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.6.3.1" class="ltx_text" style="background-color:#FFF2E6;">7.01</span></td>
<td id="S4.T5.7.6.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFF2E6;"><span id="S4.T5.7.6.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.77</span></td>
<td id="S4.T5.7.6.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T5.7.6.5.1" class="ltx_text" style="background-color:#FFE6E6;">16.0</span></td>
<td id="S4.T5.7.6.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T5.7.6.6.1" class="ltx_text" style="background-color:#E6E6FF;">39.94</span></td>
</tr>
<tr id="S4.T5.7.7" class="ltx_tr">
<td id="S4.T5.7.7.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T5.7.7.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAvgM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite></span></td>
<td id="S4.T5.7.7.2" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.7.2.1" class="ltx_text ltx_font_bold" style="background-color:#FFF2E6;">4.71</span></td>
<td id="S4.T5.7.7.3" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.7.3.1" class="ltx_text" style="background-color:#FFF2E6;">6.87</span></td>
<td id="S4.T5.7.7.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFF2E6;"><span id="S4.T5.7.7.4.1" class="ltx_text ltx_font_bold" style="background-color:#FFF2E6;">5.79</span></td>
<td id="S4.T5.7.7.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T5.7.7.5.1" class="ltx_text" style="background-color:#FFE6E6;">13.3</span></td>
<td id="S4.T5.7.7.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T5.7.7.6.1" class="ltx_text" style="background-color:#E6E6FF;">39.78</span></td>
</tr>
<tr id="S4.T5.7.8" class="ltx_tr">
<td id="S4.T5.7.8.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T5.7.8.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedYogi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T5.7.8.2" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.8.2.1" class="ltx_text" style="background-color:#FFF2E6;">4.33</span></td>
<td id="S4.T5.7.8.3" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.8.3.1" class="ltx_text" style="background-color:#FFF2E6;">6.62</span></td>
<td id="S4.T5.7.8.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFF2E6;"><span id="S4.T5.7.8.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.48</span></td>
<td id="S4.T5.7.8.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T5.7.8.5.1" class="ltx_text" style="background-color:#FFE6E6;">11.3</span></td>
<td id="S4.T5.7.8.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T5.7.8.6.1" class="ltx_text" style="background-color:#E6E6FF;">40.27</span></td>
</tr>
<tr id="S4.T5.7.9" class="ltx_tr">
<td id="S4.T5.7.9.1" class="ltx_td ltx_align_left ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T5.7.9.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAdagrad <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T5.7.9.2" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.9.2.1" class="ltx_text" style="background-color:#FFF2E6;">4.40</span></td>
<td id="S4.T5.7.9.3" class="ltx_td ltx_align_center" style="background-color:#FFF2E6;"><span id="S4.T5.7.9.3.1" class="ltx_text" style="background-color:#FFF2E6;">6.79</span></td>
<td id="S4.T5.7.9.4" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFF2E6;"><span id="S4.T5.7.9.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.60</span></td>
<td id="S4.T5.7.9.5" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T5.7.9.5.1" class="ltx_text" style="background-color:#FFE6E6;">11.0</span></td>
<td id="S4.T5.7.9.6" class="ltx_td ltx_align_center" style="background-color:#E6E6FF;"><span id="S4.T5.7.9.6.1" class="ltx_text" style="background-color:#E6E6FF;">40.30</span></td>
</tr>
<tr id="S4.T5.7.10" class="ltx_tr">
<td id="S4.T5.7.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T5.7.10.1.1" class="ltx_text" style="background-color:#F2F2F2;">FedAdam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span></td>
<td id="S4.T5.7.10.2" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFF2E6;"><span id="S4.T5.7.10.2.1" class="ltx_text" style="background-color:#FFF2E6;">4.31</span></td>
<td id="S4.T5.7.10.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFF2E6;"><span id="S4.T5.7.10.3.1" class="ltx_text" style="background-color:#FFF2E6;">6.72</span></td>
<td id="S4.T5.7.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#FFF2E6;"><span id="S4.T5.7.10.4.1" class="ltx_text" style="background-color:#FFF2E6;">5.52</span></td>
<td id="S4.T5.7.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#FFE6E6;"><span id="S4.T5.7.10.5.1" class="ltx_text" style="background-color:#FFE6E6;">11.8</span></td>
<td id="S4.T5.7.10.6" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6FF;"><span id="S4.T5.7.10.6.1" class="ltx_text" style="background-color:#E6E6FF;">40.26</span></td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Further explorations</h3>

<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Experiments of exploration of efficient collaboration among languages. FedSimLang performs better than FedSamLang on some languages, indicating its partial effectiveness and calling for future works on constructing efficient collaboration structure to facilitate multilingual collaboration.</figcaption>
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T6.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Algorithm</td>
<td id="S4.T6.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">ar</td>
<td id="S4.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">es</td>
<td id="S4.T6.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">en</td>
<td id="S4.T6.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">fr</td>
<td id="S4.T6.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">pt</td>
<td id="S4.T6.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">ru</td>
<td id="S4.T6.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">zh</td>
<td id="S4.T6.1.1.9" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#F2F2F2;"><span id="S4.T6.1.1.9.1" class="ltx_text" style="background-color:#F2F2F2;">Average</span></td>
</tr>
<tr id="S4.T6.1.2" class="ltx_tr">
<td id="S4.T6.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Local</td>
<td id="S4.T6.1.2.2" class="ltx_td ltx_align_center ltx_border_t">2.55</td>
<td id="S4.T6.1.2.3" class="ltx_td ltx_align_center ltx_border_t">5.55</td>
<td id="S4.T6.1.2.4" class="ltx_td ltx_align_center ltx_border_t">7.20</td>
<td id="S4.T6.1.2.5" class="ltx_td ltx_align_center ltx_border_t">4.20</td>
<td id="S4.T6.1.2.6" class="ltx_td ltx_align_center ltx_border_t">3.85</td>
<td id="S4.T6.1.2.7" class="ltx_td ltx_align_center ltx_border_t">4.50</td>
<td id="S4.T6.1.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.95</td>
<td id="S4.T6.1.2.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T6.1.2.9.1" class="ltx_text" style="background-color:#F2F2F2;">4.69</span></td>
</tr>
<tr id="S4.T6.1.3" class="ltx_tr">
<td id="S4.T6.1.3.1" class="ltx_td ltx_align_left ltx_border_r">FedAvg</td>
<td id="S4.T6.1.3.2" class="ltx_td ltx_align_center">2.50</td>
<td id="S4.T6.1.3.3" class="ltx_td ltx_align_center">5.50</td>
<td id="S4.T6.1.3.4" class="ltx_td ltx_align_center"><span id="S4.T6.1.3.4.1" class="ltx_text ltx_font_bold">8.00</span></td>
<td id="S4.T6.1.3.5" class="ltx_td ltx_align_center">5.35</td>
<td id="S4.T6.1.3.6" class="ltx_td ltx_align_center"><span id="S4.T6.1.3.6.1" class="ltx_text ltx_font_bold">4.95</span></td>
<td id="S4.T6.1.3.7" class="ltx_td ltx_align_center"><span id="S4.T6.1.3.7.1" class="ltx_text ltx_font_bold">5.65</span></td>
<td id="S4.T6.1.3.8" class="ltx_td ltx_align_center ltx_border_r">5.25</td>
<td id="S4.T6.1.3.9" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T6.1.3.9.1" class="ltx_text" style="background-color:#F2F2F2;">5.31</span></td>
</tr>
<tr id="S4.T6.1.4" class="ltx_tr">
<td id="S4.T6.1.4.1" class="ltx_td ltx_align_left ltx_border_r">FedSamLang</td>
<td id="S4.T6.1.4.2" class="ltx_td ltx_align_center"><span id="S4.T6.1.4.2.1" class="ltx_text ltx_font_bold">3.30</span></td>
<td id="S4.T6.1.4.3" class="ltx_td ltx_align_center"><span id="S4.T6.1.4.3.1" class="ltx_text ltx_font_bold">5.90</span></td>
<td id="S4.T6.1.4.4" class="ltx_td ltx_align_center">7.65</td>
<td id="S4.T6.1.4.5" class="ltx_td ltx_align_center"><span id="S4.T6.1.4.5.1" class="ltx_text ltx_font_bold">6.45</span></td>
<td id="S4.T6.1.4.6" class="ltx_td ltx_align_center">4.10</td>
<td id="S4.T6.1.4.7" class="ltx_td ltx_align_center">4.80</td>
<td id="S4.T6.1.4.8" class="ltx_td ltx_align_center ltx_border_r">5.35</td>
<td id="S4.T6.1.4.9" class="ltx_td ltx_align_center" style="background-color:#F2F2F2;"><span id="S4.T6.1.4.9.1" class="ltx_text ltx_font_bold" style="background-color:#F2F2F2;">5.36</span></td>
</tr>
<tr id="S4.T6.1.5" class="ltx_tr">
<td id="S4.T6.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">FedSimLang</td>
<td id="S4.T6.1.5.2" class="ltx_td ltx_align_center ltx_border_bb">3.05</td>
<td id="S4.T6.1.5.3" class="ltx_td ltx_align_center ltx_border_bb">5.85</td>
<td id="S4.T6.1.5.4" class="ltx_td ltx_align_center ltx_border_bb">7.80</td>
<td id="S4.T6.1.5.5" class="ltx_td ltx_align_center ltx_border_bb">5.40</td>
<td id="S4.T6.1.5.6" class="ltx_td ltx_align_center ltx_border_bb">4.90</td>
<td id="S4.T6.1.5.7" class="ltx_td ltx_align_center ltx_border_bb">4.30</td>
<td id="S4.T6.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T6.1.5.8.1" class="ltx_text ltx_font_bold">5.75</span></td>
<td id="S4.T6.1.5.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F2F2F2;"><span id="S4.T6.1.5.9.1" class="ltx_text" style="background-color:#F2F2F2;">5.30</span></td>
</tr>
</table>
</figure>
<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Multilingual collaboration.</span>
We have observed in Table <a href="#S4.T2" title="Table 2 ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> that despite that FL methods achieve better performance than local training on average, they fail to bring consistent benefits on every specific language.
Such observation motivates us to explore language personalization.
Therefore, in this experiment, we construct two representative baselines: FedAvg among clients with the same language (FedSamLang) and FedAvg among clients with "similar" languages (FedSimLang) to explore the potential mutual benefits among languages.
We partition languages into five "similar" groups by their language family <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> as follows:
(1) Standard Arabic, Urdu, and Iranian Persian;
(2) French, Italian, Spanish, and Portuguese;
(3) English and German;
(4) Russian, Polish and Ukrainian;
(5) Simplified Chinese, Traditional Chinese, Japanese and Korean.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">We show the experimental results in Table <a href="#S4.T6" title="Table 6 ‣ 4.2 Further explorations ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, where we compare FedSamLang and FedSimLang with FedAvg (trained on 8 languages as previous experiments) and local training.
From the results, we can see that
(1) FedSamLang outperforms local training in all languages and achieves the highest average score, indicating the benefits of collaboration among clients with the same language.
(2) Compared to FedSamLang, FedSimLang performs better on 3 languages (i.e., en, pt, and zh) but worse on other languages, showing that leveraging the power of other languages can benefit some particular languages.
Though this observation verifies the possibility of multilingual collaboration, we need more future works to fully explore its potential.
(3) FedSamLang and FedSimLang perform better or comparably compared to FedAvg with fewer collaborators, indicating the effectiveness of language personalization.
These results call for future works on exploring personalization techniques that can strike a good balance between localization and collaboration or construct a better collaboration structure among these multilingual clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>.</p>
</div>
<figure id="S4.F6" class="ltx_figure ltx_align_floatright"><img src="/html/2406.04845/assets/figs/wildchat_dp.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="140" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Experiments on Fed-WildChat with differential privacy <math id="S4.F6.5.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.F6.5.m1.2b"><mrow id="S4.F6.5.m1.2.3.2" xref="S4.F6.5.m1.2.3.1.cmml"><mo stretchy="false" id="S4.F6.5.m1.2.3.2.1" xref="S4.F6.5.m1.2.3.1.cmml">(</mo><mi id="S4.F6.5.m1.1.1" xref="S4.F6.5.m1.1.1.cmml">ϵ</mi><mo id="S4.F6.5.m1.2.3.2.2" xref="S4.F6.5.m1.2.3.1.cmml">,</mo><mi id="S4.F6.5.m1.2.2" xref="S4.F6.5.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S4.F6.5.m1.2.3.2.3" xref="S4.F6.5.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.5.m1.2c"><interval closure="open" id="S4.F6.5.m1.2.3.1.cmml" xref="S4.F6.5.m1.2.3.2"><ci id="S4.F6.5.m1.1.1.cmml" xref="S4.F6.5.m1.1.1">italic-ϵ</ci><ci id="S4.F6.5.m1.2.2.cmml" xref="S4.F6.5.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.5.m1.2d">(\epsilon,\delta)</annotation></semantics></math> (<math id="S4.F6.6.m2.1" class="ltx_Math" alttext="\delta=1e^{-4}" display="inline"><semantics id="S4.F6.6.m2.1b"><mrow id="S4.F6.6.m2.1.1" xref="S4.F6.6.m2.1.1.cmml"><mi id="S4.F6.6.m2.1.1.2" xref="S4.F6.6.m2.1.1.2.cmml">δ</mi><mo id="S4.F6.6.m2.1.1.1" xref="S4.F6.6.m2.1.1.1.cmml">=</mo><mrow id="S4.F6.6.m2.1.1.3" xref="S4.F6.6.m2.1.1.3.cmml"><mn id="S4.F6.6.m2.1.1.3.2" xref="S4.F6.6.m2.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.F6.6.m2.1.1.3.1" xref="S4.F6.6.m2.1.1.3.1.cmml">​</mo><msup id="S4.F6.6.m2.1.1.3.3" xref="S4.F6.6.m2.1.1.3.3.cmml"><mi id="S4.F6.6.m2.1.1.3.3.2" xref="S4.F6.6.m2.1.1.3.3.2.cmml">e</mi><mrow id="S4.F6.6.m2.1.1.3.3.3" xref="S4.F6.6.m2.1.1.3.3.3.cmml"><mo id="S4.F6.6.m2.1.1.3.3.3b" xref="S4.F6.6.m2.1.1.3.3.3.cmml">−</mo><mn id="S4.F6.6.m2.1.1.3.3.3.2" xref="S4.F6.6.m2.1.1.3.3.3.2.cmml">4</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.6.m2.1c"><apply id="S4.F6.6.m2.1.1.cmml" xref="S4.F6.6.m2.1.1"><eq id="S4.F6.6.m2.1.1.1.cmml" xref="S4.F6.6.m2.1.1.1"></eq><ci id="S4.F6.6.m2.1.1.2.cmml" xref="S4.F6.6.m2.1.1.2">𝛿</ci><apply id="S4.F6.6.m2.1.1.3.cmml" xref="S4.F6.6.m2.1.1.3"><times id="S4.F6.6.m2.1.1.3.1.cmml" xref="S4.F6.6.m2.1.1.3.1"></times><cn type="integer" id="S4.F6.6.m2.1.1.3.2.cmml" xref="S4.F6.6.m2.1.1.3.2">1</cn><apply id="S4.F6.6.m2.1.1.3.3.cmml" xref="S4.F6.6.m2.1.1.3.3"><csymbol cd="ambiguous" id="S4.F6.6.m2.1.1.3.3.1.cmml" xref="S4.F6.6.m2.1.1.3.3">superscript</csymbol><ci id="S4.F6.6.m2.1.1.3.3.2.cmml" xref="S4.F6.6.m2.1.1.3.3.2">𝑒</ci><apply id="S4.F6.6.m2.1.1.3.3.3.cmml" xref="S4.F6.6.m2.1.1.3.3.3"><minus id="S4.F6.6.m2.1.1.3.3.3.1.cmml" xref="S4.F6.6.m2.1.1.3.3.3"></minus><cn type="integer" id="S4.F6.6.m2.1.1.3.3.3.2.cmml" xref="S4.F6.6.m2.1.1.3.3.3.2">4</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.6.m2.1d">\delta=1e^{-4}</annotation></semantics></math>). FedDP-x indicates <math id="S4.F6.7.m3.1" class="ltx_Math" alttext="\epsilon=x" display="inline"><semantics id="S4.F6.7.m3.1b"><mrow id="S4.F6.7.m3.1.1" xref="S4.F6.7.m3.1.1.cmml"><mi id="S4.F6.7.m3.1.1.2" xref="S4.F6.7.m3.1.1.2.cmml">ϵ</mi><mo id="S4.F6.7.m3.1.1.1" xref="S4.F6.7.m3.1.1.1.cmml">=</mo><mi id="S4.F6.7.m3.1.1.3" xref="S4.F6.7.m3.1.1.3.cmml">x</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.7.m3.1c"><apply id="S4.F6.7.m3.1.1.cmml" xref="S4.F6.7.m3.1.1"><eq id="S4.F6.7.m3.1.1.1.cmml" xref="S4.F6.7.m3.1.1.1"></eq><ci id="S4.F6.7.m3.1.1.2.cmml" xref="S4.F6.7.m3.1.1.2">italic-ϵ</ci><ci id="S4.F6.7.m3.1.1.3.cmml" xref="S4.F6.7.m3.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.7.m3.1d">\epsilon=x</annotation></semantics></math>. FedAvg with <math id="S4.F6.8.m4.2" class="ltx_Math" alttext="(1e^{-2},1e^{-4})" display="inline"><semantics id="S4.F6.8.m4.2b"><mrow id="S4.F6.8.m4.2.2.2" xref="S4.F6.8.m4.2.2.3.cmml"><mo stretchy="false" id="S4.F6.8.m4.2.2.2.3" xref="S4.F6.8.m4.2.2.3.cmml">(</mo><mrow id="S4.F6.8.m4.1.1.1.1" xref="S4.F6.8.m4.1.1.1.1.cmml"><mn id="S4.F6.8.m4.1.1.1.1.2" xref="S4.F6.8.m4.1.1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.F6.8.m4.1.1.1.1.1" xref="S4.F6.8.m4.1.1.1.1.1.cmml">​</mo><msup id="S4.F6.8.m4.1.1.1.1.3" xref="S4.F6.8.m4.1.1.1.1.3.cmml"><mi id="S4.F6.8.m4.1.1.1.1.3.2" xref="S4.F6.8.m4.1.1.1.1.3.2.cmml">e</mi><mrow id="S4.F6.8.m4.1.1.1.1.3.3" xref="S4.F6.8.m4.1.1.1.1.3.3.cmml"><mo id="S4.F6.8.m4.1.1.1.1.3.3b" xref="S4.F6.8.m4.1.1.1.1.3.3.cmml">−</mo><mn id="S4.F6.8.m4.1.1.1.1.3.3.2" xref="S4.F6.8.m4.1.1.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><mo id="S4.F6.8.m4.2.2.2.4" xref="S4.F6.8.m4.2.2.3.cmml">,</mo><mrow id="S4.F6.8.m4.2.2.2.2" xref="S4.F6.8.m4.2.2.2.2.cmml"><mn id="S4.F6.8.m4.2.2.2.2.2" xref="S4.F6.8.m4.2.2.2.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.F6.8.m4.2.2.2.2.1" xref="S4.F6.8.m4.2.2.2.2.1.cmml">​</mo><msup id="S4.F6.8.m4.2.2.2.2.3" xref="S4.F6.8.m4.2.2.2.2.3.cmml"><mi id="S4.F6.8.m4.2.2.2.2.3.2" xref="S4.F6.8.m4.2.2.2.2.3.2.cmml">e</mi><mrow id="S4.F6.8.m4.2.2.2.2.3.3" xref="S4.F6.8.m4.2.2.2.2.3.3.cmml"><mo id="S4.F6.8.m4.2.2.2.2.3.3b" xref="S4.F6.8.m4.2.2.2.2.3.3.cmml">−</mo><mn id="S4.F6.8.m4.2.2.2.2.3.3.2" xref="S4.F6.8.m4.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo stretchy="false" id="S4.F6.8.m4.2.2.2.5" xref="S4.F6.8.m4.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.8.m4.2c"><interval closure="open" id="S4.F6.8.m4.2.2.3.cmml" xref="S4.F6.8.m4.2.2.2"><apply id="S4.F6.8.m4.1.1.1.1.cmml" xref="S4.F6.8.m4.1.1.1.1"><times id="S4.F6.8.m4.1.1.1.1.1.cmml" xref="S4.F6.8.m4.1.1.1.1.1"></times><cn type="integer" id="S4.F6.8.m4.1.1.1.1.2.cmml" xref="S4.F6.8.m4.1.1.1.1.2">1</cn><apply id="S4.F6.8.m4.1.1.1.1.3.cmml" xref="S4.F6.8.m4.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.F6.8.m4.1.1.1.1.3.1.cmml" xref="S4.F6.8.m4.1.1.1.1.3">superscript</csymbol><ci id="S4.F6.8.m4.1.1.1.1.3.2.cmml" xref="S4.F6.8.m4.1.1.1.1.3.2">𝑒</ci><apply id="S4.F6.8.m4.1.1.1.1.3.3.cmml" xref="S4.F6.8.m4.1.1.1.1.3.3"><minus id="S4.F6.8.m4.1.1.1.1.3.3.1.cmml" xref="S4.F6.8.m4.1.1.1.1.3.3"></minus><cn type="integer" id="S4.F6.8.m4.1.1.1.1.3.3.2.cmml" xref="S4.F6.8.m4.1.1.1.1.3.3.2">2</cn></apply></apply></apply><apply id="S4.F6.8.m4.2.2.2.2.cmml" xref="S4.F6.8.m4.2.2.2.2"><times id="S4.F6.8.m4.2.2.2.2.1.cmml" xref="S4.F6.8.m4.2.2.2.2.1"></times><cn type="integer" id="S4.F6.8.m4.2.2.2.2.2.cmml" xref="S4.F6.8.m4.2.2.2.2.2">1</cn><apply id="S4.F6.8.m4.2.2.2.2.3.cmml" xref="S4.F6.8.m4.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.F6.8.m4.2.2.2.2.3.1.cmml" xref="S4.F6.8.m4.2.2.2.2.3">superscript</csymbol><ci id="S4.F6.8.m4.2.2.2.2.3.2.cmml" xref="S4.F6.8.m4.2.2.2.2.3.2">𝑒</ci><apply id="S4.F6.8.m4.2.2.2.2.3.3.cmml" xref="S4.F6.8.m4.2.2.2.2.3.3"><minus id="S4.F6.8.m4.2.2.2.2.3.3.1.cmml" xref="S4.F6.8.m4.2.2.2.2.3.3"></minus><cn type="integer" id="S4.F6.8.m4.2.2.2.2.3.3.2.cmml" xref="S4.F6.8.m4.2.2.2.2.3.3.2">4</cn></apply></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.8.m4.2d">(1e^{-2},1e^{-4})</annotation></semantics></math>-DP still outperforms local training without DP while ensuring user-level differential privacy.</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.7" class="ltx_p"><span id="S4.SS2.p3.7.1" class="ltx_text ltx_font_bold">Differential privacy.</span>
Here, we conduct experiments to evaluate the effectiveness of differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>, where we apply user-level differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>.
Experiments are conducted on our Fed-WildChat single-turn dataset; see more details in Appendix <a href="#A4" title="Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.
We fix the <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="\delta=1e^{-4}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">δ</mi><mo id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">=</mo><mrow id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml"><mn id="S4.SS2.p3.1.m1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.1.m1.1.1.3.1" xref="S4.SS2.p3.1.m1.1.1.3.1.cmml">​</mo><msup id="S4.SS2.p3.1.m1.1.1.3.3" xref="S4.SS2.p3.1.m1.1.1.3.3.cmml"><mi id="S4.SS2.p3.1.m1.1.1.3.3.2" xref="S4.SS2.p3.1.m1.1.1.3.3.2.cmml">e</mi><mrow id="S4.SS2.p3.1.m1.1.1.3.3.3" xref="S4.SS2.p3.1.m1.1.1.3.3.3.cmml"><mo id="S4.SS2.p3.1.m1.1.1.3.3.3a" xref="S4.SS2.p3.1.m1.1.1.3.3.3.cmml">−</mo><mn id="S4.SS2.p3.1.m1.1.1.3.3.3.2" xref="S4.SS2.p3.1.m1.1.1.3.3.3.2.cmml">4</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><eq id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1"></eq><ci id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">𝛿</ci><apply id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3"><times id="S4.SS2.p3.1.m1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3.1"></times><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.2">1</cn><apply id="S4.SS2.p3.1.m1.1.1.3.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3">superscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.3.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3.2">𝑒</ci><apply id="S4.SS2.p3.1.m1.1.1.3.3.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3.3"><minus id="S4.SS2.p3.1.m1.1.1.3.3.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3.3"></minus><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.3.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3.3.2">4</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\delta=1e^{-4}</annotation></semantics></math> and tune <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mi id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><ci id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\epsilon</annotation></semantics></math> in range of <math id="S4.SS2.p3.3.m3.4" class="ltx_Math" alttext="\{1e^{-3},1e^{-2},0.1,1\}" display="inline"><semantics id="S4.SS2.p3.3.m3.4a"><mrow id="S4.SS2.p3.3.m3.4.4.2" xref="S4.SS2.p3.3.m3.4.4.3.cmml"><mo stretchy="false" id="S4.SS2.p3.3.m3.4.4.2.3" xref="S4.SS2.p3.3.m3.4.4.3.cmml">{</mo><mrow id="S4.SS2.p3.3.m3.3.3.1.1" xref="S4.SS2.p3.3.m3.3.3.1.1.cmml"><mn id="S4.SS2.p3.3.m3.3.3.1.1.2" xref="S4.SS2.p3.3.m3.3.3.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.3.3.1.1.1" xref="S4.SS2.p3.3.m3.3.3.1.1.1.cmml">​</mo><msup id="S4.SS2.p3.3.m3.3.3.1.1.3" xref="S4.SS2.p3.3.m3.3.3.1.1.3.cmml"><mi id="S4.SS2.p3.3.m3.3.3.1.1.3.2" xref="S4.SS2.p3.3.m3.3.3.1.1.3.2.cmml">e</mi><mrow id="S4.SS2.p3.3.m3.3.3.1.1.3.3" xref="S4.SS2.p3.3.m3.3.3.1.1.3.3.cmml"><mo id="S4.SS2.p3.3.m3.3.3.1.1.3.3a" xref="S4.SS2.p3.3.m3.3.3.1.1.3.3.cmml">−</mo><mn id="S4.SS2.p3.3.m3.3.3.1.1.3.3.2" xref="S4.SS2.p3.3.m3.3.3.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="S4.SS2.p3.3.m3.4.4.2.4" xref="S4.SS2.p3.3.m3.4.4.3.cmml">,</mo><mrow id="S4.SS2.p3.3.m3.4.4.2.2" xref="S4.SS2.p3.3.m3.4.4.2.2.cmml"><mn id="S4.SS2.p3.3.m3.4.4.2.2.2" xref="S4.SS2.p3.3.m3.4.4.2.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.4.4.2.2.1" xref="S4.SS2.p3.3.m3.4.4.2.2.1.cmml">​</mo><msup id="S4.SS2.p3.3.m3.4.4.2.2.3" xref="S4.SS2.p3.3.m3.4.4.2.2.3.cmml"><mi id="S4.SS2.p3.3.m3.4.4.2.2.3.2" xref="S4.SS2.p3.3.m3.4.4.2.2.3.2.cmml">e</mi><mrow id="S4.SS2.p3.3.m3.4.4.2.2.3.3" xref="S4.SS2.p3.3.m3.4.4.2.2.3.3.cmml"><mo id="S4.SS2.p3.3.m3.4.4.2.2.3.3a" xref="S4.SS2.p3.3.m3.4.4.2.2.3.3.cmml">−</mo><mn id="S4.SS2.p3.3.m3.4.4.2.2.3.3.2" xref="S4.SS2.p3.3.m3.4.4.2.2.3.3.2.cmml">2</mn></mrow></msup></mrow><mo id="S4.SS2.p3.3.m3.4.4.2.5" xref="S4.SS2.p3.3.m3.4.4.3.cmml">,</mo><mn id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">0.1</mn><mo id="S4.SS2.p3.3.m3.4.4.2.6" xref="S4.SS2.p3.3.m3.4.4.3.cmml">,</mo><mn id="S4.SS2.p3.3.m3.2.2" xref="S4.SS2.p3.3.m3.2.2.cmml">1</mn><mo stretchy="false" id="S4.SS2.p3.3.m3.4.4.2.7" xref="S4.SS2.p3.3.m3.4.4.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.4b"><set id="S4.SS2.p3.3.m3.4.4.3.cmml" xref="S4.SS2.p3.3.m3.4.4.2"><apply id="S4.SS2.p3.3.m3.3.3.1.1.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1"><times id="S4.SS2.p3.3.m3.3.3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.1"></times><cn type="integer" id="S4.SS2.p3.3.m3.3.3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.2">1</cn><apply id="S4.SS2.p3.3.m3.3.3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.3.3.1.1.3.1.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.3">superscript</csymbol><ci id="S4.SS2.p3.3.m3.3.3.1.1.3.2.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.3.2">𝑒</ci><apply id="S4.SS2.p3.3.m3.3.3.1.1.3.3.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.3.3"><minus id="S4.SS2.p3.3.m3.3.3.1.1.3.3.1.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p3.3.m3.3.3.1.1.3.3.2.cmml" xref="S4.SS2.p3.3.m3.3.3.1.1.3.3.2">3</cn></apply></apply></apply><apply id="S4.SS2.p3.3.m3.4.4.2.2.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2"><times id="S4.SS2.p3.3.m3.4.4.2.2.1.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.1"></times><cn type="integer" id="S4.SS2.p3.3.m3.4.4.2.2.2.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.2">1</cn><apply id="S4.SS2.p3.3.m3.4.4.2.2.3.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.3"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.4.4.2.2.3.1.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.3">superscript</csymbol><ci id="S4.SS2.p3.3.m3.4.4.2.2.3.2.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.3.2">𝑒</ci><apply id="S4.SS2.p3.3.m3.4.4.2.2.3.3.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.3.3"><minus id="S4.SS2.p3.3.m3.4.4.2.2.3.3.1.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.3.3"></minus><cn type="integer" id="S4.SS2.p3.3.m3.4.4.2.2.3.3.2.cmml" xref="S4.SS2.p3.3.m3.4.4.2.2.3.3.2">2</cn></apply></apply></apply><cn type="float" id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">0.1</cn><cn type="integer" id="S4.SS2.p3.3.m3.2.2.cmml" xref="S4.SS2.p3.3.m3.2.2">1</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.4c">\{1e^{-3},1e^{-2},0.1,1\}</annotation></semantics></math> that satisfies <math id="S4.SS2.p3.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.SS2.p3.4.m4.2a"><mrow id="S4.SS2.p3.4.m4.2.3.2" xref="S4.SS2.p3.4.m4.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.p3.4.m4.2.3.2.1" xref="S4.SS2.p3.4.m4.2.3.1.cmml">(</mo><mi id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml">ϵ</mi><mo id="S4.SS2.p3.4.m4.2.3.2.2" xref="S4.SS2.p3.4.m4.2.3.1.cmml">,</mo><mi id="S4.SS2.p3.4.m4.2.2" xref="S4.SS2.p3.4.m4.2.2.cmml">δ</mi><mo stretchy="false" id="S4.SS2.p3.4.m4.2.3.2.3" xref="S4.SS2.p3.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.2b"><interval closure="open" id="S4.SS2.p3.4.m4.2.3.1.cmml" xref="S4.SS2.p3.4.m4.2.3.2"><ci id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">italic-ϵ</ci><ci id="S4.SS2.p3.4.m4.2.2.cmml" xref="S4.SS2.p3.4.m4.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-differential privacy, and report the results in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.2 Further explorations ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
Results show that
(1) FedAvg with <math id="S4.SS2.p3.5.m5.2" class="ltx_Math" alttext="(1,1e^{-4})" display="inline"><semantics id="S4.SS2.p3.5.m5.2a"><mrow id="S4.SS2.p3.5.m5.2.2.1" xref="S4.SS2.p3.5.m5.2.2.2.cmml"><mo stretchy="false" id="S4.SS2.p3.5.m5.2.2.1.2" xref="S4.SS2.p3.5.m5.2.2.2.cmml">(</mo><mn id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml">1</mn><mo id="S4.SS2.p3.5.m5.2.2.1.3" xref="S4.SS2.p3.5.m5.2.2.2.cmml">,</mo><mrow id="S4.SS2.p3.5.m5.2.2.1.1" xref="S4.SS2.p3.5.m5.2.2.1.1.cmml"><mn id="S4.SS2.p3.5.m5.2.2.1.1.2" xref="S4.SS2.p3.5.m5.2.2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.5.m5.2.2.1.1.1" xref="S4.SS2.p3.5.m5.2.2.1.1.1.cmml">​</mo><msup id="S4.SS2.p3.5.m5.2.2.1.1.3" xref="S4.SS2.p3.5.m5.2.2.1.1.3.cmml"><mi id="S4.SS2.p3.5.m5.2.2.1.1.3.2" xref="S4.SS2.p3.5.m5.2.2.1.1.3.2.cmml">e</mi><mrow id="S4.SS2.p3.5.m5.2.2.1.1.3.3" xref="S4.SS2.p3.5.m5.2.2.1.1.3.3.cmml"><mo id="S4.SS2.p3.5.m5.2.2.1.1.3.3a" xref="S4.SS2.p3.5.m5.2.2.1.1.3.3.cmml">−</mo><mn id="S4.SS2.p3.5.m5.2.2.1.1.3.3.2" xref="S4.SS2.p3.5.m5.2.2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><mo stretchy="false" id="S4.SS2.p3.5.m5.2.2.1.4" xref="S4.SS2.p3.5.m5.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.2b"><interval closure="open" id="S4.SS2.p3.5.m5.2.2.2.cmml" xref="S4.SS2.p3.5.m5.2.2.1"><cn type="integer" id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1">1</cn><apply id="S4.SS2.p3.5.m5.2.2.1.1.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1"><times id="S4.SS2.p3.5.m5.2.2.1.1.1.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.1"></times><cn type="integer" id="S4.SS2.p3.5.m5.2.2.1.1.2.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.2">1</cn><apply id="S4.SS2.p3.5.m5.2.2.1.1.3.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.5.m5.2.2.1.1.3.1.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.3">superscript</csymbol><ci id="S4.SS2.p3.5.m5.2.2.1.1.3.2.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.3.2">𝑒</ci><apply id="S4.SS2.p3.5.m5.2.2.1.1.3.3.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.3.3"><minus id="S4.SS2.p3.5.m5.2.2.1.1.3.3.1.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p3.5.m5.2.2.1.1.3.3.2.cmml" xref="S4.SS2.p3.5.m5.2.2.1.1.3.3.2">4</cn></apply></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.2c">(1,1e^{-4})</annotation></semantics></math>-differential privacy can achieve comparable performance compared to FedAvg without differential privacy.
(2) With the reduction of <math id="S4.SS2.p3.6.m6.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS2.p3.6.m6.1a"><mi id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><ci id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">\epsilon</annotation></semantics></math>, the privacy preservation improves while the performance degrades.
FedAvg with <math id="S4.SS2.p3.7.m7.2" class="ltx_Math" alttext="(1e^{-3},1e^{-4})" display="inline"><semantics id="S4.SS2.p3.7.m7.2a"><mrow id="S4.SS2.p3.7.m7.2.2.2" xref="S4.SS2.p3.7.m7.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.p3.7.m7.2.2.2.3" xref="S4.SS2.p3.7.m7.2.2.3.cmml">(</mo><mrow id="S4.SS2.p3.7.m7.1.1.1.1" xref="S4.SS2.p3.7.m7.1.1.1.1.cmml"><mn id="S4.SS2.p3.7.m7.1.1.1.1.2" xref="S4.SS2.p3.7.m7.1.1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.7.m7.1.1.1.1.1" xref="S4.SS2.p3.7.m7.1.1.1.1.1.cmml">​</mo><msup id="S4.SS2.p3.7.m7.1.1.1.1.3" xref="S4.SS2.p3.7.m7.1.1.1.1.3.cmml"><mi id="S4.SS2.p3.7.m7.1.1.1.1.3.2" xref="S4.SS2.p3.7.m7.1.1.1.1.3.2.cmml">e</mi><mrow id="S4.SS2.p3.7.m7.1.1.1.1.3.3" xref="S4.SS2.p3.7.m7.1.1.1.1.3.3.cmml"><mo id="S4.SS2.p3.7.m7.1.1.1.1.3.3a" xref="S4.SS2.p3.7.m7.1.1.1.1.3.3.cmml">−</mo><mn id="S4.SS2.p3.7.m7.1.1.1.1.3.3.2" xref="S4.SS2.p3.7.m7.1.1.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="S4.SS2.p3.7.m7.2.2.2.4" xref="S4.SS2.p3.7.m7.2.2.3.cmml">,</mo><mrow id="S4.SS2.p3.7.m7.2.2.2.2" xref="S4.SS2.p3.7.m7.2.2.2.2.cmml"><mn id="S4.SS2.p3.7.m7.2.2.2.2.2" xref="S4.SS2.p3.7.m7.2.2.2.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.7.m7.2.2.2.2.1" xref="S4.SS2.p3.7.m7.2.2.2.2.1.cmml">​</mo><msup id="S4.SS2.p3.7.m7.2.2.2.2.3" xref="S4.SS2.p3.7.m7.2.2.2.2.3.cmml"><mi id="S4.SS2.p3.7.m7.2.2.2.2.3.2" xref="S4.SS2.p3.7.m7.2.2.2.2.3.2.cmml">e</mi><mrow id="S4.SS2.p3.7.m7.2.2.2.2.3.3" xref="S4.SS2.p3.7.m7.2.2.2.2.3.3.cmml"><mo id="S4.SS2.p3.7.m7.2.2.2.2.3.3a" xref="S4.SS2.p3.7.m7.2.2.2.2.3.3.cmml">−</mo><mn id="S4.SS2.p3.7.m7.2.2.2.2.3.3.2" xref="S4.SS2.p3.7.m7.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo stretchy="false" id="S4.SS2.p3.7.m7.2.2.2.5" xref="S4.SS2.p3.7.m7.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.7.m7.2b"><interval closure="open" id="S4.SS2.p3.7.m7.2.2.3.cmml" xref="S4.SS2.p3.7.m7.2.2.2"><apply id="S4.SS2.p3.7.m7.1.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1"><times id="S4.SS2.p3.7.m7.1.1.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.1"></times><cn type="integer" id="S4.SS2.p3.7.m7.1.1.1.1.2.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.2">1</cn><apply id="S4.SS2.p3.7.m7.1.1.1.1.3.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.7.m7.1.1.1.1.3.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.3">superscript</csymbol><ci id="S4.SS2.p3.7.m7.1.1.1.1.3.2.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.3.2">𝑒</ci><apply id="S4.SS2.p3.7.m7.1.1.1.1.3.3.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.3.3"><minus id="S4.SS2.p3.7.m7.1.1.1.1.3.3.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p3.7.m7.1.1.1.1.3.3.2.cmml" xref="S4.SS2.p3.7.m7.1.1.1.1.3.3.2">3</cn></apply></apply></apply><apply id="S4.SS2.p3.7.m7.2.2.2.2.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2"><times id="S4.SS2.p3.7.m7.2.2.2.2.1.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.1"></times><cn type="integer" id="S4.SS2.p3.7.m7.2.2.2.2.2.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.2">1</cn><apply id="S4.SS2.p3.7.m7.2.2.2.2.3.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.SS2.p3.7.m7.2.2.2.2.3.1.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.3">superscript</csymbol><ci id="S4.SS2.p3.7.m7.2.2.2.2.3.2.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.3.2">𝑒</ci><apply id="S4.SS2.p3.7.m7.2.2.2.2.3.3.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.3.3"><minus id="S4.SS2.p3.7.m7.2.2.2.2.3.3.1.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.3.3"></minus><cn type="integer" id="S4.SS2.p3.7.m7.2.2.2.2.3.3.2.cmml" xref="S4.SS2.p3.7.m7.2.2.2.2.3.3.2">4</cn></apply></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.7.m7.2c">(1e^{-3},1e^{-4})</annotation></semantics></math>-differential privacy can achieve comparable performance compared to local training without differential privacy technique.
To the best of our knowledge, this is the first time in the literature demonstrating the results of differential privacy in FedLLM.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">Federated learning enables multiple parties to collaboratively train large language models without sharing their raw data (FedLLM), which has attracted many research efforts from the community.
In this paper, we propose the first realistic benchmark for FedLLM, FedLLM-Bench, which involves 8 training methods, 4 training datasets, and 6 evaluation metrics.
The core contribution lies in the datasets, which cover a wide range of client scale and two common tasks (i.e., instruction tuning and preference alignment).
These datasets exhibit many real-world diversities, including language, quality, quantity, instruction, sequence length, embedding, and preference, mirroring real-world scenarios.
Based on FedLLM-Bench, we conduct extensive experiments on all datasets to benchmark classical FL methods.
Besides, we also conduct experiments to explore the effective collaboration strategies of cross-language collaboration and show results when incorporating differential privacy with federated instruction tuning.
We believe that our FedLLM-Bench could benefit the FedLLM community by reducing required efforts, providing a practical testbed, and promoting fair comparisons.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.08774</span>, 2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">NIPS</span>, 35:27730–27744, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, et al.

</span>
<span class="ltx_bibblock">Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, et al.

</span>
<span class="ltx_bibblock">Metagpt: Meta programming for multi-agent collaborative framework.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Kevin Maik Jablonka, Philippe Schwaller, Andres Ortega-Guerrero, and Berend Smit.

</span>
<span class="ltx_bibblock">Leveraging large language models for predictive chemistry.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, pages 1–9, 2024.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pages 1273–1282. PMLR, 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Foundations and Trends® in Machine Learning</span>, 14(1–2):1–210, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Rui Ye, Wenhao Wang, Jingyi Chai, Dihan Li, Zexi Li, Yinda Xu, Yaxin Du, Yanfeng Wang, and Siheng Chen.

</span>
<span class="ltx_bibblock">Openfedllm: Training large language models on decentralized private data via federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.06954</span>, 2024.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Weirui Kuang, Bingchen Qian, Zitao Li, Daoyuan Chen, Dawei Gao, Xuchen Pan, Yuexiang Xie, Yaliang Li, Bolin Ding, and Jingren Zhou.

</span>
<span class="ltx_bibblock">Federatedscope-llm: A comprehensive package for fine-tuning large language models in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2309.00363</span>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
FedML Inc.

</span>
<span class="ltx_bibblock">Federated learning on large language models (llms).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doc.fedml.ai/federate/fedllm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doc.fedml.ai/federate/fedllm</a>, 2023.

</span>
<span class="ltx_bibblock">Accessed: 2024-03-31.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Wanru Zhao, Yaxin Du, Nicholas Donald Lane, Siheng Chen, and Yanfeng Wang.

</span>
<span class="ltx_bibblock">Enhancing data quality in federated fine-tuning of foundation models.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2403.04529</span>, 2024.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Feijie Wu, Zitao Li, Yaliang Li, Bolin Ding, and Jing Gao.

</span>
<span class="ltx_bibblock">FedbiOT: a solution for federated large language model fine-tuning with intellectual property protection, 2024.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Youbang Sun, Zitao Li, Yaliang Li, and Bolin Ding.

</span>
<span class="ltx_bibblock">Improving loRA in privacy-preserving federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Zihan Fang, Zheng Lin, Zhe Chen, Xianhao Chen, Yue Gao, and Yuguang Fang.

</span>
<span class="ltx_bibblock">Automated federated pipeline for parameter-efficient fine-tuning of large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2404.06448</span>, 2024.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Jean Ogier du Terrail, Samy-Safwan Ayed, Edwige Cyffers, Felix Grimberg, Chaoyang He, Regis Loeb, Paul Mangold, Tanguy Marchand, Othmane Marfoq, Erum Mushtaq, et al.

</span>
<span class="ltx_bibblock">Flamby: Datasets and benchmarks for cross-silo federated learning in realistic healthcare settings.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 35:5315–5334, 2022.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Congzheng Song, Filip Granqvist, and Kunal Talwar.

</span>
<span class="ltx_bibblock">Flair: Federated learning annotated image repository.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 35:37792–37805, 2022.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Zhuo Zhang, Jingyuan Zhang, Jintao Huang, Lizhen Qu, Hongzhi Zhang, and Zenglin Xu.

</span>
<span class="ltx_bibblock">Fedpit: Towards privacy-preserving and few-shot federated instruction tuning.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2403.06131</span>, 2024.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konečnỳ, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.01097</span>, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Sungwon Han, Sungwon Park, Fangzhao Wu, Sundong Kim, Chuhan Wu, Xing Xie, and Meeyoung Cha.

</span>
<span class="ltx_bibblock">Fedx: Unsupervised federated learning with cross knowledge distillation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, pages 691–707. Springer, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Sungwon Park, Sungwon Han, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, and Meeyoung Cha.

</span>
<span class="ltx_bibblock">Feddefender: Client-side attack-tolerant federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</span>, pages 1850–1861, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Peihua Mai and Yan Pang.

</span>
<span class="ltx_bibblock">Vertical federated graph neural network for recommender system.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 23516–23535. PMLR, 2023.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Jingwei Yi, Fangzhao Wu, Chuhan Wu, Ruixuan Liu, Guangzhong Sun, and Xing Xie.

</span>
<span class="ltx_bibblock">Efficient-fedrec: Efficient federated learning framework for privacy-preserving news recommendation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</span>, pages 2814–2824, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.

</span>
<span class="ltx_bibblock">Measuring the effects of non-identical data distribution for federated visual classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.06335</span>, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Rui Ye, Mingkai Xu, Jianyu Wang, Chenxin Xu, Siheng Chen, and Yanfeng Wang.

</span>
<span class="ltx_bibblock">Feddisco: Federated learning with discrepancy-aware collaboration.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 39879–39902. PMLR, 2023.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Zexi Li, Xinyi Shang, Rui He, Tao Lin, and Chao Wu.

</span>
<span class="ltx_bibblock">No fear of classifier biases: Neural collapse inspired federated learning with synthetic and fixed classifier.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 5319–5329, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Ziqing Fan, Shengchao Hu, Jiangchao Yao, Gang Niu, Ya Zhang, Masashi Sugiyama, and Yanfeng Wang.

</span>
<span class="ltx_bibblock">Locally estimated global perturbations are better than local perturbations for federated sharpness-aware minimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.18890</span>, 2024.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Peihua Mai, Ran Yan, and Yan Pang.

</span>
<span class="ltx_bibblock">Rflpa: A robust federated learning framework against poisoning attacks with secure aggregation.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.15182</span>, 2024.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ziqing Fan, Jiangchao Yao, Bo Han, Ya Zhang, Yanfeng Wang, et al.

</span>
<span class="ltx_bibblock">Federated learning with bilateral curation for partially class-disjoint data.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2024.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine Learning and Systems</span>, 2:429–450, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Qinbin Li, Bingsheng He, and Dawn Song.

</span>
<span class="ltx_bibblock">Model-contrastive federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 10713–10722, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Jianqing Zhang, Yang Liu, Yang Hua, and Jian Cao.

</span>
<span class="ltx_bibblock">An upload-efficient scheme for transferring knowledge from a server-side pre-trained generator to clients in heterogeneous federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, 2024.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Jianqing Zhang, Yang Liu, Yang Hua, and Jian Cao.

</span>
<span class="ltx_bibblock">Fedtgp: Trainable global prototypes with adaptive-margin-enhanced contrastive learning for data and model heterogeneity in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</span>, 2024.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Tackling the objective inconsistency problem in heterogeneous federated optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 33:7611–7623, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Zexi Li, Tao Lin, Xinyi Shang, and Chao Wu.

</span>
<span class="ltx_bibblock">Revisiting weighted aggregation in federated learning with neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 19767–19788. PMLR, 2023.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Sashank J Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konečnỳ, Sanjiv Kumar, and Hugh Brendan McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
John Nguyen, Jianyu Wang, Kshitiz Malik, Maziar Sanjabi, and Michael Rabbat.

</span>
<span class="ltx_bibblock">Where to begin? on the impact of pre-training and initialization in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">The Eleventh International Conference on Learning Representations</span>, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Hong-You Chen, Cheng-Hao Tu, Ziwei Li, Han Wei Shen, and Wei-Lun Chao.

</span>
<span class="ltx_bibblock">On the importance and applicability of pre-training for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">The Eleventh International Conference on Learning Representations</span>, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.13971</span>, 2023.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.06825</span>, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann.

</span>
<span class="ltx_bibblock">Bloomberggpt: A large language model for finance.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.17564</span>, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Siqiao Xue, Caigao Jiang, Wenhui Shi, Fangyin Cheng, Keting Chen, Hongjun Yang, Zhiping Zhang, Jianshan He, Hongyang Zhang, Ganglin Wei, et al.

</span>
<span class="ltx_bibblock">Db-gpt: Empowering database interactions with private large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2312.17449</span>, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Shivalika Singh, Freddie Vargus, Daniel Dsouza, Börje F Karlsson, Abinaya Mahendiran, Wei-Yin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura OMahony, et al.

</span>
<span class="ltx_bibblock">Aya dataset: An open-access collection for multilingual instruction tuning.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.06619</span>, 2024.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng.

</span>
<span class="ltx_bibblock">Wildchat: 1m chatGPT interaction logs in the wild.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Han Xiao, Kashif Rasul, and Roland Vollgraf.

</span>
<span class="ltx_bibblock">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1708.07747</span>, 2017.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Li Deng.

</span>
<span class="ltx_bibblock">The mnist database of handwritten digit images for machine learning research [best of the web].

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">IEEE signal processing magazine</span>, 29(6):141–142, 2012.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 22631–22648. PMLR, 2023.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex instructions.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.12244</span>, 2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Hannah Kirk, Andrew Bean, Bertie Vidgen, Paul Röttger, and Scott Hale.

</span>
<span class="ltx_bibblock">The past, present and better future of feedback learning in large language models for subjective human preferences and values.

</span>
<span class="ltx_bibblock">In <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</span>, pages 2409–2430, 2023.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2023.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi Zhang, Ce Bian, Boyuan Chen, Ruiyang Sun, Yizhou Wang, and Yaodong Yang.

</span>
<span class="ltx_bibblock">Beavertails: Towards improved safety alignment of llm via a human-preference dataset.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2024.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al.

</span>
<span class="ltx_bibblock">Constitutional ai: Harmlessness from ai feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2212.08073</span>, 2022.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2021.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</span>, 10(2):1–19, 2019.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H Brendan McMahan, Maruan Al-Shedivat, Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data, et al.

</span>
<span class="ltx_bibblock">A field guide to federated optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2107.06917</span>, 2021.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
The Aya Project.

</span>
<span class="ltx_bibblock">Aya: An open science initiative to accelerate multilingual ai progress.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aya.for.ai" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aya.for.ai</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-06-02.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Ittai Dayan, Holger R Roth, Aoxiao Zhong, Ahmed Harouni, Amilcare Gentili, Anas Z Abidin, Andrew Liu, Anthony Beardsworth Costa, Bradford J Wood, Chien-Sung Tsai, et al.

</span>
<span class="ltx_bibblock">Federated learning for predicting clinical outcomes in patients with covid-19.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Nature medicine</span>, 27(10):1735–1743, 2021.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
InternLM Team.

</span>
<span class="ltx_bibblock">Internlm: A multilingual language model with progressively enhanced capabilities, 2023.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language models with self-generated instructions.

</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2212.10560</span>, 2022.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Nikita Kitaev and Dan Klein.

</span>
<span class="ltx_bibblock">Constituency parsing with a self-attentive encoder.

</span>
<span class="ltx_bibblock">In <span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 2676–2686, 2018.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, and Jing Xiao.

</span>
<span class="ltx_bibblock">From quantity to quality: Boosting llm performance with self-guided data selection for instruction tuning.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.12032</span>, 2023.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Laurens Van der Maaten and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Visualizing data using t-sne.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">Journal of machine learning research</span>, 9(11), 2008.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing.

</span>
<span class="ltx_bibblock">Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J. Zico Kolter, and Matt Fredrikson.

</span>
<span class="ltx_bibblock">Universal and transferable adversarial attacks on aligned language models, 2023.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Ahmet Üstün, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D’souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker.

</span>
<span class="ltx_bibblock">Aya model: An instruction finetuned open-access multilingual language model, 2024.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Yew Ken Chia, Pengfei Hong, Lidong Bing, and Soujanya Poria.

</span>
<span class="ltx_bibblock">InstructEval: Towards holistic evaluation of instruction-tuned large language models.

</span>
<span class="ltx_bibblock">In Antonio Valerio Miceli-Barone, Fazl Barez, Shay Cohen, Elena Voita, Ulrich Germann, and Michal Lukasik, editors, <span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">Proceedings of the First edition of the Workshop on the Scaling Behavior of Large Language Models (SCALE-LLM 2024)</span>, pages 35–64, St. Julian’s, Malta, March 2024. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding, 2021.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code, 2021.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith.

</span>
<span class="ltx_bibblock">Ditto: Fair and robust federated learning through personalization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 6357–6368. PMLR, 2021.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Rui Ye, Zhenyang Ni, Fangzhao Wu, Siheng Chen, and Yanfeng Wang.

</span>
<span class="ltx_bibblock">Personalized federated learning with inferred collaboration graphs.

</span>
<span class="ltx_bibblock">In <span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 39801–39817. PMLR, 2023.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al.

</span>
<span class="ltx_bibblock">Training a helpful and harmless assistant with reinforcement learning from human feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2204.05862</span>, 2022.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, et al.

</span>
<span class="ltx_bibblock">Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned.

</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2209.07858</span>, 2022.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Quentin D Atkinson and Russell D Gray.

</span>
<span class="ltx_bibblock">How old is the indo-european language family? illumination or more moths to the flame.

</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">Phylogenetic methods and the prehistory of languages</span>, 91:109, 2006.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.

</span>
<span class="ltx_bibblock">Calibrating noise to sensitivity in private data analysis.

</span>
<span class="ltx_bibblock">In <span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3</span>, pages 265–284. Springer, 2006.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Hang Su, Bo Zhang, and H. Vincent Poor.

</span>
<span class="ltx_bibblock">Performance analysis and optimization in privacy-preserving federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2003.00229, 2020.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang, Ning Cheng, and Tianyi Zhou.

</span>
<span class="ltx_bibblock">Superfiltering: Weak-to-strong data filtering for fast instruction-tuning.

</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.00530</span>, 2024.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, and Junxian He.

</span>
<span class="ltx_bibblock">What makes good data for alignment? a comprehensive study of automatic data selection in instruction tuning.

</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2312.15685</span>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Limitations</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<p id="A1.p1.1" class="ltx_p">Firstly, we explore Llama-2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> for instruction tuning task and Alpaca <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> for preference alignment task.
More future works are required to explore more model series and sizes.
Secondly, safety alignment is also an important topic in the era of LLMs, which is not comprehensively covered in our paper.
This could be an interesting and promising future direction.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Datasets</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Lengths measurement</h3>

<div id="A2.SS1.p1" class="ltx_para ltx_noindent">
<p id="A2.SS1.p1.1" class="ltx_p">To measure each data sample, We use Llama2 tokenizer to tokenize the instruction and response of each data sample and use the number of tokens as the sentence length. Figure <a href="#S3.F1.sf2" title="In Figure 1 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> shows the distribution of length of instruction and response of clients’ data of our four datasets.</p>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Verbs and nouns</h3>

<figure id="A2.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A2.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/Aya_verb_noun_sunburst.png" id="A2.F7.sf1.g1" class="ltx_graphics ltx_img_square" width="287" height="287" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Aya</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A2.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/Chatbot_verb_noun_sunburst.png" id="A2.F7.sf2.g1" class="ltx_graphics ltx_img_square" width="287" height="287" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>ChatbotIT</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A2.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/WildChat_verb_noun_sunburst.png" id="A2.F7.sf3.g1" class="ltx_graphics ltx_img_square" width="287" height="287" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>WildChat</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A2.F7.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04845/assets/figs/Chatbot-dpo_verb_noun_sunburst.png" id="A2.F7.sf4.g1" class="ltx_graphics ltx_img_square" width="287" height="287" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>ChatbotPA</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The top 20 most common root verbs (inner circle) and their top 4 direct noun objects (outer circle) in the instructions of four datasets. </figcaption>
</figure>
<div id="A2.SS2.p1" class="ltx_para ltx_noindent">
<p id="A2.SS2.p1.1" class="ltx_p">We show the top 20 verbs and corresponding top 4 nouns of instructions of overall four datasets in Figure <a href="#A2.F7" title="Figure 7 ‣ B.2 Verbs and nouns ‣ Appendix B Datasets ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We refer to the visualization code of Self-instruct <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. Note that for all four datasets, we choose clients with English samples. From Figure <a href="#A2.F7" title="Figure 7 ‣ B.2 Verbs and nouns ‣ Appendix B Datasets ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we can observe that different datasets possess diverse instruction types and distributions. For example, the top 2 verbs for Aya and WildChat datasets are (explain, write) and (write, make), respectively; While ChatbotIT and ChatbotPA, which are from the same public dataset, have a large range of keyword overlap but different quantity distributions.</p>
</div>
<div id="A2.SS2.p2" class="ltx_para ltx_noindent">
<p id="A2.SS2.p2.1" class="ltx_p">We also show the top 20 verbs and corresponding top 4 nouns of instructions of individual clients from four datasets in Figure <a href="#A4.F9" title="Figure 9 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, Figure <a href="#A4.F10" title="Figure 10 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, Figure <a href="#A4.F11" title="Figure 11 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> and Figure <a href="#A4.F12" title="Figure 12 ‣ D.3 Experiment details of differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>. For all four datasets, we choose clients with English samples to present verbs and nouns in their instructions.</p>
</div>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Quality evaluation</h3>

<div id="A2.SS3.p1" class="ltx_para ltx_noindent">
<p id="A2.SS3.p1.1" class="ltx_p">We conduct data quality evaluation with the pre-trained Llama2-7B <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and the IFD metric <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. IFD is a quality evaluation metric, qualifying the instruction-following difficulty of the given model as the data quality. It has been widely used in  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>. From Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we can see that clients in four datasets have various data qualities. This indicates these four federated datasets demonstrate quality heterogeneity, which is an inherent property of real data sets.</p>
</div>
</section>
<section id="A2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>t-SNE visualization</h3>

<div id="A2.SS4.p1" class="ltx_para ltx_noindent">
<p id="A2.SS4.p1.1" class="ltx_p">We also implement the t-SNE instruction-response embedding in four datasets. Here the <span id="A2.SS4.p1.1.1" class="ltx_text ltx_font_italic">’text-embedding-ada-002’</span> from OpenAI is utilized as the feature extraction model. We randomly select 10 clients from each dataset and use the t-SNE two-dimensional visualization to demonstrate the data heterogeneity from each client. From Figure <a href="#S3.F4" title="Figure 4 ‣ 3.2 Descriptions of training datasets ‣ 3 FedLLM-Bench: a realistic benchmark for FedLLM ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we could see that data points from the same client cluster in the feature space. This is particularly evident in Fed-Aya and Fed-WildChat, demonstrating data heterogeneity within the dataset.</p>
</div>
</section>
<section id="A2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.5 </span>Discussion about data privacy and safety</h3>

<div id="A2.SS5.p1" class="ltx_para ltx_noindent">
<p id="A2.SS5.p1.1" class="ltx_p">The base datasets we construct ours from have already undergone screenings for safety and privacy. For example, in Chatbot-arena Conversations dataset, most conversations that contain personally identifiable information have been moved. Fed-ChatbotIT, Fed-ChatbotPA and Fed-WildChat, which are based on Chatbot-arena Conversations dataset and WildChat dataset, may contain unsafe or toxic interacts, but they are kept so that these datasets can be better used to study AI safety and simulate real-world dialogue scenarios.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experiments</h2>

<figure id="A3.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Experimental setups of all datasets. ‘Local epochs’ denotes the number of training epochs in local training. In the column of ‘Clients’, x/y denotes that there are y clients in total and we same x clients for each round. </figcaption>
<table id="A3.T7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A3.T7.1.1" class="ltx_tr">
<td id="A3.T7.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Dataset</td>
<td id="A3.T7.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Local Epochs</td>
<td id="A3.T7.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Clients</td>
<td id="A3.T7.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Local Steps</td>
<td id="A3.T7.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Global Rounds</td>
</tr>
<tr id="A3.T7.1.2" class="ltx_tr">
<td id="A3.T7.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Fed-Aya</td>
<td id="A3.T7.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5</td>
<td id="A3.T7.1.2.3" class="ltx_td ltx_align_center ltx_border_t">4/38</td>
<td id="A3.T7.1.2.4" class="ltx_td ltx_align_center ltx_border_t">10</td>
<td id="A3.T7.1.2.5" class="ltx_td ltx_align_center ltx_border_t">200</td>
</tr>
<tr id="A3.T7.1.3" class="ltx_tr">
<td id="A3.T7.1.3.1" class="ltx_td ltx_align_left ltx_border_r">Fed-ChatbotIT</td>
<td id="A3.T7.1.3.2" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="A3.T7.1.3.3" class="ltx_td ltx_align_center">10/237</td>
<td id="A3.T7.1.3.4" class="ltx_td ltx_align_center">5</td>
<td id="A3.T7.1.3.5" class="ltx_td ltx_align_center">100</td>
</tr>
<tr id="A3.T7.1.4" class="ltx_tr">
<td id="A3.T7.1.4.1" class="ltx_td ltx_align_left ltx_border_r">Fed-WildChat</td>
<td id="A3.T7.1.4.2" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="A3.T7.1.4.3" class="ltx_td ltx_align_center">5/100</td>
<td id="A3.T7.1.4.4" class="ltx_td ltx_align_center">10</td>
<td id="A3.T7.1.4.5" class="ltx_td ltx_align_center">100</td>
</tr>
<tr id="A3.T7.1.5" class="ltx_tr">
<td id="A3.T7.1.5.1" class="ltx_td ltx_align_left ltx_border_r">Fed-WildChat (Multi-Turn)</td>
<td id="A3.T7.1.5.2" class="ltx_td ltx_align_center ltx_border_r">20</td>
<td id="A3.T7.1.5.3" class="ltx_td ltx_align_center">3/50</td>
<td id="A3.T7.1.5.4" class="ltx_td ltx_align_center">10</td>
<td id="A3.T7.1.5.5" class="ltx_td ltx_align_center">50</td>
</tr>
<tr id="A3.T7.1.6" class="ltx_tr">
<td id="A3.T7.1.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Fed-ChatbotPA</td>
<td id="A3.T7.1.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">10</td>
<td id="A3.T7.1.6.3" class="ltx_td ltx_align_center ltx_border_bb">10/747</td>
<td id="A3.T7.1.6.4" class="ltx_td ltx_align_center ltx_border_bb">Dynamic</td>
<td id="A3.T7.1.6.5" class="ltx_td ltx_align_center ltx_border_bb">200</td>
</tr>
</table>
</figure>
<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Experimental setups</h3>

<div id="A3.SS1.p1" class="ltx_para ltx_noindent">
<p id="A3.SS1.p1.1" class="ltx_p">We report the detailed experimental setups in Table <a href="#A3.T7" title="Table 7 ‣ Appendix C Experiments ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
For each table, we randomly sample two clients to conduct local training and average their performance as the final results of ‘local training’ in the table. We use dynamic local steps for local training in ChatbotPA. We calculate the probability of a user being selected in a round given parameters such as the total number of rounds, the number of clients sampled per round, and the total number of clients. We then adjust the local training steps for each client based on their sampling probability and data volume, ensuring that each client’s data can undergo about three epochs of training in total.
Our experiments were mainlt conducted on a machine equipped with an NVIDIA GeForce RTX 3090 GPU with 24 GB of VRAM. Experiments on Fed-WildChat(Multi-Turn) were conducted on a machine equipped with an NVIDIA A40 with 48GB of VRAM.</p>
</div>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Evaluation</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p id="A3.SS2.p1.1" class="ltx_p">Here, we show the prompt template used in GPT-4 Judge in Figure <a href="#A3.F8" title="Figure 8 ‣ C.2 Evaluation ‣ Appendix C Experiments ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. For the specific dataset Aya, we utilize some test samples from the raw dataset, where each sample contains a question and a reference answer. We infer the tested model with the question and obtain an answer. Then we fill in the "question", "answer" and "reference" blanks of the template.</p>
</div>
<figure id="A3.F8" class="ltx_figure"><img src="/html/2406.04845/assets/x13.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Prompt template used in GPT-4 judge.</figcaption>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>More details about differential privacy</h2>

<figure id="A4.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>MT-Bench on WildChat with Differential Privacy and fixed <math id="A4.T8.3.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.T8.3.m1.1b"><mi id="A4.T8.3.m1.1.1" xref="A4.T8.3.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.T8.3.m1.1c"><ci id="A4.T8.3.m1.1.1.cmml" xref="A4.T8.3.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.3.m1.1d">\sigma</annotation></semantics></math>. FedLLM with DP(<math id="A4.T8.4.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.T8.4.m2.1b"><mi id="A4.T8.4.m2.1.1" xref="A4.T8.4.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.T8.4.m2.1c"><ci id="A4.T8.4.m2.1.1.cmml" xref="A4.T8.4.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.4.m2.1d">\sigma</annotation></semantics></math>=0.1) still outperforms local and differential privacy costs slight model performance while ensuring user-level differential privacy.</figcaption>
<table id="A4.T8.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A4.T8.6.2" class="ltx_tr">
<td id="A4.T8.6.2.3" class="ltx_td ltx_align_left ltx_border_tt">local(813)</td>
<td id="A4.T8.6.2.4" class="ltx_td ltx_align_left ltx_border_tt">local(1702)</td>
<td id="A4.T8.6.2.5" class="ltx_td ltx_align_left ltx_border_tt">FedAvg</td>
<td id="A4.T8.5.1.1" class="ltx_td ltx_align_left ltx_border_tt">FedDP-<math id="A4.T8.5.1.1.m1.1" class="ltx_Math" alttext="1e^{-3}" display="inline"><semantics id="A4.T8.5.1.1.m1.1a"><mrow id="A4.T8.5.1.1.m1.1.1" xref="A4.T8.5.1.1.m1.1.1.cmml"><mn id="A4.T8.5.1.1.m1.1.1.2" xref="A4.T8.5.1.1.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A4.T8.5.1.1.m1.1.1.1" xref="A4.T8.5.1.1.m1.1.1.1.cmml">​</mo><msup id="A4.T8.5.1.1.m1.1.1.3" xref="A4.T8.5.1.1.m1.1.1.3.cmml"><mi id="A4.T8.5.1.1.m1.1.1.3.2" xref="A4.T8.5.1.1.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T8.5.1.1.m1.1.1.3.3" xref="A4.T8.5.1.1.m1.1.1.3.3.cmml"><mo id="A4.T8.5.1.1.m1.1.1.3.3a" xref="A4.T8.5.1.1.m1.1.1.3.3.cmml">−</mo><mn id="A4.T8.5.1.1.m1.1.1.3.3.2" xref="A4.T8.5.1.1.m1.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T8.5.1.1.m1.1b"><apply id="A4.T8.5.1.1.m1.1.1.cmml" xref="A4.T8.5.1.1.m1.1.1"><times id="A4.T8.5.1.1.m1.1.1.1.cmml" xref="A4.T8.5.1.1.m1.1.1.1"></times><cn type="integer" id="A4.T8.5.1.1.m1.1.1.2.cmml" xref="A4.T8.5.1.1.m1.1.1.2">1</cn><apply id="A4.T8.5.1.1.m1.1.1.3.cmml" xref="A4.T8.5.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T8.5.1.1.m1.1.1.3.1.cmml" xref="A4.T8.5.1.1.m1.1.1.3">superscript</csymbol><ci id="A4.T8.5.1.1.m1.1.1.3.2.cmml" xref="A4.T8.5.1.1.m1.1.1.3.2">𝑒</ci><apply id="A4.T8.5.1.1.m1.1.1.3.3.cmml" xref="A4.T8.5.1.1.m1.1.1.3.3"><minus id="A4.T8.5.1.1.m1.1.1.3.3.1.cmml" xref="A4.T8.5.1.1.m1.1.1.3.3"></minus><cn type="integer" id="A4.T8.5.1.1.m1.1.1.3.3.2.cmml" xref="A4.T8.5.1.1.m1.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.5.1.1.m1.1c">1e^{-3}</annotation></semantics></math>
</td>
<td id="A4.T8.6.2.2" class="ltx_td ltx_align_left ltx_border_tt">FedDP-<math id="A4.T8.6.2.2.m1.1" class="ltx_Math" alttext="1e^{-2}" display="inline"><semantics id="A4.T8.6.2.2.m1.1a"><mrow id="A4.T8.6.2.2.m1.1.1" xref="A4.T8.6.2.2.m1.1.1.cmml"><mn id="A4.T8.6.2.2.m1.1.1.2" xref="A4.T8.6.2.2.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A4.T8.6.2.2.m1.1.1.1" xref="A4.T8.6.2.2.m1.1.1.1.cmml">​</mo><msup id="A4.T8.6.2.2.m1.1.1.3" xref="A4.T8.6.2.2.m1.1.1.3.cmml"><mi id="A4.T8.6.2.2.m1.1.1.3.2" xref="A4.T8.6.2.2.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T8.6.2.2.m1.1.1.3.3" xref="A4.T8.6.2.2.m1.1.1.3.3.cmml"><mo id="A4.T8.6.2.2.m1.1.1.3.3a" xref="A4.T8.6.2.2.m1.1.1.3.3.cmml">−</mo><mn id="A4.T8.6.2.2.m1.1.1.3.3.2" xref="A4.T8.6.2.2.m1.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T8.6.2.2.m1.1b"><apply id="A4.T8.6.2.2.m1.1.1.cmml" xref="A4.T8.6.2.2.m1.1.1"><times id="A4.T8.6.2.2.m1.1.1.1.cmml" xref="A4.T8.6.2.2.m1.1.1.1"></times><cn type="integer" id="A4.T8.6.2.2.m1.1.1.2.cmml" xref="A4.T8.6.2.2.m1.1.1.2">1</cn><apply id="A4.T8.6.2.2.m1.1.1.3.cmml" xref="A4.T8.6.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T8.6.2.2.m1.1.1.3.1.cmml" xref="A4.T8.6.2.2.m1.1.1.3">superscript</csymbol><ci id="A4.T8.6.2.2.m1.1.1.3.2.cmml" xref="A4.T8.6.2.2.m1.1.1.3.2">𝑒</ci><apply id="A4.T8.6.2.2.m1.1.1.3.3.cmml" xref="A4.T8.6.2.2.m1.1.1.3.3"><minus id="A4.T8.6.2.2.m1.1.1.3.3.1.cmml" xref="A4.T8.6.2.2.m1.1.1.3.3"></minus><cn type="integer" id="A4.T8.6.2.2.m1.1.1.3.3.2.cmml" xref="A4.T8.6.2.2.m1.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.6.2.2.m1.1c">1e^{-2}</annotation></semantics></math>
</td>
<td id="A4.T8.6.2.6" class="ltx_td ltx_align_left ltx_border_tt">FedDP-0.1</td>
<td id="A4.T8.6.2.7" class="ltx_td ltx_align_left ltx_border_tt">FedDP-1</td>
</tr>
<tr id="A4.T8.6.3" class="ltx_tr">
<td id="A4.T8.6.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">3.5375</td>
<td id="A4.T8.6.3.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">4.0875</td>
<td id="A4.T8.6.3.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">4.6875</td>
<td id="A4.T8.6.3.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">4.6750</td>
<td id="A4.T8.6.3.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">4.5500</td>
<td id="A4.T8.6.3.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">4.5375</td>
<td id="A4.T8.6.3.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">1.6875</td>
</tr>
</table>
</figure>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Definition</h3>

<div id="A4.SS1.p1" class="ltx_para ltx_noindent">
<p id="A4.SS1.p1.1" class="ltx_p">Differential privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> has emerged as a broadly recognized framework for safeguarding privacy in statistical analyses. Through DP, we can perform computations on extensive datasets while ensuring that individual data points remain indistinguishable, thereby protecting personal privacy.</p>
</div>
<div id="A4.SS1.p2" class="ltx_para ltx_noindent">
<p id="A4.SS1.p2.8" class="ltx_p">In general, we use privacy parameters <math id="A4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="A4.SS1.p2.1.m1.1a"><mi id="A4.SS1.p2.1.m1.1.1" xref="A4.SS1.p2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.1.m1.1b"><ci id="A4.SS1.p2.1.m1.1.1.cmml" xref="A4.SS1.p2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.1.m1.1c">\epsilon</annotation></semantics></math> and <math id="A4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="A4.SS1.p2.2.m2.1a"><mi id="A4.SS1.p2.2.m2.1.1" xref="A4.SS1.p2.2.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.2.m2.1b"><ci id="A4.SS1.p2.2.m2.1.1.cmml" xref="A4.SS1.p2.2.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.2.m2.1c">\delta</annotation></semantics></math> to formally define DP.
Specifically, a randomized mechanism <math id="A4.SS1.p2.3.m3.1" class="ltx_Math" alttext="M:\mathcal{D}\rightarrow\mathcal{R}" display="inline"><semantics id="A4.SS1.p2.3.m3.1a"><mrow id="A4.SS1.p2.3.m3.1.1" xref="A4.SS1.p2.3.m3.1.1.cmml"><mi id="A4.SS1.p2.3.m3.1.1.2" xref="A4.SS1.p2.3.m3.1.1.2.cmml">M</mi><mo lspace="0.278em" rspace="0.278em" id="A4.SS1.p2.3.m3.1.1.1" xref="A4.SS1.p2.3.m3.1.1.1.cmml">:</mo><mrow id="A4.SS1.p2.3.m3.1.1.3" xref="A4.SS1.p2.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A4.SS1.p2.3.m3.1.1.3.2" xref="A4.SS1.p2.3.m3.1.1.3.2.cmml">𝒟</mi><mo stretchy="false" id="A4.SS1.p2.3.m3.1.1.3.1" xref="A4.SS1.p2.3.m3.1.1.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="A4.SS1.p2.3.m3.1.1.3.3" xref="A4.SS1.p2.3.m3.1.1.3.3.cmml">ℛ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.3.m3.1b"><apply id="A4.SS1.p2.3.m3.1.1.cmml" xref="A4.SS1.p2.3.m3.1.1"><ci id="A4.SS1.p2.3.m3.1.1.1.cmml" xref="A4.SS1.p2.3.m3.1.1.1">:</ci><ci id="A4.SS1.p2.3.m3.1.1.2.cmml" xref="A4.SS1.p2.3.m3.1.1.2">𝑀</ci><apply id="A4.SS1.p2.3.m3.1.1.3.cmml" xref="A4.SS1.p2.3.m3.1.1.3"><ci id="A4.SS1.p2.3.m3.1.1.3.1.cmml" xref="A4.SS1.p2.3.m3.1.1.3.1">→</ci><ci id="A4.SS1.p2.3.m3.1.1.3.2.cmml" xref="A4.SS1.p2.3.m3.1.1.3.2">𝒟</ci><ci id="A4.SS1.p2.3.m3.1.1.3.3.cmml" xref="A4.SS1.p2.3.m3.1.1.3.3">ℛ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.3.m3.1c">M:\mathcal{D}\rightarrow\mathcal{R}</annotation></semantics></math> is <math id="A4.SS1.p2.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="A4.SS1.p2.4.m4.2a"><mrow id="A4.SS1.p2.4.m4.2.3.2" xref="A4.SS1.p2.4.m4.2.3.1.cmml"><mo stretchy="false" id="A4.SS1.p2.4.m4.2.3.2.1" xref="A4.SS1.p2.4.m4.2.3.1.cmml">(</mo><mi id="A4.SS1.p2.4.m4.1.1" xref="A4.SS1.p2.4.m4.1.1.cmml">ϵ</mi><mo id="A4.SS1.p2.4.m4.2.3.2.2" xref="A4.SS1.p2.4.m4.2.3.1.cmml">,</mo><mi id="A4.SS1.p2.4.m4.2.2" xref="A4.SS1.p2.4.m4.2.2.cmml">δ</mi><mo stretchy="false" id="A4.SS1.p2.4.m4.2.3.2.3" xref="A4.SS1.p2.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.4.m4.2b"><interval closure="open" id="A4.SS1.p2.4.m4.2.3.1.cmml" xref="A4.SS1.p2.4.m4.2.3.2"><ci id="A4.SS1.p2.4.m4.1.1.cmml" xref="A4.SS1.p2.4.m4.1.1">italic-ϵ</ci><ci id="A4.SS1.p2.4.m4.2.2.cmml" xref="A4.SS1.p2.4.m4.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-differential private for <math id="A4.SS1.p2.5.m5.1" class="ltx_Math" alttext="\epsilon&gt;0" display="inline"><semantics id="A4.SS1.p2.5.m5.1a"><mrow id="A4.SS1.p2.5.m5.1.1" xref="A4.SS1.p2.5.m5.1.1.cmml"><mi id="A4.SS1.p2.5.m5.1.1.2" xref="A4.SS1.p2.5.m5.1.1.2.cmml">ϵ</mi><mo id="A4.SS1.p2.5.m5.1.1.1" xref="A4.SS1.p2.5.m5.1.1.1.cmml">&gt;</mo><mn id="A4.SS1.p2.5.m5.1.1.3" xref="A4.SS1.p2.5.m5.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.5.m5.1b"><apply id="A4.SS1.p2.5.m5.1.1.cmml" xref="A4.SS1.p2.5.m5.1.1"><gt id="A4.SS1.p2.5.m5.1.1.1.cmml" xref="A4.SS1.p2.5.m5.1.1.1"></gt><ci id="A4.SS1.p2.5.m5.1.1.2.cmml" xref="A4.SS1.p2.5.m5.1.1.2">italic-ϵ</ci><cn type="integer" id="A4.SS1.p2.5.m5.1.1.3.cmml" xref="A4.SS1.p2.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.5.m5.1c">\epsilon&gt;0</annotation></semantics></math> and <math id="A4.SS1.p2.6.m6.2" class="ltx_Math" alttext="\delta\in[0,1)" display="inline"><semantics id="A4.SS1.p2.6.m6.2a"><mrow id="A4.SS1.p2.6.m6.2.3" xref="A4.SS1.p2.6.m6.2.3.cmml"><mi id="A4.SS1.p2.6.m6.2.3.2" xref="A4.SS1.p2.6.m6.2.3.2.cmml">δ</mi><mo id="A4.SS1.p2.6.m6.2.3.1" xref="A4.SS1.p2.6.m6.2.3.1.cmml">∈</mo><mrow id="A4.SS1.p2.6.m6.2.3.3.2" xref="A4.SS1.p2.6.m6.2.3.3.1.cmml"><mo stretchy="false" id="A4.SS1.p2.6.m6.2.3.3.2.1" xref="A4.SS1.p2.6.m6.2.3.3.1.cmml">[</mo><mn id="A4.SS1.p2.6.m6.1.1" xref="A4.SS1.p2.6.m6.1.1.cmml">0</mn><mo id="A4.SS1.p2.6.m6.2.3.3.2.2" xref="A4.SS1.p2.6.m6.2.3.3.1.cmml">,</mo><mn id="A4.SS1.p2.6.m6.2.2" xref="A4.SS1.p2.6.m6.2.2.cmml">1</mn><mo stretchy="false" id="A4.SS1.p2.6.m6.2.3.3.2.3" xref="A4.SS1.p2.6.m6.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.6.m6.2b"><apply id="A4.SS1.p2.6.m6.2.3.cmml" xref="A4.SS1.p2.6.m6.2.3"><in id="A4.SS1.p2.6.m6.2.3.1.cmml" xref="A4.SS1.p2.6.m6.2.3.1"></in><ci id="A4.SS1.p2.6.m6.2.3.2.cmml" xref="A4.SS1.p2.6.m6.2.3.2">𝛿</ci><interval closure="closed-open" id="A4.SS1.p2.6.m6.2.3.3.1.cmml" xref="A4.SS1.p2.6.m6.2.3.3.2"><cn type="integer" id="A4.SS1.p2.6.m6.1.1.cmml" xref="A4.SS1.p2.6.m6.1.1">0</cn><cn type="integer" id="A4.SS1.p2.6.m6.2.2.cmml" xref="A4.SS1.p2.6.m6.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.6.m6.2c">\delta\in[0,1)</annotation></semantics></math> if for any two neighboring datasets <math id="A4.SS1.p2.7.m7.2" class="ltx_Math" alttext="D,D^{\prime}\in\mathcal{D}" display="inline"><semantics id="A4.SS1.p2.7.m7.2a"><mrow id="A4.SS1.p2.7.m7.2.2" xref="A4.SS1.p2.7.m7.2.2.cmml"><mrow id="A4.SS1.p2.7.m7.2.2.1.1" xref="A4.SS1.p2.7.m7.2.2.1.2.cmml"><mi id="A4.SS1.p2.7.m7.1.1" xref="A4.SS1.p2.7.m7.1.1.cmml">D</mi><mo id="A4.SS1.p2.7.m7.2.2.1.1.2" xref="A4.SS1.p2.7.m7.2.2.1.2.cmml">,</mo><msup id="A4.SS1.p2.7.m7.2.2.1.1.1" xref="A4.SS1.p2.7.m7.2.2.1.1.1.cmml"><mi id="A4.SS1.p2.7.m7.2.2.1.1.1.2" xref="A4.SS1.p2.7.m7.2.2.1.1.1.2.cmml">D</mi><mo id="A4.SS1.p2.7.m7.2.2.1.1.1.3" xref="A4.SS1.p2.7.m7.2.2.1.1.1.3.cmml">′</mo></msup></mrow><mo id="A4.SS1.p2.7.m7.2.2.2" xref="A4.SS1.p2.7.m7.2.2.2.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="A4.SS1.p2.7.m7.2.2.3" xref="A4.SS1.p2.7.m7.2.2.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.7.m7.2b"><apply id="A4.SS1.p2.7.m7.2.2.cmml" xref="A4.SS1.p2.7.m7.2.2"><in id="A4.SS1.p2.7.m7.2.2.2.cmml" xref="A4.SS1.p2.7.m7.2.2.2"></in><list id="A4.SS1.p2.7.m7.2.2.1.2.cmml" xref="A4.SS1.p2.7.m7.2.2.1.1"><ci id="A4.SS1.p2.7.m7.1.1.cmml" xref="A4.SS1.p2.7.m7.1.1">𝐷</ci><apply id="A4.SS1.p2.7.m7.2.2.1.1.1.cmml" xref="A4.SS1.p2.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="A4.SS1.p2.7.m7.2.2.1.1.1.1.cmml" xref="A4.SS1.p2.7.m7.2.2.1.1.1">superscript</csymbol><ci id="A4.SS1.p2.7.m7.2.2.1.1.1.2.cmml" xref="A4.SS1.p2.7.m7.2.2.1.1.1.2">𝐷</ci><ci id="A4.SS1.p2.7.m7.2.2.1.1.1.3.cmml" xref="A4.SS1.p2.7.m7.2.2.1.1.1.3">′</ci></apply></list><ci id="A4.SS1.p2.7.m7.2.2.3.cmml" xref="A4.SS1.p2.7.m7.2.2.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.7.m7.2c">D,D^{\prime}\in\mathcal{D}</annotation></semantics></math> differing by at most one entry and for any subset of outputs <math id="A4.SS1.p2.8.m8.1" class="ltx_Math" alttext="R\subseteq\mathcal{R}" display="inline"><semantics id="A4.SS1.p2.8.m8.1a"><mrow id="A4.SS1.p2.8.m8.1.1" xref="A4.SS1.p2.8.m8.1.1.cmml"><mi id="A4.SS1.p2.8.m8.1.1.2" xref="A4.SS1.p2.8.m8.1.1.2.cmml">R</mi><mo id="A4.SS1.p2.8.m8.1.1.1" xref="A4.SS1.p2.8.m8.1.1.1.cmml">⊆</mo><mi class="ltx_font_mathcaligraphic" id="A4.SS1.p2.8.m8.1.1.3" xref="A4.SS1.p2.8.m8.1.1.3.cmml">ℛ</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.8.m8.1b"><apply id="A4.SS1.p2.8.m8.1.1.cmml" xref="A4.SS1.p2.8.m8.1.1"><subset id="A4.SS1.p2.8.m8.1.1.1.cmml" xref="A4.SS1.p2.8.m8.1.1.1"></subset><ci id="A4.SS1.p2.8.m8.1.1.2.cmml" xref="A4.SS1.p2.8.m8.1.1.2">𝑅</ci><ci id="A4.SS1.p2.8.m8.1.1.3.cmml" xref="A4.SS1.p2.8.m8.1.1.3">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.8.m8.1c">R\subseteq\mathcal{R}</annotation></semantics></math> it holds that</p>
<table id="A4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A4.Ex1.m1.4" class="ltx_Math" alttext="\mathbb{P}(M(D)\in R)\leq\exp(\epsilon)\mathbb{P}(M(D^{\prime})\in R)+\delta." display="block"><semantics id="A4.Ex1.m1.4a"><mrow id="A4.Ex1.m1.4.4.1" xref="A4.Ex1.m1.4.4.1.1.cmml"><mrow id="A4.Ex1.m1.4.4.1.1" xref="A4.Ex1.m1.4.4.1.1.cmml"><mrow id="A4.Ex1.m1.4.4.1.1.1" xref="A4.Ex1.m1.4.4.1.1.1.cmml"><mi id="A4.Ex1.m1.4.4.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.1.3.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="A4.Ex1.m1.4.4.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.1.2.cmml">​</mo><mrow id="A4.Ex1.m1.4.4.1.1.1.1.1" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.cmml">(</mo><mrow id="A4.Ex1.m1.4.4.1.1.1.1.1.1" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml"><mi id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.2" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.1" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.3.2" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.3.2.1" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml">(</mo><mi id="A4.Ex1.m1.1.1" xref="A4.Ex1.m1.1.1.cmml">D</mi><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.3.2.2" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A4.Ex1.m1.4.4.1.1.1.1.1.1.1" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml">∈</mo><mi id="A4.Ex1.m1.4.4.1.1.1.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.3.cmml">R</mi></mrow><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A4.Ex1.m1.4.4.1.1.3" xref="A4.Ex1.m1.4.4.1.1.3.cmml">≤</mo><mrow id="A4.Ex1.m1.4.4.1.1.2" xref="A4.Ex1.m1.4.4.1.1.2.cmml"><mrow id="A4.Ex1.m1.4.4.1.1.2.1" xref="A4.Ex1.m1.4.4.1.1.2.1.cmml"><mrow id="A4.Ex1.m1.4.4.1.1.2.1.3.2" xref="A4.Ex1.m1.4.4.1.1.2.1.3.1.cmml"><mi id="A4.Ex1.m1.2.2" xref="A4.Ex1.m1.2.2.cmml">exp</mi><mo id="A4.Ex1.m1.4.4.1.1.2.1.3.2a" xref="A4.Ex1.m1.4.4.1.1.2.1.3.1.cmml">⁡</mo><mrow id="A4.Ex1.m1.4.4.1.1.2.1.3.2.1" xref="A4.Ex1.m1.4.4.1.1.2.1.3.1.cmml"><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.2.1.3.2.1.1" xref="A4.Ex1.m1.4.4.1.1.2.1.3.1.cmml">(</mo><mi id="A4.Ex1.m1.3.3" xref="A4.Ex1.m1.3.3.cmml">ϵ</mi><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.2.1.3.2.1.2" xref="A4.Ex1.m1.4.4.1.1.2.1.3.1.cmml">)</mo></mrow></mrow><mo lspace="0em" rspace="0em" id="A4.Ex1.m1.4.4.1.1.2.1.2" xref="A4.Ex1.m1.4.4.1.1.2.1.2.cmml">​</mo><mi id="A4.Ex1.m1.4.4.1.1.2.1.4" xref="A4.Ex1.m1.4.4.1.1.2.1.4.cmml">ℙ</mi><mo lspace="0em" rspace="0em" id="A4.Ex1.m1.4.4.1.1.2.1.2a" xref="A4.Ex1.m1.4.4.1.1.2.1.2.cmml">​</mo><mrow id="A4.Ex1.m1.4.4.1.1.2.1.1.1" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.cmml"><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.2.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.cmml">(</mo><mrow id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.cmml"><mrow id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.cmml"><mi id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.2.cmml">​</mo><mrow id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.cmml"><mi id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.2.cmml">D</mi><mo id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.2" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.2.cmml">∈</mo><mi id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.3.cmml">R</mi></mrow><mo stretchy="false" id="A4.Ex1.m1.4.4.1.1.2.1.1.1.3" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A4.Ex1.m1.4.4.1.1.2.2" xref="A4.Ex1.m1.4.4.1.1.2.2.cmml">+</mo><mi id="A4.Ex1.m1.4.4.1.1.2.3" xref="A4.Ex1.m1.4.4.1.1.2.3.cmml">δ</mi></mrow></mrow><mo lspace="0em" id="A4.Ex1.m1.4.4.1.2" xref="A4.Ex1.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.Ex1.m1.4b"><apply id="A4.Ex1.m1.4.4.1.1.cmml" xref="A4.Ex1.m1.4.4.1"><leq id="A4.Ex1.m1.4.4.1.1.3.cmml" xref="A4.Ex1.m1.4.4.1.1.3"></leq><apply id="A4.Ex1.m1.4.4.1.1.1.cmml" xref="A4.Ex1.m1.4.4.1.1.1"><times id="A4.Ex1.m1.4.4.1.1.1.2.cmml" xref="A4.Ex1.m1.4.4.1.1.1.2"></times><ci id="A4.Ex1.m1.4.4.1.1.1.3.cmml" xref="A4.Ex1.m1.4.4.1.1.1.3">ℙ</ci><apply id="A4.Ex1.m1.4.4.1.1.1.1.1.1.cmml" xref="A4.Ex1.m1.4.4.1.1.1.1.1"><in id="A4.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.1"></in><apply id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2"><times id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.1"></times><ci id="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.2.2">𝑀</ci><ci id="A4.Ex1.m1.1.1.cmml" xref="A4.Ex1.m1.1.1">𝐷</ci></apply><ci id="A4.Ex1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="A4.Ex1.m1.4.4.1.1.1.1.1.1.3">𝑅</ci></apply></apply><apply id="A4.Ex1.m1.4.4.1.1.2.cmml" xref="A4.Ex1.m1.4.4.1.1.2"><plus id="A4.Ex1.m1.4.4.1.1.2.2.cmml" xref="A4.Ex1.m1.4.4.1.1.2.2"></plus><apply id="A4.Ex1.m1.4.4.1.1.2.1.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1"><times id="A4.Ex1.m1.4.4.1.1.2.1.2.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.2"></times><apply id="A4.Ex1.m1.4.4.1.1.2.1.3.1.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.3.2"><exp id="A4.Ex1.m1.2.2.cmml" xref="A4.Ex1.m1.2.2"></exp><ci id="A4.Ex1.m1.3.3.cmml" xref="A4.Ex1.m1.3.3">italic-ϵ</ci></apply><ci id="A4.Ex1.m1.4.4.1.1.2.1.4.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.4">ℙ</ci><apply id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1"><in id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.2.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.2"></in><apply id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1"><times id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.2.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.2"></times><ci id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.3.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.3">𝑀</ci><apply id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.1.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.2.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.2">𝐷</ci><ci id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.3.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.3.cmml" xref="A4.Ex1.m1.4.4.1.1.2.1.1.1.1.3">𝑅</ci></apply></apply><ci id="A4.Ex1.m1.4.4.1.1.2.3.cmml" xref="A4.Ex1.m1.4.4.1.1.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.Ex1.m1.4c">\mathbb{P}(M(D)\in R)\leq\exp(\epsilon)\mathbb{P}(M(D^{\prime})\in R)+\delta.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="A4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>User-level differential privacy</h3>

<div id="A4.SS2.p1" class="ltx_para ltx_noindent">
<p id="A4.SS2.p1.3" class="ltx_p">We implement user-level differential privacy(UDP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> in our experiments. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, we use the Gaussian mechanism that employs the <math id="A4.SS2.p1.1.m1.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="A4.SS2.p1.1.m1.1a"><msub id="A4.SS2.p1.1.m1.1.1" xref="A4.SS2.p1.1.m1.1.1.cmml"><mi id="A4.SS2.p1.1.m1.1.1.2" xref="A4.SS2.p1.1.m1.1.1.2.cmml">L</mi><mn id="A4.SS2.p1.1.m1.1.1.3" xref="A4.SS2.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.1.m1.1b"><apply id="A4.SS2.p1.1.m1.1.1.cmml" xref="A4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A4.SS2.p1.1.m1.1.1.1.cmml" xref="A4.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="A4.SS2.p1.1.m1.1.1.2.cmml" xref="A4.SS2.p1.1.m1.1.1.2">𝐿</ci><cn type="integer" id="A4.SS2.p1.1.m1.1.1.3.cmml" xref="A4.SS2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.1.m1.1c">L_{2}</annotation></semantics></math> norm sensitivity. It adds zero-mean Gaussian noise with variance <math id="A4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\sigma^{2}\mathbf{I}" display="inline"><semantics id="A4.SS2.p1.2.m2.1a"><mrow id="A4.SS2.p1.2.m2.1.1" xref="A4.SS2.p1.2.m2.1.1.cmml"><msup id="A4.SS2.p1.2.m2.1.1.2" xref="A4.SS2.p1.2.m2.1.1.2.cmml"><mi id="A4.SS2.p1.2.m2.1.1.2.2" xref="A4.SS2.p1.2.m2.1.1.2.2.cmml">σ</mi><mn id="A4.SS2.p1.2.m2.1.1.2.3" xref="A4.SS2.p1.2.m2.1.1.2.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="A4.SS2.p1.2.m2.1.1.1" xref="A4.SS2.p1.2.m2.1.1.1.cmml">​</mo><mi id="A4.SS2.p1.2.m2.1.1.3" xref="A4.SS2.p1.2.m2.1.1.3.cmml">𝐈</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.2.m2.1b"><apply id="A4.SS2.p1.2.m2.1.1.cmml" xref="A4.SS2.p1.2.m2.1.1"><times id="A4.SS2.p1.2.m2.1.1.1.cmml" xref="A4.SS2.p1.2.m2.1.1.1"></times><apply id="A4.SS2.p1.2.m2.1.1.2.cmml" xref="A4.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="A4.SS2.p1.2.m2.1.1.2.1.cmml" xref="A4.SS2.p1.2.m2.1.1.2">superscript</csymbol><ci id="A4.SS2.p1.2.m2.1.1.2.2.cmml" xref="A4.SS2.p1.2.m2.1.1.2.2">𝜎</ci><cn type="integer" id="A4.SS2.p1.2.m2.1.1.2.3.cmml" xref="A4.SS2.p1.2.m2.1.1.2.3">2</cn></apply><ci id="A4.SS2.p1.2.m2.1.1.3.cmml" xref="A4.SS2.p1.2.m2.1.1.3">𝐈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.2.m2.1c">\sigma^{2}\mathbf{I}</annotation></semantics></math> to each coordinate of the function output <math id="A4.SS2.p1.3.m3.1" class="ltx_Math" alttext="r(D)" display="inline"><semantics id="A4.SS2.p1.3.m3.1a"><mrow id="A4.SS2.p1.3.m3.1.2" xref="A4.SS2.p1.3.m3.1.2.cmml"><mi id="A4.SS2.p1.3.m3.1.2.2" xref="A4.SS2.p1.3.m3.1.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="A4.SS2.p1.3.m3.1.2.1" xref="A4.SS2.p1.3.m3.1.2.1.cmml">​</mo><mrow id="A4.SS2.p1.3.m3.1.2.3.2" xref="A4.SS2.p1.3.m3.1.2.cmml"><mo stretchy="false" id="A4.SS2.p1.3.m3.1.2.3.2.1" xref="A4.SS2.p1.3.m3.1.2.cmml">(</mo><mi id="A4.SS2.p1.3.m3.1.1" xref="A4.SS2.p1.3.m3.1.1.cmml">D</mi><mo stretchy="false" id="A4.SS2.p1.3.m3.1.2.3.2.2" xref="A4.SS2.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.3.m3.1b"><apply id="A4.SS2.p1.3.m3.1.2.cmml" xref="A4.SS2.p1.3.m3.1.2"><times id="A4.SS2.p1.3.m3.1.2.1.cmml" xref="A4.SS2.p1.3.m3.1.2.1"></times><ci id="A4.SS2.p1.3.m3.1.2.2.cmml" xref="A4.SS2.p1.3.m3.1.2.2">𝑟</ci><ci id="A4.SS2.p1.3.m3.1.1.cmml" xref="A4.SS2.p1.3.m3.1.1">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.3.m3.1c">r(D)</annotation></semantics></math> as follows:</p>
<table id="A4.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A4.Ex2.m1.4" class="ltx_Math" alttext="\mathcal{M}(D)=r(D)+\mathcal{N}(0,\sigma^{2}\mathbf{I})," display="block"><semantics id="A4.Ex2.m1.4a"><mrow id="A4.Ex2.m1.4.4.1" xref="A4.Ex2.m1.4.4.1.1.cmml"><mrow id="A4.Ex2.m1.4.4.1.1" xref="A4.Ex2.m1.4.4.1.1.cmml"><mrow id="A4.Ex2.m1.4.4.1.1.3" xref="A4.Ex2.m1.4.4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A4.Ex2.m1.4.4.1.1.3.2" xref="A4.Ex2.m1.4.4.1.1.3.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="A4.Ex2.m1.4.4.1.1.3.1" xref="A4.Ex2.m1.4.4.1.1.3.1.cmml">​</mo><mrow id="A4.Ex2.m1.4.4.1.1.3.3.2" xref="A4.Ex2.m1.4.4.1.1.3.cmml"><mo stretchy="false" id="A4.Ex2.m1.4.4.1.1.3.3.2.1" xref="A4.Ex2.m1.4.4.1.1.3.cmml">(</mo><mi id="A4.Ex2.m1.1.1" xref="A4.Ex2.m1.1.1.cmml">D</mi><mo stretchy="false" id="A4.Ex2.m1.4.4.1.1.3.3.2.2" xref="A4.Ex2.m1.4.4.1.1.3.cmml">)</mo></mrow></mrow><mo id="A4.Ex2.m1.4.4.1.1.2" xref="A4.Ex2.m1.4.4.1.1.2.cmml">=</mo><mrow id="A4.Ex2.m1.4.4.1.1.1" xref="A4.Ex2.m1.4.4.1.1.1.cmml"><mrow id="A4.Ex2.m1.4.4.1.1.1.3" xref="A4.Ex2.m1.4.4.1.1.1.3.cmml"><mi id="A4.Ex2.m1.4.4.1.1.1.3.2" xref="A4.Ex2.m1.4.4.1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="A4.Ex2.m1.4.4.1.1.1.3.1" xref="A4.Ex2.m1.4.4.1.1.1.3.1.cmml">​</mo><mrow id="A4.Ex2.m1.4.4.1.1.1.3.3.2" xref="A4.Ex2.m1.4.4.1.1.1.3.cmml"><mo stretchy="false" id="A4.Ex2.m1.4.4.1.1.1.3.3.2.1" xref="A4.Ex2.m1.4.4.1.1.1.3.cmml">(</mo><mi id="A4.Ex2.m1.2.2" xref="A4.Ex2.m1.2.2.cmml">D</mi><mo stretchy="false" id="A4.Ex2.m1.4.4.1.1.1.3.3.2.2" xref="A4.Ex2.m1.4.4.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="A4.Ex2.m1.4.4.1.1.1.2" xref="A4.Ex2.m1.4.4.1.1.1.2.cmml">+</mo><mrow id="A4.Ex2.m1.4.4.1.1.1.1" xref="A4.Ex2.m1.4.4.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A4.Ex2.m1.4.4.1.1.1.1.3" xref="A4.Ex2.m1.4.4.1.1.1.1.3.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="A4.Ex2.m1.4.4.1.1.1.1.2" xref="A4.Ex2.m1.4.4.1.1.1.1.2.cmml">​</mo><mrow id="A4.Ex2.m1.4.4.1.1.1.1.1.1" xref="A4.Ex2.m1.4.4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A4.Ex2.m1.4.4.1.1.1.1.1.1.2" xref="A4.Ex2.m1.4.4.1.1.1.1.1.2.cmml">(</mo><mn id="A4.Ex2.m1.3.3" xref="A4.Ex2.m1.3.3.cmml">0</mn><mo id="A4.Ex2.m1.4.4.1.1.1.1.1.1.3" xref="A4.Ex2.m1.4.4.1.1.1.1.1.2.cmml">,</mo><mrow id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.cmml"><msup id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.cmml"><mi id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.2" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.2.cmml">σ</mi><mn id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.3" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.1" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.3" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.3.cmml">𝐈</mi></mrow><mo stretchy="false" id="A4.Ex2.m1.4.4.1.1.1.1.1.1.4" xref="A4.Ex2.m1.4.4.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="A4.Ex2.m1.4.4.1.2" xref="A4.Ex2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.Ex2.m1.4b"><apply id="A4.Ex2.m1.4.4.1.1.cmml" xref="A4.Ex2.m1.4.4.1"><eq id="A4.Ex2.m1.4.4.1.1.2.cmml" xref="A4.Ex2.m1.4.4.1.1.2"></eq><apply id="A4.Ex2.m1.4.4.1.1.3.cmml" xref="A4.Ex2.m1.4.4.1.1.3"><times id="A4.Ex2.m1.4.4.1.1.3.1.cmml" xref="A4.Ex2.m1.4.4.1.1.3.1"></times><ci id="A4.Ex2.m1.4.4.1.1.3.2.cmml" xref="A4.Ex2.m1.4.4.1.1.3.2">ℳ</ci><ci id="A4.Ex2.m1.1.1.cmml" xref="A4.Ex2.m1.1.1">𝐷</ci></apply><apply id="A4.Ex2.m1.4.4.1.1.1.cmml" xref="A4.Ex2.m1.4.4.1.1.1"><plus id="A4.Ex2.m1.4.4.1.1.1.2.cmml" xref="A4.Ex2.m1.4.4.1.1.1.2"></plus><apply id="A4.Ex2.m1.4.4.1.1.1.3.cmml" xref="A4.Ex2.m1.4.4.1.1.1.3"><times id="A4.Ex2.m1.4.4.1.1.1.3.1.cmml" xref="A4.Ex2.m1.4.4.1.1.1.3.1"></times><ci id="A4.Ex2.m1.4.4.1.1.1.3.2.cmml" xref="A4.Ex2.m1.4.4.1.1.1.3.2">𝑟</ci><ci id="A4.Ex2.m1.2.2.cmml" xref="A4.Ex2.m1.2.2">𝐷</ci></apply><apply id="A4.Ex2.m1.4.4.1.1.1.1.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1"><times id="A4.Ex2.m1.4.4.1.1.1.1.2.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.2"></times><ci id="A4.Ex2.m1.4.4.1.1.1.1.3.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.3">𝒩</ci><interval closure="open" id="A4.Ex2.m1.4.4.1.1.1.1.1.2.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1"><cn type="integer" id="A4.Ex2.m1.3.3.cmml" xref="A4.Ex2.m1.3.3">0</cn><apply id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1"><times id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.1"></times><apply id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.2">𝜎</ci><cn type="integer" id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.3.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.2.3">2</cn></apply><ci id="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="A4.Ex2.m1.4.4.1.1.1.1.1.1.1.3">𝐈</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.Ex2.m1.4c">\mathcal{M}(D)=r(D)+\mathcal{N}(0,\sigma^{2}\mathbf{I}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A4.SS2.p1.6" class="ltx_p">where <math id="A4.SS2.p1.4.m1.1" class="ltx_Math" alttext="\mathbf{I}" display="inline"><semantics id="A4.SS2.p1.4.m1.1a"><mi id="A4.SS2.p1.4.m1.1.1" xref="A4.SS2.p1.4.m1.1.1.cmml">𝐈</mi><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.4.m1.1b"><ci id="A4.SS2.p1.4.m1.1.1.cmml" xref="A4.SS2.p1.4.m1.1.1">𝐈</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.4.m1.1c">\mathbf{I}</annotation></semantics></math> is an identity matrix of the same size as <math id="A4.SS2.p1.5.m2.1" class="ltx_Math" alttext="r(D)" display="inline"><semantics id="A4.SS2.p1.5.m2.1a"><mrow id="A4.SS2.p1.5.m2.1.2" xref="A4.SS2.p1.5.m2.1.2.cmml"><mi id="A4.SS2.p1.5.m2.1.2.2" xref="A4.SS2.p1.5.m2.1.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="A4.SS2.p1.5.m2.1.2.1" xref="A4.SS2.p1.5.m2.1.2.1.cmml">​</mo><mrow id="A4.SS2.p1.5.m2.1.2.3.2" xref="A4.SS2.p1.5.m2.1.2.cmml"><mo stretchy="false" id="A4.SS2.p1.5.m2.1.2.3.2.1" xref="A4.SS2.p1.5.m2.1.2.cmml">(</mo><mi id="A4.SS2.p1.5.m2.1.1" xref="A4.SS2.p1.5.m2.1.1.cmml">D</mi><mo stretchy="false" id="A4.SS2.p1.5.m2.1.2.3.2.2" xref="A4.SS2.p1.5.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.5.m2.1b"><apply id="A4.SS2.p1.5.m2.1.2.cmml" xref="A4.SS2.p1.5.m2.1.2"><times id="A4.SS2.p1.5.m2.1.2.1.cmml" xref="A4.SS2.p1.5.m2.1.2.1"></times><ci id="A4.SS2.p1.5.m2.1.2.2.cmml" xref="A4.SS2.p1.5.m2.1.2.2">𝑟</ci><ci id="A4.SS2.p1.5.m2.1.1.cmml" xref="A4.SS2.p1.5.m2.1.1">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.5.m2.1c">r(D)</annotation></semantics></math>. The sensitivity of the function <math id="A4.SS2.p1.6.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="A4.SS2.p1.6.m3.1a"><mi id="A4.SS2.p1.6.m3.1.1" xref="A4.SS2.p1.6.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.6.m3.1b"><ci id="A4.SS2.p1.6.m3.1.1.cmml" xref="A4.SS2.p1.6.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.6.m3.1c">r</annotation></semantics></math> is expressed as:</p>
<table id="A4.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A4.Ex3.m1.4" class="ltx_Math" alttext="\Delta r=\max_{D,D^{\prime}\in\mathbf{D}}\|r(D)-r(D^{\prime})\|_{2}," display="block"><semantics id="A4.Ex3.m1.4a"><mrow id="A4.Ex3.m1.4.4.1" xref="A4.Ex3.m1.4.4.1.1.cmml"><mrow id="A4.Ex3.m1.4.4.1.1" xref="A4.Ex3.m1.4.4.1.1.cmml"><mrow id="A4.Ex3.m1.4.4.1.1.3" xref="A4.Ex3.m1.4.4.1.1.3.cmml"><mi mathvariant="normal" id="A4.Ex3.m1.4.4.1.1.3.2" xref="A4.Ex3.m1.4.4.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="A4.Ex3.m1.4.4.1.1.3.1" xref="A4.Ex3.m1.4.4.1.1.3.1.cmml">​</mo><mi id="A4.Ex3.m1.4.4.1.1.3.3" xref="A4.Ex3.m1.4.4.1.1.3.3.cmml">r</mi></mrow><mo id="A4.Ex3.m1.4.4.1.1.2" xref="A4.Ex3.m1.4.4.1.1.2.cmml">=</mo><mrow id="A4.Ex3.m1.4.4.1.1.1" xref="A4.Ex3.m1.4.4.1.1.1.cmml"><munder id="A4.Ex3.m1.4.4.1.1.1.2" xref="A4.Ex3.m1.4.4.1.1.1.2.cmml"><mi id="A4.Ex3.m1.4.4.1.1.1.2.2" xref="A4.Ex3.m1.4.4.1.1.1.2.2.cmml">max</mi><mrow id="A4.Ex3.m1.2.2.2" xref="A4.Ex3.m1.2.2.2.cmml"><mrow id="A4.Ex3.m1.2.2.2.2.1" xref="A4.Ex3.m1.2.2.2.2.2.cmml"><mi id="A4.Ex3.m1.1.1.1.1" xref="A4.Ex3.m1.1.1.1.1.cmml">D</mi><mo id="A4.Ex3.m1.2.2.2.2.1.2" xref="A4.Ex3.m1.2.2.2.2.2.cmml">,</mo><msup id="A4.Ex3.m1.2.2.2.2.1.1" xref="A4.Ex3.m1.2.2.2.2.1.1.cmml"><mi id="A4.Ex3.m1.2.2.2.2.1.1.2" xref="A4.Ex3.m1.2.2.2.2.1.1.2.cmml">D</mi><mo id="A4.Ex3.m1.2.2.2.2.1.1.3" xref="A4.Ex3.m1.2.2.2.2.1.1.3.cmml">′</mo></msup></mrow><mo id="A4.Ex3.m1.2.2.2.3" xref="A4.Ex3.m1.2.2.2.3.cmml">∈</mo><mi id="A4.Ex3.m1.2.2.2.4" xref="A4.Ex3.m1.2.2.2.4.cmml">𝐃</mi></mrow></munder><mo id="A4.Ex3.m1.4.4.1.1.1a" xref="A4.Ex3.m1.4.4.1.1.1.cmml">⁡</mo><msub id="A4.Ex3.m1.4.4.1.1.1.1" xref="A4.Ex3.m1.4.4.1.1.1.1.cmml"><mrow id="A4.Ex3.m1.4.4.1.1.1.1.1.1" xref="A4.Ex3.m1.4.4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.cmml"><mrow id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mi id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.1" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.1.cmml">​</mo><mrow id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.3.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.3.2.1" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.cmml">(</mo><mi id="A4.Ex3.m1.3.3" xref="A4.Ex3.m1.3.3.cmml">D</mi><mo stretchy="false" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.3.2.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.3" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.cmml">D</mi><mo id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.3" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.3" xref="A4.Ex3.m1.4.4.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="A4.Ex3.m1.4.4.1.1.1.1.3" xref="A4.Ex3.m1.4.4.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow><mo id="A4.Ex3.m1.4.4.1.2" xref="A4.Ex3.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.Ex3.m1.4b"><apply id="A4.Ex3.m1.4.4.1.1.cmml" xref="A4.Ex3.m1.4.4.1"><eq id="A4.Ex3.m1.4.4.1.1.2.cmml" xref="A4.Ex3.m1.4.4.1.1.2"></eq><apply id="A4.Ex3.m1.4.4.1.1.3.cmml" xref="A4.Ex3.m1.4.4.1.1.3"><times id="A4.Ex3.m1.4.4.1.1.3.1.cmml" xref="A4.Ex3.m1.4.4.1.1.3.1"></times><ci id="A4.Ex3.m1.4.4.1.1.3.2.cmml" xref="A4.Ex3.m1.4.4.1.1.3.2">Δ</ci><ci id="A4.Ex3.m1.4.4.1.1.3.3.cmml" xref="A4.Ex3.m1.4.4.1.1.3.3">𝑟</ci></apply><apply id="A4.Ex3.m1.4.4.1.1.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1"><apply id="A4.Ex3.m1.4.4.1.1.1.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.2"><csymbol cd="ambiguous" id="A4.Ex3.m1.4.4.1.1.1.2.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.2">subscript</csymbol><max id="A4.Ex3.m1.4.4.1.1.1.2.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.2.2"></max><apply id="A4.Ex3.m1.2.2.2.cmml" xref="A4.Ex3.m1.2.2.2"><in id="A4.Ex3.m1.2.2.2.3.cmml" xref="A4.Ex3.m1.2.2.2.3"></in><list id="A4.Ex3.m1.2.2.2.2.2.cmml" xref="A4.Ex3.m1.2.2.2.2.1"><ci id="A4.Ex3.m1.1.1.1.1.cmml" xref="A4.Ex3.m1.1.1.1.1">𝐷</ci><apply id="A4.Ex3.m1.2.2.2.2.1.1.cmml" xref="A4.Ex3.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="A4.Ex3.m1.2.2.2.2.1.1.1.cmml" xref="A4.Ex3.m1.2.2.2.2.1.1">superscript</csymbol><ci id="A4.Ex3.m1.2.2.2.2.1.1.2.cmml" xref="A4.Ex3.m1.2.2.2.2.1.1.2">𝐷</ci><ci id="A4.Ex3.m1.2.2.2.2.1.1.3.cmml" xref="A4.Ex3.m1.2.2.2.2.1.1.3">′</ci></apply></list><ci id="A4.Ex3.m1.2.2.2.4.cmml" xref="A4.Ex3.m1.2.2.2.4">𝐃</ci></apply></apply><apply id="A4.Ex3.m1.4.4.1.1.1.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="A4.Ex3.m1.4.4.1.1.1.1.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1">subscript</csymbol><apply id="A4.Ex3.m1.4.4.1.1.1.1.1.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1"><csymbol cd="latexml" id="A4.Ex3.m1.4.4.1.1.1.1.1.2.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.2">norm</csymbol><apply id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1"><minus id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.2"></minus><apply id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3"><times id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.1"></times><ci id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.3.2">𝑟</ci><ci id="A4.Ex3.m1.3.3.cmml" xref="A4.Ex3.m1.3.3">𝐷</ci></apply><apply id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1"><times id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.2"></times><ci id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.3">𝑟</ci><apply id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2">𝐷</ci><ci id="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply></apply></apply><cn type="integer" id="A4.Ex3.m1.4.4.1.1.1.1.3.cmml" xref="A4.Ex3.m1.4.4.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.Ex3.m1.4c">\Delta r=\max_{D,D^{\prime}\in\mathbf{D}}\|r(D)-r(D^{\prime})\|_{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A4.SS2.p1.8" class="ltx_p">which provides an upper bound on the necessary perturbation to its output for privacy preservation. By appropriately selecting the value of <math id="A4.SS2.p1.7.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.SS2.p1.7.m1.1a"><mi id="A4.SS2.p1.7.m1.1.1" xref="A4.SS2.p1.7.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.7.m1.1b"><ci id="A4.SS2.p1.7.m1.1.1.cmml" xref="A4.SS2.p1.7.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.7.m1.1c">\sigma</annotation></semantics></math>, this mechanism satisfies <math id="A4.SS2.p1.8.m2.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="A4.SS2.p1.8.m2.2a"><mrow id="A4.SS2.p1.8.m2.2.3.2" xref="A4.SS2.p1.8.m2.2.3.1.cmml"><mo stretchy="false" id="A4.SS2.p1.8.m2.2.3.2.1" xref="A4.SS2.p1.8.m2.2.3.1.cmml">(</mo><mi id="A4.SS2.p1.8.m2.1.1" xref="A4.SS2.p1.8.m2.1.1.cmml">ϵ</mi><mo id="A4.SS2.p1.8.m2.2.3.2.2" xref="A4.SS2.p1.8.m2.2.3.1.cmml">,</mo><mi id="A4.SS2.p1.8.m2.2.2" xref="A4.SS2.p1.8.m2.2.2.cmml">δ</mi><mo stretchy="false" id="A4.SS2.p1.8.m2.2.3.2.3" xref="A4.SS2.p1.8.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.8.m2.2b"><interval closure="open" id="A4.SS2.p1.8.m2.2.3.1.cmml" xref="A4.SS2.p1.8.m2.2.3.2"><ci id="A4.SS2.p1.8.m2.1.1.cmml" xref="A4.SS2.p1.8.m2.1.1">italic-ϵ</ci><ci id="A4.SS2.p1.8.m2.2.2.cmml" xref="A4.SS2.p1.8.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.8.m2.2c">(\epsilon,\delta)</annotation></semantics></math>-differential privacy.</p>
</div>
</section>
<section id="A4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.3 </span>Experiment details of differential privacy</h3>

<div id="A4.SS3.p1" class="ltx_para ltx_noindent">
<p id="A4.SS3.p1.1" class="ltx_p">In our experiments with UDP, we use WildChat dataset. For convenience, the batch size is 1 in all DP experiments and other settings are the same as single-turn WildChat experiment setting, see details in Section <a href="#S4" title="4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="A4.SS3.p2" class="ltx_para ltx_noindent">
<p id="A4.SS3.p2.2" class="ltx_p">We add Gaussian noise cautiously controlled by <math id="A4.SS3.p2.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.SS3.p2.1.m1.1a"><mi id="A4.SS3.p2.1.m1.1.1" xref="A4.SS3.p2.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.1.m1.1b"><ci id="A4.SS3.p2.1.m1.1.1.cmml" xref="A4.SS3.p2.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.1.m1.1c">\sigma</annotation></semantics></math> when local clients upload their local models to the server, ensuring User-level differential privacy. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>, the value of <math id="A4.SS3.p2.2.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.SS3.p2.2.m2.1a"><mi id="A4.SS3.p2.2.m2.1.1" xref="A4.SS3.p2.2.m2.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.2.m2.1b"><ci id="A4.SS3.p2.2.m2.1.1.cmml" xref="A4.SS3.p2.2.m2.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.2.m2.1c">\sigma</annotation></semantics></math> is calculated by:</p>
<table id="A4.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A4.Ex4.m1.1" class="ltx_Math" alttext="\sigma=\delta_{l}\frac{\sqrt{2qN\ln\frac{1}{\delta}}}{\epsilon}" display="block"><semantics id="A4.Ex4.m1.1a"><mrow id="A4.Ex4.m1.1.1" xref="A4.Ex4.m1.1.1.cmml"><mi id="A4.Ex4.m1.1.1.2" xref="A4.Ex4.m1.1.1.2.cmml">σ</mi><mo id="A4.Ex4.m1.1.1.1" xref="A4.Ex4.m1.1.1.1.cmml">=</mo><mrow id="A4.Ex4.m1.1.1.3" xref="A4.Ex4.m1.1.1.3.cmml"><msub id="A4.Ex4.m1.1.1.3.2" xref="A4.Ex4.m1.1.1.3.2.cmml"><mi id="A4.Ex4.m1.1.1.3.2.2" xref="A4.Ex4.m1.1.1.3.2.2.cmml">δ</mi><mi id="A4.Ex4.m1.1.1.3.2.3" xref="A4.Ex4.m1.1.1.3.2.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="A4.Ex4.m1.1.1.3.1" xref="A4.Ex4.m1.1.1.3.1.cmml">​</mo><mfrac id="A4.Ex4.m1.1.1.3.3" xref="A4.Ex4.m1.1.1.3.3.cmml"><msqrt id="A4.Ex4.m1.1.1.3.3.2" xref="A4.Ex4.m1.1.1.3.3.2.cmml"><mrow id="A4.Ex4.m1.1.1.3.3.2.2" xref="A4.Ex4.m1.1.1.3.3.2.2.cmml"><mn id="A4.Ex4.m1.1.1.3.3.2.2.2" xref="A4.Ex4.m1.1.1.3.3.2.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="A4.Ex4.m1.1.1.3.3.2.2.1" xref="A4.Ex4.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="A4.Ex4.m1.1.1.3.3.2.2.3" xref="A4.Ex4.m1.1.1.3.3.2.2.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="A4.Ex4.m1.1.1.3.3.2.2.1a" xref="A4.Ex4.m1.1.1.3.3.2.2.1.cmml">​</mo><mi id="A4.Ex4.m1.1.1.3.3.2.2.4" xref="A4.Ex4.m1.1.1.3.3.2.2.4.cmml">N</mi><mo lspace="0.167em" rspace="0em" id="A4.Ex4.m1.1.1.3.3.2.2.1b" xref="A4.Ex4.m1.1.1.3.3.2.2.1.cmml">​</mo><mrow id="A4.Ex4.m1.1.1.3.3.2.2.5" xref="A4.Ex4.m1.1.1.3.3.2.2.5.cmml"><mi id="A4.Ex4.m1.1.1.3.3.2.2.5.1" xref="A4.Ex4.m1.1.1.3.3.2.2.5.1.cmml">ln</mi><mo lspace="0.167em" id="A4.Ex4.m1.1.1.3.3.2.2.5a" xref="A4.Ex4.m1.1.1.3.3.2.2.5.cmml">⁡</mo><mfrac id="A4.Ex4.m1.1.1.3.3.2.2.5.2" xref="A4.Ex4.m1.1.1.3.3.2.2.5.2.cmml"><mn id="A4.Ex4.m1.1.1.3.3.2.2.5.2.2" xref="A4.Ex4.m1.1.1.3.3.2.2.5.2.2.cmml">1</mn><mi id="A4.Ex4.m1.1.1.3.3.2.2.5.2.3" xref="A4.Ex4.m1.1.1.3.3.2.2.5.2.3.cmml">δ</mi></mfrac></mrow></mrow></msqrt><mi id="A4.Ex4.m1.1.1.3.3.3" xref="A4.Ex4.m1.1.1.3.3.3.cmml">ϵ</mi></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.Ex4.m1.1b"><apply id="A4.Ex4.m1.1.1.cmml" xref="A4.Ex4.m1.1.1"><eq id="A4.Ex4.m1.1.1.1.cmml" xref="A4.Ex4.m1.1.1.1"></eq><ci id="A4.Ex4.m1.1.1.2.cmml" xref="A4.Ex4.m1.1.1.2">𝜎</ci><apply id="A4.Ex4.m1.1.1.3.cmml" xref="A4.Ex4.m1.1.1.3"><times id="A4.Ex4.m1.1.1.3.1.cmml" xref="A4.Ex4.m1.1.1.3.1"></times><apply id="A4.Ex4.m1.1.1.3.2.cmml" xref="A4.Ex4.m1.1.1.3.2"><csymbol cd="ambiguous" id="A4.Ex4.m1.1.1.3.2.1.cmml" xref="A4.Ex4.m1.1.1.3.2">subscript</csymbol><ci id="A4.Ex4.m1.1.1.3.2.2.cmml" xref="A4.Ex4.m1.1.1.3.2.2">𝛿</ci><ci id="A4.Ex4.m1.1.1.3.2.3.cmml" xref="A4.Ex4.m1.1.1.3.2.3">𝑙</ci></apply><apply id="A4.Ex4.m1.1.1.3.3.cmml" xref="A4.Ex4.m1.1.1.3.3"><divide id="A4.Ex4.m1.1.1.3.3.1.cmml" xref="A4.Ex4.m1.1.1.3.3"></divide><apply id="A4.Ex4.m1.1.1.3.3.2.cmml" xref="A4.Ex4.m1.1.1.3.3.2"><root id="A4.Ex4.m1.1.1.3.3.2a.cmml" xref="A4.Ex4.m1.1.1.3.3.2"></root><apply id="A4.Ex4.m1.1.1.3.3.2.2.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2"><times id="A4.Ex4.m1.1.1.3.3.2.2.1.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.1"></times><cn type="integer" id="A4.Ex4.m1.1.1.3.3.2.2.2.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.2">2</cn><ci id="A4.Ex4.m1.1.1.3.3.2.2.3.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.3">𝑞</ci><ci id="A4.Ex4.m1.1.1.3.3.2.2.4.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.4">𝑁</ci><apply id="A4.Ex4.m1.1.1.3.3.2.2.5.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.5"><ln id="A4.Ex4.m1.1.1.3.3.2.2.5.1.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.5.1"></ln><apply id="A4.Ex4.m1.1.1.3.3.2.2.5.2.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.5.2"><divide id="A4.Ex4.m1.1.1.3.3.2.2.5.2.1.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.5.2"></divide><cn type="integer" id="A4.Ex4.m1.1.1.3.3.2.2.5.2.2.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.5.2.2">1</cn><ci id="A4.Ex4.m1.1.1.3.3.2.2.5.2.3.cmml" xref="A4.Ex4.m1.1.1.3.3.2.2.5.2.3">𝛿</ci></apply></apply></apply></apply><ci id="A4.Ex4.m1.1.1.3.3.3.cmml" xref="A4.Ex4.m1.1.1.3.3.3">italic-ϵ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.Ex4.m1.1c">\sigma=\delta_{l}\frac{\sqrt{2qN\ln\frac{1}{\delta}}}{\epsilon}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A4.SS3.p2.6" class="ltx_p">where <math id="A4.SS3.p2.3.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="A4.SS3.p2.3.m1.1a"><mi id="A4.SS3.p2.3.m1.1.1" xref="A4.SS3.p2.3.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.3.m1.1b"><ci id="A4.SS3.p2.3.m1.1.1.cmml" xref="A4.SS3.p2.3.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.3.m1.1c">q</annotation></semantics></math> is the sample fraction of clients each round, <math id="A4.SS3.p2.4.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A4.SS3.p2.4.m2.1a"><mi id="A4.SS3.p2.4.m2.1.1" xref="A4.SS3.p2.4.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.4.m2.1b"><ci id="A4.SS3.p2.4.m2.1.1.cmml" xref="A4.SS3.p2.4.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.4.m2.1c">N</annotation></semantics></math> is the federated learning communication round, <math id="A4.SS3.p2.5.m3.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="A4.SS3.p2.5.m3.2a"><mrow id="A4.SS3.p2.5.m3.2.3.2" xref="A4.SS3.p2.5.m3.2.3.1.cmml"><mo stretchy="false" id="A4.SS3.p2.5.m3.2.3.2.1" xref="A4.SS3.p2.5.m3.2.3.1.cmml">(</mo><mi id="A4.SS3.p2.5.m3.1.1" xref="A4.SS3.p2.5.m3.1.1.cmml">ϵ</mi><mo id="A4.SS3.p2.5.m3.2.3.2.2" xref="A4.SS3.p2.5.m3.2.3.1.cmml">,</mo><mi id="A4.SS3.p2.5.m3.2.2" xref="A4.SS3.p2.5.m3.2.2.cmml">δ</mi><mo stretchy="false" id="A4.SS3.p2.5.m3.2.3.2.3" xref="A4.SS3.p2.5.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.5.m3.2b"><interval closure="open" id="A4.SS3.p2.5.m3.2.3.1.cmml" xref="A4.SS3.p2.5.m3.2.3.2"><ci id="A4.SS3.p2.5.m3.1.1.cmml" xref="A4.SS3.p2.5.m3.1.1">italic-ϵ</ci><ci id="A4.SS3.p2.5.m3.2.2.cmml" xref="A4.SS3.p2.5.m3.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.5.m3.2c">(\epsilon,\delta)</annotation></semantics></math> is the DP parameters and <math id="A4.SS3.p2.6.m4.1" class="ltx_Math" alttext="delta_{l}" display="inline"><semantics id="A4.SS3.p2.6.m4.1a"><mrow id="A4.SS3.p2.6.m4.1.1" xref="A4.SS3.p2.6.m4.1.1.cmml"><mi id="A4.SS3.p2.6.m4.1.1.2" xref="A4.SS3.p2.6.m4.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="A4.SS3.p2.6.m4.1.1.1" xref="A4.SS3.p2.6.m4.1.1.1.cmml">​</mo><mi id="A4.SS3.p2.6.m4.1.1.3" xref="A4.SS3.p2.6.m4.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS3.p2.6.m4.1.1.1a" xref="A4.SS3.p2.6.m4.1.1.1.cmml">​</mo><mi id="A4.SS3.p2.6.m4.1.1.4" xref="A4.SS3.p2.6.m4.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="A4.SS3.p2.6.m4.1.1.1b" xref="A4.SS3.p2.6.m4.1.1.1.cmml">​</mo><mi id="A4.SS3.p2.6.m4.1.1.5" xref="A4.SS3.p2.6.m4.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS3.p2.6.m4.1.1.1c" xref="A4.SS3.p2.6.m4.1.1.1.cmml">​</mo><msub id="A4.SS3.p2.6.m4.1.1.6" xref="A4.SS3.p2.6.m4.1.1.6.cmml"><mi id="A4.SS3.p2.6.m4.1.1.6.2" xref="A4.SS3.p2.6.m4.1.1.6.2.cmml">a</mi><mi id="A4.SS3.p2.6.m4.1.1.6.3" xref="A4.SS3.p2.6.m4.1.1.6.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.6.m4.1b"><apply id="A4.SS3.p2.6.m4.1.1.cmml" xref="A4.SS3.p2.6.m4.1.1"><times id="A4.SS3.p2.6.m4.1.1.1.cmml" xref="A4.SS3.p2.6.m4.1.1.1"></times><ci id="A4.SS3.p2.6.m4.1.1.2.cmml" xref="A4.SS3.p2.6.m4.1.1.2">𝑑</ci><ci id="A4.SS3.p2.6.m4.1.1.3.cmml" xref="A4.SS3.p2.6.m4.1.1.3">𝑒</ci><ci id="A4.SS3.p2.6.m4.1.1.4.cmml" xref="A4.SS3.p2.6.m4.1.1.4">𝑙</ci><ci id="A4.SS3.p2.6.m4.1.1.5.cmml" xref="A4.SS3.p2.6.m4.1.1.5">𝑡</ci><apply id="A4.SS3.p2.6.m4.1.1.6.cmml" xref="A4.SS3.p2.6.m4.1.1.6"><csymbol cd="ambiguous" id="A4.SS3.p2.6.m4.1.1.6.1.cmml" xref="A4.SS3.p2.6.m4.1.1.6">subscript</csymbol><ci id="A4.SS3.p2.6.m4.1.1.6.2.cmml" xref="A4.SS3.p2.6.m4.1.1.6.2">𝑎</ci><ci id="A4.SS3.p2.6.m4.1.1.6.3.cmml" xref="A4.SS3.p2.6.m4.1.1.6.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.6.m4.1c">delta_{l}</annotation></semantics></math> is decided as follows:</p>
<table id="A4.Ex5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A4.Ex5.m1.2" class="ltx_Math" alttext="\delta_{l}=\frac{2\eta C}{\frac{\left|D\right|}{\left|n\right|}}" display="block"><semantics id="A4.Ex5.m1.2a"><mrow id="A4.Ex5.m1.2.3" xref="A4.Ex5.m1.2.3.cmml"><msub id="A4.Ex5.m1.2.3.2" xref="A4.Ex5.m1.2.3.2.cmml"><mi id="A4.Ex5.m1.2.3.2.2" xref="A4.Ex5.m1.2.3.2.2.cmml">δ</mi><mi id="A4.Ex5.m1.2.3.2.3" xref="A4.Ex5.m1.2.3.2.3.cmml">l</mi></msub><mo id="A4.Ex5.m1.2.3.1" xref="A4.Ex5.m1.2.3.1.cmml">=</mo><mfrac id="A4.Ex5.m1.2.2" xref="A4.Ex5.m1.2.2.cmml"><mrow id="A4.Ex5.m1.2.2.4" xref="A4.Ex5.m1.2.2.4.cmml"><mn id="A4.Ex5.m1.2.2.4.2" xref="A4.Ex5.m1.2.2.4.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="A4.Ex5.m1.2.2.4.1" xref="A4.Ex5.m1.2.2.4.1.cmml">​</mo><mi id="A4.Ex5.m1.2.2.4.3" xref="A4.Ex5.m1.2.2.4.3.cmml">η</mi><mo lspace="0em" rspace="0em" id="A4.Ex5.m1.2.2.4.1a" xref="A4.Ex5.m1.2.2.4.1.cmml">​</mo><mi id="A4.Ex5.m1.2.2.4.4" xref="A4.Ex5.m1.2.2.4.4.cmml">C</mi></mrow><mfrac id="A4.Ex5.m1.2.2.2" xref="A4.Ex5.m1.2.2.2.cmml"><mrow id="A4.Ex5.m1.1.1.1.1.1.3" xref="A4.Ex5.m1.1.1.1.1.1.2.cmml"><mo id="A4.Ex5.m1.1.1.1.1.1.3.1" xref="A4.Ex5.m1.1.1.1.1.1.2.1.cmml">|</mo><mi id="A4.Ex5.m1.1.1.1.1.1.1" xref="A4.Ex5.m1.1.1.1.1.1.1.cmml">D</mi><mo id="A4.Ex5.m1.1.1.1.1.1.3.2" xref="A4.Ex5.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="A4.Ex5.m1.2.2.2.2.2.3" xref="A4.Ex5.m1.2.2.2.2.2.2.cmml"><mo id="A4.Ex5.m1.2.2.2.2.2.3.1" xref="A4.Ex5.m1.2.2.2.2.2.2.1.cmml">|</mo><mi id="A4.Ex5.m1.2.2.2.2.2.1" xref="A4.Ex5.m1.2.2.2.2.2.1.cmml">n</mi><mo id="A4.Ex5.m1.2.2.2.2.2.3.2" xref="A4.Ex5.m1.2.2.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mfrac></mrow><annotation-xml encoding="MathML-Content" id="A4.Ex5.m1.2b"><apply id="A4.Ex5.m1.2.3.cmml" xref="A4.Ex5.m1.2.3"><eq id="A4.Ex5.m1.2.3.1.cmml" xref="A4.Ex5.m1.2.3.1"></eq><apply id="A4.Ex5.m1.2.3.2.cmml" xref="A4.Ex5.m1.2.3.2"><csymbol cd="ambiguous" id="A4.Ex5.m1.2.3.2.1.cmml" xref="A4.Ex5.m1.2.3.2">subscript</csymbol><ci id="A4.Ex5.m1.2.3.2.2.cmml" xref="A4.Ex5.m1.2.3.2.2">𝛿</ci><ci id="A4.Ex5.m1.2.3.2.3.cmml" xref="A4.Ex5.m1.2.3.2.3">𝑙</ci></apply><apply id="A4.Ex5.m1.2.2.cmml" xref="A4.Ex5.m1.2.2"><divide id="A4.Ex5.m1.2.2.3.cmml" xref="A4.Ex5.m1.2.2"></divide><apply id="A4.Ex5.m1.2.2.4.cmml" xref="A4.Ex5.m1.2.2.4"><times id="A4.Ex5.m1.2.2.4.1.cmml" xref="A4.Ex5.m1.2.2.4.1"></times><cn type="integer" id="A4.Ex5.m1.2.2.4.2.cmml" xref="A4.Ex5.m1.2.2.4.2">2</cn><ci id="A4.Ex5.m1.2.2.4.3.cmml" xref="A4.Ex5.m1.2.2.4.3">𝜂</ci><ci id="A4.Ex5.m1.2.2.4.4.cmml" xref="A4.Ex5.m1.2.2.4.4">𝐶</ci></apply><apply id="A4.Ex5.m1.2.2.2.cmml" xref="A4.Ex5.m1.2.2.2"><divide id="A4.Ex5.m1.2.2.2.3.cmml" xref="A4.Ex5.m1.2.2.2"></divide><apply id="A4.Ex5.m1.1.1.1.1.1.2.cmml" xref="A4.Ex5.m1.1.1.1.1.1.3"><abs id="A4.Ex5.m1.1.1.1.1.1.2.1.cmml" xref="A4.Ex5.m1.1.1.1.1.1.3.1"></abs><ci id="A4.Ex5.m1.1.1.1.1.1.1.cmml" xref="A4.Ex5.m1.1.1.1.1.1.1">𝐷</ci></apply><apply id="A4.Ex5.m1.2.2.2.2.2.2.cmml" xref="A4.Ex5.m1.2.2.2.2.2.3"><abs id="A4.Ex5.m1.2.2.2.2.2.2.1.cmml" xref="A4.Ex5.m1.2.2.2.2.2.3.1"></abs><ci id="A4.Ex5.m1.2.2.2.2.2.1.cmml" xref="A4.Ex5.m1.2.2.2.2.2.1">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.Ex5.m1.2c">\delta_{l}=\frac{2\eta C}{\frac{\left|D\right|}{\left|n\right|}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A4.SS3.p2.14" class="ltx_p">where <math id="A4.SS3.p2.7.m1.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="A4.SS3.p2.7.m1.1a"><mi id="A4.SS3.p2.7.m1.1.1" xref="A4.SS3.p2.7.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.7.m1.1b"><ci id="A4.SS3.p2.7.m1.1.1.cmml" xref="A4.SS3.p2.7.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.7.m1.1c">\eta</annotation></semantics></math> is the learning rate, <math id="A4.SS3.p2.8.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A4.SS3.p2.8.m2.1a"><mi id="A4.SS3.p2.8.m2.1.1" xref="A4.SS3.p2.8.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.8.m2.1b"><ci id="A4.SS3.p2.8.m2.1.1.cmml" xref="A4.SS3.p2.8.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.8.m2.1c">C</annotation></semantics></math> is the maximum of gradients, <math id="A4.SS3.p2.9.m3.1" class="ltx_Math" alttext="\left|D\right|" display="inline"><semantics id="A4.SS3.p2.9.m3.1a"><mrow id="A4.SS3.p2.9.m3.1.2.2" xref="A4.SS3.p2.9.m3.1.2.1.cmml"><mo id="A4.SS3.p2.9.m3.1.2.2.1" xref="A4.SS3.p2.9.m3.1.2.1.1.cmml">|</mo><mi id="A4.SS3.p2.9.m3.1.1" xref="A4.SS3.p2.9.m3.1.1.cmml">D</mi><mo id="A4.SS3.p2.9.m3.1.2.2.2" xref="A4.SS3.p2.9.m3.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.9.m3.1b"><apply id="A4.SS3.p2.9.m3.1.2.1.cmml" xref="A4.SS3.p2.9.m3.1.2.2"><abs id="A4.SS3.p2.9.m3.1.2.1.1.cmml" xref="A4.SS3.p2.9.m3.1.2.2.1"></abs><ci id="A4.SS3.p2.9.m3.1.1.cmml" xref="A4.SS3.p2.9.m3.1.1">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.9.m3.1c">\left|D\right|</annotation></semantics></math> is the size of dataset and <math id="A4.SS3.p2.10.m4.1" class="ltx_Math" alttext="\left|n\right|" display="inline"><semantics id="A4.SS3.p2.10.m4.1a"><mrow id="A4.SS3.p2.10.m4.1.2.2" xref="A4.SS3.p2.10.m4.1.2.1.cmml"><mo id="A4.SS3.p2.10.m4.1.2.2.1" xref="A4.SS3.p2.10.m4.1.2.1.1.cmml">|</mo><mi id="A4.SS3.p2.10.m4.1.1" xref="A4.SS3.p2.10.m4.1.1.cmml">n</mi><mo id="A4.SS3.p2.10.m4.1.2.2.2" xref="A4.SS3.p2.10.m4.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.10.m4.1b"><apply id="A4.SS3.p2.10.m4.1.2.1.cmml" xref="A4.SS3.p2.10.m4.1.2.2"><abs id="A4.SS3.p2.10.m4.1.2.1.1.cmml" xref="A4.SS3.p2.10.m4.1.2.2.1"></abs><ci id="A4.SS3.p2.10.m4.1.1.cmml" xref="A4.SS3.p2.10.m4.1.1">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.10.m4.1c">\left|n\right|</annotation></semantics></math> is the number of clients. Note that when expressed with <math id="A4.SS3.p2.11.m5.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="A4.SS3.p2.11.m5.2a"><mrow id="A4.SS3.p2.11.m5.2.3.2" xref="A4.SS3.p2.11.m5.2.3.1.cmml"><mo stretchy="false" id="A4.SS3.p2.11.m5.2.3.2.1" xref="A4.SS3.p2.11.m5.2.3.1.cmml">(</mo><mi id="A4.SS3.p2.11.m5.1.1" xref="A4.SS3.p2.11.m5.1.1.cmml">ϵ</mi><mo id="A4.SS3.p2.11.m5.2.3.2.2" xref="A4.SS3.p2.11.m5.2.3.1.cmml">,</mo><mi id="A4.SS3.p2.11.m5.2.2" xref="A4.SS3.p2.11.m5.2.2.cmml">δ</mi><mo stretchy="false" id="A4.SS3.p2.11.m5.2.3.2.3" xref="A4.SS3.p2.11.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.11.m5.2b"><interval closure="open" id="A4.SS3.p2.11.m5.2.3.1.cmml" xref="A4.SS3.p2.11.m5.2.3.2"><ci id="A4.SS3.p2.11.m5.1.1.cmml" xref="A4.SS3.p2.11.m5.1.1">italic-ϵ</ci><ci id="A4.SS3.p2.11.m5.2.2.cmml" xref="A4.SS3.p2.11.m5.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.11.m5.2c">(\epsilon,\delta)</annotation></semantics></math>, smaller <math id="A4.SS3.p2.12.m6.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="A4.SS3.p2.12.m6.1a"><mi id="A4.SS3.p2.12.m6.1.1" xref="A4.SS3.p2.12.m6.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.12.m6.1b"><ci id="A4.SS3.p2.12.m6.1.1.cmml" xref="A4.SS3.p2.12.m6.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.12.m6.1c">\epsilon</annotation></semantics></math> means smaller privacy budget, in other words, better privacy and usually lower performance. However, when expressed with <math id="A4.SS3.p2.13.m7.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.SS3.p2.13.m7.1a"><mi id="A4.SS3.p2.13.m7.1.1" xref="A4.SS3.p2.13.m7.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.13.m7.1b"><ci id="A4.SS3.p2.13.m7.1.1.cmml" xref="A4.SS3.p2.13.m7.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.13.m7.1c">\sigma</annotation></semantics></math>, larger <math id="A4.SS3.p2.14.m8.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.SS3.p2.14.m8.1a"><mi id="A4.SS3.p2.14.m8.1.1" xref="A4.SS3.p2.14.m8.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p2.14.m8.1b"><ci id="A4.SS3.p2.14.m8.1.1.cmml" xref="A4.SS3.p2.14.m8.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p2.14.m8.1c">\sigma</annotation></semantics></math> means better privacy and usually lower performance.</p>
</div>
<div id="A4.SS3.p3" class="ltx_para ltx_noindent">
<p id="A4.SS3.p3.1" class="ltx_p">Our experiment results are shown in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.2 Further explorations ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>
and Table <a href="#A4.T8" title="Table 8 ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Figure <a href="#S4.F6" title="Figure 6 ‣ 4.2 Further explorations ‣ 4 Experiments on FedLLM-Bench ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows that FedLLM with <math id="A4.SS3.p3.1.m1.2" class="ltx_Math" alttext="(0.01,1e^{-4})" display="inline"><semantics id="A4.SS3.p3.1.m1.2a"><mrow id="A4.SS3.p3.1.m1.2.2.1" xref="A4.SS3.p3.1.m1.2.2.2.cmml"><mo stretchy="false" id="A4.SS3.p3.1.m1.2.2.1.2" xref="A4.SS3.p3.1.m1.2.2.2.cmml">(</mo><mn id="A4.SS3.p3.1.m1.1.1" xref="A4.SS3.p3.1.m1.1.1.cmml">0.01</mn><mo id="A4.SS3.p3.1.m1.2.2.1.3" xref="A4.SS3.p3.1.m1.2.2.2.cmml">,</mo><mrow id="A4.SS3.p3.1.m1.2.2.1.1" xref="A4.SS3.p3.1.m1.2.2.1.1.cmml"><mn id="A4.SS3.p3.1.m1.2.2.1.1.2" xref="A4.SS3.p3.1.m1.2.2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A4.SS3.p3.1.m1.2.2.1.1.1" xref="A4.SS3.p3.1.m1.2.2.1.1.1.cmml">​</mo><msup id="A4.SS3.p3.1.m1.2.2.1.1.3" xref="A4.SS3.p3.1.m1.2.2.1.1.3.cmml"><mi id="A4.SS3.p3.1.m1.2.2.1.1.3.2" xref="A4.SS3.p3.1.m1.2.2.1.1.3.2.cmml">e</mi><mrow id="A4.SS3.p3.1.m1.2.2.1.1.3.3" xref="A4.SS3.p3.1.m1.2.2.1.1.3.3.cmml"><mo id="A4.SS3.p3.1.m1.2.2.1.1.3.3a" xref="A4.SS3.p3.1.m1.2.2.1.1.3.3.cmml">−</mo><mn id="A4.SS3.p3.1.m1.2.2.1.1.3.3.2" xref="A4.SS3.p3.1.m1.2.2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><mo stretchy="false" id="A4.SS3.p3.1.m1.2.2.1.4" xref="A4.SS3.p3.1.m1.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS3.p3.1.m1.2b"><interval closure="open" id="A4.SS3.p3.1.m1.2.2.2.cmml" xref="A4.SS3.p3.1.m1.2.2.1"><cn type="float" id="A4.SS3.p3.1.m1.1.1.cmml" xref="A4.SS3.p3.1.m1.1.1">0.01</cn><apply id="A4.SS3.p3.1.m1.2.2.1.1.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1"><times id="A4.SS3.p3.1.m1.2.2.1.1.1.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.1"></times><cn type="integer" id="A4.SS3.p3.1.m1.2.2.1.1.2.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.2">1</cn><apply id="A4.SS3.p3.1.m1.2.2.1.1.3.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="A4.SS3.p3.1.m1.2.2.1.1.3.1.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.3">superscript</csymbol><ci id="A4.SS3.p3.1.m1.2.2.1.1.3.2.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.3.2">𝑒</ci><apply id="A4.SS3.p3.1.m1.2.2.1.1.3.3.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.3.3"><minus id="A4.SS3.p3.1.m1.2.2.1.1.3.3.1.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.3.3"></minus><cn type="integer" id="A4.SS3.p3.1.m1.2.2.1.1.3.3.2.cmml" xref="A4.SS3.p3.1.m1.2.2.1.1.3.3.2">4</cn></apply></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p3.1.m1.2c">(0.01,1e^{-4})</annotation></semantics></math>-DP still outperforms local training and differential privacy costs slight model performance while ensuring user-level differential privacy.</p>
</div>
<div id="A4.SS3.p4" class="ltx_para ltx_noindent">
<p id="A4.SS3.p4.3" class="ltx_p">In fact, the <math id="A4.SS3.p4.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.SS3.p4.1.m1.1a"><mi id="A4.SS3.p4.1.m1.1.1" xref="A4.SS3.p4.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p4.1.m1.1b"><ci id="A4.SS3.p4.1.m1.1.1.cmml" xref="A4.SS3.p4.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p4.1.m1.1c">\sigma</annotation></semantics></math> calculated in Section <a href="#A4.SS2" title="D.2 User-level differential privacy ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D.2</span></a> is a proper bound when ensuring user-level differential privacy with given <math id="A4.SS3.p4.2.m2.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="A4.SS3.p4.2.m2.2a"><mrow id="A4.SS3.p4.2.m2.2.3.2" xref="A4.SS3.p4.2.m2.2.3.1.cmml"><mo stretchy="false" id="A4.SS3.p4.2.m2.2.3.2.1" xref="A4.SS3.p4.2.m2.2.3.1.cmml">(</mo><mi id="A4.SS3.p4.2.m2.1.1" xref="A4.SS3.p4.2.m2.1.1.cmml">ϵ</mi><mo id="A4.SS3.p4.2.m2.2.3.2.2" xref="A4.SS3.p4.2.m2.2.3.1.cmml">,</mo><mi id="A4.SS3.p4.2.m2.2.2" xref="A4.SS3.p4.2.m2.2.2.cmml">δ</mi><mo stretchy="false" id="A4.SS3.p4.2.m2.2.3.2.3" xref="A4.SS3.p4.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.SS3.p4.2.m2.2b"><interval closure="open" id="A4.SS3.p4.2.m2.2.3.1.cmml" xref="A4.SS3.p4.2.m2.2.3.2"><ci id="A4.SS3.p4.2.m2.1.1.cmml" xref="A4.SS3.p4.2.m2.1.1">italic-ϵ</ci><ci id="A4.SS3.p4.2.m2.2.2.cmml" xref="A4.SS3.p4.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p4.2.m2.2c">(\epsilon,\delta)</annotation></semantics></math>. We also conduct experiments with fixed <math id="A4.SS3.p4.3.m3.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="A4.SS3.p4.3.m3.1a"><mi id="A4.SS3.p4.3.m3.1.1" xref="A4.SS3.p4.3.m3.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="A4.SS3.p4.3.m3.1b"><ci id="A4.SS3.p4.3.m3.1.1.cmml" xref="A4.SS3.p4.3.m3.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS3.p4.3.m3.1c">\sigma</annotation></semantics></math> and results are shown in Table <a href="#A4.T8" title="Table 8 ‣ Appendix D More details about differential privacy ‣ FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A4.F9" class="ltx_figure"><img src="/html/2406.04845/assets/figs/Aya_w3-l4_sunburst.png" id="A4.F9.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="957" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>The top 20 most common root verbs (inner circle) and their top 4 direct noun objects (outer circle) in the instructions of <span id="A4.F9.2.1" class="ltx_text ltx_font_bold">Aya</span> for 12 different English clients. We select English clients on purpose.</figcaption>
</figure>
<figure id="A4.F10" class="ltx_figure"><img src="/html/2406.04845/assets/figs/Chatbot_w4-l5_sunburst.png" id="A4.F10.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="897" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>The top 20 most common root verbs (inner circle) and their top 4 direct noun objects (outer circle) in the instructions of <span id="A4.F10.2.1" class="ltx_text ltx_font_bold">ChatbotIT</span> for 20 different clients.</figcaption>
</figure>
<figure id="A4.F11" class="ltx_figure"><img src="/html/2406.04845/assets/figs/WildChat_w4-l5_sunburst.png" id="A4.F11.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="897" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>The top 20 most common root verbs (inner circle) and their top 4 direct noun objects (outer circle) in the instructions of <span id="A4.F11.2.1" class="ltx_text ltx_font_bold">WildChat</span> for 20 different clients.</figcaption>
</figure>
<figure id="A4.F12" class="ltx_figure"><img src="/html/2406.04845/assets/figs/Chatbot-dpo_w4-l5_sunburst.png" id="A4.F12.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="897" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>The top 20 most common root verbs (inner circle) and their top 4 direct noun objects (outer circle) in the instructions of <span id="A4.F12.2.1" class="ltx_text ltx_font_bold">ChatbotPA</span> for 20 different clients.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.04844" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.04845" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.04845">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.04845" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.04846" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 23:06:21 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
