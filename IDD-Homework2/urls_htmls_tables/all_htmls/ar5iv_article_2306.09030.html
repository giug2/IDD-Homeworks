<article class="ltx_document ltx_authors_1line">
 <span class="ltx_ERROR undefined" id="id1">
  \DeclareMathOperator
 </span>
 <div class="ltx_para" id="p1">
  <p class="ltx_p" id="p1.1">
   *
   <span class="ltx_ERROR undefined" id="p1.1.1">
    \argmax
   </span>
   arg max
   <span class="ltx_ERROR undefined" id="p1.1.2">
    \DeclareMathOperator
   </span>
   *
   <span class="ltx_ERROR undefined" id="p1.1.3">
    \argmin
   </span>
   arg min
   <span class="ltx_ERROR undefined" id="p1.1.4">
    \DeclareMathOperator
   </span>
   *
   <span class="ltx_ERROR undefined" id="p1.1.5">
    \softmax
   </span>
   Softmax
  </p>
 </div>
 <h1 class="ltx_title ltx_title_document">
  <span class="ltx_ERROR undefined" id="id11.id1">
   \scalerel
  </span>
  *
  <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="337" id="id1.g1" src="x1.png" width="371"/>
  ○
  <span class="ltx_text" id="id12.id2" style="color:#FF00FF;">
   Di
   <span class="ltx_text" id="id12.id2.1" style="color:#00FFFF;">
    P
   </span>
   lo
   <span class="ltx_text" id="id12.id2.2" style="color:#00FFFF;">
    mat
   </span>
  </span>
  :
  <br class="ltx_break"/>
  A
  <span class="ltx_text" id="id13.id3" style="color:#FF00FF;">
   Di
  </span>
  a
  <span class="ltx_text" id="id14.id4" style="color:#FF00FF;">
   lo
  </span>
  gue Dataset for Situated
  <span class="ltx_text" id="id15.id5" style="color:#00FFFF;">
   P
  </span>
  rag
  <span class="ltx_text" id="id16.id6" style="color:#00FFFF;">
   mat
  </span>
  ic Reasoning
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Hengli Li
    <math alttext="{}^{1,2}" class="ltx_Math" display="inline" id="id2.1.m1.2">
     <semantics id="id2.1.m1.2a">
      <msup id="id2.1.m1.2.2" xref="id2.1.m1.2.2.cmml">
       <mi id="id2.1.m1.2.2a" xref="id2.1.m1.2.2.cmml">
       </mi>
       <mrow id="id2.1.m1.2.2.2.4" xref="id2.1.m1.2.2.2.3.cmml">
        <mn id="id2.1.m1.1.1.1.1" xref="id2.1.m1.1.1.1.1.cmml">
         1
        </mn>
        <mo id="id2.1.m1.2.2.2.4.1" xref="id2.1.m1.2.2.2.3.cmml">
         ,
        </mo>
        <mn id="id2.1.m1.2.2.2.2" xref="id2.1.m1.2.2.2.2.cmml">
         2
        </mn>
       </mrow>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id2.1.m1.2b">
       <apply id="id2.1.m1.2.2.cmml" xref="id2.1.m1.2.2">
        <list id="id2.1.m1.2.2.2.3.cmml" xref="id2.1.m1.2.2.2.4">
         <cn id="id2.1.m1.1.1.1.1.cmml" type="integer" xref="id2.1.m1.1.1.1.1">
          1
         </cn>
         <cn id="id2.1.m1.2.2.2.2.cmml" type="integer" xref="id2.1.m1.2.2.2.2">
          2
         </cn>
        </list>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id2.1.m1.2c">
       {}^{1,2}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id2.1.m1.2d">
       start_FLOATSUPERSCRIPT 1 , 2 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    , Song-Chun Zhu
    <math alttext="{}^{1,3,4,5}" class="ltx_Math" display="inline" id="id3.2.m2.4">
     <semantics id="id3.2.m2.4a">
      <msup id="id3.2.m2.4.4" xref="id3.2.m2.4.4.cmml">
       <mi id="id3.2.m2.4.4a" xref="id3.2.m2.4.4.cmml">
       </mi>
       <mrow id="id3.2.m2.4.4.4.6" xref="id3.2.m2.4.4.4.5.cmml">
        <mn id="id3.2.m2.1.1.1.1" xref="id3.2.m2.1.1.1.1.cmml">
         1
        </mn>
        <mo id="id3.2.m2.4.4.4.6.1" xref="id3.2.m2.4.4.4.5.cmml">
         ,
        </mo>
        <mn id="id3.2.m2.2.2.2.2" xref="id3.2.m2.2.2.2.2.cmml">
         3
        </mn>
        <mo id="id3.2.m2.4.4.4.6.2" xref="id3.2.m2.4.4.4.5.cmml">
         ,
        </mo>
        <mn id="id3.2.m2.3.3.3.3" xref="id3.2.m2.3.3.3.3.cmml">
         4
        </mn>
        <mo id="id3.2.m2.4.4.4.6.3" xref="id3.2.m2.4.4.4.5.cmml">
         ,
        </mo>
        <mn id="id3.2.m2.4.4.4.4" xref="id3.2.m2.4.4.4.4.cmml">
         5
        </mn>
       </mrow>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id3.2.m2.4b">
       <apply id="id3.2.m2.4.4.cmml" xref="id3.2.m2.4.4">
        <list id="id3.2.m2.4.4.4.5.cmml" xref="id3.2.m2.4.4.4.6">
         <cn id="id3.2.m2.1.1.1.1.cmml" type="integer" xref="id3.2.m2.1.1.1.1">
          1
         </cn>
         <cn id="id3.2.m2.2.2.2.2.cmml" type="integer" xref="id3.2.m2.2.2.2.2">
          3
         </cn>
         <cn id="id3.2.m2.3.3.3.3.cmml" type="integer" xref="id3.2.m2.3.3.3.3">
          4
         </cn>
         <cn id="id3.2.m2.4.4.4.4.cmml" type="integer" xref="id3.2.m2.4.4.4.4">
          5
         </cn>
        </list>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id3.2.m2.4c">
       {}^{1,3,4,5}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id3.2.m2.4d">
       start_FLOATSUPERSCRIPT 1 , 3 , 4 , 5 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    , Zilong Zheng
    <math alttext="{}^{1}" class="ltx_Math" display="inline" id="id4.3.m3.1">
     <semantics id="id4.3.m3.1a">
      <msup id="id4.3.m3.1.1" xref="id4.3.m3.1.1.cmml">
       <mi id="id4.3.m3.1.1a" xref="id4.3.m3.1.1.cmml">
       </mi>
       <mn id="id4.3.m3.1.1.1" xref="id4.3.m3.1.1.1.cmml">
        1
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id4.3.m3.1b">
       <apply id="id4.3.m3.1.1.cmml" xref="id4.3.m3.1.1">
        <cn id="id4.3.m3.1.1.1.cmml" type="integer" xref="id4.3.m3.1.1.1">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id4.3.m3.1c">
       {}^{1}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id4.3.m3.1d">
       start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    <br class="ltx_break"/>
    <math alttext="{}^{1}" class="ltx_Math" display="inline" id="id5.4.m4.1">
     <semantics id="id5.4.m4.1a">
      <msup id="id5.4.m4.1.1" xref="id5.4.m4.1.1.cmml">
       <mi id="id5.4.m4.1.1a" xref="id5.4.m4.1.1.cmml">
       </mi>
       <mn id="id5.4.m4.1.1.1" xref="id5.4.m4.1.1.1.cmml">
        1
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id5.4.m4.1b">
       <apply id="id5.4.m4.1.1.cmml" xref="id5.4.m4.1.1">
        <cn id="id5.4.m4.1.1.1.cmml" type="integer" xref="id5.4.m4.1.1.1">
         1
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id5.4.m4.1c">
       {}^{1}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id5.4.m4.1d">
       start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    Beijing Institute for General Artificial Intelligence (BIGAI)
    <br class="ltx_break"/>
    <math alttext="{}^{2}" class="ltx_Math" display="inline" id="id6.5.m5.1">
     <semantics id="id6.5.m5.1a">
      <msup id="id6.5.m5.1.1" xref="id6.5.m5.1.1.cmml">
       <mi id="id6.5.m5.1.1a" xref="id6.5.m5.1.1.cmml">
       </mi>
       <mn id="id6.5.m5.1.1.1" xref="id6.5.m5.1.1.1.cmml">
        2
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id6.5.m5.1b">
       <apply id="id6.5.m5.1.1.cmml" xref="id6.5.m5.1.1">
        <cn id="id6.5.m5.1.1.1.cmml" type="integer" xref="id6.5.m5.1.1.1">
         2
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id6.5.m5.1c">
       {}^{2}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id6.5.m5.1d">
       start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    Yuanpei College, Peking University
    <br class="ltx_break"/>
    <math alttext="{}^{3}" class="ltx_Math" display="inline" id="id7.6.m6.1">
     <semantics id="id7.6.m6.1a">
      <msup id="id7.6.m6.1.1" xref="id7.6.m6.1.1.cmml">
       <mi id="id7.6.m6.1.1a" xref="id7.6.m6.1.1.cmml">
       </mi>
       <mn id="id7.6.m6.1.1.1" xref="id7.6.m6.1.1.1.cmml">
        3
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id7.6.m6.1b">
       <apply id="id7.6.m6.1.1.cmml" xref="id7.6.m6.1.1">
        <cn id="id7.6.m6.1.1.1.cmml" type="integer" xref="id7.6.m6.1.1.1">
         3
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id7.6.m6.1c">
       {}^{3}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id7.6.m6.1d">
       start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    Institute for Artificial Intelligence, Peking University
    <br class="ltx_break"/>
    <math alttext="{}^{4}" class="ltx_Math" display="inline" id="id8.7.m7.1">
     <semantics id="id8.7.m7.1a">
      <msup id="id8.7.m7.1.1" xref="id8.7.m7.1.1.cmml">
       <mi id="id8.7.m7.1.1a" xref="id8.7.m7.1.1.cmml">
       </mi>
       <mn id="id8.7.m7.1.1.1" xref="id8.7.m7.1.1.1.cmml">
        4
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id8.7.m7.1b">
       <apply id="id8.7.m7.1.1.cmml" xref="id8.7.m7.1.1">
        <cn id="id8.7.m7.1.1.1.cmml" type="integer" xref="id8.7.m7.1.1.1">
         4
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id8.7.m7.1c">
       {}^{4}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id8.7.m7.1d">
       start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    School of Intelligence Science and Technology, Peking University
    <br class="ltx_break"/>
    <math alttext="{}^{5}" class="ltx_Math" display="inline" id="id9.8.m8.1">
     <semantics id="id9.8.m8.1a">
      <msup id="id9.8.m8.1.1" xref="id9.8.m8.1.1.cmml">
       <mi id="id9.8.m8.1.1a" xref="id9.8.m8.1.1.cmml">
       </mi>
       <mn id="id9.8.m8.1.1.1" xref="id9.8.m8.1.1.1.cmml">
        5
       </mn>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id9.8.m8.1b">
       <apply id="id9.8.m8.1.1.cmml" xref="id9.8.m8.1.1">
        <cn id="id9.8.m8.1.1.1.cmml" type="integer" xref="id9.8.m8.1.1.1">
         5
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id9.8.m8.1c">
       {}^{5}
      </annotation>
      <annotation encoding="application/x-llamapun" id="id9.8.m8.1d">
       start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT
      </annotation>
     </semantics>
    </math>
    Department of Automation, Tsinghua University
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id17.9.id1" style="font-size:90%;">
     lihengli@stu.pku.edu.cn, s.c.zhu@pku.edu.cn, zlzheng@bigai.ai
    </span>
    <br class="ltx_break"/>
    <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://diplomat-dataset.github.io" title="">
     https://diplomat-dataset.github.io
    </a>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id10.1">
   Pragmatic reasoning plays a pivotal role in deciphering implicit meanings that frequently arise in real-life conversations and is essential for the development of communicative social agents.
In this paper, we introduce a novel challenge,
   <span class="ltx_text ltx_font_bold" id="id10.1.1">
    DiPlomat
   </span>
   , aiming at benchmarking machines’ capabilities on pragmatic reasoning and situated conversational understanding. Compared with previous works that treat different figurative expressions (
   <em class="ltx_emph ltx_font_italic" id="id10.1.2">
    e.g
   </em>
   .
   <span class="ltx_text" id="id10.1.3">
   </span>
   metaphor, sarcasm) as individual tasks,
   <span class="ltx_text ltx_font_bold" id="id10.1.4">
    DiPlomat
   </span>
   provides a cohesive framework towards general pragmatic understanding. Our dataset is created through the utilization of
   <span class="ltx_glossaryref" title="Amazon Mechanical Turk">
    <span class="ltx_text ltx_glossary_long">
     Amazon Mechanical Turk
    </span>
   </span>
   (
   <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
    <span class="ltx_text ltx_glossary_short">
     AMT
    </span>
   </abbr>
   ), resulting in a total of
   <math alttext="4,177" class="ltx_Math" display="inline" id="id10.1.m1.2">
    <semantics id="id10.1.m1.2a">
     <mrow id="id10.1.m1.2.3.2" xref="id10.1.m1.2.3.1.cmml">
      <mn id="id10.1.m1.1.1" xref="id10.1.m1.1.1.cmml">
       4
      </mn>
      <mo id="id10.1.m1.2.3.2.1" xref="id10.1.m1.2.3.1.cmml">
       ,
      </mo>
      <mn id="id10.1.m1.2.2" xref="id10.1.m1.2.2.cmml">
       177
      </mn>
     </mrow>
     <annotation-xml encoding="MathML-Content" id="id10.1.m1.2b">
      <list id="id10.1.m1.2.3.1.cmml" xref="id10.1.m1.2.3.2">
       <cn id="id10.1.m1.1.1.cmml" type="integer" xref="id10.1.m1.1.1">
        4
       </cn>
       <cn id="id10.1.m1.2.2.cmml" type="integer" xref="id10.1.m1.2.2">
        177
       </cn>
      </list>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="id10.1.m1.2c">
      4,177
     </annotation>
     <annotation encoding="application/x-llamapun" id="id10.1.m1.2d">
      4 , 177
     </annotation>
    </semantics>
   </math>
   multi-turn dialogues. In conjunction with the dataset, we propose two tasks, Pragmatic Identification and Reasoning (PIR) and Conversational Question Answering (CQA). Experimental results with state-of-the-art (SOTA) neural architectures reveal several significant findings: 1)
   <span class="ltx_glossaryref" title="large language model">
    <span class="ltx_text ltx_glossary_long-plural">
     large language models
    </span>
   </span>
   exhibit poor performance in tackling this subjective domain; 2) comprehensive comprehension of context emerges as a critical factor for establishing benign human-machine interactions; 3) current models defect in the application of pragmatic reasoning. As a result, we call on more attention to improve the ability of context understanding, reasoning, and implied meaning modeling.
  </p>
 </div>
 <figure class="ltx_figure" id="S0.F1">
  <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="196" id="S0.F1.g1" src="x2.png" width="830"/>
  <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
   <span class="ltx_tag ltx_tag_figure">
    Figure 1:
   </span>
   <span class="ltx_text ltx_font_bold" id="S0.F1.5.1">
    Illustration of DiPlomat dataset.
   </span>
   Left: Example of a pragmatic conversation. Right: Pragmatic Identification and Reasoning task.
  </figcaption>
 </figure>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    The fabric of human sociality is made up of complicated relations that evolve through different dimensions of interaction and communication channels
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Ambrasat et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib1" title="">
      <span class="ltx_text" style="font-size:90%;">
       2014
      </span>
     </a>
     );
     <span class="ltx_text" style="font-size:90%;">
      Fiske
     </span>
     (
     <a class="ltx_ref" href="#bib.bib2" title="">
      <span class="ltx_text" style="font-size:90%;">
       1992
      </span>
     </a>
     )
    </cite>
    . Social consensuses, such as social norms and values, are thereby formed between humans that convey meanings of individual minds, including beliefs, intentions and desires
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Bargh and Chartrand
     </span>
     (
     <a class="ltx_ref" href="#bib.bib3" title="">
      <span class="ltx_text" style="font-size:90%;">
       1999
      </span>
     </a>
     )
    </cite>
    . In a process of effective negotiation and social conversation, particularly, such social behaviors are only partly driven by
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.1">
     literal
    </span>
    meanings that are
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">
     objective
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.3">
     rational
    </span>
    and
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.4">
     explicit
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Finegan
     </span>
     (
     <a class="ltx_ref" href="#bib.bib4" title="">
      <span class="ltx_text" style="font-size:90%;">
       2014
      </span>
     </a>
     );
     <span class="ltx_text" style="font-size:90%;">
      † et al.(2022)(FAIR)†, Bakhtin, Brown, Dinan, Farina,
Flaherty, Fried, Goff, Gray, Hu, et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib5" title="">
      <span class="ltx_text" style="font-size:90%;">
       FAIR
      </span>
     </a>
     )
    </cite>
    . Instead, these behaviors are commonly governed by affective or
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.5">
     pragmatic
    </span>
    meanings of dialogue utterances that refer to the emotional and cultural meanings of conversational partners and are
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.6">
     subjective
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.7">
     emotional
    </span>
    and
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.8">
     implicit
    </span>
    . For instance in
    <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Figure
     </span>
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    , the lady responds with “I doubt that” rather than “I am not tired of you” to express a sense of humor and politeness. The competency of perceiving such
    <span class="ltx_text ltx_font_italic" id="S1.p1.1.9">
     pragmatic
    </span>
    meanings is crucial to social and emotional intelligence (EI)
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Anders et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib6" title="">
      <span class="ltx_text" style="font-size:90%;">
       2016
      </span>
     </a>
     )
    </cite>
    and is referred to as
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.10">
     pragmatic reasoning
    </span>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    The rapid developments of
    <abbr class="ltx_glossaryref" title="large language model">
     <span class="ltx_text ltx_glossary_short-plural">
      LLMs
     </span>
    </abbr>
    , such as ChatGPT and InstructGPT
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Ouyang et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib7" title="">
      <span class="ltx_text" style="font-size:90%;">
       2022
      </span>
     </a>
     )
    </cite>
    , have set off a wave of the next generation of conversational AI over the recent years. Despite the inspiring capabilities of language generation
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Brown et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib8" title="">
      <span class="ltx_text" style="font-size:90%;">
       2020
      </span>
     </a>
     )
    </cite>
    and reasoning
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Wei et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib9" title="">
      <span class="ltx_text" style="font-size:90%;">
       2022
      </span>
     </a>
     )
    </cite>
    achieved with massive computational resources and tremendous natural language data,
    <abbr class="ltx_glossaryref" title="large language model">
     <span class="ltx_text ltx_glossary_short-plural">
      LLMs
     </span>
    </abbr>
    barely show convincing communicative skills
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Ruis et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib10" title="">
      <span class="ltx_text" style="font-size:90%;">
       2022
      </span>
     </a>
     )
    </cite>
    ,
    <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">
     i.e
    </em>
    .
    <span class="ltx_text" id="S1.p2.1.2">
    </span>
    , they fail to capture pragmatic and ambiguous meanings of input prompts
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Liu et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib11" title="">
      <span class="ltx_text" style="font-size:90%;">
       2023
      </span>
     </a>
     );
     <span class="ltx_text" style="font-size:90%;">
      Ruis et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib10" title="">
      <span class="ltx_text" style="font-size:90%;">
       2022
      </span>
     </a>
     );
     <span class="ltx_text" style="font-size:90%;">
      Zheng et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib12" title="">
      <span class="ltx_text" style="font-size:90%;">
       2021
      </span>
     </a>
     )
    </cite>
    . Critically, current neural generative models are trained to be objective with safe and satisfiable responses
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      OpenAI
     </span>
     (
     <a class="ltx_ref" href="#bib.bib13" title="">
      <span class="ltx_text" style="font-size:90%;">
       2023
      </span>
     </a>
     );
     <span class="ltx_text" style="font-size:90%;">
      Glaese et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib14" title="">
      <span class="ltx_text" style="font-size:90%;">
       2022
      </span>
     </a>
     )
    </cite>
    , which largely deviates from the long-standing goal of building a human-like agent. Recently, Meta Research Team
    <em class="ltx_emph ltx_font_italic" id="S1.p2.1.3">
     et al
    </em>
    .
    <span class="ltx_text" id="S1.p2.1.4">
    </span>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      † et al.(2022)(FAIR)†, Bakhtin, Brown, Dinan, Farina,
Flaherty, Fried, Goff, Gray, Hu, et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib5" title="">
      <span class="ltx_text" style="font-size:90%;">
       FAIR
      </span>
     </a>
     )
    </cite>
    introduce a ChatBot that demonstrates human-level play in a language board game
    <span class="ltx_text ltx_font_italic" id="S1.p2.1.5">
     Diplomacy
    </span>
    where lying and misleading commonly occur. However, their main focus is on game policy learning rather than pragmatic reasoning.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">
     What are the core components of real-life conversational pragmatic reasoning?
    </span>
    Motivated by theories of cognitive linguistics and conversational modeling, we anticipate it to be three-fold:
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       <span class="ltx_text ltx_font_italic" id="S1.I1.i1.p1.1.1">
        Situational Context
       </span>
       Reasoning.  Understanding pragmatic meaning requires a detailed understanding of conversational contexts. Consider the utterance “You are making the rest of us looking bad”, under different situations of praise and sarcasm, the sentence may convey completely opposite meanings. Furthermore, typical conversational reasoning challenges such as coreference resolution and intention prediction are largely dependent on the success of situated context modeling.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">
        Open-world Knowledge
       </span>
       Acquisition.  The open-world knowledge includes commonsense knowledge (
       <em class="ltx_emph ltx_font_italic" id="S1.I1.i2.p1.1.2">
        e.g
       </em>
       .
       <span class="ltx_text" id="S1.I1.i2.p1.1.3">
       </span>
       , social ethics) that can be learned from different domains of dialogue corpus and domain-specific knowledge (
       <em class="ltx_emph ltx_font_italic" id="S1.I1.i2.p1.1.4">
        e.g
       </em>
       .
       <span class="ltx_text" id="S1.I1.i2.p1.1.5">
       </span>
       , American histories). Successful pragmatic reasoning requires the acquisition of open-world knowledge and joint reasoning over the conversation.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       Unified
       <span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.1">
        figurative language
       </span>
       understanding.  Figurative language is one of the most frequently used tricks for conveying implicit meanings with subjective emotions. Previous works treat different forms of figurative language understanding as individual tasks, such as metaphors
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" style="font-size:90%;">
         Chakrabarty et al.
        </span>
        (
        <a class="ltx_ref" href="#bib.bib15" title="">
         <span class="ltx_text" style="font-size:90%;">
          2021
         </span>
        </a>
        )
       </cite>
       , idioms
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" style="font-size:90%;">
         Saxena and Paul
        </span>
        (
        <a class="ltx_ref" href="#bib.bib16" title="">
         <span class="ltx_text" style="font-size:90%;">
          2020
         </span>
        </a>
        );
        <span class="ltx_text" style="font-size:90%;">
         Adewumi et al.
        </span>
        (
        <a class="ltx_ref" href="#bib.bib17" title="">
         <span class="ltx_text" style="font-size:90%;">
          2022
         </span>
        </a>
        )
       </cite>
       , pun
       <cite class="ltx_cite ltx_citemacro_cite">
        <span class="ltx_text" style="font-size:90%;">
         Annamoradnejad and Zoghi
        </span>
        (
        <a class="ltx_ref" href="#bib.bib18" title="">
         <span class="ltx_text" style="font-size:90%;">
          2022
         </span>
        </a>
        )
       </cite>
       ,
       <em class="ltx_emph ltx_font_italic" id="S1.I1.i3.p1.1.2">
        etc
       </em>
       . Pragmatic reasoning provides a feasible unified perspective that considers all these tasks as recovering their literal meanings.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.5">
    In order to step towards a general human-like communicative agent, in this work, we introduce
    <span class="ltx_text ltx_font_bold" id="S1.p4.5.1">
     DiPlomat
    </span>
    , a real-life
    <span class="ltx_text ltx_font_bold" id="S1.p4.5.2">
     Di
    </span>
    a
    <span class="ltx_text ltx_font_bold" id="S1.p4.5.3">
     lo
    </span>
    gue dataset that focuses on
    <span class="ltx_text ltx_font_bold" id="S1.p4.5.4">
     P
    </span>
    rag
    <span class="ltx_text ltx_font_bold" id="S1.p4.5.5">
     mat
    </span>
    ic reasoning.
    <span class="ltx_text ltx_font_bold" id="S1.p4.5.6">
     DiPlomat
    </span>
    stems from an interview dataset
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Majumder et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib19" title="">
      <span class="ltx_text" style="font-size:90%;">
       2020
      </span>
     </a>
     )
    </cite>
    , and experiences three steps of curation: automatic selection, fine-grained manual annotation and human refinement (
    <a class="ltx_ref" href="#S3" title="3 The DiPlomat Dataset ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Sec.
     </span>
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    ). Our dataset owns
    <math alttext="4,177" class="ltx_Math" display="inline" id="S1.p4.1.m1.2">
     <semantics id="S1.p4.1.m1.2a">
      <mrow id="S1.p4.1.m1.2.3.2" xref="S1.p4.1.m1.2.3.1.cmml">
       <mn id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">
        4
       </mn>
       <mo id="S1.p4.1.m1.2.3.2.1" xref="S1.p4.1.m1.2.3.1.cmml">
        ,
       </mo>
       <mn id="S1.p4.1.m1.2.2" xref="S1.p4.1.m1.2.2.cmml">
        177
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.2b">
       <list id="S1.p4.1.m1.2.3.1.cmml" xref="S1.p4.1.m1.2.3.2">
        <cn id="S1.p4.1.m1.1.1.cmml" type="integer" xref="S1.p4.1.m1.1.1">
         4
        </cn>
        <cn id="S1.p4.1.m1.2.2.cmml" type="integer" xref="S1.p4.1.m1.2.2">
         177
        </cn>
       </list>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p4.1.m1.2c">
       4,177
      </annotation>
      <annotation encoding="application/x-llamapun" id="S1.p4.1.m1.2d">
       4 , 177
      </annotation>
     </semantics>
    </math>
    dialogues and covers a vocabulary of
    <math alttext="48,900" class="ltx_Math" display="inline" id="S1.p4.2.m2.2">
     <semantics id="S1.p4.2.m2.2a">
      <mrow id="S1.p4.2.m2.2.3.2" xref="S1.p4.2.m2.2.3.1.cmml">
       <mn id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml">
        48
       </mn>
       <mo id="S1.p4.2.m2.2.3.2.1" xref="S1.p4.2.m2.2.3.1.cmml">
        ,
       </mo>
       <mn id="S1.p4.2.m2.2.2" xref="S1.p4.2.m2.2.2.cmml">
        900
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.2b">
       <list id="S1.p4.2.m2.2.3.1.cmml" xref="S1.p4.2.m2.2.3.2">
        <cn id="S1.p4.2.m2.1.1.cmml" type="integer" xref="S1.p4.2.m2.1.1">
         48
        </cn>
        <cn id="S1.p4.2.m2.2.2.cmml" type="integer" xref="S1.p4.2.m2.2.2">
         900
        </cn>
       </list>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p4.2.m2.2c">
       48,900
      </annotation>
      <annotation encoding="application/x-llamapun" id="S1.p4.2.m2.2d">
       48 , 900
      </annotation>
     </semantics>
    </math>
    words. More than that, human-annotated answers reach the amount of
    <math alttext="6,494" class="ltx_Math" display="inline" id="S1.p4.3.m3.2">
     <semantics id="S1.p4.3.m3.2a">
      <mrow id="S1.p4.3.m3.2.3.2" xref="S1.p4.3.m3.2.3.1.cmml">
       <mn id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml">
        6
       </mn>
       <mo id="S1.p4.3.m3.2.3.2.1" xref="S1.p4.3.m3.2.3.1.cmml">
        ,
       </mo>
       <mn id="S1.p4.3.m3.2.2" xref="S1.p4.3.m3.2.2.cmml">
        494
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.2b">
       <list id="S1.p4.3.m3.2.3.1.cmml" xref="S1.p4.3.m3.2.3.2">
        <cn id="S1.p4.3.m3.1.1.cmml" type="integer" xref="S1.p4.3.m3.1.1">
         6
        </cn>
        <cn id="S1.p4.3.m3.2.2.cmml" type="integer" xref="S1.p4.3.m3.2.2">
         494
        </cn>
       </list>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p4.3.m3.2c">
       6,494
      </annotation>
      <annotation encoding="application/x-llamapun" id="S1.p4.3.m3.2d">
       6 , 494
      </annotation>
     </semantics>
    </math>
    and hold a vocabulary size of
    <math alttext="20,000" class="ltx_Math" display="inline" id="S1.p4.4.m4.2">
     <semantics id="S1.p4.4.m4.2a">
      <mrow id="S1.p4.4.m4.2.3.2" xref="S1.p4.4.m4.2.3.1.cmml">
       <mn id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml">
        20
       </mn>
       <mo id="S1.p4.4.m4.2.3.2.1" xref="S1.p4.4.m4.2.3.1.cmml">
        ,
       </mo>
       <mn id="S1.p4.4.m4.2.2" xref="S1.p4.4.m4.2.2.cmml">
        000
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.2b">
       <list id="S1.p4.4.m4.2.3.1.cmml" xref="S1.p4.4.m4.2.3.2">
        <cn id="S1.p4.4.m4.1.1.cmml" type="integer" xref="S1.p4.4.m4.1.1">
         20
        </cn>
        <cn id="S1.p4.4.m4.2.2.cmml" type="integer" xref="S1.p4.4.m4.2.2">
         000
        </cn>
       </list>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p4.4.m4.2c">
       20,000
      </annotation>
      <annotation encoding="application/x-llamapun" id="S1.p4.4.m4.2d">
       20 , 000
      </annotation>
     </semantics>
    </math>
    . Along with the dataset, we propose two tasks, Pragmatic Identification and Reasoning (PIR) and Conversational Question Answering (CQA), to benchmark machines’ pragmatic reasoning capabilities (
    <a class="ltx_ref" href="#S4" title="4 Task Definition ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Sec.
     </span>
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    ). The CQA task possesses
    <math alttext="19,482" class="ltx_Math" display="inline" id="S1.p4.5.m5.2">
     <semantics id="S1.p4.5.m5.2a">
      <mrow id="S1.p4.5.m5.2.3.2" xref="S1.p4.5.m5.2.3.1.cmml">
       <mn id="S1.p4.5.m5.1.1" xref="S1.p4.5.m5.1.1.cmml">
        19
       </mn>
       <mo id="S1.p4.5.m5.2.3.2.1" xref="S1.p4.5.m5.2.3.1.cmml">
        ,
       </mo>
       <mn id="S1.p4.5.m5.2.2" xref="S1.p4.5.m5.2.2.cmml">
        482
       </mn>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S1.p4.5.m5.2b">
       <list id="S1.p4.5.m5.2.3.1.cmml" xref="S1.p4.5.m5.2.3.2">
        <cn id="S1.p4.5.m5.1.1.cmml" type="integer" xref="S1.p4.5.m5.1.1">
         19
        </cn>
        <cn id="S1.p4.5.m5.2.2.cmml" type="integer" xref="S1.p4.5.m5.2.2">
         482
        </cn>
       </list>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S1.p4.5.m5.2c">
       19,482
      </annotation>
      <annotation encoding="application/x-llamapun" id="S1.p4.5.m5.2d">
       19 , 482
      </annotation>
     </semantics>
    </math>
    questions concerning the content of collected dialogues and the answers to the questions are written by humans. We run extensive experiments on previous state-of-the-art models on
    <span class="ltx_text ltx_font_bold" id="S1.p4.5.7">
     DiPlomat
    </span>
    (
    <a class="ltx_ref" href="#S5" title="5 Experiment ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Sec.
     </span>
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    ). The best model achieves less than 0.70 accuracy score in PIR, and none of the models achieve more than 0.50 accuracy score for CQA. Moreover, we test previous pre-trained
    <abbr class="ltx_glossaryref" title="large language model">
     <span class="ltx_text ltx_glossary_short-plural">
      LLMs
     </span>
    </abbr>
    ’ (including ChatGPT) zero-shot reasoning capability with a natural language inference (NLI) task.
Regarding the experimental results provided, the significance of pragmatic reasoning speaks for itself. Throughout a thorough analysis of the limitations of current models, we aim to shed light on future research toward building general conversational agents.
   </p>
  </div>
  <figure class="ltx_table" id="S1.T1">
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    Comparisons on similar datasets and our dataset. QA: Question Answering. NUP: Next Utterance Prediction. NLI: Natural Language Inference. PI: Plausible Inference. IR: Implicature Recovery. PIR: Pragmatic Identification and Reasoning.
   </figcaption>
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S1.T1.4" style="width:433.6pt;height:217.1pt;vertical-align:-0.8pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-71.9pt,35.9pt) scale(0.750990219879936,0.750990219879936) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S1.T1.4.1">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S1.T1.4.1.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S1.T1.4.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.1.1.1.1" style="font-size:90%;">
          Dataset
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.1.1.2.1" style="font-size:90%;">
          Domain
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.1.3">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.1.1.3.1" style="font-size:90%;">
          Manually
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.1.4">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.1.1.4.1" style="font-size:90%;">
          Task
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.1.5">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.1.1.5.1" style="font-size:90%;">
          Implicature
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.1.6">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.1.1.6.1" style="font-size:90%;">
          Reasoning
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S1.T1.4.1.1.1.7">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.1.1.7.1" style="font-size:90%;">
          Multi-Turn
         </span>
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S1.T1.4.1.2.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S1.T1.4.1.2.1.1">
         <span class="ltx_text" id="S1.T1.4.1.2.1.1.1" style="font-size:90%;">
          Ubuntu
         </span>
         <span class="ltx_text" id="S1.T1.4.1.2.1.1.2" style="font-size:70%;color:#808080;">
          [ACL 2015]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.2.1.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Lowe et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.2.1.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib20" title="">
           <span class="ltx_text" style="font-size:90%;">
            2015
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.2.1.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.1.2.1.2">
         <span class="ltx_text" id="S1.T1.4.1.2.1.2.1" style="font-size:90%;">
          Technique
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.1.2.1.3">
         <span class="ltx_text" id="S1.T1.4.1.2.1.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.1.2.1.4">
         <span class="ltx_text" id="S1.T1.4.1.2.1.4.1" style="font-size:90%;">
          NUP
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.1.2.1.5">
         <span class="ltx_text" id="S1.T1.4.1.2.1.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.1.2.1.6">
         <span class="ltx_text" id="S1.T1.4.1.2.1.6.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.4.1.2.1.7">
         <span class="ltx_text" id="S1.T1.4.1.2.1.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.3.2">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.3.2.1">
         <span class="ltx_text" id="S1.T1.4.1.3.2.1.1" style="font-size:90%;">
          RACE
         </span>
         <span class="ltx_text" id="S1.T1.4.1.3.2.1.2" style="font-size:70%;color:#808080;">
          [EMNLP 2017]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.3.2.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Lai et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.3.2.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib21" title="">
           <span class="ltx_text" style="font-size:90%;">
            2017
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.3.2.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.3.2.2">
         <span class="ltx_text" id="S1.T1.4.1.3.2.2.1" style="font-size:90%;">
          Open
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.3.2.3">
         <span class="ltx_text" id="S1.T1.4.1.3.2.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.3.2.4">
         <span class="ltx_text" id="S1.T1.4.1.3.2.4.1" style="font-size:90%;">
          QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.3.2.5">
         <span class="ltx_text" id="S1.T1.4.1.3.2.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.3.2.6">
         <span class="ltx_text" id="S1.T1.4.1.3.2.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.3.2.7">
         <span class="ltx_text" id="S1.T1.4.1.3.2.7.1" style="font-size:90%;">
          ✗
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.4.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.4.3.1">
         <span class="ltx_text" id="S1.T1.4.1.4.3.1.1" style="font-size:90%;">
          ARC
         </span>
         <span class="ltx_text" id="S1.T1.4.1.4.3.1.2" style="font-size:70%;color:#808080;">
          [ArXiv 2018]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.4.3.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Clark et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.4.3.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib22" title="">
           <span class="ltx_text" style="font-size:90%;">
            2018
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.4.3.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.4.3.2">
         <span class="ltx_text" id="S1.T1.4.1.4.3.2.1" style="font-size:90%;">
          Science
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.4.3.3">
         <span class="ltx_text" id="S1.T1.4.1.4.3.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.4.3.4">
         <span class="ltx_text" id="S1.T1.4.1.4.3.4.1" style="font-size:90%;">
          QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.4.3.5">
         <span class="ltx_text" id="S1.T1.4.1.4.3.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.4.3.6">
         <span class="ltx_text" id="S1.T1.4.1.4.3.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.4.3.7">
         <span class="ltx_text" id="S1.T1.4.1.4.3.7.1" style="font-size:90%;">
          ✗
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.5.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.5.4.1">
         <span class="ltx_text" id="S1.T1.4.1.5.4.1.1" style="font-size:90%;">
          MNLI
         </span>
         <span class="ltx_text" id="S1.T1.4.1.5.4.1.2" style="font-size:70%;color:#808080;">
          [NAACL 2018 ]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.5.4.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Williams et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.5.4.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib23" title="">
           <span class="ltx_text" style="font-size:90%;">
            2018
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.5.4.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.5.4.2">
         <span class="ltx_text" id="S1.T1.4.1.5.4.2.1" style="font-size:90%;">
          Open
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.5.4.3">
         <span class="ltx_text" id="S1.T1.4.1.5.4.3.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.5.4.4">
         <span class="ltx_text" id="S1.T1.4.1.5.4.4.1" style="font-size:90%;">
          NLI
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.5.4.5">
         <span class="ltx_text" id="S1.T1.4.1.5.4.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.5.4.6">
         <span class="ltx_text" id="S1.T1.4.1.5.4.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.5.4.7">
         <span class="ltx_text" id="S1.T1.4.1.5.4.7.1" style="font-size:90%;">
          ✗
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.6.5">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.6.5.1">
         <span class="ltx_text" id="S1.T1.4.1.6.5.1.1" style="font-size:90%;">
          Persona-Chat
         </span>
         <span class="ltx_text" id="S1.T1.4.1.6.5.1.2" style="font-size:70%;color:#808080;">
          [ACL 2018]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.6.5.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Zhang et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.6.5.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib24" title="">
           <span class="ltx_text" style="font-size:90%;">
            2018
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.6.5.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.6.5.2">
         <span class="ltx_text" id="S1.T1.4.1.6.5.2.1" style="font-size:90%;">
          Persona
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.6.5.3">
         <span class="ltx_text" id="S1.T1.4.1.6.5.3.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.6.5.4">
         <span class="ltx_text" id="S1.T1.4.1.6.5.4.1" style="font-size:90%;">
          NUP
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.6.5.5">
         <span class="ltx_text" id="S1.T1.4.1.6.5.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.6.5.6">
         <span class="ltx_text" id="S1.T1.4.1.6.5.6.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.6.5.7">
         <span class="ltx_text" id="S1.T1.4.1.6.5.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.7.6">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.7.6.1">
         <span class="ltx_text" id="S1.T1.4.1.7.6.1.1" style="font-size:90%;">
          SWAG
         </span>
         <span class="ltx_text" id="S1.T1.4.1.7.6.1.2" style="font-size:70%;color:#808080;">
          [EMNLP 2018]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.7.6.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Zellers et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.7.6.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib25" title="">
           <span class="ltx_text" style="font-size:90%;">
            2018
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.7.6.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.7.6.2">
         <span class="ltx_text" id="S1.T1.4.1.7.6.2.1" style="font-size:90%;">
          Movie
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.7.6.3">
         <span class="ltx_text" id="S1.T1.4.1.7.6.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.7.6.4">
         <span class="ltx_text" id="S1.T1.4.1.7.6.4.1" style="font-size:90%;">
          PI
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.7.6.5">
         <span class="ltx_text" id="S1.T1.4.1.7.6.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.7.6.6">
         <span class="ltx_text" id="S1.T1.4.1.7.6.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.7.6.7">
         <span class="ltx_text" id="S1.T1.4.1.7.6.7.1" style="font-size:90%;">
          ✗
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.8.7">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.8.7.1">
         <span class="ltx_text" id="S1.T1.4.1.8.7.1.1" style="font-size:90%;">
          Cosmos QA
         </span>
         <span class="ltx_text" id="S1.T1.4.1.8.7.1.2" style="font-size:70%;color:#808080;">
          [EMNLP 2019]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.8.7.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Huang et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.8.7.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib26" title="">
           <span class="ltx_text" style="font-size:90%;">
            2019
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.8.7.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.8.7.2">
         <span class="ltx_text" id="S1.T1.4.1.8.7.2.1" style="font-size:90%;">
          Persona
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.8.7.3">
         <span class="ltx_text" id="S1.T1.4.1.8.7.3.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.8.7.4">
         <span class="ltx_text" id="S1.T1.4.1.8.7.4.1" style="font-size:90%;">
          QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.8.7.5">
         <span class="ltx_text" id="S1.T1.4.1.8.7.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.8.7.6">
         <span class="ltx_text" id="S1.T1.4.1.8.7.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.8.7.7">
         <span class="ltx_text" id="S1.T1.4.1.8.7.7.1" style="font-size:90%;">
          ✗
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.9.8">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.9.8.1">
         <span class="ltx_text" id="S1.T1.4.1.9.8.1.1" style="font-size:90%;">
          CoQA
         </span>
         <span class="ltx_text" id="S1.T1.4.1.9.8.1.2" style="font-size:70%;color:#808080;">
          [NAACL 2019]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.9.8.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Reddy et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.9.8.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib27" title="">
           <span class="ltx_text" style="font-size:90%;">
            2019
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.9.8.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.9.8.2">
         <span class="ltx_text" id="S1.T1.4.1.9.8.2.1" style="font-size:90%;">
          Diverse
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.9.8.3">
         <span class="ltx_text" id="S1.T1.4.1.9.8.3.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.9.8.4">
         <span class="ltx_text" id="S1.T1.4.1.9.8.4.1" style="font-size:90%;">
          QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.9.8.5">
         <span class="ltx_text" id="S1.T1.4.1.9.8.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.9.8.6">
         <span class="ltx_text" id="S1.T1.4.1.9.8.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.9.8.7">
         <span class="ltx_text" id="S1.T1.4.1.9.8.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.10.9">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.10.9.1">
         <span class="ltx_text" id="S1.T1.4.1.10.9.1.1" style="font-size:90%;">
          DREAM
         </span>
         <span class="ltx_text" id="S1.T1.4.1.10.9.1.2" style="font-size:70%;color:#808080;">
          [ACL 2019]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.10.9.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Sun et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.10.9.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib28" title="">
           <span class="ltx_text" style="font-size:90%;">
            2019
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.10.9.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.10.9.2">
         <span class="ltx_text" id="S1.T1.4.1.10.9.2.1" style="font-size:90%;">
          Open
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.10.9.3">
         <span class="ltx_text" id="S1.T1.4.1.10.9.3.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.10.9.4">
         <span class="ltx_text" id="S1.T1.4.1.10.9.4.1" style="font-size:90%;">
          QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.10.9.5">
         <span class="ltx_text" id="S1.T1.4.1.10.9.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.10.9.6">
         <span class="ltx_text" id="S1.T1.4.1.10.9.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.10.9.7">
         <span class="ltx_text" id="S1.T1.4.1.10.9.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.11.10">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.11.10.1">
         <span class="ltx_text" id="S1.T1.4.1.11.10.1.1" style="font-size:90%;">
          Dialogue NLI
         </span>
         <span class="ltx_text" id="S1.T1.4.1.11.10.1.2" style="font-size:70%;color:#808080;">
          [ACL 2019]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.11.10.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Welleck et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.11.10.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib29" title="">
           <span class="ltx_text" style="font-size:90%;">
            2019
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.11.10.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.11.10.2">
         <span class="ltx_text" id="S1.T1.4.1.11.10.2.1" style="font-size:90%;">
          Persona
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.11.10.3">
         <span class="ltx_text" id="S1.T1.4.1.11.10.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.11.10.4">
         <span class="ltx_text" id="S1.T1.4.1.11.10.4.1" style="font-size:90%;">
          NLI
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.11.10.5">
         <span class="ltx_text" id="S1.T1.4.1.11.10.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.11.10.6">
         <span class="ltx_text" id="S1.T1.4.1.11.10.6.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.11.10.7">
         <span class="ltx_text" id="S1.T1.4.1.11.10.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.12.11">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.12.11.1">
         <span class="ltx_text" id="S1.T1.4.1.12.11.1.1" style="font-size:90%;">
          DROP
         </span>
         <span class="ltx_text" id="S1.T1.4.1.12.11.1.2" style="font-size:70%;color:#808080;">
          [ACL 2019]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.12.11.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Dua et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.12.11.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib30" title="">
           <span class="ltx_text" style="font-size:90%;">
            2019
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.12.11.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.12.11.2">
         <span class="ltx_text" id="S1.T1.4.1.12.11.2.1" style="font-size:90%;">
          Open
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.12.11.3">
         <span class="ltx_text" id="S1.T1.4.1.12.11.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.12.11.4">
         <span class="ltx_text" id="S1.T1.4.1.12.11.4.1" style="font-size:90%;">
          QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.12.11.5">
         <span class="ltx_text" id="S1.T1.4.1.12.11.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.12.11.6">
         <span class="ltx_text" id="S1.T1.4.1.12.11.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.12.11.7">
         <span class="ltx_text" id="S1.T1.4.1.12.11.7.1" style="font-size:90%;">
          ✗
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.13.12">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.13.12.1">
         <span class="ltx_text" id="S1.T1.4.1.13.12.1.1" style="font-size:90%;">
          MuTual
         </span>
         <span class="ltx_text" id="S1.T1.4.1.13.12.1.2" style="font-size:70%;color:#808080;">
          [ACL 2020]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.13.12.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Cui et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.13.12.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib31" title="">
           <span class="ltx_text" style="font-size:90%;">
            2020
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.13.12.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.13.12.2">
         <span class="ltx_text" id="S1.T1.4.1.13.12.2.1" style="font-size:90%;">
          Open
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.13.12.3">
         <span class="ltx_text" id="S1.T1.4.1.13.12.3.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.13.12.4">
         <span class="ltx_text" id="S1.T1.4.1.13.12.4.1" style="font-size:90%;">
          NUP
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.13.12.5">
         <span class="ltx_text" id="S1.T1.4.1.13.12.5.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.13.12.6">
         <span class="ltx_text" id="S1.T1.4.1.13.12.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.13.12.7">
         <span class="ltx_text" id="S1.T1.4.1.13.12.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.14.13">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.14.13.1">
         <span class="ltx_text" id="S1.T1.4.1.14.13.1.1" style="font-size:90%;">
          IMPPRES
         </span>
         <span class="ltx_text" id="S1.T1.4.1.14.13.1.2" style="font-size:70%;color:#808080;">
          [ACL 2020]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.14.13.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Jeretic et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.14.13.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib32" title="">
           <span class="ltx_text" style="font-size:90%;">
            2020
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.14.13.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.14.13.2">
         <span class="ltx_text" id="S1.T1.4.1.14.13.2.1" style="font-size:90%;">
          Open
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.14.13.3">
         <span class="ltx_text" id="S1.T1.4.1.14.13.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.14.13.4">
         <span class="ltx_text" id="S1.T1.4.1.14.13.4.1" style="font-size:90%;">
          NLI
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.14.13.5">
         <span class="ltx_text" id="S1.T1.4.1.14.13.5.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.14.13.6">
         <span class="ltx_text" id="S1.T1.4.1.14.13.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.14.13.7">
         <span class="ltx_text" id="S1.T1.4.1.14.13.7.1" style="font-size:90%;">
          ✗
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.15.14">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S1.T1.4.1.15.14.1">
         <span class="ltx_text" id="S1.T1.4.1.15.14.1.1" style="font-size:90%;">
          GRICE
         </span>
         <span class="ltx_text" id="S1.T1.4.1.15.14.1.2" style="font-size:70%;color:#808080;">
          [ACL 2021]
         </span>
         <span class="ltx_text" id="S1.T1.4.1.15.14.1.3" style="font-size:90%;">
         </span>
         <cite class="ltx_cite ltx_citemacro_cite">
          <span class="ltx_text" style="font-size:90%;">
           Zheng et al.
          </span>
          <span class="ltx_text" id="S1.T1.4.1.15.14.1.4.1.1.1" style="font-size:90%;">
           (
          </span>
          <a class="ltx_ref" href="#bib.bib12" title="">
           <span class="ltx_text" style="font-size:90%;">
            2021
           </span>
          </a>
          <span class="ltx_text" id="S1.T1.4.1.15.14.1.5.2.2.1" style="font-size:90%;">
           )
          </span>
         </cite>
        </th>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.15.14.2">
         <span class="ltx_text" id="S1.T1.4.1.15.14.2.1" style="font-size:90%;">
          Daily
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.15.14.3">
         <span class="ltx_text" id="S1.T1.4.1.15.14.3.1" style="font-size:90%;">
          ✗
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.15.14.4">
         <span class="ltx_text" id="S1.T1.4.1.15.14.4.1" style="font-size:90%;">
          IR &amp; QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.15.14.5">
         <span class="ltx_text" id="S1.T1.4.1.15.14.5.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.15.14.6">
         <span class="ltx_text" id="S1.T1.4.1.15.14.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S1.T1.4.1.15.14.7">
         <span class="ltx_text" id="S1.T1.4.1.15.14.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S1.T1.4.1.16.15">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S1.T1.4.1.16.15.1">
         <span class="ltx_text ltx_font_bold" id="S1.T1.4.1.16.15.1.1" style="font-size:90%;">
          DiPlomat
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.4.1.16.15.2">
         <span class="ltx_text" id="S1.T1.4.1.16.15.2.1" style="font-size:90%;">
          Open
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.4.1.16.15.3">
         <span class="ltx_text" id="S1.T1.4.1.16.15.3.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.4.1.16.15.4">
         <span class="ltx_text" id="S1.T1.4.1.16.15.4.1" style="font-size:90%;">
          PIR &amp; QA
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.4.1.16.15.5">
         <span class="ltx_text" id="S1.T1.4.1.16.15.5.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.4.1.16.15.6">
         <span class="ltx_text" id="S1.T1.4.1.16.15.6.1" style="font-size:90%;">
          ✓
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S1.T1.4.1.16.15.7">
         <span class="ltx_text" id="S1.T1.4.1.16.15.7.1" style="font-size:90%;">
          ✓
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
  </figure>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    Conversational Dataset
   </h4>
   <div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">
     <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Table
      </span>
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     provides a comparative analysis of our dataset with similar conversational datasets. The Dream
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Sun et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib28" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
     dataset formalizes dialogues from English exams into question-answering task with a focus on in-depth dialogue comprehension.
With question-answer pairs compiled by two annotators, CoQA
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Reddy et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib27" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
     focuses on reasoning in conversation understanding. By utilizing Chinese student English listening comprehension tests, MuTual
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Cui et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib31" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     is built to address the issue of general dialogue reasoning. In contrast to these preceding datasets, the GRICE
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Zheng et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib12" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      )
     </cite>
     dataset represents a significant advancement in the field of pragmatic reasoning as it incorporates implicature and reasoning. However, both MuTual and GRICE exhibit a shared limitation in that they do not possess data that closely resembles real-world interactions, leading to a lack of diversity in their respective datasets.
Additionally, other relevant datasets, including commonsense
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Huang et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib26" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
     , reasoning
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Lai et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib21" title="">
       <span class="ltx_text" style="font-size:90%;">
        2017
       </span>
      </a>
      )
     </cite>
     , and natural language inference (NLI)
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Welleck et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib29" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      );
      <span class="ltx_text" style="font-size:90%;">
       Williams et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib23" title="">
       <span class="ltx_text" style="font-size:90%;">
        2018
       </span>
      </a>
      )
     </cite>
     , are also included in
     <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Table
      </span>
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . By examining various dimensions such as domain, manual annotation, task variety, implicature, reasoning, and multi-turn interactions,
our dataset offers unique advantages in addressing the challenge of pragmatic reasoning in dialogues.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    Language Models for Dialogue Generation
   </h4>
   <div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">
     Conversational AI has emerged as a prominent research area within the field of
     <span class="ltx_glossaryref" title="natural language processing">
      <span class="ltx_text ltx_glossary_long">
       natural language processing
      </span>
     </span>
     (
     <abbr class="ltx_glossaryref" title="natural language processing">
      <span class="ltx_text ltx_glossary_short">
       NLP
      </span>
     </abbr>
     ), attracting significant attention and interest. Numerous pre-trained models have been proposed to tackle dialogue generation tasks, such as DialogGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Zhang et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib33" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020a
       </span>
      </a>
      )
     </cite>
     , GODEL
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Peng et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib34" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     , LaMDA
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Thoppilan et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib35" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     , and Meena
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Adiwardana et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib36" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     ,
and they have achieved marvelous results on competitions
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Gunasekara et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib37" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     . Furthermore, a pivotal milestone has been achieved with the advent of ChatGPT, garnering widespread interest and stimulating further investigation in the domain of conversational AI. ChatGPT, built upon the principles of transformer models
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Vaswani et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib38" title="">
       <span class="ltx_text" style="font-size:90%;">
        2017
       </span>
      </a>
      )
     </cite>
     , undergoes training on an extensive corpus of data, resulting in its profound efficacy. Notably, this system boasts an impressive magnitude of billions of parameters. In a notable study conducted by OpenAI
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       OpenAI
      </span>
      (
      <a class="ltx_ref" href="#bib.bib13" title="">
       <span class="ltx_text" style="font-size:90%;">
        2023
       </span>
      </a>
      )
     </cite>
     , it has been demonstrated that the augmentation of parameters, referred to as the Scaling Law, substantially enhances the model’s capabilities. Also, the enlargement of the number of parameters triggers the emergence of miraculous ability. After the success of ChatGPT, more models such as PaLM 2
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Anil et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib39" title="">
       <span class="ltx_text" style="font-size:90%;">
        2023
       </span>
      </a>
      )
     </cite>
     appear in the field.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
   <h4 class="ltx_title ltx_title_paragraph">
    Pragmatics Reasoning
   </h4>
   <div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">
     Pragmatic reasoning is a significant subject within the field of pragmatics, attracting considerable attention from linguists.
Existing datasets for pragmatic reasoning predominantly focus on specific types of phenomena. For example, EPIE
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Saxena and Paul
      </span>
      (
      <a class="ltx_ref" href="#bib.bib16" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     , PIE
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Adewumi et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib17" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     center around idiomatic expressions, while MOVER
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Zhang and Wan
      </span>
      (
      <a class="ltx_ref" href="#bib.bib40" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022a
       </span>
      </a>
      )
     </cite>
     emphasizes hyperbole, and MERMAID
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Chakrabarty et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib15" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      )
     </cite>
     investigates metaphor usage. However, paronomasia is much more under-studied
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Annamoradnejad and Zoghi
      </span>
      (
      <a class="ltx_ref" href="#bib.bib18" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     , with researchers frequently intertwining it with humor
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Weller and Seppi
      </span>
      (
      <a class="ltx_ref" href="#bib.bib41" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     . In a related vein, GRICE
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Zheng et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib12" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      )
     </cite>
     endeavors to study implicature in a unified manner, but its data does not originate from real-world contexts, thereby lacking diversity and exhibiting conspicuous patterns. In addition to these datasets,
     <cite class="ltx_cite ltx_citemacro_citet">
      <span class="ltx_text" style="font-size:90%;">
       Frank and Goodman
      </span>
      (
      <a class="ltx_ref" href="#bib.bib42" title="">
       <span class="ltx_text" style="font-size:90%;">
        2012
       </span>
      </a>
      )
     </cite>
     attempt to model pragmatic reasoning phenomenon through language games. Insights into the comprehension of figurative language is provided by works such as those by
     <cite class="ltx_cite ltx_citemacro_citet">
      <span class="ltx_text" style="font-size:90%;">
       Stowe et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib43" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     and
     <cite class="ltx_cite ltx_citemacro_citet">
      <span class="ltx_text" style="font-size:90%;">
       Chakrabarty et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib44" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     , with the former specifically delves into the realm of metaphors and idioms, and the latter investigating idioms and similes. The successful completion of our task necessitates the incorporation of commonsense knowledge. Extensive scholarly efforts have been dedicated to addressing the challenge of leveraging commonsense in various works
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Cui et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib31" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      );
      <span class="ltx_text" style="font-size:90%;">
       Ghosal et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib45" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib46" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      );
      <span class="ltx_text" style="font-size:90%;">
       Zhou et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib47" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="497" id="S2.F2.g1" src="x3.png" width="830"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <br class="ltx_break ltx_centering"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S2.F2.3.1.1" style="font-size:90%;">
       Figure 2
      </span>
      :
     </span>
     <span class="ltx_text ltx_font_bold" id="S2.F2.4.2" style="font-size:90%;">
      DiPlomat
      <span class="ltx_text ltx_font_medium" id="S2.F2.4.2.1">
       dataset samples. Each row illustrates an exemplar case with its reasoning type, dialogue context, pragmatic turn, and the corresponding rationale. Evidence that support the pragmatic identification are marked in orange.
      </span>
     </span>
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   The
   <span class="ltx_text ltx_font_bold" id="S3.1.1">
    DiPlomat
   </span>
   Dataset
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Data Source Construction
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     The
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">
      DiPlomat
     </span>
     dataset stems from the Interview dataset
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Majumder et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib19" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     , which consists of two subsets, a two-party subset comprising 23,714 dialogues and a multi-party subset with 105,848 dialogues. Given our specific focus on conversations involving only two communicators, we exclusively utilize the two-party subset for our research purposes. The Interview dataset itself is a real-world collection of NPR radio transcripts, spanning a period of 20 years of NPR programs. The curation process for our dataset involved several stages, including automatic selection, fine-grained annotation, and human refinement. Details are provided as follows.
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Step I. Automatic Selection.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">
      The extensive size of the source dataset introduces redundancy, necessitating automatic measures to alleviate the burden of human annotation. Therefore, we employ algorithms and models to perform an initial filtering process. In order to establish a unified framework, we consider various types of pragmatic phenomena and utilize different techniques to extract relevant instances from the source dataset. For instance, we utilize the EPIE list
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Saxena and Paul
       </span>
       (
       <a class="ltx_ref" href="#bib.bib16" title="">
        <span class="ltx_text" style="font-size:90%;">
         2020
        </span>
       </a>
       )
      </cite>
      for a string-matching method to identify idioms in dialogues, and we train RoBERTa
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Liu et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib48" title="">
        <span class="ltx_text" style="font-size:90%;">
         2019
        </span>
       </a>
       )
      </cite>
      on Hypo-XL
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Zhang and Wan
       </span>
       (
       <a class="ltx_ref" href="#bib.bib49" title="">
        <span class="ltx_text" style="font-size:90%;">
         2022b
        </span>
       </a>
       )
      </cite>
      for hyperbole detection; refer to
      <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px1.p1.1.1">
       Supplementary
      </span>
      for more details.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Step II. Fine-grained Annotation.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">
      We leverage
      <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
       <span class="ltx_text ltx_glossary_short">
        AMT
       </span>
      </abbr>
      to conduct detailed annotation of pragmatic turns within our dialogues. Workers participating in the annotation task are instructed to select all turns that exhibit a divergence between their literal meaning and their intended or implied meaning. Due to the subjective nature of pragmatic reasoning, we request the workers to provide confidence scores along with reasons for their choices. Specifically, in order to avoid introducing the extra difficulty of lengthy texts, the reasons are required to be no more than 8 words.
All annotators shall meet the following criteria: (i) from English-speaking countries; (ii) Completion of a minimum of 1,300 tasks with a 98% approval rate. We also present them with detailed instructions and four examples so that workers shall be clear about our objectives and requirements. The instructions part outlines the step-by-step procedures for accomplishing the assigned tasks and highlights some key points that workers should pay attention to. The four examples offered are representative of classical pragmatic conversations drawn from the field of linguistics, serving as practical references for the workers. To mitigate the intricacies arising from the identities of dialogue communicators, a simplified representation is adopted, whereby the speakers are denoted as
      <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px2.p1.1.1">
       PersonA
      </span>
      and
      <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px2.p1.1.2">
       PersonB
      </span>
      . To ensure the reasonableness and quality of the data, we manually examined 30 data samples and blocked workers who are unqualified. As a result, a total of 5,869 dialogues are selected. Refer to the
      <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px2.p1.1.3">
       Supplementary
      </span>
      for the detailed annotation process.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Step III. Human Refinement.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.1">
      In this process, tasks for workers are formulated as multiple-choice questions. Previously collected human-annotated reasons are transformed into choices, utilizing a template format:
      <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px3.p1.1.1">
       [turn {turn_id}: {reason}]
      </span>
      . In addition, to mitigate the impact of careless workers, we introduce a disturbing choice for each gold choice. These disturbing choices are generated using BERTScore
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Zhang et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib50" title="">
        <span class="ltx_text" style="font-size:90%;">
         2020b
        </span>
       </a>
       )
      </cite>
      by selecting the reason with the highest score from other unrelated dialogue. Of note, for each dialogue, an equal number of gold choices and disturbing choices are provided. Workers are requested to select all reasonable choices for each conversation and are warned of the presence of disturbing choices. Workers who frequently select disturbing choices are blocked, and their work is rejected.
Through this refinement process, 1,692 dialogues are filtered out, while 4,177 dialogues are preserved, ensuring the integrity and reliability of our dataset; Refer to
      <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.1.2">
       Supplementary
      </span>
      for more detail.
     </p>
    </div>
    <figure class="ltx_table ltx_align_floatright" id="S3.T2">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 2:
      </span>
      Statistical feature of
      <span class="ltx_text ltx_font_bold" id="S3.T2.13.1">
       DiPlomat
      </span>
      .
     </figcaption>
     <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.7" style="width:433.6pt;height:248.4pt;vertical-align:-0.0pt;">
      <span class="ltx_transformed_inner" style="transform:translate(106.8pt,-61.2pt) scale(1.97171287808737,1.97171287808737) ;">
       <table class="ltx_tabular ltx_align_middle" id="S3.T2.7.7">
        <tbody class="ltx_tbody">
         <tr class="ltx_tr" id="S3.T2.1.1.1">
          <td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.1.1.1.2">
           <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.2.1" style="font-size:90%;">
            # Dialogues
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.1.1.1">
           <math alttext="4.17\times 10^{3}" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.m1.1">
            <semantics id="S3.T2.1.1.1.1.m1.1a">
             <mrow id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">
              <mn id="S3.T2.1.1.1.1.m1.1.1.2" mathsize="90%" xref="S3.T2.1.1.1.1.m1.1.1.2.cmml">
               4.17
              </mn>
              <mo id="S3.T2.1.1.1.1.m1.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.T2.1.1.1.1.m1.1.1.1.cmml">
               ×
              </mo>
              <msup id="S3.T2.1.1.1.1.m1.1.1.3" xref="S3.T2.1.1.1.1.m1.1.1.3.cmml">
               <mn id="S3.T2.1.1.1.1.m1.1.1.3.2" mathsize="90%" xref="S3.T2.1.1.1.1.m1.1.1.3.2.cmml">
                10
               </mn>
               <mn id="S3.T2.1.1.1.1.m1.1.1.3.3" mathsize="90%" xref="S3.T2.1.1.1.1.m1.1.1.3.3.cmml">
                3
               </mn>
              </msup>
             </mrow>
             <annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b">
              <apply id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">
               <times id="S3.T2.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1.1">
               </times>
               <cn id="S3.T2.1.1.1.1.m1.1.1.2.cmml" type="float" xref="S3.T2.1.1.1.1.m1.1.1.2">
                4.17
               </cn>
               <apply id="S3.T2.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.1.1.1.1.m1.1.1.3">
                <csymbol cd="ambiguous" id="S3.T2.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1.3">
                 superscript
                </csymbol>
                <cn id="S3.T2.1.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="S3.T2.1.1.1.1.m1.1.1.3.2">
                 10
                </cn>
                <cn id="S3.T2.1.1.1.1.m1.1.1.3.3.cmml" type="integer" xref="S3.T2.1.1.1.1.m1.1.1.3.3">
                 3
                </cn>
               </apply>
              </apply>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">
              4.17\times 10^{3}
             </annotation>
             <annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.1.m1.1d">
              4.17 × 10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT
             </annotation>
            </semantics>
           </math>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T2.2.2.2">
          <td class="ltx_td ltx_align_left" id="S3.T2.2.2.2.2">
           <span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.2.1" style="font-size:90%;">
            Avg. Turns per Dialogue
           </span>
          </td>
          <td class="ltx_td ltx_align_center" id="S3.T2.2.2.2.1">
           <math alttext="4.10" class="ltx_Math" display="inline" id="S3.T2.2.2.2.1.m1.1">
            <semantics id="S3.T2.2.2.2.1.m1.1a">
             <mn id="S3.T2.2.2.2.1.m1.1.1" mathsize="90%" xref="S3.T2.2.2.2.1.m1.1.1.cmml">
              4.10
             </mn>
             <annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.m1.1b">
              <cn id="S3.T2.2.2.2.1.m1.1.1.cmml" type="float" xref="S3.T2.2.2.2.1.m1.1.1">
               4.10
              </cn>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.m1.1c">
              4.10
             </annotation>
             <annotation encoding="application/x-llamapun" id="S3.T2.2.2.2.1.m1.1d">
              4.10
             </annotation>
            </semantics>
           </math>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T2.3.3.3">
          <td class="ltx_td ltx_align_left" id="S3.T2.3.3.3.2">
           <span class="ltx_text ltx_font_bold" id="S3.T2.3.3.3.2.1" style="font-size:90%;">
            Avg. Words per Turn
           </span>
          </td>
          <td class="ltx_td ltx_align_center" id="S3.T2.3.3.3.1">
           <math alttext="42.80" class="ltx_Math" display="inline" id="S3.T2.3.3.3.1.m1.1">
            <semantics id="S3.T2.3.3.3.1.m1.1a">
             <mn id="S3.T2.3.3.3.1.m1.1.1" mathsize="90%" xref="S3.T2.3.3.3.1.m1.1.1.cmml">
              42.80
             </mn>
             <annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b">
              <cn id="S3.T2.3.3.3.1.m1.1.1.cmml" type="float" xref="S3.T2.3.3.3.1.m1.1.1">
               42.80
              </cn>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">
              42.80
             </annotation>
             <annotation encoding="application/x-llamapun" id="S3.T2.3.3.3.1.m1.1d">
              42.80
             </annotation>
            </semantics>
           </math>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T2.4.4.4">
          <td class="ltx_td ltx_align_left" id="S3.T2.4.4.4.2">
           <span class="ltx_text ltx_font_bold" id="S3.T2.4.4.4.2.1" style="font-size:90%;">
            Avg.Human Reason per Dialogue
           </span>
          </td>
          <td class="ltx_td ltx_align_center" id="S3.T2.4.4.4.1">
           <math alttext="1.56" class="ltx_Math" display="inline" id="S3.T2.4.4.4.1.m1.1">
            <semantics id="S3.T2.4.4.4.1.m1.1a">
             <mn id="S3.T2.4.4.4.1.m1.1.1" mathsize="90%" xref="S3.T2.4.4.4.1.m1.1.1.cmml">
              1.56
             </mn>
             <annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.1.m1.1b">
              <cn id="S3.T2.4.4.4.1.m1.1.1.cmml" type="float" xref="S3.T2.4.4.4.1.m1.1.1">
               1.56
              </cn>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S3.T2.4.4.4.1.m1.1c">
              1.56
             </annotation>
             <annotation encoding="application/x-llamapun" id="S3.T2.4.4.4.1.m1.1d">
              1.56
             </annotation>
            </semantics>
           </math>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T2.5.5.5">
          <td class="ltx_td ltx_align_left" id="S3.T2.5.5.5.2">
           <span class="ltx_text ltx_font_bold" id="S3.T2.5.5.5.2.1" style="font-size:90%;">
            Avg. Words per Human Annotated Reason
           </span>
          </td>
          <td class="ltx_td ltx_align_center" id="S3.T2.5.5.5.1">
           <math alttext="25.31" class="ltx_Math" display="inline" id="S3.T2.5.5.5.1.m1.1">
            <semantics id="S3.T2.5.5.5.1.m1.1a">
             <mn id="S3.T2.5.5.5.1.m1.1.1" mathsize="90%" xref="S3.T2.5.5.5.1.m1.1.1.cmml">
              25.31
             </mn>
             <annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.1.m1.1b">
              <cn id="S3.T2.5.5.5.1.m1.1.1.cmml" type="float" xref="S3.T2.5.5.5.1.m1.1.1">
               25.31
              </cn>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S3.T2.5.5.5.1.m1.1c">
              25.31
             </annotation>
             <annotation encoding="application/x-llamapun" id="S3.T2.5.5.5.1.m1.1d">
              25.31
             </annotation>
            </semantics>
           </math>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T2.6.6.6">
          <td class="ltx_td ltx_align_left" id="S3.T2.6.6.6.2">
           <span class="ltx_text ltx_font_bold" id="S3.T2.6.6.6.2.1" style="font-size:90%;">
            Vocabulary Size (dialogue)
           </span>
          </td>
          <td class="ltx_td ltx_align_center" id="S3.T2.6.6.6.1">
           <math alttext="4.89\times 10^{4}" class="ltx_Math" display="inline" id="S3.T2.6.6.6.1.m1.1">
            <semantics id="S3.T2.6.6.6.1.m1.1a">
             <mrow id="S3.T2.6.6.6.1.m1.1.1" xref="S3.T2.6.6.6.1.m1.1.1.cmml">
              <mn id="S3.T2.6.6.6.1.m1.1.1.2" mathsize="90%" xref="S3.T2.6.6.6.1.m1.1.1.2.cmml">
               4.89
              </mn>
              <mo id="S3.T2.6.6.6.1.m1.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.T2.6.6.6.1.m1.1.1.1.cmml">
               ×
              </mo>
              <msup id="S3.T2.6.6.6.1.m1.1.1.3" xref="S3.T2.6.6.6.1.m1.1.1.3.cmml">
               <mn id="S3.T2.6.6.6.1.m1.1.1.3.2" mathsize="90%" xref="S3.T2.6.6.6.1.m1.1.1.3.2.cmml">
                10
               </mn>
               <mn id="S3.T2.6.6.6.1.m1.1.1.3.3" mathsize="90%" xref="S3.T2.6.6.6.1.m1.1.1.3.3.cmml">
                4
               </mn>
              </msup>
             </mrow>
             <annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.1.m1.1b">
              <apply id="S3.T2.6.6.6.1.m1.1.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1">
               <times id="S3.T2.6.6.6.1.m1.1.1.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1.1">
               </times>
               <cn id="S3.T2.6.6.6.1.m1.1.1.2.cmml" type="float" xref="S3.T2.6.6.6.1.m1.1.1.2">
                4.89
               </cn>
               <apply id="S3.T2.6.6.6.1.m1.1.1.3.cmml" xref="S3.T2.6.6.6.1.m1.1.1.3">
                <csymbol cd="ambiguous" id="S3.T2.6.6.6.1.m1.1.1.3.1.cmml" xref="S3.T2.6.6.6.1.m1.1.1.3">
                 superscript
                </csymbol>
                <cn id="S3.T2.6.6.6.1.m1.1.1.3.2.cmml" type="integer" xref="S3.T2.6.6.6.1.m1.1.1.3.2">
                 10
                </cn>
                <cn id="S3.T2.6.6.6.1.m1.1.1.3.3.cmml" type="integer" xref="S3.T2.6.6.6.1.m1.1.1.3.3">
                 4
                </cn>
               </apply>
              </apply>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S3.T2.6.6.6.1.m1.1c">
              4.89\times 10^{4}
             </annotation>
             <annotation encoding="application/x-llamapun" id="S3.T2.6.6.6.1.m1.1d">
              4.89 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT
             </annotation>
            </semantics>
           </math>
          </td>
         </tr>
         <tr class="ltx_tr" id="S3.T2.7.7.7">
          <td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.7.7.7.2">
           <span class="ltx_text ltx_font_bold" id="S3.T2.7.7.7.2.1" style="font-size:90%;">
            Vocabulary Size (human-annotated reasons)
           </span>
          </td>
          <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.7.7.7.1">
           <math alttext="2.00\times 10^{4}" class="ltx_Math" display="inline" id="S3.T2.7.7.7.1.m1.1">
            <semantics id="S3.T2.7.7.7.1.m1.1a">
             <mrow id="S3.T2.7.7.7.1.m1.1.1" xref="S3.T2.7.7.7.1.m1.1.1.cmml">
              <mn id="S3.T2.7.7.7.1.m1.1.1.2" mathsize="90%" xref="S3.T2.7.7.7.1.m1.1.1.2.cmml">
               2.00
              </mn>
              <mo id="S3.T2.7.7.7.1.m1.1.1.1" lspace="0.222em" mathsize="90%" rspace="0.222em" xref="S3.T2.7.7.7.1.m1.1.1.1.cmml">
               ×
              </mo>
              <msup id="S3.T2.7.7.7.1.m1.1.1.3" xref="S3.T2.7.7.7.1.m1.1.1.3.cmml">
               <mn id="S3.T2.7.7.7.1.m1.1.1.3.2" mathsize="90%" xref="S3.T2.7.7.7.1.m1.1.1.3.2.cmml">
                10
               </mn>
               <mn id="S3.T2.7.7.7.1.m1.1.1.3.3" mathsize="90%" xref="S3.T2.7.7.7.1.m1.1.1.3.3.cmml">
                4
               </mn>
              </msup>
             </mrow>
             <annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.1.m1.1b">
              <apply id="S3.T2.7.7.7.1.m1.1.1.cmml" xref="S3.T2.7.7.7.1.m1.1.1">
               <times id="S3.T2.7.7.7.1.m1.1.1.1.cmml" xref="S3.T2.7.7.7.1.m1.1.1.1">
               </times>
               <cn id="S3.T2.7.7.7.1.m1.1.1.2.cmml" type="float" xref="S3.T2.7.7.7.1.m1.1.1.2">
                2.00
               </cn>
               <apply id="S3.T2.7.7.7.1.m1.1.1.3.cmml" xref="S3.T2.7.7.7.1.m1.1.1.3">
                <csymbol cd="ambiguous" id="S3.T2.7.7.7.1.m1.1.1.3.1.cmml" xref="S3.T2.7.7.7.1.m1.1.1.3">
                 superscript
                </csymbol>
                <cn id="S3.T2.7.7.7.1.m1.1.1.3.2.cmml" type="integer" xref="S3.T2.7.7.7.1.m1.1.1.3.2">
                 10
                </cn>
                <cn id="S3.T2.7.7.7.1.m1.1.1.3.3.cmml" type="integer" xref="S3.T2.7.7.7.1.m1.1.1.3.3">
                 4
                </cn>
               </apply>
              </apply>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="S3.T2.7.7.7.1.m1.1c">
              2.00\times 10^{4}
             </annotation>
             <annotation encoding="application/x-llamapun" id="S3.T2.7.7.7.1.m1.1d">
              2.00 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT
             </annotation>
            </semantics>
           </math>
          </td>
         </tr>
        </tbody>
       </table>
      </span>
     </div>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Dataset Statistics
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     The
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.1">
      DiPlomat
     </span>
     dataset comprises a total of 4,177 multi-turn dialogues, with each dialogue averaging 4.1 turns. On average, there are 1.56 pragmatic turns per dialogue. The distribution of dialogues with different quantities of pragmatic turns is illustrated in
     <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ 3.2 Dataset Statistics ‣ 3 The DiPlomat Dataset ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Figure
      </span>
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     ; see
     <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ Step III. Human Refinement. ‣ 3.1 Data Source Construction ‣ 3 The DiPlomat Dataset ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Table
      </span>
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     for detailed dataset statistics.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     With respect to the motivation introduced in
     <a class="ltx_ref" href="#S1" title="1 Introduction ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Sec.
      </span>
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     , we categorize the process of transitioning from dialogue to human-annotated rationales into five reasoning types:
    </p>
    <ul class="ltx_itemize" id="S3.I1">
     <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i1.p1">
       <p class="ltx_p" id="S3.I1.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">
         Contextual Reasoning:
        </span>
        The comprehension of the context is paramount for this reasoning process.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i2.p1">
       <p class="ltx_p" id="S3.I1.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">
         Figurative Language Reasoning:
        </span>
        Proficiency in understanding figurative language, such as idioms and metaphors, is indispensable for advancing this type of reasoning.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i3.p1">
       <p class="ltx_p" id="S3.I1.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">
         Commonsense Reasoning:
        </span>
        The utilization of commonsense knowledge, such as recognizing that a chateau cannot fall from the sky, is vital for this category.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i4.p1">
       <p class="ltx_p" id="S3.I1.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">
         External Knowledge Reasoning:
        </span>
        This form of reasoning necessitates knowledge that extends beyond commonsense and is not explicitly mentioned in the dialogue.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i5.p1">
       <p class="ltx_p" id="S3.I1.i5.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">
         Others:
        </span>
        This category includes pragmatic turns that fit none of the above.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S3.SS2.p3">
    <p class="ltx_p" id="S3.SS2.p3.1">
     <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ Pragmatics Reasoning ‣ 2 Related Work ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Figure
      </span>
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     demonstrates the proportion of each type. The prevalence of data within the context partition prove the significance of context in pragmatic reasoning of real life.
     <a class="ltx_ref" href="#S3.F2.sf1" title="2(a) ‣ Figure 4 ‣ 3.2 Dataset Statistics ‣ 3 The DiPlomat Dataset ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Figure
      </span>
      <span class="ltx_text ltx_ref_tag">
       2(a)
      </span>
     </a>
     depicts a sunburst visualization illustrating the distribution of trigram words within pragmatic turns. The diverse range of trigram words indicates that the
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">
      DiPlomat
     </span>
     dataset enjoys the rich diversity from real-life corpora, and covers a wide array of topics. In addition, the recurring occurrence of the words “president‘’ and
“world‘’ is observed, demonstrating
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.2">
      DiPlomat
     </span>
     ’s slight bias to politics and world-wide events.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F4">
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Distribution of trigram words of pragmatic turns and questions.
    </figcaption>
    <div class="ltx_flex_figure">
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_cell ltx_flex_size_1">
      <span class="ltx_inline-para ltx_minipage ltx_flex_size_1 ltx_align_center ltx_align_top" id="S3.F4.3" style="width:277.5pt;">
       <span class="ltx_figure ltx_align_center" id="S3.F2.sf1">
        <br class="ltx_break ltx_centering"/>
        <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="831" id="S3.F2.sf1.g1" src="x4.png" width="831"/>
        <span class="ltx_caption ltx_centering" style="font-size:90%;">
         <span class="ltx_tag ltx_tag_figure">
          (a)
         </span>
         Pragmatic Turns
        </span>
       </span>
       <span class="ltx_figure ltx_align_center" id="S3.F2.sf2">
        <br class="ltx_break"/>
        <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="705" id="S3.F2.sf2.g1" src="x5.png" width="705"/>
        <span class="ltx_caption" style="font-size:90%;">
         <span class="ltx_tag ltx_tag_figure">
          (b)
         </span>
         Questions
        </span>
       </span>
      </span>
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_cell ltx_flex_size_1">
      <span class="ltx_inline-para ltx_minipage ltx_flex_size_1 ltx_align_center ltx_align_top" id="S3.F4.1" style="width:143.1pt;">
       <span class="ltx_para ltx_align_center" id="S3.F4.1.p1">
        <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="612" id="S3.F4.1.p1.g1" src="x6.png" width="830"/>
       </span>
      </span>
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_break">
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Distribution of trigram words of pragmatic turns and questions.
    </figcaption>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Distribution of dialogues
     <em class="ltx_emph ltx_font_italic" id="S3.F4.12.1">
      w.r.t
     </em>
     .
     <span class="ltx_text" id="S3.F4.13.2">
     </span>
     # of pragmatic turns.
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Task Definition
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    We propose 2 distinct tasks for our dataset: (i) Pragmatics Identification and Reasoning and (ii) Conversational Question Answering. The former task focuses on assessing the capability of models to identify the presence of pragmatic phenomena and their ability to select a suitable answer for such identification. The latter task aims to evaluate the models’ adeptness in employing pragmatic reasoning by presenting them with carefully designed questions.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Task 1: Pragmatics Identification and Reasoning (PIR)
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     Inspired by previous work
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Zellers et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib51" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
     , we present the
     <span class="ltx_glossaryref" title="Pragmatic Identification and Reasoning">
      <span class="ltx_text ltx_glossary_long">
       Pragmatic Identification and Reasoning
      </span>
     </span>
     (
     <abbr class="ltx_glossaryref" title="Pragmatic Identification and Reasoning">
      <span class="ltx_text ltx_glossary_short">
       PIR
      </span>
     </abbr>
     ) task. In this task, models are provided with dialogues and are required to identify turns whose actual meanings deviate from their literal interpretations, commonly referred to as pragmatic turns.
If their selections are accurate, a set of rationales is presented and they are expected to choose the most plausible reason for each pragmatic turn. For each turn, there are 5 candidate reasons available, comprising one gold choice and four disturbing choices. The model’s success in this task depends on the precise execution of both steps. We consider three diagnostic settings to test the machine’s capability on pragmatic understanding:
    </p>
    <ul class="ltx_itemize" id="S4.I1">
     <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I1.i1.p1">
       <p class="ltx_p" id="S4.I1.i1.p1.2">
        Conversation
        <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.I1.i1.p1.1.m1.1">
         <semantics id="S4.I1.i1.p1.1.m1.1a">
          <mo id="S4.I1.i1.p1.1.m1.1.1" stretchy="false" xref="S4.I1.i1.p1.1.m1.1.1.cmml">
           →
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b">
           <ci id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">
            →
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">
           \rightarrow
          </annotation>
          <annotation encoding="application/x-llamapun" id="S4.I1.i1.p1.1.m1.1d">
           →
          </annotation>
         </semantics>
        </math>
        Pragmatic Turn (
        <span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.2.1">
         C
         <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.I1.i1.p1.2.1.m1.1">
          <semantics id="S4.I1.i1.p1.2.1.m1.1a">
           <mo id="S4.I1.i1.p1.2.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S4.I1.i1.p1.2.1.m1.1.1.cmml">
            →
           </mo>
           <annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.2.1.m1.1b">
            <ci id="S4.I1.i1.p1.2.1.m1.1.1.cmml" xref="S4.I1.i1.p1.2.1.m1.1.1">
             normal-→
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S4.I1.i1.p1.2.1.m1.1c">
            \rightarrow
           </annotation>
           <annotation encoding="application/x-llamapun" id="S4.I1.i1.p1.2.1.m1.1d">
            →
           </annotation>
          </semantics>
         </math>
         P
        </span>
        ). For each instance, models are presented with a dialogue and a specific turn extracted from that dialogue. They are then required to determine and whether the given turn qualifies as a pragmatic turn. Consequently, the dataset is flattened to a total of 17,129 instances, with each instance corresponding to a single turn. It’s important to highlight that turns without pragmatic meanings are also extracted for evaluation.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I1.i2.p1">
       <p class="ltx_p" id="S4.I1.i2.p1.3">
        Conversation
        <math alttext="+" class="ltx_Math" display="inline" id="S4.I1.i2.p1.1.m1.1">
         <semantics id="S4.I1.i2.p1.1.m1.1a">
          <mo id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">
           +
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b">
           <plus id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">
           </plus>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">
           +
          </annotation>
          <annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.1.m1.1d">
           +
          </annotation>
         </semantics>
        </math>
        Pragmatic Turn
        <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.I1.i2.p1.2.m2.1">
         <semantics id="S4.I1.i2.p1.2.m2.1a">
          <mo id="S4.I1.i2.p1.2.m2.1.1" stretchy="false" xref="S4.I1.i2.p1.2.m2.1.1.cmml">
           →
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.2.m2.1b">
           <ci id="S4.I1.i2.p1.2.m2.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1">
            →
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I1.i2.p1.2.m2.1c">
           \rightarrow
          </annotation>
          <annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.2.m2.1d">
           →
          </annotation>
         </semantics>
        </math>
        Rationale (
        <span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.3.1">
         CP
         <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.I1.i2.p1.3.1.m1.1">
          <semantics id="S4.I1.i2.p1.3.1.m1.1a">
           <mo id="S4.I1.i2.p1.3.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S4.I1.i2.p1.3.1.m1.1.1.cmml">
            →
           </mo>
           <annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.3.1.m1.1b">
            <ci id="S4.I1.i2.p1.3.1.m1.1.1.cmml" xref="S4.I1.i2.p1.3.1.m1.1.1">
             normal-→
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S4.I1.i2.p1.3.1.m1.1c">
            \rightarrow
           </annotation>
           <annotation encoding="application/x-llamapun" id="S4.I1.i2.p1.3.1.m1.1d">
            →
           </annotation>
          </semantics>
         </math>
         R
        </span>
        ). In this subtask, we offer the model both the dialogue and the pragmatic turn and it needs to choose the most plausible rationale out of five candidate choices.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S4.I1.i3.p1">
       <p class="ltx_p" id="S4.I1.i3.p1.4">
        Conversation
        <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.I1.i3.p1.1.m1.1">
         <semantics id="S4.I1.i3.p1.1.m1.1a">
          <mo id="S4.I1.i3.p1.1.m1.1.1" stretchy="false" xref="S4.I1.i3.p1.1.m1.1.1.cmml">
           →
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b">
           <ci id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1">
            →
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">
           \rightarrow
          </annotation>
          <annotation encoding="application/x-llamapun" id="S4.I1.i3.p1.1.m1.1d">
           →
          </annotation>
         </semantics>
        </math>
        Pragmatic Turn
        <math alttext="+" class="ltx_Math" display="inline" id="S4.I1.i3.p1.2.m2.1">
         <semantics id="S4.I1.i3.p1.2.m2.1a">
          <mo id="S4.I1.i3.p1.2.m2.1.1" xref="S4.I1.i3.p1.2.m2.1.1.cmml">
           +
          </mo>
          <annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.2.m2.1b">
           <plus id="S4.I1.i3.p1.2.m2.1.1.cmml" xref="S4.I1.i3.p1.2.m2.1.1">
           </plus>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S4.I1.i3.p1.2.m2.1c">
           +
          </annotation>
          <annotation encoding="application/x-llamapun" id="S4.I1.i3.p1.2.m2.1d">
           +
          </annotation>
         </semantics>
        </math>
        Rationale (
        <span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.3.1">
         C
         <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.I1.i3.p1.3.1.m1.1">
          <semantics id="S4.I1.i3.p1.3.1.m1.1a">
           <mo id="S4.I1.i3.p1.3.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S4.I1.i3.p1.3.1.m1.1.1.cmml">
            →
           </mo>
           <annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.3.1.m1.1b">
            <ci id="S4.I1.i3.p1.3.1.m1.1.1.cmml" xref="S4.I1.i3.p1.3.1.m1.1.1">
             normal-→
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S4.I1.i3.p1.3.1.m1.1c">
            \rightarrow
           </annotation>
           <annotation encoding="application/x-llamapun" id="S4.I1.i3.p1.3.1.m1.1d">
            →
           </annotation>
          </semantics>
         </math>
         PR
        </span>
        ) In this subtask, models pre-trained on the previous two subtasks are combined to infer the final results. Specifically, the model obtained from the first subtask is utilized for determining pragmatic turns, while its version finetuned on the second subtask is employed for selecting the most suitable rationale. It is worth noting that, in contrast to
        <span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.4.2">
         C
         <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.I1.i3.p1.4.2.m1.1">
          <semantics id="S4.I1.i3.p1.4.2.m1.1a">
           <mo id="S4.I1.i3.p1.4.2.m1.1.1" mathvariant="normal" stretchy="false" xref="S4.I1.i3.p1.4.2.m1.1.1.cmml">
            →
           </mo>
           <annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.4.2.m1.1b">
            <ci id="S4.I1.i3.p1.4.2.m1.1.1.cmml" xref="S4.I1.i3.p1.4.2.m1.1.1">
             normal-→
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S4.I1.i3.p1.4.2.m1.1c">
            \rightarrow
           </annotation>
           <annotation encoding="application/x-llamapun" id="S4.I1.i3.p1.4.2.m1.1d">
            →
           </annotation>
          </semantics>
         </math>
         P
        </span>
        , in this subtask, extracted turns are limited to pragmatic turns only.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Pragmatic Turns and Gold Choices
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">
      Recall that in our data collecting procedure outlined in
      <a class="ltx_ref" href="#S3.SS1" title="3.1 Data Source Construction ‣ 3 The DiPlomat Dataset ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        3.1
       </span>
      </a>
      , despite asking workers to select pragmatic turns, they are also instructed to fill in reasons to explain their choices. To simplify the evaluation process, the selected turns are directly utilized as answers for the first subtask, while the reasons provided by the workers serve as the designated correct choices (referred to as "gold choices") for the second subtask.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Disturbing Choice
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">
      As a result of the time-consuming nature of BERTScore
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Zhang et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib50" title="">
        <span class="ltx_text" style="font-size:90%;">
         2020b
        </span>
       </a>
       )
      </cite>
      , an alternative approach is adopted for measuring sentence similarity using Sentence-Transformers
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Reimers and Gurevych
       </span>
       (
       <a class="ltx_ref" href="#bib.bib52" title="">
        <span class="ltx_text" style="font-size:90%;">
         2019
        </span>
       </a>
       )
      </cite>
      , which is a significantly faster method. In our methodology, for each gold choice, four alternative choices with high similarity scores are selected from the pool of gold choices to serve as disturbing answers. Despite their high similarity scores, upon careful examination within the given context, it’s apparent that the disturbing answers convey entirely different meanings from the gold answer. This characteristic makes them appropriate components to build our task.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Task 2: Conversational Question Answering (CQA)
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     The ability in applying pragmatic reasoning is crucial for effective communication and achieving a thorough grasp of the natural language system. To address this, we propose conversational question-answering, wherein multiple questions are formulated for each dialogue, and an example is shown in
     <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ 4.2 Task 2: Conversational Question Answering (CQA) ‣ 4 Task Definition ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Figure
      </span>
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     . The questions focus on delving deeper into dialogues, often necessitating insights into the intended meanings to answer. ChatGPT assumes a pivotal role in question generation and thanks to
     <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
      <span class="ltx_text ltx_glossary_short">
       AMT
      </span>
     </abbr>
     , we can ensure the collection of high-quality answers. Ultimately,
     <math alttext="19,482" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.2">
      <semantics id="S4.SS2.p1.1.m1.2a">
       <mrow id="S4.SS2.p1.1.m1.2.3.2" xref="S4.SS2.p1.1.m1.2.3.1.cmml">
        <mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">
         19
        </mn>
        <mo id="S4.SS2.p1.1.m1.2.3.2.1" xref="S4.SS2.p1.1.m1.2.3.1.cmml">
         ,
        </mo>
        <mn id="S4.SS2.p1.1.m1.2.2" xref="S4.SS2.p1.1.m1.2.2.cmml">
         482
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.2b">
        <list id="S4.SS2.p1.1.m1.2.3.1.cmml" xref="S4.SS2.p1.1.m1.2.3.2">
         <cn id="S4.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1">
          19
         </cn>
         <cn id="S4.SS2.p1.1.m1.2.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.2.2">
          482
         </cn>
        </list>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.2c">
        19,482
       </annotation>
       <annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.2d">
        19 , 482
       </annotation>
      </semantics>
     </math>
     question-answer pairs are assembled.
    </p>
   </div>
   <figure class="ltx_figure ltx_align_floatright" id="S4.F5">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_1">
      <div class="ltx_inline-block ltx_flex_size_1 ltx_align_center ltx_transformed_outer" id="S4.F5.6" style="width:390.3pt;height:52.5pt;vertical-align:-48.4pt;">
       <span class="ltx_transformed_inner" style="transform:translate(-129.1pt,1.3pt) scale(0.601780453887083,0.601780453887083) ;">
        <span class="ltx_ERROR undefined" id="S4.F5.6.1">
         {tcolorbox}
        </span>
        <p class="ltx_p" id="S4.F5.6.2">
         <span class="ltx_text" id="S4.F5.6.2.1" style="font-size:90%;">
          [enhanced,boxrule=1pt,boxsep=1pt,left=0mm,right=0mm,top=2pt,bottom=1pt,colback=gray!10, breakable,width=8cm,colframe=black,arc=2mm, auto outer arc]
         </span>
         <span class="ltx_tabular ltx_align_middle" id="S4.F5.6.2.2">
          <span class="ltx_tbody">
           <span class="ltx_tr" id="S4.F5.6.2.2.1.1">
            <span class="ltx_td ltx_align_justify" id="S4.F5.6.2.2.1.1.1" style="width:213.4pt;">
             <span class="ltx_p ltx_align_top" id="S4.F5.6.2.2.1.1.1.1">
              <span class="ltx_text ltx_font_bold" id="S4.F5.6.2.2.1.1.1.1.1" style="font-size:90%;">
               A:
              </span>
              <span class="ltx_text" id="S4.F5.6.2.2.1.1.1.1.2" style="font-size:90%;">
               Finally, Ron, lots of talk about Congress releasing the second half of this $700 billion bailout this week. Where do we stand with that?
              </span>
             </span>
            </span>
           </span>
           <span class="ltx_tr" id="S4.F5.6.2.2.2.2">
            <span class="ltx_td ltx_align_justify" id="S4.F5.6.2.2.2.2.1" style="width:213.4pt;">
             <span class="ltx_p ltx_align_top" id="S4.F5.6.2.2.2.2.1.1">
              <span class="ltx_text ltx_font_bold" id="S4.F5.6.2.2.2.2.1.1.1" style="font-size:90%;">
               B:
              </span>
              <span class="ltx_text" id="S4.F5.6.2.2.2.2.1.1.2" style="font-size:90%;">
               Quite possible that Congress will get that done this week now that Barack
              </span>
              <span class="ltx_text" id="S4.F5.6.2.2.2.2.1.1.3" style="font-size:90%;color:#FF0000;">
               Obama
              </span>
              <span class="ltx_text" id="S4.F5.6.2.2.2.2.1.1.4" style="font-size:90%;">
               has asked George Bush, has asked the current president, to formally put in a
              </span>
              <span class="ltx_text" id="S4.F5.6.2.2.2.2.1.1.5" style="font-size:90%;color:#0000FF;">
               request
              </span>
              <span class="ltx_text" id="S4.F5.6.2.2.2.2.1.1.6" style="font-size:90%;">
               for that money. Congress has got a lot of questions about how this money is going to be spent, as it has questions about how the first half of the money was spent.
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
         <span class="ltx_text" id="S4.F5.6.2.3" style="font-size:90%;">
         </span>
        </p>
       </span>
      </div>
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_cell ltx_flex_size_1">
      <div class="ltx_inline-block ltx_flex_size_1 ltx_align_center ltx_transformed_outer" id="S4.F5.7" style="width:390.3pt;height:23.5pt;vertical-align:-18.7pt;">
       <span class="ltx_transformed_inner" style="transform:translate(-81.7pt,1.0pt) scale(0.704844229178808,0.704844229178808) ;">
        <span class="ltx_ERROR undefined" id="S4.F5.7.1">
         {tcolorbox}
        </span>
        <p class="ltx_p" id="S4.F5.7.2">
         <span class="ltx_text" id="S4.F5.7.2.1" style="font-size:90%;">
          [enhanced jigsaw,boxrule=0pt,left=0mm,right=0mm,top=2pt,bottom=1pt, width=8cm,arc=2mm, auto outer arc,borderline=0.5mm0mmblack!50!white,dashed]
         </span>
         <span class="ltx_tabular ltx_align_middle" id="S4.F5.7.2.2">
          <span class="ltx_tbody">
           <span class="ltx_tr" id="S4.F5.7.2.2.1.1">
            <span class="ltx_td ltx_align_justify" id="S4.F5.7.2.2.1.1.1" style="width:213.4pt;">
             <span class="ltx_p ltx_align_top" id="S4.F5.7.2.2.1.1.1.1">
              <span class="ltx_text ltx_font_bold" id="S4.F5.7.2.2.1.1.1.1.1" style="font-size:90%;">
               Rationale:
              </span>
              <span class="ltx_text" id="S4.F5.7.2.2.1.1.1.1.2" style="font-size:90%;">
               Barack Obama’s request for the $700 billion bailout may expedite the process.
              </span>
             </span>
            </span>
           </span>
          </span>
         </span>
         <span class="ltx_text" id="S4.F5.7.2.3" style="font-size:90%;">
         </span>
        </p>
       </span>
      </div>
     </div>
     <div class="ltx_flex_break">
     </div>
     <div class="ltx_flex_cell ltx_flex_size_1">
      <div class="ltx_inline-block ltx_flex_size_1 ltx_align_center ltx_transformed_outer" id="S4.F5.4" style="width:403.3pt;height:103.1pt;vertical-align:-0.0pt;">
       <span class="ltx_transformed_inner" style="transform:translate(60.8pt,-15.5pt) scale(1.43130414419174,1.43130414419174) ;">
        <table class="ltx_tabular ltx_align_middle" id="S4.F5.4.4">
         <tbody class="ltx_tbody">
          <tr class="ltx_tr" id="S4.F5.1.1.1">
           <td class="ltx_td ltx_align_justify" id="S4.F5.1.1.1.1" style="width:213.4pt;">
            <p class="ltx_p ltx_align_top" id="S4.F5.1.1.1.1.1.1">
             <span class="ltx_text ltx_font_bold" id="S4.F5.1.1.1.1.1.1.1" style="font-size:90%;">
              Q
              <math alttext="{}_{1}" class="ltx_Math" display="inline" id="S4.F5.1.1.1.1.1.1.1.m1.1">
               <semantics id="S4.F5.1.1.1.1.1.1.1.m1.1a">
                <msub id="S4.F5.1.1.1.1.1.1.1.m1.1.1" xref="S4.F5.1.1.1.1.1.1.1.m1.1.1.cmml">
                 <mi id="S4.F5.1.1.1.1.1.1.1.m1.1.1a" xref="S4.F5.1.1.1.1.1.1.1.m1.1.1.cmml">
                 </mi>
                 <mn id="S4.F5.1.1.1.1.1.1.1.m1.1.1.1" mathvariant="normal" xref="S4.F5.1.1.1.1.1.1.1.m1.1.1.1.cmml">
                  1
                 </mn>
                </msub>
                <annotation-xml encoding="MathML-Content" id="S4.F5.1.1.1.1.1.1.1.m1.1b">
                 <apply id="S4.F5.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.F5.1.1.1.1.1.1.1.m1.1.1">
                  <cn id="S4.F5.1.1.1.1.1.1.1.m1.1.1.1.cmml" type="integer" xref="S4.F5.1.1.1.1.1.1.1.m1.1.1.1">
                   1
                  </cn>
                 </apply>
                </annotation-xml>
                <annotation encoding="application/x-tex" id="S4.F5.1.1.1.1.1.1.1.m1.1c">
                 {}_{1}
                </annotation>
                <annotation encoding="application/x-llamapun" id="S4.F5.1.1.1.1.1.1.1.m1.1d">
                 start_FLOATSUBSCRIPT 1 end_FLOATSUBSCRIPT
                </annotation>
               </semantics>
              </math>
              :
             </span>
             <span class="ltx_text" id="S4.F5.1.1.1.1.1.1.2" style="font-size:90%;">
              What may expedite the process?
             </span>
            </p>
           </td>
          </tr>
          <tr class="ltx_tr" id="S4.F5.2.2.2">
           <td class="ltx_td ltx_align_justify" id="S4.F5.2.2.2.1" style="width:213.4pt;">
            <p class="ltx_p ltx_align_top" id="S4.F5.2.2.2.1.1.1">
             <span class="ltx_text ltx_font_bold" id="S4.F5.2.2.2.1.1.1.1" style="font-size:90%;">
              A
              <math alttext="{}_{1}" class="ltx_Math" display="inline" id="S4.F5.2.2.2.1.1.1.1.m1.1">
               <semantics id="S4.F5.2.2.2.1.1.1.1.m1.1a">
                <msub id="S4.F5.2.2.2.1.1.1.1.m1.1.1" xref="S4.F5.2.2.2.1.1.1.1.m1.1.1.cmml">
                 <mi id="S4.F5.2.2.2.1.1.1.1.m1.1.1a" xref="S4.F5.2.2.2.1.1.1.1.m1.1.1.cmml">
                 </mi>
                 <mn id="S4.F5.2.2.2.1.1.1.1.m1.1.1.1" mathvariant="normal" xref="S4.F5.2.2.2.1.1.1.1.m1.1.1.1.cmml">
                  1
                 </mn>
                </msub>
                <annotation-xml encoding="MathML-Content" id="S4.F5.2.2.2.1.1.1.1.m1.1b">
                 <apply id="S4.F5.2.2.2.1.1.1.1.m1.1.1.cmml" xref="S4.F5.2.2.2.1.1.1.1.m1.1.1">
                  <cn id="S4.F5.2.2.2.1.1.1.1.m1.1.1.1.cmml" type="integer" xref="S4.F5.2.2.2.1.1.1.1.m1.1.1.1">
                   1
                  </cn>
                 </apply>
                </annotation-xml>
                <annotation encoding="application/x-tex" id="S4.F5.2.2.2.1.1.1.1.m1.1c">
                 {}_{1}
                </annotation>
                <annotation encoding="application/x-llamapun" id="S4.F5.2.2.2.1.1.1.1.m1.1d">
                 start_FLOATSUBSCRIPT 1 end_FLOATSUBSCRIPT
                </annotation>
               </semantics>
              </math>
              :
             </span>
             <span class="ltx_text" id="S4.F5.2.2.2.1.1.1.2" style="font-size:90%;">
             </span>
             <span class="ltx_text" id="S4.F5.2.2.2.1.1.1.3" style="font-size:90%;color:#0000FF;">
              Request
             </span>
            </p>
           </td>
          </tr>
          <tr class="ltx_tr" id="S4.F5.3.3.3">
           <td class="ltx_td ltx_align_justify" id="S4.F5.3.3.3.1" style="width:213.4pt;">
            <p class="ltx_p ltx_align_top" id="S4.F5.3.3.3.1.1.1">
             <span class="ltx_text ltx_font_bold" id="S4.F5.3.3.3.1.1.1.1" style="font-size:90%;">
              Q
              <math alttext="{}_{2}" class="ltx_Math" display="inline" id="S4.F5.3.3.3.1.1.1.1.m1.1">
               <semantics id="S4.F5.3.3.3.1.1.1.1.m1.1a">
                <msub id="S4.F5.3.3.3.1.1.1.1.m1.1.1" xref="S4.F5.3.3.3.1.1.1.1.m1.1.1.cmml">
                 <mi id="S4.F5.3.3.3.1.1.1.1.m1.1.1a" xref="S4.F5.3.3.3.1.1.1.1.m1.1.1.cmml">
                 </mi>
                 <mn id="S4.F5.3.3.3.1.1.1.1.m1.1.1.1" mathvariant="normal" xref="S4.F5.3.3.3.1.1.1.1.m1.1.1.1.cmml">
                  2
                 </mn>
                </msub>
                <annotation-xml encoding="MathML-Content" id="S4.F5.3.3.3.1.1.1.1.m1.1b">
                 <apply id="S4.F5.3.3.3.1.1.1.1.m1.1.1.cmml" xref="S4.F5.3.3.3.1.1.1.1.m1.1.1">
                  <cn id="S4.F5.3.3.3.1.1.1.1.m1.1.1.1.cmml" type="integer" xref="S4.F5.3.3.3.1.1.1.1.m1.1.1.1">
                   2
                  </cn>
                 </apply>
                </annotation-xml>
                <annotation encoding="application/x-tex" id="S4.F5.3.3.3.1.1.1.1.m1.1c">
                 {}_{2}
                </annotation>
                <annotation encoding="application/x-llamapun" id="S4.F5.3.3.3.1.1.1.1.m1.1d">
                 start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT
                </annotation>
               </semantics>
              </math>
              :
             </span>
             <span class="ltx_text" id="S4.F5.3.3.3.1.1.1.2" style="font-size:90%;">
              Which president requested the $700 billion bailout to be released?
             </span>
            </p>
           </td>
          </tr>
          <tr class="ltx_tr" id="S4.F5.4.4.4">
           <td class="ltx_td ltx_align_justify" id="S4.F5.4.4.4.1" style="width:213.4pt;">
            <p class="ltx_p ltx_align_top" id="S4.F5.4.4.4.1.1.1">
             <span class="ltx_text ltx_font_bold" id="S4.F5.4.4.4.1.1.1.1" style="font-size:90%;">
              A
              <math alttext="{}_{2}" class="ltx_Math" display="inline" id="S4.F5.4.4.4.1.1.1.1.m1.1">
               <semantics id="S4.F5.4.4.4.1.1.1.1.m1.1a">
                <msub id="S4.F5.4.4.4.1.1.1.1.m1.1.1" xref="S4.F5.4.4.4.1.1.1.1.m1.1.1.cmml">
                 <mi id="S4.F5.4.4.4.1.1.1.1.m1.1.1a" xref="S4.F5.4.4.4.1.1.1.1.m1.1.1.cmml">
                 </mi>
                 <mn id="S4.F5.4.4.4.1.1.1.1.m1.1.1.1" mathvariant="normal" xref="S4.F5.4.4.4.1.1.1.1.m1.1.1.1.cmml">
                  2
                 </mn>
                </msub>
                <annotation-xml encoding="MathML-Content" id="S4.F5.4.4.4.1.1.1.1.m1.1b">
                 <apply id="S4.F5.4.4.4.1.1.1.1.m1.1.1.cmml" xref="S4.F5.4.4.4.1.1.1.1.m1.1.1">
                  <cn id="S4.F5.4.4.4.1.1.1.1.m1.1.1.1.cmml" type="integer" xref="S4.F5.4.4.4.1.1.1.1.m1.1.1.1">
                   2
                  </cn>
                 </apply>
                </annotation-xml>
                <annotation encoding="application/x-tex" id="S4.F5.4.4.4.1.1.1.1.m1.1c">
                 {}_{2}
                </annotation>
                <annotation encoding="application/x-llamapun" id="S4.F5.4.4.4.1.1.1.1.m1.1d">
                 start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT
                </annotation>
               </semantics>
              </math>
              :
             </span>
             <span class="ltx_text" id="S4.F5.4.4.4.1.1.1.2" style="font-size:90%;">
             </span>
             <span class="ltx_text" id="S4.F5.4.4.4.1.1.1.3" style="font-size:90%;color:#FF0000;">
              Obama
             </span>
            </p>
           </td>
          </tr>
         </tbody>
        </table>
       </span>
      </div>
     </div>
    </div>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     Conversational Question Answering example.
    </figcaption>
   </figure>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Question Generation
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">
      ChatGPT is employed to generate questions with prompts consisting of dialogues and human-annotated reasons. We task it to generate questions challenging for individuals who are unaware of the dialogues’ intended meanings. More than that, for the convenience of evaluation, the question is also asked to be able to answer within one or two words. Furthermore, to ensure diversity, we instruct ChatGPT to initiate the questions with "What", "Which" or "How". A preliminary assessment is carried out by sampling a few examples out of the question pool to guarantee quality.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Answer Collection
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">
      The answers to the questions are obtained through the utilization of
      <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
       <span class="ltx_text ltx_glossary_short">
        AMT
       </span>
      </abbr>
      . Each worker is provided with a dialogue along with several associated questions and it is requested to answer the questions in one single word. To minimize the potential for misinterpretation, we offer an example coming from our dataset, which is annotated by the author itself. Through the process of human annotation, we consistently evaluate the collected data and reject unqualified answers as well as block workers who fail to meet our standards.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Statistical feature of Questions
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px3.p1.1">
      <a class="ltx_ref" href="#S3.F2.sf2" title="2(b) ‣ Figure 4 ‣ 3.2 Dataset Statistics ‣ 3 The DiPlomat Dataset ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Figure
       </span>
       <span class="ltx_text ltx_ref_tag">
        2(b)
       </span>
      </a>
      showcases the diverse range of our questions. These questions encompass a variety of sentence structures, starting with interrogative words: What, Which, and How, their following words vary a lot. Apart from the questions, the answer set holds a vocabulary size of 8,179, which is also of great diversity and raises a challenge for models.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Experiment
  </h2>
  <figure class="ltx_table ltx_align_floatright" id="S5.T3">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.15" style="width:433.6pt;height:199.2pt;vertical-align:-0.0pt;">
    <span class="ltx_transformed_inner" style="transform:translate(99.3pt,-45.6pt) scale(1.84464230249563,1.84464230249563) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T3.15.15">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S5.T3.3.3.3">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T3.3.3.3.4">
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1.1">
          C
          <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.T3.1.1.1.1.1.m1.1">
           <semantics id="S5.T3.1.1.1.1.1.m1.1a">
            <mo id="S5.T3.1.1.1.1.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.T3.1.1.1.1.1.m1.1.1.cmml">
             →
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.1.m1.1b">
             <ci id="S5.T3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1">
              normal-→
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.1.m1.1c">
             \rightarrow
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.1.1.m1.1d">
             →
            </annotation>
           </semantics>
          </math>
          P
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.2.2.2.2">
         <span class="ltx_text ltx_font_bold" id="S5.T3.2.2.2.2.1">
          CP
          <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.T3.2.2.2.2.1.m1.1">
           <semantics id="S5.T3.2.2.2.2.1.m1.1a">
            <mo id="S5.T3.2.2.2.2.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.T3.2.2.2.2.1.m1.1.1.cmml">
             →
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.1.m1.1b">
             <ci id="S5.T3.2.2.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1">
              normal-→
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.1.m1.1c">
             \rightarrow
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.2.1.m1.1d">
             →
            </annotation>
           </semantics>
          </math>
          R
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.3.3.3.3">
         <span class="ltx_text ltx_font_bold" id="S5.T3.3.3.3.3.1">
          C
          <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.T3.3.3.3.3.1.m1.1">
           <semantics id="S5.T3.3.3.3.3.1.m1.1a">
            <mo id="S5.T3.3.3.3.3.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.T3.3.3.3.3.1.m1.1.1.cmml">
             →
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.3.1.m1.1b">
             <ci id="S5.T3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.3.3.1.m1.1.1">
              normal-→
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T3.3.3.3.3.1.m1.1c">
             \rightarrow
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.3.1.m1.1d">
             →
            </annotation>
           </semantics>
          </math>
          PR
         </span>
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S5.T3.15.15.16.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T3.15.15.16.1.1">
         Random
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.15.15.16.1.2">
         50
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.15.15.16.1.3">
         20
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.15.15.16.1.4">
         10
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.6.6.6">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.6.6.6.4">
         BERT
         <sub class="ltx_sub" id="S5.T3.6.6.6.4.1">
          base
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="S5.T3.4.4.4.1">
         63.2
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.4.4.4.1.m1.1">
          <semantics id="S5.T3.4.4.4.1.m1.1a">
           <mo id="S5.T3.4.4.4.1.m1.1.1" xref="S5.T3.4.4.4.1.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.1.m1.1b">
            <csymbol cd="latexml" id="S5.T3.4.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.4.1.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.4.4.4.1.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.4.4.4.1.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         1.1
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.5.5.5.2">
         91.3
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.5.5.5.2.m1.1">
          <semantics id="S5.T3.5.5.5.2.m1.1a">
           <mo id="S5.T3.5.5.5.2.m1.1.1" xref="S5.T3.5.5.5.2.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.5.5.5.2.m1.1b">
            <csymbol cd="latexml" id="S5.T3.5.5.5.2.m1.1.1.cmml" xref="S5.T3.5.5.5.2.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.5.5.5.2.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.5.5.5.2.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         0.7
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.6.6.6.3">
         <span class="ltx_text ltx_font_bold" id="S5.T3.6.6.6.3.1">
          50.2
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.6.6.6.3.1.m1.1">
           <semantics id="S5.T3.6.6.6.3.1.m1.1a">
            <mo id="S5.T3.6.6.6.3.1.m1.1.1" mathvariant="normal" xref="S5.T3.6.6.6.3.1.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T3.6.6.6.3.1.m1.1b">
             <csymbol cd="latexml" id="S5.T3.6.6.6.3.1.m1.1.1.cmml" xref="S5.T3.6.6.6.3.1.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T3.6.6.6.3.1.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T3.6.6.6.3.1.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          6.8
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.9.9.9">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.9.9.9.4">
         RoBERTa
         <sub class="ltx_sub" id="S5.T3.9.9.9.4.1">
          base
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="S5.T3.7.7.7.1">
         64.4
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.7.7.7.1.m1.1">
          <semantics id="S5.T3.7.7.7.1.m1.1a">
           <mo id="S5.T3.7.7.7.1.m1.1.1" xref="S5.T3.7.7.7.1.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.7.7.7.1.m1.1b">
            <csymbol cd="latexml" id="S5.T3.7.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.7.1.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.7.7.7.1.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.7.7.7.1.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         1.3
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.8.8.8.2">
         <span class="ltx_text ltx_font_bold" id="S5.T3.8.8.8.2.1">
          92.0
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.8.8.8.2.1.m1.1">
           <semantics id="S5.T3.8.8.8.2.1.m1.1a">
            <mo id="S5.T3.8.8.8.2.1.m1.1.1" mathvariant="normal" xref="S5.T3.8.8.8.2.1.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T3.8.8.8.2.1.m1.1b">
             <csymbol cd="latexml" id="S5.T3.8.8.8.2.1.m1.1.1.cmml" xref="S5.T3.8.8.8.2.1.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T3.8.8.8.2.1.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T3.8.8.8.2.1.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          0.4
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.9.9.9.3">
         50.0
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.9.9.9.3.m1.1">
          <semantics id="S5.T3.9.9.9.3.m1.1a">
           <mo id="S5.T3.9.9.9.3.m1.1.1" xref="S5.T3.9.9.9.3.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.9.9.9.3.m1.1b">
            <csymbol cd="latexml" id="S5.T3.9.9.9.3.m1.1.1.cmml" xref="S5.T3.9.9.9.3.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.9.9.9.3.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.9.9.9.3.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         11.28
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.12.12.12">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T3.12.12.12.4">
         GPT-2
         <sub class="ltx_sub" id="S5.T3.12.12.12.4.1">
          base
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="S5.T3.10.10.10.1">
         64.4
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.10.10.10.1.m1.1">
          <semantics id="S5.T3.10.10.10.1.m1.1a">
           <mo id="S5.T3.10.10.10.1.m1.1.1" xref="S5.T3.10.10.10.1.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.10.10.10.1.m1.1b">
            <csymbol cd="latexml" id="S5.T3.10.10.10.1.m1.1.1.cmml" xref="S5.T3.10.10.10.1.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.10.10.10.1.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.10.10.10.1.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         0.7
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.11.11.11.2">
         90.9
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.11.11.11.2.m1.1">
          <semantics id="S5.T3.11.11.11.2.m1.1a">
           <mo id="S5.T3.11.11.11.2.m1.1.1" xref="S5.T3.11.11.11.2.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.11.11.11.2.m1.1b">
            <csymbol cd="latexml" id="S5.T3.11.11.11.2.m1.1.1.cmml" xref="S5.T3.11.11.11.2.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.11.11.11.2.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.11.11.11.2.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         0.9
        </td>
        <td class="ltx_td ltx_align_center" id="S5.T3.12.12.12.3">
         13.06
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.12.12.12.3.m1.1">
          <semantics id="S5.T3.12.12.12.3.m1.1a">
           <mo id="S5.T3.12.12.12.3.m1.1.1" xref="S5.T3.12.12.12.3.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.12.12.12.3.m1.1b">
            <csymbol cd="latexml" id="S5.T3.12.12.12.3.m1.1.1.cmml" xref="S5.T3.12.12.12.3.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.12.12.12.3.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.12.12.12.3.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         1.1
        </td>
       </tr>
       <tr class="ltx_tr" id="S5.T3.15.15.15">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T3.15.15.15.4">
         DialoGPT
         <sub class="ltx_sub" id="S5.T3.15.15.15.4.1">
          medium
         </sub>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.13.13.13.1">
         <span class="ltx_text ltx_font_bold" id="S5.T3.13.13.13.1.1">
          65.0
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.13.13.13.1.1.m1.1">
           <semantics id="S5.T3.13.13.13.1.1.m1.1a">
            <mo id="S5.T3.13.13.13.1.1.m1.1.1" mathvariant="normal" xref="S5.T3.13.13.13.1.1.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T3.13.13.13.1.1.m1.1b">
             <csymbol cd="latexml" id="S5.T3.13.13.13.1.1.m1.1.1.cmml" xref="S5.T3.13.13.13.1.1.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T3.13.13.13.1.1.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T3.13.13.13.1.1.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          0.6
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.14.14.14.2">
         24.5
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.14.14.14.2.m1.1">
          <semantics id="S5.T3.14.14.14.2.m1.1a">
           <mo id="S5.T3.14.14.14.2.m1.1.1" xref="S5.T3.14.14.14.2.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.14.14.14.2.m1.1b">
            <csymbol cd="latexml" id="S5.T3.14.14.14.2.m1.1.1.cmml" xref="S5.T3.14.14.14.2.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.14.14.14.2.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.14.14.14.2.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         1.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.15.15.15.3">
         3.8
         <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T3.15.15.15.3.m1.1">
          <semantics id="S5.T3.15.15.15.3.m1.1a">
           <mo id="S5.T3.15.15.15.3.m1.1.1" xref="S5.T3.15.15.15.3.m1.1.1.cmml">
            ±
           </mo>
           <annotation-xml encoding="MathML-Content" id="S5.T3.15.15.15.3.m1.1b">
            <csymbol cd="latexml" id="S5.T3.15.15.15.3.m1.1.1.cmml" xref="S5.T3.15.15.15.3.m1.1.1">
             plus-or-minus
            </csymbol>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S5.T3.15.15.15.3.m1.1c">
            \pm
           </annotation>
           <annotation encoding="application/x-llamapun" id="S5.T3.15.15.15.3.m1.1d">
            ±
           </annotation>
          </semantics>
         </math>
         1.5
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     <span class="ltx_text" id="S5.T3.17.1.1" style="font-size:90%;">
      Table 3
     </span>
     :
    </span>
    <span class="ltx_text" id="S5.T3.18.2" style="font-size:90%;">
     Pragmatics Identification and Reasoning Results. The numerical results are
accuracy scores in their percentage
    </span>
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Pragmatics Identification and Reasoning
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.3">
     For
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">
      C
      <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p1.1.1.m1.1">
       <semantics id="S5.SS1.p1.1.1.m1.1a">
        <mo id="S5.SS1.p1.1.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.p1.1.1.m1.1.1.cmml">
         →
        </mo>
        <annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.1.m1.1b">
         <ci id="S5.SS1.p1.1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.1.m1.1.1">
          normal-→
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS1.p1.1.1.m1.1c">
         \rightarrow
        </annotation>
        <annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.1.m1.1d">
         →
        </annotation>
       </semantics>
      </math>
      P
     </span>
     , we partitioned the dataset into distinct subsets for training, validation, and testing. The training set consists of 13,708 examples, surpassing the 1,361 instances in the validation set and the 2,060 instances in the test set in terms of size. Models are trained on the training set and their performance is evaluated on the validation set after each epoch to determine the optimal checkpoint. The best checkpoint is subsequently loaded for the final evaluation on the test dataset.
The evaluation metric employed is the accuracy score, calculated as the ratio of correct predictions to the total number of instances. Similarly, for the task of
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.2.2">
      CP
      <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p1.2.2.m1.1">
       <semantics id="S5.SS1.p1.2.2.m1.1a">
        <mo id="S5.SS1.p1.2.2.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.p1.2.2.m1.1.1.cmml">
         →
        </mo>
        <annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.2.m1.1b">
         <ci id="S5.SS1.p1.2.2.m1.1.1.cmml" xref="S5.SS1.p1.2.2.m1.1.1">
          normal-→
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS1.p1.2.2.m1.1c">
         \rightarrow
        </annotation>
        <annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.2.m1.1d">
         →
        </annotation>
       </semantics>
      </math>
      R
     </span>
     , the dataset is also partitioned into training, validation, and test subsets. The respective sizes of these subsets are 5,188, 244, and 1,062 examples. The training and evaluation procedures are identical to those of the previous subtask.
For
     <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.3.3">
      C
      <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.p1.3.3.m1.1">
       <semantics id="S5.SS1.p1.3.3.m1.1a">
        <mo id="S5.SS1.p1.3.3.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.p1.3.3.m1.1.1.cmml">
         →
        </mo>
        <annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.3.m1.1b">
         <ci id="S5.SS1.p1.3.3.m1.1.1.cmml" xref="S5.SS1.p1.3.3.m1.1.1">
          normal-→
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS1.p1.3.3.m1.1c">
         \rightarrow
        </annotation>
        <annotation encoding="application/x-llamapun" id="S5.SS1.p1.3.3.m1.1d">
         →
        </annotation>
       </semantics>
      </math>
      PR
     </span>
     , the test sets in previous subtasks are taken for evaluation, and it’s worth noting that their test sets consist of exactly the same instances. This design ensures the prevention of any leakage of the test set into the training set, thereby maintaining the integrity of the evaluation process.
    </p>
   </div>
   <section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Results and Analysis
    </h4>
    <div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.8">
      We present three key observations for this task: (1)The primary performance bottleneck lies in the subtask
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.1">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.1.1.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.1.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.1.1.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
      . As shown in
      <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5 Experiment ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      , the models achieve an accuracy score of approximately 90 in the
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.2.2">
       CP
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.2.2.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.2.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.2.2.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       R
      </span>
      subtask, indicating their capability to reason to some extent. However, when it comes to the
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.3.3">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.3.3.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.3.3.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.3.3.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.3.3.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.3.3.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.3.3.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.3.3.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.3.3.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.3.3.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       PR
      </span>
      task, the best-performing model achieves only 50.2 accuracy, while the highest accuracy achieved in the
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.4.4">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.4.4.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.4.4.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.4.4.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.4.4.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.4.4.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.4.4.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.4.4.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.4.4.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.4.4.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
      task is 65.0. The substantial difference between the score of 90 and the score of 65.0 suggests that the difficulty in accomplishing the task primarily stems from the
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.5.5">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.5.5.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.5.5.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.5.5.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.5.5.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.5.5.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.5.5.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.5.5.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.5.5.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.5.5.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
      subtask. (2) Accumulated variance in the
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.6.6">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.6.6.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.6.6.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.6.6.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.6.6.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.6.6.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.6.6.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.6.6.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.6.6.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.6.6.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       PR
      </span>
      subtask. The models exhibit significant variance in the results of the third subtask, which can be attributed to the variance introduced by its constituent tasks (3) The significance of pragmatic awareness in language models. Both the
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.7.7">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.7.7.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.7.7.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.7.7.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.7.7.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.7.7.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.7.7.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.7.7.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.7.7.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.7.7.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
      and
      <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.8.8">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.8.8.m1.1">
        <semantics id="S5.SS1.SSS0.Px1.p1.8.8.m1.1a">
         <mo id="S5.SS1.SSS0.Px1.p1.8.8.m1.1.1" mathvariant="normal" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.8.8.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.8.8.m1.1b">
          <ci id="S5.SS1.SSS0.Px1.p1.8.8.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.8.8.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.8.8.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.8.8.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       PR
      </span>
      subtasks require pragmatic awareness, and the poor performances of the models on these subtasks highlight their limitations in accurately determining the optimal timing for deploying reasoning abilities.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Conversational Question Answering
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     Similarly to the previous task, the question-answering dataset is divided into training, validation, and test sets, comprising 15,585, 1,559, and 2,338 instances, respectively. Experimental subjects includes BART
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Lewis et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib53" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
     , T5
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Raffel et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib54" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     , UnifiedQA
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Khashabi et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib55" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     , and mT5
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Xue et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib56" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      )
     </cite>
     . The metric adopted is also accuracy score. Given ChatGPT’s impressive performance in MMLU and AI2 Reasoning Challenge
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       OpenAI
      </span>
      (
      <a class="ltx_ref" href="#bib.bib13" title="">
       <span class="ltx_text" style="font-size:90%;">
        2023
       </span>
      </a>
      )
     </cite>
     , we further examine ChatGPT’s capability in the context of CQA by prompting it to provide one-word answers to questions. However, due to its uncontrollable nature, the generated answers may not always align with our desired settings. Hence, we introduce two evaluation metrics for ChatGPT: (1) em (exact match), which requires ChatGPT to produce the exact same word as our answer, and (2) pm (partially match), where we consider ChatGPT to be correct as long as our answer appears in its generated output. Two configurations are employed for evaluation. In the first configuration, models receive dialogues and questions while remaining blind to human-annotated rationales. The second configuration is a contrasting experiment with human-annotated rationales provided. For each configuration, we run each model three times using different random seeds and report the mean and variance of their results as the final outcomes.
    </p>
   </div>
   <figure class="ltx_table" id="S5.T4">
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     CQA task results with/without human annotated rationales. The numerical results are accuracy scores in their percentage. em: exact match, pm: partially match.
    </figcaption>
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.11" style="width:433.6pt;height:68pt;vertical-align:-0.9pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-15.9pt,2.5pt) scale(0.93158105988993,0.93158105988993) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T4.11.11">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="S5.T4.11.11.12.1">
         <th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S5.T4.11.11.12.1.1">
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.11.11.12.1.2">
          <span class="ltx_text" id="S5.T4.11.11.12.1.2.1" style="font-size:90%;">
           BART-base
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.11.11.12.1.3">
          <span class="ltx_text" id="S5.T4.11.11.12.1.3.1" style="font-size:90%;">
           T5-small
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.11.11.12.1.4">
          <span class="ltx_text" id="S5.T4.11.11.12.1.4.1" style="font-size:90%;">
           mT5-small
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.11.11.12.1.5">
          <span class="ltx_text" id="S5.T4.11.11.12.1.5.1" style="font-size:90%;">
           UnifiedQA-base
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.11.11.12.1.6">
          <span class="ltx_text" id="S5.T4.11.11.12.1.6.1" style="font-size:90%;">
           UnifiedQA-large
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.11.11.12.1.7">
          <span class="ltx_text" id="S5.T4.11.11.12.1.7.1" style="font-size:90%;">
           ChatGPT (em)
          </span>
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.11.11.12.1.8">
          <span class="ltx_text" id="S5.T4.11.11.12.1.8.1" style="font-size:90%;">
           ChatGPT (pm)
          </span>
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S5.T4.5.5.5">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.5.5.5.6">
          <span class="ltx_text" id="S5.T4.5.5.5.6.1" style="font-size:90%;">
           w/o rationale
          </span>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.1.1">
          <span class="ltx_text" id="S5.T4.1.1.1.1.1" style="font-size:90%;">
           20.2
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.1.1.1.1.m1.1">
           <semantics id="S5.T4.1.1.1.1.m1.1a">
            <mo id="S5.T4.1.1.1.1.m1.1.1" mathsize="90%" xref="S5.T4.1.1.1.1.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b">
             <csymbol cd="latexml" id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.1.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.1.1.1.1.2" style="font-size:90%;">
           1.1
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.2.2">
          <span class="ltx_text" id="S5.T4.2.2.2.2.1" style="font-size:90%;">
           24.9
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.2.2.2.2.m1.1">
           <semantics id="S5.T4.2.2.2.2.m1.1a">
            <mo id="S5.T4.2.2.2.2.m1.1.1" mathsize="90%" xref="S5.T4.2.2.2.2.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.2.m1.1b">
             <csymbol cd="latexml" id="S5.T4.2.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.2.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.2.2.2.2.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.2.2.2.2.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.2.2.2.2.2" style="font-size:90%;">
           0.7
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.3.3.3.3">
          <span class="ltx_text" id="S5.T4.3.3.3.3.1" style="font-size:90%;">
           19.7
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.3.3.3.3.m1.1">
           <semantics id="S5.T4.3.3.3.3.m1.1a">
            <mo id="S5.T4.3.3.3.3.m1.1.1" mathsize="90%" xref="S5.T4.3.3.3.3.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.3.m1.1b">
             <csymbol cd="latexml" id="S5.T4.3.3.3.3.m1.1.1.cmml" xref="S5.T4.3.3.3.3.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.3.3.3.3.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.3.3.3.3.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.3.3.3.3.2" style="font-size:90%;">
           0.4
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.4.4.4.4">
          <span class="ltx_text" id="S5.T4.4.4.4.4.1" style="font-size:90%;">
           28.9
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.4.4.4.4.m1.1">
           <semantics id="S5.T4.4.4.4.4.m1.1a">
            <mo id="S5.T4.4.4.4.4.m1.1.1" mathsize="90%" xref="S5.T4.4.4.4.4.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.4.m1.1b">
             <csymbol cd="latexml" id="S5.T4.4.4.4.4.m1.1.1.cmml" xref="S5.T4.4.4.4.4.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.4.4.4.4.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.4.4.4.4.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.4.4.4.4.2" style="font-size:90%;">
           2.0
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.5.5.5">
          <span class="ltx_text" id="S5.T4.5.5.5.5.1" style="font-size:90%;">
           32.8
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.5.5.5.5.m1.1">
           <semantics id="S5.T4.5.5.5.5.m1.1a">
            <mo id="S5.T4.5.5.5.5.m1.1.1" mathsize="90%" xref="S5.T4.5.5.5.5.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.5.5.5.5.m1.1b">
             <csymbol cd="latexml" id="S5.T4.5.5.5.5.m1.1.1.cmml" xref="S5.T4.5.5.5.5.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.5.5.5.5.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.5.5.5.5.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.5.5.5.5.2" style="font-size:90%;">
           0
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.5.5.7">
          <span class="ltx_text" id="S5.T4.5.5.5.7.1" style="font-size:90%;">
           1.0
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.5.5.5.8">
          <span class="ltx_text ltx_font_bold" id="S5.T4.5.5.5.8.1" style="font-size:90%;">
           40.6
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.10.10.10">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.10.10.10.6">
          <span class="ltx_text" id="S5.T4.10.10.10.6.1" style="font-size:90%;">
           w/ rationale
          </span>
         </th>
         <td class="ltx_td ltx_align_center" id="S5.T4.6.6.6.1">
          <span class="ltx_text" id="S5.T4.6.6.6.1.1" style="font-size:90%;">
           29.6
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.6.6.6.1.m1.1">
           <semantics id="S5.T4.6.6.6.1.m1.1a">
            <mo id="S5.T4.6.6.6.1.m1.1.1" mathsize="90%" xref="S5.T4.6.6.6.1.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.6.6.6.1.m1.1b">
             <csymbol cd="latexml" id="S5.T4.6.6.6.1.m1.1.1.cmml" xref="S5.T4.6.6.6.1.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.6.6.6.1.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.6.6.6.1.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.6.6.6.1.2" style="font-size:90%;">
           0.6
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.7.7.7.2">
          <span class="ltx_text" id="S5.T4.7.7.7.2.1" style="font-size:90%;">
           34.1
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.7.7.7.2.m1.1">
           <semantics id="S5.T4.7.7.7.2.m1.1a">
            <mo id="S5.T4.7.7.7.2.m1.1.1" mathsize="90%" xref="S5.T4.7.7.7.2.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.7.7.7.2.m1.1b">
             <csymbol cd="latexml" id="S5.T4.7.7.7.2.m1.1.1.cmml" xref="S5.T4.7.7.7.2.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.7.7.7.2.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.7.7.7.2.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.7.7.7.2.2" style="font-size:90%;">
           1.4
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.8.8.8.3">
          <span class="ltx_text" id="S5.T4.8.8.8.3.1" style="font-size:90%;">
           29.8
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.8.8.8.3.m1.1">
           <semantics id="S5.T4.8.8.8.3.m1.1a">
            <mo id="S5.T4.8.8.8.3.m1.1.1" mathsize="90%" xref="S5.T4.8.8.8.3.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.8.8.8.3.m1.1b">
             <csymbol cd="latexml" id="S5.T4.8.8.8.3.m1.1.1.cmml" xref="S5.T4.8.8.8.3.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.8.8.8.3.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.8.8.8.3.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.8.8.8.3.2" style="font-size:90%;">
           0.8
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.9.9.9.4">
          <span class="ltx_text" id="S5.T4.9.9.9.4.1" style="font-size:90%;">
           38.8
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.9.9.9.4.m1.1">
           <semantics id="S5.T4.9.9.9.4.m1.1a">
            <mo id="S5.T4.9.9.9.4.m1.1.1" mathsize="90%" xref="S5.T4.9.9.9.4.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.9.9.9.4.m1.1b">
             <csymbol cd="latexml" id="S5.T4.9.9.9.4.m1.1.1.cmml" xref="S5.T4.9.9.9.4.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.9.9.9.4.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.9.9.9.4.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.9.9.9.4.2" style="font-size:90%;">
           0.2
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.10.10.10.5">
          <span class="ltx_text" id="S5.T4.10.10.10.5.1" style="font-size:90%;">
           42.4
          </span>
          <math alttext="\pm" class="ltx_Math" display="inline" id="S5.T4.10.10.10.5.m1.1">
           <semantics id="S5.T4.10.10.10.5.m1.1a">
            <mo id="S5.T4.10.10.10.5.m1.1.1" mathsize="90%" xref="S5.T4.10.10.10.5.m1.1.1.cmml">
             ±
            </mo>
            <annotation-xml encoding="MathML-Content" id="S5.T4.10.10.10.5.m1.1b">
             <csymbol cd="latexml" id="S5.T4.10.10.10.5.m1.1.1.cmml" xref="S5.T4.10.10.10.5.m1.1.1">
              plus-or-minus
             </csymbol>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.10.10.10.5.m1.1c">
             \pm
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.10.10.10.5.m1.1d">
             ±
            </annotation>
           </semantics>
          </math>
          <span class="ltx_text" id="S5.T4.10.10.10.5.2" style="font-size:90%;">
           0.6
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.10.10.10.7">
          <span class="ltx_text" id="S5.T4.10.10.10.7.1" style="font-size:90%;">
           1.5
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S5.T4.10.10.10.8">
          <span class="ltx_text ltx_font_bold" id="S5.T4.10.10.10.8.1" style="font-size:90%;">
           45.1
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S5.T4.11.11.11">
         <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T4.11.11.11.1">
          <math alttext="\Delta" class="ltx_Math" display="inline" id="S5.T4.11.11.11.1.m1.1">
           <semantics id="S5.T4.11.11.11.1.m1.1a">
            <mi id="S5.T4.11.11.11.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S5.T4.11.11.11.1.m1.1.1.cmml">
             Δ
            </mi>
            <annotation-xml encoding="MathML-Content" id="S5.T4.11.11.11.1.m1.1b">
             <ci id="S5.T4.11.11.11.1.m1.1.1.cmml" xref="S5.T4.11.11.11.1.m1.1.1">
              Δ
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S5.T4.11.11.11.1.m1.1c">
             \Delta
            </annotation>
            <annotation encoding="application/x-llamapun" id="S5.T4.11.11.11.1.m1.1d">
             roman_Δ
            </annotation>
           </semantics>
          </math>
         </th>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.11.11.11.2">
          <span class="ltx_text" id="S5.T4.11.11.11.2.1" style="font-size:90%;">
           +9.4 (46.5%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.11.11.11.3">
          <span class="ltx_text" id="S5.T4.11.11.11.3.1" style="font-size:90%;">
           +9.0 (35.8%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.11.11.11.4">
          <span class="ltx_text ltx_font_bold" id="S5.T4.11.11.11.4.1" style="font-size:90%;">
           +10.1 (51.3%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.11.11.11.5">
          <span class="ltx_text" id="S5.T4.11.11.11.5.1" style="font-size:90%;">
           +9.9 (34.1%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.11.11.11.6">
          <span class="ltx_text" id="S5.T4.11.11.11.6.1" style="font-size:90%;">
           +9.6 (29.3%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.11.11.11.7">
          <span class="ltx_text" id="S5.T4.11.11.11.7.1" style="font-size:90%;">
           +0.5 (60%)
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.11.11.11.8">
          <span class="ltx_text" id="S5.T4.11.11.11.8.1" style="font-size:90%;">
           +5 (12.3%)
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
   </figure>
   <section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Results and Analysis
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">
      The experimental results are presented in
      <a class="ltx_ref" href="#S5.T4" title="Table 4 ‣ 5.2 Conversational Question Answering ‣ 5 Experiment ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      . Our observations can be categorized into three main aspects. Firstly, the importance of pragmatic meaning is evident. As shown in
      <a class="ltx_ref" href="#S5.T5" title="Table 5 ‣ 5.3 Zero-Shot Natural Language Inference ‣ 5 Experiment ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      , there exists a notable disparity between the results of models that have access to human-annotated answers and those that do not. On average, the model performances improve by 38.47% after the introduction of human-annotated rationales. Even the lowest-performing model in the initial experiment, mT5-small, demonstrates a 9.4% increase in accuracy. The substantial discrepancy in results between the two configurations underscores the significance of elucidating intended meanings in the development of effective communicators. Second, the models display deficiencies in applying pragmatic reasoning. Our questions are designed to demand a deeper understanding of conversations, however, the models struggle to perform well on our task. The best-performing model, ChatGPT, achieves an accuracy score of 40.6%. It is worth noting that our questions are generated by ChatGPT itself, and our source dataset, Interview, was proposed prior to the emergence of ChatGPT, which means that ChatGPT may have encountered our text during training. These characteristics render its result unsatisfactory. Third, generalization across different types of pragmatic reasoning poses challenges. In this analysis, we focus exclusively on models other than ChatGPT due to the lack of clarity regarding its training process. As demonstrated in
      <a class="ltx_ref" href="#S5.T5" title="Table 5 ‣ 5.3 Zero-Shot Natural Language Inference ‣ 5 Experiment ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      , these models showcase a substantial improvement in performance following the inclusion of human-annotated rationale. The extent of this improvement exhibits slight fluctuations among the various models, suggesting a shared obstacle that hinders their overall performance. Noticed that the models are fine-tuned on a training set using a training set that is 5.2 times larger than the test set, thus we can conclude that achieving effective generalization from one pragmatic reasoning process to another remains a formidable and challenging task.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Zero-Shot Natural Language Inference
   </h3>
   <div class="ltx_para" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     The natural language inference task
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       MacCartney and Manning
      </span>
      (
      <a class="ltx_ref" href="#bib.bib57" title="">
       <span class="ltx_text" style="font-size:90%;">
        2008
       </span>
      </a>
      )
     </cite>
     evaluates the model’s comprehension of language. It involves providing two sentences: a premise and a hypothesis, and models are required to determine the relationship between the two sentences, which can be entailment, contradiction, or neutral. As there are no negative samples in our dataset, we simplify the task by asking the model to judge only whether there is entailment. . In this task, models are presented with a dialogue, a turn of the dialogue, and an intended meaning, they need to judge whether the turn entails the intended meaning. Noticed that collected data as described in
     <a class="ltx_ref" href="#S3.SS1" title="3.1 Data Source Construction ‣ 3 The DiPlomat Dataset ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Sec.
      </span>
      <span class="ltx_text ltx_ref_tag">
       3.1
      </span>
     </a>
     consists of reasons and implied meanings, to better fit our task, we abandon the reasons and preserve the implied meanings; refer to Appendix
     <span class="ltx_text" id="S5.SS3.p1.1.1" style="color:#FF0000;">
      X
     </span>
     . Models are tested under zero-shot setting, which means that they are not allowed to train on any data before testing. Thus the innate abilities of models play a decisive role.
    </p>
   </div>
   <div class="ltx_para" id="S5.SS3.p2">
    <p class="ltx_p" id="S5.SS3.p2.1">
     Baseline models include T5
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Raffel et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib54" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     , DeBERTa
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       He et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib58" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      )
     </cite>
     , and ChatGPT.
It’s important to note that ChatGPT and the other two models are tested on different settings. ChatGPT is tested with the whole dialogue and the implied meaning as a prompt. However, to inspect the significance of context, the other two models are only provided with the pragmatic turn and the corresponding pragmatic meaning. ChatGPT is evaluated using two types of prompts: with and without step-by-step instructions. “
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p2.1.1">
      Let’s think step by step
     </span>
     ” is a prompt discovered
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Kojima et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib59" title="">
       <span class="ltx_text" style="font-size:90%;">
        2023
       </span>
      </a>
      )
     </cite>
     to improve the model’s reasoning ability.
    </p>
   </div>
   <figure class="ltx_table ltx_align_floatright" id="S5.T5">
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_table">
      Table 5:
     </span>
     Results of Natural Language Inference Task.
     <math alttext="{}^{\diamond}" class="ltx_Math" display="inline" id="S5.T5.3.m1.1">
      <semantics id="S5.T5.3.m1.1b">
       <msup id="S5.T5.3.m1.1.1" xref="S5.T5.3.m1.1.1.cmml">
        <mi id="S5.T5.3.m1.1.1b" xref="S5.T5.3.m1.1.1.cmml">
        </mi>
        <mo id="S5.T5.3.m1.1.1.1" xref="S5.T5.3.m1.1.1.1.cmml">
         ⋄
        </mo>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S5.T5.3.m1.1c">
        <apply id="S5.T5.3.m1.1.1.cmml" xref="S5.T5.3.m1.1.1">
         <ci id="S5.T5.3.m1.1.1.1.cmml" xref="S5.T5.3.m1.1.1.1">
          ⋄
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.T5.3.m1.1d">
        {}^{\diamond}
       </annotation>
       <annotation encoding="application/x-llamapun" id="S5.T5.3.m1.1e">
        start_FLOATSUPERSCRIPT ⋄ end_FLOATSUPERSCRIPT
       </annotation>
      </semantics>
     </math>
     : T5-XXL fine-tuned on true NLI mixure
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Honovich et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib60" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     .
     <math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="S5.T5.4.m2.1">
      <semantics id="S5.T5.4.m2.1b">
       <msup id="S5.T5.4.m2.1.1" xref="S5.T5.4.m2.1.1.cmml">
        <mi id="S5.T5.4.m2.1.1b" xref="S5.T5.4.m2.1.1.cmml">
        </mi>
        <mo id="S5.T5.4.m2.1.1.1" xref="S5.T5.4.m2.1.1.1.cmml">
         †
        </mo>
       </msup>
       <annotation-xml encoding="MathML-Content" id="S5.T5.4.m2.1c">
        <apply id="S5.T5.4.m2.1.1.cmml" xref="S5.T5.4.m2.1.1">
         <ci id="S5.T5.4.m2.1.1.1.cmml" xref="S5.T5.4.m2.1.1.1">
          †
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.T5.4.m2.1d">
        {}^{\dagger}
       </annotation>
       <annotation encoding="application/x-llamapun" id="S5.T5.4.m2.1e">
        start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT
       </annotation>
      </semantics>
     </math>
     : DeBERTa-v3 trained on MNLI
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Williams et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib23" title="">
       <span class="ltx_text" style="font-size:90%;">
        2018
       </span>
      </a>
      )
     </cite>
     and SNLI
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Bowman et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib61" title="">
       <span class="ltx_text" style="font-size:90%;">
        2015
       </span>
      </a>
      )
     </cite>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.6">
     <thead class="ltx_thead">
      <tr class="ltx_tr" id="S5.T5.6.3.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T5.6.3.1.1">
        <span class="ltx_text ltx_font_bold" id="S5.T5.6.3.1.1.1" style="font-size:90%;">
         Method
        </span>
       </th>
       <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.6.3.1.2">
        <span class="ltx_text ltx_font_bold" id="S5.T5.6.3.1.2.1" style="font-size:90%;">
         Acc.
        </span>
       </th>
      </tr>
     </thead>
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T5.6.4.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.6.4.1.1">
        <span class="ltx_text" id="S5.T5.6.4.1.1.1" style="font-size:90%;">
         Random
        </span>
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.6.4.1.2">
        <span class="ltx_text" id="S5.T5.6.4.1.2.1" style="font-size:90%;">
         50.0
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.5.1">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.5.1.1">
        <span class="ltx_text" id="S5.T5.5.1.1.1" style="font-size:90%;">
         DeBERTa-Large
        </span>
        <math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="S5.T5.5.1.1.m1.1">
         <semantics id="S5.T5.5.1.1.m1.1a">
          <msup id="S5.T5.5.1.1.m1.1.1" xref="S5.T5.5.1.1.m1.1.1.cmml">
           <mi id="S5.T5.5.1.1.m1.1.1a" xref="S5.T5.5.1.1.m1.1.1.cmml">
           </mi>
           <mo id="S5.T5.5.1.1.m1.1.1.1" mathsize="90%" xref="S5.T5.5.1.1.m1.1.1.1.cmml">
            †
           </mo>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S5.T5.5.1.1.m1.1b">
           <apply id="S5.T5.5.1.1.m1.1.1.cmml" xref="S5.T5.5.1.1.m1.1.1">
            <ci id="S5.T5.5.1.1.m1.1.1.1.cmml" xref="S5.T5.5.1.1.m1.1.1.1">
             †
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.5.1.1.m1.1c">
           {}^{\dagger}
          </annotation>
          <annotation encoding="application/x-llamapun" id="S5.T5.5.1.1.m1.1d">
           start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT
          </annotation>
         </semantics>
        </math>
       </th>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.5.1.2">
        <span class="ltx_text" id="S5.T5.5.1.2.1" style="font-size:90%;">
         44.3
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.6.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.6.2.1">
        <span class="ltx_text" id="S5.T5.6.2.1.1" style="font-size:90%;">
         T5-XXL
        </span>
        <math alttext="{}^{\diamond}" class="ltx_Math" display="inline" id="S5.T5.6.2.1.m1.1">
         <semantics id="S5.T5.6.2.1.m1.1a">
          <msup id="S5.T5.6.2.1.m1.1.1" xref="S5.T5.6.2.1.m1.1.1.cmml">
           <mi id="S5.T5.6.2.1.m1.1.1a" xref="S5.T5.6.2.1.m1.1.1.cmml">
           </mi>
           <mo id="S5.T5.6.2.1.m1.1.1.1" mathsize="90%" xref="S5.T5.6.2.1.m1.1.1.1.cmml">
            ⋄
           </mo>
          </msup>
          <annotation-xml encoding="MathML-Content" id="S5.T5.6.2.1.m1.1b">
           <apply id="S5.T5.6.2.1.m1.1.1.cmml" xref="S5.T5.6.2.1.m1.1.1">
            <ci id="S5.T5.6.2.1.m1.1.1.1.cmml" xref="S5.T5.6.2.1.m1.1.1.1">
             ⋄
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S5.T5.6.2.1.m1.1c">
           {}^{\diamond}
          </annotation>
          <annotation encoding="application/x-llamapun" id="S5.T5.6.2.1.m1.1d">
           start_FLOATSUPERSCRIPT ⋄ end_FLOATSUPERSCRIPT
          </annotation>
         </semantics>
        </math>
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T5.6.2.2">
        <span class="ltx_text" id="S5.T5.6.2.2.1" style="font-size:90%;">
         45.3
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.6.5.2">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.6.5.2.1">
        <span class="ltx_text" id="S5.T5.6.5.2.1.1" style="font-size:90%;">
         ChatGPT
        </span>
       </th>
       <td class="ltx_td ltx_align_center" id="S5.T5.6.5.2.2">
        <span class="ltx_text ltx_font_bold" id="S5.T5.6.5.2.2.1" style="font-size:90%;">
         85.7
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S5.T5.6.6.3">
       <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T5.6.6.3.1">
        <span class="ltx_text" id="S5.T5.6.6.3.1.1" style="font-size:90%;">
         ChatGPT w/ CoT
        </span>
       </th>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.6.6.3.2">
        <span class="ltx_text" id="S5.T5.6.6.3.2.1" style="font-size:90%;">
         63.8
        </span>
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <section class="ltx_paragraph" id="S5.SS3.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Results and Analysis
    </h4>
    <div class="ltx_para" id="S5.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S5.SS3.SSS0.Px1.p1.1">
      Results are listed in
      <a class="ltx_ref" href="#S5.T5" title="Table 5 ‣ 5.3 Zero-Shot Natural Language Inference ‣ 5 Experiment ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      . As this task shares similar settings as binary classification, randomized answer accuracy is expected to be 50%. We observe below randomized performance on some previous SOTA models. Note that, each of the data is annotated by two humans, thus it’s reasonable to view human performance as 100%.
ChatGPT achieves the highest result but still shows a huge gap compared with human annotations.
The outcomes highlight the imperfectness of the models’ reasoning abilities.
For T5-large and DeBERTa, context is blinded, but for ChatGPT, it is reachable. Hence, the performance gap among T5-large, DeBERTa, and ChatGPT shows the importance of context in our task. Interestingly, COT doesn’t offer help to ChatGPT but is harmful to ChatGPT’s performance.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Discussions and Future Work
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this paper, we propose
    <span class="ltx_text ltx_font_bold" id="S6.p1.1.1">
     DiPlomat
    </span>
    , a high-quality manually annotated multi-turn dataset of pragmatic reasoning in conversations. Along with the dataset, we propose two tasks and baselines. Comparing experimental results, we emphasize the nonnegligible impact of contexts and reasoning on building perfect communicators. We also highlight the importance of pragmatic awareness and its bottleneck effect on our tasks. There is still a large gap between current performances and qualified performances.
   </p>
  </div>
  <div class="ltx_para" id="S6.p2">
   <p class="ltx_p" id="S6.p2.3">
    <span class="ltx_text ltx_font_bold" id="S6.p2.3.3">
     Memorization
     <em class="ltx_emph ltx_font_italic" id="S6.p2.3.3.1">
      vs
     </em>
     .
     <span class="ltx_text" id="S6.p2.3.3.2">
     </span>
     Reasoning
    </span>
    Noticed that models exhibit outstanding performance on
    <span class="ltx_text ltx_font_bold" id="S6.p2.1.1">
     CP
     <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S6.p2.1.1.m1.1">
      <semantics id="S6.p2.1.1.m1.1a">
       <mo id="S6.p2.1.1.m1.1.1" mathvariant="normal" stretchy="false" xref="S6.p2.1.1.m1.1.1.cmml">
        →
       </mo>
       <annotation-xml encoding="MathML-Content" id="S6.p2.1.1.m1.1b">
        <ci id="S6.p2.1.1.m1.1.1.cmml" xref="S6.p2.1.1.m1.1.1">
         normal-→
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.p2.1.1.m1.1c">
        \rightarrow
       </annotation>
       <annotation encoding="application/x-llamapun" id="S6.p2.1.1.m1.1d">
        →
       </annotation>
      </semantics>
     </math>
     R
    </span>
    of
    <a class="ltx_ref" href="#S5.SS1" title="5.1 Pragmatics Identification and Reasoning ‣ 5 Experiment ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Sec.
     </span>
     <span class="ltx_text ltx_ref_tag">
      5.1
     </span>
    </a>
    . On the contrary, for
    <span class="ltx_text ltx_font_bold" id="S6.p2.2.2">
     C
     <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S6.p2.2.2.m1.1">
      <semantics id="S6.p2.2.2.m1.1a">
       <mo id="S6.p2.2.2.m1.1.1" mathvariant="normal" stretchy="false" xref="S6.p2.2.2.m1.1.1.cmml">
        →
       </mo>
       <annotation-xml encoding="MathML-Content" id="S6.p2.2.2.m1.1b">
        <ci id="S6.p2.2.2.m1.1.1.cmml" xref="S6.p2.2.2.m1.1.1">
         normal-→
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.p2.2.2.m1.1c">
        \rightarrow
       </annotation>
       <annotation encoding="application/x-llamapun" id="S6.p2.2.2.m1.1d">
        →
       </annotation>
      </semantics>
     </math>
     PR
    </span>
    , models achieve poor results. Since the underlying knowledge is consistent for both tasks, the disparity in performance is hypothesized to be attributed to
    <math alttext="memorization" class="ltx_Math" display="inline" id="S6.p2.3.m1.1">
     <semantics id="S6.p2.3.m1.1a">
      <mrow id="S6.p2.3.m1.1.1" xref="S6.p2.3.m1.1.1.cmml">
       <mi id="S6.p2.3.m1.1.1.2" xref="S6.p2.3.m1.1.1.2.cmml">
        m
       </mi>
       <mo id="S6.p2.3.m1.1.1.1" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.3" xref="S6.p2.3.m1.1.1.3.cmml">
        e
       </mi>
       <mo id="S6.p2.3.m1.1.1.1a" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.4" xref="S6.p2.3.m1.1.1.4.cmml">
        m
       </mi>
       <mo id="S6.p2.3.m1.1.1.1b" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.5" xref="S6.p2.3.m1.1.1.5.cmml">
        o
       </mi>
       <mo id="S6.p2.3.m1.1.1.1c" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.6" xref="S6.p2.3.m1.1.1.6.cmml">
        r
       </mi>
       <mo id="S6.p2.3.m1.1.1.1d" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.7" xref="S6.p2.3.m1.1.1.7.cmml">
        i
       </mi>
       <mo id="S6.p2.3.m1.1.1.1e" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.8" xref="S6.p2.3.m1.1.1.8.cmml">
        z
       </mi>
       <mo id="S6.p2.3.m1.1.1.1f" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.9" xref="S6.p2.3.m1.1.1.9.cmml">
        a
       </mi>
       <mo id="S6.p2.3.m1.1.1.1g" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.10" xref="S6.p2.3.m1.1.1.10.cmml">
        t
       </mi>
       <mo id="S6.p2.3.m1.1.1.1h" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.11" xref="S6.p2.3.m1.1.1.11.cmml">
        i
       </mi>
       <mo id="S6.p2.3.m1.1.1.1i" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.12" xref="S6.p2.3.m1.1.1.12.cmml">
        o
       </mi>
       <mo id="S6.p2.3.m1.1.1.1j" xref="S6.p2.3.m1.1.1.1.cmml">
        ⁢
       </mo>
       <mi id="S6.p2.3.m1.1.1.13" xref="S6.p2.3.m1.1.1.13.cmml">
        n
       </mi>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S6.p2.3.m1.1b">
       <apply id="S6.p2.3.m1.1.1.cmml" xref="S6.p2.3.m1.1.1">
        <times id="S6.p2.3.m1.1.1.1.cmml" xref="S6.p2.3.m1.1.1.1">
        </times>
        <ci id="S6.p2.3.m1.1.1.2.cmml" xref="S6.p2.3.m1.1.1.2">
         𝑚
        </ci>
        <ci id="S6.p2.3.m1.1.1.3.cmml" xref="S6.p2.3.m1.1.1.3">
         𝑒
        </ci>
        <ci id="S6.p2.3.m1.1.1.4.cmml" xref="S6.p2.3.m1.1.1.4">
         𝑚
        </ci>
        <ci id="S6.p2.3.m1.1.1.5.cmml" xref="S6.p2.3.m1.1.1.5">
         𝑜
        </ci>
        <ci id="S6.p2.3.m1.1.1.6.cmml" xref="S6.p2.3.m1.1.1.6">
         𝑟
        </ci>
        <ci id="S6.p2.3.m1.1.1.7.cmml" xref="S6.p2.3.m1.1.1.7">
         𝑖
        </ci>
        <ci id="S6.p2.3.m1.1.1.8.cmml" xref="S6.p2.3.m1.1.1.8">
         𝑧
        </ci>
        <ci id="S6.p2.3.m1.1.1.9.cmml" xref="S6.p2.3.m1.1.1.9">
         𝑎
        </ci>
        <ci id="S6.p2.3.m1.1.1.10.cmml" xref="S6.p2.3.m1.1.1.10">
         𝑡
        </ci>
        <ci id="S6.p2.3.m1.1.1.11.cmml" xref="S6.p2.3.m1.1.1.11">
         𝑖
        </ci>
        <ci id="S6.p2.3.m1.1.1.12.cmml" xref="S6.p2.3.m1.1.1.12">
         𝑜
        </ci>
        <ci id="S6.p2.3.m1.1.1.13.cmml" xref="S6.p2.3.m1.1.1.13">
         𝑛
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S6.p2.3.m1.1c">
       memorization
      </annotation>
      <annotation encoding="application/x-llamapun" id="S6.p2.3.m1.1d">
       italic_m italic_e italic_m italic_o italic_r italic_i italic_z italic_a italic_t italic_i italic_o italic_n
      </annotation>
     </semantics>
    </math>
    . Instead of truly understanding the knowledge, the models tend to memorize patterns.
   </p>
  </div>
  <div class="ltx_para" id="S6.p3">
   <p class="ltx_p" id="S6.p3.1">
    <span class="ltx_text ltx_font_bold" id="S6.p3.1.1">
     Subjectiveness
     <em class="ltx_emph ltx_font_italic" id="S6.p3.1.1.1">
      vs
     </em>
     .
     <span class="ltx_text" id="S6.p3.1.1.2">
     </span>
     Objectiveness
    </span>
    <cite class="ltx_cite ltx_citemacro_citet">
     <span class="ltx_text" style="font-size:90%;">
      Ji et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib62" title="">
      <span class="ltx_text" style="font-size:90%;">
       2022
      </span>
     </a>
     )
    </cite>
    emphasize the importance of modeling a distribution that encompasses a diverse range of possibilities, rather than solely relying on a single “best” prediction.
During the annotation process, we observe a phenomenon that different workers hold diverse opinions regarding pragmatic turns and their intended meanings. Their annotations often exhibit significant variations, sometimes even presenting completely opposing interpretations. We maintain the possibility of subjectiveness with careful task metric design (
    <a class="ltx_ref" href="#S4.SS1" title="4.1 Task 1: Pragmatics Identification and Reasoning (PIR) ‣ 4 Task Definition ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Sec.
     </span>
     <span class="ltx_text ltx_ref_tag">
      4.1
     </span>
    </a>
    ).
   </p>
  </div>
  <div class="ltx_para" id="S6.p4">
   <p class="ltx_p" id="S6.p4.1">
    <span class="ltx_text ltx_font_bold" id="S6.p4.1.1">
     Future Work
    </span>
    Achieving generalization across multiple types of pragmatic reasoning processes poses significant challenges. Consequently, we propose that the construction of a proficient communicator necessitates the incorporation of methods beyond purely data-driven approaches. Furthermore, the availability of comprehensive evaluation data is of utmost importance. As a result, we target more high-quality datasets and new methods other than data-driven for the problem.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib1.5.5.1" style="font-size:90%;">
      Ambrasat et al. [2014]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib1.7.1" style="font-size:90%;">
      Jens Ambrasat, Christian von Scheve, Markus Conrad, Gesche Schauenburg, and
Tobias Schröder.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib1.8.1" style="font-size:90%;">
      Consensus and stratification in the affective meaning of human
sociality.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.9.1" style="font-size:90%;">
      Proceedings of the National Academy of Sciences
     </em>
     <span class="ltx_text" id="bib.bib1.10.2" style="font-size:90%;">
      , 111(22):8001–8006, 2014.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib2.4.4.1" style="font-size:90%;">
      Fiske [1992]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib2.6.1" style="font-size:90%;">
      Alan P Fiske.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib2.7.1" style="font-size:90%;">
      The four elementary forms of sociality: framework for a unified
theory of social relations.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.8.1" style="font-size:90%;">
      Psychological review
     </em>
     <span class="ltx_text" id="bib.bib2.9.2" style="font-size:90%;">
      , 99(4):689, 1992.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib3.4.4.1" style="font-size:90%;">
      Bargh and Chartrand [1999]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib3.6.1" style="font-size:90%;">
      John A Bargh and Tanya L Chartrand.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib3.7.1" style="font-size:90%;">
      The unbearable automaticity of being.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.8.1" style="font-size:90%;">
      American psychologist
     </em>
     <span class="ltx_text" id="bib.bib3.9.2" style="font-size:90%;">
      , 54(7):462, 1999.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib4.4.4.1" style="font-size:90%;">
      Finegan [2014]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.6.1" style="font-size:90%;">
      Edward Finegan.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.7.1" style="font-size:90%;">
      Language: Its structure and use
     </em>
     <span class="ltx_text" id="bib.bib4.8.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib4.9.1" style="font-size:90%;">
      Cengage Learning, 2014.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib5.4.4.1" style="font-size:90%;">
      [5]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib5.6.1" style="font-size:90%;">
      Meta Fundamental AI Research Diplomacy Team (FAIR)†, Anton Bakhtin, Noam
Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew
Goff, Jonathan Gray, Hengyuan Hu, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib5.7.1" style="font-size:90%;">
      Human-level play in the game of diplomacy by combining language
models with strategic reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.8.1" style="font-size:90%;">
      Science
     </em>
     <span class="ltx_text" id="bib.bib5.9.2" style="font-size:90%;">
      , 378(6624):1067–1074, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">
      Anders et al. [2016]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib6.7.1" style="font-size:90%;">
      Silke Anders, Roos de Jong, Christian Beck, John-Dylan Haynes, and Thomas
Ethofer.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib6.8.1" style="font-size:90%;">
      A neural link between affective understanding and interpersonal
attraction.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.9.1" style="font-size:90%;">
      Proceedings of the National Academy of Sciences
     </em>
     <span class="ltx_text" id="bib.bib6.10.2" style="font-size:90%;">
      , 113(16):E2248–E2257, 2016.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib7.5.5.1" style="font-size:90%;">
      Ouyang et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib7.7.1" style="font-size:90%;">
      Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib7.8.1" style="font-size:90%;">
      Training language models to follow instructions with human feedback.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.9.1" style="font-size:90%;">
      Advances in Neural Information Processing Systems
     </em>
     <span class="ltx_text" id="bib.bib7.10.2" style="font-size:90%;">
      ,
35:27730–27744, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib8.5.5.1" style="font-size:90%;">
      Brown et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.7.1" style="font-size:90%;">
      Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,
Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
Ilya Sutskever, and Dario Amodei.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.8.1" style="font-size:90%;">
      Language models are few-shot learners.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib8.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.10.2" style="font-size:90%;">
      Advances in Neural Information Processing Systems
(NeurIPS)
     </em>
     <span class="ltx_text" id="bib.bib8.11.3" style="font-size:90%;">
      , 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib9.5.5.1" style="font-size:90%;">
      Wei et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.7.1" style="font-size:90%;">
      Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and
Denny Zhou.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib9.8.1" style="font-size:90%;">
      Chain of thought prompting elicits reasoning in large language
models.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2201.11903
     </em>
     <span class="ltx_text" id="bib.bib9.10.2" style="font-size:90%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib10.5.5.1" style="font-size:90%;">
      Ruis et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.7.1" style="font-size:90%;">
      Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rocktäschel, and
Edward Grefenstette.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib10.8.1" style="font-size:90%;">
      Large language models are not zero-shot communicators, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib11.5.5.1" style="font-size:90%;">
      Liu et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib11.7.1" style="font-size:90%;">
      Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander
Koller, Swabha Swayamdipta, Noah A. Smith, and Yejin Choi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib11.8.1" style="font-size:90%;">
      We’re afraid language models aren’t modeling ambiguity, 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib12.5.5.1" style="font-size:90%;">
      Zheng et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">
      Zilong Zheng, Shuwen Qiu, Lifeng Fan, Yixin Zhu, and Song-Chun Zhu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.8.1" style="font-size:90%;">
      GRICE: A grammar-based dataset for recovering implicature and
conversational rEasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib12.11.3" style="font-size:90%;">
      , pages 2074–2085, Online, August 2021. Association for
Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.12.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.18653/v1/2021.findings-acl.182" style="font-size:90%;" title="">
      10.18653/v1/2021.findings-acl.182
     </a>
     <span class="ltx_text" id="bib.bib12.13.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib12.14.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.findings-acl.182" style="font-size:90%;" title="">
      https://aclanthology.org/2021.findings-acl.182
     </a>
     <span class="ltx_text" id="bib.bib12.15.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib13.4.4.1" style="font-size:90%;">
      OpenAI [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib13.6.1" style="font-size:90%;">
      OpenAI.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib13.7.1" style="font-size:90%;">
      Gpt-4 technical report, 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib14.5.5.1" style="font-size:90%;">
      Glaese et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib14.7.1" style="font-size:90%;">
      Amelia Glaese, Nat McAleese, Maja Trębacz, John Aslanides, Vlad Firoiu,
Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker,
et al.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib14.8.1" style="font-size:90%;">
      Improving alignment of dialogue agents via targeted human judgements.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.9.1" style="font-size:90%;">
      arXiv preprint arXiv:2209.14375
     </em>
     <span class="ltx_text" id="bib.bib14.10.2" style="font-size:90%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib15.5.5.1" style="font-size:90%;">
      Chakrabarty et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.7.1" style="font-size:90%;">
      Tuhin Chakrabarty, Xurui Zhang, Smaranda Muresan, and Nanyun Peng.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.8.1" style="font-size:90%;">
      Mermaid: Metaphor generation with symbolism and discriminative
decoding.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib15.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib15.11.3" style="font-size:90%;">
      , 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib16.4.4.1" style="font-size:90%;">
      Saxena and Paul [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.6.1" style="font-size:90%;">
      Prateek Saxena and Soma Paul.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">
      Epie dataset: A corpus for possible idiomatic expressions.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib16.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.9.2" style="font-size:90%;">
      Text, Speech, and Dialogue - 23rd International Conference,
TSD 2020, Brno, Czech Republic, September 8-11, 2020, Proceedings
     </em>
     <span class="ltx_text" id="bib.bib16.10.3" style="font-size:90%;">
      , 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib17.5.5.1" style="font-size:90%;">
      Adewumi et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.7.1" style="font-size:90%;">
      Tosin P. Adewumi, Roshanak Vadoodi, Aparajita Tripathy, Konstantina Nikolaidou,
Foteini Liwicki, and Marcus Liwicki.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.8.1" style="font-size:90%;">
      Potential idiomatic expression (pie)-english: Corpus for classes of
idioms.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib17.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.10.2" style="font-size:90%;">
      Proceedings of the Thirteenth Language Resources and
Evaluation Conference
     </em>
     <span class="ltx_text" id="bib.bib17.11.3" style="font-size:90%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib18.4.4.1" style="font-size:90%;">
      Annamoradnejad and Zoghi [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.6.1" style="font-size:90%;">
      Issa Annamoradnejad and Gohar Zoghi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib18.7.1" style="font-size:90%;">
      Colbert: Using bert sentence embedding in parallel neural networks
for computational humor, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib19.5.5.1" style="font-size:90%;">
      Majumder et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.7.1" style="font-size:90%;">
      Bodhisattwa Prasad Majumder, Shuyang Li, Jianmo Ni, and Julian McAuley.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.8.1" style="font-size:90%;">
      Interview: Large-scale modeling of media dialog with discourse
patterns and knowledge grounding.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.10.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib19.11.3" style="font-size:90%;">
      , pages 8129–8141, Online, November 2020. Association for
Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.12.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.18653/v1/2020.emnlp-main.653" style="font-size:90%;" title="">
      10.18653/v1/2020.emnlp-main.653
     </a>
     <span class="ltx_text" id="bib.bib19.13.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib19.14.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.emnlp-main.653" style="font-size:90%;" title="">
      https://aclanthology.org/2020.emnlp-main.653
     </a>
     <span class="ltx_text" id="bib.bib19.15.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib20.5.5.1" style="font-size:90%;">
      Lowe et al. [2015]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">
      Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle Pineau.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.8.1" style="font-size:90%;">
      The Ubuntu dialogue corpus: A large dataset for research in
unstructured multi-turn dialogue systems.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.10.2" style="font-size:90%;">
      Proceedings of the 16th Annual Meeting of the Special
Interest Group on Discourse and Dialogue
     </em>
     <span class="ltx_text" id="bib.bib20.11.3" style="font-size:90%;">
      , pages 285–294, Prague, Czech
Republic, September 2015. Association for Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.12.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.18653/v1/W15-4640" style="font-size:90%;" title="">
      10.18653/v1/W15-4640
     </a>
     <span class="ltx_text" id="bib.bib20.13.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib20.14.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W15-4640" style="font-size:90%;" title="">
      https://aclanthology.org/W15-4640
     </a>
     <span class="ltx_text" id="bib.bib20.15.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib21.5.5.1" style="font-size:90%;">
      Lai et al. [2017]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.7.1" style="font-size:90%;">
      Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.8.1" style="font-size:90%;">
      Race: Large-scale reading comprehension dataset from examinations.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib21.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.10.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib21.11.3" style="font-size:90%;">
      , 2017.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib22.5.5.1" style="font-size:90%;">
      Clark et al. [2018]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib22.7.1" style="font-size:90%;">
      Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa
     </span>
     <span class="ltx_text" id="bib.bib22.8.2" style="font-size:90%;">
      Schoenick, and Oyvind Tafjord.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib22.9.1" style="font-size:90%;">
      Think you have solved question answering? try arc, the ai2 reasoning
challenge, 2018.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib23.5.5.1" style="font-size:90%;">
      Williams et al. [2018]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib23.7.1" style="font-size:90%;">
      Adina Williams, Nikita Nangia, and Samuel R. Bowman.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib23.8.1" style="font-size:90%;">
      A broad-coverage challenge corpus for sentence understanding through
inference.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib23.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.10.2" style="font-size:90%;">
      North American Chapter of the Association for Computational
Linguistics: Human Language Technologies (NAACL-HLT)
     </em>
     <span class="ltx_text" id="bib.bib23.11.3" style="font-size:90%;">
      , 2018.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">
      Zhang et al. [2018]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.7.1" style="font-size:90%;">
      Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason
Weston.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.8.1" style="font-size:90%;">
      Personalizing dialogue agents: I have a dog, do you have pets too?
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib24.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib24.11.3" style="font-size:90%;">
      , 2018.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">
      Zellers et al. [2018]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.7.1" style="font-size:90%;">
      Rowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin Choi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.8.1" style="font-size:90%;">
      Swag: A large-scale adversarial dataset for grounded commonsense
inference.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib25.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.10.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib25.11.3" style="font-size:90%;">
      , 2018.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">
      Huang et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib26.7.1" style="font-size:90%;">
      Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib26.8.1" style="font-size:90%;">
      Cosmos qa: Machine reading comprehension with contextual commonsense
reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib26.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.10.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib26.11.3" style="font-size:90%;">
      , 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib27.5.5.1" style="font-size:90%;">
      Reddy et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.7.1" style="font-size:90%;">
      Siva Reddy, Danqi Chen, and Christopher D. Manning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.8.1" style="font-size:90%;">
      Coqa: A conversational question answering challenge.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib27.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.10.2" style="font-size:90%;">
      Transactions of the Association for Computational
Linguistics (TACL)
     </em>
     <span class="ltx_text" id="bib.bib27.11.3" style="font-size:90%;">
      , 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib28.5.5.1" style="font-size:90%;">
      Sun et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">
      Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, and Claire Cardie.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib28.8.1" style="font-size:90%;">
      Dream: A challenge dataset and models for dialogue-based reading
comprehension.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib28.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.10.2" style="font-size:90%;">
      Transactions of the Association for Computational
Linguistics (TACL)
     </em>
     <span class="ltx_text" id="bib.bib28.11.3" style="font-size:90%;">
      , 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib29.5.5.1" style="font-size:90%;">
      Welleck et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.7.1" style="font-size:90%;">
     </span>
     <span class="ltx_text" id="bib.bib29.8.2" style="font-size:90%;">
      Sean Welleck, Jason Weston, Arthur Szlam, and Kyunghyun Cho.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.9.1" style="font-size:90%;">
      Dialogue natural language inference.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib29.10.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.11.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib29.12.3" style="font-size:90%;">
      , 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib30.5.5.1" style="font-size:90%;">
      Dua et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib30.7.1" style="font-size:90%;">
      Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and
Matt Gardner.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib30.8.1" style="font-size:90%;">
      Drop: A reading comprehension benchmark requiring discrete reasoning
over paragraphs.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib30.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.10.2" style="font-size:90%;">
      North American Chapter of the Association for Computational
Linguistics: Human Language Technologies (NAACL-HLT)
     </em>
     <span class="ltx_text" id="bib.bib30.11.3" style="font-size:90%;">
      , 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib31.5.5.1" style="font-size:90%;">
      Cui et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.7.1" style="font-size:90%;">
      Leyang Cui, Yu Wu, Shujie Liu, Yue Zhang, and Ming Zhou.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.8.1" style="font-size:90%;">
      Mutual: A dataset for multi-turn dialogue reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib31.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib31.11.3" style="font-size:90%;">
      , 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib32.5.5.1" style="font-size:90%;">
      Jeretic et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.7.1" style="font-size:90%;">
      Paloma Jeretic, Alex Warstadt, Suvrat Bhooshan, and Adina Williams.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.8.1" style="font-size:90%;">
      Are natural language inference models imppressive? learning
implicature and presupposition.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib32.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib32.11.3" style="font-size:90%;">
      , 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib33.5.5.1" style="font-size:90%;">
      Zhang et al. [2020a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.7.1" style="font-size:90%;">
      Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao,
Jianfeng Gao, Jingjing Liu, and Bill Dolan.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.8.1" style="font-size:90%;">
      Dialogpt: Large-scale generative pre-training for conversational
response generation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib33.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib33.11.3" style="font-size:90%;">
      , 2020a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib34.5.5.1" style="font-size:90%;">
      Peng et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib34.7.1" style="font-size:90%;">
      Baolin Peng, Michel Galley, Pengcheng He, Chris Brockett, Lars Liden, Elnaz
Nouri, Zhou Yu, Bill Dolan, and Jianfeng Gao.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib34.8.1" style="font-size:90%;">
      Godel: Large-scale pre-training for goal-directed dialog, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib35.5.5.1" style="font-size:90%;">
      Thoppilan et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib35.7.1" style="font-size:90%;">
      Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv
Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,
YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo
Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao
Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao,
Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett,
Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel
Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben
Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen
Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi
Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron
Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui,
Marian Croak, Ed Chi, and Quoc Le.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib35.8.1" style="font-size:90%;">
      Lamda: Language models for dialog applications, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib36.5.5.1" style="font-size:90%;">
      Adiwardana et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib36.7.1" style="font-size:90%;">
      Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel,
Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and
Quoc V. Le.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib36.8.1" style="font-size:90%;">
      Towards a human-like open-domain chatbot, 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib37.5.5.1" style="font-size:90%;">
      Gunasekara et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib37.7.1" style="font-size:90%;">
      Chulaka Gunasekara, Seokhwan Kim, Luis Fernando D’Haro, Abhinav Rastogi,
Yun-Nung Chen, Mihail Eric, Behnam Hedayatnia, Karthik Gopalakrishnan, Yang
Liu, Chao-Wei Huang, Dilek Hakkani-Tür, Jinchao Li, Qi Zhu, Lingxiao Luo,
Lars Liden, Kaili Huang, Shahin Shayandeh, Runze Liang, Baolin Peng, Zheng
Zhang, Swadheen Shukla, Minlie Huang, Jianfeng Gao, Shikib Mehri, Yulan Feng,
Carla Gordon, Seyed Hossein Alavi, David Traum, Maxine Eskenazi, Ahmad
Beirami, Eunjoon, Cho, Paul A. Crook, Ankita De, Alborz Geramifard, Satwik
Kottur, Seungwhan Moon, Shivani Poddar, and Rajen Subba.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib37.8.1" style="font-size:90%;">
      Overview of the ninth dialog system technology challenge: Dstc9,
2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib38.5.5.1" style="font-size:90%;">
      Vaswani et al. [2017]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib38.7.1" style="font-size:90%;">
      Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib38.8.1" style="font-size:90%;">
      Attention is all you need.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib38.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.10.2" style="font-size:90%;">
      Advances in Neural Information Processing Systems
(NeurIPS)
     </em>
     <span class="ltx_text" id="bib.bib38.11.3" style="font-size:90%;">
      , 2017.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib39.5.5.1" style="font-size:90%;">
      Anil et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib39.7.1" style="font-size:90%;">
      Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,
Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy
Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson,
Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang,
Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha,
James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng,
Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément
Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz,
Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus
Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari,
Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui,
Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao
Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine
Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek
     </span>
     <span class="ltx_text" id="bib.bib39.8.2" style="font-size:90%;">
      Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma
Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John
Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek,
Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker
Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee
Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon
Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang,
Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan
Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng,
Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib39.9.1" style="font-size:90%;">
      Palm 2 technical report, 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib40.4.4.1" style="font-size:90%;">
      Zhang and Wan [2022a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib40.6.1" style="font-size:90%;">
      Yunxiang Zhang and Xiaojun Wan.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib40.7.1" style="font-size:90%;">
      MOVER: Mask, over-generate and rank for hyperbole generation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib40.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.9.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib40.10.3" style="font-size:90%;">
      , pages 6018–6030, Seattle, United States, July
2022a. Association for Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib40.11.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.18653/v1/2022.naacl-main.440" style="font-size:90%;" title="">
      10.18653/v1/2022.naacl-main.440
     </a>
     <span class="ltx_text" id="bib.bib40.12.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib40.13.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.naacl-main.440" style="font-size:90%;" title="">
      https://aclanthology.org/2022.naacl-main.440
     </a>
     <span class="ltx_text" id="bib.bib40.14.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib41.4.4.1" style="font-size:90%;">
      Weller and Seppi [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib41.6.1" style="font-size:90%;">
      Orion Weller and Kevin Seppi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib41.7.1" style="font-size:90%;">
      The rJokes dataset: a large scale humor collection.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib41.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.9.2" style="font-size:90%;">
      Proceedings of the Twelfth Language Resources and Evaluation
Conference
     </em>
     <span class="ltx_text" id="bib.bib41.10.3" style="font-size:90%;">
      , pages 6136–6141, Marseille, France, May 2020. European Language
Resources Association.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib41.11.1" style="font-size:90%;">
      ISBN 979-10-95546-34-4.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib41.12.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.lrec-1.753" style="font-size:90%;" title="">
      https://aclanthology.org/2020.lrec-1.753
     </a>
     <span class="ltx_text" id="bib.bib41.13.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib42.4.4.1" style="font-size:90%;">
      Frank and Goodman [2012]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib42.6.1" style="font-size:90%;">
      Michael C. Frank and Noah D. Goodman.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib42.7.1" style="font-size:90%;">
      Predicting pragmatic reasoning in language games.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.8.1" style="font-size:90%;">
      Science
     </em>
     <span class="ltx_text" id="bib.bib42.9.2" style="font-size:90%;">
      , 336(6084):998–998, 2012.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib42.10.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.1126/science.1218633" style="font-size:90%;" title="">
      10.1126/science.1218633
     </a>
     <span class="ltx_text" id="bib.bib42.11.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib42.12.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.science.org/doi/abs/10.1126/science.1218633" style="font-size:90%;" title="">
      https://www.science.org/doi/abs/10.1126/science.1218633
     </a>
     <span class="ltx_text" id="bib.bib42.13.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib43.5.5.1" style="font-size:90%;">
      Stowe et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib43.7.1" style="font-size:90%;">
      Kevin Stowe, Prasetya Utama, and Iryna Gurevych.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib43.8.1" style="font-size:90%;">
      IMPLI: Investigating NLI models’ performance on figurative
language.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib43.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib43.11.3" style="font-size:90%;">
      , pages 5375–5388, Dublin, Ireland, May 2022. Association
for Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib43.12.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.18653/v1/2022.acl-long.369" style="font-size:90%;" title="">
      10.18653/v1/2022.acl-long.369
     </a>
     <span class="ltx_text" id="bib.bib43.13.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib43.14.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.acl-long.369" style="font-size:90%;" title="">
      https://aclanthology.org/2022.acl-long.369
     </a>
     <span class="ltx_text" id="bib.bib43.15.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib44.5.5.1" style="font-size:90%;">
      Chakrabarty et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib44.7.1" style="font-size:90%;">
      Tuhin Chakrabarty, Yejin Choi, and Vered Shwartz.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib44.8.1" style="font-size:90%;">
      It’s not rocket science : Interpreting figurative language in
narratives.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib44.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib44.11.3" style="font-size:90%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib45.5.5.1" style="font-size:90%;">
      Ghosal et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib45.7.1" style="font-size:90%;">
      Deepanway Ghosal, Siqi Shen, Navonil Majumder, Rada Mihalcea, and Soujanya
Poria.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib45.8.1" style="font-size:90%;">
      Cicero: A dataset for contextualized commonsense inference in
dialogues.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib45.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib45.11.3" style="font-size:90%;">
      , 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib46.5.5.1" style="font-size:90%;">
      Ghosal et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib46.7.1" style="font-size:90%;">
      Deepanway Ghosal, Pengfei Hong, Siqi Shen, Navonil Majumder, Rada Mihalcea, and
Soujanya Poria.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib46.8.1" style="font-size:90%;">
      Cider: Commonsense inference for dialogue explanation and reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib46.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.10.2" style="font-size:90%;">
      Proceedings of the 22nd Annual Meeting of the Special
Interest Group on Discourse and Dialogue
     </em>
     <span class="ltx_text" id="bib.bib46.11.3" style="font-size:90%;">
      , 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib47.5.5.1" style="font-size:90%;">
      Zhou et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib47.7.1" style="font-size:90%;">
      Pei Zhou, Pegah Jandaghi, Bill Yuchen Lin, Justin Cho, Jay Pujara, and Xiang
     </span>
     <span class="ltx_text" id="bib.bib47.8.2" style="font-size:90%;">
      Ren.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib47.9.1" style="font-size:90%;">
      Probing commonsense explanation in dialogue response generation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib47.10.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.11.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib47.12.3" style="font-size:90%;">
      , 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib48.5.5.1" style="font-size:90%;">
      Liu et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib48.7.1" style="font-size:90%;">
      Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib48.8.1" style="font-size:90%;">
      Roberta: A robustly optimized bert pretraining approach.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib48.9.1" style="font-size:90%;">
      2019.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib48.10.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1907.11692" style="font-size:90%;" title="">
      http://arxiv.org/abs/1907.11692
     </a>
     <span class="ltx_text" id="bib.bib48.11.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib49.4.4.1" style="font-size:90%;">
      Zhang and Wan [2022b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib49.6.1" style="font-size:90%;">
      Yunxiang Zhang and Xiaojun Wan.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib49.7.1" style="font-size:90%;">
      Mover: Mask, over-generate and rank for hyperbole generation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib49.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.9.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib49.10.3" style="font-size:90%;">
      , 2022b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib50.5.5.1" style="font-size:90%;">
      Zhang et al. [2020b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib50.7.1" style="font-size:90%;">
      Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib50.8.1" style="font-size:90%;">
      Bertscore: Evaluating text generation with bert.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib50.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib50.11.3" style="font-size:90%;">
      , 2020b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib51.5.5.1" style="font-size:90%;">
      Zellers et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib51.7.1" style="font-size:90%;">
      Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib51.8.1" style="font-size:90%;">
      From recognition to cognition: Visual commonsense reasoning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib51.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.10.2" style="font-size:90%;">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     <span class="ltx_text" id="bib.bib51.11.3" style="font-size:90%;">
      , June 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib52.4.4.1" style="font-size:90%;">
      Reimers and Gurevych [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib52.6.1" style="font-size:90%;">
      Nils Reimers and Iryna Gurevych.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib52.7.1" style="font-size:90%;">
      Sentence-bert: Sentence embeddings using siamese bert-networks.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib52.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.9.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib52.10.3" style="font-size:90%;">
      . Association for Computational Linguistics, 11 2019.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib52.11.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1908.10084" style="font-size:90%;" title="">
      http://arxiv.org/abs/1908.10084
     </a>
     <span class="ltx_text" id="bib.bib52.12.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib53.5.5.1" style="font-size:90%;">
      Lewis et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib53.7.1" style="font-size:90%;">
      Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Ves Stoyanov, and Luke Zettlemoyer.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib53.8.1" style="font-size:90%;">
      Bart: Denoising sequence-to-sequence pre-training for natural
language generation, translation, and comprehension.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib53.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.10.2" style="font-size:90%;">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     <span class="ltx_text" id="bib.bib53.11.3" style="font-size:90%;">
      , 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib54.5.5.1" style="font-size:90%;">
      Raffel et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib54.7.1" style="font-size:90%;">
     </span>
     <span class="ltx_text" id="bib.bib54.8.2" style="font-size:90%;">
      Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter J. Liu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib54.9.1" style="font-size:90%;">
      Exploring the limits of transfer learning with a unified text-to-text
transformer.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib54.10.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.11.2" style="font-size:90%;">
      Journal of Machine Learning Research (JMLR)
     </em>
     <span class="ltx_text" id="bib.bib54.12.3" style="font-size:90%;">
      , 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib55.5.5.1" style="font-size:90%;">
      Khashabi et al. [2020]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib55.7.1" style="font-size:90%;">
      Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord,
Peter Clark, and Hannaneh Hajishirzi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib55.8.1" style="font-size:90%;">
      Unifiedqa: Crossing format boundaries with a single qa system.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib55.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.10.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib55.11.3" style="font-size:90%;">
      , 2020.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib56.5.5.1" style="font-size:90%;">
      Xue et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib56.7.1" style="font-size:90%;">
      Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya
Siddhant, Aditya Barua, and Colin Raffel.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib56.8.1" style="font-size:90%;">
      mT5: A massively multilingual pre-trained text-to-text transformer.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib56.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.10.2" style="font-size:90%;">
      North American Chapter of the Association for Computational
Linguistics: Human Language Technologies (NAACL-HLT)
     </em>
     <span class="ltx_text" id="bib.bib56.11.3" style="font-size:90%;">
      , pages 483–498,
Online, June 2021. Association for Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib56.12.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.18653/v1/2021.naacl-main.41" style="font-size:90%;" title="">
      10.18653/v1/2021.naacl-main.41
     </a>
     <span class="ltx_text" id="bib.bib56.13.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib56.14.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.naacl-main.41" style="font-size:90%;" title="">
      https://aclanthology.org/2021.naacl-main.41
     </a>
     <span class="ltx_text" id="bib.bib56.15.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib57.4.4.1" style="font-size:90%;">
      MacCartney and Manning [2008]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib57.6.1" style="font-size:90%;">
      Bill MacCartney and Christopher D. Manning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib57.7.1" style="font-size:90%;">
      Modeling semantic containment and exclusion in natural language
inference.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib57.8.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.9.2" style="font-size:90%;">
      International Conference on Computational Linguistics
(COLING)
     </em>
     <span class="ltx_text" id="bib.bib57.10.3" style="font-size:90%;">
      , pages 521–528, Manchester, UK, August 2008. Coling 2008
Organizing Committee.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib57.11.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/C08-1066" style="font-size:90%;" title="">
      https://aclanthology.org/C08-1066
     </a>
     <span class="ltx_text" id="bib.bib57.12.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib58.5.5.1" style="font-size:90%;">
      He et al. [2021]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib58.7.1" style="font-size:90%;">
      Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib58.8.1" style="font-size:90%;">
      Deberta: Decoding-enhanced bert with disentangled attention.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib58.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.10.2" style="font-size:90%;">
      International Conference on Learning Representations
(ICLR)
     </em>
     <span class="ltx_text" id="bib.bib58.11.3" style="font-size:90%;">
      , 2021.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib59.5.5.1" style="font-size:90%;">
      Kojima et al. [2023]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib59.7.1" style="font-size:90%;">
      Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke
Iwasawa.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib59.8.1" style="font-size:90%;">
      Large language models are zero-shot reasoners.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib59.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib59.10.2" style="font-size:90%;">
      Advances in Neural Information Processing Systems
(NeurIPS)
     </em>
     <span class="ltx_text" id="bib.bib59.11.3" style="font-size:90%;">
      , 2023.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib60.5.5.1" style="font-size:90%;">
      Honovich et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib60.7.1" style="font-size:90%;">
      Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy,
Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, and Yossi
Matias.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib60.8.1" style="font-size:90%;">
      TRUE: Re-evaluating factual consistency evaluation.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib60.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.10.2" style="font-size:90%;">
      North American Chapter of the Association for Computational
Linguistics: Human Language Technologies (NAACL-HLT)
     </em>
     <span class="ltx_text" id="bib.bib60.11.3" style="font-size:90%;">
      , pages 3905–3920,
Seattle, United States, July 2022. Association for Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib60.12.1" style="font-size:90%;">
      doi:
     </span>
     <a class="ltx_ref ltx_Url" href="10.18653/v1/2022.naacl-main.287" style="font-size:90%;" title="">
      10.18653/v1/2022.naacl-main.287
     </a>
     <span class="ltx_text" id="bib.bib60.13.2" style="font-size:90%;">
      .
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib60.14.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.naacl-main.287" style="font-size:90%;" title="">
      https://aclanthology.org/2022.naacl-main.287
     </a>
     <span class="ltx_text" id="bib.bib60.15.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib61.5.5.1" style="font-size:90%;">
      Bowman et al. [2015]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib61.7.1" style="font-size:90%;">
      Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib61.8.1" style="font-size:90%;">
      A large annotated corpus for learning natural language inference.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib61.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.10.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib61.11.3" style="font-size:90%;">
      , 2015.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib62.5.5.1" style="font-size:90%;">
      Ji et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib62.7.1" style="font-size:90%;">
      Anya Ji, Noriyuki Kojima, Noah Rush, Alane Suhr, Wai Keen Vong, Robert Hawkins,
and Yoav Artzi.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib62.8.1" style="font-size:90%;">
      Abstract visual reasoning with tangram shapes.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib62.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.10.2" style="font-size:90%;">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     <span class="ltx_text" id="bib.bib62.11.3" style="font-size:90%;">
      , pages 582–601, Abu Dhabi, United Arab Emirates,
     </span>
     <span class="ltx_text" id="bib.bib62.12.4" style="font-size:90%;">
      December 2022. Association for Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib62.13.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.emnlp-main.38" style="font-size:90%;" title="">
      https://aclanthology.org/2022.emnlp-main.38
     </a>
     <span class="ltx_text" id="bib.bib62.14.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib63.5.5.1" style="font-size:90%;">
      Lan et al. [2020a]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib63.7.1" style="font-size:90%;">
      Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
Radu Soricut.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib63.8.1" style="font-size:90%;">
      ALBERT: A lite BERT for self-supervised learning of language
representations.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib63.9.1" style="font-size:90%;">
      2020a.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib64.5.5.1" style="font-size:90%;">
      Lan et al. [2020b]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib64.7.1" style="font-size:90%;">
      Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
Radu Soricut.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib64.8.1" style="font-size:90%;">
      Albert: A lite bert for self-supervised learning of language
representations.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib64.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.10.2" style="font-size:90%;">
      International Conference on Learning Representations
(ICLR)
     </em>
     <span class="ltx_text" id="bib.bib64.11.3" style="font-size:90%;">
      , 2020b.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib65.4.4.1" style="font-size:90%;">
      Misra [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib65.6.1" style="font-size:90%;">
      Rishabh Misra.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib65.7.1" style="font-size:90%;">
      News headlines dataset for sarcasm detection, 2022.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib66.5.5.1" style="font-size:90%;">
      Wachowiak et al. [2022]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib66.7.1" style="font-size:90%;">
      Lennart Wachowiak, Dagmar Gromann, and Chao Xu.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib66.8.1" style="font-size:90%;">
      Drum up SUPPORT: Systematic analysis of image-schematic conceptual
metaphors.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib66.9.1" style="font-size:90%;">
      In
     </span>
     <em class="ltx_emph ltx_font_italic" id="bib.bib66.10.2" style="font-size:90%;">
      Proceedings of the 3rd Workshop on Figurative Language
Processing (FLP)
     </em>
     <span class="ltx_text" id="bib.bib66.11.3" style="font-size:90%;">
      , pages 44–53, Abu Dhabi, United Arab Emirates (Hybrid),
December 2022. Association for Computational Linguistics.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib66.12.1" style="font-size:90%;">
      URL
     </span>
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.flp-1.7" style="font-size:90%;" title="">
      https://aclanthology.org/2022.flp-1.7
     </a>
     <span class="ltx_text" id="bib.bib66.13.2" style="font-size:90%;">
      .
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib67.4.4.1" style="font-size:90%;">
      Hearst [1997]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib67.6.1" style="font-size:90%;">
      Marti A. Hearst.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib67.7.1" style="font-size:90%;">
      Texttiling: Segmenting text into multi-paragraph subtopic passages.
     </span>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.8.1" style="font-size:90%;">
      Comput. Linguist.
     </em>
     <span class="ltx_text" id="bib.bib67.9.2" style="font-size:90%;">
      , 23(1):33–64, mar
1997.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib67.10.1" style="font-size:90%;">
      ISSN 0891-2017.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib68.5.5.1" style="font-size:90%;">
      Devlin et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib68.7.1" style="font-size:90%;">
      Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib68.8.1" style="font-size:90%;">
      Bert: Pre-training of deep bidirectional transformers for language
understanding, 2019.
     </span>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     <span class="ltx_text" id="bib.bib69.5.5.1" style="font-size:90%;">
      Radford et al. [2019]
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib69.7.1" style="font-size:90%;">
      Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib69.8.1" style="font-size:90%;">
      Language models are unsupervised multitask learners.
     </span>
    </span>
    <span class="ltx_bibblock">
     <span class="ltx_text" id="bib.bib69.9.1" style="font-size:90%;">
      2019.
     </span>
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <div class="ltx_para" id="p2">
  <p class="ltx_p" id="p2.1">
   <span class="ltx_text ltx_font_bold" id="p2.1.1" style="font-size:173%;">
    Supplementary Material
   </span>
  </p>
 </div>
 <span class="ltx_ERROR undefined" id="id2">
  \startcontents
 </span>
 <span class="ltx_ERROR undefined" id="id3">
  \printcontents
 </span>
 <div class="ltx_para" id="p3">
  <p class="ltx_p" id="p3.1">
   1
   <span class="ltx_text ltx_font_bold" id="p3.1.1" style="font-size:144%;">
    Contents
    <span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;">
    </span>
   </span>
   <span class="ltx_rule" style="width:100%;height:1px;background:black;display:inline-block;">
   </span>
  </p>
 </div>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   More Experimental Results for Pragmatic Identification and Reasoning
  </h2>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.1">
    We conducted additional experiments on
    <abbr class="ltx_glossaryref" title="Pragmatic Identification and Reasoning">
     <span class="ltx_text ltx_glossary_short">
      PIR
     </span>
    </abbr>
    employing various models, including RoBERT
    <sub class="ltx_sub" id="A1.p1.1.1">
     large
    </sub>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Liu et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib48" title="">
      <span class="ltx_text" style="font-size:90%;">
       2019
      </span>
     </a>
     )
    </cite>
    , DeBERTa
    <sub class="ltx_sub" id="A1.p1.1.2">
     base
    </sub>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Lan et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib63" title="">
      <span class="ltx_text" style="font-size:90%;">
       2020a
      </span>
     </a>
     )
    </cite>
    , and ALBERT
    <sub class="ltx_sub" id="A1.p1.1.3">
     base
    </sub>
    <cite class="ltx_cite ltx_citemacro_cite">
     <span class="ltx_text" style="font-size:90%;">
      Lan et al.
     </span>
     (
     <a class="ltx_ref" href="#bib.bib64" title="">
      <span class="ltx_text" style="font-size:90%;">
       2020b
      </span>
     </a>
     )
    </cite>
    . The training and testing procedures remained consistent with the aforementioned models described in the main body. All experimental results have been compiled and presented in
    <a class="ltx_ref" href="#A1.T6" title="Table 6 ‣ Appendix A More Experimental Results for Pragmatic Identification and Reasoning ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    . Analysing newly proposed result, it’s obvious to observe that our conclusions mentioned in the main body still hold.
   </p>
  </div>
  <figure class="ltx_table" id="A1.T6">
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     <span class="ltx_text" id="A1.T6.26.1.1" style="font-size:90%;">
      Table 6
     </span>
     :
    </span>
    <span class="ltx_text" id="A1.T6.27.2" style="font-size:90%;">
     Pragmatics Identification and Reasoning Results. The numerical results are
accuracy scores in their percentage.
    </span>
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T6.24">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="A1.T6.3.3">
      <th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A1.T6.3.3.4">
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T6.1.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.1.1.1.1">
        C
        <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.T6.1.1.1.1.m1.1">
         <semantics id="A1.T6.1.1.1.1.m1.1a">
          <mo id="A1.T6.1.1.1.1.m1.1.1" mathvariant="normal" stretchy="false" xref="A1.T6.1.1.1.1.m1.1.1.cmml">
           →
          </mo>
          <annotation-xml encoding="MathML-Content" id="A1.T6.1.1.1.1.m1.1b">
           <ci id="A1.T6.1.1.1.1.m1.1.1.cmml" xref="A1.T6.1.1.1.1.m1.1.1">
            normal-→
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A1.T6.1.1.1.1.m1.1c">
           \rightarrow
          </annotation>
          <annotation encoding="application/x-llamapun" id="A1.T6.1.1.1.1.m1.1d">
           →
          </annotation>
         </semantics>
        </math>
        P
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T6.2.2.2">
       <span class="ltx_text ltx_font_bold" id="A1.T6.2.2.2.1">
        CP
        <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.T6.2.2.2.1.m1.1">
         <semantics id="A1.T6.2.2.2.1.m1.1a">
          <mo id="A1.T6.2.2.2.1.m1.1.1" mathvariant="normal" stretchy="false" xref="A1.T6.2.2.2.1.m1.1.1.cmml">
           →
          </mo>
          <annotation-xml encoding="MathML-Content" id="A1.T6.2.2.2.1.m1.1b">
           <ci id="A1.T6.2.2.2.1.m1.1.1.cmml" xref="A1.T6.2.2.2.1.m1.1.1">
            normal-→
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A1.T6.2.2.2.1.m1.1c">
           \rightarrow
          </annotation>
          <annotation encoding="application/x-llamapun" id="A1.T6.2.2.2.1.m1.1d">
           →
          </annotation>
         </semantics>
        </math>
        R
       </span>
      </th>
      <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T6.3.3.3">
       <span class="ltx_text ltx_font_bold" id="A1.T6.3.3.3.1">
        C
        <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.T6.3.3.3.1.m1.1">
         <semantics id="A1.T6.3.3.3.1.m1.1a">
          <mo id="A1.T6.3.3.3.1.m1.1.1" mathvariant="normal" stretchy="false" xref="A1.T6.3.3.3.1.m1.1.1.cmml">
           →
          </mo>
          <annotation-xml encoding="MathML-Content" id="A1.T6.3.3.3.1.m1.1b">
           <ci id="A1.T6.3.3.3.1.m1.1.1.cmml" xref="A1.T6.3.3.3.1.m1.1.1">
            normal-→
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A1.T6.3.3.3.1.m1.1c">
           \rightarrow
          </annotation>
          <annotation encoding="application/x-llamapun" id="A1.T6.3.3.3.1.m1.1d">
           →
          </annotation>
         </semantics>
        </math>
        PR
       </span>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A1.T6.24.25.1">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T6.24.25.1.1">
       Random
      </th>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.24.25.1.2">
       50
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.24.25.1.3">
       20
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.24.25.1.4">
       10
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.6.6">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.6.6.4">
       BERT
       <sub class="ltx_sub" id="A1.T6.6.6.4.1">
        base
       </sub>
      </th>
      <td class="ltx_td ltx_align_center" id="A1.T6.4.4.1">
       63.2
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.4.4.1.m1.1">
        <semantics id="A1.T6.4.4.1.m1.1a">
         <mo id="A1.T6.4.4.1.m1.1.1" xref="A1.T6.4.4.1.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.4.4.1.m1.1b">
          <csymbol cd="latexml" id="A1.T6.4.4.1.m1.1.1.cmml" xref="A1.T6.4.4.1.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.4.4.1.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.4.4.1.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       1.1
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.5.5.2">
       91.3
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.5.5.2.m1.1">
        <semantics id="A1.T6.5.5.2.m1.1a">
         <mo id="A1.T6.5.5.2.m1.1.1" xref="A1.T6.5.5.2.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.5.5.2.m1.1b">
          <csymbol cd="latexml" id="A1.T6.5.5.2.m1.1.1.cmml" xref="A1.T6.5.5.2.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.5.5.2.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.5.5.2.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.7
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.6.6.3">
       <span class="ltx_text ltx_font_bold" id="A1.T6.6.6.3.1">
        50.2
        <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.6.6.3.1.m1.1">
         <semantics id="A1.T6.6.6.3.1.m1.1a">
          <mo id="A1.T6.6.6.3.1.m1.1.1" mathvariant="normal" xref="A1.T6.6.6.3.1.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="A1.T6.6.6.3.1.m1.1b">
           <csymbol cd="latexml" id="A1.T6.6.6.3.1.m1.1.1.cmml" xref="A1.T6.6.6.3.1.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A1.T6.6.6.3.1.m1.1c">
           \pm
          </annotation>
          <annotation encoding="application/x-llamapun" id="A1.T6.6.6.3.1.m1.1d">
           ±
          </annotation>
         </semantics>
        </math>
        6.8
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.9.9">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.9.9.4">
       RoBERTa
       <sub class="ltx_sub" id="A1.T6.9.9.4.1">
        base
       </sub>
      </th>
      <td class="ltx_td ltx_align_center" id="A1.T6.7.7.1">
       64.4
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.7.7.1.m1.1">
        <semantics id="A1.T6.7.7.1.m1.1a">
         <mo id="A1.T6.7.7.1.m1.1.1" xref="A1.T6.7.7.1.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.7.7.1.m1.1b">
          <csymbol cd="latexml" id="A1.T6.7.7.1.m1.1.1.cmml" xref="A1.T6.7.7.1.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.7.7.1.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.7.7.1.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       1.3
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.8.8.2">
       92.0
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.8.8.2.m1.1">
        <semantics id="A1.T6.8.8.2.m1.1a">
         <mo id="A1.T6.8.8.2.m1.1.1" xref="A1.T6.8.8.2.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.8.8.2.m1.1b">
          <csymbol cd="latexml" id="A1.T6.8.8.2.m1.1.1.cmml" xref="A1.T6.8.8.2.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.8.8.2.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.8.8.2.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.4
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.9.9.3">
       50.0
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.9.9.3.m1.1">
        <semantics id="A1.T6.9.9.3.m1.1a">
         <mo id="A1.T6.9.9.3.m1.1.1" xref="A1.T6.9.9.3.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.9.9.3.m1.1b">
          <csymbol cd="latexml" id="A1.T6.9.9.3.m1.1.1.cmml" xref="A1.T6.9.9.3.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.9.9.3.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.9.9.3.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       11.28
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.12.12">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.12.12.4">
       RoBERTa
       <sub class="ltx_sub" id="A1.T6.12.12.4.1">
        large
       </sub>
      </th>
      <td class="ltx_td ltx_align_center" id="A1.T6.10.10.1">
       63.8
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.10.10.1.m1.1">
        <semantics id="A1.T6.10.10.1.m1.1a">
         <mo id="A1.T6.10.10.1.m1.1.1" xref="A1.T6.10.10.1.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.10.10.1.m1.1b">
          <csymbol cd="latexml" id="A1.T6.10.10.1.m1.1.1.cmml" xref="A1.T6.10.10.1.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.10.10.1.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.10.10.1.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.0
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.11.11.2">
       60.8
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.11.11.2.m1.1">
        <semantics id="A1.T6.11.11.2.m1.1a">
         <mo id="A1.T6.11.11.2.m1.1.1" xref="A1.T6.11.11.2.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.11.11.2.m1.1b">
          <csymbol cd="latexml" id="A1.T6.11.11.2.m1.1.1.cmml" xref="A1.T6.11.11.2.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.11.11.2.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.11.11.2.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.5
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.12.12.3">
       0.0
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.12.12.3.m1.1">
        <semantics id="A1.T6.12.12.3.m1.1a">
         <mo id="A1.T6.12.12.3.m1.1.1" xref="A1.T6.12.12.3.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.12.12.3.m1.1b">
          <csymbol cd="latexml" id="A1.T6.12.12.3.m1.1.1.cmml" xref="A1.T6.12.12.3.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.12.12.3.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.12.12.3.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.0
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.15.15">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.15.15.4">
       GPT-2
       <sub class="ltx_sub" id="A1.T6.15.15.4.1">
        base
       </sub>
      </th>
      <td class="ltx_td ltx_align_center" id="A1.T6.13.13.1">
       64.4
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.13.13.1.m1.1">
        <semantics id="A1.T6.13.13.1.m1.1a">
         <mo id="A1.T6.13.13.1.m1.1.1" xref="A1.T6.13.13.1.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.13.13.1.m1.1b">
          <csymbol cd="latexml" id="A1.T6.13.13.1.m1.1.1.cmml" xref="A1.T6.13.13.1.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.13.13.1.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.13.13.1.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.7
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.14.14.2">
       90.9
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.14.14.2.m1.1">
        <semantics id="A1.T6.14.14.2.m1.1a">
         <mo id="A1.T6.14.14.2.m1.1.1" xref="A1.T6.14.14.2.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.14.14.2.m1.1b">
          <csymbol cd="latexml" id="A1.T6.14.14.2.m1.1.1.cmml" xref="A1.T6.14.14.2.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.14.14.2.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.14.14.2.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.9
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.15.15.3">
       13.06
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.15.15.3.m1.1">
        <semantics id="A1.T6.15.15.3.m1.1a">
         <mo id="A1.T6.15.15.3.m1.1.1" xref="A1.T6.15.15.3.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.15.15.3.m1.1b">
          <csymbol cd="latexml" id="A1.T6.15.15.3.m1.1.1.cmml" xref="A1.T6.15.15.3.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.15.15.3.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.15.15.3.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       1.1
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.18.18">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.18.18.4">
       DialoGPT
       <sub class="ltx_sub" id="A1.T6.18.18.4.1">
        medium
       </sub>
      </th>
      <td class="ltx_td ltx_align_center" id="A1.T6.16.16.1">
       65.0
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.16.16.1.m1.1">
        <semantics id="A1.T6.16.16.1.m1.1a">
         <mo id="A1.T6.16.16.1.m1.1.1" xref="A1.T6.16.16.1.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.16.16.1.m1.1b">
          <csymbol cd="latexml" id="A1.T6.16.16.1.m1.1.1.cmml" xref="A1.T6.16.16.1.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.16.16.1.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.16.16.1.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.6
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.17.17.2">
       24.5
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.17.17.2.m1.1">
        <semantics id="A1.T6.17.17.2.m1.1a">
         <mo id="A1.T6.17.17.2.m1.1.1" xref="A1.T6.17.17.2.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.17.17.2.m1.1b">
          <csymbol cd="latexml" id="A1.T6.17.17.2.m1.1.1.cmml" xref="A1.T6.17.17.2.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.17.17.2.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.17.17.2.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       1.9
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.18.18.3">
       3.8
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.18.18.3.m1.1">
        <semantics id="A1.T6.18.18.3.m1.1a">
         <mo id="A1.T6.18.18.3.m1.1.1" xref="A1.T6.18.18.3.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.18.18.3.m1.1b">
          <csymbol cd="latexml" id="A1.T6.18.18.3.m1.1.1.cmml" xref="A1.T6.18.18.3.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.18.18.3.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.18.18.3.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       1.5
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.21.21">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T6.21.21.4">
       DeBERTa
       <sub class="ltx_sub" id="A1.T6.21.21.4.1">
        base
       </sub>
      </th>
      <td class="ltx_td ltx_align_center" id="A1.T6.19.19.1">
       64.9
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.19.19.1.m1.1">
        <semantics id="A1.T6.19.19.1.m1.1a">
         <mo id="A1.T6.19.19.1.m1.1.1" xref="A1.T6.19.19.1.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.19.19.1.m1.1b">
          <csymbol cd="latexml" id="A1.T6.19.19.1.m1.1.1.cmml" xref="A1.T6.19.19.1.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.19.19.1.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.19.19.1.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.2
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.20.20.2">
       <span class="ltx_text ltx_font_bold" id="A1.T6.20.20.2.1">
        92.6
        <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.20.20.2.1.m1.1">
         <semantics id="A1.T6.20.20.2.1.m1.1a">
          <mo id="A1.T6.20.20.2.1.m1.1.1" mathvariant="normal" xref="A1.T6.20.20.2.1.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="A1.T6.20.20.2.1.m1.1b">
           <csymbol cd="latexml" id="A1.T6.20.20.2.1.m1.1.1.cmml" xref="A1.T6.20.20.2.1.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A1.T6.20.20.2.1.m1.1c">
           \pm
          </annotation>
          <annotation encoding="application/x-llamapun" id="A1.T6.20.20.2.1.m1.1d">
           ±
          </annotation>
         </semantics>
        </math>
        0.6
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A1.T6.21.21.3">
       43.9
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.21.21.3.m1.1">
        <semantics id="A1.T6.21.21.3.m1.1a">
         <mo id="A1.T6.21.21.3.m1.1.1" xref="A1.T6.21.21.3.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.21.21.3.m1.1b">
          <csymbol cd="latexml" id="A1.T6.21.21.3.m1.1.1.cmml" xref="A1.T6.21.21.3.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.21.21.3.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.21.21.3.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       1.2
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.24.24">
      <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A1.T6.24.24.4">
       ALBERT
       <sub class="ltx_sub" id="A1.T6.24.24.4.1">
        base
       </sub>
      </th>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T6.22.22.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.22.22.1.1">
        65.1
        <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.22.22.1.1.m1.1">
         <semantics id="A1.T6.22.22.1.1.m1.1a">
          <mo id="A1.T6.22.22.1.1.m1.1.1" mathvariant="normal" xref="A1.T6.22.22.1.1.m1.1.1.cmml">
           ±
          </mo>
          <annotation-xml encoding="MathML-Content" id="A1.T6.22.22.1.1.m1.1b">
           <csymbol cd="latexml" id="A1.T6.22.22.1.1.m1.1.1.cmml" xref="A1.T6.22.22.1.1.m1.1.1">
            plus-or-minus
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A1.T6.22.22.1.1.m1.1c">
           \pm
          </annotation>
          <annotation encoding="application/x-llamapun" id="A1.T6.22.22.1.1.m1.1d">
           ±
          </annotation>
         </semantics>
        </math>
        0.4
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T6.23.23.2">
       90.6
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.23.23.2.m1.1">
        <semantics id="A1.T6.23.23.2.m1.1a">
         <mo id="A1.T6.23.23.2.m1.1.1" xref="A1.T6.23.23.2.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.23.23.2.m1.1b">
          <csymbol cd="latexml" id="A1.T6.23.23.2.m1.1.1.cmml" xref="A1.T6.23.23.2.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.23.23.2.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.23.23.2.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       0.2
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T6.24.24.3">
       34.9
       <math alttext="\pm" class="ltx_Math" display="inline" id="A1.T6.24.24.3.m1.1">
        <semantics id="A1.T6.24.24.3.m1.1a">
         <mo id="A1.T6.24.24.3.m1.1.1" xref="A1.T6.24.24.3.m1.1.1.cmml">
          ±
         </mo>
         <annotation-xml encoding="MathML-Content" id="A1.T6.24.24.3.m1.1b">
          <csymbol cd="latexml" id="A1.T6.24.24.3.m1.1.1.cmml" xref="A1.T6.24.24.3.m1.1.1">
           plus-or-minus
          </csymbol>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A1.T6.24.24.3.m1.1c">
          \pm
         </annotation>
         <annotation encoding="application/x-llamapun" id="A1.T6.24.24.3.m1.1d">
          ±
         </annotation>
        </semantics>
       </math>
       1.8
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Annotation Details
  </h2>
  <section class="ltx_subsection" id="A2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     B.1
    </span>
    Details For Automatic Selection
   </h3>
   <div class="ltx_para" id="A2.SS1.p1">
    <p class="ltx_p" id="A2.SS1.p1.1">
     Different methodologies are employed to address various pragmatic phenomena. To leverage prior advancements in the field, we begin by segmenting each dialogue into individual utterances. Subsequently, we employ two distinct approaches, namely string matching and pretrained model classification, to identify these phenomena within our source data. In the case of scalar implicature, which exhibits a noticeable pattern characterized by word pairs such as
     <span class="ltx_text ltx_font_italic" id="A2.SS1.p1.1.1">
      (some, all)
     </span>
     appearing in adjacent turns of dialogues, we employ string matching to annotate instances of scalar implicature in conversations. Similarly, for popeq, which often features a continuous question mark, we utilize this characteristic as a means of detection. With regards to idioms, which exhibit more evident patterns, we employ the idiom set proposed by
     <cite class="ltx_cite ltx_citemacro_citet">
      <span class="ltx_text" style="font-size:90%;">
       Saxena and Paul
      </span>
      (
      <a class="ltx_ref" href="#bib.bib16" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020
       </span>
      </a>
      )
     </cite>
     to conduct searches. For other types of phenomena that lack obvious patterns, we leverage a pretrained RoBERTa base model
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Liu et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib48" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
     , and fine-tune it for our specific task. The sarcasm dataset by
     <cite class="ltx_cite ltx_citemacro_citet">
      <span class="ltx_text" style="font-size:90%;">
       Misra
      </span>
      (
      <a class="ltx_ref" href="#bib.bib65" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     is used for finetuning the sarcasm model, the MOVER dataset by
     <cite class="ltx_cite ltx_citemacro_citet">
      <span class="ltx_text" style="font-size:90%;">
       Zhang and Wan
      </span>
      (
      <a class="ltx_ref" href="#bib.bib40" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022a
       </span>
      </a>
      )
     </cite>
     for hyperbole and the ColBERT dataset by
     <cite class="ltx_cite ltx_citemacro_citet">
      <span class="ltx_text" style="font-size:90%;">
       Annamoradnejad and Zoghi
      </span>
      (
      <a class="ltx_ref" href="#bib.bib18" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     for paronomasia. Several models have been proposed for metaphor detection, thus we utilize an existing model
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Wachowiak et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib66" title="">
       <span class="ltx_text" style="font-size:90%;">
        2022
       </span>
      </a>
      )
     </cite>
     specifically designed for metaphor identification.
    </p>
   </div>
   <section class="ltx_paragraph" id="A2.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Topic Segmentation
    </h4>
    <div class="ltx_para" id="A2.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="A2.SS1.SSS0.Px1.p1.1">
      The original dialogues employed in our study consist of lengthy and multi-turn exchanges, which are well-suited for our research objectives. Consequently, we implement a segmentation process to break down these dialogues into shorter units. To achieve this, we employ two techniques, namely BERTScore
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Zhang et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib50" title="">
        <span class="ltx_text" style="font-size:90%;">
         2020b
        </span>
       </a>
       )
      </cite>
      and TextTiling
      <cite class="ltx_cite ltx_citemacro_cite">
       <span class="ltx_text" style="font-size:90%;">
        Hearst
       </span>
       (
       <a class="ltx_ref" href="#bib.bib67" title="">
        <span class="ltx_text" style="font-size:90%;">
         1997
        </span>
       </a>
       )
      </cite>
      . The segmentation procedure starts with computing the BERTScore between adjacent turns and subsequently applying the TextTiling algorithm to the generated BERTScores.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="A2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     B.2
    </span>
    Details For Fine-grained Annotation
   </h3>
   <div class="ltx_para" id="A2.SS2.p1">
    <p class="ltx_p" id="A2.SS2.p1.1">
     <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
      <span class="ltx_text ltx_glossary_short">
       AMT
      </span>
     </abbr>
     is integral to our process. To ensure clarity and consistency, we provide explicit instructions to the workers. Additionally, to further elucidate the objectives of our study, we offer illustrative examples. The task itself is presented below the instructions and examples, with the dialogue and corresponding turn numbers provided for workers to select. Furthermore, as workers check a checkbox, we prompt them to select a confidence score and provide a rationale. In order to strike a balance between our budget, the quality of annotations, and the speed of annotation, we have determined the compensation of $0.1 per completed task. The whole view of the worker interface is presented in
     <a class="ltx_ref" href="#A2.F6" title="Figure 6 ‣ B.2 Details For Fine-grained Annotation ‣ Appendix B Annotation Details ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Figure
      </span>
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     .
After the annotation process, we collect responses that are assigned with a confidence score of 4 or higher.
    </p>
   </div>
   <figure class="ltx_figure" id="A2.F6">
    <br class="ltx_break ltx_centering"/>
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F6.g1" src=""/>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      Figure 6:
     </span>
     Fine-grained annotation worker interface
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="A2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     B.3
    </span>
    Details on Human Refinements
   </h3>
   <div class="ltx_para" id="A2.SS3.p1">
    <p class="ltx_p" id="A2.SS3.p1.1">
     Disturbing choices are chosen based on the BERTScore metric
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Zhang et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib50" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020b
       </span>
      </a>
      )
     </cite>
     . The rationale with the highest similarity, as determined by other dialogues, is selected and included in the pool of candidate options. The instructions provided to the workers align with those used for Fine-grained Annotation, wherein they are also instructed to assign a confidence score to their responses. The remuneration for workers is set at $0.05 per task. The worker interface is included in
     <a class="ltx_ref" href="#A2.F7" title="Figure 7 ‣ B.3 Details on Human Refinements ‣ Appendix B Annotation Details ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
      <span class="ltx_text ltx_ref_tag">
       Figure
      </span>
      <span class="ltx_text ltx_ref_tag">
       7
      </span>
     </a>
     .
    </p>
   </div>
   <figure class="ltx_figure" id="A2.F7">
    <br class="ltx_break ltx_centering"/>
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="A2.F7.g1" src=""/>
    <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
     <span class="ltx_tag ltx_tag_figure">
      Figure 7:
     </span>
     Human refinements worker interface
    </figcaption>
   </figure>
   <section class="ltx_paragraph" id="A2.SS3.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
      <span class="ltx_text ltx_glossary_short">
       AMT
      </span>
     </abbr>
     Workers Requirements
    </h4>
    <div class="ltx_para" id="A2.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="A2.SS3.SSS0.Px1.p1.1">
      In order to guarantee the quality of annotated data, the qualification rules for workers are strict and can be found in
      <a class="ltx_ref" href="#A2.T7" title="Table 7 ‣ Workers Requirements ‣ B.3 Details on Human Refinements ‣ Appendix B Annotation Details ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      .
     </p>
    </div>
    <figure class="ltx_table" id="A2.T7">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 7:
      </span>
      <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
       <span class="ltx_text ltx_glossary_short">
        AMT
       </span>
      </abbr>
      workers requirements
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T7.4">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A2.T7.4.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A2.T7.4.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A2.T7.4.1.1.1.1" style="font-size:90%;">
          Country
          <sub class="ltx_sub" id="A2.T7.4.1.1.1.1.1">
           <span class="ltx_text ltx_font_medium" id="A2.T7.4.1.1.1.1.1.1">
            In
           </span>
          </sub>
         </span>
        </th>
        <td class="ltx_td ltx_align_justify ltx_border_tt" id="A2.T7.4.1.1.2" style="width:227.6pt;">
         <p class="ltx_p ltx_align_top" id="A2.T7.4.1.1.2.1">
          <span class="ltx_text" id="A2.T7.4.1.1.2.1.1" style="font-size:90%;">
           United States, Canada, Great Britain, Australia, Singapore, Ireland, New Zealand
          </span>
         </p>
        </td>
       </tr>
       <tr class="ltx_tr" id="A2.T7.4.2.2">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T7.4.2.2.1">
         <span class="ltx_text ltx_font_bold" id="A2.T7.4.2.2.1.1" style="font-size:90%;">
          # Tasks approved
          <sub class="ltx_sub" id="A2.T7.4.2.2.1.1.1">
           <span class="ltx_text ltx_font_medium" id="A2.T7.4.2.2.1.1.1.1">
            GreaterThanOrEqualTo
           </span>
          </sub>
         </span>
        </th>
        <td class="ltx_td ltx_align_justify" id="A2.T7.4.2.2.2" style="width:227.6pt;">
         <p class="ltx_p ltx_align_top" id="A2.T7.4.2.2.2.1">
          <span class="ltx_text" id="A2.T7.4.2.2.2.1.1" style="font-size:90%;">
           1300
          </span>
         </p>
        </td>
       </tr>
       <tr class="ltx_tr" id="A2.T7.4.3.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A2.T7.4.3.3.1">
         <span class="ltx_text ltx_font_bold" id="A2.T7.4.3.3.1.1" style="font-size:90%;">
          Tasks approved Rate
          <sub class="ltx_sub" id="A2.T7.4.3.3.1.1.1">
           <span class="ltx_text ltx_font_medium" id="A2.T7.4.3.3.1.1.1.1">
            GreaterThanOrEqualTo
           </span>
          </sub>
         </span>
        </th>
        <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T7.4.3.3.2" style="width:227.6pt;">
         <p class="ltx_p ltx_align_top" id="A2.T7.4.3.3.2.1">
          <span class="ltx_text" id="A2.T7.4.3.3.2.1.1" style="font-size:90%;">
           95%
          </span>
         </p>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Experimental Detail
  </h2>
  <section class="ltx_subsection" id="A3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     C.1
    </span>
    Pragmatic Identification and Reasoning (PIR)
   </h3>
   <section class="ltx_paragraph" id="A3.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     BERT
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px1.1.1">
      base
     </sub>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Devlin et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib68" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
    </h4>
    <div class="ltx_para" id="A3.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="A3.SS1.SSS0.Px1.p1.1">
      BERT (Bidirectional Encoder Representations from Transformers) is a revolutionary language representation model that has had a significant impact on natural language processing (NLP) tasks. It has achieved remarkable performance across various NLP benchmarks, including question answering, sentiment analysis, named entity recognition, and many others. Its birth brings profound influence on pretrained language models.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="A3.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     RoBERTa
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px2.1.1">
      base
     </sub>
     &amp; RoBERTa
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px2.2.2">
      large
     </sub>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Liu et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib48" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
    </h4>
    <div class="ltx_para" id="A3.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="A3.SS1.SSS0.Px2.p1.1">
      RoBERTa improves upon BERT by incorporating enhancements such as larger and more diverse training data, longer pretraining duration, dynamic masking, and advanced training strategies. These improvements enable RoBERTa to achieve even better performance on a wide range of NLP benchmarks. While BERT paved the way for contextualized representations in NLP, RoBERTa further refines and pushes the boundaries of language understanding, making it a powerful and preferred choice for many researchers and practitioners in the field.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="A3.SS1.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     ALBERT
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px3.1.1">
      base
     </sub>
     &amp; ALBERT
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px3.2.2">
      large
     </sub>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Lan et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib64" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020b
       </span>
      </a>
      )
     </cite>
    </h4>
    <div class="ltx_para" id="A3.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="A3.SS1.SSS0.Px3.p1.1">
      ALBERT (A Lite BERT) is a highly efficient and compact variant of the BERT model that addresses the computational limitations of the original architecture. It incorporates parameter-reduction techniques to alleviate training time constraints and achieve improved performance compared to BERT.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="A3.SS1.SSS0.Px4">
    <h4 class="ltx_title ltx_title_paragraph">
     DeBERTa
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px4.1.1">
      base
     </sub>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       He et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib58" title="">
       <span class="ltx_text" style="font-size:90%;">
        2021
       </span>
      </a>
      )
     </cite>
    </h4>
    <div class="ltx_para" id="A3.SS1.SSS0.Px4.p1">
     <p class="ltx_p" id="A3.SS1.SSS0.Px4.p1.1">
      DeBERTa (Decoding-enhanced BERT with Disentangled Attention) is a state-of-the-art language representation model that builds upon the BERT architecture and introduces several key innovations, including disentangled attention mechanism. The performance of DeBERTa has been demonstrated to surpass that of BERT on a wide range of NLP tasks.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="A3.SS1.SSS0.Px5">
    <h4 class="ltx_title ltx_title_paragraph">
     GPT2
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px5.1.1">
      base
     </sub>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Radford et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib69" title="">
       <span class="ltx_text" style="font-size:90%;">
        2019
       </span>
      </a>
      )
     </cite>
    </h4>
    <div class="ltx_para" id="A3.SS1.SSS0.Px5.p1">
     <p class="ltx_p" id="A3.SS1.SSS0.Px5.p1.1">
      Leveraging transformers decoder,
      <cite class="ltx_cite ltx_citemacro_citet">
       <span class="ltx_text" style="font-size:90%;">
        Radford et al.
       </span>
       (
       <a class="ltx_ref" href="#bib.bib69" title="">
        <span class="ltx_text" style="font-size:90%;">
         2019
        </span>
       </a>
       )
      </cite>
      proposed GPT2. It represents a significant breakthrough in natural language processing and generation. One of the most notable features of GPT-2 is its ability to generate coherent and contextually relevant text. Through unsupervised pretraining on a large corpus of internet text, GPT-2 learns to predict the next word in a sequence of text, enabling it to generate human-like responses.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="A3.SS1.SSS0.Px6">
    <h4 class="ltx_title ltx_title_paragraph">
     DialogGPT
     <sub class="ltx_sub" id="A3.SS1.SSS0.Px6.1.1">
      medium
     </sub>
     <cite class="ltx_cite ltx_citemacro_cite">
      <span class="ltx_text" style="font-size:90%;">
       Zhang et al.
      </span>
      (
      <a class="ltx_ref" href="#bib.bib33" title="">
       <span class="ltx_text" style="font-size:90%;">
        2020a
       </span>
      </a>
      )
     </cite>
    </h4>
    <div class="ltx_para" id="A3.SS1.SSS0.Px6.p1">
     <p class="ltx_p" id="A3.SS1.SSS0.Px6.p1.1">
      DialogGPT is dialogue-oriented GPT. It builds upon the GPT architecture and extends it to support interactive conversations. DialogGPT is trained in a supervised manner using a dialogue dataset, which allows it to understand and generate responses in a conversational context.
     </p>
    </div>
    <div class="ltx_para" id="A3.SS1.SSS0.Px6.p2">
     <p class="ltx_p" id="A3.SS1.SSS0.Px6.p2.10">
      The PIR task encompasses three distinct settings:
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.1.1">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.1.1.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.1.1.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.1.1.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.1.1.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.1.1.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.1.1.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.1.1.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.1.1.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.1.1.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
      ,
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.2.2">
       CP
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.2.2.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.2.2.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.2.2.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.2.2.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.2.2.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.2.2.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.2.2.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.2.2.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.2.2.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       R
      </span>
      , and
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.3.3">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.3.3.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.3.3.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.3.3.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.3.3.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.3.3.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.3.3.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.3.3.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.3.3.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.3.3.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       PR
      </span>
      . In the
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.4.4">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.4.4.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.4.4.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.4.4.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.4.4.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.4.4.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.4.4.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.4.4.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.4.4.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.4.4.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
      setting, models are trained for 20 epochs, employing a batch size as indicated in
      <a class="ltx_ref" href="#A3.T9" title="Table 9 ‣ DialogGPTmedium Zhang et al. (2020a) ‣ C.1 Pragmatic Identification and Reasoning (PIR) ‣ Appendix C Experimental Detail ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        9
       </span>
      </a>
      , a learning rate of
      <math alttext="2e-5" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.5.m1.1">
       <semantics id="A3.SS1.SSS0.Px6.p2.5.m1.1a">
        <mrow id="A3.SS1.SSS0.Px6.p2.5.m1.1.1" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.cmml">
         <mrow id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.cmml">
          <mn id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.2" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.2.cmml">
           2
          </mn>
          <mo id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.1" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.1.cmml">
           ⁢
          </mo>
          <mi id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.3" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.3.cmml">
           e
          </mi>
         </mrow>
         <mo id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.1" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.1.cmml">
          −
         </mo>
         <mn id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.3" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.3.cmml">
          5
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.5.m1.1b">
         <apply id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1">
          <minus id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.1">
          </minus>
          <apply id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.cmml" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2">
           <times id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.1.cmml" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.1">
           </times>
           <cn id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.2.cmml" type="integer" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.2">
            2
           </cn>
           <ci id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.3.cmml" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.2.3">
            𝑒
           </ci>
          </apply>
          <cn id="A3.SS1.SSS0.Px6.p2.5.m1.1.1.3.cmml" type="integer" xref="A3.SS1.SSS0.Px6.p2.5.m1.1.1.3">
           5
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.5.m1.1c">
         2e-5
        </annotation>
        <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.5.m1.1d">
         2 italic_e - 5
        </annotation>
       </semantics>
      </math>
      , and weight decay of
      <math alttext="0.01" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.6.m2.1">
       <semantics id="A3.SS1.SSS0.Px6.p2.6.m2.1a">
        <mn id="A3.SS1.SSS0.Px6.p2.6.m2.1.1" xref="A3.SS1.SSS0.Px6.p2.6.m2.1.1.cmml">
         0.01
        </mn>
        <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.6.m2.1b">
         <cn id="A3.SS1.SSS0.Px6.p2.6.m2.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px6.p2.6.m2.1.1">
          0.01
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.6.m2.1c">
         0.01
        </annotation>
        <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.6.m2.1d">
         0.01
        </annotation>
       </semantics>
      </math>
      . As for
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.7.5">
       CP
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.7.5.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.7.5.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.7.5.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.7.5.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.7.5.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.7.5.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.7.5.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.7.5.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.7.5.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       R
      </span>
      , the hyperparameters adopted are listed in
      <a class="ltx_ref" href="#A3.T8" title="Table 8 ‣ DialogGPTmedium Zhang et al. (2020a) ‣ C.1 Pragmatic Identification and Reasoning (PIR) ‣ Appendix C Experimental Detail ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        8
       </span>
      </a>
      . For the
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.8.6">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.8.6.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.8.6.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.8.6.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.8.6.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.8.6.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.8.6.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.8.6.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.8.6.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.8.6.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       PR
      </span>
      setting, there is no training required; instead, we simply load the best checkpoint obtained from the previous training for this task. The concrete implementation is as follows: we initially flatten the test dataset of
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.9.7">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.9.7.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.9.7.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.9.7.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.9.7.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.9.7.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.9.7.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.9.7.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.9.7.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.9.7.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
      , ensuring that each instance contains both a dialogue and a pragmatic turn extracted from the same dialogue. As for the test dataset of
      <span class="ltx_text ltx_font_bold" id="A3.SS1.SSS0.Px6.p2.10.8">
       CP
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px6.p2.10.8.m1.1">
        <semantics id="A3.SS1.SSS0.Px6.p2.10.8.m1.1a">
         <mo id="A3.SS1.SSS0.Px6.p2.10.8.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.SS1.SSS0.Px6.p2.10.8.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px6.p2.10.8.m1.1b">
          <ci id="A3.SS1.SSS0.Px6.p2.10.8.m1.1.1.cmml" xref="A3.SS1.SSS0.Px6.p2.10.8.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px6.p2.10.8.m1.1c">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px6.p2.10.8.m1.1d">
          →
         </annotation>
        </semantics>
       </math>
       R
      </span>
      , no modifications are made. It should be noted that, following the processing steps, both datasets own the same dialogues and corresponding pragmatic turns, resulting in identical instance numbers. For an instance to be deemed correct, the models must successfully accomplish both component tasks
      <em class="ltx_emph ltx_font_italic" id="A3.SS1.SSS0.Px6.p2.10.9">
       i.e
      </em>
      .
      <span class="ltx_text" id="A3.SS1.SSS0.Px6.p2.10.10">
      </span>
      succeed in Identification and Reasoning.
     </p>
    </div>
    <figure class="ltx_table" id="A3.T8">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 8:
      </span>
      Hyperparameters for models on
      <span class="ltx_text ltx_font_bold" id="A3.T8.2.1">
       CP
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.T8.2.1.m1.1">
        <semantics id="A3.T8.2.1.m1.1b">
         <mo id="A3.T8.2.1.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.T8.2.1.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.T8.2.1.m1.1c">
          <ci id="A3.T8.2.1.m1.1.1.cmml" xref="A3.T8.2.1.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.T8.2.1.m1.1d">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.T8.2.1.m1.1e">
          →
         </annotation>
        </semantics>
       </math>
       R
      </span>
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T8.6">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="A3.T8.6.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A3.T8.6.1.1.1">
         <span class="ltx_text" id="A3.T8.6.1.1.1.1" style="font-size:90%;">
          Model
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T8.6.1.1.2">
         <span class="ltx_text" id="A3.T8.6.1.1.2.1" style="font-size:90%;">
          learning rate
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T8.6.1.1.3">
         <span class="ltx_text" id="A3.T8.6.1.1.3.1" style="font-size:90%;">
          batch size
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T8.6.1.1.4">
         <span class="ltx_text" id="A3.T8.6.1.1.4.1" style="font-size:90%;">
          weight decay
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T8.6.1.1.5">
         <span class="ltx_text" id="A3.T8.6.1.1.5.1" style="font-size:90%;">
          epochs
         </span>
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T8.6.2.1">
        <td class="ltx_td ltx_align_left ltx_border_t" id="A3.T8.6.2.1.1">
         <span class="ltx_text" id="A3.T8.6.2.1.1.1" style="font-size:90%;">
          BERT
         </span>
         <sub class="ltx_sub" id="A3.T8.6.2.1.1.2">
          <span class="ltx_text" id="A3.T8.6.2.1.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.6.2.1.2">
         <span class="ltx_text" id="A3.T8.6.2.1.2.1" style="font-size:90%;">
          5e-5
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.6.2.1.3">
         <span class="ltx_text" id="A3.T8.6.2.1.3.1" style="font-size:90%;">
          12
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.6.2.1.4">
         <span class="ltx_text" id="A3.T8.6.2.1.4.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.6.2.1.5">
         <span class="ltx_text" id="A3.T8.6.2.1.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.3.2">
        <td class="ltx_td ltx_align_left" id="A3.T8.6.3.2.1">
         <span class="ltx_text" id="A3.T8.6.3.2.1.1" style="font-size:90%;">
          BERT
         </span>
         <sub class="ltx_sub" id="A3.T8.6.3.2.1.2">
          <span class="ltx_text" id="A3.T8.6.3.2.1.2.1" style="font-size:90%;">
           large
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.3.2.2">
         <span class="ltx_text" id="A3.T8.6.3.2.2.1" style="font-size:90%;">
          5e-5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.3.2.3">
         <span class="ltx_text" id="A3.T8.6.3.2.3.1" style="font-size:90%;">
          12
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.3.2.4">
         <span class="ltx_text" id="A3.T8.6.3.2.4.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.3.2.5">
         <span class="ltx_text" id="A3.T8.6.3.2.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.4.3">
        <td class="ltx_td ltx_align_left" id="A3.T8.6.4.3.1">
         <span class="ltx_text" id="A3.T8.6.4.3.1.1" style="font-size:90%;">
          ALBERT
         </span>
         <sub class="ltx_sub" id="A3.T8.6.4.3.1.2">
          <span class="ltx_text" id="A3.T8.6.4.3.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.4.3.2">
         <span class="ltx_text" id="A3.T8.6.4.3.2.1" style="font-size:90%;">
          5e-5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.4.3.3">
         <span class="ltx_text" id="A3.T8.6.4.3.3.1" style="font-size:90%;">
          12
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.4.3.4">
         <span class="ltx_text" id="A3.T8.6.4.3.4.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.4.3.5">
         <span class="ltx_text" id="A3.T8.6.4.3.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.5.4">
        <td class="ltx_td ltx_align_left" id="A3.T8.6.5.4.1">
         <span class="ltx_text" id="A3.T8.6.5.4.1.1" style="font-size:90%;">
          ALBERT
         </span>
         <sub class="ltx_sub" id="A3.T8.6.5.4.1.2">
          <span class="ltx_text" id="A3.T8.6.5.4.1.2.1" style="font-size:90%;">
           large
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.5.4.2">
         <span class="ltx_text" id="A3.T8.6.5.4.2.1" style="font-size:90%;">
          5e-5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.5.4.3">
         <span class="ltx_text" id="A3.T8.6.5.4.3.1" style="font-size:90%;">
          12
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.5.4.4">
         <span class="ltx_text" id="A3.T8.6.5.4.4.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.5.4.5">
         <span class="ltx_text" id="A3.T8.6.5.4.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.6.5">
        <td class="ltx_td ltx_align_left" id="A3.T8.6.6.5.1">
         <span class="ltx_text" id="A3.T8.6.6.5.1.1" style="font-size:90%;">
          DeBERTa
         </span>
         <sub class="ltx_sub" id="A3.T8.6.6.5.1.2">
          <span class="ltx_text" id="A3.T8.6.6.5.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.6.5.2">
         <span class="ltx_text" id="A3.T8.6.6.5.2.1" style="font-size:90%;">
          5e-5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.6.5.3">
         <span class="ltx_text" id="A3.T8.6.6.5.3.1" style="font-size:90%;">
          12
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.6.5.4">
         <span class="ltx_text" id="A3.T8.6.6.5.4.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.6.5.5">
         <span class="ltx_text" id="A3.T8.6.6.5.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.7.6">
        <td class="ltx_td ltx_align_left" id="A3.T8.6.7.6.1">
         <span class="ltx_text" id="A3.T8.6.7.6.1.1" style="font-size:90%;">
          RoBERTa
         </span>
         <sub class="ltx_sub" id="A3.T8.6.7.6.1.2">
          <span class="ltx_text" id="A3.T8.6.7.6.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.7.6.2">
         <span class="ltx_text" id="A3.T8.6.7.6.2.1" style="font-size:90%;">
          5e-5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.7.6.3">
         <span class="ltx_text" id="A3.T8.6.7.6.3.1" style="font-size:90%;">
          12
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.7.6.4">
         <span class="ltx_text" id="A3.T8.6.7.6.4.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.7.6.5">
         <span class="ltx_text" id="A3.T8.6.7.6.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.8.7">
        <td class="ltx_td ltx_align_left" id="A3.T8.6.8.7.1">
         <span class="ltx_text" id="A3.T8.6.8.7.1.1" style="font-size:90%;">
          RoBERTa
         </span>
         <sub class="ltx_sub" id="A3.T8.6.8.7.1.2">
          <span class="ltx_text" id="A3.T8.6.8.7.1.2.1" style="font-size:90%;">
           large
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.8.7.2">
         <span class="ltx_text" id="A3.T8.6.8.7.2.1" style="font-size:90%;">
          5e-5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.8.7.3">
         <span class="ltx_text" id="A3.T8.6.8.7.3.1" style="font-size:90%;">
          12
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.8.7.4">
         <span class="ltx_text" id="A3.T8.6.8.7.4.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.8.7.5">
         <span class="ltx_text" id="A3.T8.6.8.7.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.9.8">
        <td class="ltx_td ltx_align_left" id="A3.T8.6.9.8.1">
         <span class="ltx_text" id="A3.T8.6.9.8.1.1" style="font-size:90%;">
          GPT2
         </span>
         <sub class="ltx_sub" id="A3.T8.6.9.8.1.2">
          <span class="ltx_text" id="A3.T8.6.9.8.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.9.8.2">
         <span class="ltx_text" id="A3.T8.6.9.8.2.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.9.8.3">
         <span class="ltx_text" id="A3.T8.6.9.8.3.1" style="font-size:90%;">
          8
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.9.8.4">
         <span class="ltx_text" id="A3.T8.6.9.8.4.1" style="font-size:90%;">
          0.01
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A3.T8.6.9.8.5">
         <span class="ltx_text" id="A3.T8.6.9.8.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.6.10.9">
        <td class="ltx_td ltx_align_left ltx_border_bb" id="A3.T8.6.10.9.1">
         <span class="ltx_text" id="A3.T8.6.10.9.1.1" style="font-size:90%;">
          DialoGPT
         </span>
         <sub class="ltx_sub" id="A3.T8.6.10.9.1.2">
          <span class="ltx_text" id="A3.T8.6.10.9.1.2.1" style="font-size:90%;">
           medium
          </span>
         </sub>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T8.6.10.9.2">
         <span class="ltx_text" id="A3.T8.6.10.9.2.1" style="font-size:90%;">
          0.001
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T8.6.10.9.3">
         <span class="ltx_text" id="A3.T8.6.10.9.3.1" style="font-size:90%;">
          2
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T8.6.10.9.4">
         <span class="ltx_text" id="A3.T8.6.10.9.4.1" style="font-size:90%;">
          0.01
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T8.6.10.9.5">
         <span class="ltx_text" id="A3.T8.6.10.9.5.1" style="font-size:90%;">
          50
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
    <figure class="ltx_table" id="A3.T9">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 9:
      </span>
      Batch size for models on
      <span class="ltx_text ltx_font_bold" id="A3.T9.2.1">
       C
       <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A3.T9.2.1.m1.1">
        <semantics id="A3.T9.2.1.m1.1b">
         <mo id="A3.T9.2.1.m1.1.1" mathvariant="normal" stretchy="false" xref="A3.T9.2.1.m1.1.1.cmml">
          →
         </mo>
         <annotation-xml encoding="MathML-Content" id="A3.T9.2.1.m1.1c">
          <ci id="A3.T9.2.1.m1.1.1.cmml" xref="A3.T9.2.1.m1.1.1">
           normal-→
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A3.T9.2.1.m1.1d">
          \rightarrow
         </annotation>
         <annotation encoding="application/x-llamapun" id="A3.T9.2.1.m1.1e">
          →
         </annotation>
        </semantics>
       </math>
       P
      </span>
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T9.6">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="A3.T9.6.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A3.T9.6.1.1.1">
         <span class="ltx_text" id="A3.T9.6.1.1.1.1" style="font-size:90%;">
          Model
         </span>
        </th>
        <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T9.6.1.1.2">
         <span class="ltx_text" id="A3.T9.6.1.1.2.1" style="font-size:90%;">
          Batch Size
         </span>
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T9.6.2.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A3.T9.6.2.1.1">
         <span class="ltx_text" id="A3.T9.6.2.1.1.1" style="font-size:90%;">
          BERT
         </span>
         <sub class="ltx_sub" id="A3.T9.6.2.1.1.2">
          <span class="ltx_text" id="A3.T9.6.2.1.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T9.6.2.1.2">
         <span class="ltx_text" id="A3.T9.6.2.1.2.1" style="font-size:90%;">
          80
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T9.6.3.2">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T9.6.3.2.1">
         <span class="ltx_text" id="A3.T9.6.3.2.1.1" style="font-size:90%;">
          ALBERT
         </span>
         <sub class="ltx_sub" id="A3.T9.6.3.2.1.2">
          <span class="ltx_text" id="A3.T9.6.3.2.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T9.6.3.2.2">
         <span class="ltx_text" id="A3.T9.6.3.2.2.1" style="font-size:90%;">
          24
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T9.6.4.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T9.6.4.3.1">
         <span class="ltx_text" id="A3.T9.6.4.3.1.1" style="font-size:90%;">
          ALBERT
         </span>
         <sub class="ltx_sub" id="A3.T9.6.4.3.1.2">
          <span class="ltx_text" id="A3.T9.6.4.3.1.2.1" style="font-size:90%;">
           large
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T9.6.4.3.2">
         <span class="ltx_text" id="A3.T9.6.4.3.2.1" style="font-size:90%;">
          24
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T9.6.5.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T9.6.5.4.1">
         <span class="ltx_text" id="A3.T9.6.5.4.1.1" style="font-size:90%;">
          DeBERTa
         </span>
         <sub class="ltx_sub" id="A3.T9.6.5.4.1.2">
          <span class="ltx_text" id="A3.T9.6.5.4.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T9.6.5.4.2">
         <span class="ltx_text" id="A3.T9.6.5.4.2.1" style="font-size:90%;">
          24
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T9.6.6.5">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T9.6.6.5.1">
         <span class="ltx_text" id="A3.T9.6.6.5.1.1" style="font-size:90%;">
          RoBERTa
         </span>
         <sub class="ltx_sub" id="A3.T9.6.6.5.1.2">
          <span class="ltx_text" id="A3.T9.6.6.5.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T9.6.6.5.2">
         <span class="ltx_text" id="A3.T9.6.6.5.2.1" style="font-size:90%;">
          80
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T9.6.7.6">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T9.6.7.6.1">
         <span class="ltx_text" id="A3.T9.6.7.6.1.1" style="font-size:90%;">
          RoBERTa
         </span>
         <sub class="ltx_sub" id="A3.T9.6.7.6.1.2">
          <span class="ltx_text" id="A3.T9.6.7.6.1.2.1" style="font-size:90%;">
           large
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T9.6.7.6.2">
         <span class="ltx_text" id="A3.T9.6.7.6.2.1" style="font-size:90%;">
          24
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T9.6.8.7">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T9.6.8.7.1">
         <span class="ltx_text" id="A3.T9.6.8.7.1.1" style="font-size:90%;">
          GPT2
         </span>
         <sub class="ltx_sub" id="A3.T9.6.8.7.1.2">
          <span class="ltx_text" id="A3.T9.6.8.7.1.2.1" style="font-size:90%;">
           base
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T9.6.8.7.2">
         <span class="ltx_text" id="A3.T9.6.8.7.2.1" style="font-size:90%;">
          24
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T9.6.9.8">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T9.6.9.8.1">
         <span class="ltx_text" id="A3.T9.6.9.8.1.1" style="font-size:90%;">
          DialoGPT
         </span>
         <sub class="ltx_sub" id="A3.T9.6.9.8.1.2">
          <span class="ltx_text" id="A3.T9.6.9.8.1.2.1" style="font-size:90%;">
           medium
          </span>
         </sub>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T9.6.9.8.2">
         <span class="ltx_text" id="A3.T9.6.9.8.2.1" style="font-size:90%;">
          8
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="A3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     C.2
    </span>
    Conversational Question Answering (CQA)
   </h3>
   <section class="ltx_paragraph" id="A3.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     CQA
    </h4>
    <div class="ltx_para" id="A3.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="A3.SS2.SSS0.Px1.p1.1">
      ChatGPT was instructed to generate questions for our tasks. The prompt template that starts the questions with "Which" is depicted in
      <a class="ltx_ref" href="#A3.T11" title="Table 11 ‣ CQA ‣ C.2 Conversational Question Answering (CQA) ‣ Appendix C Experimental Detail ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        11
       </span>
      </a>
      . Through this methodology, we collected a total of 19,482 questions. To ensure the reliability of the answers provided to these questions,
      <abbr class="ltx_glossaryref" title="Amazon Mechanical Turk">
       <span class="ltx_text ltx_glossary_short">
        AMT
       </span>
      </abbr>
      is utilized. The task template is demonstrated in
      <a class="ltx_ref" href="#A3.F8" title="Figure 8 ‣ CQA ‣ C.2 Conversational Question Answering (CQA) ‣ Appendix C Experimental Detail ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Figure
       </span>
       <span class="ltx_text ltx_ref_tag">
        8
       </span>
      </a>
      . In our experiment, the hyperparameters adopted are illustrated in
      <a class="ltx_ref" href="#A3.T12" title="Table 12 ‣ CQA ‣ C.2 Conversational Question Answering (CQA) ‣ Appendix C Experimental Detail ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        12
       </span>
      </a>
      . To assess the performance of ChatGPT, we conducted testing using the template outlined in
      <a class="ltx_ref" href="#A3.T14" title="Table 14 ‣ CQA ‣ C.2 Conversational Question Answering (CQA) ‣ Appendix C Experimental Detail ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        14
       </span>
      </a>
      .
     </p>
    </div>
    <figure class="ltx_table" id="A3.T10">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 10:
      </span>
      Hyperparameters for models on CQA.
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T10.4">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T10.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T10.1.1.2">
         <span class="ltx_text" id="A3.T10.1.1.2.1" style="font-size:90%;">
          Training Epoch
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T10.1.1.1">
         <math alttext="50" class="ltx_Math" display="inline" id="A3.T10.1.1.1.m1.1">
          <semantics id="A3.T10.1.1.1.m1.1a">
           <mn id="A3.T10.1.1.1.m1.1.1" mathsize="90%" xref="A3.T10.1.1.1.m1.1.1.cmml">
            50
           </mn>
           <annotation-xml encoding="MathML-Content" id="A3.T10.1.1.1.m1.1b">
            <cn id="A3.T10.1.1.1.m1.1.1.cmml" type="integer" xref="A3.T10.1.1.1.m1.1.1">
             50
            </cn>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T10.1.1.1.m1.1c">
            50
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T10.1.1.1.m1.1d">
            50
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T10.2.2">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T10.2.2.2">
         <span class="ltx_text" id="A3.T10.2.2.2.1" style="font-size:90%;">
          Learning Rate
         </span>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T10.2.2.1">
         <math alttext="5.6e-5" class="ltx_Math" display="inline" id="A3.T10.2.2.1.m1.1">
          <semantics id="A3.T10.2.2.1.m1.1a">
           <mrow id="A3.T10.2.2.1.m1.1.1" xref="A3.T10.2.2.1.m1.1.1.cmml">
            <mrow id="A3.T10.2.2.1.m1.1.1.2" xref="A3.T10.2.2.1.m1.1.1.2.cmml">
             <mn id="A3.T10.2.2.1.m1.1.1.2.2" mathsize="90%" xref="A3.T10.2.2.1.m1.1.1.2.2.cmml">
              5.6
             </mn>
             <mo id="A3.T10.2.2.1.m1.1.1.2.1" xref="A3.T10.2.2.1.m1.1.1.2.1.cmml">
              ⁢
             </mo>
             <mi id="A3.T10.2.2.1.m1.1.1.2.3" mathsize="90%" xref="A3.T10.2.2.1.m1.1.1.2.3.cmml">
              e
             </mi>
            </mrow>
            <mo id="A3.T10.2.2.1.m1.1.1.1" mathsize="90%" xref="A3.T10.2.2.1.m1.1.1.1.cmml">
             −
            </mo>
            <mn id="A3.T10.2.2.1.m1.1.1.3" mathsize="90%" xref="A3.T10.2.2.1.m1.1.1.3.cmml">
             5
            </mn>
           </mrow>
           <annotation-xml encoding="MathML-Content" id="A3.T10.2.2.1.m1.1b">
            <apply id="A3.T10.2.2.1.m1.1.1.cmml" xref="A3.T10.2.2.1.m1.1.1">
             <minus id="A3.T10.2.2.1.m1.1.1.1.cmml" xref="A3.T10.2.2.1.m1.1.1.1">
             </minus>
             <apply id="A3.T10.2.2.1.m1.1.1.2.cmml" xref="A3.T10.2.2.1.m1.1.1.2">
              <times id="A3.T10.2.2.1.m1.1.1.2.1.cmml" xref="A3.T10.2.2.1.m1.1.1.2.1">
              </times>
              <cn id="A3.T10.2.2.1.m1.1.1.2.2.cmml" type="float" xref="A3.T10.2.2.1.m1.1.1.2.2">
               5.6
              </cn>
              <ci id="A3.T10.2.2.1.m1.1.1.2.3.cmml" xref="A3.T10.2.2.1.m1.1.1.2.3">
               𝑒
              </ci>
             </apply>
             <cn id="A3.T10.2.2.1.m1.1.1.3.cmml" type="integer" xref="A3.T10.2.2.1.m1.1.1.3">
              5
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T10.2.2.1.m1.1c">
            5.6e-5
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T10.2.2.1.m1.1d">
            5.6 italic_e - 5
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T10.3.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T10.3.3.2">
         <span class="ltx_text" id="A3.T10.3.3.2.1" style="font-size:90%;">
          Batch Size
         </span>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T10.3.3.1">
         <math alttext="24" class="ltx_Math" display="inline" id="A3.T10.3.3.1.m1.1">
          <semantics id="A3.T10.3.3.1.m1.1a">
           <mn id="A3.T10.3.3.1.m1.1.1" mathsize="90%" xref="A3.T10.3.3.1.m1.1.1.cmml">
            24
           </mn>
           <annotation-xml encoding="MathML-Content" id="A3.T10.3.3.1.m1.1b">
            <cn id="A3.T10.3.3.1.m1.1.1.cmml" type="integer" xref="A3.T10.3.3.1.m1.1.1">
             24
            </cn>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T10.3.3.1.m1.1c">
            24
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T10.3.3.1.m1.1d">
            24
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T10.4.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T10.4.4.2">
         <span class="ltx_text" id="A3.T10.4.4.2.1" style="font-size:90%;">
          Weight Decay
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T10.4.4.1">
         <math alttext="0.001" class="ltx_Math" display="inline" id="A3.T10.4.4.1.m1.1">
          <semantics id="A3.T10.4.4.1.m1.1a">
           <mn id="A3.T10.4.4.1.m1.1.1" mathsize="90%" xref="A3.T10.4.4.1.m1.1.1.cmml">
            0.001
           </mn>
           <annotation-xml encoding="MathML-Content" id="A3.T10.4.4.1.m1.1b">
            <cn id="A3.T10.4.4.1.m1.1.1.cmml" type="float" xref="A3.T10.4.4.1.m1.1.1">
             0.001
            </cn>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T10.4.4.1.m1.1c">
            0.001
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T10.4.4.1.m1.1d">
            0.001
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
    <figure class="ltx_table" id="A3.T11">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 11:
      </span>
      ChatGPT question generation template: using "Which" to start the question.
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T11.4">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T11.4.1.1">
        <td class="ltx_td ltx_align_justify ltx_border_tt" id="A3.T11.4.1.1.1" style="width:341.4pt;">
         <span class="ltx_text ltx_font_typewriter ltx_align_top" id="A3.T11.4.1.1.1.1" style="font-size:90%;">
          You are sensitive and always view others’ words as having some implied meanings.
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T11.4.2.2">
        <td class="ltx_td ltx_align_justify" id="A3.T11.4.2.2.1" style="width:341.4pt;">
         <span class="ltx_text ltx_font_typewriter ltx_align_top" id="A3.T11.4.2.2.1.1" style="font-size:90%;">
          For the dialogue between "A" and "B" in this task, we have offered a statement that is the implied meaning of a turn, please only offer one reading comprehension question that can be answered with only one word based on the dialogue and mostly focuses on the turn the statement mentions.
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T11.4.3.3">
        <td class="ltx_td ltx_align_justify" id="A3.T11.4.3.3.1" style="width:341.4pt;">
         <div class="ltx_block ltx_align_top" id="A3.T11.4.3.3.1.1">
          <p class="ltx_p" id="A3.T11.4.3.3.1.1.1">
           <span class="ltx_text ltx_font_typewriter" id="A3.T11.4.3.3.1.1.1.1" style="font-size:90%;">
            The question will be tested by only by viewing the dialogue, so please make the question hard enough that it’s impossible to answer without viewing the statement.
           </span>
          </p>
          <p class="ltx_p" id="A3.T11.4.3.3.1.1.2">
           <span class="ltx_text ltx_font_typewriter" id="A3.T11.4.3.3.1.1.2.1" style="font-size:90%;">
            Use "Which" to ask the question!
           </span>
          </p>
         </div>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T11.4.4.4">
        <td class="ltx_td ltx_align_justify" id="A3.T11.4.4.4.1" style="width:341.4pt;">
         <div class="ltx_block ltx_align_top" id="A3.T11.4.4.4.1.1">
          <p class="ltx_p" id="A3.T11.4.4.4.1.1.1">
           <span class="ltx_text ltx_font_typewriter" id="A3.T11.4.4.4.1.1.1.1" style="font-size:90%;">
            Following is the dialogue:
           </span>
          </p>
          <p class="ltx_p" id="A3.T11.4.4.4.1.1.2">
           <span class="ltx_text ltx_font_bold" id="A3.T11.4.4.4.1.1.2.1" style="font-size:90%;">
            {dialogue}
           </span>
           <span class="ltx_text ltx_font_typewriter" id="A3.T11.4.4.4.1.1.2.2" style="font-size:90%;">
           </span>
          </p>
          <p class="ltx_p" id="A3.T11.4.4.4.1.1.3">
           <span class="ltx_text ltx_font_typewriter" id="A3.T11.4.4.4.1.1.3.1" style="font-size:90%;">
            Following is the statement:
           </span>
          </p>
          <p class="ltx_p" id="A3.T11.4.4.4.1.1.4">
           <span class="ltx_text ltx_font_bold" id="A3.T11.4.4.4.1.1.4.1" style="font-size:90%;">
            {statement}
           </span>
          </p>
         </div>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T11.4.5.5">
        <td class="ltx_td ltx_align_justify ltx_border_bb" id="A3.T11.4.5.5.1" style="width:341.4pt;">
         <span class="ltx_text ltx_font_typewriter ltx_align_top" id="A3.T11.4.5.5.1.1" style="font-size:90%;">
          Use "Which" to ask the question! And please make the question hard
enough that it’s impossible to answer without viewing
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
    <figure class="ltx_table" id="A3.T12">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 12:
      </span>
      Hyperparameters for models on CQA.
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T12.4">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T12.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T12.1.1.2">
         <span class="ltx_text" id="A3.T12.1.1.2.1" style="font-size:90%;">
          Training Epoch
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T12.1.1.1">
         <math alttext="50" class="ltx_Math" display="inline" id="A3.T12.1.1.1.m1.1">
          <semantics id="A3.T12.1.1.1.m1.1a">
           <mn id="A3.T12.1.1.1.m1.1.1" mathsize="90%" xref="A3.T12.1.1.1.m1.1.1.cmml">
            50
           </mn>
           <annotation-xml encoding="MathML-Content" id="A3.T12.1.1.1.m1.1b">
            <cn id="A3.T12.1.1.1.m1.1.1.cmml" type="integer" xref="A3.T12.1.1.1.m1.1.1">
             50
            </cn>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T12.1.1.1.m1.1c">
            50
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T12.1.1.1.m1.1d">
            50
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T12.2.2">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T12.2.2.2">
         <span class="ltx_text" id="A3.T12.2.2.2.1" style="font-size:90%;">
          Learning Rate
         </span>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T12.2.2.1">
         <math alttext="5.6e-5" class="ltx_Math" display="inline" id="A3.T12.2.2.1.m1.1">
          <semantics id="A3.T12.2.2.1.m1.1a">
           <mrow id="A3.T12.2.2.1.m1.1.1" xref="A3.T12.2.2.1.m1.1.1.cmml">
            <mrow id="A3.T12.2.2.1.m1.1.1.2" xref="A3.T12.2.2.1.m1.1.1.2.cmml">
             <mn id="A3.T12.2.2.1.m1.1.1.2.2" mathsize="90%" xref="A3.T12.2.2.1.m1.1.1.2.2.cmml">
              5.6
             </mn>
             <mo id="A3.T12.2.2.1.m1.1.1.2.1" xref="A3.T12.2.2.1.m1.1.1.2.1.cmml">
              ⁢
             </mo>
             <mi id="A3.T12.2.2.1.m1.1.1.2.3" mathsize="90%" xref="A3.T12.2.2.1.m1.1.1.2.3.cmml">
              e
             </mi>
            </mrow>
            <mo id="A3.T12.2.2.1.m1.1.1.1" mathsize="90%" xref="A3.T12.2.2.1.m1.1.1.1.cmml">
             −
            </mo>
            <mn id="A3.T12.2.2.1.m1.1.1.3" mathsize="90%" xref="A3.T12.2.2.1.m1.1.1.3.cmml">
             5
            </mn>
           </mrow>
           <annotation-xml encoding="MathML-Content" id="A3.T12.2.2.1.m1.1b">
            <apply id="A3.T12.2.2.1.m1.1.1.cmml" xref="A3.T12.2.2.1.m1.1.1">
             <minus id="A3.T12.2.2.1.m1.1.1.1.cmml" xref="A3.T12.2.2.1.m1.1.1.1">
             </minus>
             <apply id="A3.T12.2.2.1.m1.1.1.2.cmml" xref="A3.T12.2.2.1.m1.1.1.2">
              <times id="A3.T12.2.2.1.m1.1.1.2.1.cmml" xref="A3.T12.2.2.1.m1.1.1.2.1">
              </times>
              <cn id="A3.T12.2.2.1.m1.1.1.2.2.cmml" type="float" xref="A3.T12.2.2.1.m1.1.1.2.2">
               5.6
              </cn>
              <ci id="A3.T12.2.2.1.m1.1.1.2.3.cmml" xref="A3.T12.2.2.1.m1.1.1.2.3">
               𝑒
              </ci>
             </apply>
             <cn id="A3.T12.2.2.1.m1.1.1.3.cmml" type="integer" xref="A3.T12.2.2.1.m1.1.1.3">
              5
             </cn>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T12.2.2.1.m1.1c">
            5.6e-5
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T12.2.2.1.m1.1d">
            5.6 italic_e - 5
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T12.3.3">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T12.3.3.2">
         <span class="ltx_text" id="A3.T12.3.3.2.1" style="font-size:90%;">
          Batch Size
         </span>
        </th>
        <td class="ltx_td ltx_align_center" id="A3.T12.3.3.1">
         <math alttext="24" class="ltx_Math" display="inline" id="A3.T12.3.3.1.m1.1">
          <semantics id="A3.T12.3.3.1.m1.1a">
           <mn id="A3.T12.3.3.1.m1.1.1" mathsize="90%" xref="A3.T12.3.3.1.m1.1.1.cmml">
            24
           </mn>
           <annotation-xml encoding="MathML-Content" id="A3.T12.3.3.1.m1.1b">
            <cn id="A3.T12.3.3.1.m1.1.1.cmml" type="integer" xref="A3.T12.3.3.1.m1.1.1">
             24
            </cn>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T12.3.3.1.m1.1c">
            24
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T12.3.3.1.m1.1d">
            24
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T12.4.4">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T12.4.4.2">
         <span class="ltx_text" id="A3.T12.4.4.2.1" style="font-size:90%;">
          Weight Decay
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T12.4.4.1">
         <math alttext="0.001" class="ltx_Math" display="inline" id="A3.T12.4.4.1.m1.1">
          <semantics id="A3.T12.4.4.1.m1.1a">
           <mn id="A3.T12.4.4.1.m1.1.1" mathsize="90%" xref="A3.T12.4.4.1.m1.1.1.cmml">
            0.001
           </mn>
           <annotation-xml encoding="MathML-Content" id="A3.T12.4.4.1.m1.1b">
            <cn id="A3.T12.4.4.1.m1.1.1.cmml" type="float" xref="A3.T12.4.4.1.m1.1.1">
             0.001
            </cn>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A3.T12.4.4.1.m1.1c">
            0.001
           </annotation>
           <annotation encoding="application/x-llamapun" id="A3.T12.4.4.1.m1.1d">
            0.001
           </annotation>
          </semantics>
         </math>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
    <figure class="ltx_table" id="A3.T13">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 13:
      </span>
      Test ChatGPT: answer questions with only one word.
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T13.4">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T13.4.1.1">
        <td class="ltx_td ltx_align_justify ltx_border_tt" id="A3.T13.4.1.1.1" style="width:341.4pt;">
         <span class="ltx_text ltx_font_typewriter ltx_align_top" id="A3.T13.4.1.1.1.1" style="font-size:90%;">
          For the dialogue between "A" and "B" in this task, please answer a
question according to the dialogue with only one word
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T13.4.2.2">
        <td class="ltx_td ltx_align_justify" id="A3.T13.4.2.2.1" style="width:341.4pt;">
         <div class="ltx_block ltx_align_top" id="A3.T13.4.2.2.1.1">
          <p class="ltx_p" id="A3.T13.4.2.2.1.1.1">
           <span class="ltx_text ltx_font_typewriter" id="A3.T13.4.2.2.1.1.1.1" style="font-size:90%;">
            Following is the dialogue:
           </span>
          </p>
          <p class="ltx_p" id="A3.T13.4.2.2.1.1.2">
           <span class="ltx_text ltx_font_bold" id="A3.T13.4.2.2.1.1.2.1" style="font-size:90%;">
            {dialogue}
           </span>
          </p>
         </div>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T13.4.3.3">
        <td class="ltx_td ltx_align_justify ltx_border_bb" id="A3.T13.4.3.3.1" style="width:341.4pt;">
         <p class="ltx_p ltx_align_top" id="A3.T13.4.3.3.1.1">
          <span class="ltx_text ltx_font_typewriter" id="A3.T13.4.3.3.1.1.1" style="font-size:90%;">
           Following is the question:
          </span>
          <span class="ltx_text ltx_font_bold" id="A3.T13.4.3.3.1.1.2" style="font-size:90%;">
           {question}
          </span>
         </p>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
    <figure class="ltx_table" id="A3.T14">
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_table">
       Table 14:
      </span>
      ChatGPT test template of Zero-Shot CoT
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T14.4">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T14.4.1.1">
        <td class="ltx_td ltx_align_justify ltx_border_tt" id="A3.T14.4.1.1.1" style="width:341.4pt;">
         <span class="ltx_text ltx_font_typewriter ltx_align_top" id="A3.T14.4.1.1.1.1" style="font-size:90%;">
          This is a natural language inference task.
Given the dialogue context:
{context}
Does {pragmatic turn} entails {implied meaning}?
Reply ’entails’ or ’not entails’.
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T14.4.2.2">
        <td class="ltx_td ltx_align_justify ltx_border_bb" id="A3.T14.4.2.2.1" style="width:341.4pt;">
         <span class="ltx_text ltx_font_typewriter ltx_align_top" id="A3.T14.4.2.2.1.1" style="font-size:90%;color:#FF0000;">
          Think step by step.
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
    <figure class="ltx_figure" id="A3.F8">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1190" id="A3.F8.g1" src="x9.png" width="830"/>
     <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
      <span class="ltx_tag ltx_tag_figure">
       Figure 8:
      </span>
      Answer collecting worker interface
     </figcaption>
    </figure>
   </section>
   <section class="ltx_paragraph" id="A3.SS2.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Zero-Shot Natural Language Inference
    </h4>
    <div class="ltx_para" id="A3.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="A3.SS2.SSS0.Px2.p1.1">
      Details are provided as follows. T5-XXL, and DeBERTa-v3 are tested with the pragmatic turn as premise and implied meaning as a hypothesis. The context is out of reach for these models. In contrast, as shown in
      <a class="ltx_ref" href="#A3.T11" title="Table 11 ‣ CQA ‣ C.2 Conversational Question Answering (CQA) ‣ Appendix C Experimental Detail ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        11
       </span>
      </a>
      , ChatGPT is given the context, and the red line labeled “
      <span class="ltx_text ltx_font_typewriter" id="A3.SS2.SSS0.Px2.p1.1.1">
       Think step by step
      </span>
      ” represents two distinct configurations: one with
      <span class="ltx_text ltx_font_typewriter" id="A3.SS2.SSS0.Px2.p1.1.2">
       step-by-step
      </span>
      and one without it.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_appendix" id="A4">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix D
   </span>
   More Detail on
   <span class="ltx_text ltx_font_bold" id="A4.1.1">
    DiPlomat
   </span>
  </h2>
  <div class="ltx_para" id="A4.p1">
   <p class="ltx_p" id="A4.p1.1">
    In this section, we will propose more examples of our dataset in
    <a class="ltx_ref" href="#A4.T15" title="Table 15 ‣ Appendix D More Detail on DiPlomat ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      15
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#A4.T16" title="Table 16 ‣ Appendix D More Detail on DiPlomat ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      16
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#A4.T17" title="Table 17 ‣ Appendix D More Detail on DiPlomat ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      17
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#A4.T18" title="Table 18 ‣ Appendix D More Detail on DiPlomat ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      18
     </span>
    </a>
    , and
    <a class="ltx_ref" href="#A4.T19" title="Table 19 ‣ Appendix D More Detail on DiPlomat ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      19
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_table" id="A4.T15">
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 15:
    </span>
    Contextual reasoning examples of
    <span class="ltx_text ltx_font_bold" id="A4.T15.6.1">
     DiPlomat
    </span>
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T15.7">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="A4.T15.7.1.1">
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A4.T15.7.1.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T15.7.1.1.1.1">
        <p class="ltx_p" id="A4.T15.7.1.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.1.1.1.1.1.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T15.7.1.1.1.1.1.2" style="font-size:90%;">
          : Yeah. They say that he’s the fastest pitcher there ever was. It’s just he really couldn’t find home plate. I mean, some of the stories you learn about this guy, it reads like fiction. When he was - I think this is around 1960. He’s pitching in the minor leagues, and he pitched so fast he ripped the man’s ear off.
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.1.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.1.1.1.1.2.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T15.7.1.1.1.1.2.2" style="font-size:90%;">
          : Oh.
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.1.1.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.1.1.1.1.3.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T15.7.1.1.1.1.3.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T15.7.1.1.1.1.3.3" style="font-size:90%;color:#FF0000;">
          Yeah
          <span class="ltx_text" id="A4.T15.7.1.1.1.1.3.3.1" style="color:#000000;">
           .
          </span>
         </span>
        </p>
       </div>
      </th>
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="A4.T15.7.1.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T15.7.1.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T15.7.1.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T15.7.1.1.2.1.2" style="font-size:90%;">
         : The literal meaning is a simple expression of agreement, while the implied meaning is that the speaker is amazed by the story of Steve Dalkowski’s feats.
        </span>
       </p>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A4.T15.7.2.1">
      <td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="A4.T15.7.2.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T15.7.2.1.1.1">
        <p class="ltx_p" id="A4.T15.7.2.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.2.1.1.1.1.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T15.7.2.1.1.1.1.2" style="font-size:90%;">
          : We’re talking about 2. 8 million people. Has the rise of temporary workers figured into, at least, the statistical improvement of the U. S. economy for some people?
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.2.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.2.1.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T15.7.2.1.1.1.2.2" style="font-size:90%;">
          : It has. Overall, about one seventh of the total job growth has been in the temp sector. The temp sector is growing nine times faster than the overall private sector as a whole. And the 2. 9 million workers represents a record number, both in the number of temp workers and in the percentage of the economy that they make up.
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.2.1.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.2.1.1.1.3.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T15.7.2.1.1.1.3.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T15.7.2.1.1.1.3.3" style="font-size:90%;color:#FF0000;">
          You know in "Harvest Of Shame," Edward R. Murrow very famously said, the people we’re showing you in this documentary have picked your Thanksgiving bounty with their bare hands, and this is how they live.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="A4.T15.7.2.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T15.7.2.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T15.7.2.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T15.7.2.1.2.1.2" style="font-size:90%;">
         : The implied meaning of this turn is to reflect on our reliance on temporary workers in our day-to-day lives.
        </span>
       </p>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.7.3.2">
      <td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="A4.T15.7.3.2.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T15.7.3.2.1.1">
        <p class="ltx_p" id="A4.T15.7.3.2.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.3.2.1.1.1.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T15.7.3.2.1.1.1.2" style="font-size:90%;">
          : And so I got up and ran. And it wasn’t too far. But I just - at that moment, I thought, I don’t want to be shot in the back, and I need to find some cover. And there’s really no place to hide. But there are these
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.3.2.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.3.2.1.1.2.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T15.7.3.2.1.1.2.2" style="font-size:90%;">
          : You found a little, like, alcove that you could duck into.
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.3.2.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.3.2.1.1.3.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T15.7.3.2.1.1.3.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T15.7.3.2.1.1.3.3" style="font-size:90%;color:#FF0000;">
          There was a little alcove, yeah. And I just made myself as small as I could in that little corner.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="A4.T15.7.3.2.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T15.7.3.2.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T15.7.3.2.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T15.7.3.2.2.1.2" style="font-size:90%;">
         : The speaker tried to protect itself from danger.
        </span>
       </p>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.7.4.3">
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="A4.T15.7.4.3.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T15.7.4.3.1.1">
        <p class="ltx_p" id="A4.T15.7.4.3.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.4.3.1.1.1.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T15.7.4.3.1.1.1.2" style="font-size:90%;">
          : Well, there’s a big argument in the United States about this. There’s one group of folks who think that engagement policy failed. We engaged with China from 1979 until about 2013 when Xi Jinping came into power. And the idea of engagement was that coevolution was in the American interest as well as in China’s interest. And you could bring China along to be a responsible player to some degree.
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.4.3.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.4.3.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T15.7.4.3.1.1.2.2" style="font-size:90%;">
          : Many hardliners in the United States government - and outside and including in the expert community - now claim that engagement was a sucker’s game and that we have raised up a tiger which could now devour us. But there are different schools of thought about this, and many of us think that we still need to engage with China, albeit more strategically.
         </span>
        </p>
        <p class="ltx_p" id="A4.T15.7.4.3.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T15.7.4.3.1.1.3.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T15.7.4.3.1.1.3.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T15.7.4.3.1.1.3.3" style="font-size:90%;color:#FF0000;">
          That image of raising a tiger that will devour us is very dramatic.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A4.T15.7.4.3.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T15.7.4.3.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T15.7.4.3.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T15.7.4.3.2.1.2" style="font-size:90%;">
         : The situation is not necessarily an ’either/or’ between China and the United States.
        </span>
       </p>
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
  <figure class="ltx_table" id="A4.T16">
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 16:
    </span>
    Figurative language reasoning examples of
    <span class="ltx_text ltx_font_bold" id="A4.T16.7.1">
     DiPlomat
    </span>
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T16.1">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="A4.T16.1.2.1">
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A4.T16.1.2.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T16.1.2.1.1.1">
        <p class="ltx_p" id="A4.T16.1.2.1.1.1.1">
         <span class="ltx_text" id="A4.T16.1.2.1.1.1.1.1" style="font-size:90%;">
          A: Thank you. How are you?
         </span>
        </p>
        <p class="ltx_p" id="A4.T16.1.2.1.1.1.2">
         <span class="ltx_text" id="A4.T16.1.2.1.1.1.2.1" style="font-size:90%;">
          B: I’m pretty good. Thank you. You must be
         </span>
         <span class="ltx_text" id="A4.T16.1.2.1.1.1.2.2" style="font-size:90%;color:#FF0000;">
          stuck like glue
          <span class="ltx_text" id="A4.T16.1.2.1.1.1.2.2.1" style="color:#000000;">
           on this, but, you know, you’ve played in three World Cups, including one of the wins for the U. S. team in 1999. How would you describe what it’s like to be out there on that field in that final game?
          </span>
         </span>
        </p>
       </div>
      </th>
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="A4.T16.1.2.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T16.1.2.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T16.1.2.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T16.1.2.1.2.1.2" style="font-size:90%;">
         : Stuck like glue means to be attached to something, which is a particular issue or a person.
        </span>
       </p>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A4.T16.1.1">
      <td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="A4.T16.1.1.1" style="width:284.5pt;">
       <p class="ltx_p ltx_align_top" id="A4.T16.1.1.1.1.1">
        <span class="ltx_text ltx_font_bold" id="A4.T16.1.1.1.1.1.2" style="font-size:90%;">
         B
        </span>
        <span class="ltx_text" id="A4.T16.1.1.1.1.1.3" style="font-size:90%;">
         : So in terms of what to do about it, we’ve said Twitter and Facebook have shut down these accounts, which prompts me to wonder - does shutting down a fake account do that much? Can’t the Chinese government, if it’s determined to go down this path, just open up two new ones in place of the one that was closed?
        </span>
        <span class="ltx_text ltx_font_bold" id="A4.T16.1.1.1.1.1.4" style="font-size:90%;">
         A
        </span>
        <span class="ltx_text" id="A4.T16.1.1.1.1.1.5" style="font-size:90%;">
         :
        </span>
        <span class="ltx_text" id="A4.T16.1.1.1.1.1.1" style="font-size:90%;color:#FF0000;">
         It is a cat-and-mouse game, and the companies are constantly trying to get ahead of it.
         <span class="ltx_text" id="A4.T16.1.1.1.1.1.1.1" style="color:#000000;">
          [
          <math alttext="\cdots" class="ltx_Math" display="inline" id="A4.T16.1.1.1.1.1.1.1.m1.1">
           <semantics id="A4.T16.1.1.1.1.1.1.1.m1.1a">
            <mi id="A4.T16.1.1.1.1.1.1.1.m1.1.1" mathcolor="#000000" mathvariant="normal" xref="A4.T16.1.1.1.1.1.1.1.m1.1.1.cmml">
             ⋯
            </mi>
            <annotation-xml encoding="MathML-Content" id="A4.T16.1.1.1.1.1.1.1.m1.1b">
             <ci id="A4.T16.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A4.T16.1.1.1.1.1.1.1.m1.1.1">
              ⋯
             </ci>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="A4.T16.1.1.1.1.1.1.1.m1.1c">
             \cdots
            </annotation>
            <annotation encoding="application/x-llamapun" id="A4.T16.1.1.1.1.1.1.1.m1.1d">
             ⋯
            </annotation>
           </semantics>
          </math>
          ]
         </span>
         As you said, they can always set up new accounts.
        </span>
       </p>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="A4.T16.1.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T16.1.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T16.1.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T16.1.1.2.1.2" style="font-size:90%;">
         : Mice are constantly trying to get away from cats and cats are constantly trying to catch mice. In the same way, the Chinese government will always be trying to escape restrictions on social media accounts and media companies will always be trying to find fake accounts.
        </span>
       </p>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T16.1.3.1">
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="A4.T16.1.3.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T16.1.3.1.1.1">
        <p class="ltx_p" id="A4.T16.1.3.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T16.1.3.1.1.1.1.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T16.1.3.1.1.1.1.2" style="font-size:90%;">
          : I really didn’t feel safe because the Turkish government is very famous for hunting down those who oppose Erdogan. So, I mean, I just didn’t want to really risk my life by going to Europe. But, you know, I talked to my team. I told them all, like, how many times I want to come because I want to be with you guys there, and I want to get a win with you guys. And then, later on, they came back with the news and said, you know what?I think the best decision is if you don’t come. Let’s just not risk it for one game.
         </span>
        </p>
        <p class="ltx_p" id="A4.T16.1.3.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T16.1.3.1.1.1.2.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T16.1.3.1.1.1.2.2" style="font-size:90%;">
          : Do you feel safe in New York and elsewhere in the U. S. ?
         </span>
        </p>
        <p class="ltx_p" id="A4.T16.1.3.1.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T16.1.3.1.1.1.3.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T16.1.3.1.1.1.3.2" style="font-size:90%;">
          : I have been getting last two, three days hundreds death threats, but I think I feel safe in America.
         </span>
         <span class="ltx_text" id="A4.T16.1.3.1.1.1.3.3" style="font-size:90%;color:#FF0000;">
          But anywhere else in the world, I wouldn’t really feel safe.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A4.T16.1.3.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T16.1.3.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T16.1.3.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T16.1.3.1.2.1.2" style="font-size:90%;">
         : He is implying that he is still not safe.
        </span>
       </p>
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
  <figure class="ltx_table" id="A4.T17">
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 17:
    </span>
    Commonsense reasoning examples of
    <span class="ltx_text ltx_font_bold" id="A4.T17.7.1">
     DiPlomat
    </span>
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T17.1">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="A4.T17.1.2.1">
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A4.T17.1.2.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T17.1.2.1.1.1">
        <p class="ltx_p" id="A4.T17.1.2.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.2.1.1.1.1.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T17.1.2.1.1.1.1.2" style="font-size:90%;">
          : Yeah - African-American mayor from Tallahassee.
         </span>
        </p>
        <p class="ltx_p" id="A4.T17.1.2.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.2.1.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T17.1.2.1.1.1.2.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T17.1.2.1.1.1.2.3" style="font-size:90%;color:#FF0000;">
          Yes. So this is sort of a test of whether real progressive candidates can win in these sort of purplish states.
          <span class="ltx_text" id="A4.T17.1.2.1.1.1.2.3.1" style="color:#000000;">
           […]
          </span>
         </span>
        </p>
       </div>
      </th>
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="A4.T17.1.2.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T17.1.2.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T17.1.2.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T17.1.2.1.2.1.2" style="font-size:90%;">
         : "Purplish" states are not really colored. They refer to US states that are neither clearly Republican (red) nor Democrat (blue) in their voting.
        </span>
       </p>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A4.T17.1.1">
      <td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="A4.T17.1.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T17.1.1.1.1">
        <p class="ltx_p" id="A4.T17.1.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.1.1.1.2.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T17.1.1.1.1.2.2" style="font-size:90%;">
          : He wrote a lot of letters by hand, didn’t he?
         </span>
        </p>
        <p class="ltx_p" id="A4.T17.1.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.1.1.1.1.2" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T17.1.1.1.1.1.3" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T17.1.1.1.1.1.1" style="font-size:90%;color:#FF0000;">
          He wrote tons of letters. I bet there are a hundred thousand - hundreds out there
          <span class="ltx_text" id="A4.T17.1.1.1.1.1.1.1" style="color:#000000;">
           [
           <math alttext="\cdots" class="ltx_Math" display="inline" id="A4.T17.1.1.1.1.1.1.1.m1.1">
            <semantics id="A4.T17.1.1.1.1.1.1.1.m1.1a">
             <mi id="A4.T17.1.1.1.1.1.1.1.m1.1.1" mathcolor="#000000" mathvariant="normal" xref="A4.T17.1.1.1.1.1.1.1.m1.1.1.cmml">
              ⋯
             </mi>
             <annotation-xml encoding="MathML-Content" id="A4.T17.1.1.1.1.1.1.1.m1.1b">
              <ci id="A4.T17.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A4.T17.1.1.1.1.1.1.1.m1.1.1">
               ⋯
              </ci>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="A4.T17.1.1.1.1.1.1.1.m1.1c">
              \cdots
             </annotation>
             <annotation encoding="application/x-llamapun" id="A4.T17.1.1.1.1.1.1.1.m1.1d">
              ⋯
             </annotation>
            </semantics>
           </math>
           ]
          </span>
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="A4.T17.1.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T17.1.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T17.1.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T17.1.1.2.1.2" style="font-size:90%;">
         : tons of letters implies a very large number and not to full a ton.
        </span>
       </p>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T17.1.3.1">
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="A4.T17.1.3.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T17.1.3.1.1.1">
        <p class="ltx_p" id="A4.T17.1.3.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.3.1.1.1.1.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T17.1.3.1.1.1.1.2" style="font-size:90%;">
          : Well, Pluto’s official designation is a dwarf planet. And I have to tell you the people who sent this probe all the way out to Pluto are a little angry about that because when they launched it a decade ago, Pluto was still a planet.
         </span>
        </p>
        <p class="ltx_p" id="A4.T17.1.3.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.3.1.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T17.1.3.1.1.1.2.2" style="font-size:90%;">
          : (Laughter)
         </span>
        </p>
        <p class="ltx_p" id="A4.T17.1.3.1.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.3.1.1.1.3.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T17.1.3.1.1.1.3.2" style="font-size:90%;">
          : It got downgraded in the intervening years.
         </span>
        </p>
        <p class="ltx_p" id="A4.T17.1.3.1.1.1.4">
         <span class="ltx_text ltx_font_bold" id="A4.T17.1.3.1.1.1.4.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T17.1.3.1.1.1.4.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T17.1.3.1.1.1.4.3" style="font-size:90%;color:#FF0000;">
          That seems so unfair.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A4.T17.1.3.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T17.1.3.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T17.1.3.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T17.1.3.1.2.1.2" style="font-size:90%;">
         : A is expressing sympathy for the people who sent the probe, showing that they understand why they feel so disappointed.
        </span>
       </p>
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
  <figure class="ltx_table" id="A4.T18">
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 18:
    </span>
    External knowledge reasoning examples of
    <span class="ltx_text ltx_font_bold" id="A4.T18.6.1">
     DiPlomat
    </span>
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A4.T18.7">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="A4.T18.7.1.1">
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A4.T18.7.1.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T18.7.1.1.1.1">
        <p class="ltx_p" id="A4.T18.7.1.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.1.1.1.1.1.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T18.7.1.1.1.1.1.2" style="font-size:90%;">
          : Inside of his house, family pictures decorate the walls and the fridge. Les has 15 great grandchildren. He grew up in an orphanage, and he couldn’t wait to leave to join the military. And so in early 1944, he boarded a ship and crossed the Atlantic Ocean to go to the frontline.
         </span>
        </p>
        <p class="ltx_p" id="A4.T18.7.1.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.1.1.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T18.7.1.1.1.1.2.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T18.7.1.1.1.1.2.3" style="font-size:90%;color:#FF0000;">
          I loved that sailing on, of course. It was so dramatic. You could see all these ships bobbing up and down on the ocean. And destroyers were weaving in and out of them to make sure they uncovered any mines or anything
          <span class="ltx_text" id="A4.T18.7.1.1.1.1.2.3.1" style="color:#000000;">
           .
          </span>
         </span>
        </p>
       </div>
      </th>
      <th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="A4.T18.7.1.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T18.7.1.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T18.7.1.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T18.7.1.1.2.1.2" style="font-size:90%;">
         : Sailing across the ocean during wartime was a perilous experience.
        </span>
       </p>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A4.T18.7.2.1">
      <td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="A4.T18.7.2.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T18.7.2.1.1.1">
        <p class="ltx_p" id="A4.T18.7.2.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.2.1.1.1.1.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T18.7.2.1.1.1.1.2" style="font-size:90%;">
          : . . . equivalent to a nuclear bomb?
         </span>
        </p>
        <p class="ltx_p" id="A4.T18.7.2.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.2.1.1.1.2.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T18.7.2.1.1.1.2.2" style="font-size:90%;">
          : Well, it’s about - its equivalent -
         </span>
         <span class="ltx_text" id="A4.T18.7.2.1.1.1.2.3" style="font-size:90%;color:#FF0000;">
          the energy in that explosion is about 10 times the energy in the first atomic bomb. . .
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="A4.T18.7.2.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T18.7.2.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T18.7.2.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T18.7.2.1.2.1.2" style="font-size:90%;">
         : The energy released in the explosion is incredibly powerful.
        </span>
       </p>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T18.7.3.2">
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="A4.T18.7.3.2.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T18.7.3.2.1.1">
        <p class="ltx_p" id="A4.T18.7.3.2.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.3.2.1.1.1.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T18.7.3.2.1.1.1.2" style="font-size:90%;">
          : So in your polling, in your research, do you find that it’s going to come down to maybe a couple thousand votes from these unaffiliated voters and on what issues?Or will they vote?
         </span>
        </p>
        <p class="ltx_p" id="A4.T18.7.3.2.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.3.2.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T18.7.3.2.1.1.2.2" style="font-size:90%;">
          : It is likely at the moment to be a very narrow victory. President Bush won in 2004 with five percent. That was 100,000 votes. In other words, if it is one percent, that would be 20,000 votes, and right now, the polls are moving around in just single percentage points. So it could be that narrow.
         </span>
        </p>
        <p class="ltx_p" id="A4.T18.7.3.2.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.3.2.1.1.3.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T18.7.3.2.1.1.3.2" style="font-size:90%;">
          : Now, I have read that Colorado is going to be this year’s Florida and Ohio, that this is going to be the state that decides the election.
         </span>
        </p>
        <p class="ltx_p" id="A4.T18.7.3.2.1.1.4">
         <span class="ltx_text ltx_font_bold" id="A4.T18.7.3.2.1.1.4.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T18.7.3.2.1.1.4.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T18.7.3.2.1.1.4.3" style="font-size:90%;color:#FF0000;">
          I think it could be, and the interesting thing is that Obama and Palin were both in Jefferson County a couple of days ago, indicating that there may be actually even a county that could be looked at to be beyond an entire state.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A4.T18.7.3.2.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T18.7.3.2.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T18.7.3.2.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T18.7.3.2.2.1.2" style="font-size:90%;">
         : The turn is suggesting that the county of Jefferson in Colorado could be a key factor in deciding the election, despite the fact that it is only one of many counties in the state and there are other swing states in the election.
        </span>
       </p>
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
  <figure class="ltx_table" id="A4.T19">
   <figcaption class="ltx_caption ltx_centering" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 19:
    </span>
    Others examples of
    <span class="ltx_text ltx_font_bold" id="A4.T19.6.1">
     DiPlomat
    </span>
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A4.T19.7">
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A4.T19.7.1.1">
      <td class="ltx_td ltx_align_justify ltx_border_r ltx_border_tt" id="A4.T19.7.1.1.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T19.7.1.1.1.1">
        <p class="ltx_p" id="A4.T19.7.1.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T19.7.1.1.1.1.1.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T19.7.1.1.1.1.1.2" style="font-size:90%;">
          : There’s that feeling - I mean, so many of us have parents in the industry. I mean, that’s what this region is about, especially around Detroit, and Wayne State’s in Detroit, the heart of Detroit. So, it’s nerve-racking. Everyone is nervous. Everyone doesn’t know what’s going to happen next. We’re all watching the news very closely. But at the same time, it’s interesting, because with my generation, we almost seem to, kind of, not be as directly impacted. I mean, our family is, it puts stress on us, but the day to day of the university and the day to day at school doesn’t seem to have changed that much.
         </span>
        </p>
        <p class="ltx_p" id="A4.T19.7.1.1.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T19.7.1.1.1.1.2.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T19.7.1.1.1.1.2.2" style="font-size:90%;">
          : I understand you have friends there who are engineering majors. Do they have any sense of what their future looks like, and will be it there in Michigan?
         </span>
        </p>
        <p class="ltx_p" id="A4.T19.7.1.1.1.1.3">
         <span class="ltx_text ltx_font_bold" id="A4.T19.7.1.1.1.1.3.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T19.7.1.1.1.1.3.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T19.7.1.1.1.1.3.3" style="font-size:90%;color:#FF0000;">
          Everybody is secure in their choices and secure in their decision. Everybody thinks that the industry will come around, especially now with the news that GM is getting money from the government. And everybody is more hopeful, and I mean, the auto industry has always been one of the largest industries and a staple in America, and to think that that industry is just going to vanish, nobody is willing to concede that.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_tt" id="A4.T19.7.1.1.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T19.7.1.1.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T19.7.1.1.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T19.7.1.1.2.1.2" style="font-size:90%;">
         : A believes that the auto industry will not vanish despite the current situation
        </span>
       </p>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T19.7.2.2">
      <td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="A4.T19.7.2.2.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T19.7.2.2.1.1">
        <p class="ltx_p" id="A4.T19.7.2.2.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T19.7.2.2.1.1.1.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T19.7.2.2.1.1.1.2" style="font-size:90%;">
          : In the meantime, what more have you learned in your reporting about the death of Carlos Hernandez Vasquez?
         </span>
        </p>
        <p class="ltx_p" id="A4.T19.7.2.2.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T19.7.2.2.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T19.7.2.2.1.1.2.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T19.7.2.2.1.1.2.3" style="font-size:90%;color:#FF0000;">
          Well, a couple of things. One thing that really stands out is that Carlos Hernandez Vasquez died in a Border Patrol station. The previous migrant children who died were taken to the hospital first; Hernandez Vasquez was not even though immigration authorities clearly knew that he was sick. He was diagnosed with the flu by a nurse practitioner.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_t" id="A4.T19.7.2.2.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T19.7.2.2.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T19.7.2.2.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T19.7.2.2.2.1.2" style="font-size:90%;">
         : The death of Carlos Hernandez Vasquez could have been prevented if he had been taken to the hospital.
        </span>
       </p>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T19.7.3.3">
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" id="A4.T19.7.3.3.1" style="width:284.5pt;">
       <div class="ltx_block ltx_align_top" id="A4.T19.7.3.3.1.1">
        <p class="ltx_p" id="A4.T19.7.3.3.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A4.T19.7.3.3.1.1.1.1" style="font-size:90%;">
          B
         </span>
         <span class="ltx_text" id="A4.T19.7.3.3.1.1.1.2" style="font-size:90%;">
          : So, how do you and the retired general, James Jones, know each other?
         </span>
        </p>
        <p class="ltx_p" id="A4.T19.7.3.3.1.1.2">
         <span class="ltx_text ltx_font_bold" id="A4.T19.7.3.3.1.1.2.1" style="font-size:90%;">
          A
         </span>
         <span class="ltx_text" id="A4.T19.7.3.3.1.1.2.2" style="font-size:90%;">
          :
         </span>
         <span class="ltx_text" id="A4.T19.7.3.3.1.1.2.3" style="font-size:90%;color:#FF0000;">
          My gosh, I think - I can’t even remember when I first met him. It’s been so long ago. I’m sure I met him when he was head of the legislative liaison over the Senate. But I really became acquainted with him when he became a brigadier general, and, of course, I followed his career. Of course, he served very ably as a commandant in the marine corps and then as the European commander, just been with him from time to time. And I just consider him a very good friend.
         </span>
        </p>
       </div>
      </td>
      <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A4.T19.7.3.3.2" style="width:85.4pt;">
       <p class="ltx_p ltx_align_top" id="A4.T19.7.3.3.2.1">
        <span class="ltx_text ltx_font_bold" id="A4.T19.7.3.3.2.1.1" style="font-size:90%;">
         Rationale
        </span>
        <span class="ltx_text" id="A4.T19.7.3.3.2.1.2" style="font-size:90%;">
         : A has a high opinion of James Jones’ character and career.
        </span>
       </p>
      </td>
     </tr>
    </tbody>
   </table>
  </figure>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_appendix" id="A5">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix E
   </span>
   Computational Resources
  </h2>
  <div class="ltx_para" id="A5.p1">
   <p class="ltx_p" id="A5.p1.1">
    For our experiment, we utilized two A100s and one 3090. The majority of our experiments were conducted on the A100s, while for practical reasons, only Unified-QA-base, BART-base, and T5-small were tested on the 3090. It is important to mention that each experiment was run on a single GPU.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A6">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix F
   </span>
   Limitations &amp; Negative Societal Impacts
  </h2>
  <div class="ltx_para" id="A6.p1">
   <p class="ltx_p" id="A6.p1.1">
    We acknowledge two limitations in our study: bias and subjectivity. Since our dialogues primarily stem from an interview dataset, a considerable focus is placed on political topics. This is reasonable, as pragmatic phenomena frequently emerge in the statements of politicians to advance their specific goals. However, this focus introduces a certain degree of bias into our dataset. The second limitation relates to the absence of subjectivity. In our methodology, the data undergoes two stages of human annotation, ensuring higher quality and objectivity. However, pragmatic reasoning is inherently subjective, and prioritizing objectivity compromises the preservation of subjectivity, resulting in a limitation in terms of subjectivity coverage. Our dataset exhibits minimal negative societal impacts. This is primarily due to the fact that our dialogues are transcriptions of publicly available TV shows, which inherently limits the potential for negative effects.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A7">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix G
   </span>
   Ethics Concern
  </h2>
  <div class="ltx_para" id="A7.p1">
   <p class="ltx_p" id="A7.p1.1">
    <span class="ltx_text ltx_font_bold" id="A7.p1.1.1">
     Were any ethical review processes conducted (e.g., by an institutional review board)?
    </span>
    No official processes were done, as our research is not on human subjects, but our data comes from published dataset.
   </p>
  </div>
  <div class="ltx_para" id="A7.p2">
   <p class="ltx_p" id="A7.p2.1">
    <span class="ltx_text ltx_font_bold" id="A7.p2.1.1">
     Does the dataset contain data that might be considered confidential?
    </span>
    No, our data comes from an existing public interview dataset.
   </p>
  </div>
  <div class="ltx_para" id="A7.p3">
   <p class="ltx_p" id="A7.p3.1">
    <span class="ltx_text ltx_font_bold" id="A7.p3.1.1">
     Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? If so, please describe why.
    </span>
    Few of the dialogues may talk about offensive topics.
    <span class="ltx_text ltx_font_bold" id="A7.p3.1.2">
     Does the dataset identify subpopulations (e.g., by age or gender)?
    </span>
    Not explicitly.
   </p>
  </div>
  <div class="ltx_para" id="A7.p4">
   <p class="ltx_p" id="A7.p4.1">
    <span class="ltx_text ltx_font_bold" id="A7.p4.1.1">
     Is it possible to identify individuals (i.e., one or more natural persons) directly or indirectly (i.e., in combination with other data) from the dataset?
    </span>
    Yes, our data contains names of famous people.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A8">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix H
   </span>
   Responsibility &amp; Dataset Liscence
  </h2>
  <div class="ltx_para" id="A8.p1">
   <p class="ltx_p" id="A8.p1.1">
    We bear all responsibility in case of violation of rights and our dataset is under the license of CC BY-NC-SA (Attribution-NonCommercial-ShareAlike).
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A9">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix I
   </span>
   Datasheets for Our Dataset
  </h2>
  <section class="ltx_subsection" id="A9.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.1
    </span>
    Motivation
   </h3>
   <div class="ltx_para" id="A9.SS1.p1">
    <ol class="ltx_enumerate" id="A9.I1">
     <li class="ltx_item" id="A9.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A9.I1.i1.p1">
       <p class="ltx_p" id="A9.I1.i1.p1.1">
        For what purpose was the dataset created? (Was there a specific task in mind? Was there a specific gap that needed to be filled? Please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i1.p2">
       <p class="ltx_p" id="A9.I1.i1.p2.1">
        This dataset was created to study pragmatic reasoning in dialogues, a specific gap is mentioned above in
        <a class="ltx_ref" href="#A6" title="Appendix F Limitations &amp; Negative Societal Impacts ‣ \scalerel*○DiPlomat: A Dialogue Dataset for Situated Pragmatic Reasoning">
         <span class="ltx_text ltx_ref_tag">
          Appendix
         </span>
         <span class="ltx_text ltx_ref_tag">
          F
         </span>
        </a>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="A9.I1.i2.p1">
       <p class="ltx_p" id="A9.I1.i2.p1.1">
        Who created this dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)?
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i2.p2">
       <p class="ltx_p" id="A9.I1.i2.p2.1">
        This dataset was created by the authors of this paper.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="A9.I1.i3.p1">
       <p class="ltx_p" id="A9.I1.i3.p1.1">
        Who funded the creation of the dataset? (If there is an associated grant, please provide the name of the grantor and the grant name and number.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i3.p2">
       <p class="ltx_p" id="A9.I1.i3.p2.1">
        The institute of the authors funded the creation of the dataset.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="A9.I1.i4.p1">
       <p class="ltx_p" id="A9.I1.i4.p1.1">
        Any other comments?
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i4.p2">
       <p class="ltx_p" id="A9.I1.i4.p2.1">
        None.
       </p>
      </div>
      <section class="ltx_subsection" id="A9.SS2">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         I.2
        </span>
        Composition
       </h3>
      </section>
     </li>
     <li class="ltx_item" id="A9.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       5.
      </span>
      <div class="ltx_para" id="A9.I1.i5.p1">
       <p class="ltx_p" id="A9.I1.i5.p1.1">
        What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)? (Are there multiple types of instances (e.g., movies, users, and ratings; people and interactions between them; nodes and edges)? Please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i5.p2">
       <p class="ltx_p" id="A9.I1.i5.p2.1">
        An instance of our dataset represent a piece of dialogue. Description is provided in our paper.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       6.
      </span>
      <div class="ltx_para" id="A9.I1.i6.p1">
       <p class="ltx_p" id="A9.I1.i6.p1.1">
        How many instances are there in total (of each type, if appropriate)?
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i6.p2">
       <p class="ltx_p" id="A9.I1.i6.p2.1">
        We answer the question in our paper. Our datasets owns 4,177 dialogues.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i7" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       7.
      </span>
      <div class="ltx_para" id="A9.I1.i7.p1">
       <p class="ltx_p" id="A9.I1.i7.p1.1">
        Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set? (If the dataset is a sample, then what is the larger set? Is the sample representative of the larger set (e.g., geographic coverage)? If so, please describe how this representativeness was validated/verified. If it is not representative of the larger set, please describe why not (e.g., to cover a more diverse range of instances, because instances were withheld or unavailable).)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i7.p2">
       <p class="ltx_p" id="A9.I1.i7.p2.1">
        It is a sample of all possible cases. As pragmatic phenomena aren’t proved to be limited, we can’t guarantee a full sampling of them.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i8" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       8.
      </span>
      <div class="ltx_para" id="A9.I1.i8.p1">
       <p class="ltx_p" id="A9.I1.i8.p1.1">
        What data does each instance consist of?
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i8.p2">
       <p class="ltx_p" id="A9.I1.i8.p2.1">
        We mention it in our paper.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i9" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       9.
      </span>
      <div class="ltx_para" id="A9.I1.i9.p1">
       <p class="ltx_p" id="A9.I1.i9.p1.1">
        Is there a label or target associated with each instance? If so, please provide a description.
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i9.p2">
       <p class="ltx_p" id="A9.I1.i9.p2.1">
        Yes. The description is in our paper.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i10" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       10.
      </span>
      <div class="ltx_para" id="A9.I1.i10.p1">
       <p class="ltx_p" id="A9.I1.i10.p1.1">
        Is any information missing from individual instances? (If so, please provide a description, explaining why this information is missing (e.g., because it was unavailable). This does not include intentionally removed information, but might include, e.g., redacted text.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i10.p2">
       <p class="ltx_p" id="A9.I1.i10.p2.1">
        No. We leverage the original dialogues.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i11" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       11.
      </span>
      <div class="ltx_para" id="A9.I1.i11.p1">
       <p class="ltx_p" id="A9.I1.i11.p1.1">
        Are relationships between individual instances made explicit (e.g., users’ movie ratings, social network links)? ( If so, please describe how these relationships are made explicit.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i11.p2">
       <p class="ltx_p" id="A9.I1.i11.p2.1">
        No. Instances are weakly related, but focus on the same phenomenon.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i12" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       12.
      </span>
      <div class="ltx_para" id="A9.I1.i12.p1">
       <p class="ltx_p" id="A9.I1.i12.p1.1">
        Are there recommended data splits (e.g., training, development/validation, testing)? (If so, please provide a description of these splits, explaining the rationale behind them.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i12.p2">
       <p class="ltx_p" id="A9.I1.i12.p2.1">
        Yes. We provide it.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i13" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       13.
      </span>
      <div class="ltx_para" id="A9.I1.i13.p1">
       <p class="ltx_p" id="A9.I1.i13.p1.1">
        Are there any errors, sources of noise, or redundancies in the dataset? (If so, please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i13.p2">
       <p class="ltx_p" id="A9.I1.i13.p2.1">
        Yes. We may have some answers just by giving
        <span class="ltx_text ltx_font_italic" id="A9.I1.i13.p2.1.1">
         a
        </span>
        , which is meaningless.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i14" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       14.
      </span>
      <div class="ltx_para" id="A9.I1.i14.p1">
       <p class="ltx_p" id="A9.I1.i14.p1.1">
        Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g., websites, tweets, other datasets)? (If it links to or relies on external resources, a) are there guarantees that they will exist, and remain constant, over time; b) are there official archival versions of the complete dataset (i.e., including the external resources as they existed at the time the dataset was created); c) are there any restrictions (e.g., licenses, fees) associated with any of the external resources that might apply to a future user? Please provide descriptions of all external resources and any restrictions associated with them, as well as links or other access points, as appropriate.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i14.p2">
       <p class="ltx_p" id="A9.I1.i14.p2.1">
        It’s self-contained.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i15" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       15.
      </span>
      <div class="ltx_para" id="A9.I1.i15.p1">
       <p class="ltx_p" id="A9.I1.i15.p1.1">
        Does the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by doctor-patient confidentiality, data that includes the content of individuals’ non-public communications)? (If so, please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i15.p2">
       <p class="ltx_p" id="A9.I1.i15.p2.1">
        No.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i16" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       16.
      </span>
      <div class="ltx_para" id="A9.I1.i16.p1">
       <p class="ltx_p" id="A9.I1.i16.p1.1">
        Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? (If so, please describe why.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i16.p2">
       <p class="ltx_p" id="A9.I1.i16.p2.1">
        Yes. Some of the topic are big events, they may be offensive for some people. However, we consider our dataset’s offensiveness to be limited, for the source dataset is a TV show transcript.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i17" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       17.
      </span>
      <div class="ltx_para" id="A9.I1.i17.p1">
       <p class="ltx_p" id="A9.I1.i17.p1.1">
        Does the dataset relate to people? (If not, you may skip the remaining questions in this section.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i17.p2">
       <p class="ltx_p" id="A9.I1.i17.p2.1">
        Yes.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i18" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       18.
      </span>
      <div class="ltx_para" id="A9.I1.i18.p1">
       <p class="ltx_p" id="A9.I1.i18.p1.1">
        Does the dataset identify any subpopulations (e.g., by age, gender)? (If so, please describe how these subpopulations are identified and provide a description of their respective distributions within the dataset.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i18.p2">
       <p class="ltx_p" id="A9.I1.i18.p2.1">
        No. This is not explicitly identified
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i19" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       19.
      </span>
      <div class="ltx_para" id="A9.I1.i19.p1">
       <p class="ltx_p" id="A9.I1.i19.p1.1">
        Is it possible to identify individuals (i.e., one or more natural persons), either directly or indirectly (i.e., in combination with other data) from the dataset? (If so, please describe how.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i19.p2">
       <p class="ltx_p" id="A9.I1.i19.p2.1">
        Yes; their names are given in running text.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i20" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       20.
      </span>
      <div class="ltx_para" id="A9.I1.i20.p1">
       <p class="ltx_p" id="A9.I1.i20.p1.1">
        Does the dataset contain data that might be considered sensitive in any way (e.g., data that reveals racial or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic data; forms of government identification, such as social security numbers; criminal history)? (If so, please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i20.p2">
       <p class="ltx_p" id="A9.I1.i20.p2.1">
        Yes. Our dataset may have dialogues talking about religious, politics and so on.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i21" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       21.
      </span>
      <div class="ltx_para" id="A9.I1.i21.p1">
       <p class="ltx_p" id="A9.I1.i21.p1.1">
        Any other comments?
       </p>
      </div>
      <div class="ltx_para" id="A9.I1.i21.p2">
       <p class="ltx_p" id="A9.I1.i21.p2.1">
        None.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
  <section class="ltx_subsection" id="A9.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.3
    </span>
    Collection Process
   </h3>
   <div class="ltx_para" id="A9.SS3.p1">
    <ol class="ltx_enumerate" id="A9.I2">
     <li class="ltx_item" id="A9.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A9.I2.i1.p1">
       <p class="ltx_p" id="A9.I2.i1.p1.1">
        How was the data associated with each instance acquired? (Was the data directly observable (e.g., raw text, movie ratings), reported by subjects (e.g., survey responses), or indirectly inferred/derived from other data (e.g., part-of-speech tags, model-based guesses for age or language)? If data was reported by subjects or indirectly inferred/derived from other data, was the data validated/verified? If so, please describe how.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i1.p2">
       <p class="ltx_p" id="A9.I2.i1.p2.1">
        The data all comes from an interview dataset already published. (See our paper)
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="A9.I2.i2.p1">
       <p class="ltx_p" id="A9.I2.i2.p1.1">
        What mechanisms or procedures were used to collect the data (e.g., hardware apparatus or sensor, manual human curation, software program, software API)? (How were these mechanisms or procedures validated?)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i2.p2">
       <p class="ltx_p" id="A9.I2.i2.p2.1">
        Software program and manual human curation (2 times). See our paper for details.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="A9.I2.i3.p1">
       <p class="ltx_p" id="A9.I2.i3.p1.1">
        If the dataset is a sample from a larger set, what was the sampling strategy (e.g., deterministic, probabilistic with specific sampling probabilities)?
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i3.p2">
       <p class="ltx_p" id="A9.I2.i3.p2.1">
        Randomly.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="A9.I2.i4.p1">
       <p class="ltx_p" id="A9.I2.i4.p1.1">
        Who was involved in the data collection process (e.g., students, crowdworkers, contractors) and how were they compensated (e.g., how much were crowdworkers paid)?
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i4.p2">
       <p class="ltx_p" id="A9.I2.i4.p2.1">
        Crowdworkers. They are paid nicely. See Appendix for detail.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       5.
      </span>
      <div class="ltx_para" id="A9.I2.i5.p1">
       <p class="ltx_p" id="A9.I2.i5.p1.1">
        Over what timeframe was the data collected? (Does this timeframe match the creation timeframe of the data associated with the instances (e.g., recent crawl of old news articles)? If not, please describe the timeframe in which the data associated with the instances was created.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i5.p2">
       <p class="ltx_p" id="A9.I2.i5.p2.1">
        The dataset was collected in the early Spring of 2023, which does not necessarily reflect the timeframe of the data collected.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       6.
      </span>
      <div class="ltx_para" id="A9.I2.i6.p1">
       <p class="ltx_p" id="A9.I2.i6.p1.1">
        Were any ethical review processes conducted (e.g., by an institutional review board)? (If so, please provide a description of these review processes, including the outcomes, as well as a link or other access point to any supporting documentation.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i6.p2">
       <p class="ltx_p" id="A9.I2.i6.p2.1">
        No review processes were conducted with respect to the collection and annotation of this data (though review was done for other aspects of this work; see the paper linked at the top of the datasheet).
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i7" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       7.
      </span>
      <div class="ltx_para" id="A9.I2.i7.p1">
       <p class="ltx_p" id="A9.I2.i7.p1.1">
        Does the dataset relate to people? (If not, you may skip the remaining questions in this section.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i7.p2">
       <p class="ltx_p" id="A9.I2.i7.p2.1">
        Yes.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i8" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       8.
      </span>
      <div class="ltx_para" id="A9.I2.i8.p1">
       <p class="ltx_p" id="A9.I2.i8.p1.1">
        Did you collect the data from the individuals in question directly, or obtain it via third parties or other sources (e.g., websites)?
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i8.p2">
       <p class="ltx_p" id="A9.I2.i8.p2.1">
        Other sources. By curating a published dataset.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i9" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       9.
      </span>
      <div class="ltx_para" id="A9.I2.i9.p1">
       <p class="ltx_p" id="A9.I2.i9.p1.1">
        Were the individuals in question notified about the data collection? (If so, please describe (or show with screenshots or other information) how notice was provided, and provide a link or other access point to, or otherwise reproduce, the exact language of the notification itself.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i9.p2">
       <p class="ltx_p" id="A9.I2.i9.p2.1">
        No.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i10" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       10.
      </span>
      <div class="ltx_para" id="A9.I2.i10.p1">
       <p class="ltx_p" id="A9.I2.i10.p1.1">
        Did the individuals in question consent to the collection and use of their data? (If so, please describe (or show with screenshots or other information) how consent was requested and provided, and provide a link or other access point to, or otherwise reproduce, the exact language to which the individuals consented.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i10.p2">
       <p class="ltx_p" id="A9.I2.i10.p2.1">
        No. All data are public.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i11" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       11.
      </span>
      <div class="ltx_para" id="A9.I2.i11.p1">
       <p class="ltx_p" id="A9.I2.i11.p1.1">
        If consent was obtained, were the consenting individuals provided with a mechanism to revoke their consent in the future or for certain uses? (If so, please provide a description, as well as a link or other access point to the mechanism (if appropriate).)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i11.p2">
       <p class="ltx_p" id="A9.I2.i11.p2.1">
        N/A.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i12" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       12.
      </span>
      <div class="ltx_para" id="A9.I2.i12.p1">
       <p class="ltx_p" id="A9.I2.i12.p1.1">
        Has an analysis of the potential impact of the dataset and its use on data subjects (e.g., a data protection impact analysis) been conducted? (If so, please provide a description of this analysis, including the outcomes, as well as a link or other access point to any supporting documentation.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I2.i12.p2">
       <p class="ltx_p" id="A9.I2.i12.p2.1">
        No. We consider our dataset having a limited negative effect, for all of our data has been published for more than a year.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I2.i13" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       13.
      </span>
      <div class="ltx_para" id="A9.I2.i13.p1">
       <p class="ltx_p" id="A9.I2.i13.p1.1">
        Any other comments?
None.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
  <section class="ltx_subsection" id="A9.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.4
    </span>
    Preprocessing/cleaning/labeling
   </h3>
   <div class="ltx_para" id="A9.SS4.p1">
    <ol class="ltx_enumerate" id="A9.I3">
     <li class="ltx_item" id="A9.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A9.I3.i1.p1">
       <p class="ltx_p" id="A9.I3.i1.p1.1">
        Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)? (If so, please provide a description. If not, you may skip the remainder of the questions in this section.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I3.i1.p2">
       <p class="ltx_p" id="A9.I3.i1.p2.1">
        No.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
  <section class="ltx_subsection" id="A9.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.5
    </span>
    Uses
   </h3>
   <div class="ltx_para" id="A9.SS5.p1">
    <ol class="ltx_enumerate" id="A9.I4">
     <li class="ltx_item" id="A9.I4.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A9.I4.i1.p1">
       <p class="ltx_p" id="A9.I4.i1.p1.1">
        Has the dataset been used for any tasks already? (If so, please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I4.i1.p2">
       <p class="ltx_p" id="A9.I4.i1.p2.1">
        Yes. See our paper for details.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I4.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="A9.I4.i2.p1">
       <p class="ltx_p" id="A9.I4.i2.p1.1">
        Is there a repository that links to any or all papers or systems that use the dataset? (If so, please provide a link or other access point.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I4.i2.p2">
       <p class="ltx_p" id="A9.I4.i2.p2.1">
        No.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I4.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="A9.I4.i3.p1">
       <p class="ltx_p" id="A9.I4.i3.p1.1">
        What (other) tasks could the dataset be used for?
       </p>
      </div>
      <div class="ltx_para" id="A9.I4.i3.p2">
       <p class="ltx_p" id="A9.I4.i3.p2.1">
        Many more. Such as generation of implied meanings.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I4.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="A9.I4.i4.p1">
       <p class="ltx_p" id="A9.I4.i4.p1.1">
        Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? (For example, is there anything that a future user might need to know to avoid uses that could result in unfair treatment of individuals or groups (e.g., stereotyping, quality of service issues) or other undesirable harms (e.g., financial harms, legal risks) If so, please provide a description. Is there anything a future user could do to mitigate these undesirable harms?)
       </p>
      </div>
      <div class="ltx_para" id="A9.I4.i4.p2">
       <p class="ltx_p" id="A9.I4.i4.p2.1">
        No.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I4.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       5.
      </span>
      <div class="ltx_para" id="A9.I4.i5.p1">
       <p class="ltx_p" id="A9.I4.i5.p1.1">
        Are there tasks for which the dataset should not be used? (If so, please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I4.i5.p2">
       <p class="ltx_p" id="A9.I4.i5.p2.1">
        No.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I4.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       6.
      </span>
      <div class="ltx_para" id="A9.I4.i6.p1">
       <p class="ltx_p" id="A9.I4.i6.p1.1">
        Any other comments?
       </p>
      </div>
      <div class="ltx_para" id="A9.I4.i6.p2">
       <p class="ltx_p" id="A9.I4.i6.p2.1">
        None.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
  <section class="ltx_subsection" id="A9.SS6">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.6
    </span>
    Distribution
   </h3>
   <div class="ltx_para" id="A9.SS6.p1">
    <ol class="ltx_enumerate" id="A9.I5">
     <li class="ltx_item" id="A9.I5.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A9.I5.i1.p1">
       <p class="ltx_p" id="A9.I5.i1.p1.1">
        Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created? (If so, please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I5.i1.p2">
       <p class="ltx_p" id="A9.I5.i1.p2.1">
        Yes, the dataset is freely available.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I5.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="A9.I5.i2.p1">
       <p class="ltx_p" id="A9.I5.i2.p1.1">
        How will the dataset will be distributed (e.g., tarball on website, API, GitHub)? (Does the dataset have a digital object identifier (DOI)?)
       </p>
      </div>
      <div class="ltx_para" id="A9.I5.i2.p2">
       <p class="ltx_p" id="A9.I5.i2.p2.1">
        On our website.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I5.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="A9.I5.i3.p1">
       <p class="ltx_p" id="A9.I5.i3.p1.1">
        When will the dataset be distributed?
       </p>
      </div>
      <div class="ltx_para" id="A9.I5.i3.p2">
       <p class="ltx_p" id="A9.I5.i3.p2.1">
        It’s already been distributed.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I5.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="A9.I5.i4.p1">
       <p class="ltx_p" id="A9.I5.i4.p1.1">
        Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)? (If so, please describe this license and/or ToU, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms or ToU, as well as any fees associated with these restrictions.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I5.i4.p2">
       <p class="ltx_p" id="A9.I5.i4.p2.1">
        The dataset is licensed under a CC license.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I5.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       5.
      </span>
      <div class="ltx_para" id="A9.I5.i5.p1">
       <p class="ltx_p" id="A9.I5.i5.p1.1">
        Have any third parties imposed IP-based or other restrictions on the data associated with the instances? (If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms, as well as any fees associated with these restrictions.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I5.i5.p2">
       <p class="ltx_p" id="A9.I5.i5.p2.1">
        Not to our knowledge.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I5.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       6.
      </span>
      <div class="ltx_para" id="A9.I5.i6.p1">
       <p class="ltx_p" id="A9.I5.i6.p1.1">
        Do any export controls or other regulatory restrictions apply to the dataset or to individual instances? (If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any supporting documentation.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I5.i6.p2">
       <p class="ltx_p" id="A9.I5.i6.p2.1">
        Not to our knowledge.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I5.i7" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       7.
      </span>
      <div class="ltx_para" id="A9.I5.i7.p1">
       <p class="ltx_p" id="A9.I5.i7.p1.1">
        Any other comments?
       </p>
      </div>
      <div class="ltx_para" id="A9.I5.i7.p2">
       <p class="ltx_p" id="A9.I5.i7.p2.1">
        None.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
  <section class="ltx_subsection" id="A9.SS7">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.7
    </span>
    Maintenance
   </h3>
   <div class="ltx_para" id="A9.SS7.p1">
    <ol class="ltx_enumerate" id="A9.I6">
     <li class="ltx_item" id="A9.I6.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       1.
      </span>
      <div class="ltx_para" id="A9.I6.i1.p1">
       <p class="ltx_p" id="A9.I6.i1.p1.1">
        Who is supporting/hosting/maintaining the dataset?
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i1.p2">
       <p class="ltx_p" id="A9.I6.i1.p2.1">
        The authors.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I6.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       2.
      </span>
      <div class="ltx_para" id="A9.I6.i2.p1">
       <p class="ltx_p" id="A9.I6.i2.p1.1">
        How can the owner/curator/manager of the dataset be contacted (e.g., email address)?
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i2.p2">
       <p class="ltx_p" id="A9.I6.i2.p2.1">
        We will post our email address.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I6.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       3.
      </span>
      <div class="ltx_para" id="A9.I6.i3.p1">
       <p class="ltx_p" id="A9.I6.i3.p1.1">
        Is there an erratum? (If so, please provide a link or other access point.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i3.p2">
       <p class="ltx_p" id="A9.I6.i3.p2.1">
        Currently, no. As errors are encountered, future versions of the dataset may be released (but will be versioned). They will all be provided in the same location.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I6.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       4.
      </span>
      <div class="ltx_para" id="A9.I6.i4.p1">
       <p class="ltx_p" id="A9.I6.i4.p1.1">
        Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete instances’)? (If so, please describe how often, by whom, and how updates will be communicated to users (e.g., mailing list, GitHub)?)
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i4.p2">
       <p class="ltx_p" id="A9.I6.i4.p2.1">
        Yes.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I6.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       5.
      </span>
      <div class="ltx_para" id="A9.I6.i5.p1">
       <p class="ltx_p" id="A9.I6.i5.p1.1">
        If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances (e.g., were individuals in question told that their data would be retained for a fixed period of time and then deleted)? (If so, please describe these limits and explain how they will be enforced.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i5.p2">
       <p class="ltx_p" id="A9.I6.i5.p2.1">
        No.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I6.i6" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       6.
      </span>
      <div class="ltx_para" id="A9.I6.i6.p1">
       <p class="ltx_p" id="A9.I6.i6.p1.1">
        Will older versions of the dataset continue to be supported/hosted/maintained? (If so, please describe how. If not, please describe how its obsolescence will be communicated to users.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i6.p2">
       <p class="ltx_p" id="A9.I6.i6.p2.1">
        Yes.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I6.i7" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       7.
      </span>
      <div class="ltx_para" id="A9.I6.i7.p1">
       <p class="ltx_p" id="A9.I6.i7.p1.1">
        If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so? (If so, please provide a description. Will these contributions be validated/verified? If so, please describe how. If not, why not? Is there a process for communicating/distributing these contributions to other users? If so, please provide a description.)
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i7.p2">
       <p class="ltx_p" id="A9.I6.i7.p2.1">
        Yes. They can email us.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I6.i8" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       8.
      </span>
      <div class="ltx_para" id="A9.I6.i8.p1">
       <p class="ltx_p" id="A9.I6.i8.p1.1">
        Any other comments?
       </p>
      </div>
      <div class="ltx_para" id="A9.I6.i8.p2">
       <p class="ltx_p" id="A9.I6.i8.p2.1">
        None.
       </p>
      </div>
     </li>
    </ol>
   </div>
  </section>
 </section>
</article>
