<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Yingqiang Ge
    <br class="ltx_break"/>
    Rutgers University
    <br class="ltx_break"/>
    Yujie Ren
    <br class="ltx_break"/>
    Rutgers University
    <br class="ltx_break"/>
    Wenyue Hua
    <br class="ltx_break"/>
    Rutgers University
    <br class="ltx_break"/>
    Shuyuan Xu
    <br class="ltx_break"/>
    Rutgers University
    <br class="ltx_break"/>
    Juntao Tan
    <br class="ltx_break"/>
    Rutgers University
    <br class="ltx_break"/>
    Yongfeng Zhang
    <br class="ltx_break"/>
    Rutgers University
    <br class="ltx_break"/>
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_text ltx_font_bold" id="id1.1.id1">
     Author Affiliation
    </span>
    : Department of Computer Science, Rutgers University, New Brunswick, NJ, 08854, US;
    <span class="ltx_text ltx_font_bold" id="id2.2.id2">
     Author Emails
    </span>
    : {yingqiang.ge,yujie.ren,wenyue.hua,shuyuan.xu,juntao.tan,yongfeng.zhang}@rutgers.edu
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id3.id1">
   This paper envisions a revolutionary AIOS-Agent ecosystem, where Large Language Model (LLM) serves as the (Artificial) Intelligent Operating System (IOS, or AIOS)–an operating system “with soul”. Upon this foundation, a diverse range of LLM-based AI Agent Applications (Agents, or AAPs) are developed, enriching the AIOS-Agent ecosystem and signaling a paradigm shift from the traditional OS-APP ecosystem.
We envision that LLM’s impact will not be limited to the AI application level, instead, it will in turn revolutionize the design and implementation of computer system, architecture, software, and programming language, featured by several main concepts: LLM as OS (system-level), Agents as Applications (application-level), Natural Language as Programming Interface (user-level), and Tools as Devices/Libraries (hardware/middleware-level).
  </p>
  <p class="ltx_p" id="id4.id2">
   In this paper, we begin by introducing the architecture and historical evolution of traditional Operating Systems (OS).
Then we formalize a conceptual framework for AIOS through “LLM as OS (LLMOS),”
   <span class="ltx_note ltx_role_footnote" id="footnote1">
    <sup class="ltx_note_mark">
     1
    </sup>
    <span class="ltx_note_outer">
     <span class="ltx_note_content">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_tag ltx_tag_note">
       1
      </span>
      For convenience, LLMOS may be pronounced as “el-mos”.
     </span>
    </span>
   </span>
   drawing analogies between AIOS components and traditional OS elements: LLM is likened to OS kernel, context window to memory, external storage to file system, hardware tools to peripheral devices, software tools to programming libraries, and user prompts to user commands.
Subsequently, we introduce the new AIOS-Agent Ecosystem, where users and developers can easily program Agent Applications (AAPs) using natural language, democratizing the development of and the access to computer software, which is different from the traditional OS-APP ecosystem, where desktop or mobile applications (APPs) have to be programmed by well-trained software developers using professional programming languages.
Following this, we explore the diverse scope of
Agent Applications. These agents can autonomously
perform diverse tasks, showcasing intelligent task-solving ability in various scenarios.
We delve into both single agent systems and multi-agent systems, as well as human-agent interaction.
Lastly, we posit that the AIOS-Agent ecosystem can gain invaluable insights from the development trajectory of the traditional OS-APP ecosystem. Drawing on these insights, we propose a strategic roadmap for the evolution of the AIOS-Agent ecosystem. This roadmap is designed to guide the future research and development, suggesting systematic progresses of AIOS and its Agent applications.
  </p>
 </div>
 <figure class="ltx_figure" id="S0.F1">
  <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="369" id="S0.F1.g1" src="/html/2312.03815/assets/x1.png" width="369"/>
  <figcaption class="ltx_caption ltx_centering">
   <span class="ltx_tag ltx_tag_figure">
    <span class="ltx_text" id="S0.F1.2.1.1" style="font-size:90%;">
     Figure 1
    </span>
    :
   </span>
   <span class="ltx_text" id="S0.F1.3.2" style="font-size:90%;">
    OS-APP ecosystem vs. AIOS-Agent ecosystem.
   </span>
  </figcaption>
 </figure>
 <nav class="ltx_TOC ltx_list_toc ltx_toc_toc">
  <h6 class="ltx_title ltx_title_contents">
   Contents
  </h6>
  <ol class="ltx_toclist">
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S1" title="In LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       1
      </span>
      Introduction
     </span>
    </a>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S2" title="In LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       2
      </span>
      Aligning LLM and OS
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S2.SS1" title="In 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         2.1
        </span>
        OS and Connections with LLM
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS1.SSS1" title="In 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.1.1
          </span>
          Kernel
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS1.SSS2" title="In 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.1.2
          </span>
          User Interface
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS1.SSS3" title="In 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.1.3
          </span>
          Operating System Ecosystem
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS1.SSS4" title="In 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.1.4
          </span>
          Evolution History of Operating Systems
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S2.SS2" title="In 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         2.2
        </span>
        AIOS, LLMOS and AI Agents
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS2.SSS1" title="In 2.2 AIOS, LLMOS and AI Agents ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.2.1
          </span>
          LLM as OS (system-level)
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS2.SSS2" title="In 2.2 AIOS, LLMOS and AI Agents ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.2.2
          </span>
          Agents as Applications (application-level)
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS2.SSS3" title="In 2.2 AIOS, LLMOS and AI Agents ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.2.3
          </span>
          Natural Language as Programming Interface (user-level)
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S2.SS2.SSS4" title="In 2.2 AIOS, LLMOS and AI Agents ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           2.2.4
          </span>
          Tools as Devices/Libraries (hardware/middleware-level)
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S2.SS3" title="In 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         2.3
        </span>
        Development of OS and AIOS Aligned
       </span>
      </a>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S3" title="In LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       3
      </span>
      Architecture of AIOS
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S3.SS1" title="In 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         3.1
        </span>
        LLM (as AIOS Kernel)
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS1.SSS1" title="In 3.1 LLM (as AIOS Kernel) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.1.1
          </span>
          Reasoning and Planning
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS1.SSS2" title="In 3.1 LLM (as AIOS Kernel) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.1.2
          </span>
          Self-Improving
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S3.SS2" title="In 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         3.2
        </span>
        Context Window (as Memory)
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S3.SS3" title="In 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         3.3
        </span>
        External Storage (as Files)
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS3.SSS1" title="In 3.3 External Storage (as Files) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.3.1
          </span>
          Data Formats
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS3.SSS2" title="In 3.3 External Storage (as Files) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.3.2
          </span>
          Data Retrieval Methods
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S3.SS4" title="In 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         3.4
        </span>
        Tools (as Devices/Libraries)
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS4.SSS1" title="In 3.4 Tools (as Devices/Libraries) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.4.1
          </span>
          Tool Categories
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS4.SSS2" title="In 3.4 Tools (as Devices/Libraries) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.4.2
          </span>
          Tool-Driver and Tool-API
         </span>
        </a>
       </li>
      </ol>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S4" title="In LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       4
      </span>
      AIOS-Agent Ecosystem
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S4.SS1" title="In 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         4.1
        </span>
        Agents as Applications
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S4.SS2" title="In 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         4.2
        </span>
        Natural Language Programming for Agents
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S4.SS3" title="In 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         4.3
        </span>
        The Ecosystem
       </span>
      </a>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S5" title="In LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       5
      </span>
      LLMOS in Practice: AI Agents
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S5.SS1" title="In 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         5.1
        </span>
        Single Agent Applications
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS1.SSS1" title="In 5.1 Single Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.1.1
          </span>
          Physical Environment
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS1.SSS2" title="In 5.1 Single Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.1.2
          </span>
          Virtual/Digital Environment
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S5.SS2" title="In 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         5.2
        </span>
        Multi-Agent Applications
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS2.SSS1" title="In 5.2 Multi-Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.2.1
          </span>
          Collaborative Interaction
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS2.SSS2" title="In 5.2 Multi-Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.2.2
          </span>
          Adversarial Interaction
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S5.SS3" title="In 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         5.3
        </span>
        Human-Agent Applications
       </span>
      </a>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S6" title="In LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       6
      </span>
      OS-inspired Future Directions
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S6.SS1" title="In 6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         6.1
        </span>
        Resource Management
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S6.SS1.SSS1" title="In 6.1 Resource Management ‣ 6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           6.1.1
          </span>
          Memory Management
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S6.SS1.SSS2" title="In 6.1 Resource Management ‣ 6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           6.1.2
          </span>
          Tool Management
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S6.SS2" title="In 6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         6.2
        </span>
        Communication
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S6.SS3" title="In 6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         6.3
        </span>
        Security
       </span>
      </a>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S7" title="In LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       7
      </span>
      Conclusions
     </span>
    </a>
   </li>
  </ol>
 </nav>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    In the evolving landscape of information technology, Operating Systems (OS) such as Windows
    <span class="ltx_note ltx_role_footnote" id="footnote2">
     <sup class="ltx_note_mark">
      2
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        2
       </sup>
       <span class="ltx_tag ltx_tag_note">
        2
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/windows/" target="_blank" title="">
        https://www.microsoft.com/en-us/windows/
       </a>
      </span>
     </span>
    </span>
    , MacOS
    <span class="ltx_note ltx_role_footnote" id="footnote3">
     <sup class="ltx_note_mark">
      3
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        3
       </sup>
       <span class="ltx_tag ltx_tag_note">
        3
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.apple.com/macos/" target="_blank" title="">
        https://www.apple.com/macos/
       </a>
      </span>
     </span>
    </span>
    , iOS
    <span class="ltx_note ltx_role_footnote" id="footnote4">
     <sup class="ltx_note_mark">
      4
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        4
       </sup>
       <span class="ltx_tag ltx_tag_note">
        4
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.apple.com/ios/" target="_blank" title="">
        https://www.apple.com/ios/
       </a>
      </span>
     </span>
    </span>
    , and Android
    <span class="ltx_note ltx_role_footnote" id="footnote5">
     <sup class="ltx_note_mark">
      5
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        5
       </sup>
       <span class="ltx_tag ltx_tag_note">
        5
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.android.com/" target="_blank" title="">
        https://www.android.com/
       </a>
      </span>
     </span>
    </span>
    have become cornerstones of our digital lives.
On top of the operating systems, a diverse range of applications (APPs) are developed, helping with users’ diverse tasks and enriching the OS-APP ecosystem.
For example, Microsoft Word
    <span class="ltx_note ltx_role_footnote" id="footnote6">
     <sup class="ltx_note_mark">
      6
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        6
       </sup>
       <span class="ltx_tag ltx_tag_note">
        6
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/microsoft-365/word/" target="_blank" title="">
        https://www.microsoft.com/en-us/microsoft-365/word/
       </a>
      </span>
     </span>
    </span>
    and Google Docs
    <span class="ltx_note ltx_role_footnote" id="footnote7">
     <sup class="ltx_note_mark">
      7
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        7
       </sup>
       <span class="ltx_tag ltx_tag_note">
        7
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.google.com/docs/about/" target="_blank" title="">
        https://www.google.com/docs/about/
       </a>
      </span>
     </span>
    </span>
    excel in drafting documents, while Microsoft Outlook
    <span class="ltx_note ltx_role_footnote" id="footnote8">
     <sup class="ltx_note_mark">
      8
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        8
       </sup>
       <span class="ltx_tag ltx_tag_note">
        8
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/microsoft-365/outlook/" target="_blank" title="">
        https://www.microsoft.com/en-us/microsoft-365/outlook/
       </a>
      </span>
     </span>
    </span>
    and Gmail
    <span class="ltx_note ltx_role_footnote" id="footnote9">
     <sup class="ltx_note_mark">
      9
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        9
       </sup>
       <span class="ltx_tag ltx_tag_note">
        9
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.google.com/gmail/about/" target="_blank" title="">
        https://www.google.com/gmail/about/
       </a>
      </span>
     </span>
    </span>
    offer efficient email management.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Operating systems have advanced significantly, becoming more intuitive and user-friendly, yet their core remains rooted in static rules and predefined logic flows, without the intelligent, creative, and emergent task-solving abilities. The applications built on top of such OS, on the other hand,
are also limited to their designed purposes, unable to transcend beyond their individual scopes. Whenever individual applications need to incorporate intelligent abilities, they have to implement their own AI methods or functionalities, sometimes based on third-party libraries.
This isolated framework underscores a significant shortfall in the current OS-APP ecosystem and highlights the pressing need of infusing (artificial) intelligence into operating systems, so that intelligence can be natively distributed to the various applications built on top of it.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    As a result, this paper envisions (Artificial) Intelligent Operating System (IOS, or AIOS), an operating system “with soul”. Furthermore, a diverse scope of intelligent Agent applications are built on top of the AIOS, leading to the new AIOS-Agent ecosystem, in comparison to the traditional OS-APP ecosystem, as shown in Figure
    <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    .
Due to the versatile and remarkable capabilities they demonstrate, Large Language Models (LLMs)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Radford et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib84" title="">
      2019
     </a>
     ; Brown et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2020
     </a>
     ; Touvron et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib107" title="">
      2023
     </a>
     ; Taori et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib106" title="">
      2023
     </a>
     )
    </cite>
    are regarded as potential sparks for Artificial General Intelligence (AGI)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Bubeck et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      2023
     </a>
     ; Morris et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib67" title="">
      2023
     </a>
     ; Ge et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2023
     </a>
     )
    </cite>
    , offering hope as foundational elements for the development of AIOS.
There are several reasons confirming LLMs’ general capability and feasibility for building AIOS:
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       First, LLMs have demonstrated exceptional language understanding abilities as well as reasoning/planning abilities to solve complex tasks, which can divide the tasks into several sub-tasks and conquer them one-by-one, sometimes with the assistance of external tools
       <cite class="ltx_cite ltx_citemacro_citep">
        (Ge et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib35" title="">
         2023
        </a>
        ; Wei et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib121" title="">
         2022
        </a>
        ; Huang and Chang,
        <a class="ltx_ref" href="#bib.bib45" title="">
         2022
        </a>
        )
       </cite>
       .
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       Second, LLMs offer a highly flexible platform to process virtually any prompt, instruction, or query expressed in natural language, making it possible for a diverse range of Software Development Kits (SDKs) and/or applications to be built on top of them.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       Third, LLMs offer a more intuitive and user-friendly interface, since they can understand and respond to user prompts or instructions in natural language
       <cite class="ltx_cite ltx_citemacro_citep">
        (Brown et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib12" title="">
         2020
        </a>
        ; Touvron et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib107" title="">
         2023
        </a>
        )
       </cite>
       . This sheds light on the future where natural language serves as the programming language, making technology more accessible, especially for those who may not be familiar with traditional computer interfaces and programming languages.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i4.p1">
      <p class="ltx_p" id="S1.I1.i4.p1.1">
       Fourth, LLMs can be programmed to learn from interactions and customize their responses based on user preferences and past interactions, providing a more personalized experience
       <cite class="ltx_cite ltx_citemacro_citep">
        (Safdari et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib91" title="">
         2023
        </a>
        ; Durmus et al
        <span class="ltx_text">
         .
        </span>
        ,
        <a class="ltx_ref" href="#bib.bib28" title="">
         2023
        </a>
        )
       </cite>
       .
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    As a result, infusing intelligence into the OS-level through LLM makes it possible for easily distributing intelligent abilities into the application-level, providing a promising way to democratize intelligence across various applications.
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F2">
   <div class="ltx_flex_figure">
    <div class="ltx_flex_cell ltx_flex_size_1">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf1">
      <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="323" id="S1.F2.sf1.g1" src="/html/2312.03815/assets/x2.png" width="461"/>
      <figcaption class="ltx_caption">
       <span class="ltx_tag ltx_tag_figure">
        <span class="ltx_text" id="S1.F2.sf1.2.1.1" style="font-size:90%;">
         (a)
        </span>
       </span>
       <span class="ltx_text" id="S1.F2.sf1.3.2" style="font-size:90%;">
        Architecture of Operating System (OS).
       </span>
      </figcaption>
     </figure>
    </div>
    <div class="ltx_flex_break">
    </div>
    <div class="ltx_flex_cell ltx_flex_size_1">
     <figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf2">
      <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="248" id="S1.F2.sf2.g1" src="/html/2312.03815/assets/x3.png" width="461"/>
      <figcaption class="ltx_caption">
       <span class="ltx_tag ltx_tag_figure">
        <span class="ltx_text" id="S1.F2.sf2.2.1.1" style="font-size:90%;">
         (b)
        </span>
       </span>
       <span class="ltx_text" id="S1.F2.sf2.3.2" style="font-size:90%;">
        Architecture of Large Language Model as OS (LLMOS) for AIOS.
       </span>
      </figcaption>
     </figure>
    </div>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     <span class="ltx_text" id="S1.F2.2.1.1" style="font-size:90%;">
      Figure 2
     </span>
     :
    </span>
    <span class="ltx_text" id="S1.F2.3.2" style="font-size:90%;">
     Illustrations of the architectures of OS and AIOS (LLMOS).
    </span>
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    Inspired by the architecture of traditional OS (as shown in Figure.
    <a class="ltx_ref" href="#S1.F2.sf1" title="Figure 2(a) ‣ Figure 2 ‣ 1 Introduction ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      2(a)
     </span>
    </a>
    ), we present a general framework for
    <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">
     LLM as OS (LLMOS)
    </span>
    with several key components in Section
    <a class="ltx_ref" href="#S3" title="3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    (as shown in Figure.
    <a class="ltx_ref" href="#S1.F2.sf2" title="Figure 2(b) ‣ Figure 2 ‣ 1 Introduction ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      2(b)
     </span>
    </a>
    ): LLM as Kernel, Context Window as Memory, External Storage as File, Tools as Devices/Libraries, User Prompt/Instruction as User Interface (UI), and Agents as Applications.
The conceptual framework presented draws an analogy between an LLM as OS (LLMOS) and a traditional Operating System (OS), mapping various components of the LLMOS to elements of an OS. The LLM itself is likened to the kernel, the central part managing the system’s core functions. The LLM’s context window is compared to the memory of an OS, handling immediate context selection and data processing
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shi et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib96" title="">
      2023
     </a>
     )
    </cite>
    . External storage for the LLM is analogous to the files of an OS, allowing for long-term data storage. Meanwhile, there are corresponding data retrieval methods to enable retrieval-augmented LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Guu et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib39" title="">
      2020
     </a>
     )
    </cite>
    , which serve as the file system of OS to manage and find relevant files. Besides, LLM can make use of various tools for task solving
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ge et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2023
     </a>
     )
    </cite>
    , including both hardware tools and software tools. Hardware tools in the LLMOS framework are equated to peripheral devices in a traditional OS, each offering specific functionalities to help interact with the physical world, while software tools in the LLMOS framework serve as the programming libraries in traditional OS, enabling Agent applications to interact with the virtual/digital world. User prompts or instructions for the LLM are akin to the user interface (UI) in a traditional OS, facilitating interaction between the user and the system. The user prompts or instructions can be direct natural language instructions provided by the user, and they may also be (sometimes semi-structured) natural language instructions converted from users’ non-natural language instructions such as clicking on icons.
This mapping provides a systematic way to understand the operational similarities between LLMOS-based AIOS and traditional OS.
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    Upon establishing a robust conceptual framework for LLMOS-based AIOS, we introduce the AIOS-Agent Ecosystem, akin to the traditional OS-APP Ecosystem, in Section
    <a class="ltx_ref" href="#S4" title="4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    . We begin by introducing the concept of Agent Applications (AAPs) within LLMOS, analogous to traditional applications (APPs) based on an operating system. These AAPs represent a diverse scope of specialized tasks for users to execute based on LLMOS. As illustrated in Figure
    <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4.1 Agents as Applications ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    , by integrating the LLMOS layer with the OS layer, Hardware layer, and the Agent Application layer, we can construct an autonomous AI Agent system. Such AI Agent system responds to user prompts or instructions in natural language and is capable of performing a multitude of tasks based on its interaction with the physical or digital environment. Since a diverse scope of Agents can be developed on top of the shared AIOS foundation, this eventually leads to an AIOS-Agent ecosystem. Moreover, in the new AIOS-Agent Ecosystem, the users and developers can easily program Agent Applications (AAPs) using natural language, democratizing the development of and the access to computer software, which is different from the traditional OS-APP ecosystem, where desktop or mobile applications (APPs) have to be programmed by well-trained software developers using professional programming languages.
   </p>
  </div>
  <div class="ltx_para" id="S1.p7">
   <p class="ltx_p" id="S1.p7.1">
    Following this, we further delve into the practical LLMOS-based Agent Applications in Section
    <a class="ltx_ref" href="#S5" title="5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    . This section explores the potential of enhancing LLMOS’s functionality by developing various agents in the real world, and further investigates the dynamic interactions between multiple agents and humans.
LLMOS-based agents are characterized by their creative autonomy, enabling them to generate novel ideas, narratives, or solutions not pre-programmed into them
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib15" title="">
      2022
     </a>
     ; Gravitas,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023
     </a>
     ; Ge et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2023
     </a>
     ; Li et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib58" title="">
      2023
     </a>
     ; Yao et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib132" title="">
      2022b
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib129" title="">
      a
     </a>
     )
    </cite>
    , which is indicative of an advanced level of creative intelligence
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yuan et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib134" title="">
      2022
     </a>
     ; Franceschelli and Musolesi,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2023
     </a>
     )
    </cite>
    . Specifically, Section
    <a class="ltx_ref" href="#S5.SS1" title="5.1 Single Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      5.1
     </span>
    </a>
    discusses applications of single agents, Section
    <a class="ltx_ref" href="#S5.SS2" title="5.2 Multi-Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      5.2
     </span>
    </a>
    explores multi-agent systems, and Section
    <a class="ltx_ref" href="#S5.SS3" title="5.3 Human-Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      5.3
     </span>
    </a>
    focuses on human-agent interactions.
   </p>
  </div>
  <div class="ltx_para" id="S1.p8">
   <p class="ltx_p" id="S1.p8.1">
    Finally, in Section
    <a class="ltx_ref" href="#S6" title="6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    , we explore several crucial future research directions for LLMOS and AIOS in general, drawing parallels and learning from the evolution of traditional operating systems. These directions span a wide array of areas, aiming to enhance the capabilities and applications of LLMOS: 1)
    <span class="ltx_text ltx_font_bold" id="S1.p8.1.1">
     Resource Management.
    </span>
    For example, OS employs virtual and shared memories to address the issue of limited physical memory. LLMOS can inspire from these ideas to mitigate its own problem of limited context window challenges; 2)
    <span class="ltx_text ltx_font_bold" id="S1.p8.1.2">
     Communication.
    </span>
    Different OSes and applications communicate using standardized protocols (such as Domain-Specific Languages); LLMOSes and Agents can build and use similar standard protocols for exchanging data and instructions with various systems, ensuring compatibility and smooth interaction across diverse platforms;
3)
    <span class="ltx_text ltx_font_bold" id="S1.p8.1.3">
     Security.
    </span>
    Security vulnerabilities in OS are important issues. State-of-the-art approaches aim to detect and capture malware and viruses at various levels. Similarly, LLMOS can implement detection and intervention mechanisms to regulate and monitor the implementation of third-party tools and Agent Applications.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Aligning LLM and OS
  </h2>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    OS and Connections with LLM
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     The von Neaumann architecture, laying the foundation of modern computer hardware system, manipulate electrons and gates in the binary world, whereas human beings communicate with natural languages. Such gigantic semantic gaps between human users and computer hardware motivates an intermediary software layer interacting with users with a protected and abstracted view of underlying hardware resources such as CPU (Central Processing Unit), GPU (Graphics Processing Unit), RAM (Random Access Memory), storage and various other devices, which is called the Operating System (OS). The modern operating systems, over the past few decades, have evolved in a multi-layered architecture with modular components in each layer. This design not only enhances the efficiency and functionality of the systems but also facilitates easier management, scalability, and integration of diverse hardware and software elements.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.1.1
     </span>
     Kernel
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS1.p1">
     <p class="ltx_p" id="S2.SS1.SSS1.p1.1">
      The kernel, as its name suggests, encapsulates a set of core functionalities of managing hardware resources (e.g., CPU, GPU, DRAM, storage, and devices) as a nutshell.
      <span class="ltx_note ltx_role_footnote" id="footnote10">
       <sup class="ltx_note_mark">
        10
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          10
         </sup>
         <span class="ltx_tag ltx_tag_note">
          10
         </span>
         We limit our scope to traditional monolithic kernel design.
        </span>
       </span>
      </span>
     </p>
    </div>
    <div class="ltx_para" id="S2.SS1.SSS1.p2">
     <ul class="ltx_itemize" id="S2.I1">
      <li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I1.i1.p1">
        <p class="ltx_p" id="S2.I1.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">
          CPU Management
         </span>
         (Process/Thread, scheduling). To manage the CPU resources, modern operating systems abstract the execution of user programs or applications on a physical CPU as processes or threads. When the user launches an application, the operating system kernel loads the executable binary files of this application or program into DRAM, create the necessary data structures to book-keep any running states for this program, and allocate necessary resources.
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i1.p2">
        <p class="ltx_p" id="S2.I1.i1.p2.1">
         However, the power wall
         <cite class="ltx_cite ltx_citemacro_citep">
          (Agarwal et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib2" title="">
           2006
          </a>
          )
         </cite>
         limits the number of physical CPUs to be integrated into a single chip. To provide users with the illusion that they possess physical CPUs without sharing with others, modern operating systems multiplex the running processes or threads with limited number of CPUs with time-sharing
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ritchie and Thompson,
          <a class="ltx_ref" href="#bib.bib85" title="">
           1974
          </a>
          )
         </cite>
         and more dedicated policies
         <cite class="ltx_cite ltx_citemacro_citep">
          (Molnár,
          <a class="ltx_ref" href="#bib.bib66" title="">
           2007
          </a>
          ; Stoica and Abdel-Wahab,
          <a class="ltx_ref" href="#bib.bib100" title="">
           1995
          </a>
          )
         </cite>
         , much like multiple users share the same LLM backbone when processing their prompts or instructions. In such cases, if the inputs from multiple users are beyond the capacity of the resources, such as the tools, then the LLM may perform scheduling of the user prompts.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I1.i2.p1">
        <p class="ltx_p" id="S2.I1.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">
          Memory Management.
         </span>
         The physical memory in a computer, also known as DRAM (Dynamic Random Access Memory), is the key component to store the instructions and data of both the OS and applications. The OS is responsible for managing and allocating free space in the physical memory from application’s requests.
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i2.p2">
        <p class="ltx_p" id="S2.I1.i2.p2.1">
         As described above, the physical memory, depicted as “dynamic,” cannot store data persistently when power is off, as it needs to refresh periodically to prevent the loss of data. In addition to its volatile nature, the evolution of memory falls behind the CPU for a long time, which is known for “The memory wall”. This fact lays in two orthogonal aspects. First, the data transfer rate between DRAM and CPU can no longer catch up with the speed that CPU processes data. Second, the memory capacity on a single node stops scaling. Although the emergence of Compute eXpress Link
         <cite class="ltx_cite ltx_citemacro_citep">
          (CXL,
          <a class="ltx_ref" href="#bib.bib24" title="">
           2023
          </a>
          )
         </cite>
         alleviates the memory capacity wall, it still cannot keep the rapid pace of data growth at the artificial intelligence era.
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i2.p3">
        <p class="ltx_p" id="S2.I1.i2.p3.1">
         This is much like the context window of LLMs, which is usually limited by the maximum number of tokens that the LLM can handle. Besides, LLM usually needs to select the relevant information from the input context, since not all contexts are relevant for the current task and LLM may be easily distracted by irrelevant contexts
         <cite class="ltx_cite ltx_citemacro_citep">
          (Shi et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib96" title="">
           2023
          </a>
          )
         </cite>
         . Context selection can be either implicitly realized through attention mechanisms, or be explicitly implemented by selecting relevant segments from the input context, much like the memory management process by traditional OS.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I1.i3.p1">
        <p class="ltx_p" id="S2.I1.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">
          Storage Management.
         </span>
         Storage devices, which store data persistently, provide much more density than memory with fewer cost, but much slower. The operating systems abstract the storage as file, and organize files in a systematic way with a component called the “file system”. The file system contains the meta-data to index the actual data stored on the storage media.
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i3.p2">
        <p class="ltx_p" id="S2.I1.i3.p2.1">
         In addition to the file abstract, modern operating systems reserve a small portion of storage as an extension of memory, which is called the “swap area”. It is the operating system that tracks the hotness and coldness of the data from user applications, and swaps code data from physical memory to the swap area on the storage devices.
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i3.p3">
        <p class="ltx_p" id="S2.I1.i3.p3.1">
         Similarly, LLM often has access to external data storage for retrieval-augmented language modeling
         <cite class="ltx_cite ltx_citemacro_citep">
          (Guu et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib39" title="">
           2020
          </a>
          )
         </cite>
         . These external data can be free text data, structured tabular data, semi-structured graph data, or others. Furthermore, the external data are usually properly indexed for efficient and accurate retrieval, much like the storage management process of traditional operating systems.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I1.i4.p1">
        <p class="ltx_p" id="S2.I1.i4.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">
          Device Management.
         </span>
         Peripheral devices, often excluded from the core computing system of CPU and DRAM, form an important set of functionalities for user input and output. Those devices range from mouse, keyboard, to GPU and network interface cards (NIC). The operating systems take the responsibility to manage those devices to orchestrate with other core components in the OS kernel.
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i4.p2">
        <p class="ltx_p" id="S2.I1.i4.p2.1">
         There are thousands of different devices for different purposes and from different vendors all around the world. Hence, it is not possible to implement the driver program for all of those devices. Instead, modern operating systems expose a generic interface as device driver APIs for device vendors, and thus shifts the responsibility of developing device driver programs from OS maintainers to vendors of those devices. To provide a ’plug-and-play’ feature, modern operating systems such as Linux include some universal and necessary device drivers for some common devices; for example, the drivers for GPU and USB devices
         <cite class="ltx_cite ltx_citemacro_citep">
          (Corbet et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib21" title="">
           2005
          </a>
          )
         </cite>
         .
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i4.p3">
        <p class="ltx_p" id="S2.I1.i4.p3.1">
         Similarly, large language models are not only text-in-text-out models, instead, they have the ability of leveraging various tools for solving complex tasks
         <cite class="ltx_cite ltx_citemacro_citep">
          (Schick et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib93" title="">
           2023
          </a>
          ; Ge et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib35" title="">
           2023
          </a>
          )
         </cite>
         . There can be two types of tools, hardware tools and software tools, which help the LLM to interact with the physical world and the digital world, respectively. In this context, the hardware tools for LLM are similar to the devices for traditional OS. Furthermore, just like driver programs connect devices with OS, Tool-Drivers can be developed to connect LLM and hardware tools, so that LLM can easily leverage the tools for task-solving. We will discuss software tools in the following.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I1.i5.p1">
        <p class="ltx_p" id="S2.I1.i5.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">
          SDK and Programming Libraries.
         </span>
         The SDK (Software Development Kit) and programming libraries of an operating system are crucial tools that enable developers to easily create applications.
They serve as the backbone of application development for operating systems, not only enabling and simplifying the creation of applications, but also ensuring that these applications are secure, efficient and compatible with the OS, which significantly contribute to the vitality and growth of the OS-APP ecosystem.
        </p>
       </div>
       <div class="ltx_para" id="S2.I1.i5.p2">
        <p class="ltx_p" id="S2.I1.i5.p2.1">
         Similarly, LLM and the various AI Agents built on top of it can make use of various software tools such as searching on the web, checking for weather conditions, and booking for flight tickets
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ge et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib35" title="">
           2023
          </a>
          )
         </cite>
         . These software tools serve as reusable functionalities that can be leveraged by LLM and Agents for complex task-solving, and they can be provided as SDK or programming libraries so that users or developers can easily use them.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.1.2
     </span>
     User Interface
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS2.p1">
     <p class="ltx_p" id="S2.SS1.SSS2.p1.1">
      As detailed previously, the kernel manages the hardware resources with proper abstraction for user to utilize. In order to enhance the accessibility of virtualized hardware resources, it is crucial to establish an interface between user and OS.
     </p>
    </div>
    <div class="ltx_para" id="S2.SS1.SSS2.p2">
     <ul class="ltx_itemize" id="S2.I2">
      <li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I2.i1.p1">
        <p class="ltx_p" id="S2.I2.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">
          System Call.
         </span>
         The system call, as the channel between OS kernel and users, defines a set of core functions to allocate and use the virtualized hardware resources. For instance, in a POSIX-compliant operating system
         <cite class="ltx_cite ltx_citemacro_citep">
          (IEEE and Group,
          <a class="ltx_ref" href="#bib.bib47" title="">
           2018
          </a>
          )
         </cite>
         , the
         <span class="ltx_text ltx_font_typewriter" id="S2.I2.i1.p1.1.2">
          mmap
         </span>
         system call allocates and manipulates memory resources. The
         <span class="ltx_text ltx_font_typewriter" id="S2.I2.i1.p1.1.3">
          fork
         </span>
         and
         <span class="ltx_text ltx_font_typewriter" id="S2.I2.i1.p1.1.4">
          exec
         </span>
         system call family deals with process and thread creation. The
         <span class="ltx_text ltx_font_typewriter" id="S2.I2.i1.p1.1.5">
          read
         </span>
         and
         <span class="ltx_text ltx_font_typewriter" id="S2.I2.i1.p1.1.6">
          write
         </span>
         system call are used to interact with storage devices. In terms of LLMs, the system calls can be formulated as natural language prompts into instruct the LLM for task execution.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I2.i2.p1">
        <p class="ltx_p" id="S2.I2.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.1.1">
          Command-line Interface (CLI).
         </span>
         The command-line interface defines a set of utility programs built on top of system calls to facilitate users to operate on the computer hardware in an interactive manner. Users interact with the OS in those utility programs as commands. For instance, the
         <span class="ltx_text ltx_font_typewriter" id="S2.I2.i2.p1.1.2">
          cd
         </span>
         and
         <span class="ltx_text ltx_font_typewriter" id="S2.I2.i2.p1.1.3">
          ls
         </span>
         commands implement the action of entering a directory and list all the files and folders in a directory. In the context of LLM, natural language prompts naturally serve as the interface for users to interact with LLMs. Furthermore, the LLM may also pre-define some foundational and commonly used functionalities as standard prompt templates for users to use, similar to the standard commands as in traditional OS.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I2.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I2.i3.p1">
        <p class="ltx_p" id="S2.I2.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I2.i3.p1.1.1">
          Graphic User Interface (GUI).
         </span>
         The graphic user interface is a visual way for users to interact with computers and electronic devices using graphical elements such as icons, buttons, windows, and menus, as opposed to a text-based interface such as a command-line interface. GUIs make it easier for users to interact with complex systems by representing actions through visual elements and providing a more intuitive user experience, especially with the increasing demand and use of mobile devices such as smart phones discussed in
         <a class="ltx_ref" href="#S2.SS1.SSS4" title="2.1.4 Evolution History of Operating Systems ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
          <span class="ltx_text ltx_ref_tag">
           section
          </span>
          <span class="ltx_text ltx_ref_tag">
           2.1.4
          </span>
         </a>
         . In terms of LLMs, graphic user interfaces can also be developed for LLM and Agents so that users can more conveniently interact with them without the need to writing long prompts. Instead, these GUIs will convert user’s non-language instructions (such as clicking on icons) into (sometimes semi-structured) natural language prompts based on pre-defined prompt templates, and these converted natural language prompts will be sent to LLM for executing the user instruction.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.1.3
     </span>
     Operating System Ecosystem
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS3.p1">
     <p class="ltx_p" id="S2.SS1.SSS3.p1.1">
      The operating system ecosystem functions as an extension of the operating system, providing a comprehensive set of developer tool-kits (OS SDK) and runtime libraries, shown in Figure
      <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      . These tools empower application developers to efficiently design, implement, and run their applications within the operating system environment. For instance, the well-known iOS ecosystem includes a dedicated application development toolkit known as Xcode
      <span class="ltx_note ltx_role_footnote" id="footnote11">
       <sup class="ltx_note_mark">
        11
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          11
         </sup>
         <span class="ltx_tag ltx_tag_note">
          11
         </span>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://developer.apple.com/xcode/" target="_blank" title="">
          https://developer.apple.com/xcode/
         </a>
        </span>
       </span>
      </span>
      , alongside an application publishing platform called the AppStore
      <span class="ltx_note ltx_role_footnote" id="footnote12">
       <sup class="ltx_note_mark">
        12
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          12
         </sup>
         <span class="ltx_tag ltx_tag_note">
          12
         </span>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.apple.com/app-store/" target="_blank" title="">
          https://www.apple.com/app-store/
         </a>
        </span>
       </span>
      </span>
      , complementing the core iOS ecosystem. In this ecosystem, the OS provides a bunch of resources to support APP development and also services as the platform for deploying and hosting these APPs, which eventually leads to a prospering OS-APP ecosystem.
     </p>
    </div>
    <div class="ltx_para" id="S2.SS1.SSS3.p2">
     <p class="ltx_p" id="S2.SS1.SSS3.p2.1">
      Similarly, we envision an AIOS-Agent ecosystem, where LLM serves as the operating system and hosts a diverse range of AI Agent applications, as shown in Figure
      <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      . The LLM as OS (LLMOS) environment shall also provide a comprehensive set of AIOS SDKs and/or libraries, predominately supporting programming in natural language, to help developers or even average users without any knowledge on professional programming languages, to easily develop and deploy Agent applications in the LLMOS-based AIOS-Agent ecosystem.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS1.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.1.4
     </span>
     Evolution History of Operating Systems
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS4.p1">
     <ul class="ltx_itemize" id="S2.I3">
      <li class="ltx_item" id="S2.I3.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I3.i1.p1">
        <p class="ltx_p" id="S2.I3.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I3.i1.p1.1.1">
          Batch Processing System.
         </span>
         Early batch processing systems were a fundamental aspect of the early days of computing, dating back to 1950s
         <cite class="ltx_cite ltx_citemacro_citep">
          (UW:CSE451,
          <a class="ltx_ref" href="#bib.bib108" title="">
           2023
          </a>
          )
         </cite>
         . These systems were characterized by a sequential execution of tasks, where jobs were submitted in batches for processing. Early batch processing systems laid the groundwork for subsequent developments in operating systems. While lacking the interactivity and responsiveness of modern systems, they played a crucial role in advancing computing capabilities and setting the stage for more interactive and user-friendly computing environments in the years to come.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I3.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I3.i2.p1">
        <p class="ltx_p" id="S2.I3.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I3.i2.p1.1.1">
          Time Sharing.
         </span>
         Time-sharing systems
         <cite class="ltx_cite ltx_citemacro_citep">
          (UW:CSE451,
          <a class="ltx_ref" href="#bib.bib108" title="">
           2023
          </a>
          )
         </cite>
         , as proposed in
         <span class="ltx_text ltx_font_italic" id="S2.I3.i2.p1.1.2">
          Multics
         </span>
         <cite class="ltx_cite ltx_citemacro_citep">
          (Corbató et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib20" title="">
           1971
          </a>
          )
         </cite>
         represent a significant advancement in the history of operating systems, providing a departure from traditional batch processing systems and introducing the concept of shared, interactive computing. Many concepts introduced in time-sharing systems, such as multitasking, interactive interfaces, and dynamic resource allocation, have become integral parts of modern operating systems, which laid the groundwork for user-friendly computing environments, enabling efficient resource utilization and interactive computing.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I3.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I3.i3.p1">
        <p class="ltx_p" id="S2.I3.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I3.i3.p1.1.1">
          Multitasking.
         </span>
         As the hardware evolved to multiple cores, planning user tasks on available multi-core CPU is critical to maximize the CPU utiliztion. Multitasking involves scheduling processes to run on the CPU in a way that gives the appearance of concurrent execution. Process scheduling algorithms determine the order in which processes are executed. The UNIX operating system
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ritchie and Thompson,
          <a class="ltx_ref" href="#bib.bib85" title="">
           1974
          </a>
          )
         </cite>
         , developed in the late 1960s and early 1970s at Bell Labs, introduced the concept of processes, each with its own address space, and implemented a simple and efficient multitasking model.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I3.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I3.i4.p1">
        <p class="ltx_p" id="S2.I3.i4.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I3.i4.p1.1.1">
          Visualization (GUI).
         </span>
         As described previously in
         <a class="ltx_ref" href="#S2.SS1.SSS2" title="2.1.2 User Interface ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
          <span class="ltx_text ltx_ref_tag">
           section
          </span>
          <span class="ltx_text ltx_ref_tag">
           2.1.2
          </span>
         </a>
         , the command-line interface used to be the narrow bridge between users to interact with OS. Since command lines are highly professional, it prevented broader groups of users from easily and efficiently operating the computers. From Xerox Alto introduced by Palo Alto Research Center (PARC) in 1973
         <span class="ltx_note ltx_role_footnote" id="footnote13">
          <sup class="ltx_note_mark">
           13
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             13
            </sup>
            <span class="ltx_tag ltx_tag_note">
             13
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://spectrum.ieee.org/xerox-alto" target="_blank" title="">
             https://spectrum.ieee.org/xerox-alto
            </a>
           </span>
          </span>
         </span>
         , to Apple Macintosh introduced in 1984
         <span class="ltx_note ltx_role_footnote" id="footnote14">
          <sup class="ltx_note_mark">
           14
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             14
            </sup>
            <span class="ltx_tag ltx_tag_note">
             14
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://apple-history.com/128k" target="_blank" title="">
             http://apple-history.com/128k
            </a>
           </span>
          </span>
         </span>
         , to Microsoft Windows
         <span class="ltx_note ltx_role_footnote" id="footnote15">
          <sup class="ltx_note_mark">
           15
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             15
            </sup>
            <span class="ltx_tag ltx_tag_note">
             15
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://winworldpc.com/product/windows-3/31" target="_blank" title="">
             https://winworldpc.com/product/windows-3/31
            </a>
           </span>
          </span>
         </span>
         introduced in the early 1990s, and to a wide range of open-source GUIs for Linux such as GNOME
         <span class="ltx_note ltx_role_footnote" id="footnote16">
          <sup class="ltx_note_mark">
           16
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             16
            </sup>
            <span class="ltx_tag ltx_tag_note">
             16
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.gnome.org/" target="_blank" title="">
             https://www.gnome.org/
            </a>
           </span>
          </span>
         </span>
         , KDE
         <span class="ltx_note ltx_role_footnote" id="footnote17">
          <sup class="ltx_note_mark">
           17
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             17
            </sup>
            <span class="ltx_tag ltx_tag_note">
             17
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kde.org/" target="_blank" title="">
             https://www.kde.org/
            </a>
           </span>
          </span>
         </span>
         and UNITY
         <span class="ltx_note ltx_role_footnote" id="footnote18">
          <sup class="ltx_note_mark">
           18
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             18
            </sup>
            <span class="ltx_tag ltx_tag_note">
             18
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://unityd.org/" target="_blank" title="">
             https://unityd.org/
            </a>
           </span>
          </span>
         </span>
         , the development of GUIs has significantly influenced the accessibility and usability of computers, making computing more intuitive and user-friendly.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I3.i5" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I3.i5.p1">
        <p class="ltx_p" id="S2.I3.i5.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I3.i5.p1.1.1">
          Cloud Computing.
         </span>
         Performing data computing and storage on a single computing node was no longer sufficient as the data scale grew significantly in the early 2010s. The development of client-server architecture in the early 1990s, where multiple clients connect to centralized servers, laid the foundation for distributed computing with the support of networked environments and the communication between clients and servers that emerged as OS core functionalities.
More technologies such as virtualization and resource disaggregation empower the modern cloud computing community and market.
Though cloud computing is not directly tied to the history of operating systems, the evolution of cloud computing has had a profound impact on how operating systems are designed, deployed, and utilized.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I3.i6" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I3.i6.p1">
        <p class="ltx_p" id="S2.I3.i6.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I3.i6.p1.1.1">
          Mobile and Embedded Systems.
         </span>
         Aligning with the Moore’s law, the size and the computing power of a general-purpose CPU redefines the capability of modern embedded devices. Tailored for operating on a relatively constrained computing resource, modern mobile OS are specifically focused on power efficiency, network efficiency, optimized graphics for touch screen, and the prospering application ecosystem (detailed in
         <a class="ltx_ref" href="#S2.SS1.SSS3" title="2.1.3 Operating System Ecosystem ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
          <span class="ltx_text ltx_ref_tag">
           section
          </span>
          <span class="ltx_text ltx_ref_tag">
           2.1.3
          </span>
         </a>
         ). Similarly, embedded devices ranging from IoT to robotics pose the aspect of real-time responses and more strict resource management in OS, which has been reflected in many successful embedded OSes such as VxWorks
         <span class="ltx_note ltx_role_footnote" id="footnote19">
          <sup class="ltx_note_mark">
           19
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             19
            </sup>
            <span class="ltx_tag ltx_tag_note">
             19
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.windriver.com/products/vxworks" target="_blank" title="">
             https://www.windriver.com/products/vxworks
            </a>
           </span>
          </span>
         </span>
         and QNX
         <span class="ltx_note ltx_role_footnote" id="footnote20">
          <sup class="ltx_note_mark">
           20
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             20
            </sup>
            <span class="ltx_tag ltx_tag_note">
             20
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://blackberry.qnx.com/en" target="_blank" title="">
             https://blackberry.qnx.com/en
            </a>
           </span>
          </span>
         </span>
         .
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S2.I3.i7" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S2.I3.i7.p1">
        <p class="ltx_p" id="S2.I3.i7.p1.1">
         <span class="ltx_text ltx_font_bold" id="S2.I3.i7.p1.1.1">
          AI-powered Features.
         </span>
         In the past decade, artificial intelligence (AI) technologies have experienced explosive growth. Specifically, breakthroughs in several areas of AI, such as natural language processing, computer vision, and speech recognition, are extending the interactive interface between users and OS to a new level. As examples of early implementations, Siri
         <span class="ltx_note ltx_role_footnote" id="footnote21">
          <sup class="ltx_note_mark">
           21
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             21
            </sup>
            <span class="ltx_tag ltx_tag_note">
             21
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.apple.com/siri/" target="_blank" title="">
             https://www.apple.com/siri/
            </a>
           </span>
          </span>
         </span>
         from Apple and Cortana
         <span class="ltx_note ltx_role_footnote" id="footnote22">
          <sup class="ltx_note_mark">
           22
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             22
            </sup>
            <span class="ltx_tag ltx_tag_note">
             22
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/cortana" target="_blank" title="">
             https://www.microsoft.com/en-us/cortana
            </a>
           </span>
          </span>
         </span>
         from Microsoft, the AI-powered virtual assistants provide a rich set of capabilities to understand the requests from the users, such as message sending, call making, question answering, web search, recommendation, and controlling smart home devices.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    AIOS, LLMOS and AI Agents
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Recent advances in foundation models, such as Large Language Models (LLMs), have significantly changed how AI applications are designed, trained, and used, including but not limited to NLP, CV, Search, RecSys, Multimedia, and Game applications. We envision that the influence of LLMs will not be limited to the application level, instead, it will in turn revolutionize the design and implementation of computer system, architecture, software, and the system-application ecosystem. This is realized through the following key concepts.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S2.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.1
     </span>
     LLM as OS (system-level)
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS1.p1">
     <p class="ltx_p" id="S2.SS2.SSS1.p1.1">
      LLM serves as the foundation AIOS platform that provides intelligent computing, APIs, and services that support various applications and manage various computing resources; Different from traditional OS, which aims at precision and efficiency, AIOS is characterized by its “intelligence,” which enables its intelligent and creative interaction with various applications and computing resources for task solving, leading to an operating system “with soul”.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.2
     </span>
     Agents as Applications (application-level)
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS2.p1">
     <p class="ltx_p" id="S2.SS2.SSS2.p1.1">
      Based on the LLM-driven AIOS, various AI Agents can be developed as AIOS-native applications, such as trip planning agent, medical consulting agent, financial management agent, etc.; these agents make use of the intelligent computing power of the LLM and the various tools provided by the AIOS SDK to solve various tasks; except for single-agent applications, agents may also communicate and interact with each other, enabling multi-agent applications; agent can even be created when needed and released after use, enabling on-the-fly creation of agents. There are several reasons that many specialized agents will be developed instead of integrating all of the functionality into one LLM: 1) the tasks that may be initiated by users are diverse, unbounded and unable to predetermine, 2) tasks may require specialized tools, reasoning and planning abilities, accessing the external physical or digital world, or domain-specific knowledge to complete, which the LLM-based AIOS platform may not support and need to be developed at the agent-level, 3) though language is a very powerful medium for describing tasks, objects, information or ideas, it may not be able to describe everything, and the completion of certain tasks may need creative forms of interaction beyond the “language input, language output” paradigm, such as the processing of vision, sound, touch, smell, and the diverse types of signals from various sensors. The processing of these unbounded and unpredictable types of information needs to be handled at the agent-level instead of the AIOS-level.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.3
     </span>
     Natural Language as Programming Interface (user-level)
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS3.p1">
     <p class="ltx_p" id="S2.SS2.SSS3.p1.1">
      In the AIOS-Agent ecosystem, average users can easily program Agent Applications (AAPs) using natural language, democratizing the development of and the access to computer software, which is very different from traditional OS-APP ecosystem, where desktop or mobile applications (APPs) have to be programmed by well-trained software developers using professional programming languages. This trend is consistent with the evolving history of programming languages, which are becoming more and more user-friendly, beginning from binary codes to assembly language to various high-level languages such as C, C++, Java and Python; Natural Language as Programming Language is a natural extension of this evolving history, making it possible for average users to program agent applications and interact with computers without special training on professional programming languages.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S2.SS2.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      2.2.4
     </span>
     Tools as Devices/Libraries (hardware/middleware-level)
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS4.p1">
     <p class="ltx_p" id="S2.SS2.SSS4.p1.1">
      Just like traditional OS can take advantage of various input and output devices such as keyboards and printers to support various APPs for task fulfillment, AIOS can also provide various tools as services to support the agents’ task fulfillment. Such tools include both hardware tools such as devices and software tools such as plugins or libraries;
the tools also include both input tools such as collecting signals from a sensor and output tools such as sending messages to other agents;
the AIOS shall include the basic and foundational tools that are frequently used by many agents as part of the platform, and provide Tool-Drivers (for hardware tools) and tool-APIs (for software tools) to enable easy calling of such tools by agents; Besides, each agent may also include its own specialized tools used for its own tasks.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Development of OS and AIOS Aligned
   </h3>
   <figure class="ltx_figure" id="S2.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="195" id="S2.F3.g1" src="/html/2312.03815/assets/x4.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S2.F3.2.1.1" style="font-size:90%;">
       Figure 3
      </span>
      :
     </span>
     <span class="ltx_text" id="S2.F3.3.2" style="font-size:90%;">
      Parallel Development of OS and AIOS/LLMOS.
      <span class="ltx_note ltx_role_footnote" id="footnote24">
       <sup class="ltx_note_mark">
        24
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          24
         </sup>
         <span class="ltx_tag ltx_tag_note">
          <span class="ltx_text" id="footnote24.1.1.1" style="font-size:111%;">
           24
          </span>
         </span>
         Image Sources:
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://history-computer.com/atlas-computer/" style="font-size:111%;" target="_blank" title="">
          https://history-computer.com/atlas-computer/
         </a>
         ,
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/History_of_Unix" style="font-size:111%;" target="_blank" title="">
          https://en.wikipedia.org/wiki/History_of_Unix
         </a>
         ,
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.magzter.com/stories/technology/Gadgets-Philippines/ARPANET" style="font-size:111%;" target="_blank" title="">
          https://www.magzter.com/stories/technology/Gadgets-Philippines/ARPANET
         </a>
         ,
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Windows_1.0x" style="font-size:111%;" target="_blank" title="">
          https://en.wikipedia.org/wiki/Windows_1.0x
         </a>
         ,
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.brookings.edu/articles/chatgpt-educational-friend-or-foe/" style="font-size:111%;" target="_blank" title="">
          https://www.brookings.edu/articles/chatgpt-educational-friend-or-foe/
         </a>
         ,
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/agiresearch/OpenAGI" style="font-size:111%;" target="_blank" title="">
          https://github.com/agiresearch/OpenAGI
         </a>
         ,
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/joonspk-research/generative_agents" style="font-size:111%;" target="_blank" title="">
          https://github.com/joonspk-research/generative_agents
         </a>
         ,
         <br class="ltx_break"/>
         <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/research/gpt-4v-system-card" style="font-size:111%;" target="_blank" title="">
          https://openai.com/research/gpt-4v-system-card
         </a>
        </span>
       </span>
      </span>
     </span>
    </figcaption>
   </figure>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Figure
     <a class="ltx_ref" href="#footnote24" title="Footnote 24 ‣ Figure 3 ‣ 2.3 Development of OS and AIOS Aligned ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
      <span class="ltx_text ltx_ref_tag">
       <span class="ltx_text" style="font-size:111%;">
        24
       </span>
      </span>
     </a>
     draws a parallel between the evolution of Operating Systems (OS) and LLM as OS (LLMOS). This comparison highlights their parallel progression in terms of enhanced functionality and user interaction. Initially, operating systems such as Atlas Supervisor were designed to manage basic computer resources such as CPU and DRAM. This evolved into more sophisticated version, exemplified by UNIX which can manage various peripheral devices. In a similar vein, LLMs have progressed from text-in-text-out chatbots to intricate LLM-based agents capable of managing various tools for complex task solving, as seen in OpenAGI
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ge et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023
      </a>
      )
     </cite>
     . The figure also emphasizes the pivotal role of ARPANET in the development of TCP/IP protocols, which laid the foundation for today’s Internet and connects multiple computers for communicating with each other. This is paralleled by the advancement of LLM-based multi-agent systems where agents can communicate with each other, signifying a trend towards more interconnected and collaborative LLM-based computing environments
     <cite class="ltx_cite ltx_citemacro_citep">
      (Park et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib75" title="">
       2023
      </a>
      )
     </cite>
     . Additionally, the evolution of operating systems is marked by the development of sophisticated graphical user interfaces (GUIs), such as those in Windows and Apple Macintosh. Similarly, LLM is evolving to include multi-modal interfaces, as demonstrated by GPT-4V(ision)
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib69" title="">
       2023
      </a>
      )
     </cite>
     . This comparison underscores the role of both OS and LLM in revolutionizing user interaction with technology, transitioning from managing fundamental components to facilitating more intuitive, user-centric experiences.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Architecture of AIOS
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    In this section, we establish the conceptual framework of “LLM as OS (LLMOS),” creating parallels between LLMOS components and traditional OS elements, as is shown in Table
    <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    . In this analogy, the LLM is compared to the OS kernel, the context window to memory, and external storage to the file system. Tools and user prompts are equated with devices/libraries and the user interface, respectively. We will delve into the specifics of this correlation in the following discussion.
   </p>
  </div>
  <figure class="ltx_table" id="S3.T1">
   <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.2">
    <thead class="ltx_thead">
     <tr class="ltx_tr" id="S3.T1.2.1.1">
      <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S3.T1.2.1.1.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.1.1.1.1">
        <span class="ltx_p" id="S3.T1.2.1.1.1.1.1" style="width:74.0pt;">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.1.1.1" style="font-size:90%;">
          OS-APP Ecosystem
         </span>
        </span>
       </span>
      </th>
      <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S3.T1.2.1.1.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.1.1.2.1">
        <span class="ltx_p" id="S3.T1.2.1.1.2.1.1" style="width:91.0pt;">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.2.1.1.1" style="font-size:90%;">
          AIOS-Agent Ecosystem
         </span>
        </span>
       </span>
      </th>
      <th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="S3.T1.2.1.1.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.1.1.3.1">
        <span class="ltx_p" id="S3.T1.2.1.1.3.1.1" style="width:187.8pt;">
         <span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.3.1.1.1" style="font-size:90%;">
          Explanation
         </span>
        </span>
       </span>
      </th>
     </tr>
    </thead>
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="S3.T1.2.2.1">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.2.1.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.2.1.1.1">
        <span class="ltx_p" id="S3.T1.2.2.1.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.2.1.1.1.1.1" style="font-size:90%;">
          Kernel
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.2.1.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.2.1.2.1">
        <span class="ltx_p" id="S3.T1.2.2.1.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.2.1.2.1.1.1" style="font-size:90%;">
          LLM
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.2.1.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.2.1.3.1">
        <span class="ltx_p" id="S3.T1.2.2.1.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.2.1.3.1.1.1" style="font-size:90%;">
          The core of AIOS, providing supportive services for Agent Applications (AAPs).
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.3.2">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.3.2.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.3.2.1.1">
        <span class="ltx_p" id="S3.T1.2.3.2.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.3.2.1.1.1.1" style="font-size:90%;">
          Memory
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.3.2.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.3.2.2.1">
        <span class="ltx_p" id="S3.T1.2.3.2.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.3.2.2.1.1.1" style="font-size:90%;">
          Context Window
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.3.2.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.3.2.3.1">
        <span class="ltx_p" id="S3.T1.2.3.2.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.3.2.3.1.1.1" style="font-size:90%;">
          Short-term memory of the current session, such as the prompt-response history of this session.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.4.3">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.4.3.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.4.3.1.1">
        <span class="ltx_p" id="S3.T1.2.4.3.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.4.3.1.1.1.1" style="font-size:90%;">
          Memory Management
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.4.3.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.4.3.2.1">
        <span class="ltx_p" id="S3.T1.2.4.3.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.4.3.2.1.1.1" style="font-size:90%;">
          Context Selection and Management
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.4.3.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.4.3.3.1">
        <span class="ltx_p" id="S3.T1.2.4.3.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.4.3.3.1.1.1" style="font-size:90%;">
          Select relevant context for the session, and manage the context such as adding, deleting and changing context information.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.5.4">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.5.4.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.5.4.1.1">
        <span class="ltx_p" id="S3.T1.2.5.4.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.5.4.1.1.1.1" style="font-size:90%;">
          File
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.5.4.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.5.4.2.1">
        <span class="ltx_p" id="S3.T1.2.5.4.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.5.4.2.1.1.1" style="font-size:90%;">
          External Storage
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.5.4.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.5.4.3.1">
        <span class="ltx_p" id="S3.T1.2.5.4.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.5.4.3.1.1.1" style="font-size:90%;">
          Long-term storage of the AIOS’s history sessions, user profiles, factual knowledge, etc.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.6.5">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.6.5.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.6.5.1.1">
        <span class="ltx_p" id="S3.T1.2.6.5.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.6.5.1.1.1.1" style="font-size:90%;">
          File System
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.6.5.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.6.5.2.1">
        <span class="ltx_p" id="S3.T1.2.6.5.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.6.5.2.1.1.1" style="font-size:90%;">
          Retrieval-augmentation
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.6.5.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.6.5.3.1">
        <span class="ltx_p" id="S3.T1.2.6.5.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.6.5.3.1.1.1" style="font-size:90%;">
          Retrieve relevant information from long-term storage.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.7.6">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.7.6.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.7.6.1.1">
        <span class="ltx_p" id="S3.T1.2.7.6.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.7.6.1.1.1.1" style="font-size:90%;">
          Devices/Libraries
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.7.6.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.7.6.2.1">
        <span class="ltx_p" id="S3.T1.2.7.6.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.7.6.2.1.1.1" style="font-size:90%;">
          Hardware/Software Tools
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.7.6.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.7.6.3.1">
        <span class="ltx_p" id="S3.T1.2.7.6.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.7.6.3.1.1.1" style="font-size:90%;">
          Help systems interact with the external world (both physical and virtual/digital world).
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.8.7">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.8.7.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.8.7.1.1">
        <span class="ltx_p" id="S3.T1.2.8.7.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.8.7.1.1.1.1" style="font-size:90%;">
          Driver/API
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.8.7.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.8.7.2.1">
        <span class="ltx_p" id="S3.T1.2.8.7.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.8.7.2.1.1.1" style="font-size:90%;">
          Tool-Driver/Tool-API
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.8.7.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.8.7.3.1">
        <span class="ltx_p" id="S3.T1.2.8.7.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.8.7.3.1.1.1" style="font-size:90%;">
          Serves as the interface for LLM/Agents to access and use the tools, usually in the form of prompts.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.9.8">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.9.8.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.9.8.1.1">
        <span class="ltx_p" id="S3.T1.2.9.8.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.9.8.1.1.1.1" style="font-size:90%;">
          OS SDK
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.9.8.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.9.8.2.1">
        <span class="ltx_p" id="S3.T1.2.9.8.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.9.8.2.1.1.1" style="font-size:90%;">
          AIOS SDK
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.9.8.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.9.8.3.1">
        <span class="ltx_p" id="S3.T1.2.9.8.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.9.8.3.1.1.1" style="font-size:90%;">
          Assist users in developing Agent Applications.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.10.9">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.10.9.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.10.9.1.1">
        <span class="ltx_p" id="S3.T1.2.10.9.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.10.9.1.1.1.1" style="font-size:90%;">
          User Interface (UI)
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.10.9.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.10.9.2.1">
        <span class="ltx_p" id="S3.T1.2.10.9.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.10.9.2.1.1.1" style="font-size:90%;">
          User Prompt/Instruction
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.2.10.9.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.10.9.3.1">
        <span class="ltx_p" id="S3.T1.2.10.9.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.10.9.3.1.1.1" style="font-size:90%;">
          Instruction(s) given by user to the system in (sometimes semi-structured) natural language (NL) to perform specific tasks. The NL instruction may be converted from users’ non-NL instructions such as clicks.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="S3.T1.2.11.10">
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S3.T1.2.11.10.1">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.11.10.1.1">
        <span class="ltx_p" id="S3.T1.2.11.10.1.1.1" style="width:74.0pt;">
         <span class="ltx_text" id="S3.T1.2.11.10.1.1.1.1" style="font-size:90%;">
          Application (APP)
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S3.T1.2.11.10.2">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.11.10.2.1">
        <span class="ltx_p" id="S3.T1.2.11.10.2.1.1" style="width:91.0pt;">
         <span class="ltx_text" id="S3.T1.2.11.10.2.1.1.1" style="font-size:90%;">
          Agent Application (AAP)
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S3.T1.2.11.10.3">
       <span class="ltx_inline-block ltx_align_top" id="S3.T1.2.11.10.3.1">
        <span class="ltx_p" id="S3.T1.2.11.10.3.1.1" style="width:187.8pt;">
         <span class="ltx_text" id="S3.T1.2.11.10.3.1.1.1" style="font-size:90%;">
          A diverse world of AI Agents.
         </span>
        </span>
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption" style="font-size:90%;">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    Comparison of OS-APP Ecosystem and AIOS-Agent Ecosystem
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    LLM (as AIOS Kernel)
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     The kernel is a set of computer programs at the core of a computer’s operating system and generally has complete control over everything in the system. When a user command is issued, the OS parses the command and translates it into one or more system calls to enter the kernel, which are precise requests for the kernel to perform tasks such as process creation, memory allocation, and file manipulation. It then manages these tasks by scheduling the processes, allocating the necessary resources, interacting with device drivers for hardware access, and enforcing security measures. Throughout this process, the kernel also handles error checking and provides appropriate feedback. Upon completion, the kernel ensures that outputs are directed back to the user and that all resources are cleaned up to maintain system stability, effectively abstracting the intricate hardware details from the user.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     Similarly, LLM acts as the operational core, akin to an OS kernel, responsible for planning and decomposing user requests, selectively calling tools, performing retrieval, and integrating all the information from previous steps to generate the final response. An LLM handles a complex prompt or instruction by first interpreting the input to understand its context and intent, and then uses its internal parameters to process the information, decomposing the instruction into manageable sub-tasks. The LLM generates responses for these sub-tasks, ensuring coherence and relevance to the original instruction. Finally, it synthesizes these into a cohesive output delivered to the user.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.1
     </span>
     Reasoning and Planning
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS1.p1">
     <p class="ltx_p" id="S3.SS1.SSS1.p1.1">
      In LLMOS, the role of LLM as the kernel subtly echoes the dynamics illustrated in the Dining Philosophers problem from computer science, a scenario that highlights the challenges of resource allocation and synchronization. In this problem, philosophers seated around a table must navigate shared resource usage–forks–in a way that avoids deadlock, a situation where no progress is made due to mutual blocking.
Reflecting these challenges, the kernel in an operating system is adept at managing and scheduling resources to avert system deadlocks, ensuring smooth and conflict-free operations. This essential function of the kernel in maintaining system stability and efficiency finds a parallel in the role of the LLM within the AIOS framework. Here, the LLM is responsible for navigating complex informational environments and managing external resources.
Crucial to the LLM’s role is its planning ability, which involves generating a series of actions to achieve a specific goal
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ge et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib35" title="">
        2023
       </a>
       )
      </cite>
      .
Central to the planning ability is the capability of reasoning
      <cite class="ltx_cite ltx_citemacro_citep">
       (Bratman et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib11" title="">
        1988
       </a>
       ; Russell and Norvig,
       <a class="ltx_ref" href="#bib.bib90" title="">
        1995
       </a>
       ; Fainstein and DeFilippis,
       <a class="ltx_ref" href="#bib.bib29" title="">
        2015
       </a>
       ; Huang and Chang,
       <a class="ltx_ref" href="#bib.bib45" title="">
        2022
       </a>
       )
      </cite>
      . Through reasoning, LLMOS deconstructs complex tasks from user instructions into more manageable sub-tasks, devising appropriate plans for each. Next, we will explore several representative planning strategies that illustrate this capability.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS1.SSS1.p2">
     <ul class="ltx_itemize" id="S3.I1">
      <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I1.i1.p1">
        <p class="ltx_p" id="S3.I1.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">
          Single-path Planning.
         </span>
         In this strategy, the final task is decomposed into several intermediate steps, which are connected in a cascading manner, with each step leading to only one subsequent step. For example, CoT (Chain of Thoughts) prompting
         <cite class="ltx_cite ltx_citemacro_citep">
          (Wei et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib121" title="">
           2022
          </a>
          )
         </cite>
         , as one of the celebrated capabilities of recent LLMs, is a pivotal breakthrough for performing complex multi-step reasoning when provided with limited examples. For example, by providing the models with “chain of thoughts”, i.e., reasoning exemplars, or a simple prompt “Let’s think step by step”, these models are able to answer questions with explicit reasoning steps
         <cite class="ltx_cite ltx_citemacro_citep">
          (Kojima et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib55" title="">
           2022
          </a>
          )
         </cite>
         . ReAct (Reasoning + Acting)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Yao et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib132" title="">
           2022b
          </a>
          )
         </cite>
         is a prompt-based paradigm to synergize reasoning and acting in language models. It enriches the action space with self-thinking (or thoughts), which compose useful information by reasoning over the current context to support future reasoning or acting. RAFA (Reason for Future, Act for Now)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Liu et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib63" title="">
           2023a
          </a>
          )
         </cite>
         studies how to complete a given task provably within a minimum number of interactions with the external environment.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I1.i2.p1">
        <p class="ltx_p" id="S3.I1.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">
          Multi-path Planning.
         </span>
         In this strategy, the reasoning steps for generating the final plans are organized into a tree-like or graph-like structure. This mirrors the nature of human decision-making, where individuals often encounter a range of choices at each step of their reasoning process. For example, CoT-SC (Self-consistent CoT)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Wang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib115" title="">
           2022
          </a>
          )
         </cite>
         uses the CoT approach to produce multiple reasoning paths and answers for a complex problem, selecting the most frequently occurring answer as the final output. Tree of Thoughts (ToT)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Yao et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib131" title="">
           2023
          </a>
          )
         </cite>
         assumes that humans tend to think in a tree-like structure when making decisions on complex problems for planning purposes, where each tree node is a thinking state. It uses LLM to generate evaluations or votes of thoughts, which can be searched using breadth first search (BFS) or depth first search (DFS). These methods improve the performance of LLMs on complex reasoning tasks. DFSDT (Depth-first search-based decision tree)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Qin et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib83" title="">
           2023b
          </a>
          )
         </cite>
         employs a tree structure with each node representing a state that includes instruction context, prior API calls, and observations. The model not only reasons and moves to child nodes based on API calls but can also backtrack to explore alternative paths, ensuring a more diversified search and preventing cumulative errors. Graph of Thoughts (GoT)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Besta et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib7" title="">
           2023
          </a>
          )
         </cite>
         further extends the reasoning paths from tree-structure to graph-structure, representing data produced by an LLM in the form of a flexible graph with individual units of information as nodes.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para" id="S3.SS1.SSS1.p3">
     <p class="ltx_p" id="S3.SS1.SSS1.p3.1">
      <cite class="ltx_cite ltx_citemacro_cite">
       Valmeekam et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib109" title="">
        2022
       </a>
       )
      </cite>
      concluded that “LLMs are still far from achieving acceptable performance on common planning/reasoning tasks which pose no issues for humans to do.” Similarly,
      <cite class="ltx_cite ltx_citemacro_cite">
       Wei et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib121" title="">
        2022
       </a>
       )
      </cite>
      also acknowledged this limitation, noting that “we qualify that although chain of thought emulates the thought processes of human reasoners, this does not answer whether the neural network is actually reasoning.” As a result, extensive efforts are still needed from the community to enhance the reasoning and planning ability of large language models.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.2
     </span>
     Self-Improving
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS2.p1">
     <p class="ltx_p" id="S3.SS1.SSS2.p1.1">
      Just as kernel updates are driven by human feedback, focusing on bug reports and performance issues, leading to improvements in functionality, security, and stability, LLMOS also requires continuous enhancement to elevate its performance. This process involves the LLMs learning from interactions, refining their algorithms based on user experiences and feedback. By doing so, LLMs can develop new capabilities and skills, adapting to changing requirements and expectations. This iterative process of improvement ensures that LLMs remain effective, relevant, and efficient in handling diverse tasks and queries, mirroring the evolving nature of technology and user needs. After the LLM has been pre-trained, the learning strategies of LLM can be broadly categorized into two main types, as summarized and exemplified in the following.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS1.SSS2.p2">
     <ul class="ltx_itemize" id="S3.I2">
      <li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I2.i1.p1">
        <p class="ltx_p" id="S3.I2.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">
          Learning from Feedback.
         </span>
         LLMs can learn from feedback about the consequences of its actions to the environment. For example, Reflexion, as proposed by
         <cite class="ltx_cite ltx_citemacro_cite">
          Shinn et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib97" title="">
           2023
          </a>
          )
         </cite>
         , is a framework to reinforce language agents through linguistic task feedback rather than update weights, enabling them to learn from prior failings. Similarly, Recursively Criticize and Improve (RCI)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Kim et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib53" title="">
           2023
          </a>
          )
         </cite>
         is a prompting approach, which involves prompting the LLMs to identify issues in their output and subsequently enhance it based on the identified problems. Furthermore, these learning processes can be framed within the paradigm of Reinforcement Learning (RL). In this context, the LLM is trained to select actions that maximize a reward signal, aligning with the principles of RL. For example,
         <cite class="ltx_cite ltx_citemacro_cite">
          Ouyang et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib71" title="">
           2022
          </a>
          )
         </cite>
         presents Reinforcement Learning from Human Feedback (RLHF) to align LLMs with the feedback from human users; OpenAGI
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ge et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib35" title="">
           2023
          </a>
          )
         </cite>
         presents Reinforcement Learning from Task Feedback (RLTF), which learns from the performance of executing the LLM-generated task solution to fine-tune the planning strategy of the LLM.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I2.i2.p1">
        <p class="ltx_p" id="S3.I2.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">
          Learning from Examples.
         </span>
         Recently, there has been a surge of interest in fine-tuning LLMs to perform tasks in a supervised way. For example, ToolLLaMA
         <cite class="ltx_cite ltx_citemacro_citep">
          (Qin et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib83" title="">
           2023b
          </a>
          )
         </cite>
         is created by collecting various real-world APIs and generating instructions for their practical use, with solutions annotated using a language model such as ChatGPT and an efficient Depth-First Search Decision Tree. This process results in a dataset of instruction-solution pairs, on which a large language model such as LLaMA is fine-tuned to execute APIs according to instructions.
Moreover, Gorilla
         <cite class="ltx_cite ltx_citemacro_citep">
          (Patil et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib76" title="">
           2023
          </a>
          )
         </cite>
         is trained by extracting key fields from API documentation and using GPT-4 to create instruction-API pairs, which are then used in a conversational format to fine-tune a model such as LLaMA, incorporating both retriever-aware and non-retriever training methods.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Context Window (as Memory)
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     In LLMOS, memory functions similarly to the context window in an LLM, defining the scope of information that the LLM can utilize and learn from while producing outputs. Increasing the amount of memory is desirable but always at a high cost.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     Within the framework of an LLM, an expansion of the context window precipitates increased computational demands. This escalation is attributed to the quadratic computational complexity that is a characteristic of the attention mechanism employed in these models
     <cite class="ltx_cite ltx_citemacro_citep">
      (Vaswani et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib110" title="">
       2017
      </a>
      )
     </cite>
     . During the training phase, one widely adopted strategy to avoid the exorbitant costs associated with lengthy context is to conduct an initial pre-training phase using a relatively limited context window, and subsequently followed by a fine-tuning stage employing an expanded context window
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chen et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib18" title="">
       2023b
      </a>
      )
     </cite>
     . Consequently, two primary challenges emerge: 1) the reduction of computational costs associated with processing long contexts, and 2) the development of a flexible position encoding mechanism suitable for extended contexts.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p3">
    <ul class="ltx_itemize" id="S3.I3">
     <li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I3.i1.p1">
       <p class="ltx_p" id="S3.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">
         Efficient attention
        </span>
        : Various methods have been proposed to reduce the complexity of the multi-head attention mechanism, which can be categorized into three primary types: 1) Sparse attention mechanism
        <cite class="ltx_cite ltx_citemacro_citep">
         (Zaheer et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib135" title="">
          2020
         </a>
         ; Gray et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib38" title="">
          2017
         </a>
         ; Kitaev et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib54" title="">
          2020
         </a>
         ; Beltagy et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib6" title="">
          2020
         </a>
         ; Ainslie et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib5" title="">
          2020
         </a>
         ; Wang et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib114" title="">
          2020
         </a>
         )
        </cite>
        redefines the traditional computation of attention weights. In this approach, each query tensor is limited to engaging with only a subset of key tensors, as opposed to the entire set. This method effectively zeroes out other attention weights, thereby diluting the computation and reducing the overall computational burden; 2) Linear attention mechanism
        <cite class="ltx_cite ltx_citemacro_citep">
         (Katharopoulos et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib52" title="">
          2020
         </a>
         )
        </cite>
        , which modifies the tensor multiplication process to be linear with respect to the sequence length without reducing the interaction between query tensors and key tensors; 3) Traditional multi-head attention uses multiple heads to split the query, key, and value tensor. Another method of reducing complexity aims at sharing heads for keys and values to optimize memory usage. By sharing heads between the keys and values in the multi-head attention setup
        <cite class="ltx_cite ltx_citemacro_citep">
         (Shazeer,
         <a class="ltx_ref" href="#bib.bib95" title="">
          2019
         </a>
         ; Ainslie et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib4" title="">
          2023
         </a>
         )
        </cite>
        , it reduces the storage requirements for the key-value (KV) cache and improves efficiency.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I3.i2.p1">
       <p class="ltx_p" id="S3.I3.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">
         Position encoding
        </span>
        : Position encoding can be classified into absolute position encoding and relative position encoding. The original Transformers paper
        <cite class="ltx_cite ltx_citemacro_citep">
         (Vaswani et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib110" title="">
          2017
         </a>
         )
        </cite>
        utilizes absolute position encoding, in which information is encoded in a combination of sin/cos functions whose wavelength increases from low- to higher-order dimensions of the embedding. Various methods, such as RoPE
        <cite class="ltx_cite ltx_citemacro_citep">
         (Su et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib101" title="">
          2021
         </a>
         )
        </cite>
        , are proposed later to emphasize the relative position information between tokens. To extend the context window size, Alibi
        <cite class="ltx_cite ltx_citemacro_citep">
         (Sun et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib103" title="">
          2022
         </a>
         )
        </cite>
        , LeX
        <cite class="ltx_cite ltx_citemacro_citep">
         (Sun et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib103" title="">
          2022
         </a>
         )
        </cite>
        , and XPos
        <cite class="ltx_cite ltx_citemacro_citep">
         (Press et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib77" title="">
          2021
         </a>
         )
        </cite>
        are proposed to enable length extrapolation so that a model can conduct inference on long context while being trained only on short context. To increase context length, methods such as position interpolation
        <cite class="ltx_cite ltx_citemacro_citep">
         (Chen et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib18" title="">
          2023b
         </a>
         )
        </cite>
        and NTK-aware
        <cite class="ltx_cite ltx_citemacro_citep">
         (Rozière et al
         <span class="ltx_text">
          .
         </span>
         ,
         <a class="ltx_ref" href="#bib.bib87" title="">
          2023
         </a>
         )
        </cite>
        position interpolation based on RoPE can be used.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S3.SS2.p4">
    <p class="ltx_p" id="S3.SS2.p4.1">
     Even though technically, the long context can be processed, there is no guarantee that the information in the long context can be correctly used and learned by LLM. Recent research has found that LLM does not robustly make use of information in long input contexts
     <cite class="ltx_cite ltx_citemacro_citep">
      (Liu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib62" title="">
       2023b
      </a>
      ; Shi et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib96" title="">
       2023
      </a>
      )
     </cite>
     . In particular, performance is often highest when relevant information occurs at the beginning or end of the input context and significantly degrades when models must access relevant information in the middle of long contexts. Similar findings are also found in chat-based LLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yang and Ettinger,
      <a class="ltx_ref" href="#bib.bib125" title="">
       2023
      </a>
      )
     </cite>
     , where model’s ability to track and enumerate environment states is unsatisfying. Given long documents, various prompt compression methods, such as LLMLingua
     <cite class="ltx_cite ltx_citemacro_citep">
      (Jiang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib49" title="">
       2023
      </a>
      )
     </cite>
     , have been proposed to reduce context length by removing unimportant tokens from the text.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    External Storage (as Files)
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     In addition to generating content based on knowledge acquired during pre-training, LLMs also utilize externally stored information for several purposes. These include enhancing predictions in domain-specific areas, generating more current information based on recent updates, and improving long-term memory retention. The external storage functions similarly to a file system within an operating system and supports various data formats. Certain formats enable the LLMs to swiftly query data as required, while others act as auxiliary knowledge bases. These knowledge are accessible for instant access to provide information in response to queries requiring high precision or expert knowledge. This section will commence with an explanation of how data is stored, followed by a discussion on the methodologies employed to retrieve pertinent information from the data storage.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.3.1
     </span>
     Data Formats
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS1.p1">
     <p class="ltx_p" id="S3.SS3.SSS1.p1.1">
      A file system in OS stores, organizes, and retrieves information in different modalities, including but not limited to plain text, images, audios, or videos. Similarly, LLM stores and retrieves data in different formats, such as natural language, embedding vectors, or graphs. It should be emphasized that these formats are not mutually exclusive, and many models incorporate multiple formats to concurrently harness their respective benefits. In the following, we introduce several representative data formats, each with its distinct features and applications:
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS1.p2">
     <ul class="ltx_itemize" id="S3.I4">
      <li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I4.i1.p1">
        <p class="ltx_p" id="S3.I4.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I4.i1.p1.1.1">
          Embedding Vectors.
         </span>
         Embedding vectors represent words, phrases, or even entire documents as dense vectors in high-dimensional spaces. This format is crucial for processing information in machine-readable forms, such as natural language and images, enabling LLMs to efficiently and accurately retrieve necessary information for content generation. We note that dense vector retrieval, as exemplified by
         <cite class="ltx_cite ltx_citemacro_cite">
          Karpukhin et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib51" title="">
           2020
          </a>
          )
         </cite>
         , generally serves as a necessary intermediate step for various data formats. Many different data formats are represented as dense vectors during this retrieval process. Specifically, when introducing embedding vector-based data formats, we refer to methods that explicitly store information in vector format. This approach is commonly used in conversational agents to maintain long-term memories. For example,
         <cite class="ltx_cite ltx_citemacro_cite">
          Zhong et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib139" title="">
           2023
          </a>
          )
         </cite>
         identified the lack of long-term memory as a significant limitation in current LLM-based applications such as ChatGPT. This issue is particularly noticeable in scenarios that require sustained interactions, such as personal companionship, psychological counseling, and secretarial tasks. To equip LLMs with the ability to effectively access long-term memory,
         <cite class="ltx_cite ltx_citemacro_cite">
          Zhong et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib139" title="">
           2023
          </a>
          )
         </cite>
         proposed “MemoryBank,” a novel vector-retrieval mechanism designed specifically for LLM-based applications. MemoryBank stores user-system past interactions, such as dialogues, as time-aware dense vectors known as memory pieces, with a dual-tower dense retriever and a memory updater inspired by Ebbinghaus’ Forgetting Curve theory. A chatbot powered by MemoryBank demonstrates the effectiveness of this mechanism in long-term conversation. Similarly,
         <cite class="ltx_cite ltx_citemacro_cite">
          Zhao et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib138" title="">
           2023
          </a>
          )
         </cite>
         stores long-term conversational data as vectors for open-domain dialogue applications, where each piece of dialogue or summarized memory is transformed into a high-dimensional vector that captures its semantic meaning. Contrastive representation learning is used to increase the accuracy of memory retrieval.
         <cite class="ltx_cite ltx_citemacro_cite">
          Lee et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib56" title="">
           2023
          </a>
          )
         </cite>
         proposed a memory-enhanced chatbot to achieve long-term consistency and flexibility in open-domain conversations. It uses a summarizer model to summarize dialogues and store them as dense vectors in a memory pool after a certain number of rounds. Then, the relevant memory is retrieved to help generate responses. Later,
         <cite class="ltx_cite ltx_citemacro_cite">
          Lu et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib65" title="">
           2023
          </a>
          )
         </cite>
         introduced “Memochat,” which proposed an iterative “memorization-retrieval-response” cycle to maintain consistency in long conversations covering multiple topics. In this cycle, LLMs are trained to create structured memos, which help to keep track of the conversation context and topics.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I4.i2.p1">
        <p class="ltx_p" id="S3.I4.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I4.i2.p1.1.1">
          Plain-Text Documents.
         </span>
         Language models that generate responses by retrieving external plain-text documents can greatly improve the quality of responses. This is especially true for tasks that demand domain-specific knowledge or up-to-date information, such as question answering
         <cite class="ltx_cite ltx_citemacro_citep">
          (Guu et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib39" title="">
           2020
          </a>
          ; Borgeaud et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib9" title="">
           2022
          </a>
          )
         </cite>
         and fact verification
         <cite class="ltx_cite ltx_citemacro_citep">
          (Lewis et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib57" title="">
           2020
          </a>
          ; Izacard et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib48" title="">
           2022
          </a>
          )
         </cite>
         . Plain-text documents, which consist of unstructured text data, are often vast in size and contain a wealth of information. Examples of such retrieval include Wikipedia articles
         <cite class="ltx_cite ltx_citemacro_citep">
          (Guu et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib39" title="">
           2020
          </a>
          )
         </cite>
         , textbooks
         <cite class="ltx_cite ltx_citemacro_citep">
          (Wang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib117" title="">
           2023d
          </a>
          )
         </cite>
         , and programming code
         <cite class="ltx_cite ltx_citemacro_citep">
          (Zhou et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib140" title="">
           2022
          </a>
          )
         </cite>
         . Retrieving information from these documents poses a challenge due to their dense and extensive nature. Therefore, advanced retrieval methods such as Dense Passage Retrieval (DPR)
         <cite class="ltx_cite ltx_citemacro_citep">
          (Karpukhin et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib51" title="">
           2020
          </a>
          )
         </cite>
         are frequently utilized in the retrieval process. Retrieval-augmented LLM based on external document collections is an important extension of LLMs, where the system is not just reliant on pre-trained knowledge but also actively retrieves external knowledge for better response generation. The augmentation allows for more accurate, up-to-date, and context-relevant responses, particularly crucial for tasks involving real-time data or specialized knowledge. Research in this field is often referred to as Retrieval-Augmented Generation (RAG), focusing on critical issues such as pre-training language models in retrieval contexts and fine-tuning them for downstream tasks.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I4.i3.p1">
        <p class="ltx_p" id="S3.I4.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I4.i3.p1.1.1">
          Structured Data.
         </span>
         Structured data is a commonly used format for storing external, useful knowledge for LLMs. Since much information naturally exists in structural formats, this enables models to access a wide range of information within complex knowledge structures. The sources of structured data are diverse, with knowledge graphs being one of the most pertinent formats for augmenting LLMs’ generative abilities:
         <cite class="ltx_cite ltx_citemacro_cite">
          Pan et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib73" title="">
           2023
          </a>
          )
         </cite>
         explicitly discuss the use of knowledge graphs to address the hallucination issues in LLMs and enhance their interpretability. Furthermore, several popular LLM tools, such as LlamaIndex
         <cite class="ltx_cite ltx_citemacro_citep">
          (Liu,
          <a class="ltx_ref" href="#bib.bib61" title="">
           2022
          </a>
          )
         </cite>
         , offer options to leverage existing knowledge graphs to improve knowledge generation. Another potentially valuable data format is tabular data. As introduced in
         <cite class="ltx_cite ltx_citemacro_cite">
          Sundar and Heck (
          <a class="ltx_ref" href="#bib.bib104" title="">
           2023
          </a>
          )
         </cite>
         , a novel concept of Conversational Tables (cTBLS) is designed to enhance the capabilities of conversational AI by integrating tabular data. This work utilizes a dense table retrieval method to rank relevant table cells. Subsequently, the responses of LLMs are grounded in the tabular information and the conversational context.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.3.2
     </span>
     Data Retrieval Methods
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS2.p1">
     <p class="ltx_p" id="S3.SS3.SSS2.p1.1">
      The ability to access relevant and accurate information from external storage through sophisticated data retrieval methods is crucial for LLMOS’s execution of targeted actions. A primary challenge in this process is selecting the most appropriate data file from an extensive repository of information. These data retrieval methods operate automatically, leveraging advanced algorithms and machine learning techniques.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS2.p2">
     <p class="ltx_p" id="S3.SS3.SSS2.p2.1">
      For instance,
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhu et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib142" title="">
        2023
       </a>
       )
      </cite>
      show that LLM can store past accomplished sub-goals of video games using a dictionary, where the sub-goals are keys, and the corresponding action sequences are values. When encountering familiar objectives, the first action is easily retrieved using the name of the goal. Conversely,
      <cite class="ltx_cite ltx_citemacro_cite">
       Park et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib75" title="">
        2023
       </a>
       )
      </cite>
      propose a more sophisticated “memory stream” to record agents’ past experiences in a list, labeled with text descriptions and timestamps of creation or last interaction. This data storage strategy enables agents to effectively retrieve useful experiences based on their current situation, using scores of Recency, Importance, and Relevance. Similarly,
      <cite class="ltx_cite ltx_citemacro_cite">
       Zhong et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib139" title="">
        2023
       </a>
       )
      </cite>
      discuss storing detailed records of daily conversations, summaries of past events, and assessments of user personalities as vector representations indexed by FAISS
      <cite class="ltx_cite ltx_citemacro_citep">
       (Johnson et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib50" title="">
        2019
       </a>
       )
      </cite>
      , a library used for efficient similarity search in stored vectors. Furthermore,
      <cite class="ltx_cite ltx_citemacro_cite">
       Hu et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib42" title="">
        2023
       </a>
       )
      </cite>
      highlight the limitations of conventional neural memory mechanisms, which are not symbolic and rely on vector similarity calculations, being prone to errors. It suggests the use of databases as an external symbolic memory for LLMs. Complex problems are decomposed into a series of SQL-based memory operation steps, greatly simplifying the retrieval process.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS3.SSS2.p3">
     <p class="ltx_p" id="S3.SS3.SSS2.p3.1">
      On the other hand, retrieving information from extremely large external documents heavily relies on existing methods in Information Retrieval (IR) research
      <cite class="ltx_cite ltx_citemacro_citep">
       (Croft et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib23" title="">
        2010
       </a>
       )
      </cite>
      . Modern Information Retrieval involves two key stages: retrieval and ranking. The retrieval stage focuses on fetching relevant documents based on user queries using algorithms such as vector space models
      <cite class="ltx_cite ltx_citemacro_citep">
       (Salton,
       <a class="ltx_ref" href="#bib.bib92" title="">
        1975
       </a>
       ; Robertson et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib86" title="">
        2009
       </a>
       )
      </cite>
      , or pre-trained models such as BERT
      <cite class="ltx_cite ltx_citemacro_citep">
       (Devlin et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib26" title="">
        2018
       </a>
       ; Karpukhin et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib51" title="">
        2020
       </a>
       )
      </cite>
      . LLM extensively applies these methods for applications that depend on generating comprehensive domain knowledge or accurate information. To ensure better accuracy in retrieving information from a vast amount of documents, effective index representations are usually learned during pre-training or fine-tuning
      <cite class="ltx_cite ltx_citemacro_citep">
       (Guu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib39" title="">
        2020
       </a>
       ; Borgeaud et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib9" title="">
        2022
       </a>
       ; Lewis et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib57" title="">
        2020
       </a>
       ; Izacard et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib48" title="">
        2022
       </a>
       ; Hua et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib44" title="">
        2023b
       </a>
       )
      </cite>
      .
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.4
    </span>
    Tools (as Devices/Libraries)
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     In a traditional OS, peripheral devices, such as keyboards, mice, and printers, extend the system’s capabilities, allowing for diverse forms of input and output that enhance the overall functionality of the computer. There are also various programming libraries, which include a diverse set of reusable functionalities that can be leveraged by applications through API calls.
Similarly, in the context of AIOS, hardware tools can be seen as analogous to these peripheral devices, and software tools can be seen as analogous to these libraries and APIs.
These tools can range from data analysis modules to interactive interfaces, each adding a unique dimension to the LLM’s processing and response abilities. They allow the LLM to interact with different data types, environments, and user requirements, significantly enriching its functionality.
As a result, these hardware and software tools help the LLM to interact with the physical and digital worlds, expanding LLM’s capabilities, and can be leveraged by agents for complex task solving.
In the upcoming sections, we will delve into the specifics of these tools, illustrating how they enrich the LLM’s capacity within the AIOS.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS4.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.4.1
     </span>
     Tool Categories
    </h4>
    <div class="ltx_para" id="S3.SS4.SSS1.p1">
     <p class="ltx_p" id="S3.SS4.SSS1.p1.1">
      Though LLMs are adept at handling numerous tasks, they encounter limitations in complex tasks that require deep domain knowledge or interaction with the external world. External tools enable LLMs to harness various resources and specialized knowledge, bolstering their capabilities. In the following, we present several representative tools for LLMs, as discussed in the existing literature.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS4.SSS1.p2">
     <ul class="ltx_itemize" id="S3.I5">
      <li class="ltx_item" id="S3.I5.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I5.i1.p1">
        <p class="ltx_p" id="S3.I5.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I5.i1.p1.1.1">
          Software Tools
         </span>
         are domain expert models or APIs that help LLMs to finish a specialized sub-task, such as searching a query on the Web through a search API or checking the weather through a third party weather service API.
Recent trends show a growing integration of APIs with LLMs, serving as interfaces for external programs to interact with LLMs, and acting as a bridge between the LLM and other software applications, thus extending LLMs’ capabilities across various applications and services. For instance, OpenAGI
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ge et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib35" title="">
           2023
          </a>
          )
         </cite>
         trains LLMs to use various domain expert models as tools for reasoning, planing, and complex task solving based on reinforcement learning from task feedback (RLTF). TPTU
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ruan et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib88" title="">
           2023a
          </a>
          )
         </cite>
         interfaces with both Python interpreters and LaTeX compilers for mathematical computations. Gorilla
         <cite class="ltx_cite ltx_citemacro_citep">
          (Patil et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib76" title="">
           2023
          </a>
          )
         </cite>
         , a fine-tuned LLM, is engineered to generate precise API call arguments and prevent hallucinations. ToolLLM
         <cite class="ltx_cite ltx_citemacro_citep">
          (Qin et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib83" title="">
           2023b
          </a>
          )
         </cite>
         presents a general framework for tool use, including data construction, model training, and evaluation. It also provides an instruction-tuning dataset for tools, collected from over 16,000 real-world APIs. TaskMatrix.AI
         <cite class="ltx_cite ltx_citemacro_citep">
          (Liang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib60" title="">
           2023b
          </a>
          )
         </cite>
         connects foundational models with millions of APIs for diverse task completion, facilitating user interaction in an interactive manner.
ChemCrow
         <cite class="ltx_cite ltx_citemacro_citep">
          (Bran et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib10" title="">
           2023
          </a>
          )
         </cite>
         integrates several expert-designed models to augment LLMs in chemistry-related tasks such as organic synthesis, drug discovery, and materials design. MM-REACT
         <cite class="ltx_cite ltx_citemacro_citep">
          (Yang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib128" title="">
           2023a
          </a>
          )
         </cite>
         combines LLMs with various vision expert models for advanced multi-modal reasoning and actions. Using expert models as tools, LLM agents can tackle advanced tasks necessitating expert knowledge.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I5.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I5.i2.p1">
        <p class="ltx_p" id="S3.I5.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I5.i2.p1.1.1">
          Hardware Tools.
         </span>
         While the aforementioned tools enhance LLMs in the digital world, physical tools such as robotics and embodied AI serve as pivotal means to connect LLMs with the physical world. These tools enable LLMs to actively observe, understand, and interact with their physical surroundings. Observations allow LLMs to gather various inputs from the physical world, converting them into multi-modal signals to augment actions such as navigation and manipulation. For example, Soundspace
         <cite class="ltx_cite ltx_citemacro_citep">
          (Chen et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib16" title="">
           2020
          </a>
          )
         </cite>
         explores observing physical space geometry using reverberating audio sensory inputs. Physical tools enable LLMs to execute user commands, transcending the role of merely providing natural language instructions. SayCan
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ahn et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib3" title="">
           2022
          </a>
          )
         </cite>
         , for instance, incorporates physical tools into LLMs for real-world tasks such as cleaning tabletops or retrieving items. In essence, physical tools act as the “hands, ears, eyes” etc. of LLMs to interact with the physical world, fostering real-world grounding.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S3.I5.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S3.I5.i3.p1">
        <p class="ltx_p" id="S3.I5.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S3.I5.i3.p1.1.1">
          Self-made Tools.
         </span>
         Current tools are primarily designed by humans. Recently, there are increasing interest in the use of LLMs for automated tool making. This involves generating executable programs or enhancing existing tools to create more powerful solutions, guided by appropriate instructions and demonstrations
         <cite class="ltx_cite ltx_citemacro_citep">
          (Qin et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib82" title="">
           2023a
          </a>
          ; Qian et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib81" title="">
           2023b
          </a>
          ; Chen et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib17" title="">
           2021
          </a>
          )
         </cite>
         . For example, a large code model, as evaluated in
         <cite class="ltx_cite ltx_citemacro_cite">
          Chen et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib17" title="">
           2021
          </a>
          )
         </cite>
         , is capable of generating executable programs based on user-provided instructions. These programs can then serve as specialized tools to address particular tasks. Furthermore, these LLMs can also acquire the ability to self-debug, which is an essential skill for maintaining and improving the tool functionality, as detailed in
         <cite class="ltx_cite ltx_citemacro_cite">
          Chen et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib19" title="">
           2023a
          </a>
          )
         </cite>
         .
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS4.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.4.2
     </span>
     Tool-Driver and Tool-API
    </h4>
    <div class="ltx_para" id="S3.SS4.SSS2.p1">
     <p class="ltx_p" id="S3.SS4.SSS2.p1.1">
      In traditional OS, Drivers or APIs play a pivotal role in enabling the system to interact with specific Devices or Libraries. The drivers provide interfaces to connect the OS with hardware devices, while the APIs provide interfaces to connect the OS or application with software libraries.
In the context AIOS, where hardware tools are viewed as devices and software tools are viewed as libraries, Tool-Drivers and Tool-APIs are required, which serve as the interface for AIOS or agents to use these hardware and sofware tools, respectively.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS4.SSS2.p2">
     <p class="ltx_p" id="S3.SS4.SSS2.p2.1">
      Existing literature usually defines the Tool-Drivers and Tool-APIs in the form of prompts. Specifically, these prompts are composed of two essential elements: application scenarios and invocation methods. Much like how Drivers or APIs in a traditional OS control access to specific Devices or Libraries, commonly used prompts in AIOS should equip LLMs with an in-depth understanding of application scenarios. This enables LLMs to judiciously determine the appropriateness of a particular tool for a given task. Moreover, in parallel to how Drivers or APIs facilitate the communication between the OS and devices, tool instruction prompts should clearly outline the invocation methods. This is crucial for LLMs to comprehend the inputs and outputs of the tools, ensuring their effective execution and integration into the system.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS4.SSS2.p3">
     <p class="ltx_p" id="S3.SS4.SSS2.p3.1">
      Utilizing the inherent zero-shot and few-shot learning capabilities of LLMs
      <cite class="ltx_cite ltx_citemacro_citep">
       (Radford et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib84" title="">
        2019
       </a>
       ; Brown et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib12" title="">
        2020
       </a>
       )
      </cite>
      , agents can gain insights about tools through zero-shot prompts that elucidate tool functionalities and parameters, or few-shot prompts offering demonstrations of particular tool usage scenarios and methodologies
      <cite class="ltx_cite ltx_citemacro_citep">
       (Schick et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib93" title="">
        2023
       </a>
       ; Parisi et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib74" title="">
        2022
       </a>
       )
      </cite>
      . Usually, a single tool is inadequate for complex tasks. Hence, agents must adeptly decompose these tasks into manageable subtasks, where their understanding of the tools is pivotal. After understanding individual tools, LLMs should determine their application in addressing complex tasks. One approach is to generate actions by extracting pertinent information from memory relevant to the current task. For instance, Generative Agents
      <cite class="ltx_cite ltx_citemacro_citep">
       (Park et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib75" title="">
        2023
       </a>
       )
      </cite>
      maintain a memory stream, consulting it for recent, pertinent, and crucial information before each action to guide their decisions. In GITM (Ghost in the Minecraft)
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib142" title="">
        2023
       </a>
       )
      </cite>
      , to achieve specific sub-goals, the agent probes its memory to identify if any similar tasks have been successfully executed before. If so, it replicates those successful actions for the current task. In collaborative frameworks such as ChatDev
      <cite class="ltx_cite ltx_citemacro_citep">
       (Qian et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib80" title="">
        2023a
       </a>
       )
      </cite>
      and MetaGPT
      <cite class="ltx_cite ltx_citemacro_citep">
       (Hong et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib41" title="">
        2023
       </a>
       )
      </cite>
      , agents engage in mutual communication, retaining the conversation history in their memories. Another strategy involves executing a pre-formulated plan. For example, in DEPS (Describe, Explain, Plan and Select)
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib118" title="">
        2023a
       </a>
       )
      </cite>
      , given a task, if there are no indicators of the plan’s failure, the agent proceeds with actions based on that plan.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   AIOS-Agent Ecosystem
  </h2>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Agents as Applications
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     On top of the LLMOS-based AIOS, a diverse scope of AI Agent applications can be developed, akin to traditional OS-based applications such as browsers and photo-editing softwares. These Agent Applications (AAPs) generally comprise three components: the agent profile, an accessible external database, and task-specific tools.
On one hand, the agent profiles are written into the prompt and used to indicate the agent functionality, influencing the LLM behaviors to exhibit certain roles such as a coder agent, a teacher agent, or a travel planning agent, as described in sources such as
     <cite class="ltx_cite ltx_citemacro_cite">
      Qian et al
      <span class="ltx_text">
       .
      </span>
      (
      <a class="ltx_ref" href="#bib.bib80" title="">
       2023a
      </a>
      ); Li et al
      <span class="ltx_text">
       .
      </span>
      (
      <a class="ltx_ref" href="#bib.bib58" title="">
       2023
      </a>
      ); Ge et al
      <span class="ltx_text">
       .
      </span>
      (
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023
      </a>
      )
     </cite>
     . Typical agent profiles may encompass basic information such as age, gender, and career
     <cite class="ltx_cite ltx_citemacro_citep">
      (Park et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib75" title="">
       2023
      </a>
      )
     </cite>
     , or psychology information reflecting the personalities of the agents
     <cite class="ltx_cite ltx_citemacro_citep">
      (Serapio-García et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib94" title="">
       2023
      </a>
      )
     </cite>
     , as well as social information detailing the relationships between agents
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib58" title="">
       2023
      </a>
      )
     </cite>
     . The nature of the agent’s profile is tailored to the application’s context; for example, applications focused on human cognitive processes will emphasize psychological information.
Furthermore, the inclusion of an external database and toolset within the prompt enhances the LLM’s interaction with the external world, specifying elements such as file locations and tool descriptions.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     As illustrated in Figure
     <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4.1 Agents as Applications ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     , by merging the LLMOS layer with the OS layer, Hardware layer, and the Agent Application layer, we can establish an autonomous LLMOS-based Agent system. This system will respond to natural language instructions from users, capable of executing a variety of tasks through its interactions with the environment and its inherent knowledge.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="136" id="S4.F4.g1" src="/html/2312.03815/assets/x5.png" width="461"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      <span class="ltx_text" id="S4.F4.2.1.1" style="font-size:90%;">
       Figure 4
      </span>
      :
     </span>
     <span class="ltx_text" id="S4.F4.3.2" style="font-size:90%;">
      An illustration of LLMOS-based AI Agent.
     </span>
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Natural Language Programming for Agents
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     Natural Language Programming (NLProg) acts as a crucial intermediary between LLMOS and Agents within the AIOS-Agent ecosystem. This innovative approach allows average users to easily program Agent Applications (AAPs) using natural language. This development democratizes the creation and accessibility of computer software, representing a significant shift from the traditional OS-APP ecosystem. Traditionally, desktop or mobile applications (APPs) required programming by skilled software developers using professional programming languages. In contrast, NLProg empowers even those without formal training in these languages to develop applications.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     This trend aligns with the historical evolution of programming languages, which have progressively become more user-friendly. The journey from binary codes to assembly language and then to various high-level languages such as C, C++, Java, and Python reflects this trend. The introduction of Natural Language as a Programming Interface is a natural progression in this evolution. It simplifies programming for the average user, allowing them to program agent applications and interact with computers without the need for specialized training in conventional programming languages.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     Moreover, this shift has broader implications for the field of computer science and technology. It opens up new possibilities for innovation and creativity, as a wider range of individuals can contribute to software development. This inclusivity can lead to the development of more diverse and tailored applications, as people from different backgrounds and with varying expertise can bring their unique perspectives to software design. Additionally, NLProg in the AIOS ecosystem fosters a more intuitive interaction between humans and computers, enhancing user experience and potentially leading to more efficient and effective use of technology in various sectors. As this approach gains traction, it could significantly alter the landscape of technology development, making it more accessible and aligned with the natural human way of communication and understanding.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    The Ecosystem
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     In the AIOS-Agent ecosystem, the potential for collaboration and networking among agents heralds a new era of digital assistance and decision-making. These agents, with their diverse skill sets and role profiles, can work in tandem to address complex challenges, offering a multifaceted approach to problem-solving. For instance, an agent with a background in data analysis can collaborate with another agent specialized in creative design, leading to innovative solutions that a single agent might not conceive.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p2">
    <p class="ltx_p" id="S4.SS3.p2.1">
     Moreover, the AIOS ecosystem is designed to be scalable, accommodating an increasing number of agents as user needs grow and evolve. This scalability ensures that the system remains efficient and effective, even as the complexity of tasks increases. The AIOS also emphasizes the importance of learning and adaptation. Agents in this ecosystem can learn from their interactions, both with users and other agents, continuously evolving and enhancing their capabilities. This feature is crucial for keeping up with the rapidly changing landscape of technology and user expectations.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p3">
    <p class="ltx_p" id="S4.SS3.p3.1">
     In the broader context, the AIOS-Agent ecosystem can significantly impact various industries, from healthcare, where agents can assist in patient care and medical research, to education, where agents can offer personalized learning experiences. The versatility and adaptability of this ecosystem make it a valuable asset in any field where decision making, data analysis, and creative problem solving are crucial. As this technology matures, it holds the promise of transforming our interaction with the digital world, making it more intuitive, efficient, and responsive to our needs.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   LLMOS in Practice: AI Agents
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In this section, we present a comprehensive overview of the current applications of LLMOS-based agents, aiming to provide a wide-ranging perspective on their practical deployment scenarios.
Specifically, we mainly introduce three scenarios: single agent applications, multi-agent applications, and human-agent applications.
   </p>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Single Agent Applications
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     Single agent applications mainly focus on utilizing a single agent to address various user tasks. We categorize single agent applications into two distinct types based on the external environments they interacted with, i.e., physical environment and virtual/digital environment.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S5.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.1
     </span>
     Physical Environment
    </h4>
    <div class="ltx_para" id="S5.SS1.SSS1.p1">
     <p class="ltx_p" id="S5.SS1.SSS1.p1.1">
      Unlike virtual or simulated environments, the physical environment is made up of tangible elements that an AI Agent must navigate or manipulate. This concept is particularly relevant in the field of robotics and embodied AI, where the agents are not just software algorithms but have a physical presence or are integrated with physical systems. Following this, we present a range of exemplary scenarios, as detailed in existing literature.
     </p>
    </div>
    <div class="ltx_para" id="S5.SS1.SSS1.p2">
     <ul class="ltx_itemize" id="S5.I1">
      <li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I1.i1.p1">
        <p class="ltx_p" id="S5.I1.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">
          Scientific Research.
         </span>
         Agents have the capacity to function autonomously, undertaking experiments independently, while also serving as invaluable resources for scientists engaged in research projects
         <cite class="ltx_cite ltx_citemacro_citep">
          (Boiko et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib8" title="">
           2023
          </a>
          ; Bran et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib10" title="">
           2023
          </a>
          )
         </cite>
         . For instance,
         <cite class="ltx_cite ltx_citemacro_cite">
          Boiko et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib8" title="">
           2023
          </a>
          )
         </cite>
         propose an end-to-end platform that automates scientific experimentation, integrating AI modules, reasoning capabilities, software tools, and laboratory hardware. It autonomously performs tasks ranging from online information gathering and experiment design to running protocols and controlling robotic equipment, while adapting to errors and refusing unethical requests. ChemCrow
         <cite class="ltx_cite ltx_citemacro_citep">
          (Bran et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib10" title="">
           2023
          </a>
          )
         </cite>
         is a suite of 17 specialized tools designed to aid chemical research, offering methodological suggestions and highlighting safety hazards based on the input objectives.
         <cite class="ltx_cite ltx_citemacro_cite">
          Huang et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib46" title="">
           2023
          </a>
          )
         </cite>
         also propose MLAgentBench, a suite of ML tasks for benchmarking AI research agents.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I1.i2.p1">
        <p class="ltx_p" id="S5.I1.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">
          Robotics.
         </span>
         Recent studies have employed LLM-based agents in the fields of Robotics. For example, ChatGPT for Robotics
         <cite class="ltx_cite ltx_citemacro_citep">
          (Vemprala et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib111" title="">
           2023
          </a>
          )
         </cite>
         employs ChatGPT for a wide array of robotics tasks through strategic prompt engineering, showing its ability to comprehend and respond to natural language instructions in the context of robotics applications. SayCan
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ahn et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib3" title="">
           2022
          </a>
          )
         </cite>
         comprises two integral components: the “Say” part of the LLM, responsible for task-grounding by identifying pertinent actions for a high-level objective, and the “Can” part, which encompasses the learned affordance functions that offer a world-grounding, thereby determining the feasible actions for the plan’s execution.
It ensures not only the relevance of the actions chosen for the specified task but also their feasibility in the real-world scenario.
VOYAGER
         <cite class="ltx_cite ltx_citemacro_citep">
          (Wang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib112" title="">
           2023e
          </a>
          )
         </cite>
         presents lifelong learning with prompting mechanisms, skill library, and self-verification, which are based on LLM. These three modules aim to enhance the development of more complex behaviors of agents.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I1.i3.p1">
        <p class="ltx_p" id="S5.I1.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">
          Autonomous Driving.
         </span>
         Recent studies have harnessed LLMs to enhance self-driving car technologies. For example,
         <cite class="ltx_cite ltx_citemacro_citet">
          Fu et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib33" title="">
           2023a
          </a>
          )
         </cite>
         propose an agent-based autonomous driving system, which widely adopts a four-module framework: Environment, Agent, Memory, and Expert. Within this framework, the Environment sets the interaction stage, the Agent perceives the environment and makes decision, the Memory accumulates experience for action, and the Expert provides training advice and inconsistency feedback.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.2
     </span>
     Virtual/Digital Environment
    </h4>
    <div class="ltx_para" id="S5.SS1.SSS2.p1">
     <p class="ltx_p" id="S5.SS1.SSS2.p1.1">
      Agents in virtual or digital environment mainly includes the manipulation of APIs
      <cite class="ltx_cite ltx_citemacro_citep">
       (Schick et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib93" title="">
        2023
       </a>
       ; Yao and Narasimhan,
       <a class="ltx_ref" href="#bib.bib130" title="">
        2023
       </a>
       ; Ge et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib35" title="">
        2023
       </a>
       ; Parisi et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib74" title="">
        2022
       </a>
       ; Tang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib105" title="">
        2023
       </a>
       )
      </cite>
      , accessing the Internet and websites
      <cite class="ltx_cite ltx_citemacro_citep">
       (Nakano et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib68" title="">
        2022
       </a>
       )
      </cite>
      , executing codes
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib137" title="">
        2023
       </a>
       )
      </cite>
      , and simulation in historical settings
      <cite class="ltx_cite ltx_citemacro_citep">
       (Hua et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib43" title="">
        2023a
       </a>
       )
      </cite>
      . Such digital grounding is cheaper and faster than physical or human interaction. It is thus a convenient test bed for language agents and has been studied with increasing intensity in recent years.
In the following, we present several representative scenarios as studied in the existing literature.
     </p>
    </div>
    <div class="ltx_para" id="S5.SS1.SSS2.p2">
     <ul class="ltx_itemize" id="S5.I2">
      <li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I2.i1.p1">
        <p class="ltx_p" id="S5.I2.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i1.p1.1.1">
          Coding.
         </span>
         This category focuses on leveraging the capabilities of agents to generate programs. For example, ToolCoder
         <cite class="ltx_cite ltx_citemacro_citep">
          (Zhang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib137" title="">
           2023
          </a>
          )
         </cite>
         is a system that merges API search tools with existing models to facilitate code generation and API selection, using a two-step approach. Initially, an automated data annotation technique involving ChatGPT embeds tool usage data into the source code, followed by fine-tuning the code generation model; during inference, the API search tool is integrated to autonomously suggest API choices, optimizing code generation and improving API selection decision-making. Moreover, Lemur-series models
         <cite class="ltx_cite ltx_citemacro_citep">
          (Xu et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib124" title="">
           2023
          </a>
          )
         </cite>
         are meticulously pre-trained and instruction fine-tuned to demonstrate balanced language and coding capabilities.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I2.i2.p1">
        <p class="ltx_p" id="S5.I2.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i2.p1.1.1">
          Web Service.
         </span>
         This category primarily revolves around utilizing agents to address web-based tasks through diverse APIs. For example, Auto-GPT
         <cite class="ltx_cite ltx_citemacro_citep">
          (Gravitas,
          <a class="ltx_ref" href="#bib.bib37" title="">
           2023
          </a>
          )
         </cite>
         is an automated agent designed to set multiple objectives, break them down into relevant tasks, and iterate on these tasks until the objectives are achieved. OpenAGI
         <cite class="ltx_cite ltx_citemacro_citep">
          (Ge et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib35" title="">
           2023
          </a>
          )
         </cite>
         is an LLM-based agent designed for reasoning, planing, and executing tools to achieve complex tasks, accompanied with a benchmark to evalute the agent’s task-solving performance.
BMTools
         <cite class="ltx_cite ltx_citemacro_citep">
          (Qin et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib82" title="">
           2023a
          </a>
          )
         </cite>
         is an open-source repository that extends LLMs with tools and provides a platform for community-driven tool building and sharing. It supports various types of tools, enables simultaneous task execution using multiple tools, and offers a simple interface for loading plugins via URLs, fostering easy development and contribution to the BMTools ecosystem.
Mind2Web
         <cite class="ltx_cite ltx_citemacro_citep">
          (Deng et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib25" title="">
           2023
          </a>
          )
         </cite>
         provides a benchmark for developing and evaluating generalist agents for the Web, which are agents that can follow language instructions to complete complex tasks on websites.
MusicAgent
         <cite class="ltx_cite ltx_citemacro_citep">
          (Yu et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib133" title="">
           2023
          </a>
          )
         </cite>
         integrates numerous music-related tools and an autonomous workflow to address user requirements. Auto-UI
         <cite class="ltx_cite ltx_citemacro_citep">
          (Zhan and Zhang,
          <a class="ltx_ref" href="#bib.bib136" title="">
           2023
          </a>
          )
         </cite>
         is a multi-modal solution that directly interacts with the interface, bypassing the need for environment parsing or the dependence on application-dependent APIs.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I2.i3.p1">
        <p class="ltx_p" id="S5.I2.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i3.p1.1.1">
          Games.
         </span>
         This includes agents interacting in the game environments
         <cite class="ltx_cite ltx_citemacro_citep">
          (Hausknecht et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib40" title="">
           2020
          </a>
          ; Côté et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib22" title="">
           2019
          </a>
          ; Shridhar et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib98" title="">
           2020
          </a>
          )
         </cite>
         . For example, MineClip, introduced by
         <cite class="ltx_cite ltx_citemacro_cite">
          Fan et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib30" title="">
           2022
          </a>
          )
         </cite>
         , is a novel agent learning algorithm that leverages large pre-trained video-language models as a learned reward function. Based on it, the authors further proposed MineDojo, a framework built on the popular Minecraft game that features a simulation suite with thousands of diverse open-ended tasks and an internet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and forum discussions.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I2.i4.p1">
        <p class="ltx_p" id="S5.I2.i4.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i4.p1.1.1">
          Recommendation.
         </span>
         Recent literature demonstrates the efficacy of employing LLM and Agents in recommender systems
         <cite class="ltx_cite ltx_citemacro_citep">
          (Geng et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib36" title="">
           2022
          </a>
          ; Wang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib116" title="">
           2023c
          </a>
          ; Feng et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib31" title="">
           2023
          </a>
          ; Wang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib113" title="">
           2023f
          </a>
          )
         </cite>
         . For instance, RecMind
         <cite class="ltx_cite ltx_citemacro_citep">
          (Wang et al
          <span class="ltx_text">
           .
          </span>
          ,
          <a class="ltx_ref" href="#bib.bib116" title="">
           2023c
          </a>
          )
         </cite>
         develop an LLM-based recommender system agent, which provides personalized recommendations based on planning, use of tools, obtaining external knowledge, and leveraging individual user’s personalized data. LLMCRS
         <cite class="ltx_cite ltx_citemacro_cite">
          Feng et al
          <span class="ltx_text">
           .
          </span>
          (
          <a class="ltx_ref" href="#bib.bib31" title="">
           2023
          </a>
          )
         </cite>
         is a conversational recommendation agent that utilizes Large Language Models (LLMs) for efficient sub-task management during the recommendation process. It combines LLMs with expert models for specific sub-tasks and employs LLMs as a language interface for generating improved user responses, thereby enhancing overall performance and response quality in conversational recommendation systems.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Multi-Agent Applications
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     Multi-Agent Systems (MAS)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wooldridge and Jennings,
      <a class="ltx_ref" href="#bib.bib122" title="">
       1995
      </a>
      )
     </cite>
     emphasize the coordination and collaboration among a group of agents to effectively solve problems. The existing LLM-based MAS landscape is broadly categorized into two types: Collaborative Interaction and Adversarial Interaction.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S5.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.1
     </span>
     Collaborative Interaction
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS1.p1">
     <p class="ltx_p" id="S5.SS2.SSS1.p1.1">
      As the scope and complexity of tasks amenable to Large Language Models (LLMs) increase, a logical strategy to augment the effectiveness of these agents is to employ cooperative multi-agent systems. Such systems, prevalently utilized in practical applications, operate on the principle where each agent evaluates and understands the requirements and capabilities of its peers, thereby fostering a collaborative environment conducive to shared actions and information exchange
      <cite class="ltx_cite ltx_citemacro_citep">
       (Li et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib58" title="">
        2023
       </a>
       )
      </cite>
      .
In the specific area of Non-Player Characters (NPCs), the concept of Generative Agents
      <cite class="ltx_cite ltx_citemacro_citep">
       (Park et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib75" title="">
        2023
       </a>
       )
      </cite>
      emerges as a compelling simulation of human behavior within interactive applications. This approach is exemplified by the deployment of twenty-five agents in a sandbox environment akin to The Sims, allowing users to engage with and influence the agents as they execute daily routines, interact socially, establish relationships, and organize group activities. Furthermore, the Humanoid Agents system
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib119" title="">
        2023b
       </a>
       )
      </cite>
      enhances the realism of Generative Agents by incorporating three fundamental aspects of “System 1” processing: the fulfillment of basic needs (such as hunger, health, and energy), emotional responses, and the dynamics of interpersonal relationships.
In the field of Software Development, the MetaGPT system
      <cite class="ltx_cite ltx_citemacro_citep">
       (Hong et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib41" title="">
        2023
       </a>
       )
      </cite>
      represents a specialized LLM application that leverages a multi-agent conversational framework. This innovative framework facilitates automatic software development by assigning distinct roles to various GPT models, enabling them to collaborate effectively in the creation of software applications. Additionally, BOLAA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Liu et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib64" title="">
        2023c
       </a>
       )
      </cite>
      introduces a controller module that orchestrates the coordination and communication among multiple collaborative agents, thereby streamlining the selection and interaction processes between different labor agents. CHATDEV
      <cite class="ltx_cite ltx_citemacro_citep">
       (Qian et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib80" title="">
        2023a
       </a>
       )
      </cite>
      proposes an advanced software development framework that utilizes agents to foster enhanced collaboration among the diverse roles integral to the software development cycle.
In the domain of Conversational AI, research exemplified by
      <cite class="ltx_cite ltx_citemacro_cite">
       Fu et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib34" title="">
        2023b
       </a>
       )
      </cite>
      delves into the potential of LLMs to autonomously refine their negotiation skills. This is achieved through engaging the models in bargaining games against one another, complemented by the integration of natural language feedback from an AI critic. This study underscores the evolving capabilities of LLMs in complex, interactive settings.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.2
     </span>
     Adversarial Interaction
    </h4>
    <div class="ltx_para" id="S5.SS2.SSS2.p1">
     <p class="ltx_p" id="S5.SS2.SSS2.p1.1">
      Traditionally, collaborative methods have been extensively explored in multi-agent systems. However, researchers are increasingly recognizing that introducing concepts from game theory into systems can lead to more robust and efficient behaviors.
For example,
      <cite class="ltx_cite ltx_citemacro_cite">
       Du et al
       <span class="ltx_text">
        .
       </span>
       (
       <a class="ltx_ref" href="#bib.bib27" title="">
        2023
       </a>
       )
      </cite>
      introduce the concept of debate, endowing agents with responses from fellow peers. When these responses diverge from an agent’s own judgments, a “mental” argumentation occurs, leading to refined solutions. ChatEval
      <cite class="ltx_cite ltx_citemacro_citep">
       (Chan et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib14" title="">
        2023
       </a>
       )
      </cite>
      establishes a role-playing-based multi-agent referee team. Through self-initiated debates, agents evaluate the quality of text generated by LLMs, reaching a level of excellence comparable to human evaluators. Corex
      <cite class="ltx_cite ltx_citemacro_citep">
       (Sun et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib102" title="">
        2023
       </a>
       )
      </cite>
      is constituted by diverse collaboration paradigms including Debate, Review, and Retrieve modes, which collectively work towards enhancing the factuality, faithfulness, and reliability of the reasoning process. These paradigms foster task-agnostic approaches that enable LLMs to “think outside the box,” thereby overcoming hallucinations and providing better solutions. MAD (Multi-Agent Debate)
      <cite class="ltx_cite ltx_citemacro_citep">
       (Liang et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib59" title="">
        2023a
       </a>
       )
      </cite>
      is a framework wherein several agents engage in a “tit-for-tat” exchange of arguments under the oversight of a judge who steers the discussion towards a conclusive solution. Furthermore, WarAgent
      <cite class="ltx_cite ltx_citemacro_citep">
       (Hua et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib43" title="">
        2023a
       </a>
       )
      </cite>
      considers each country as an LLM-based agent and simulates the international conflicts among the countries using World War I, World War II, and the Warring States Period in Ancient China as examples, which showcases possible approaches towards LLM multi-agent based policy simulation and answering the “what if” questions for historical analysis.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Human-Agent Applications
   </h3>
   <div class="ltx_para" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     Most existing agent frameworks often limit themselves to defining and controlling agent behavior through system prompts, allowing the agent to independently plan and act. A notable shortcoming of this approach is the restricted, and sometimes non-existent, capacity for meaningful interaction between human users and agents, including multi-agent setups.
Addressing this gap, AutoGen
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib123" title="">
       2023
      </a>
      )
     </cite>
     offers an open-source solution enabling developers to construct LLM applications through multiple agents. Specifically, AutoGen distinguishes itself with agents that are not only customizable and conversable, but also versatile in their operational modes, which incorporate a blend of LLMs, human inputs, and tools, enhancing the interaction capabilities and efficiency of the agents.
Furthermore, AGENTS
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhou et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib141" title="">
       2023
      </a>
      )
     </cite>
     introduces a novel approach to creating controllable agents. This method involves the use of symbolic plans or standard operating procedures (SOPs), which can be generated by an LLM and subsequently modified by the user. This feature allows for greater customization and fine-tuning of agents, providing a more user-centric and adaptable agent framework.
Collectively, these developments represent a significant shift in the landscape of agent frameworks, moving towards systems that not only automate tasks but also facilitate a more interactive and collaborative environment between humans and agents.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   OS-inspired Future Directions
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    The evolution history of operating system over the past half century has witnessed the continuous development of computer hardware and the explosive growth of data, which empowers the fast iteration of Artificial Intelligence in the past decade. In this section, we enumerate the lessons learned from the history of operating systems and provide envisions of the future directions for AIOS.
   </p>
  </div>
  <section class="ltx_subsection" id="S6.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.1
    </span>
    Resource Management
   </h3>
   <section class="ltx_subsubsection" id="S6.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.1.1
     </span>
     Memory Management
    </h4>
    <div class="ltx_para" id="S6.SS1.SSS1.p1">
     <p class="ltx_p" id="S6.SS1.SSS1.p1.1">
      Physical memory (DRAM) has always been an insufficient resource from the beginning age of computer systems until now. To reduce the tension between users’ requirements and the fact of DRAM resource shortage, several approaches have been proposed in modern operating systems.
     </p>
    </div>
    <div class="ltx_para" id="S6.SS1.SSS1.p2">
     <ul class="ltx_itemize" id="S6.I1">
      <li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S6.I1.i1.p1">
        <p class="ltx_p" id="S6.I1.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">
          Swapping to external storage.
         </span>
         A dedicated partition in external storage is reserved for swapping unused memory regions to external storage in a user-transparent way, as detailed in
         <a class="ltx_ref" href="#S2.SS1.SSS1" title="2.1.1 Kernel ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
          <span class="ltx_text ltx_ref_tag">
           section
          </span>
          <span class="ltx_text ltx_ref_tag">
           2.1.1
          </span>
         </a>
         . This approach enlarges the available DRAM resources in the system.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S6.I1.i2.p1">
        <p class="ltx_p" id="S6.I1.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">
          Memory sharing.
         </span>
         To support data sharing across applications, modern operating systems provide memory sharing between applications, which provides both sharing and also reduces the extra copies of shared data.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S6.I1.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S6.I1.i3.p1">
        <p class="ltx_p" id="S6.I1.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I1.i3.p1.1.1">
          Memory disaggregation.
         </span>
         Entering the terabyte scale data, fitting the memory requirements for an application in a single operating system on a sole machine is becoming challenging. To remedy this, disaggregated memory techniques were proposed to allow an application to use memory on another machine via network. Moreover, recent Compute eXpress Link (CXL) technique
         <cite class="ltx_cite ltx_citemacro_citep">
          (CXL,
          <a class="ltx_ref" href="#bib.bib24" title="">
           2023
          </a>
          )
         </cite>
         significantly reduces the software overheads and hardware latency of remote memory access.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para" id="S6.SS1.SSS1.p3">
     <p class="ltx_p" id="S6.SS1.SSS1.p3.1">
      LLMs have revolutionized abilities, but are constrained by limited context windows, hindering their utility in tasks such as extended conversations and document analysis.
To mitigate the limited context window problem in LLMs, approaches inspired by the above operating system memory management methods can be developed. A swapping mechanism, similar to OS swapping to external storage, can be implemented in LLMs to temporarily store inactive parts of their context, effectively enlarging the context window. This would require efficient retrieval systems to minimize latency. For example, MemGPT
      <cite class="ltx_cite ltx_citemacro_citep">
       (Packer et al
       <span class="ltx_text">
        .
       </span>
       ,
       <a class="ltx_ref" href="#bib.bib72" title="">
        2023
       </a>
       )
      </cite>
      intelligently manages different memory tiers in order to effectively provide extended context within the LLM’s limited context window, and utilizes interrupts to manage control flow between itself and the user. Additionally, mirroring OS memory sharing, LLMOS can share context or learned patterns across different LLMOS-based Agent instances, reducing redundancy and allowing access to a larger shared knowledge pool for agents. Finally, drawing from memory disaggregation in modern OS, agents can leverage networked memory resources, enabling them to access and process data stored across multiple LLMOSes, thus expanding their abilities significantly. Each of these strategies, while offering potential solutions, also presents unique challenges such as managing latency, ensuring consistency in shared contexts, and handling the complexities of distributed memory systems.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.1.2
     </span>
     Tool Management
    </h4>
    <div class="ltx_para" id="S6.SS1.SSS2.p1">
     <p class="ltx_p" id="S6.SS1.SSS2.p1.1">
      Serving as external resources outside LLM, the hardware tools (e.g., robotics) and software tools (e.g., Web Search API) are the counterpart of devices and libraries in modern operating systems as shown in Table
      <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      , respectively. Taking the example of the ecosystem in modern Linux operating system–the most widely-used open source operating system community by now, here are the successful experiences in its evolving history. Specifically, a rich set of built-in and third-party libraries from thousands of experts and open-source developers leads to the success of the Linux ecosystem. Managing the install/uninstall and dependencies of those libraries, along with the versioning for tracking software development, is critical. The Linux ecosystem, over the past few decades, provides library management tools such as
      <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p1.1.1">
       dpkg
       <span class="ltx_note ltx_role_footnote" id="footnote25">
        <sup class="ltx_note_mark">
         25
        </sup>
        <span class="ltx_note_outer">
         <span class="ltx_note_content">
          <sup class="ltx_note_mark">
           25
          </sup>
          <span class="ltx_tag ltx_tag_note">
           <span class="ltx_text ltx_font_upright" id="footnote25.1.1.1">
            25
           </span>
          </span>
          <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://man7.org/linux/man-pages/man1/dpkg.1.html" target="_blank" title="">
           https://man7.org/linux/man-pages/man1/dpkg.1.html
          </a>
         </span>
        </span>
       </span>
      </span>
      in Debian-based Linux distributions, and
      <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p1.1.2">
       yum
       <span class="ltx_note ltx_role_footnote" id="footnote26">
        <sup class="ltx_note_mark">
         26
        </sup>
        <span class="ltx_note_outer">
         <span class="ltx_note_content">
          <sup class="ltx_note_mark">
           26
          </sup>
          <span class="ltx_tag ltx_tag_note">
           <span class="ltx_text ltx_font_upright" id="footnote26.1.1.1">
            26
           </span>
          </span>
          <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="http://yum.baseurl.org/" target="_blank" title="">
           http://yum.baseurl.org/
          </a>
         </span>
        </span>
       </span>
      </span>
      in RHEL-based Linux distributions.
      <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS2.p1.1.3">
       Git
       <span class="ltx_note ltx_role_footnote" id="footnote27">
        <sup class="ltx_note_mark">
         27
        </sup>
        <span class="ltx_note_outer">
         <span class="ltx_note_content">
          <sup class="ltx_note_mark">
           27
          </sup>
          <span class="ltx_tag ltx_tag_note">
           <span class="ltx_text ltx_font_upright" id="footnote27.1.1.1">
            27
           </span>
          </span>
          <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://git-scm.com/" target="_blank" title="">
           https://git-scm.com/
          </a>
         </span>
        </span>
       </span>
      </span>
      , a distributed version control system that plays a crucial role in the development of the Linux ecosystem, allows collaborative and parallel development, boost the speed of development cycles in building the Linux ecosystem.
     </p>
    </div>
    <div class="ltx_para" id="S6.SS1.SSS2.p2">
     <p class="ltx_p" id="S6.SS1.SSS2.p2.1">
      The process of code comparison in Git, particularly during merging and rebasing, typically analyzes changes at the line level rather than understanding the semantic meaning of the text. However, as discussed in Section
      <a class="ltx_ref" href="#S4.SS2" title="4.2 Natural Language Programming for Agents ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem">
       <span class="ltx_text ltx_ref_tag">
        4.2
       </span>
      </a>
      , the development of agents using natural language is increasingly achievable. Adapting existing version control software, which is based on the code or texts without knowing the semantics and contexts, for use with natural languages poses distinct challenges. First, natural languages, while structured by grammars, exhibit a loosely coupled relationship with the varied expressions of different users. Second, this loose coupling can result in natural language statements that are semantically equivalent but differ in their wording. For example, in the context of an AI agent system, the instructions “Analyze the latest sales data and generate a report” and “Generate a report based on the analysis of the most recent sales data” convey the same instruction to the agent but are phrased differently. Incorporating the ability to recognize and reconcile these semantic nuances in natural language into version control software is essential. This is especially critical in collaborative development of complex AI agent systems, where such a feature can greatly streamline development cycles by effectively managing and merging diverse natural language inputs.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S6.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.2
    </span>
    Communication
   </h3>
   <div class="ltx_para" id="S6.SS2.p1">
    <p class="ltx_p" id="S6.SS2.p1.1">
     Domain-Specific Languages (DSLs) are widely used in both native operating systems and cloud environments, which address specific requirements or tasks within a particular domain. Operating systems are often equipped with scripting languages on top of the command-line interfaces that allow users to perform various tasks collaboratively. Unix-like operating systems use shell scripting languages such as
     <span class="ltx_text ltx_font_italic" id="S6.SS2.p1.1.1">
      Bash
      <span class="ltx_note ltx_role_footnote" id="footnote28">
       <sup class="ltx_note_mark">
        28
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          28
         </sup>
         <span class="ltx_tag ltx_tag_note">
          <span class="ltx_text ltx_font_upright" id="footnote28.1.1.1">
           28
          </span>
         </span>
         <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://www.gnu.org/software/bash/" target="_blank" title="">
          https://www.gnu.org/software/bash/
         </a>
        </span>
       </span>
      </span>
     </span>
     , which is designed for automating tasks in a command-line environment. In the cloud computing, DSLs are commonly used to define infrastructure as code
     <cite class="ltx_cite ltx_citemacro_citep">
      (Sledziewski et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib99" title="">
       2010
      </a>
      )
     </cite>
     . It allows users to describe and provision cloud infrastructure resources, including virtual machines, networks, and storage; It can also be used for scheduling tasks on infrastructure resources. DSLs strike a balance between the underlying OSes and users that they are readable for both.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p2">
    <p class="ltx_p" id="S6.SS2.p2.1">
     Leveraging the wisdom gleaned from OSes, multi-AIOS communication can be enhanced by adopting structured communication protocols that are analogous to the function of DSLs in simplifying complex tasks. Just as DSLs provide a medium for users to interact effectively with the operating system and its resources, a similar specialized protocol can be established for LLMs to communicate with one another. This protocol would standardize interactions, allowing for the clear transmission of context, tasks, and goals between LLMs, thus facilitating a more coordinated and coherent multi-agent operation. It would ensure that despite the varied functionalities and knowledge bases of individual LLMs, there is a common language or method through which they can collaborate, share insights, and synchronize their learning processes. This approach mirrors the way operating systems manage resources and processes, ensuring harmonious and efficient functionality across various components of a system.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p3">
    <p class="ltx_p" id="S6.SS2.p3.1">
     In current AI Agents, the task-solving plan is still represented by natural language in most cases. However, in the future, we can even develop DSLs or semi-structured natural language grammars for representing Agent’s task-solving plans. This involves the following breakthroughs:
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p4">
    <ul class="ltx_itemize" id="S6.I2">
     <li class="ltx_item" id="S6.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S6.I2.i1.p1">
       <p class="ltx_p" id="S6.I2.i1.p1.1">
        Defining Basic Operations:
This would standardize the basic operations, tools, or commands that an AI Agent understands and can execute for task-solving.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S6.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S6.I2.i2.p1">
       <p class="ltx_p" id="S6.I2.i2.p1.1">
        Sequence of Operations: Task-solving plans would then be sequences of these basic operations, making them more structured and potentially more efficient.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S6.SS2.p5">
    <p class="ltx_p" id="S6.SS2.p5.1">
     Using LLM to interpret users’ natural language instructions into a DSL-composed plan brings several benefits, including 1) Improved Consistency: Standardized operations would lead to more predictable and consistent outcomes; 2) Easier to Interpret: A well-defined DSL makes it easier for AI Agents to interpret and execute plans; and 3) Scalability: With a standard DSL, it is easier to scale solutions across different platforms and applications.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p6">
    <p class="ltx_p" id="S6.SS2.p6.1">
     However, achieving this goal also meets some important challenges that need future research attention: 1) Complexity of Natural Language: Natural language is inherently ambiguous and context-dependent, making it challenging to convert instructions into structured plans consistently; 2) Flexibility vs. Standardization: Striking a balance between the flexibility of natural language and the rigidity of a standardized DSL; 3) Interoperability: Ensuring the DSL works well with a wide range of tools and platforms; and 4) Adaptation and Learning: The system needs to continuously learn and adapt to new instructions, tools, and tasks.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS2.p7">
    <p class="ltx_p" id="S6.SS2.p7.1">
     Overall, the use of a large language model as an interpreter (LLM as Interpreter), which can translate natural language described plans to DSL described plans, can be an important direction to create task-solving plans, and to bridge LLM as OS (LLMOS) and Agent Applications (AAP). The development of a DSL for such plans could further streamline and standardize the process, though it would come with its own set of challenges. This approach has the potential to make complex task execution more accessible and efficient, paving the way for more advanced AI systems in the future.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.3
    </span>
    Security
   </h3>
   <div class="ltx_para" id="S6.SS3.p1">
    <p class="ltx_p" id="S6.SS3.p1.1">
     Security has been an important issue as the wide-spread of operating systems from labs to our daily life in the 1980s. The consequences of the operating system vulnerabilities can be roughly categorized as following.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS3.p2">
    <ul class="ltx_itemize" id="S6.I3">
     <li class="ltx_item" id="S6.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S6.I3.i1.p1">
       <p class="ltx_p" id="S6.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S6.I3.i1.p1.1.1">
         Breaking down the system.
        </span>
        In its early stages, viruses like the
        <span class="ltx_text ltx_font_italic" id="S6.I3.i1.p1.1.2">
         Morris Worm
        </span>
        <cite class="ltx_cite ltx_citemacro_citep">
         (Orman,
         <a class="ltx_ref" href="#bib.bib70" title="">
          2003
         </a>
         )
        </cite>
        were primarily created to compromise operating systems, serving as a demonstration of individual programmers’ prowess in hacking. While these attacks did not result in direct financial losses, users faced potential harm through the compromise of personal data or critical workplace documents.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S6.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S6.I3.i2.p1">
       <p class="ltx_p" id="S6.I3.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S6.I3.i2.p1.1.1">
         Racketeering.
        </span>
        In later stages, vulnerabilities within operating systems became targets for illicit activities, including the exploitation of users for racketeering purposes. An example of this is the
        <span class="ltx_text ltx_font_italic" id="S6.I3.i2.p1.1.2">
         WannaCry Ransomware
         <span class="ltx_note ltx_role_footnote" id="footnote29">
          <sup class="ltx_note_mark">
           29
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             29
            </sup>
            <span class="ltx_tag ltx_tag_note">
             <span class="ltx_text ltx_font_upright" id="footnote29.1.1.1">
              29
             </span>
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://nvd.nist.gov/vuln/detail/cve-2017-0143" target="_blank" title="">
             https://nvd.nist.gov/vuln/detail/cve-2017-0143
            </a>
           </span>
          </span>
         </span>
        </span>
        , which encrypts users’ files and demands a ransom for their release. Additionally, banking trojans like
        <span class="ltx_text ltx_font_italic" id="S6.I3.i2.p1.1.3">
         Zeus
         <span class="ltx_note ltx_role_footnote" id="footnote30">
          <sup class="ltx_note_mark">
           30
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             30
            </sup>
            <span class="ltx_tag ltx_tag_note">
             <span class="ltx_text ltx_font_upright" id="footnote30.1.1.1">
              30
             </span>
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://nvd.nist.gov/vuln/detail/cve-2010-0188" target="_blank" title="">
             https://nvd.nist.gov/vuln/detail/cve-2010-0188
            </a>
           </span>
          </span>
         </span>
        </span>
        exploit vulnerabilities by intercepting communication channels between users and banking systems, resulting in direct financial losses for the affected users.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S6.I3.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S6.I3.i3.p1">
       <p class="ltx_p" id="S6.I3.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S6.I3.i3.p1.1.1">
         Stealing Resource.
        </span>
        Malicious software, such as
        <span class="ltx_text ltx_font_italic" id="S6.I3.i3.p1.1.2">
         Coinhive
         <span class="ltx_note ltx_role_footnote" id="footnote31">
          <sup class="ltx_note_mark">
           31
          </sup>
          <span class="ltx_note_outer">
           <span class="ltx_note_content">
            <sup class="ltx_note_mark">
             31
            </sup>
            <span class="ltx_tag ltx_tag_note">
             <span class="ltx_text ltx_font_upright" id="footnote31.1.1.1">
              31
             </span>
            </span>
            <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="https://krebsonsecurity.com/2018/03/who-and-what-is-coinhive/" target="_blank" title="">
             https://krebsonsecurity.com/2018/03/who-and-what-is-coinhive/
            </a>
           </span>
          </span>
         </span>
        </span>
        , is crafted to harness the computing power of other machines for cryptocurrency mining, including Bitcoin. While it may not inflict direct harm on operating systems, the substantial utilization of CPU and memory resources can significantly impair the overall system performance. In cloud environments, this slowdown has the potential to translate into financial losses, making it imperative to address such threats proactively.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S6.SS3.p3">
    <p class="ltx_p" id="S6.SS3.p3.1">
     Security vulnerabilities in operating systems are hard to prevent. The state-of-the-art approaches detect and capture those malware and virus at different levels.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS3.p4">
    <ul class="ltx_itemize" id="S6.I4">
     <li class="ltx_item" id="S6.I4.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S6.I4.i1.p1">
       <p class="ltx_p" id="S6.I4.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S6.I4.i1.p1.1.1">
         Static Analysis.
        </span>
        This approach conducts code-level or binary-level analyses by examining the code or binary image of an application or part of the OS. It is often performed when a third-party application is published to the cloud, or when a file is downloaded to the file system in a user’s operating system.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S6.I4.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S6.I4.i2.p1">
       <p class="ltx_p" id="S6.I4.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S6.I4.i2.p1.1.1">
         Fuzzing.
        </span>
        Fuzzing (Fuzz Testing) involves the automated generation of a large number of random or semi-random inputs to a program to discover vulnerabilities, crashes, or unexpected behaviors.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S6.SS3.p5">
    <p class="ltx_p" id="S6.SS3.p5.1">
     Similarly, adversarial attacks have been the subject of extensive study in LLM research
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib120" title="">
       2023
      </a>
      ; Zou et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib143" title="">
       2023
      </a>
      ; Qi et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib78" title="">
       2023a
      </a>
      ; Yang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib126" title="">
       2023c
      </a>
      )
     </cite>
     , representing a significant threat to the security of AIOS. Furthermore, research
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yang et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib127" title="">
       2023b
      </a>
      ; Qi et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib79" title="">
       2023b
      </a>
      )
     </cite>
     has revealed that an aligned LLM can be broken using a very small dataset comprising only a few hundred data points. This vulnerability is not only a significant concern in terms of system integrity but also raises alarming implications for the safety of agents interacting with these systems. How to be robust and defend against such attacks has yet to be studied in the context of AIOS, LLMOS, and Agents.
    </p>
   </div>
   <div class="ltx_para" id="S6.SS3.p6">
    <p class="ltx_p" id="S6.SS3.p6.1">
     Looking into the future, as agent applications in AIOS evolve to be programmed by natural language, the intricacy of scanning the code of such applications will increase due to the expansive and less structured nature of natural language compared to the constrained syntax of programming languages. This necessitates a robust and effective scanning tool for AIOS agents. Moreover, fuzzing can be seen as an initial step towards creating a Red-teaming dataset for LLMOS-based Agents. For instance,
     <cite class="ltx_cite ltx_citemacro_cite">
      Ruan et al
      <span class="ltx_text">
       .
      </span>
      (
      <a class="ltx_ref" href="#bib.bib89" title="">
       2023b
      </a>
      )
     </cite>
     have developed a multi-agent system that generates red-teaming scenarios for LLM-based agents, using GPT-4 to simulate adversarial environments within textual scenarios. The study provides a rich array of scenarios that serve as a valuable resource for future research into the alignment of LLM-based Agents.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Conclusions
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    This paper presents a novel vision for the future of computing within the AIOS-Agent ecosystem, where the LLM functions as the core of AIOS. This innovative approach marks a significant departure from the conventional OS-APP ecosystem, heralding a new era in technology where AI and traditional computing systems merge seamlessly. The AIOS-Agent ecosystem envisaged here is not just an incremental change but a fundamental shift in how we interact with technology. By positioning LLM at the system level, Agents as applications, Tools as devices/libraries, and Natural Language as the Programming Interface, we redefine the interaction between users, developers, and the digital world. This paradigm shift promises to democratize software development and access, allowing users and developers to program Agent Applications (AAPs) using natural language. This accessibility contrasts sharply with the traditional ecosystem, where software development is confined to those with specialized programming skills. Moreover, the discussion of single and multi-agent systems, as well as human-agent interactions, illustrates the potential of AIOS in enhancing productivity, creativity, and decision-making processes across various domains. Looking ahead, the proposed strategic roadmap, informed by the developmental trajectory of the traditional OS-APP ecosystem, offers a pragmatic and systematic approach to the evolution of AIOS and its Agent Applications. This roadmap not only guides future development and research in this field but also anticipates the challenges and opportunities that lie ahead.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (1)
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Agarwal et al
     <span class="ltx_text" id="bib.bib2.2.2.1">
      .
     </span>
     (2006)
    </span>
    <span class="ltx_bibblock">
     Amit Agarwal, Saibal
Mukhopadhyay, Arijit Raychowdhury,
Kaushik Roy, and Chris H Kim.
2006.
    </span>
    <span class="ltx_bibblock">
     Leakage power analysis and reduction for nanoscale
circuits.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">
      IEeE Micro
     </em>
     26,
2 (2006), 68–80.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahn et al
     <span class="ltx_text" id="bib.bib3.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Michael Ahn, Anthony
Brohan, Noah Brown, Yevgen Chebotar,
Omar Cortes, Byron David,
Chelsea Finn, Chuyuan Fu,
Keerthana Gopalakrishnan, Karol Hausman,
et al
     <span class="ltx_text" id="bib.bib3.3.1">
      .
     </span>
     2022.
    </span>
    <span class="ltx_bibblock">
     Do as i can, not as i say: Grounding language in
robotic affordances.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.4.1">
      arXiv preprint arXiv:2204.01691
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ainslie et al
     <span class="ltx_text" id="bib.bib4.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Joshua Ainslie, James
Lee-Thorp, Michiel de Jong, Yury
Zemlyanskiy, Federico Lebrón, and
Sumit Sanghai. 2023.
    </span>
    <span class="ltx_bibblock">
     GQA: Training Generalized Multi-Query Transformer
Models from Multi-Head Checkpoints.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">
      arXiv preprint arXiv:2305.13245
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ainslie et al
     <span class="ltx_text" id="bib.bib5.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Joshua Ainslie, Santiago
Ontanon, Chris Alberti, Vaclav Cvicek,
Zachary Fisher, Philip Pham,
Anirudh Ravula, Sumit Sanghai,
Qifan Wang, and Li Yang.
2020.
    </span>
    <span class="ltx_bibblock">
     ETC: Encoding long and structured inputs in
transformers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">
      arXiv preprint arXiv:2004.08483
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Beltagy et al
     <span class="ltx_text" id="bib.bib6.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Iz Beltagy, Matthew E
Peters, and Arman Cohan.
2020.
    </span>
    <span class="ltx_bibblock">
     Longformer: The long-document transformer.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">
      arXiv preprint arXiv:2004.05150
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Besta et al
     <span class="ltx_text" id="bib.bib7.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Maciej Besta, Nils Blach,
Ales Kubicek, Robert Gerstenberger,
Lukas Gianinazzi, Joanna Gajda,
Tomasz Lehmann, Michal Podstawski,
Hubert Niewiadomski, Piotr Nyczyk,
et al
     <span class="ltx_text" id="bib.bib7.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Graph of thoughts: Solving elaborate problems with
large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.4.1">
      arXiv preprint arXiv:2308.09687
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Boiko et al
     <span class="ltx_text" id="bib.bib8.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Daniil A Boiko, Robert
MacKnight, and Gabe Gomes.
2023.
    </span>
    <span class="ltx_bibblock">
     Emergent autonomous scientific research
capabilities of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">
      arXiv preprint arXiv:2304.05332
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Borgeaud et al
     <span class="ltx_text" id="bib.bib9.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Sebastian Borgeaud, Arthur
Mensch, Jordan Hoffmann, Trevor Cai,
Eliza Rutherford, Katie Millican,
George Bm Van Den Driessche, Jean-Baptiste
Lespiau, Bogdan Damoc, Aidan Clark,
et al
     <span class="ltx_text" id="bib.bib9.3.1">
      .
     </span>
     2022.
    </span>
    <span class="ltx_bibblock">
     Improving language models by retrieving from
trillions of tokens. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.4.1">
      International conference
on machine learning
     </em>
     . PMLR, 2206–2240.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bran et al
     <span class="ltx_text" id="bib.bib10.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Andres M Bran, Sam Cox,
Andrew D White, and Philippe
Schwaller. 2023.
    </span>
    <span class="ltx_bibblock">
     ChemCrow: Augmenting large-language models with
chemistry tools.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">
      arXiv preprint arXiv:2304.05376
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bratman et al
     <span class="ltx_text" id="bib.bib11.2.2.1">
      .
     </span>
     (1988)
    </span>
    <span class="ltx_bibblock">
     Michael E Bratman, David J
Israel, and Martha E Pollack.
1988.
    </span>
    <span class="ltx_bibblock">
     Plans and resource-bounded practical reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">
      Computational intelligence
     </em>
     4, 3 (1988),
349–355.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al
     <span class="ltx_text" id="bib.bib12.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann,
Nick Ryder, Melanie Subbiah,
Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam,
Girish Sastry, Amanda Askell,
et al
     <span class="ltx_text" id="bib.bib12.3.1">
      .
     </span>
     2020.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.4.1">
      Advances in neural information processing
systems
     </em>
     33 (2020),
1877–1901.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bubeck et al
     <span class="ltx_text" id="bib.bib13.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Sébastien Bubeck, Varun
Chandrasekaran, Ronen Eldan, Johannes
Gehrke, Eric Horvitz, Ece Kamar,
Peter Lee, Yin Tat Lee,
Yuanzhi Li, Scott Lundberg,
Harsha Nori, Hamid Palangi,
Marco Tulio Ribeiro, and Yi Zhang.
2023.
    </span>
    <span class="ltx_bibblock">
     Sparks of Artificial General Intelligence: Early
experiments with GPT-4.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.12712 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chan et al
     <span class="ltx_text" id="bib.bib14.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Chi-Min Chan, Weize Chen,
Yusheng Su, Jianxuan Yu,
Wei Xue, Shanghang Zhang,
Jie Fu, and Zhiyuan Liu.
2023.
    </span>
    <span class="ltx_bibblock">
     ChatEval: Towards Better LLM-based Evaluators through
Multi-Agent Debate.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2308.07201 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chase (2022)
    </span>
    <span class="ltx_bibblock">
     Harrison Chase.
2022.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      LangChain
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/hwchase17/langchain" target="_blank" title="">
      https://github.com/hwchase17/langchain
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib16.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Changan Chen, Unnat Jain,
Carl Schissler, Sebastia Vicenc Amengual
Gari, Ziad Al-Halah, Vamsi Krishna
Ithapu, Philip Robinson, and Kristen
Grauman. 2020.
    </span>
    <span class="ltx_bibblock">
     Soundspaces: Audio-visual navigation in 3d
environments. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">
      Computer Vision–ECCV 2020: 16th
European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part VI
16
     </em>
     . Springer, 17–36.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib17.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek,
Heewoo Jun, Qiming Yuan,
Henrique Ponde de Oliveira Pinto, Jared
Kaplan, Harri Edwards, Yuri Burda,
Nicholas Joseph, Greg Brockman,
et al
     <span class="ltx_text" id="bib.bib17.3.1">
      .
     </span>
     2021.
    </span>
    <span class="ltx_bibblock">
     Evaluating large language models trained on code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.4.1">
      arXiv preprint arXiv:2107.03374
     </em>
     (2021).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib18.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Shouyuan Chen, Sherman
Wong, Liangjian Chen, and Yuandong
Tian. 2023b.
    </span>
    <span class="ltx_bibblock">
     Extending context window of large language models
via positional interpolation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">
      arXiv preprint arXiv:2306.15595
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al
     <span class="ltx_text" id="bib.bib19.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Xinyun Chen, Maxwell Lin,
Nathanael Schärli, and Denny Zhou.
2023a.
    </span>
    <span class="ltx_bibblock">
     Teaching large language models to self-debug.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">
      arXiv preprint arXiv:2304.05128
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Corbató et al
     <span class="ltx_text" id="bib.bib20.2.2.1">
      .
     </span>
     (1971)
    </span>
    <span class="ltx_bibblock">
     F. J. Corbató, J. H.
Saltzer, and C. T. Clingen.
1971.
    </span>
    <span class="ltx_bibblock">
     Multics: The First Seven Years. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">
      Proceedings of the May 16-18, 1972, Spring Joint
Computer Conference
     </em>
     (Atlantic City, New Jersey)
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.4.2">
      (AFIPS ’72 (Spring))
     </em>
     .
Association for Computing Machinery,
New York, NY, USA, 571–583.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1478873.1478950" target="_blank" title="">
      https://doi.org/10.1145/1478873.1478950
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Corbet et al
     <span class="ltx_text" id="bib.bib21.2.2.1">
      .
     </span>
     (2005)
    </span>
    <span class="ltx_bibblock">
     Jonathan Corbet,
Alessandro Rubini, and Greg
Kroah-Hartman. 2005.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">
      Linux Device Drivers, 3rd Edition
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     O’Reilly Media, Inc.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Côté et al
     <span class="ltx_text" id="bib.bib22.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Marc-Alexandre Côté,
Akos Kádár, Xingdi Yuan,
Ben Kybartas, Tavian Barnes,
Emery Fine, James Moore,
Matthew Hausknecht, Layla El Asri,
Mahmoud Adada, et al
     <span class="ltx_text" id="bib.bib22.3.1">
      .
     </span>
     2019.
    </span>
    <span class="ltx_bibblock">
     Textworld: A learning environment for text-based
games. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.4.1">
      Computer Games: 7th Workshop, CGW 2018,
Held in Conjunction with the 27th International Conference on Artificial
Intelligence, IJCAI 2018, Stockholm, Sweden, July 13, 2018, Revised Selected
Papers 7
     </em>
     . Springer, 41–75.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Croft et al
     <span class="ltx_text" id="bib.bib23.2.2.1">
      .
     </span>
     (2010)
    </span>
    <span class="ltx_bibblock">
     W Bruce Croft, Donald
Metzler, and Trevor Strohman.
2010.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">
      Search engines: Information retrieval in
practice
     </em>
     . Vol. 520.
    </span>
    <span class="ltx_bibblock">
     Addison-Wesley Reading.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     CXL (2023)
    </span>
    <span class="ltx_bibblock">
     CXL. 2023.
    </span>
    <span class="ltx_bibblock">
     Compute Express Link Specification.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.computeexpresslink.org/" target="_blank" title="">
      https://www.computeexpresslink.org/
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Deng et al
     <span class="ltx_text" id="bib.bib25.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Xiang Deng, Yu Gu,
Boyuan Zheng, Shijie Chen,
Samuel Stevens, Boshi Wang,
Huan Sun, and Yu Su.
2023.
    </span>
    <span class="ltx_bibblock">
     Mind2Web: Towards a Generalist Agent for the Web.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">
      arXiv preprint arXiv:2306.06070
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Devlin et al
     <span class="ltx_text" id="bib.bib26.2.2.1">
      .
     </span>
     (2018)
    </span>
    <span class="ltx_bibblock">
     Jacob Devlin, Ming-Wei
Chang, Kenton Lee, and Kristina
Toutanova. 2018.
    </span>
    <span class="ltx_bibblock">
     Bert: Pre-training of deep bidirectional
transformers for language understanding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">
      arXiv preprint arXiv:1810.04805
     </em>
     (2018).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Du et al
     <span class="ltx_text" id="bib.bib27.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yilun Du, Shuang Li,
Antonio Torralba, Joshua B. Tenenbaum,
and Igor Mordatch. 2023.
    </span>
    <span class="ltx_bibblock">
     Improving Factuality and Reasoning in Language Models
through Multiagent Debate.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.14325 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Durmus et al
     <span class="ltx_text" id="bib.bib28.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Esin Durmus, Karina
Nyugen, Thomas I Liao, Nicholas
Schiefer, Amanda Askell, Anton Bakhtin,
Carol Chen, Zac Hatfield-Dodds,
Danny Hernandez, Nicholas Joseph,
et al
     <span class="ltx_text" id="bib.bib28.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Towards measuring the representation of subjective
global opinions in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.4.1">
      arXiv preprint arXiv:2306.16388
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fainstein and DeFilippis (2015)
    </span>
    <span class="ltx_bibblock">
     Susan S Fainstein and
James DeFilippis. 2015.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      Readings in planning theory
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     John Wiley &amp; Sons.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fan et al
     <span class="ltx_text" id="bib.bib30.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Linxi Fan, Guanzhi Wang,
Yunfan Jiang, Ajay Mandlekar,
Yuncong Yang, Haoyi Zhu,
Andrew Tang, De-An Huang,
Yuke Zhu, and Anima Anandkumar.
2022.
    </span>
    <span class="ltx_bibblock">
     Minedojo: Building open-ended embodied agents with
internet-scale knowledge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">
      Advances in Neural Information Processing
Systems
     </em>
     35 (2022),
18343–18362.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al
     <span class="ltx_text" id="bib.bib31.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yue Feng, Shuchang Liu,
Zhenghai Xue, Qingpeng Cai,
Lantao Hu, Peng Jiang,
Kun Gai, and Fei Sun.
2023.
    </span>
    <span class="ltx_bibblock">
     A Large Language Model Enhanced Conversational
Recommender System.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">
      arXiv preprint arXiv:2308.06212
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Franceschelli and Musolesi (2023)
    </span>
    <span class="ltx_bibblock">
     Giorgio Franceschelli and
Mirco Musolesi. 2023.
    </span>
    <span class="ltx_bibblock">
     On the creativity of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2304.00008
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al
     <span class="ltx_text" id="bib.bib33.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Daocheng Fu, Xin Li,
Licheng Wen, Min Dou,
Pinlong Cai, Botian Shi, and
Yu Qiao. 2023a.
    </span>
    <span class="ltx_bibblock">
     Drive Like a Human: Rethinking Autonomous Driving
with Large Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2307.07162 [cs.RO]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al
     <span class="ltx_text" id="bib.bib34.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Yao Fu, Hao Peng,
Tushar Khot, and Mirella Lapata.
2023b.
    </span>
    <span class="ltx_bibblock">
     Improving language model negotiation with self-play
and in-context learning from ai feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">
      arXiv preprint arXiv:2305.10142
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ge et al
     <span class="ltx_text" id="bib.bib35.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yingqiang Ge, Wenyue Hua,
Kai Mei, jianchao ji,
Juntao Tan, Shuyuan Xu,
Zelong Li, and Yongfeng Zhang.
2023.
    </span>
    <span class="ltx_bibblock">
     OpenAGI: When LLM Meets Domain Experts. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">
      Thirty-seventh Conference on Neural Information
Processing Systems
     </em>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Geng et al
     <span class="ltx_text" id="bib.bib36.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Shijie Geng, Shuchang
Liu, Zuohui Fu, Yingqiang Ge, and
Yongfeng Zhang. 2022.
    </span>
    <span class="ltx_bibblock">
     Recommendation as Language Processing (RLP): A
Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5). In
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">
      Proceedings of the 16th ACM Conference on
Recommender Systems
     </em>
     . 299–315.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gravitas (2023)
    </span>
    <span class="ltx_bibblock">
     Significant Gravitas.
2023.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      AutoGPT
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://news.agpt.co/" target="_blank" title="">
      https://news.agpt.co/
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gray et al
     <span class="ltx_text" id="bib.bib38.2.2.1">
      .
     </span>
     (2017)
    </span>
    <span class="ltx_bibblock">
     Scott Gray, Alec Radford,
and Diederik P Kingma. 2017.
    </span>
    <span class="ltx_bibblock">
     Gpu kernels for block-sparse weights.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">
      arXiv preprint arXiv:1711.09224
     </em>
     3, 2 (2017),
2.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guu et al
     <span class="ltx_text" id="bib.bib39.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Kelvin Guu, Kenton Lee,
Zora Tung, Panupong Pasupat, and
Mingwei Chang. 2020.
    </span>
    <span class="ltx_bibblock">
     Retrieval augmented language model pre-training.
In
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">
      International conference on machine learning
     </em>
     .
PMLR, 3929–3938.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hausknecht et al
     <span class="ltx_text" id="bib.bib40.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Matthew Hausknecht,
Prithviraj Ammanabrolu, Marc-Alexandre
Côté, and Xingdi Yuan.
2020.
    </span>
    <span class="ltx_bibblock">
     Interactive fiction games: A colossal adventure.
In
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">
      Proceedings of the AAAI Conference on Artificial
Intelligence
     </em>
     , Vol. 34. 7903–7910.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hong et al
     <span class="ltx_text" id="bib.bib41.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Sirui Hong, Xiawu Zheng,
Jonathan Chen, Yuheng Cheng,
Ceyao Zhang, Zili Wang,
Steven Ka Shing Yau, Zijuan Lin,
Liyang Zhou, Chenyu Ran, et al
     <span class="ltx_text" id="bib.bib41.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Metagpt: Meta programming for multi-agent
collaborative framework.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.4.1">
      arXiv preprint arXiv:2308.00352
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al
     <span class="ltx_text" id="bib.bib42.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Chenxu Hu, Jie Fu,
Chenzhuang Du, Simian Luo,
Junbo Zhao, and Hang Zhao.
2023.
    </span>
    <span class="ltx_bibblock">
     ChatDB: Augmenting LLMs with Databases as Their
Symbolic Memory.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">
      arXiv preprint arXiv:2306.03901
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hua et al
     <span class="ltx_text" id="bib.bib43.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Wenyue Hua, Lizhou Fan,
Lingyao Li, Kai Mei,
Jianchao Ji, Yingqiang Ge,
Libby Hemphill, and Yongfeng Zhang.
2023a.
    </span>
    <span class="ltx_bibblock">
     War and Peace (WarAgent): Large Language
Model-based Multi-Agent Simulation of World Wars.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">
      arXiv preprint arXiv:2311.17227
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hua et al
     <span class="ltx_text" id="bib.bib44.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Wenyue Hua, Shuyuan Xu,
Yingqiang Ge, and Yongfeng Zhang.
2023b.
    </span>
    <span class="ltx_bibblock">
     How to Index Item IDs for Recommendation Foundation
Models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">
      Proceedings of the Annual International
ACM SIGIR Conference on Research and Development in Information Retrieval in
the Asia Pacific Region
     </em>
     . 195–204.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang and Chang (2022)
    </span>
    <span class="ltx_bibblock">
     Jie Huang and Kevin
Chen-Chuan Chang. 2022.
    </span>
    <span class="ltx_bibblock">
     Towards reasoning in large language models: A
survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      arXiv preprint arXiv:2212.10403
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al
     <span class="ltx_text" id="bib.bib46.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Qian Huang, Jian Vora,
Percy Liang, and Jure Leskovec.
2023.
    </span>
    <span class="ltx_bibblock">
     Benchmarking Large Language Models As AI Research
Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">
      arXiv preprint arXiv:2310.03302
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     IEEE and Group (2018)
    </span>
    <span class="ltx_bibblock">
     IEEE and The Open
Group. 2018.
    </span>
    <span class="ltx_bibblock">
     The POSIX standard.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/" target="_blank" title="">
      https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Izacard et al
     <span class="ltx_text" id="bib.bib48.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Gautier Izacard, Patrick
Lewis, Maria Lomeli, Lucas Hosseini,
Fabio Petroni, Timo Schick,
Jane Dwivedi-Yu, Armand Joulin,
Sebastian Riedel, and Edouard Grave.
2022.
    </span>
    <span class="ltx_bibblock">
     Few-shot learning with retrieval augmented language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">
      arXiv preprint arXiv:2208.03299
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al
     <span class="ltx_text" id="bib.bib49.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Huiqiang Jiang, Qianhui
Wu, Chin-Yew Lin, Yuqing Yang, and
Lili Qiu. 2023.
    </span>
    <span class="ltx_bibblock">
     Llmlingua: Compressing prompts for accelerated
inference of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">
      arXiv preprint arXiv:2310.05736
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Johnson et al
     <span class="ltx_text" id="bib.bib50.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Jeff Johnson, Matthijs
Douze, and Hervé Jégou.
2019.
    </span>
    <span class="ltx_bibblock">
     Billion-scale similarity search with gpus.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">
      IEEE Transactions on Big Data
     </em>
     7, 3 (2019),
535–547.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Karpukhin et al
     <span class="ltx_text" id="bib.bib51.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Vladimir Karpukhin, Barlas
Oğuz, Sewon Min, Patrick Lewis,
Ledell Wu, Sergey Edunov,
Danqi Chen, and Wen-tau Yih.
2020.
    </span>
    <span class="ltx_bibblock">
     Dense passage retrieval for open-domain question
answering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">
      arXiv preprint arXiv:2004.04906
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Katharopoulos et al
     <span class="ltx_text" id="bib.bib52.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Angelos Katharopoulos,
Apoorv Vyas, Nikolaos Pappas, and
François Fleuret. 2020.
    </span>
    <span class="ltx_bibblock">
     Transformers are rnns: Fast autoregressive
transformers with linear attention. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">
      International conference on machine learning
     </em>
     .
PMLR, 5156–5165.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kim et al
     <span class="ltx_text" id="bib.bib53.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Geunwoo Kim, Pierre
Baldi, and Stephen McAleer.
2023.
    </span>
    <span class="ltx_bibblock">
     Language Models can Solve Computer Tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.3.1">
      arXiv preprint arXiv:2303.17491
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kitaev et al
     <span class="ltx_text" id="bib.bib54.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Nikita Kitaev, Łukasz
Kaiser, and Anselm Levskaya.
2020.
    </span>
    <span class="ltx_bibblock">
     Reformer: The efficient transformer.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">
      arXiv preprint arXiv:2001.04451
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kojima et al
     <span class="ltx_text" id="bib.bib55.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Takeshi Kojima,
Shixiang Shane Gu, Machel Reid,
Yutaka Matsuo, and Yusuke Iwasawa.
2022.
    </span>
    <span class="ltx_bibblock">
     Large language models are zero-shot reasoners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">
      Advances in neural information processing
systems
     </em>
     35 (2022),
22199–22213.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lee et al
     <span class="ltx_text" id="bib.bib56.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Gibbeum Lee, Volker
Hartmann, Jongho Park, Dimitris
Papailiopoulos, and Kangwook Lee.
2023.
    </span>
    <span class="ltx_bibblock">
     Prompted LLMs as Chatbot Modules for Long
Open-domain Conversation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">
      arXiv preprint arXiv:2305.04533
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewis et al
     <span class="ltx_text" id="bib.bib57.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Patrick Lewis, Ethan
Perez, Aleksandra Piktus, Fabio Petroni,
Vladimir Karpukhin, Naman Goyal,
Heinrich Küttler, Mike Lewis,
Wen-tau Yih, Tim Rocktäschel,
et al
     <span class="ltx_text" id="bib.bib57.3.1">
      .
     </span>
     2020.
    </span>
    <span class="ltx_bibblock">
     Retrieval-augmented generation for
knowledge-intensive nlp tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.4.1">
      Advances in Neural Information Processing
Systems
     </em>
     33 (2020),
9459–9474.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al
     <span class="ltx_text" id="bib.bib58.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Guohao Li, Hasan Abed
Al Kader Hammoud, Hani Itani, Dmitrii
Khizbullin, and Bernard Ghanem.
2023.
    </span>
    <span class="ltx_bibblock">
     CAMEL: Communicative Agents for "Mind" Exploration of
Large Scale Language Model Society.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2303.17760 [cs.AI]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang et al
     <span class="ltx_text" id="bib.bib59.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Tian Liang, Zhiwei He,
Wenxiang Jiao, Xing Wang,
Yan Wang, Rui Wang,
Yujiu Yang, Zhaopeng Tu, and
Shuming Shi. 2023a.
    </span>
    <span class="ltx_bibblock">
     Encouraging Divergent Thinking in Large Language
Models through Multi-Agent Debate.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2305.19118 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang et al
     <span class="ltx_text" id="bib.bib60.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Yaobo Liang, Chenfei Wu,
Ting Song, Wenshan Wu,
Yan Xia, Yu Liu, Yang
Ou, Shuai Lu, Lei Ji,
Shaoguang Mao, et al
     <span class="ltx_text" id="bib.bib60.3.1">
      .
     </span>
     2023b.
    </span>
    <span class="ltx_bibblock">
     Taskmatrix. ai: Completing tasks by connecting
foundation models with millions of apis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.4.1">
      arXiv preprint arXiv:2303.16434
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu (2022)
    </span>
    <span class="ltx_bibblock">
     Jerry Liu.
2022.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">
      LlamaIndex
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.1234" target="_blank" title="">
      https://doi.org/10.5281/zenodo.1234
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al
     <span class="ltx_text" id="bib.bib62.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Nelson F Liu, Kevin Lin,
John Hewitt, Ashwin Paranjape,
Michele Bevilacqua, Fabio Petroni, and
Percy Liang. 2023b.
    </span>
    <span class="ltx_bibblock">
     Lost in the middle: How language models use long
contexts.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">
      arXiv preprint arXiv:2307.03172
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al
     <span class="ltx_text" id="bib.bib63.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Zhihan Liu, Hao Hu,
Shenao Zhang, Hongyi Guo,
Shuqi Ke, Boyi Liu, and
Zhaoran Wang. 2023a.
    </span>
    <span class="ltx_bibblock">
     Reason for Future, Act for Now: A Principled
Framework for Autonomous LLM Agents with Provable Sample Efficiency.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.3.1">
      arXiv preprint arXiv:2309.17382
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al
     <span class="ltx_text" id="bib.bib64.2.2.1">
      .
     </span>
     (2023c)
    </span>
    <span class="ltx_bibblock">
     Zhiwei Liu, Weiran Yao,
Jianguo Zhang, Le Xue,
Shelby Heinecke, Rithesh Murthy,
Yihao Feng, Zeyuan Chen,
Juan Carlos Niebles, Devansh Arpit,
et al
     <span class="ltx_text" id="bib.bib64.3.1">
      .
     </span>
     2023c.
    </span>
    <span class="ltx_bibblock">
     BOLAA: Benchmarking and Orchestrating LLM-augmented
Autonomous Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.4.1">
      arXiv preprint arXiv:2308.05960
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lu et al
     <span class="ltx_text" id="bib.bib65.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Junru Lu, Siyu An,
Mingbao Lin, Gabriele Pergola,
Yulan He, Di Yin, Xing
Sun, and Yunsheng Wu. 2023.
    </span>
    <span class="ltx_bibblock">
     MemoChat: Tuning LLMs to Use Memos for Consistent
Long-Range Open-Domain Conversation.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2308.08239 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Molnár (2007)
    </span>
    <span class="ltx_bibblock">
     Ingo Molnár.
2007.
    </span>
    <span class="ltx_bibblock">
     Linux CFS Scheduler.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://docs.kernel.org/scheduler/sched-design-CFS.html" target="_blank" title="">
      https://docs.kernel.org/scheduler/sched-design-CFS.html
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Morris et al
     <span class="ltx_text" id="bib.bib67.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Meredith Ringel Morris,
Jascha Sohl-dickstein, Noah Fiedel,
Tris Warkentin, Allan Dafoe,
Aleksandra Faust, Clement Farabet, and
Shane Legg. 2023.
    </span>
    <span class="ltx_bibblock">
     Levels of AGI: Operationalizing Progress on the
Path to AGI.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.3.1">
      arXiv preprint arXiv:2311.02462
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nakano et al
     <span class="ltx_text" id="bib.bib68.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Reiichiro Nakano, Jacob
Hilton, Suchir Balaji, Jeff Wu,
Long Ouyang, Christina Kim,
Christopher Hesse, Shantanu Jain,
Vineet Kosaraju, William Saunders,
Xu Jiang, Karl Cobbe,
Tyna Eloundou, Gretchen Krueger,
Kevin Button, Matthew Knight,
Benjamin Chess, and John Schulman.
2022.
    </span>
    <span class="ltx_bibblock">
     WebGPT: Browser-assisted question-answering with
human feedback.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2112.09332 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023.
    </span>
    <span class="ltx_bibblock">
     GPT-4V(ision) System Card.
    </span>
    <span class="ltx_bibblock">
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Orman (2003)
    </span>
    <span class="ltx_bibblock">
     H. Orman. 2003.
    </span>
    <span class="ltx_bibblock">
     The Morris worm: a fifteen-year perspective.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">
      IEEE Security &amp; Privacy
     </em>
     1, 5 (2003),
35–43.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/MSECP.2003.1236233" target="_blank" title="">
      https://doi.org/10.1109/MSECP.2003.1236233
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ouyang et al
     <span class="ltx_text" id="bib.bib71.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Long Ouyang, Jeffrey Wu,
Xu Jiang, Diogo Almeida,
Carroll Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal,
Katarina Slama, Alex Ray,
et al
     <span class="ltx_text" id="bib.bib71.3.1">
      .
     </span>
     2022.
    </span>
    <span class="ltx_bibblock">
     Training language models to follow instructions
with human feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib71.4.1">
      Advances in Neural Information Processing
Systems
     </em>
     35 (2022),
27730–27744.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Packer et al
     <span class="ltx_text" id="bib.bib72.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Charles Packer, Vivian
Fang, Shishir G Patil, Kevin Lin,
Sarah Wooders, and Joseph E Gonzalez.
2023.
    </span>
    <span class="ltx_bibblock">
     MemGPT: Towards LLMs as Operating Systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib72.3.1">
      arXiv preprint arXiv:2310.08560
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pan et al
     <span class="ltx_text" id="bib.bib73.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Shirui Pan, Linhao Luo,
Yufei Wang, Chen Chen,
Jiapu Wang, and Xindong Wu.
2023.
    </span>
    <span class="ltx_bibblock">
     Unifying Large Language Models and Knowledge
Graphs: A Roadmap.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib73.3.1">
      arXiv preprint arXiv:2306.08302
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parisi et al
     <span class="ltx_text" id="bib.bib74.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Aaron Parisi, Yao Zhao,
and Noah Fiedel. 2022.
    </span>
    <span class="ltx_bibblock">
     Talm: Tool augmented language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib74.3.1">
      arXiv preprint arXiv:2205.12255
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Park et al
     <span class="ltx_text" id="bib.bib75.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Joseph
O’Brien, Carrie Jun Cai, Meredith Ringel
Morris, Percy Liang, and Michael S
Bernstein. 2023.
    </span>
    <span class="ltx_bibblock">
     Generative agents: Interactive simulacra of human
behavior. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib75.3.1">
      Proceedings of the 36th Annual ACM
Symposium on User Interface Software and Technology
     </em>
     .
1–22.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Patil et al
     <span class="ltx_text" id="bib.bib76.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Shishir G Patil, Tianjun
Zhang, Xin Wang, and Joseph E
Gonzalez. 2023.
    </span>
    <span class="ltx_bibblock">
     Gorilla: Large language model connected with
massive apis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib76.3.1">
      arXiv preprint arXiv:2305.15334
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Press et al
     <span class="ltx_text" id="bib.bib77.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Ofir Press, Noah A Smith,
and Mike Lewis. 2021.
    </span>
    <span class="ltx_bibblock">
     Train short, test long: Attention with linear
biases enables input length extrapolation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib77.3.1">
      arXiv preprint arXiv:2108.12409
     </em>
     (2021).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qi et al
     <span class="ltx_text" id="bib.bib78.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Xiangyu Qi, Kaixuan
Huang, Ashwinee Panda, Peter Henderson,
Mengdi Wang, and Prateek Mittal.
2023a.
    </span>
    <span class="ltx_bibblock">
     Visual Adversarial Examples Jailbreak Aligned Large
Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2306.13213 [cs.CR]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qi et al
     <span class="ltx_text" id="bib.bib79.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Xiangyu Qi, Yi Zeng,
Tinghao Xie, Pin-Yu Chen,
Ruoxi Jia, Prateek Mittal, and
Peter Henderson. 2023b.
    </span>
    <span class="ltx_bibblock">
     Fine-tuning Aligned Language Models Compromises
Safety, Even When Users Do Not Intend To!
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib79.3.1">
      arXiv preprint arXiv:2310.03693
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qian et al
     <span class="ltx_text" id="bib.bib80.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Chen Qian, Xin Cong,
Cheng Yang, Weize Chen,
Yusheng Su, Juyuan Xu,
Zhiyuan Liu, and Maosong Sun.
2023a.
    </span>
    <span class="ltx_bibblock">
     Communicative agents for software development.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib80.3.1">
      arXiv preprint arXiv:2307.07924
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qian et al
     <span class="ltx_text" id="bib.bib81.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Cheng Qian, Chi Han,
Yi R Fung, Yujia Qin,
Zhiyuan Liu, and Heng Ji.
2023b.
    </span>
    <span class="ltx_bibblock">
     CREATOR: Disentangling Abstract and Concrete
Reasonings of Large Language Models through Tool Creation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib81.3.1">
      arXiv preprint arXiv:2305.14318
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al
     <span class="ltx_text" id="bib.bib82.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Yujia Qin, Shengding Hu,
Yankai Lin, Weize Chen,
Ning Ding, Ganqu Cui,
Zheni Zeng, Yufei Huang,
Chaojun Xiao, Chi Han, et al
     <span class="ltx_text" id="bib.bib82.3.1">
      .
     </span>
     2023a.
    </span>
    <span class="ltx_bibblock">
     Tool learning with foundation models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib82.4.1">
      arXiv preprint arXiv:2304.08354
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al
     <span class="ltx_text" id="bib.bib83.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Yujia Qin, Shihao Liang,
Yining Ye, Kunlun Zhu,
Lan Yan, Yaxi Lu, Yankai
Lin, Xin Cong, Xiangru Tang,
Bill Qian, et al
     <span class="ltx_text" id="bib.bib83.3.1">
      .
     </span>
     2023b.
    </span>
    <span class="ltx_bibblock">
     Toolllm: Facilitating large language models to
master 16000+ real-world apis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib83.4.1">
      arXiv preprint arXiv:2307.16789
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Radford et al
     <span class="ltx_text" id="bib.bib84.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Alec Radford, Jeffrey Wu,
Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever,
et al
     <span class="ltx_text" id="bib.bib84.3.1">
      .
     </span>
     2019.
    </span>
    <span class="ltx_bibblock">
     Language models are unsupervised multitask
learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib84.4.1">
      OpenAI blog
     </em>
     1,
8 (2019), 9.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ritchie and Thompson (1974)
    </span>
    <span class="ltx_bibblock">
     Dennis M. Ritchie and
Ken Thompson. 1974.
    </span>
    <span class="ltx_bibblock">
     The UNIX Time-Sharing System.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">
      Commun. ACM
     </em>
     17,
7 (jul 1974),
365–375.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/361011.361061" target="_blank" title="">
      https://doi.org/10.1145/361011.361061
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Robertson et al
     <span class="ltx_text" id="bib.bib86.2.2.1">
      .
     </span>
     (2009)
    </span>
    <span class="ltx_bibblock">
     Stephen Robertson, Hugo
Zaragoza, et al
     <span class="ltx_text" id="bib.bib86.3.1">
      .
     </span>
     2009.
    </span>
    <span class="ltx_bibblock">
     The probabilistic relevance framework: BM25 and
beyond.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib86.4.1">
      Foundations and Trends® in
Information Retrieval
     </em>
     3, 4
(2009), 333–389.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rozière et al
     <span class="ltx_text" id="bib.bib87.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Baptiste Rozière, Jonas
Gehring, Fabian Gloeckle, Sten Sootla,
Itai Gat, Xiaoqing Ellen Tan,
Yossi Adi, Jingyu Liu,
Tal Remez, Jérémy Rapin,
Artyom Kozhevnikov, Ivan Evtimov,
Joanna Bitton, Manish Bhatt,
Cristian Canton Ferrer, Aaron
Grattafiori, Wenhan Xiong, Alexandre
Défossez, Jade Copet, Faisal Azhar,
Hugo Touvron, Louis Martin,
Nicolas Usunier, Thomas Scialom, and
Gabriel Synnaeve. 2023.
    </span>
    <span class="ltx_bibblock">
     Code Llama: Open Foundation Models for Code.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2308.12950 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ruan et al
     <span class="ltx_text" id="bib.bib88.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Jingqing Ruan, Yihong
Chen, Bin Zhang, Zhiwei Xu,
Tianpeng Bao, Guoqing Du,
Shiwei Shi, Hangyu Mao,
Xingyu Zeng, and Rui Zhao.
2023a.
    </span>
    <span class="ltx_bibblock">
     Tptu: Task planning and tool usage of large
language model-based ai agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib88.3.1">
      arXiv preprint arXiv:2308.03427
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib89">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ruan et al
     <span class="ltx_text" id="bib.bib89.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Yangjun Ruan, Honghua
Dong, Andrew Wang, Silviu Pitis,
Yongchao Zhou, Jimmy Ba,
Yann Dubois, Chris J. Maddison, and
Tatsunori Hashimoto. 2023b.
    </span>
    <span class="ltx_bibblock">
     Identifying the Risks of LM Agents with an
LM-Emulated Sandbox.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2309.15817 [cs.AI]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib90">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Russell and Norvig (1995)
    </span>
    <span class="ltx_bibblock">
     Stuart Russell and Peter
Norvig. 1995.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">
      Prentice Hall series in artificial
intelligence
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Prentice Hall Englewood Cliffs, NJ:.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib91">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Safdari et al
     <span class="ltx_text" id="bib.bib91.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Mustafa Safdari, Greg
Serapio-García, Clément Crepy,
Stephen Fitz, Peter Romero,
Luning Sun, Marwa Abdulhai,
Aleksandra Faust, and Maja
Matarić. 2023.
    </span>
    <span class="ltx_bibblock">
     Personality traits in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib91.3.1">
      arXiv preprint arXiv:2307.00184
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib92">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Salton (1975)
    </span>
    <span class="ltx_bibblock">
     Gerard Salton.
1975.
    </span>
    <span class="ltx_bibblock">
     A vector space model for information retrieval.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">
      Journal of the ASIS
     </em>
     (1975),
613–620.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib93">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schick et al
     <span class="ltx_text" id="bib.bib93.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Timo Schick, Jane
Dwivedi-Yu, Roberto Dessì, Roberta
Raileanu, Maria Lomeli, Luke
Zettlemoyer, Nicola Cancedda, and
Thomas Scialom. 2023.
    </span>
    <span class="ltx_bibblock">
     Toolformer: Language models can teach themselves to
use tools.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib93.3.1">
      arXiv preprint arXiv:2302.04761
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib94">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Serapio-García et al
     <span class="ltx_text" id="bib.bib94.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Greg Serapio-García,
Mustafa Safdari, Clément Crepy,
Luning Sun, Stephen Fitz,
Peter Romero, Marwa Abdulhai,
Aleksandra Faust, and Maja Matarić.
2023.
    </span>
    <span class="ltx_bibblock">
     Personality Traits in Large Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2307.00184 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib95">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shazeer (2019)
    </span>
    <span class="ltx_bibblock">
     Noam Shazeer.
2019.
    </span>
    <span class="ltx_bibblock">
     Fast transformer decoding: One write-head is all
you need.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">
      arXiv preprint arXiv:1911.02150
     </em>
     (2019).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib96">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shi et al
     <span class="ltx_text" id="bib.bib96.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Freda Shi, Xinyun Chen,
Kanishka Misra, Nathan Scales,
David Dohan, Ed H Chi,
Nathanael Schärli, and Denny Zhou.
2023.
    </span>
    <span class="ltx_bibblock">
     Large language models can be easily distracted by
irrelevant context. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib96.3.1">
      International Conference on
Machine Learning
     </em>
     . PMLR, 31210–31227.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib97">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al
     <span class="ltx_text" id="bib.bib97.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Federico
Cassano, Beck Labash, Ashwin Gopinath,
Karthik Narasimhan, and Shunyu Yao.
2023.
    </span>
    <span class="ltx_bibblock">
     Reflexion: Language agents with verbal
reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib97.3.1">
      arXiv preprint arXiv:2303.11366
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib98">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shridhar et al
     <span class="ltx_text" id="bib.bib98.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Xingdi
Yuan, Marc-Alexandre Côté,
Yonatan Bisk, Adam Trischler, and
Matthew Hausknecht. 2020.
    </span>
    <span class="ltx_bibblock">
     Alfworld: Aligning text and embodied environments
for interactive learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib98.3.1">
      arXiv preprint arXiv:2010.03768
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib99">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sledziewski et al
     <span class="ltx_text" id="bib.bib99.2.2.1">
      .
     </span>
     (2010)
    </span>
    <span class="ltx_bibblock">
     Krzysztof Sledziewski,
Behzad Bordbar, and Rachid Anane.
2010.
    </span>
    <span class="ltx_bibblock">
     A DSL-Based Approach to Software Development and
Deployment on Cloud. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib99.3.1">
      2010 24th IEEE
International Conference on Advanced Information Networking and
Applications
     </em>
     . 414–421.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/AINA.2010.81" target="_blank" title="">
      https://doi.org/10.1109/AINA.2010.81
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib100">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Stoica and Abdel-Wahab (1995)
    </span>
    <span class="ltx_bibblock">
     I. Stoica and H.
Abdel-Wahab. 1995.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">
      Earliest Eligible Virtual Deadline First: A
Flexible and Accurate Mechanism for Proportional Share Resource Allocation
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Technical Report. USA.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib101">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Su et al
     <span class="ltx_text" id="bib.bib101.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Jianlin Su, Yu Lu,
Shengfeng Pan, Ahmed Murtadha,
Bo Wen, and Yunfeng Liu.
2021.
    </span>
    <span class="ltx_bibblock">
     Roformer: Enhanced transformer with rotary position
embedding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib101.3.1">
      arXiv preprint arXiv:2104.09864
     </em>
     (2021).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib102">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al
     <span class="ltx_text" id="bib.bib102.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Qiushi Sun, Zhangyue Yin,
Xiang Li, Zhiyong Wu,
Xipeng Qiu, and Lingpeng Kong.
2023.
    </span>
    <span class="ltx_bibblock">
     Corex: Pushing the Boundaries of Complex Reasoning
through Multi-Model Collaboration.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2310.00280 [cs.AI]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib103">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al
     <span class="ltx_text" id="bib.bib103.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Yutao Sun, Li Dong,
Barun Patra, Shuming Ma,
Shaohan Huang, Alon Benhaim,
Vishrav Chaudhary, Xia Song, and
Furu Wei. 2022.
    </span>
    <span class="ltx_bibblock">
     A length-extrapolatable transformer.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib103.3.1">
      arXiv preprint arXiv:2212.10554
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib104">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sundar and Heck (2023)
    </span>
    <span class="ltx_bibblock">
     Anirudh S Sundar and
Larry Heck. 2023.
    </span>
    <span class="ltx_bibblock">
     cTBL: Augmenting Large Language Models for
Conversational Tables.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">
      arXiv preprint arXiv:2303.12024
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib105">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tang et al
     <span class="ltx_text" id="bib.bib105.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Qiaoyu Tang, Ziliang
Deng, Hongyu Lin, Xianpei Han,
Qiao Liang, and Le Sun.
2023.
    </span>
    <span class="ltx_bibblock">
     ToolAlpaca: Generalized Tool Learning for Language
Models with 3000 Simulated Cases.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib105.3.1">
      arXiv preprint arXiv:2306.05301
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib106">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Taori et al
     <span class="ltx_text" id="bib.bib106.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Rohan Taori, Ishaan
Gulrajani, Tianyi Zhang, Yann Dubois,
Xuechen Li, Carlos Guestrin,
Percy Liang, and Tatsunori B.
Hashimoto. 2023.
    </span>
    <span class="ltx_bibblock">
     Stanford Alpaca: An Instruction-following LLaMA
model.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" target="_blank" title="">
      https://github.com/tatsu-lab/stanford_alpaca
     </a>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib107">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al
     <span class="ltx_text" id="bib.bib107.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Louis
Martin, Kevin Stone, Peter Albert,
Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra,
Prajjwal Bhargava, Shruti Bhosale,
et al
     <span class="ltx_text" id="bib.bib107.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Llama 2: Open foundation and fine-tuned chat
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib107.4.1">
      arXiv preprint arXiv:2307.09288
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib108">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     UW:CSE451 (2023)
    </span>
    <span class="ltx_bibblock">
     UW:CSE451.
2023.
    </span>
    <span class="ltx_bibblock">
     History of Operating Systems.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf" target="_blank" title="">
      https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib109">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al
     <span class="ltx_text" id="bib.bib109.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Karthik Valmeekam, Alberto
Olmo, Sarath Sreedharan, and Subbarao
Kambhampati. 2022.
    </span>
    <span class="ltx_bibblock">
     Large Language Models Still Can’t Plan (A Benchmark
for LLMs on Planning and Reasoning about Change). In
     <em class="ltx_emph ltx_font_italic" id="bib.bib109.3.1">
      NeurIPS 2022 Foundation Models for Decision Making
Workshop
     </em>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib110">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Vaswani et al
     <span class="ltx_text" id="bib.bib110.2.2.1">
      .
     </span>
     (2017)
    </span>
    <span class="ltx_bibblock">
     Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N Gomez,
Łukasz Kaiser, and Illia
Polosukhin. 2017.
    </span>
    <span class="ltx_bibblock">
     Attention is all you need.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib110.3.1">
      Advances in neural information processing
systems
     </em>
     30 (2017).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib111">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Vemprala et al
     <span class="ltx_text" id="bib.bib111.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Sai Vemprala, Rogerio
Bonatti, Arthur Bucker, and Ashish
Kapoor. 2023.
    </span>
    <span class="ltx_bibblock">
     Chatgpt for robotics: Design principles and model
abilities.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib111.3.1">
      Microsoft Auton. Syst. Robot. Res
     </em>
     2 (2023), 20.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib112">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib112.2.2.1">
      .
     </span>
     (2023e)
    </span>
    <span class="ltx_bibblock">
     Guanzhi Wang, Yuqi Xie,
Yunfan Jiang, Ajay Mandlekar,
Chaowei Xiao, Yuke Zhu,
Linxi Fan, and Anima Anandkumar.
2023e.
    </span>
    <span class="ltx_bibblock">
     Voyager: An open-ended embodied agent with large
language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib112.3.1">
      arXiv preprint arXiv:2305.16291
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib113">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib113.2.2.1">
      .
     </span>
     (2023f)
    </span>
    <span class="ltx_bibblock">
     Lei Wang, Jingsen Zhang,
Xu Chen, Yankai Lin,
Ruihua Song, Wayne Xin Zhao, and
Ji-Rong Wen. 2023f.
    </span>
    <span class="ltx_bibblock">
     RecAgent: A Novel Simulation Paradigm for
Recommender Systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib113.3.1">
      arXiv preprint arXiv:2306.02552
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib114">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib114.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Sinong Wang, Belinda Z
Li, Madian Khabsa, Han Fang, and
Hao Ma. 2020.
    </span>
    <span class="ltx_bibblock">
     Linformer: Self-attention with linear complexity.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib114.3.1">
      arXiv preprint arXiv:2006.04768
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib115">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib115.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Xuezhi Wang, Jason Wei,
Dale Schuurmans, Quoc V Le,
Ed H Chi, Sharan Narang,
Aakanksha Chowdhery, and Denny Zhou.
2022.
    </span>
    <span class="ltx_bibblock">
     Self-Consistency Improves Chain of Thought
Reasoning in Language Models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib115.3.1">
      The Eleventh
International Conference on Learning Representations
     </em>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib116">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib116.2.2.1">
      .
     </span>
     (2023c)
    </span>
    <span class="ltx_bibblock">
     Yancheng Wang, Ziyan
Jiang, Zheng Chen, Fan Yang,
Yingxue Zhou, Eunah Cho,
Xing Fan, Xiaojiang Huang,
Yanbin Lu, and Yingzhen Yang.
2023c.
    </span>
    <span class="ltx_bibblock">
     RecMind: Large Language Model Powered Agent For
Recommendation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib116.3.1">
      arXiv preprint arXiv:2308.14296
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib117">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib117.2.2.1">
      .
     </span>
     (2023d)
    </span>
    <span class="ltx_bibblock">
     Yubo Wang, Xueguang Ma,
and Wenhu Chen. 2023d.
    </span>
    <span class="ltx_bibblock">
     Augmenting Black-box LLMs with Medical Textbooks
for Clinical Question Answering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib117.3.1">
      arXiv preprint arXiv:2309.02233
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib118">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib118.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Zihao Wang, Shaofei Cai,
Anji Liu, Xiaojian Ma, and
Yitao Liang. 2023a.
    </span>
    <span class="ltx_bibblock">
     Describe, explain, plan and select: Interactive
planning with large language models enables open-world multi-task agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib118.3.1">
      arXiv preprint arXiv:2302.01560
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib119">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib119.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Zhilin Wang, Yu Ying
Chiu, and Yu Cheung Chiu.
2023b.
    </span>
    <span class="ltx_bibblock">
     Humanoid Agents: Platform for Simulating Human-like
Generative Agents.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2310.05418 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib120">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al
     <span class="ltx_text" id="bib.bib120.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Alexander Wei, Nika
Haghtalab, and Jacob Steinhardt.
2023.
    </span>
    <span class="ltx_bibblock">
     Jailbroken: How Does LLM Safety Training Fail?
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2307.02483 [cs.LG]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib121">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al
     <span class="ltx_text" id="bib.bib121.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang,
Dale Schuurmans, Maarten Bosma,
Fei Xia, Ed Chi, Quoc V
Le, Denny Zhou, et al
     <span class="ltx_text" id="bib.bib121.3.1">
      .
     </span>
     2022.
    </span>
    <span class="ltx_bibblock">
     Chain-of-thought prompting elicits reasoning in
large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib121.4.1">
      Advances in Neural Information Processing
Systems
     </em>
     35 (2022),
24824–24837.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib122">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wooldridge and Jennings (1995)
    </span>
    <span class="ltx_bibblock">
     Michael Wooldridge and
Nicholas R Jennings. 1995.
    </span>
    <span class="ltx_bibblock">
     Intelligent agents: Theory and practice.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">
      The knowledge engineering review
     </em>
     10, 2 (1995),
115–152.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib123">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al
     <span class="ltx_text" id="bib.bib123.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Qingyun Wu, Gagan Bansal,
Jieyu Zhang, Yiran Wu,
Beibin Li, Erkang Zhu,
Li Jiang, Xiaoyun Zhang,
Shaokun Zhang, Jiale Liu,
Ahmed Hassan Awadallah, Ryen W White,
Doug Burger, and Chi Wang.
2023.
    </span>
    <span class="ltx_bibblock">
     AutoGen: Enabling Next-Gen LLM Applications via
Multi-Agent Conversation.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2308.08155 [cs.AI]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib124">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al
     <span class="ltx_text" id="bib.bib124.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yiheng Xu, Hongjin Su,
Chen Xing, Boyu Mi, Qian
Liu, Weijia Shi, Binyuan Hui,
Fan Zhou, Yitao Liu,
Tianbao Xie, et al
     <span class="ltx_text" id="bib.bib124.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Lemur: Harmonizing Natural Language and Code for
Language Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib124.4.1">
      arXiv preprint arXiv:2310.06830
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib125">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang and Ettinger (2023)
    </span>
    <span class="ltx_bibblock">
     Chenghao Yang and
Allyson Ettinger. 2023.
    </span>
    <span class="ltx_bibblock">
     Can You Follow Me? Testing Situational
Understanding in ChatGPT.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">
      arXiv preprint arXiv:2310.16135
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib126">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al
     <span class="ltx_text" id="bib.bib126.2.2.1">
      .
     </span>
     (2023c)
    </span>
    <span class="ltx_bibblock">
     Haomiao Yang, Kunlan
Xiang, Hongwei Li, and Rongxing Lu.
2023c.
    </span>
    <span class="ltx_bibblock">
     A Comprehensive Overview of Backdoor Attacks in
Large Language Models within Communication Networks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib126.3.1">
      arXiv preprint arXiv:2308.14367
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib127">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al
     <span class="ltx_text" id="bib.bib127.2.2.1">
      .
     </span>
     (2023b)
    </span>
    <span class="ltx_bibblock">
     Xianjun Yang, Xiao Wang,
Qi Zhang, Linda Petzold,
William Yang Wang, Xun Zhao, and
Dahua Lin. 2023b.
    </span>
    <span class="ltx_bibblock">
     Shadow alignment: The ease of subverting
safely-aligned language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib127.3.1">
      arXiv preprint arXiv:2310.02949
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib128">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al
     <span class="ltx_text" id="bib.bib128.2.2.1">
      .
     </span>
     (2023a)
    </span>
    <span class="ltx_bibblock">
     Zhengyuan Yang, Linjie
Li, Jianfeng Wang, Kevin Lin,
Ehsan Azarnasab, Faisal Ahmed,
Zicheng Liu, Ce Liu,
Michael Zeng, and Lijuan Wang.
2023a.
    </span>
    <span class="ltx_bibblock">
     Mm-react: Prompting chatgpt for multimodal
reasoning and action.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib128.3.1">
      arXiv preprint arXiv:2303.11381
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib129">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al
     <span class="ltx_text" id="bib.bib129.2.2.1">
      .
     </span>
     (2022a)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Howard Chen,
John Yang, and Karthik Narasimhan.
2022a.
    </span>
    <span class="ltx_bibblock">
     Webshop: Towards scalable real-world web
interaction with grounded language agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib129.3.1">
      Advances in Neural Information Processing
Systems
     </em>
     35 (2022),
20744–20757.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib130">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao and Narasimhan (2023)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao and Karthik
Narasimhan. 2023.
    </span>
    <span class="ltx_bibblock">
     Language Agents in the Digital World: Opportunities
and Risks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">
      princeton-nlp.github.io
     </em>
     (Jul 2023).
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://princeton-nlp.github.io/language-agent-impact/" target="_blank" title="">
      https://princeton-nlp.github.io/language-agent-impact/
     </a>
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib131">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al
     <span class="ltx_text" id="bib.bib131.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Dian Yu,
Jeffrey Zhao, Izhak Shafran,
Thomas L Griffiths, Yuan Cao, and
Karthik Narasimhan. 2023.
    </span>
    <span class="ltx_bibblock">
     Tree of thoughts: Deliberate problem solving with
large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib131.3.1">
      arXiv preprint arXiv:2305.10601
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib132">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al
     <span class="ltx_text" id="bib.bib132.2.2.1">
      .
     </span>
     (2022b)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao,
Dian Yu, Nan Du, Izhak
Shafran, Karthik R Narasimhan, and Yuan
Cao. 2022b.
    </span>
    <span class="ltx_bibblock">
     ReAct: Synergizing Reasoning and Acting in Language
Models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib132.3.1">
      The Eleventh International Conference
on Learning Representations
     </em>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib133">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yu et al
     <span class="ltx_text" id="bib.bib133.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Dingyao Yu, Kaitao Song,
Peiling Lu, Tianyu He,
Xu Tan, Wei Ye, Shikun
Zhang, and Jiang Bian. 2023.
    </span>
    <span class="ltx_bibblock">
     MusicAgent: An AI Agent for Music Understanding and
Generation with Large Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2310.11954 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib134">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yuan et al
     <span class="ltx_text" id="bib.bib134.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Ann Yuan, Andy Coenen,
Emily Reif, and Daphne Ippolito.
2022.
    </span>
    <span class="ltx_bibblock">
     Wordcraft: story writing with large language
models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib134.3.1">
      27th International Conference on
Intelligent User Interfaces
     </em>
     . 841–852.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib135">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zaheer et al
     <span class="ltx_text" id="bib.bib135.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Manzil Zaheer, Guru
Guruganesh, Kumar Avinava Dubey, Joshua
Ainslie, Chris Alberti, Santiago
Ontanon, Philip Pham, Anirudh Ravula,
Qifan Wang, Li Yang, et al
     <span class="ltx_text" id="bib.bib135.3.1">
      .
     </span>
     2020.
    </span>
    <span class="ltx_bibblock">
     Big bird: Transformers for longer sequences.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib135.4.1">
      Advances in neural information processing
systems
     </em>
     33 (2020),
17283–17297.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib136">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhan and Zhang (2023)
    </span>
    <span class="ltx_bibblock">
     Zhuosheng Zhan and Aston
Zhang. 2023.
    </span>
    <span class="ltx_bibblock">
     You Only Look at Screens: Multimodal
Chain-of-Action Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib136.1.1">
      arXiv preprint arXiv:2309.11436
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib137">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al
     <span class="ltx_text" id="bib.bib137.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Kechi Zhang, Ge Li,
Jia Li, Zhuo Li, and
Zhi Jin. 2023.
    </span>
    <span class="ltx_bibblock">
     ToolCoder: Teach Code Generation Models to use APIs
with search tools.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib137.3.1">
      arXiv preprint arXiv:2305.04032
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib138">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al
     <span class="ltx_text" id="bib.bib138.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Kang Zhao, Wei Liu,
Jian Luan, Minglei Gao,
Li Qian, Hanlin Teng, and
Bin Wang. 2023.
    </span>
    <span class="ltx_bibblock">
     UniMC: A Unified Framework for Long-Term Memory
Conversation via Relevance Representation Learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib138.3.1">
      arXiv preprint arXiv:2306.10543
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib139">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhong et al
     <span class="ltx_text" id="bib.bib139.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Wanjun Zhong, Lianghong
Guo, Qiqi Gao, and Yanlin Wang.
2023.
    </span>
    <span class="ltx_bibblock">
     MemoryBank: Enhancing Large Language Models with
Long-Term Memory.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib139.3.1">
      arXiv preprint arXiv:2305.10250
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib140">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al
     <span class="ltx_text" id="bib.bib140.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Shuyan Zhou, Uri Alon,
Frank F Xu, Zhengbao Jiang, and
Graham Neubig. 2022.
    </span>
    <span class="ltx_bibblock">
     Docprompting: Generating code by retrieving the
docs. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib140.3.1">
      The Eleventh International Conference on
Learning Representations
     </em>
     .
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib141">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al
     <span class="ltx_text" id="bib.bib141.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Wangchunshu Zhou,
Yuchen Eleanor Jiang, Long Li,
Jialong Wu, Tiannan Wang,
Shi Qiu, Jintian Zhang,
Jing Chen, Ruipu Wu,
Shuai Wang, Shiding Zhu,
Jiyu Chen, Wentao Zhang,
Ningyu Zhang, Huajun Chen,
Peng Cui, and Mrinmaya Sachan.
2023.
    </span>
    <span class="ltx_bibblock">
     Agents: An Open-source Framework for Autonomous
Language Agents.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2309.07870 [cs.CL]
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib142">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al
     <span class="ltx_text" id="bib.bib142.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Xizhou Zhu, Yuntao Chen,
Hao Tian, Chenxin Tao,
Weijie Su, Chenyu Yang,
Gao Huang, Bin Li, Lewei
Lu, Xiaogang Wang, et al
     <span class="ltx_text" id="bib.bib142.3.1">
      .
     </span>
     2023.
    </span>
    <span class="ltx_bibblock">
     Ghost in the Minecraft: Generally Capable Agents
for Open-World Enviroments via Large Language Models with Text-based
Knowledge and Memory.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib142.4.1">
      arXiv preprint arXiv:2305.17144
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib143">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zou et al
     <span class="ltx_text" id="bib.bib143.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Andy Zou, Zifan Wang,
J. Zico Kolter, and Matt Fredrikson.
2023.
    </span>
    <span class="ltx_bibblock">
     Universal and Transferable Adversarial Attacks on
Aligned Language Models.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
     arXiv:2307.15043 [cs.CL]
    </span>
   </li>
  </ul>
 </section>
</article>
