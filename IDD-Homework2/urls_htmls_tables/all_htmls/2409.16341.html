<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.16341] Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs</title><meta property="og:description" content="Training large language models (LLMs) for external tool usage is a rapidly expanding field, with recent research focusing on generating synthetic data to address the shortage of available data. However, the absence of …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.16341">

<!--Generated on Sat Oct  5 20:12:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shadi Iskander 
<br class="ltx_break">Amazon
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">shadisk@amazon.com</span> 
<br class="ltx_break">&amp;Nachshon Cohen 
<br class="ltx_break">Amazon 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">nachshon@amazon.com</span> 
<br class="ltx_break">&amp;Zohar Karnin 
<br class="ltx_break">Technology Innovation Institute 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">zohar.karnin@tii.ae</span> 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_ERROR undefined">\AND</span>Ori Shapira 
<br class="ltx_break">OriginAI 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_typewriter">obspp18@gmail.com</span> 
<br class="ltx_break">&amp;Sofia Tolmach 
<br class="ltx_break">Amazon 
<br class="ltx_break"><span id="id6.6.id6" class="ltx_text ltx_font_typewriter">sofiato@amazon.com</span> 
<br class="ltx_break">
</span><span class="ltx_author_notes">This work was done during an internship in Amazon and as part of graduate studies at the Technion - Israel Institute of Technology.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">Training large language models (LLMs) for external tool usage is a rapidly expanding field, with recent research focusing on generating synthetic data to address the shortage of available data. However, the absence of systematic data quality checks poses complications for properly training and testing models. To that end, we propose two approaches for assessing the reliability of data for training LLMs to use external tools. The first approach uses intuitive, human-defined correctness criteria. The second approach uses a model-driven assessment with in-context evaluation. We conduct a thorough evaluation of data quality on two popular benchmarks, followed by an extrinsic evaluation that showcases the impact of data quality on model performance. Our results demonstrate that models trained on high-quality data outperform those trained on unvalidated data, even when trained with a smaller quantity of data. These findings empirically support the significance of assessing and ensuring the reliability of training data for tool-using LLMs.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.1" class="ltx_block ltx_align_bottom">
<p id="p1.1.1" class="ltx_p"><span id="p1.1.1.1" class="ltx_text ltx_font_bold">Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.1.2" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.1.2.1" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.1.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.1.1.1.1" class="ltx_tr">
<span id="p1.1.2.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Shadi Iskander<span id="p1.1.2.1.1.1.1.1.1.1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>This work was done during an internship in Amazon and as part of graduate studies at the Technion - Israel Institute of Technology.</span></span></span></span></span></span>
<span id="p1.1.2.1.1.2.2" class="ltx_tr">
<span id="p1.1.2.1.1.2.2.1" class="ltx_td ltx_align_center">Amazon</span></span>
<span id="p1.1.2.1.1.3.3" class="ltx_tr">
<span id="p1.1.2.1.1.3.3.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.3.3.1.1" class="ltx_text ltx_font_typewriter">shadisk@amazon.com</span></span></span>
</span>
</span></span>                      <span id="p1.1.2.2" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.2.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.2.1.1.1" class="ltx_tr">
<span id="p1.1.2.2.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Nachshon Cohen</span></span></span>
<span id="p1.1.2.2.1.2.2" class="ltx_tr">
<span id="p1.1.2.2.1.2.2.1" class="ltx_td ltx_align_center">Amazon</span></span>
<span id="p1.1.2.2.1.3.3" class="ltx_tr">
<span id="p1.1.2.2.1.3.3.1" class="ltx_td ltx_align_center"><span id="p1.1.2.2.1.3.3.1.1" class="ltx_text ltx_font_typewriter">nachshon@amazon.com</span></span></span>
</span>
</span></span>                      <span id="p1.1.2.3" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.3.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.3.1.1.1" class="ltx_tr">
<span id="p1.1.2.3.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Zohar Karnin</span></span></span>
<span id="p1.1.2.3.1.2.2" class="ltx_tr">
<span id="p1.1.2.3.1.2.2.1" class="ltx_td ltx_align_center">Technology Innovation Institute</span></span>
<span id="p1.1.2.3.1.3.3" class="ltx_tr">
<span id="p1.1.2.3.1.3.3.1" class="ltx_td ltx_align_center"><span id="p1.1.2.3.1.3.3.1.1" class="ltx_text ltx_font_typewriter">zohar.karnin@tii.ae</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
<p id="p1.1.3" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.1.3.1" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.3.1.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.3.1.1.1.1" class="ltx_tr">
<span id="p1.1.3.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ori Shapira</span></span></span>
<span id="p1.1.3.1.1.2.2" class="ltx_tr">
<span id="p1.1.3.1.1.2.2.1" class="ltx_td ltx_align_center">OriginAI</span></span>
<span id="p1.1.3.1.1.3.3" class="ltx_tr">
<span id="p1.1.3.1.1.3.3.1" class="ltx_td ltx_align_center"><span id="p1.1.3.1.1.3.3.1.1" class="ltx_text ltx_font_typewriter">obspp18@gmail.com</span></span></span>
</span>
</span></span>                      <span id="p1.1.3.2" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.3.2.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.3.2.1.1.1" class="ltx_tr">
<span id="p1.1.3.2.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.3.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Sofia Tolmach</span></span></span>
<span id="p1.1.3.2.1.2.2" class="ltx_tr">
<span id="p1.1.3.2.1.2.2.1" class="ltx_td ltx_align_center">Amazon</span></span>
<span id="p1.1.3.2.1.3.3" class="ltx_tr">
<span id="p1.1.3.2.1.3.3.1" class="ltx_td ltx_align_center"><span id="p1.1.3.2.1.3.3.1.1" class="ltx_text ltx_font_typewriter">sofiato@amazon.com</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Enabling LLMs to make use of external tools is a promising frontier that allows tapping into information that is not readily available to the model itself
<cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a href="#bib.bib10" title="" class="ltx_ref">2024</a>); Li et al. (<a href="#bib.bib13" title="" class="ltx_ref">2023a</a>); Qin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>); Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>); Yang et al. (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>); Patil et al. (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>); Schick et al. (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>. Given a request and a list of available external API functions, the basic task of a model is to collect information by invoking functions, and then to generate a response for the request.
Due to the lack of data for the task and the high cost of creating such data, researchers have
devised synthetic datasets, predominantly with the assistance of LLMs
<cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a href="#bib.bib10" title="" class="ltx_ref">2024</a>); Li et al. (<a href="#bib.bib13" title="" class="ltx_ref">2023a</a>); Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>. These datasets have facilitated a great leap in promoting the appealing applications of tool-using LLMs.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recently, <cite class="ltx_cite ltx_citemacro_citet">Zhou et al. (<a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> showed that higher quality training data yields better performance by LLMs in text generation tasks.
However, leading works on tool-using LLMs have not made an effort to measure the quality of training data. Rather, only model outputs are extrinsically evaluated, disregarding the effect of the data on the tested models.
Most research on tool-using LLMs focuses on improving training and evaluation processes <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a href="#bib.bib10" title="" class="ltx_ref">2024</a>); Qin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>); Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>. The lack of attention to <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">data quality</span> makes it difficult to interpret potential pitfalls for models. In turn, this wastes valuable resources for configuring and tuning models over possibly erroneous data.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.16341/assets/figures/intro_fig.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="342" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Data quality assessment methods for improving the training
process of tool-using LLMs (a), employing two different approaches: (b) intrinsic quality evaluation, using an external LLM to measure various human-defined criteria;
(c) in-context evaluation, using the target LLM to measure the educational value of data instances. A smaller high-quality training dataset is more effective than a larger unvalidated set.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Datasets for tool-using LLMs comprise instructions and ground truth API call sequences, and are created mainly with LLMs.
Two such prominent datasets <cite class="ltx_cite ltx_citemacro_citep">(Qin et al., <a href="#bib.bib18" title="" class="ltx_ref">2024</a>; Tang et al., <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> were produced with the help of ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib16" title="" class="ltx_ref">2024</a>)</cite>, and were not explicitly assessed for their quality. A closer inspection, conducted in this work, reveals numerous errors within the data, both in the instructions and in the ground-truth API calls (§<a href="#S4" title="4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To conduct our inspections, we define intrinsic measures for data quality assessment,
focusing on different aspects of quality. For each aspect we outline human evaluation guidelines,
as well as implement automated methods for evaluation.
The automatic methods employ ChatGPT, either by directly asking for its evaluation or by having it perform a proxy task and deriving the evaluation from its output. We show high agreement for our automated methods with expert human annotations. In addition to the intrinsic measures, we propose a metric we call <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">In-Context Evaluation</span> (ICE; §<a href="#S5" title="5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). ICE evaluates a data instance by how helpful it is for in-context learning, thus predicting its helpfulness for training a model (§<a href="#S5" title="5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).
This metric is fully automated and does not rely on task-specific measurement definitions.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Other than being appraisal instruments, the intrinsic evaluation and ICE metrics can be used to automatically filter out low quality data from an existing dataset. In Section <a href="#S6" title="6 Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> we carry out this procedure, and display the effect of training tool-using LLMs with higher quality data.
Our findings, demonstrated
on the ToolBench <cite class="ltx_cite ltx_citemacro_cite">Qin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite> and ToolAlpaca <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> benchmarks, show either better or comparable performance when using a small high-quality training dataset, compared to the original models trained on larger unverified datasets. The two benchmarks
are based on different API function sets, and different data generation and training methods, indicating the generalized applicability of our methods.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>External Tool Usage by LLMs</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Tool learning is a recent area of research, aiming to enable LLMs to overcome limitations by accessing tools for, e.g., retrieving up-to-date information <cite class="ltx_cite ltx_citemacro_citep">(Kasai et al., <a href="#bib.bib11" title="" class="ltx_ref">2023</a>; Cheng et al., <a href="#bib.bib4" title="" class="ltx_ref">2024</a>)</cite>, or performing mathematical calculations <cite class="ltx_cite ltx_citemacro_citep">(Schick et al., <a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>, thereby enhancing their usability for real-world needs.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Research on tool learning focuses on various aspects of training LLMs to use external tools. These mainly include tool selection, tool usage, and planning <cite class="ltx_cite ltx_citemacro_citep">(Zhuang et al., <a href="#bib.bib27" title="" class="ltx_ref">2023</a>; Qin et al., <a href="#bib.bib18" title="" class="ltx_ref">2024</a>; Patil et al., <a href="#bib.bib17" title="" class="ltx_ref">2023</a>; Yao et al., <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>.
Such models are mainly evaluated extrinsically, only measuring the final results. T-Eval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2024</a>)</cite> is the first evaluation framework that analyzes tool-using LLMs intrinsically. That is, it decomposes the evaluation into all sub-tasks (such as selection, usage and planning), measuring the fine-grained abilities of models as
tool agents.
We intrinsically evaluate the <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">data</span> for tool-usage instead of a <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">model</span>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data Generation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Recent notable works generated synthetic data for tool learning.
ToolBench <cite class="ltx_cite ltx_citemacro_cite">Qin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite> leverages a large pool of real API functions.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Based on RapidAPI: <a target="_blank" href="https://rapidapi.com/hub" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://rapidapi.com/hub</a></span></span></span> ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib16" title="" class="ltx_ref">2024</a>)</cite> was used to generate an instruction that would require invoking a given small set of these tools, as well as to produce a solution path for the respective instruction.
The data was constructed with a varying number of tools per instance and varying relatedness between the tools. API Bank <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib13" title="" class="ltx_ref">2023a</a>)</cite> created synthetic API documentation, instruction queries, and responses using strong LLMs <cite class="ltx_cite ltx_citemacro_citep">(GPT-4 and ChatGPT; OpenAI, <a href="#bib.bib16" title="" class="ltx_ref">2024</a>)</cite>. A smaller test set was created and validated manually by humans.
<cite class="ltx_cite ltx_citemacro_citet">Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> constructed the ToolAlpaca dataset using ChatGPT to generate cleaner documentation upon existing APIs, and respective instructions and responses. In ToolAlpaca, most synthesized instructions only require a single tool to fulfill the request.
The test set was validated by humans to ensure quality.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">To strengthen the credibility of our findings in this work, we conduct our experiments over both ToolBench and ToolAlpaca, which differ in API quality and instruction requirements.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Data Quality</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The ever-increasing dependence on data for training large models has paved a line of work that analyzes the effect of data quality on fine-tuning models. Findings show that
a small but high-quality dataset can be highly effective for fine-tuning
a relatively small model, surpassing the performance of a larger model.
For example, Phi <cite class="ltx_cite ltx_citemacro_cite">Gunasekar et al. (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>); Li et al. (<a href="#bib.bib15" title="" class="ltx_ref">2023b</a>)</cite> explored code generation tasks and prompted GPT-4 to assess the educational value of coding examples. They demonstrated that a small number of high-quality and diverse examples are sufficient to reach good quality of code generation.
In the realm of instruction tuning, <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a href="#bib.bib14" title="" class="ltx_ref">2024</a>)</cite> suggest employing self-augmentation and self-curation to iteratively improve the set of instructions used for instruct-tuning an LLM.
LIMA <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> considers the broader picture of data quality, and show that as few as 1000 high-quality examples can be sufficient for training an instruction-following model.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Our work differs from these studies in that it applies to the regime of tool usage. It can be seen as additional evidence reinforcing the prevailing “less is more” trend, proving the importance of data quality in this regime.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Task Setup</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.9" class="ltx_p">Tool-using LLMs are expected to behave as follows.
Given a set of tools <math id="S3.p1.1.m1.3" class="ltx_Math" alttext="T=\{t_{1},...,t_{n}\}" display="inline"><semantics id="S3.p1.1.m1.3a"><mrow id="S3.p1.1.m1.3.3" xref="S3.p1.1.m1.3.3.cmml"><mi id="S3.p1.1.m1.3.3.4" xref="S3.p1.1.m1.3.3.4.cmml">T</mi><mo id="S3.p1.1.m1.3.3.3" xref="S3.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S3.p1.1.m1.3.3.2.2" xref="S3.p1.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S3.p1.1.m1.3.3.2.2.3" xref="S3.p1.1.m1.3.3.2.3.cmml">{</mo><msub id="S3.p1.1.m1.2.2.1.1.1" xref="S3.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.p1.1.m1.2.2.1.1.1.2" xref="S3.p1.1.m1.2.2.1.1.1.2.cmml">t</mi><mn id="S3.p1.1.m1.2.2.1.1.1.3" xref="S3.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p1.1.m1.3.3.2.2.4" xref="S3.p1.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">…</mi><mo id="S3.p1.1.m1.3.3.2.2.5" xref="S3.p1.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.p1.1.m1.3.3.2.2.2" xref="S3.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.p1.1.m1.3.3.2.2.2.2" xref="S3.p1.1.m1.3.3.2.2.2.2.cmml">t</mi><mi id="S3.p1.1.m1.3.3.2.2.2.3" xref="S3.p1.1.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.p1.1.m1.3.3.2.2.6" xref="S3.p1.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.3b"><apply id="S3.p1.1.m1.3.3.cmml" xref="S3.p1.1.m1.3.3"><eq id="S3.p1.1.m1.3.3.3.cmml" xref="S3.p1.1.m1.3.3.3"></eq><ci id="S3.p1.1.m1.3.3.4.cmml" xref="S3.p1.1.m1.3.3.4">𝑇</ci><set id="S3.p1.1.m1.3.3.2.3.cmml" xref="S3.p1.1.m1.3.3.2.2"><apply id="S3.p1.1.m1.2.2.1.1.1.cmml" xref="S3.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.p1.1.m1.2.2.1.1.1.2">𝑡</ci><cn type="integer" id="S3.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.p1.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">…</ci><apply id="S3.p1.1.m1.3.3.2.2.2.cmml" xref="S3.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.p1.1.m1.3.3.2.2.2.2">𝑡</ci><ci id="S3.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.p1.1.m1.3.3.2.2.2.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.3c">T=\{t_{1},...,t_{n}\}</annotation></semantics></math>, represented as API functions, and an instruction query <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">q</annotation></semantics></math>, a model is required to plan a call sequence <math id="S3.p1.3.m3.3" class="ltx_Math" alttext="S=(t^{\prime}_{1},...,t^{\prime}_{k})" display="inline"><semantics id="S3.p1.3.m3.3a"><mrow id="S3.p1.3.m3.3.3" xref="S3.p1.3.m3.3.3.cmml"><mi id="S3.p1.3.m3.3.3.4" xref="S3.p1.3.m3.3.3.4.cmml">S</mi><mo id="S3.p1.3.m3.3.3.3" xref="S3.p1.3.m3.3.3.3.cmml">=</mo><mrow id="S3.p1.3.m3.3.3.2.2" xref="S3.p1.3.m3.3.3.2.3.cmml"><mo stretchy="false" id="S3.p1.3.m3.3.3.2.2.3" xref="S3.p1.3.m3.3.3.2.3.cmml">(</mo><msubsup id="S3.p1.3.m3.2.2.1.1.1" xref="S3.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.p1.3.m3.2.2.1.1.1.2.2" xref="S3.p1.3.m3.2.2.1.1.1.2.2.cmml">t</mi><mn id="S3.p1.3.m3.2.2.1.1.1.3" xref="S3.p1.3.m3.2.2.1.1.1.3.cmml">1</mn><mo id="S3.p1.3.m3.2.2.1.1.1.2.3" xref="S3.p1.3.m3.2.2.1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.p1.3.m3.3.3.2.2.4" xref="S3.p1.3.m3.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">…</mi><mo id="S3.p1.3.m3.3.3.2.2.5" xref="S3.p1.3.m3.3.3.2.3.cmml">,</mo><msubsup id="S3.p1.3.m3.3.3.2.2.2" xref="S3.p1.3.m3.3.3.2.2.2.cmml"><mi id="S3.p1.3.m3.3.3.2.2.2.2.2" xref="S3.p1.3.m3.3.3.2.2.2.2.2.cmml">t</mi><mi id="S3.p1.3.m3.3.3.2.2.2.3" xref="S3.p1.3.m3.3.3.2.2.2.3.cmml">k</mi><mo id="S3.p1.3.m3.3.3.2.2.2.2.3" xref="S3.p1.3.m3.3.3.2.2.2.2.3.cmml">′</mo></msubsup><mo stretchy="false" id="S3.p1.3.m3.3.3.2.2.6" xref="S3.p1.3.m3.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.3b"><apply id="S3.p1.3.m3.3.3.cmml" xref="S3.p1.3.m3.3.3"><eq id="S3.p1.3.m3.3.3.3.cmml" xref="S3.p1.3.m3.3.3.3"></eq><ci id="S3.p1.3.m3.3.3.4.cmml" xref="S3.p1.3.m3.3.3.4">𝑆</ci><vector id="S3.p1.3.m3.3.3.2.3.cmml" xref="S3.p1.3.m3.3.3.2.2"><apply id="S3.p1.3.m3.2.2.1.1.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1">subscript</csymbol><apply id="S3.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.2.2.1.1.1.2.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1">superscript</csymbol><ci id="S3.p1.3.m3.2.2.1.1.1.2.2.cmml" xref="S3.p1.3.m3.2.2.1.1.1.2.2">𝑡</ci><ci id="S3.p1.3.m3.2.2.1.1.1.2.3.cmml" xref="S3.p1.3.m3.2.2.1.1.1.2.3">′</ci></apply><cn type="integer" id="S3.p1.3.m3.2.2.1.1.1.3.cmml" xref="S3.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">…</ci><apply id="S3.p1.3.m3.3.3.2.2.2.cmml" xref="S3.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p1.3.m3.3.3.2.2.2.1.cmml" xref="S3.p1.3.m3.3.3.2.2.2">subscript</csymbol><apply id="S3.p1.3.m3.3.3.2.2.2.2.cmml" xref="S3.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p1.3.m3.3.3.2.2.2.2.1.cmml" xref="S3.p1.3.m3.3.3.2.2.2">superscript</csymbol><ci id="S3.p1.3.m3.3.3.2.2.2.2.2.cmml" xref="S3.p1.3.m3.3.3.2.2.2.2.2">𝑡</ci><ci id="S3.p1.3.m3.3.3.2.2.2.2.3.cmml" xref="S3.p1.3.m3.3.3.2.2.2.2.3">′</ci></apply><ci id="S3.p1.3.m3.3.3.2.2.2.3.cmml" xref="S3.p1.3.m3.3.3.2.2.2.3">𝑘</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.3c">S=(t^{\prime}_{1},...,t^{\prime}_{k})</annotation></semantics></math>, based on <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">T</annotation></semantics></math>, that would obtain information, or perform actions, needed to address <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.p1.5.m5.1a"><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">q</annotation></semantics></math>. Based on the responses obtained after performing the call sequence (using an external API invoker), the model then generates a final response <math id="S3.p1.6.m6.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.p1.6.m6.1a"><mi id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">r</annotation></semantics></math> that responds to <math id="S3.p1.7.m7.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.p1.7.m7.1a"><mi id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">q</annotation></semantics></math>. The primary method for model evaluation is based on calculating the <span id="S3.p1.9.1" class="ltx_text ltx_font_italic">pass rate</span>, which measures the proportion of instances that successfully addressed their instructions, i.e., a predicted <math id="S3.p1.8.m8.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.p1.8.m8.1a"><mi id="S3.p1.8.m8.1.1" xref="S3.p1.8.m8.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.1b"><ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.1c">r</annotation></semantics></math> responded to <math id="S3.p1.9.m9.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.p1.9.m9.1a"><mi id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><ci id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">q</annotation></semantics></math> adequately (explained further in §<a href="#S6" title="6 Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">As mentioned in Section <a href="#S2" title="2 Background and Related Work ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the prominent datasets created for training and testing tool-using models were created synthetically with the assistance of LLMs. Specifically, we utilize the ToolBench <cite class="ltx_cite ltx_citemacro_cite">Qin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite> and ToolAlpaca <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> datasets. <a href="#S3.T1" title="Table 1 ‣ 3 Task Setup ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> summarizes their characteristics. The main practical differences are the quality of the APIs (i.e., the documentation clarity and uniformity of ToolBench is inferior to that of ToolAlpaca), and the number of tools required to respond to a query instruction (ToolBench might require several calls to unrelated tools, while ToolAlpaca requires calling a maximum of two related tools). As presented later in this work, these two differences strongly reflect on the overall quality of the respective datasets.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:123.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(58.4pt,-16.6pt) scale(1.36878412210187,1.36878412210187) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S3.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Characteristic</span></th>
<th id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">ToolBench</span></th>
<th id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">ToolAlpaca</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.2.1" class="ltx_tr">
<th id="S3.T1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">API source</th>
<td id="S3.T1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">real-world</td>
<td id="S3.T1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">synthesized w/GPT</td>
</tr>
<tr id="S3.T1.1.1.3.2" class="ltx_tr">
<th id="S3.T1.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"># available APIs</th>
<td id="S3.T1.1.1.3.2.2" class="ltx_td ltx_align_center">16K</td>
<td id="S3.T1.1.1.3.2.3" class="ltx_td ltx_align_center">2.3K</td>
</tr>
<tr id="S3.T1.1.1.4.3" class="ltx_tr">
<th id="S3.T1.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"># of training instances</th>
<td id="S3.T1.1.1.4.3.2" class="ltx_td ltx_align_center">125K</td>
<td id="S3.T1.1.1.4.3.3" class="ltx_td ltx_align_center">4.2K</td>
</tr>
<tr id="S3.T1.1.1.5.4" class="ltx_tr">
<th id="S3.T1.1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"># required API calls per instance</th>
<td id="S3.T1.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">1-5</td>
<td id="S3.T1.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb">1-2</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Summary of relevant dataset characteristics.</figcaption>
</figure>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Problem statement.</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">Our primary focus is on evaluating and improving data quality, and to show its effect on model performance in tool-using LLMs. Following a similar line of research, we hypothesize that a small quantity of high-quality training data is preferred over a large quantity of lower-quality data. To demonstrate this, we first define intrinsic quality criteria for the data (§<a href="#S4.SS1" title="4.1 Quality Criteria ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) and implement automated metrics accordingly (§<a href="#S4.SS3" title="4.3 Automated Metrics ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>). We additionally propose an alternative data quality appraisal method using in-context evaluation (§<a href="#S5" title="5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). Finally, we filter out the lower-quality data from datasets using our automated metrics, and analyze the effect of the improved data quality on model performance (§<a href="#S6" title="6 Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Intrinsic Quality Evaluation</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Quality Criteria</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We set out to understand what makes an instance of data high quality, specifically for training tool-using LLMs. The criteria we discuss pertain to both the query instruction and the API call sequence of a data instance.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We considered other properties that were eventually excluded from our framework, such as diversity and syntax validity. See Appendix <a href="#A1.SS1" title="A.1 Other Quality Criteria ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> for more details.</span></span></span></p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Synthetic Instruction</span></th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Error Type</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<td id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T2.1.2.1.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:346.9pt;">
<span id="S4.T2.1.2.1.1.1.1" class="ltx_p">I’m curious about <span id="S4.T2.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">a famous actor’s</span> career. Can you provide details about their filmography, including their best-known titles and streaming availability on Netflix, Hulu, and Prime Video? Also, share some interesting facts about the actor.</span>
</span>
</td>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Low Specificity</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<td id="S4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T2.1.3.2.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:346.9pt;">
<span id="S4.T2.1.3.2.1.1.1" class="ltx_p">As a language enthusiast, I’m always eager to learn new languages. Can you help me explore the possible translations between Russian, Japanese, and Arabic? <span id="S4.T2.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">Additionally, I would like to obtain a list of available language codes for future reference</span>.</span>
</span>
</td>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Low Coherence</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<td id="S4.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T2.1.4.3.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:346.9pt;">
<span id="S4.T2.1.4.3.1.1.1" class="ltx_p">I need to <span id="S4.T2.1.4.3.1.1.1.1" class="ltx_text ltx_font_bold">create</span> a temporary email address with the domain ’example.com’. Once created, I want to fetch the latest message from this email address.</span>
<span id="S4.T2.1.4.3.1.1.2" class="ltx_p">Given APIs: [Get list of domains for email, Get message by message ID]</span>
</span>
</td>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Unsolvable</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Examples of synthesized instructions, <span id="S4.T2.3.1" class="ltx_text ltx_font_bold">highlighted</span> with errors involving our defined properties.</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:67.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.2pt,2.8pt) scale(0.922422700975581,0.922422700975581) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Synthetic Instruction</span></th>
<th id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">API-Call within Sequence</span></th>
<th id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Error Type</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.2.1" class="ltx_tr">
<td id="S4.T3.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.2.1.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:216.8pt;">
<span id="S4.T3.1.1.2.1.1.1.1" class="ltx_p">Can you create a shield logo for my friend’s blog? The name of the blog is ‘The Creative Mind’.</span>
</span>
</td>
<td id="S4.T3.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.2.1.2.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:108.4pt;">
<span id="S4.T3.1.1.2.1.2.1.1" class="ltx_p"><span id="S4.T3.1.1.2.1.2.1.1.1" class="ltx_text ltx_font_typewriter">generate_shield(name=None)</span></span>
</span>
</td>
<td id="S4.T3.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Missing Parameter</td>
</tr>
<tr id="S4.T3.1.1.3.2" class="ltx_tr">
<td id="S4.T3.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.3.2.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:216.8pt;">
<span id="S4.T3.1.1.3.2.1.1.1" class="ltx_p">I need to fetch the current weather conditions for a specific location. Can you help me by providing the address and geocoordinates of the location?</span>
</span>
</td>
<td id="S4.T3.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T3.1.1.3.2.2.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:108.4pt;">
<span id="S4.T3.1.1.3.2.2.1.1" class="ltx_p"><span id="S4.T3.1.1.3.2.2.1.1.1" class="ltx_text ltx_font_typewriter">geocode(address="San Francisco")</span></span>
<span id="S4.T3.1.1.3.2.2.1.2" class="ltx_p">…</span>
</span>
</td>
<td id="S4.T3.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Hallucinated Parameter</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Examples of synthesized API-call sequences for respective instructions, with incorrect parameters.</figcaption>
</figure>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Instruction Properties</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">In our setting, an instruction is a free-form text of one-to-a-few sentences that describes a user requirement.
An instruction can contain more than one request, likely implying the need for several tool invocations. The following properties in the instruction demand validation (examples in <a href="#S4.T2" title="Table 2 ‣ 4.1 Quality Criteria ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>):</p>
</div>
<section id="S4.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Specificity.</h5>

<div id="S4.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px1.p1.1" class="ltx_p">All the required details are present in the instruction for the LLM to be able to fulfill the user requests.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Coherence.</h5>

<div id="S4.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px2.p1.1" class="ltx_p">The requests within the instruction are logically related, and the order of requests makes sense for a real-world use case.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Solvability.</h5>

<div id="S4.SS1.SSS1.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px3.p1.1" class="ltx_p">The requests within the instruction can be addressed by the given API tools.</p>
</div>
</section>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>API-Call Sequence Properties</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Apart from the instruction, given as input to a model, the other vital component of a training instance is the ground-truth output used for training (or evaluating) a model. In our setting, this is the sequence of API calls that the model is expected to infer. We define the following properties for API-call sequence correctness (see <a href="#S4.T3" title="Table 3 ‣ 4.1 Quality Criteria ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 3</span></a> for examples):</p>
</div>
<section id="S4.SS1.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parameter alignment.</h5>

<div id="S4.SS1.SSS2.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS2.Px1.p1.1" class="ltx_p">The parameter values in each of the API calls are correctly extracted or inferred from the instruction, there are no missing or hallucinated parameter values.</p>
</div>
</section>
<section id="S4.SS1.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Sufficiency.</h5>

<div id="S4.SS1.SSS2.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.Px2.p1.1" class="ltx_p">The API-call sequence applies to all required actions for the instruction’s requests.</p>
</div>
</section>
<section id="S4.SS1.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Minimality.</h5>

<div id="S4.SS1.SSS2.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS2.Px3.p1.1" class="ltx_p">The API-call sequence would address all the instruction requirements with a minimal number of API calls. No unnecessary or redundant API calls are included in the sequence.</p>
</div>
</section>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Manual Annotations</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The six intrinsic properties defined above specify the desired qualities for data instances of tool-using LLMs. Existing datasets do not always abide by these quality criteria, especially when they are collected synthetically and do not go through a cleaning phase. We inspect such noisy data by preparing annotation guidelines with respect to the criteria, and annotating accordingly. Specifically, we methodically<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Annotation process and agreement in Appendix <a href="#A1.SS4" title="A.4 Manual Annotation Process ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.4</span></a>.</span></span></span> annotated 50 (instruction, API sequence) pairs from each of the training sets of ToolBench <cite class="ltx_cite ltx_citemacro_cite">Qin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite> and ToolAlpaca <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>, as well as a large portion of the ToolBench test set (<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mo id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\sim</annotation></semantics></math>700 instances).<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We did not review ToolAlpaca’s test set since it is already manually verified.</span></span></span> Each of the criteria is marked either as valid or invalid for each of the annotated instances. The annotated data is used in later sections for analyses and experiments.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:165.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-33.5pt,16.0pt) scale(0.837971488066729,0.837971488066729) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt" style="padding:1pt 5.0pt;"></th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_tt" style="padding:1pt 5.0pt;"></th>
<td id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;" colspan="4"><span id="S4.T4.1.1.1.1.3.1" class="ltx_text ltx_font_bold">ToolBench Dataset</span></td>
<td id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;" colspan="4"><span id="S4.T4.1.1.1.1.4.1" class="ltx_text ltx_font_bold">ToolAlpaca Dataset</span></td>
</tr>
<tr id="S4.T4.1.1.2.2" class="ltx_tr">
<th id="S4.T4.1.1.2.2.1" class="ltx_td ltx_th ltx_th_row" style="padding:1pt 5.0pt;"></th>
<th id="S4.T4.1.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.2.1" class="ltx_text ltx_font_bold">Quality Criterion</span></th>
<td id="S4.T4.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.3.1" class="ltx_text ltx_font_bold">Accuracy</span></td>
<td id="S4.T4.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.4.1" class="ltx_text ltx_font_bold">Prec.</span></td>
<td id="S4.T4.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.5.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T4.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.6.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="S4.T4.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.7.1" class="ltx_text ltx_font_bold">Accuracy</span></td>
<td id="S4.T4.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.8.1" class="ltx_text ltx_font_bold">Prec.</span></td>
<td id="S4.T4.1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.9.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T4.1.1.2.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;"><span id="S4.T4.1.1.2.2.10.1" class="ltx_text ltx_font_bold">F1</span></td>
</tr>
<tr id="S4.T4.1.1.3.3" class="ltx_tr">
<th id="S4.T4.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding:1pt 5.0pt;" rowspan="4"><span id="S4.T4.1.1.3.3.1.1" class="ltx_text">
<span id="S4.T4.1.1.3.3.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.8pt;height:48.2pt;vertical-align:-20.7pt;"><span class="ltx_transformed_inner" style="width:48.1pt;transform:translate(-20.65pt,0pt) rotate(-90deg) ;">
<span id="S4.T4.1.1.3.3.1.1.1.1" class="ltx_p">Instruction</span>
</span></span></span></th>
<th id="S4.T4.1.1.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 5.0pt;">Specificity</th>
<td id="S4.T4.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.74</td>
<td id="S4.T4.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.70</td>
<td id="S4.T4.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.84</td>
<td id="S4.T4.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1pt 5.0pt;">0.76</td>
<td id="S4.T4.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.88</td>
<td id="S4.T4.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.75</td>
<td id="S4.T4.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.86</td>
<td id="S4.T4.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.80</td>
</tr>
<tr id="S4.T4.1.1.4.4" class="ltx_tr">
<th id="S4.T4.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 5.0pt;">Coherence</th>
<td id="S4.T4.1.1.4.4.2" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.82</td>
<td id="S4.T4.1.1.4.4.3" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.62</td>
<td id="S4.T4.1.1.4.4.4" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.77</td>
<td id="S4.T4.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:1pt 5.0pt;">0.69</td>
<td id="S4.T4.1.1.4.4.6" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.98</td>
<td id="S4.T4.1.1.4.4.7" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.50</td>
<td id="S4.T4.1.1.4.4.8" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">1.00</td>
<td id="S4.T4.1.1.4.4.9" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.66</td>
</tr>
<tr id="S4.T4.1.1.5.5" class="ltx_tr">
<th id="S4.T4.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 5.0pt;">Solvability</th>
<td id="S4.T4.1.1.5.5.2" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.90</td>
<td id="S4.T4.1.1.5.5.3" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.70</td>
<td id="S4.T4.1.1.5.5.4" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.78</td>
<td id="S4.T4.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:1pt 5.0pt;">0.74</td>
<td id="S4.T4.1.1.5.5.6" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.92</td>
<td id="S4.T4.1.1.5.5.7" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.75</td>
<td id="S4.T4.1.1.5.5.8" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.50</td>
<td id="S4.T4.1.1.5.5.9" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.60</td>
</tr>
<tr id="S4.T4.1.1.6.6" class="ltx_tr">
<th id="S4.T4.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 5.0pt;">Instruction Correctness</th>
<td id="S4.T4.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.72</td>
<td id="S4.T4.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.72</td>
<td id="S4.T4.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.90</td>
<td id="S4.T4.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1pt 5.0pt;">0.80</td>
<td id="S4.T4.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.86</td>
<td id="S4.T4.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.80</td>
<td id="S4.T4.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.84</td>
<td id="S4.T4.1.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.82</td>
</tr>
<tr id="S4.T4.1.1.7.7" class="ltx_tr">
<th id="S4.T4.1.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding:1pt 5.0pt;" rowspan="4"><span id="S4.T4.1.1.7.7.1.1" class="ltx_text">
<span id="S4.T4.1.1.7.7.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:60.4pt;vertical-align:-27.7pt;"><span class="ltx_transformed_inner" style="width:60.4pt;transform:translate(-25.76pt,2.92pt) rotate(-90deg) ;">
<span id="S4.T4.1.1.7.7.1.1.1.1" class="ltx_p">API Call Seq.</span>
</span></span></span></th>
<th id="S4.T4.1.1.7.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding:1pt 5.0pt;">Parameter Alignment</th>
<td id="S4.T4.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;">0.70</td>
<td id="S4.T4.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;">0.63</td>
<td id="S4.T4.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;">0.92</td>
<td id="S4.T4.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding:1pt 5.0pt;">0.74</td>
<td id="S4.T4.1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;">0.76</td>
<td id="S4.T4.1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;">0.74</td>
<td id="S4.T4.1.1.7.7.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;">0.80</td>
<td id="S4.T4.1.1.7.7.10" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 5.0pt;">0.77</td>
</tr>
<tr id="S4.T4.1.1.8.8" class="ltx_tr">
<th id="S4.T4.1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 5.0pt;">Sufficiency</th>
<td id="S4.T4.1.1.8.8.2" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.78</td>
<td id="S4.T4.1.1.8.8.3" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.64</td>
<td id="S4.T4.1.1.8.8.4" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.60</td>
<td id="S4.T4.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:1pt 5.0pt;">0.62</td>
<td id="S4.T4.1.1.8.8.6" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.88</td>
<td id="S4.T4.1.1.8.8.7" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.80</td>
<td id="S4.T4.1.1.8.8.8" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.50</td>
<td id="S4.T4.1.1.8.8.9" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.62</td>
</tr>
<tr id="S4.T4.1.1.9.9" class="ltx_tr">
<th id="S4.T4.1.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 5.0pt;">Minimality</th>
<td id="S4.T4.1.1.9.9.2" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.76</td>
<td id="S4.T4.1.1.9.9.3" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.95</td>
<td id="S4.T4.1.1.9.9.4" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.63</td>
<td id="S4.T4.1.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:1pt 5.0pt;">0.76</td>
<td id="S4.T4.1.1.9.9.6" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.86</td>
<td id="S4.T4.1.1.9.9.7" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.88</td>
<td id="S4.T4.1.1.9.9.8" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.57</td>
<td id="S4.T4.1.1.9.9.9" class="ltx_td ltx_align_center" style="padding:1pt 5.0pt;">0.70</td>
</tr>
<tr id="S4.T4.1.1.10.10" class="ltx_tr">
<th id="S4.T4.1.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 5.0pt;">Sequence Correctness</th>
<td id="S4.T4.1.1.10.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.82</td>
<td id="S4.T4.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.83</td>
<td id="S4.T4.1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.94</td>
<td id="S4.T4.1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:1pt 5.0pt;">0.88</td>
<td id="S4.T4.1.1.10.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.76</td>
<td id="S4.T4.1.1.10.10.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.70</td>
<td id="S4.T4.1.1.10.10.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.85</td>
<td id="S4.T4.1.1.10.10.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 5.0pt;">0.80</td>
</tr>
<tr id="S4.T4.1.1.11.11" class="ltx_tr">
<th id="S4.T4.1.1.11.11.1" class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;"></th>
<th id="S4.T4.1.1.11.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">Overall Correctness</th>
<td id="S4.T4.1.1.11.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">0.86</td>
<td id="S4.T4.1.1.11.11.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">0.89</td>
<td id="S4.T4.1.1.11.11.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">0.95</td>
<td id="S4.T4.1.1.11.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" style="padding:1pt 5.0pt;">0.92</td>
<td id="S4.T4.1.1.11.11.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">0.76</td>
<td id="S4.T4.1.1.11.11.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">0.74</td>
<td id="S4.T4.1.1.11.11.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">0.90</td>
<td id="S4.T4.1.1.11.11.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" style="padding:1pt 5.0pt;">0.81</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Validation results of the automated metrics for each criterion, in the ToolBench and ToolAlpaca datasets. Coarse-grained correctness considers combined correctness over specific criteria. Note that precision, recall and F1 are measured w.r.t. a label that is positive when an error occurs, so e.g., recall means the amount of errors caught.
</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Automated Metrics</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Although manual assessment of data is preferred for its reliability, it is labor-intensive and therefore not scalable or practical. We propose automatic metrics for the intrinsic quality criteria defined above.
The metrics are based on ChatGPT,<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Throughout the paper, we use <span id="footnote5.1" class="ltx_text ltx_font_typewriter">gpt-3.5-turbo-0613</span>.</span></span></span> which is tasked to determine the validity of each criterion as a binary decision.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">For the dimensions of Specificity, Coherence and Parameter alignment, direct annotation with ChatGPT proved to be challenging. That is, simply asking the model to validate the property in a natural language instruction did not yield sufficient decisions (see Appendix <a href="#A1.SS3" title="A.3 Unsuccessful Prompts ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>).
Thus, we transformed the direct annotation tasks into traditional NLP tasks, on which ChatGPT performed better.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Specificity.</h5>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">Validating the specificity of requests is modeled as
an <span id="S4.SS3.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">extraction</span> task. ChatGPT is tasked to infer the details required for a given request, and then extract the available values from the instruction, or mark a parameter as <span id="S4.SS3.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_typewriter">#missing</span>. We then compute a proxy score for specificity: 1 if all parameters were successfully extracted from the instruction, and 0 otherwise.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Coherence.</h5>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">We adopt the concept of <span id="S4.SS3.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">next sentence prediction</span> to assess coherence. The instruction is split into sentences, and ChatGPT determines if each subsequent sentence logically follows the previous one. We set a coherence score as 1 if all sentence pairs are judged logically connected, and 0 otherwise.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parameter alignment.</h5>

<div id="S4.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px3.p1.1" class="ltx_p">ChatGPT first extracts parameters (as in specificity), and then compares it to the ground truth parameter values.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Solvability, Sufficiency &amp; Minimality.</h5>

<div id="S4.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px4.p1.1" class="ltx_p">The remaining criteria use direct instructions to ChatGPT. The prompts used are provided in Appendix <a href="#A1.SS2" title="A.2 Prompts for Assessment ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:49.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-97.4pt,11.2pt) scale(0.690049149427976,0.690049149427976) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T5.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" colspan="4"><span id="S4.T5.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Instruction</span></td>
<td id="S4.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" colspan="4"><span id="S4.T5.1.1.1.1.3.1" class="ltx_text ltx_font_bold">API-Call Sequence</span></td>
<td id="S4.T5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T5.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Inst. &amp; Seq. Overall</span></td>
</tr>
<tr id="S4.T5.1.1.2.2" class="ltx_tr">
<td id="S4.T5.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Specificity</span></td>
<td id="S4.T5.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.2.1" class="ltx_text ltx_font_bold">Coherence</span></td>
<td id="S4.T5.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.3.1" class="ltx_text ltx_font_bold">Solvable</span></td>
<td id="S4.T5.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.4.1" class="ltx_text ltx_font_bold">Overall</span></td>
<td id="S4.T5.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.5.1" class="ltx_text ltx_font_bold">Param. Alignment</span></td>
<td id="S4.T5.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.6.1" class="ltx_text ltx_font_bold">Sufficiency</span></td>
<td id="S4.T5.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.7.1" class="ltx_text ltx_font_bold">Minimality</span></td>
<td id="S4.T5.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_rr" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.2.2.8.1" class="ltx_text ltx_font_bold">Overall</span></td>
</tr>
<tr id="S4.T5.1.1.3.3" class="ltx_tr">
<td id="S4.T5.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.3.3.1.1" class="ltx_text ltx_font_bold">ToolBench</span></td>
<td id="S4.T5.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">20.4%</td>
<td id="S4.T5.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">22.1%</td>
<td id="S4.T5.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">18.2%</td>
<td id="S4.T5.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">47.3%</td>
<td id="S4.T5.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">47.9%</td>
<td id="S4.T5.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">33.6%</td>
<td id="S4.T5.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">45.1%</td>
<td id="S4.T5.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">74.4%</td>
<td id="S4.T5.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.3.3.10.1" class="ltx_text">84.0%</span></td>
</tr>
<tr id="S4.T5.1.1.4.4" class="ltx_tr">
<td id="S4.T5.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.4.4.1.1" class="ltx_text ltx_font_bold">ToolAlpaca</span></td>
<td id="S4.T5.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">17.5%</td>
<td id="S4.T5.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">4.1%</td>
<td id="S4.T5.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">12.7%</td>
<td id="S4.T5.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">27.2%</td>
<td id="S4.T5.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">33.1%</td>
<td id="S4.T5.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">13.6%</td>
<td id="S4.T5.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">15.9%</td>
<td id="S4.T5.1.1.4.4.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">35.5%</td>
<td id="S4.T5.1.1.4.4.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T5.1.1.4.4.10.1" class="ltx_text">44.8%</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Percentage of instances containing errors in each dimension, according to our automated methods, in the train sets of the examined datasets. This analysis is done on 125K examples in ToolBench and 4.2K in ToolAlpaca.</figcaption>
</figure>
</section>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Evaluation of Automated Metrics</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Using the manually annotated data (described in §<a href="#S4.SS2" title="4.2 Manual Annotations ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>), we conduct an assessment of the automatic metrics proposed. For each of the ToolBench and ToolAlpaca datasets, the 50 annotated instances are compared against the automatically produced values, producing measures of accuracy (agreement), precision, recall and F1 score. We treat instances marked as incorrect instances as positive labels, since we aim to identify and filter erroneous instances.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">We conduct a coarser-grained evaluation of the criteria, assessing <span id="S4.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Instruction Correctness</span> as incorrect if any instruction criterion is wrong, and <span id="S4.SS3.SSS1.p2.1.2" class="ltx_text ltx_font_bold">Sequence Correctness</span> as incorrect if any API-call sequence criterion is wrong. <span id="S4.SS3.SSS1.p2.1.3" class="ltx_text ltx_font_bold">Overall Correctness</span> aggregates all six criteria similarly.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p">Results are presented in <a href="#S4.T4" title="Table 4 ‣ 4.2 Manual Annotations ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 4</span></a>. Given that our main objective is to identify and filter out incorrect data samples, our emphasis is on achieving high recall. This objective is largely met across most criteria in both datasets. In the Overall Correctness assessment, which aggregates all criteria, we observe high recall and precision, demonstrating a strong alignment of the automated metrics with human judgment. This approach thus offers a reliable mechanism to identify problematic data instances.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>
Quality of Datasets
</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Table <a href="#S4.T5" title="Table 5 ‣ Solvability, Sufficiency &amp; Minimality. ‣ 4.3 Automated Metrics ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents the percentage of instances containing errors in the train sets of both ToolBench and ToolAlpaca, as determined by the automated metrics. These statistics provide insights into the quality of the data in each dataset. In the ToolBench dataset we observe a much higher percentage of errors across most quality criteria, when compared to ToolAlpaca. This difference may be attributed to (1) the complexity of instructions in ToolBench, which can
require several (up to 5) API calls; (2) real-world APIs used in ToolBench, where the API documentation is not always clear, resulting in incorrectly generated instructions and API-call sequences. Notice that in both datasets, over <math id="S4.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="33\%" display="inline"><semantics id="S4.SS3.SSS2.p1.1.m1.1a"><mrow id="S4.SS3.SSS2.p1.1.m1.1.1" xref="S4.SS3.SSS2.p1.1.m1.1.1.cmml"><mn id="S4.SS3.SSS2.p1.1.m1.1.1.2" xref="S4.SS3.SSS2.p1.1.m1.1.1.2.cmml">33</mn><mo id="S4.SS3.SSS2.p1.1.m1.1.1.1" xref="S4.SS3.SSS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS2.p1.1.m1.1b"><apply id="S4.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS2.p1.1.m1.1.1.2">33</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS2.p1.1.m1.1c">33\%</annotation></semantics></math> of instances have parameter alignment errors. Such an error means that one of the core requirements of a tool-using model – identifying parameters correctly – is misleadingly learned in more than a third of the cases, due to wrong training examples.
Some anecdotal examples of incorrect instructions found by our metrics can be seen in Appendix <a href="#A1.SS5" title="A.5 Qualitative Examples ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.5</span></a>.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p">We further explore the relationship between quality criteria within the datasets in Appendix <a href="#A1.SS6" title="A.6 Relationship Between Quality Criteria ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.6</span></a>.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>In-Context Evaluation (ICE) as an Alternative Data Measurement</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Using intrinsic evaluation, we have defined an intuitive and straightforward approach to identify low-quality data instances based on human understanding of data correctness. However, assessing the “educational” value of an instance, i.e., its contribution to the learning process of a model, is a complex task.
In addition, the intrinsic evaluation metrics proposed rely on prompting a powerful LLM, which can become costly on large datasets. To address these challenges, we propose In-Context Evaluation (ICE) as an alternative automatic approach for assessing data quality.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Recent studies found a connection between in-context learning and fine-tuning, demonstrating that language models implicitly perform gradient descent when dealing with in-context tasks <cite class="ltx_cite ltx_citemacro_cite">Von Oswald et al. (<a href="#bib.bib22" title="" class="ltx_ref">2023</a>); Dai et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite>. Motivated by this insight, we seek to evaluate the educational value of each data instance by measuring the performance of in-context learning using the specific instance as a one-shot example.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Setup</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.6" class="ltx_p">To construct the in-context task for external tool use, we prepare a set of 10 human-written APIs, denoted by <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mi id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">A</annotation></semantics></math>, with simple accompanying documentation.
In addition, we hand-craft a set of 7 test query instructions, <span id="S5.SS1.p1.6.1" class="ltx_text ltx_font_smallcaps">Test</span>, where each such example contains a natural language instruction and an expected API-call sequence, from the APIs in <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mi id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><ci id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">A</annotation></semantics></math>, that would address the instruction.
For each evaluation instance, we insert an in-context example, <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><mi id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><ci id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">x</annotation></semantics></math>, which consists of an instruction and API-call sequence from the training dataset (i.e., ToolBench or ToolAlpaca).
<math id="S5.SS1.p1.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.SS1.p1.4.m4.1a"><mi id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><ci id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">x</annotation></semantics></math> follows the structure of the test examples.
We then formulate a prompt for the LLM that we aim to train, that asks to generate responses for the 7 test cases. In particular, the prompt includes (1) task instructions,
(2) the API documentation of <math id="S5.SS1.p1.5.m5.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S5.SS1.p1.5.m5.1a"><mi id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><ci id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">A</annotation></semantics></math>, (3) the training instance, <math id="S5.SS1.p1.6.m6.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.SS1.p1.6.m6.1a"><mi id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.1b"><ci id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.1c">x</annotation></semantics></math>, given as a one-shot example, (4) the 7 testing instructions of <span id="S5.SS1.p1.6.2" class="ltx_text ltx_font_smallcaps">Test</span>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.2" class="ltx_p">The prompt is given to an LLM we aim to train: LLaMA-7B for ToolBench or Vicuna-7B for ToolAlpaca. We analyze its response, that should include the 7 API-call sequences of <span id="S5.SS1.p2.2.1" class="ltx_text ltx_font_smallcaps">Test</span>.
The responses for the test instructions are evaluated against the ground truth (using Levenshtein similarity <cite class="ltx_cite ltx_citemacro_cite">Levenshtein et al. (<a href="#bib.bib12" title="" class="ltx_ref">1966</a>)</cite>, expecting an exact match for API-call sequences). The final ICE score for <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mi id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><ci id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">x</annotation></semantics></math> is the average over the 7 test examples, interpreted as a measure of the educational value of <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><mi id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><ci id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">x</annotation></semantics></math>. We provide the full prompt and the precise way we compute
the ICE score in Appendix <a href="#A2" title="Appendix B ICE ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Analysis</h3>

<figure id="S5.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.16341/assets/figures/ice_dist_bench.png" id="S5.F2.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="269" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>ToolBench</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.16341/assets/figures/ice_dist_alpaca.png" id="S5.F2.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="269" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>ToolAlpaca</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distribution of ICE scores. Most instances in ToolAlpaca are beneficial as the one-shot in-context example. ToolBench instances are not as effective.</figcaption>
</figure>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2409.16341/assets/figures/ice_overall_confusion_matrices.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Confusion matrices comparing ICE scores and human Overall Correctness scores.</figcaption>
</figure>
<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Score distribution.</h5>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.1" class="ltx_p">We present ICE scores for both datasets in Figure <a href="#S5.F2" title="Figure 2 ‣ 5.2 Analysis ‣ 5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Interestingly, the ICE scores distribution in ToolAlpaca exhibits bimodal distribution, which suggests the presence of two types of examples: one with higher ICE scores, which we expect to correlate with good-quality examples, and another with lower ICE scores, which is expected to lean towards low-quality examples. The majority of instances in ToolAlpaca have relatively high ICE scores – indicating high overall dataset quality. In contrast, most samples in ToolBench have low ICE scores, suggesting that the overall data quality in this dataset may be lower compared to ToolAlpaca. This observation is consistent with the analysis presented using the intrinsic evaluation in Section <a href="#S4.SS3.SSS2" title="4.3.2 Quality of Datasets ‣ 4.3 Automated Metrics ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.2</span></a>.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Correlation to human-defined criteria.</h5>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.1" class="ltx_p">ICE is a model-driven assessment method that may not necessarily align with human-defined correctness criteria. To investigate the relationship between ICE approach and human-defined criteria, we divide the datasets into low and high ICE scores using a threshold of 0.5. We then generate confusion matrices between ICE scores and human <span id="S5.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Overall Correctness</span> scores.
As seen in Figure <a href="#S5.F3" title="Figure 3 ‣ 5.2 Analysis ‣ 5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>,
ICE scores correlate with human-defined correctness to some extent,
showing it is a sensible metric and can be beneficial as an alternative method for filtering data. On the other hand, this correlation is far from perfect, showing that ICE is inherently different from human-prescribed correctness.
In Section <a href="#S6" title="6 Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> we test ICE both as an alternative and as a complementary filtering technique to human-defined correctness.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Extrinsic Evaluation</h2>

<figure id="S6.T6" class="ltx_table">
<table id="S6.T6.43" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T6.43.44.1" class="ltx_tr">
<th id="S6.T6.43.44.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"></th>
<th id="S6.T6.43.44.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S6.T6.43.44.1.2.1" class="ltx_text ltx_font_bold">Fine-tune Set</span></th>
<th id="S6.T6.43.44.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" colspan="3"><span id="S6.T6.43.44.1.3.1" class="ltx_text ltx_font_bold">ToolBench</span></th>
<th id="S6.T6.43.44.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" colspan="3"><span id="S6.T6.43.44.1.4.1" class="ltx_text ltx_font_bold">ToolAlpaca</span></th>
</tr>
<tr id="S6.T6.43.45.2" class="ltx_tr">
<th id="S6.T6.43.45.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"></th>
<th id="S6.T6.43.45.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.43.45.2.2.1" class="ltx_text ltx_font_bold">Size</span></th>
<th id="S6.T6.43.45.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.43.45.2.3.1" class="ltx_text ltx_font_bold">Pass Rate</span></th>
<th id="S6.T6.43.45.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.43.45.2.4.1" class="ltx_text ltx_font_bold">95% CI</span></th>
<th id="S6.T6.43.45.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.43.45.2.5.1" class="ltx_text ltx_font_bold">Size</span></th>
<th id="S6.T6.43.45.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.43.45.2.6.1" class="ltx_text ltx_font_bold">Pass Rate</span></th>
<th id="S6.T6.43.45.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.43.45.2.7.1" class="ltx_text ltx_font_bold">95% CI</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T6.6.6" class="ltx_tr">
<th id="S6.T6.6.6.7" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.6.6.7.1" class="ltx_text" style="color:#808080;">1</span></th>
<th id="S6.T6.6.6.8" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">Random Sample</th>
<td id="S6.T6.6.6.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">10K</td>
<td id="S6.T6.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.1.1.1.m1.1" class="ltx_Math" alttext="0.35" display="inline"><semantics id="S6.T6.1.1.1.m1.1a"><mn id="S6.T6.1.1.1.m1.1.1" xref="S6.T6.1.1.1.m1.1.1.cmml">0.35</mn><annotation-xml encoding="MathML-Content" id="S6.T6.1.1.1.m1.1b"><cn type="float" id="S6.T6.1.1.1.m1.1.1.cmml" xref="S6.T6.1.1.1.m1.1.1">0.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.1.1.1.m1.1c">0.35</annotation></semantics></math></td>
<td id="S6.T6.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">(0.31, 0.39)</td>
<td id="S6.T6.6.6.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">2K</td>
<td id="S6.T6.4.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.4.4.4.m1.1" class="ltx_Math" alttext="0.48" display="inline"><semantics id="S6.T6.4.4.4.m1.1a"><mn id="S6.T6.4.4.4.m1.1.1" xref="S6.T6.4.4.4.m1.1.1.cmml">0.48</mn><annotation-xml encoding="MathML-Content" id="S6.T6.4.4.4.m1.1b"><cn type="float" id="S6.T6.4.4.4.m1.1.1.cmml" xref="S6.T6.4.4.4.m1.1.1">0.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.4.4.4.m1.1c">0.48</annotation></semantics></math></td>
<td id="S6.T6.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">(0.38, 0.58)</td>
</tr>
<tr id="S6.T6.12.12" class="ltx_tr">
<th id="S6.T6.12.12.7" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.12.12.7.1" class="ltx_text" style="color:#808080;">2</span></th>
<th id="S6.T6.12.12.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">Low ICE</th>
<td id="S6.T6.12.12.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">10K</td>
<td id="S6.T6.7.7.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.7.7.1.m1.1" class="ltx_Math" alttext="0.24" display="inline"><semantics id="S6.T6.7.7.1.m1.1a"><mn id="S6.T6.7.7.1.m1.1.1" xref="S6.T6.7.7.1.m1.1.1.cmml">0.24</mn><annotation-xml encoding="MathML-Content" id="S6.T6.7.7.1.m1.1b"><cn type="float" id="S6.T6.7.7.1.m1.1.1.cmml" xref="S6.T6.7.7.1.m1.1.1">0.24</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.7.7.1.m1.1c">0.24</annotation></semantics></math></td>
<td id="S6.T6.9.9.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">(0.20, 0.28)</td>
<td id="S6.T6.12.12.10" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2K</td>
<td id="S6.T6.10.10.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.10.10.4.m1.1" class="ltx_Math" alttext="0.48" display="inline"><semantics id="S6.T6.10.10.4.m1.1a"><mn id="S6.T6.10.10.4.m1.1.1" xref="S6.T6.10.10.4.m1.1.1.cmml">0.48</mn><annotation-xml encoding="MathML-Content" id="S6.T6.10.10.4.m1.1b"><cn type="float" id="S6.T6.10.10.4.m1.1.1.cmml" xref="S6.T6.10.10.4.m1.1.1">0.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.10.10.4.m1.1c">0.48</annotation></semantics></math></td>
<td id="S6.T6.12.12.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">(0.38, 0.58)</td>
</tr>
<tr id="S6.T6.18.18" class="ltx_tr">
<th id="S6.T6.18.18.7" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.18.18.7.1" class="ltx_text" style="color:#808080;">3</span></th>
<th id="S6.T6.18.18.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">High ICE</th>
<td id="S6.T6.18.18.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">10K</td>
<td id="S6.T6.13.13.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.13.13.1.m1.1" class="ltx_Math" alttext="0.43" display="inline"><semantics id="S6.T6.13.13.1.m1.1a"><mn id="S6.T6.13.13.1.m1.1.1" xref="S6.T6.13.13.1.m1.1.1.cmml">0.43</mn><annotation-xml encoding="MathML-Content" id="S6.T6.13.13.1.m1.1b"><cn type="float" id="S6.T6.13.13.1.m1.1.1.cmml" xref="S6.T6.13.13.1.m1.1.1">0.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.13.13.1.m1.1c">0.43</annotation></semantics></math></td>
<td id="S6.T6.15.15.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">(0.38, 0.47)</td>
<td id="S6.T6.18.18.10" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2K</td>
<td id="S6.T6.16.16.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.16.16.4.m1.1" class="ltx_Math" alttext="0.54" display="inline"><semantics id="S6.T6.16.16.4.m1.1a"><mn id="S6.T6.16.16.4.m1.1.1" xref="S6.T6.16.16.4.m1.1.1.cmml">0.54</mn><annotation-xml encoding="MathML-Content" id="S6.T6.16.16.4.m1.1b"><cn type="float" id="S6.T6.16.16.4.m1.1.1.cmml" xref="S6.T6.16.16.4.m1.1.1">0.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.16.16.4.m1.1c">0.54</annotation></semantics></math></td>
<td id="S6.T6.18.18.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">(0.44, 0.64)</td>
</tr>
<tr id="S6.T6.24.24" class="ltx_tr">
<th id="S6.T6.24.24.7" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.24.24.7.1" class="ltx_text" style="color:#808080;">4</span></th>
<th id="S6.T6.24.24.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">High Instruction</th>
<td id="S6.T6.24.24.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">10K</td>
<td id="S6.T6.19.19.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.19.19.1.m1.1" class="ltx_Math" alttext="0.49" display="inline"><semantics id="S6.T6.19.19.1.m1.1a"><mn id="S6.T6.19.19.1.m1.1.1" xref="S6.T6.19.19.1.m1.1.1.cmml">0.49</mn><annotation-xml encoding="MathML-Content" id="S6.T6.19.19.1.m1.1b"><cn type="float" id="S6.T6.19.19.1.m1.1.1.cmml" xref="S6.T6.19.19.1.m1.1.1">0.49</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.19.19.1.m1.1c">0.49</annotation></semantics></math></td>
<td id="S6.T6.21.21.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">(0.44, 0.53)</td>
<td id="S6.T6.24.24.10" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2K</td>
<td id="S6.T6.22.22.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.22.22.4.m1.1" class="ltx_Math" alttext="0.52" display="inline"><semantics id="S6.T6.22.22.4.m1.1a"><mn id="S6.T6.22.22.4.m1.1.1" xref="S6.T6.22.22.4.m1.1.1.cmml">0.52</mn><annotation-xml encoding="MathML-Content" id="S6.T6.22.22.4.m1.1b"><cn type="float" id="S6.T6.22.22.4.m1.1.1.cmml" xref="S6.T6.22.22.4.m1.1.1">0.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.22.22.4.m1.1c">0.52</annotation></semantics></math></td>
<td id="S6.T6.24.24.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">(0.42, 0.62)</td>
</tr>
<tr id="S6.T6.30.30" class="ltx_tr">
<th id="S6.T6.30.30.7" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.30.30.7.1" class="ltx_text" style="color:#808080;">5</span></th>
<th id="S6.T6.30.30.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">High Instruction + Seq</th>
<td id="S6.T6.30.30.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">10K</td>
<td id="S6.T6.25.25.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.25.25.1.m1.1" class="ltx_Math" alttext="0.52" display="inline"><semantics id="S6.T6.25.25.1.m1.1a"><mn id="S6.T6.25.25.1.m1.1.1" xref="S6.T6.25.25.1.m1.1.1.cmml">0.52</mn><annotation-xml encoding="MathML-Content" id="S6.T6.25.25.1.m1.1b"><cn type="float" id="S6.T6.25.25.1.m1.1.1.cmml" xref="S6.T6.25.25.1.m1.1.1">0.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.25.25.1.m1.1c">0.52</annotation></semantics></math></td>
<td id="S6.T6.27.27.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">(0.47, 0.56)</td>
<td id="S6.T6.30.30.10" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2K</td>
<td id="S6.T6.28.28.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.28.28.4.m1.1" class="ltx_Math" alttext="0.54" display="inline"><semantics id="S6.T6.28.28.4.m1.1a"><mn id="S6.T6.28.28.4.m1.1.1" xref="S6.T6.28.28.4.m1.1.1.cmml">0.54</mn><annotation-xml encoding="MathML-Content" id="S6.T6.28.28.4.m1.1b"><cn type="float" id="S6.T6.28.28.4.m1.1.1.cmml" xref="S6.T6.28.28.4.m1.1.1">0.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.28.28.4.m1.1c">0.54</annotation></semantics></math></td>
<td id="S6.T6.30.30.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">(0.44, 0.64)</td>
</tr>
<tr id="S6.T6.36.36" class="ltx_tr">
<th id="S6.T6.36.36.7" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.36.36.7.1" class="ltx_text" style="color:#808080;">6</span></th>
<th id="S6.T6.36.36.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">High Instruction + Seq + ICE</th>
<td id="S6.T6.36.36.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">10K</td>
<td id="S6.T6.31.31.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.31.31.1.m1.1" class="ltx_Math" alttext="0.54" display="inline"><semantics id="S6.T6.31.31.1.m1.1a"><mn id="S6.T6.31.31.1.m1.1.1" xref="S6.T6.31.31.1.m1.1.1.cmml">0.54</mn><annotation-xml encoding="MathML-Content" id="S6.T6.31.31.1.m1.1b"><cn type="float" id="S6.T6.31.31.1.m1.1.1.cmml" xref="S6.T6.31.31.1.m1.1.1">0.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.31.31.1.m1.1c">0.54</annotation></semantics></math></td>
<td id="S6.T6.33.33.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">(0.49, 0.58)</td>
<td id="S6.T6.36.36.10" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2K</td>
<td id="S6.T6.34.34.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.34.34.4.m1.1" class="ltx_Math" alttext="0.55" display="inline"><semantics id="S6.T6.34.34.4.m1.1a"><mn id="S6.T6.34.34.4.m1.1.1" xref="S6.T6.34.34.4.m1.1.1.cmml">0.55</mn><annotation-xml encoding="MathML-Content" id="S6.T6.34.34.4.m1.1b"><cn type="float" id="S6.T6.34.34.4.m1.1.1.cmml" xref="S6.T6.34.34.4.m1.1.1">0.55</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.34.34.4.m1.1c">0.55</annotation></semantics></math></td>
<td id="S6.T6.36.36.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">(0.45, 0.65)</td>
</tr>
<tr id="S6.T6.43.43" class="ltx_tr">
<th id="S6.T6.43.43.8" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><span id="S6.T6.43.43.8.1" class="ltx_text" style="color:#808080;">7</span></th>
<th id="S6.T6.43.43.9" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">Original</th>
<td id="S6.T6.37.37.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">73K<sup id="S6.T6.37.37.1.1" class="ltx_sup">†</sup>
</td>
<td id="S6.T6.38.38.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.38.38.2.m1.1" class="ltx_Math" alttext="0.45" display="inline"><semantics id="S6.T6.38.38.2.m1.1a"><mn id="S6.T6.38.38.2.m1.1.1" xref="S6.T6.38.38.2.m1.1.1.cmml">0.45</mn><annotation-xml encoding="MathML-Content" id="S6.T6.38.38.2.m1.1b"><cn type="float" id="S6.T6.38.38.2.m1.1.1.cmml" xref="S6.T6.38.38.2.m1.1.1">0.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.38.38.2.m1.1c">0.45</annotation></semantics></math></td>
<td id="S6.T6.40.40.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">(0.40, 0.49)</td>
<td id="S6.T6.43.43.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">4.2K</td>
<td id="S6.T6.41.41.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S6.T6.41.41.5.m1.1" class="ltx_Math" alttext="0.56" display="inline"><semantics id="S6.T6.41.41.5.m1.1a"><mn id="S6.T6.41.41.5.m1.1.1" xref="S6.T6.41.41.5.m1.1.1.cmml">0.56</mn><annotation-xml encoding="MathML-Content" id="S6.T6.41.41.5.m1.1b"><cn type="float" id="S6.T6.41.41.5.m1.1.1.cmml" xref="S6.T6.41.41.5.m1.1.1">0.56</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.41.41.5.m1.1c">0.56</annotation></semantics></math></td>
<td id="S6.T6.43.43.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">(0.46, 0.66)</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Extrinsic evaluation results with confidence intervals, and the size of the training sets. By filtering out low-quality training instances, the models perform significantly better than (in ToolBench) or as good as (in ToolAlpaca) the original models that use a much larger unvalidated training set. <sup id="S6.T6.47.1" class="ltx_sup">†</sup> Although there are 125K instances in the released dataset, the model published in the original paper was trained on a subset of 73K instances.</figcaption>
</figure>
<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we validate our main claim that fine-tuning a tool-using LLM with less higher-quality data can lead to better performance of the model on the task, compared to a more noisy dataset. We use both intrinsic metrics and ICE to create training sets of varying quality, and compare the results of training with the different sets.</p>
</div>
<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training setup.</h5>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">We follow the general setup used by the ToolAlpaca <cite class="ltx_cite ltx_citemacro_citep">(Tang et al., <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> and ToolBench <cite class="ltx_cite ltx_citemacro_citep">(Qin et al., <a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite> benchmarks. Specifically, we fine-tune Vicuna-7B <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib5" title="" class="ltx_ref">Chiang et al. </a></cite> for ToolAlpaca, and LLaMA-7B <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a href="#bib.bib21" title="" class="ltx_ref">2023</a>)</cite> for ToolBench, both using LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite> (see Appendix <a href="#A3.SS1" title="C.1 Training Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1</span></a> for more details).</p>
</div>
<div id="S6.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p2.1" class="ltx_p">We use the following train sub-sets from each model’s respective benchmark training sets:</p>
</div>
<div id="S6.SS0.SSS0.Px1.p3" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Random Sample</span>: uniform random subset.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">High Instruction</span>: uniform sample of instances with all three instruction criteria intact.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">High Instruction + Seq</span>: uniform sample of instances with all six criteria intact.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p"><span id="S6.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Low ICE</span>: instances with the lowest ICE scores.</p>
</div>
</li>
<li id="S6.I1.i5" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i5.p1" class="ltx_para">
<p id="S6.I1.i5.p1.1" class="ltx_p"><span id="S6.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">High ICE</span>: instances with the highest ICE scores.
</p>
</div>
</li>
<li id="S6.I1.i6" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i6.p1" class="ltx_para">
<p id="S6.I1.i6.p1.1" class="ltx_p"><span id="S6.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">High Instruction + Seq + ICE</span>: instances with all six criteria intact and high ICE scores.</p>
</div>
</li>
<li id="S6.I1.i7" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i7.p1" class="ltx_para">
<p id="S6.I1.i7.p1.1" class="ltx_p"><span id="S6.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">Original</span>: the full original training set.</p>
</div>
</li>
</ul>
</div>
<div id="S6.SS0.SSS0.Px1.p4" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p4.1" class="ltx_p">Each fine-tuned model is evaluated using <span id="S6.SS0.SSS0.Px1.p4.1.1" class="ltx_text ltx_font_bold">pass rate</span>, which is an extrinsic evaluation procedure used in both benchmarks.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>In ToolAlpaca this metric is referred to as “overall accuracy”, although it conveys the same concept.</span></span></span> This measures the proportion of instances in which the resulting API-call sequences and responses adequately address their respective instruction query. See Appendix <a href="#A3.SS2" title="C.2 Evaluation Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.2</span></a> for more details on the evaluation procedure.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Test sets.</h5>

<div id="S6.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p1.1" class="ltx_p">For ToolAlpaca we use the original test set, as it is created with human annotation. It consists of 100 instructions of simulated tools that were not part of the training tool set. ToolBench test set was created using LLMs and was not manually validated. We inspected 674 examples, as detailed in Appendix <a href="#A1.SS4" title="A.4 Manual Annotation Process ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.4</span></a>. For instances of low quality, we either rectified them (e.g., manually adding a missing parameter value), or discarded them. The resulting test set contains 420 high-quality examples.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>This test set is available in the supplementary material.</span></span></span></p>
</div>
</section>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Main Results</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Results are presented in <a href="#S6.T6" title="Table 6 ‣ 6 Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 6</span></a>, where the training sub-sets are fixed to size 10K for ToolBench and 2K for ToolAlpaca. The results demonstrate the impact of training data quality on model performance.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">When comparing to a model fine-tuned on a random subset of the original training data (row <span id="S6.SS1.p2.1.1" class="ltx_text" style="color:#808080;">1</span>), all methods of filtering low-quality instances (rows <span id="S6.SS1.p2.1.2" class="ltx_text" style="color:#808080;">3</span>-<span id="S6.SS1.p2.1.3" class="ltx_text" style="color:#808080;">6</span>) are clearly beneficial.
Moreover, when fine-tuning models with <span id="S6.SS1.p2.1.4" class="ltx_text ltx_font_italic">much smaller</span> high-quality sub-sets (rows <span id="S6.SS1.p2.1.5" class="ltx_text" style="color:#808080;">3</span>-<span id="S6.SS1.p2.1.6" class="ltx_text" style="color:#808080;">6</span>), performance is comparable or superior to models fine-tuned on the <span id="S6.SS1.p2.1.7" class="ltx_text ltx_font_italic">full</span> original training sets (row <span id="S6.SS1.p2.1.8" class="ltx_text" style="color:#808080;">7</span>). Consistent with the findings on the ToolBench dataset’s lower overall quality (§<a href="#S4" title="4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and §<a href="#S5" title="5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), results indicate improved model performance with a high-quality subset, comprising only <math id="S6.SS1.p2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S6.SS1.p2.1.m1.1a"><mo id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><csymbol cd="latexml" id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">\sim</annotation></semantics></math>14% of the original dataset’s size (row <span id="S6.SS1.p2.1.9" class="ltx_text" style="color:#808080;">6</span>).</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">Comparing the intrinsic metrics to the ICE method, we find that the former is a better mechanism for filtering training data (row <span id="S6.SS1.p3.1.1" class="ltx_text" style="color:#808080;">3</span> vs. <span id="S6.SS1.p3.1.2" class="ltx_text" style="color:#808080;">5</span>). Using both techniques together can be marginally better (row <span id="S6.SS1.p3.1.3" class="ltx_text" style="color:#808080;">5</span> vs. <span id="S6.SS1.p3.1.4" class="ltx_text" style="color:#808080;">6</span>). Another insight to consider is that taking data with low ICE scores (row <span id="S6.SS1.p3.1.5" class="ltx_text" style="color:#808080;">2</span>) is indeed harmful to model performance, further reinforcing that the method is valuable despite its partial agreement with intrinsic human-defined criteria (§<a href="#S5" title="5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.1" class="ltx_p">In ToolAlpaca, the gaps are less pronounced than in ToolBench, likely influenced by: (1) the higher quality of the original dataset, (2) smaller original training set, causing the filtered datasets to be too small, (3) smaller test set, only 100 instances. Nonetheless, the trend still exists (albeit being within the confidence intervals). This, combined with the intrinsic assessment of Table <a href="#S4.T5" title="Table 5 ‣ Solvability, Sufficiency &amp; Minimality. ‣ 4.3 Automated Metrics ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, provides encouraging evidence for the effectiveness of our methods, even for this smaller-scale dataset.</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2409.16341/assets/figures/varying_sizes_skip.png" id="S6.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="431" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Pass rate results in ToolBench when using train sets with different sizes and filtration methods.</figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Data Scaling Analysis</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">To further explore the effects of training tool-using LLMs with high-quality data, we analyze the performance of models when fine-tuning with <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_italic">different sizes</span> of train sets. We focus here on ToolBench, where the impact is more significant and the original training set is larger, and use subsets with sizes ranging from 1K to 20K for the different filtration methods. Results can be found in <a href="#S6.F4" title="Figure 4 ‣ 6.1 Main Results ‣ 6 Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 4</span></a>. As size increases, we observe consistently better performance, with an expected plateau in the largest dataset sizes. Notice that at some point the training datasets have no more high-quality data instances that pass our filters, putting a natural limit on our experiments.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We demonstrated the importance of evaluating the quality of training data for fine-tuning tool-using LLMs.
We introduce two data-evaluation approaches. The first is a rigorously devised intrinsic quality assessment, for which we implement automated metrics. The second uses in-context evaluation, that measures the educational value of training examples.
While the former method is more explainable and dependable, the latter is computationally cheaper. We apply both approaches to filter data instances from two large datasets of differing qualities. The resulting subsets of training data demonstrate comparable or superior quality in terms of model performance, despite their smaller size compared to the original datasets.
Overall, we observe that it is worthwhile to more carefully choose the training data for tool-using LLMs. If investing in better methods of data generation is costly, automatic post-hoc filtration can be a great alternative. </p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">In this work, we address the quality of data instances, and refrain from overall dataset-level quality criteria, primarily diversity of data. Our focus is on instance-level quality, and we show the advantage of training LLMs with data that is identified as high-quality with instance-level criteria only. Future work can explore the benefits of dataset-level quality criteria as well.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">Our experiments span over two popular benchmarks for tool-using LLMs. They are differing in characteristics and quality, and can therefore provide insights that are not benchmark-specific. Nevertheless, conducting our analyses on additional related datasets and LLMs would provide an even more generalized representation of our results.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Celikyilmaz et al. (2021)</span>
<span class="ltx_bibblock">
Asli Celikyilmaz, Elizabeth Clark, and Jianfeng Gao. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2006.14799" title="" class="ltx_ref ltx_href">Evaluation of Text Generation: A Survey</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2306.15595" title="" class="ltx_ref ltx_href">Extending Context Window of Large Language Models via Positional Interpolation</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Zehui Chen, Weihua Du, Wenwei Zhang, Kuikun Liu, Jiangning Liu, Miao Zheng, Jingming Zhuo, Songyang Zhang, Dahua Lin, Kai Chen, and Feng Zhao. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2312.14033" title="" class="ltx_ref ltx_href">T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2024)</span>
<span class="ltx_bibblock">
Jeffrey Cheng, Marc Marone, Orion Weller, Dawn Lawrie, Daniel Khashabi, and Benjamin Van Durme. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2403.12958" title="" class="ltx_ref ltx_href">Dated Data: Tracing Knowledge Cutoffs in Large Language Models</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al.

</span>
<span class="ltx_bibblock">Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://lmsys.org/blog/2023-03-30-vicuna/</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-04-01.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. (2023)</span>
<span class="ltx_bibblock">
Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Shuming Ma, Zhifang Sui, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.247" title="" class="ltx_ref ltx_href">Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 4005–4019, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al. (2019)</span>
<span class="ltx_bibblock">
Zhiqiang Gong, Ping Zhong, and Weidong Hu. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ACCESS.2019.2917620" title="" class="ltx_ref ltx_href">Diversity in Machine Learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 7:64323–64350.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunasekar et al. (2023)</span>
<span class="ltx_bibblock">
Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, and Yuanzhi Li. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2306.11644" title="" class="ltx_ref ltx_href">Textbooks Are All You Need</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="" class="ltx_ref ltx_href">LoRA: Low-Rank Adaptation of Large Language Models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2024)</span>
<span class="ltx_bibblock">
Yue Huang, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Qihui Zhang, Yixin Liu, Pan Zhou, Yao Wan, Neil Zhenqiang Gong, and Lichao Sun. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=R0c2qtalgG" title="" class="ltx_ref ltx_href">MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kasai et al. (2023)</span>
<span class="ltx_bibblock">
Jungo Kasai, Keisuke Sakaguchi, yoichi takahashi, Ronan Le Bras, Akari Asai, Xinyan Velocity Yu, Dragomir Radev, Noah A. Smith, Yejin Choi, and Kentaro Inui. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=HfKOIPCvsv" title="" class="ltx_ref ltx_href">RealTime QA: What’s the Answer Right Now?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levenshtein et al. (1966)</span>
<span class="ltx_bibblock">
Vladimir I Levenshtein et al. 1966.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf" title="" class="ltx_ref ltx_href">Binary Codes Capable of Correcting Deletions, Insertions and Reversals</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Soviet Physics Doklady</em>, volume 10, pages 707–710. Soviet Union.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.187" title="" class="ltx_ref ltx_href">API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 3102–3116, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Omer Levy, Luke Zettlemoyer, Jason E Weston, and Mike Lewis. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=1oijHJBRsT" title="" class="ltx_ref ltx_href">Self-Alignment with Instruction Backtranslation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, and Yin Tat Lee. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2309.05463" title="" class="ltx_ref ltx_href">Textbooks Are All You Need II: phi-1.5 technical report</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2303.08774" title="" class="ltx_ref ltx_href">GPT-4 Technical Report</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patil et al. (2023)</span>
<span class="ltx_bibblock">
Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2305.15334" title="" class="ltx_ref ltx_href">Gorilla: Large Language Model Connected with Massive APIs</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et al. (2024)</span>
<span class="ltx_bibblock">
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, and Maosong Sun. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=dHng2O0Jjr" title="" class="ltx_ref ltx_href">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick et al. (2023)</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/d842425e4bf79ba039352da0f658a906-Paper-Conference.pdf" title="" class="ltx_ref ltx_href">Toolformer: Language Models Can Teach Themselves to Use Tools</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 36, pages 68539–68551. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2023)</span>
<span class="ltx_bibblock">
Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, Boxi Cao, and Le Sun. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2306.05301" title="" class="ltx_ref ltx_href">ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2302.13971" title="" class="ltx_ref ltx_href">LLaMA: Open and Efficient Foundation Language Models</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Von Oswald et al. (2023)</span>
<span class="ltx_bibblock">
Johannes Von Oswald, Eyvind Niklasson, Ettore Randazzo, Joao Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v202/von-oswald23a.html" title="" class="ltx_ref ltx_href">Transformers Learn In-Context by Gradient Descent</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th International Conference on Machine Learning</em>, volume 202 of <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 35151–35174. PMLR.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023)</span>
<span class="ltx_bibblock">
Hui Yang, Sifu Yue, and Yunzhong He. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2306.02224" title="" class="ltx_ref ltx_href">Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2023)</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan Cao. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=WE_vluYUL-X" title="" class="ltx_ref ltx_href">ReAct: Synergizing Reasoning and Acting in Language Models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023)</span>
<span class="ltx_bibblock">
Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander J Ratner, Ranjay Krishna, Jiaming Shen, and Chao Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/ae9500c4f5607caf2eff033c67daa9d7-Paper-Datasets_and_Benchmarks.pdf" title="" class="ltx_ref ltx_href">Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 36, pages 55734–55784. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, LILI YU, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/ac662d74829e4407ce1d126477f4a03a-Paper-Conference.pdf" title="" class="ltx_ref ltx_href">LIMA: Less Is More for Alignment</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 36, pages 55006–55021. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang et al. (2023)</span>
<span class="ltx_bibblock">
Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and Chao Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/9cb2a7495900f8b602cb10159246a016-Paper-Datasets_and_Benchmarks.pdf" title="" class="ltx_ref ltx_href">ToolQA: A Dataset for LLM Question Answering with External Tools</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 36, pages 50117–50143. Curran Associates, Inc.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Intrinsic Evaluation</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Other Quality Criteria</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">We outline here three quality criteria that are commonly addressed in the domain of data quality evaluation, and that we did not include in this work. (1) <span id="A1.SS1.p1.1.1" class="ltx_text ltx_font_bold">Fluency</span> is the lexical quality of the text in terms of grammar, spelling, and
style <cite class="ltx_cite ltx_citemacro_cite">Celikyilmaz et al. (<a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite>. The reason for omitting this dimension is that the lexical quality of texts generated by powerful LLMs is very high. We found that virtually all instances in an assessment set had highly fluent texts.
(2) <span id="A1.SS1.p1.1.2" class="ltx_text ltx_font_bold">Syntax Validity</span> is whether the function calls and parameter names (not values) in the API-call sequence are valid. Using both manual validation and automatic rule-based lexical matching we found that data generated with ChatGPT did not exhibit such errors.
(3) <span id="A1.SS1.p1.1.3" class="ltx_text ltx_font_bold">Diversity</span> captures how different the data instances are amongst themselves in terms of assortment of requests, tool usage, difficulty, length and other properties. Similarly to other tasks and domains, it is expected that an LLM would learn to generalize better given diverse examples <cite class="ltx_cite ltx_citemacro_cite">Gong et al. (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>); Yu et al. (<a href="#bib.bib25" title="" class="ltx_ref">2023</a>)</cite>. We focus on instance-level criteria, and leave dataset-level criteria, such as diversity, for future work.</p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Prompts for Assessment</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">In Figures <a href="#A3.F6" title="Figure 6 ‣ ToolAlpaca. ‣ C.2 Evaluation Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>–<a href="#A3.F10" title="Figure 10 ‣ ToolAlpaca. ‣ C.2 Evaluation Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> we provide the prompts we use for automatically assessing the six human-defined quality criteria, using ChatGPT.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Unsuccessful Prompts</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p">Direct questioning and annotation instruction with ChatGPT did not work well for the criteria of <span id="A1.SS3.p1.1.1" class="ltx_text ltx_font_italic">Specificity</span>, <span id="A1.SS3.p1.1.2" class="ltx_text ltx_font_italic">Coherence</span> and <span id="A1.SS3.p1.1.3" class="ltx_text ltx_font_italic">Parameter Alignment</span>. In Figures <a href="#A3.F11" title="Figure 11 ‣ ToolAlpaca. ‣ C.2 Evaluation Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>–<a href="#A3.F13" title="Figure 13 ‣ ToolAlpaca. ‣ C.2 Evaluation Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> we provide the prompts. In <a href="#A1.T7" title="Table 7 ‣ A.3 Unsuccessful Prompts ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 7</span></a> we provide validation results of alignment with human annotation on the same subset of examples of the ToolBench dataset.</p>
</div>
<figure id="A1.T7" class="ltx_table">
<table id="A1.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T7.1.1.1" class="ltx_tr">
<th id="A1.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><span id="A1.T7.1.1.1.1.1" class="ltx_text ltx_font_bold">Criterion</span></th>
<th id="A1.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><span id="A1.T7.1.1.1.2.1" class="ltx_text ltx_font_bold">Acc.</span></th>
<th id="A1.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><span id="A1.T7.1.1.1.3.1" class="ltx_text ltx_font_bold">Precision</span></th>
<th id="A1.T7.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><span id="A1.T7.1.1.1.4.1" class="ltx_text ltx_font_bold">Recall</span></th>
<th id="A1.T7.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><span id="A1.T7.1.1.1.5.1" class="ltx_text ltx_font_bold">F1</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T7.1.2.1" class="ltx_tr">
<td id="A1.T7.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">Specificity</td>
<td id="A1.T7.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.54</td>
<td id="A1.T7.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.56</td>
<td id="A1.T7.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.36</td>
<td id="A1.T7.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.43</td>
</tr>
<tr id="A1.T7.1.3.2" class="ltx_tr">
<td id="A1.T7.1.3.2.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">Coherence</td>
<td id="A1.T7.1.3.2.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.74</td>
<td id="A1.T7.1.3.2.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.50</td>
<td id="A1.T7.1.3.2.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.46</td>
<td id="A1.T7.1.3.2.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.48</td>
</tr>
<tr id="A1.T7.1.4.3" class="ltx_tr">
<td id="A1.T7.1.4.3.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">Alignment</td>
<td id="A1.T7.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">0.66</td>
<td id="A1.T7.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">0.69</td>
<td id="A1.T7.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">0.71</td>
<td id="A1.T7.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">0.70</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Validation results when using the direct questioning approach for <span id="A1.T7.5.1" class="ltx_text ltx_font_italic">Specificity</span>, <span id="A1.T7.6.2" class="ltx_text ltx_font_italic">Coherence</span> and <span id="A1.T7.7.3" class="ltx_text ltx_font_italic">Parameter Alignment</span>. Compare to <a href="#S4.T4" title="Table 4 ‣ 4.2 Manual Annotations ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 4</span></a>, which shows higher scores for the prompts ultimately used.</figcaption>
</figure>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Manual Annotation Process</h3>

<section id="A1.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.1 </span>Annotating Training Data</h4>

<div id="A1.SS4.SSS1.p1" class="ltx_para">
<p id="A1.SS4.SSS1.p1.1" class="ltx_p">To initiate the annotation process, we examined the data and identified the quality criteria (as outlined in §<a href="#S4.SS1" title="4.1 Quality Criteria ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>). We then went through several cycles of examination and refinement of respective guidelines.</p>
</div>
<div id="A1.SS4.SSS1.p2" class="ltx_para">
<p id="A1.SS4.SSS1.p2.1" class="ltx_p">An instance of annotation shows the instruction, the available API functions, and the API-call sequence that should solve the instruction. The annotator needs to mark level of specificity of the instruction (1 to 3), its coherence (1 to 3), whether it is solvable with respect to the available API functions (yes/no), the sequence call validity in terms of function availability (yes/no), parameter alignment in the calls (yes/no), whether the sequence call solves the instruction (yes/no), and whether it does so minimally (yes/no). See Tables <a href="#A1.T8" title="Table 8 ‣ A.4.2 Annotating the ToolBench Test Set ‣ A.4 Manual Annotation Process ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, <a href="#A1.T9" title="Table 9 ‣ A.4.2 Annotating the ToolBench Test Set ‣ A.4 Manual Annotation Process ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> and <a href="#A1.T10" title="Table 10 ‣ A.4.2 Annotating the ToolBench Test Set ‣ A.4 Manual Annotation Process ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> for annotation instructions of the first three criteria.</p>
</div>
<div id="A1.SS4.SSS1.p3" class="ltx_para">
<p id="A1.SS4.SSS1.p3.1" class="ltx_p">The annotators (authors of this paper) first annotated the same 20 instances from ToolBench and discussed differences, culminating in strong agreement between the annotators.
The averaged Kappa statistics for the first three criteria are: Specificity 0.674 (“substantial”), Coherence 0.508 (“moderate”), and Solvability 0.414 (“moderate”).
Annotators were then assigned different samples of data, for a total of 50 instances from the ToolBench train set, and 50 from the ToolAlpaca train set. We used this data to assess the intrinsic metrics that we developed (§<a href="#S4.SS3" title="4.3 Automated Metrics ‣ 4 Intrinsic Quality Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</p>
</div>
</section>
<section id="A1.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.4.2 </span>Annotating the ToolBench Test Set</h4>

<div id="A1.SS4.SSS2.p1" class="ltx_para">
<p id="A1.SS4.SSS2.p1.1" class="ltx_p">In comparison to annotation of training instances, the test set annotation differs in two major aspects. First, the test set does not include API-call sequences, but rather only the input instructions. A training instance consists of an API-call sequence in order to teach an LLM how to devise a solution for attaining a final result. However during test time, tool-assisted LLMs are typically evaluated on the final result, and not on the API-call sequence used to achieve the result.
Second, in our cleaned test set, we do not only mark inadequate instances, but we also attempt to fix instructions so that they become usable. The ToolBench test set contains 1100 instances (distinct from the 125K instances), and only filtering out faulty instances would leave very few suitable ones. Essentially, we use the ToolBench test set as data to build upon instead of creating new data altogether, which would be a much costlier procedure. The ultimate goal is to produce a high-quality test set of solvable multi-request instructions.</p>
</div>
<div id="A1.SS4.SSS2.p2" class="ltx_para">
<p id="A1.SS4.SSS2.p2.1" class="ltx_p">An instruction can fail on either specificity, coherence or solvability. Therefore, to repair an instruction we focused on the failing criteria and rewrote the instruction to mend the faults. We allowed for some creativity as long as the quality criteria were intact, and the same number of requests was kept within the instruction.</p>
</div>
<div id="A1.SS4.SSS2.p3" class="ltx_para">
<p id="A1.SS4.SSS2.p3.1" class="ltx_p">For example,
<span id="A1.SS4.SSS2.p3.1.1" class="ltx_text ltx_font_italic">“I’m planning a family movie night and I want to watch some classic films. Can you suggest some iconic movies available on YouTube? Also, find a YouTube playlist of movie soundtracks. Additionally, provide the latest versions of C++, Objective-C, and Scala programming languages for my cousin who is a software developer.”</span> Here, the first request (“suggest iconic movies”) and the second request (“find a YouTube playlist”) are not specific enough for the available API functions, and the third request (“provide the latest versions of C++…”) is not coherent with the beginning of the instruction. We therefore rewrote the instruction for this instance as <span id="A1.SS4.SSS2.p3.1.2" class="ltx_text ltx_font_italic">“I’m learning how to program and I’d like some assistance. Can you suggest some videos on YouTube about C++? Also, download the video to MP3 from ‘www.youtube.com/?123abc’. Additionally, please let me know the the latest versions of C++, Objective-C, and Scala programming languages.”</span> The new instruction resolves the three issues described. In a case where it is unclear how to use the respective available API functions, no fix is made and the instance is simply discarded.</p>
</div>
<div id="A1.SS4.SSS2.p4" class="ltx_para">
<p id="A1.SS4.SSS2.p4.4" class="ltx_p">Five annotators annotated 674 of the 1100 instances in the ToolBench test set. <math id="A1.SS4.SSS2.p4.1.m1.1" class="ltx_Math" alttext="27.6\%" display="inline"><semantics id="A1.SS4.SSS2.p4.1.m1.1a"><mrow id="A1.SS4.SSS2.p4.1.m1.1.1" xref="A1.SS4.SSS2.p4.1.m1.1.1.cmml"><mn id="A1.SS4.SSS2.p4.1.m1.1.1.2" xref="A1.SS4.SSS2.p4.1.m1.1.1.2.cmml">27.6</mn><mo id="A1.SS4.SSS2.p4.1.m1.1.1.1" xref="A1.SS4.SSS2.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.SSS2.p4.1.m1.1b"><apply id="A1.SS4.SSS2.p4.1.m1.1.1.cmml" xref="A1.SS4.SSS2.p4.1.m1.1.1"><csymbol cd="latexml" id="A1.SS4.SSS2.p4.1.m1.1.1.1.cmml" xref="A1.SS4.SSS2.p4.1.m1.1.1.1">percent</csymbol><cn type="float" id="A1.SS4.SSS2.p4.1.m1.1.1.2.cmml" xref="A1.SS4.SSS2.p4.1.m1.1.1.2">27.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.SSS2.p4.1.m1.1c">27.6\%</annotation></semantics></math> of the instances lacked specificity, <math id="A1.SS4.SSS2.p4.2.m2.1" class="ltx_Math" alttext="21.5\%" display="inline"><semantics id="A1.SS4.SSS2.p4.2.m2.1a"><mrow id="A1.SS4.SSS2.p4.2.m2.1.1" xref="A1.SS4.SSS2.p4.2.m2.1.1.cmml"><mn id="A1.SS4.SSS2.p4.2.m2.1.1.2" xref="A1.SS4.SSS2.p4.2.m2.1.1.2.cmml">21.5</mn><mo id="A1.SS4.SSS2.p4.2.m2.1.1.1" xref="A1.SS4.SSS2.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.SSS2.p4.2.m2.1b"><apply id="A1.SS4.SSS2.p4.2.m2.1.1.cmml" xref="A1.SS4.SSS2.p4.2.m2.1.1"><csymbol cd="latexml" id="A1.SS4.SSS2.p4.2.m2.1.1.1.cmml" xref="A1.SS4.SSS2.p4.2.m2.1.1.1">percent</csymbol><cn type="float" id="A1.SS4.SSS2.p4.2.m2.1.1.2.cmml" xref="A1.SS4.SSS2.p4.2.m2.1.1.2">21.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.SSS2.p4.2.m2.1c">21.5\%</annotation></semantics></math> lacked coherence, and <math id="A1.SS4.SSS2.p4.3.m3.1" class="ltx_Math" alttext="32.7\%" display="inline"><semantics id="A1.SS4.SSS2.p4.3.m3.1a"><mrow id="A1.SS4.SSS2.p4.3.m3.1.1" xref="A1.SS4.SSS2.p4.3.m3.1.1.cmml"><mn id="A1.SS4.SSS2.p4.3.m3.1.1.2" xref="A1.SS4.SSS2.p4.3.m3.1.1.2.cmml">32.7</mn><mo id="A1.SS4.SSS2.p4.3.m3.1.1.1" xref="A1.SS4.SSS2.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.SSS2.p4.3.m3.1b"><apply id="A1.SS4.SSS2.p4.3.m3.1.1.cmml" xref="A1.SS4.SSS2.p4.3.m3.1.1"><csymbol cd="latexml" id="A1.SS4.SSS2.p4.3.m3.1.1.1.cmml" xref="A1.SS4.SSS2.p4.3.m3.1.1.1">percent</csymbol><cn type="float" id="A1.SS4.SSS2.p4.3.m3.1.1.2.cmml" xref="A1.SS4.SSS2.p4.3.m3.1.1.2">32.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.SSS2.p4.3.m3.1c">32.7\%</annotation></semantics></math> were unsolvable. Overall, <math id="A1.SS4.SSS2.p4.4.m4.1" class="ltx_Math" alttext="37.7\%" display="inline"><semantics id="A1.SS4.SSS2.p4.4.m4.1a"><mrow id="A1.SS4.SSS2.p4.4.m4.1.1" xref="A1.SS4.SSS2.p4.4.m4.1.1.cmml"><mn id="A1.SS4.SSS2.p4.4.m4.1.1.2" xref="A1.SS4.SSS2.p4.4.m4.1.1.2.cmml">37.7</mn><mo id="A1.SS4.SSS2.p4.4.m4.1.1.1" xref="A1.SS4.SSS2.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS4.SSS2.p4.4.m4.1b"><apply id="A1.SS4.SSS2.p4.4.m4.1.1.cmml" xref="A1.SS4.SSS2.p4.4.m4.1.1"><csymbol cd="latexml" id="A1.SS4.SSS2.p4.4.m4.1.1.1.cmml" xref="A1.SS4.SSS2.p4.4.m4.1.1.1">percent</csymbol><cn type="float" id="A1.SS4.SSS2.p4.4.m4.1.1.2.cmml" xref="A1.SS4.SSS2.p4.4.m4.1.1.2">37.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.SSS2.p4.4.m4.1c">37.7\%</annotation></semantics></math> of the instances were discarded, in cases where errors were too severe to be readily fixable.
The new test set is used for measuring the performance of tool-using models in the multi-request setting (§<a href="#S6" title="6 Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>), and can generally be used as a high-quality benchmark. We provide the new test set in the supplementary material.</p>
</div>
<figure id="A1.T8" class="ltx_table">
<table id="A1.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T8.1.1.1" class="ltx_tr">
<td id="A1.T8.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T8.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T8.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Specificity</span></span>
</span>
</td>
</tr>
<tr id="A1.T8.1.2.2" class="ltx_tr">
<td id="A1.T8.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T8.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.1.2.2.1.1.1" class="ltx_p" style="width:411.9pt;">Evaluate the extent to which the data examples contain all necessary information without gaps or missing variables for the AI assistant to address the user requests.</span>
</span>
</td>
</tr>
<tr id="A1.T8.1.3.3" class="ltx_tr">
<td id="A1.T8.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T8.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.1.3.3.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T8.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">1 (Poor):</span> The instruction is extremely broad and general, lacking essential information.</span>
</span>
</td>
</tr>
<tr id="A1.T8.1.4.4" class="ltx_tr">
<td id="A1.T8.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T8.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.1.4.4.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T8.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">2 (Medium):</span> The instruction includes moderate specific details but there are some gaps in information.</span>
</span>
</td>
</tr>
<tr id="A1.T8.1.5.5" class="ltx_tr">
<td id="A1.T8.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T8.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T8.1.5.5.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T8.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">3 (Excellent):</span> The instruction is highly specific and complete, with no significant missing information.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Human annotation guidelines for Specificity.</figcaption>
</figure>
<figure id="A1.T9" class="ltx_table">
<table id="A1.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T9.1.1.1" class="ltx_tr">
<td id="A1.T9.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T9.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T9.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Coherence</span></span>
</span>
</td>
</tr>
<tr id="A1.T9.1.2.2" class="ltx_tr">
<td id="A1.T9.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T9.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.1.2.2.1.1.1" class="ltx_p" style="width:411.9pt;">Evaluate the extent to which the different requests in the instruction are logically connected and relevant to each other.</span>
</span>
</td>
</tr>
<tr id="A1.T9.1.3.3" class="ltx_tr">
<td id="A1.T9.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T9.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.1.3.3.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T9.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">1 (Poor):</span> The different requests of the instruction are highly disjointed, lacking a logical connection.</span>
</span>
</td>
</tr>
<tr id="A1.T9.1.4.4" class="ltx_tr">
<td id="A1.T9.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T9.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.1.4.4.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T9.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">2 (Medium):</span> The different requests of the instruction have a moderate level of coherence but still possess some degree of separation.</span>
</span>
</td>
</tr>
<tr id="A1.T9.1.5.5" class="ltx_tr">
<td id="A1.T9.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T9.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.1.5.5.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T9.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">3 (Excellent):</span> The components of the instruction are highly coherent, with a strong logical connection.</span>
</span>
</td>
</tr>
<tr id="A1.T9.1.6.6" class="ltx_tr">
<td id="A1.T9.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T9.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T9.1.6.6.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T9.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">Not Applicable:</span> When there is only one request. (Considered as ‘3’ for filtering.)</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Human annotation guidelines for Coherence.</figcaption>
</figure>
<figure id="A1.T10" class="ltx_table">
<table id="A1.T10.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T10.1.1.1" class="ltx_tr">
<td id="A1.T10.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T10.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T10.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Solvability</span></span>
</span>
</td>
</tr>
<tr id="A1.T10.1.2.2" class="ltx_tr">
<td id="A1.T10.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T10.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.1.2.2.1.1.1" class="ltx_p" style="width:411.9pt;">Determine if the ground truth APIs can handle the instruction in terms of functionality. It is alright if a parameter value is not explicitly provided in the query.</span>
</span>
</td>
</tr>
<tr id="A1.T10.1.3.3" class="ltx_tr">
<td id="A1.T10.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T10.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.1.3.3.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T10.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">0 (No):</span> The request cannot be handled by the given APIs. The APIs’ functionalities do not fit or address the request.</span>
</span>
</td>
</tr>
<tr id="A1.T10.1.4.4" class="ltx_tr">
<td id="A1.T10.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T10.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T10.1.4.4.1.1.1" class="ltx_p" style="width:411.9pt;"><span id="A1.T10.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">1 (Yes):</span> The instruction can be handled by using the given APIs. A parameter value might not be explicitly provided in the query.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Human annotation guidelines for Solvability.</figcaption>
</figure>
</section>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Qualitative Examples</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p id="A1.SS5.p1.1" class="ltx_p">In Tables <a href="#A1.T11" title="Table 11 ‣ A.5 Qualitative Examples ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> and <a href="#A1.T12" title="Table 12 ‣ A.5 Qualitative Examples ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> we provide examples of instructions which our method found as lacking specificity and coherence, from both ToolBench and ToolAlpaca datasets.</p>
</div>
<figure id="A1.T11" class="ltx_table">
<table id="A1.T11.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T11.1.1.1" class="ltx_tr">
<th id="A1.T11.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="2"><span id="A1.T11.1.1.1.1.1" class="ltx_text ltx_font_bold">Instruction Examples</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T11.1.2.1" class="ltx_tr">
<th id="A1.T11.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="5"><span id="A1.T11.1.2.1.1.1" class="ltx_text">
<span id="A1.T11.1.2.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:72.5pt;vertical-align:-32.8pt;"><span class="ltx_transformed_inner" style="width:72.5pt;transform:translate(-32.79pt,0pt) rotate(-90deg) ;">
<span id="A1.T11.1.2.1.1.1.1.1" class="ltx_p"><span id="A1.T11.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">From ToolBench</span></span>
</span></span></span></th>
<td id="A1.T11.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.2.1.2.1.1" class="ltx_p" style="width:390.3pt;">I’m planning to buy a used car and I need to decode the VIN number of a specific vehicle. Can you provide me with the car model, maker, year, engine, and other relevant information? Additionally, I’m curious about the trending search results on Google.</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.3.2" class="ltx_tr">
<td id="A1.T11.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.3.2.1.1.1" class="ltx_p" style="width:390.3pt;">I’m a wedding planner and I want to create personalized videos for my clients. Can you give me the details of a specific template I have in mind, including the variables it offers? Also, I need to access all my campaigns’ information, including the images, videos, and image+video campaigns.</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.4.3" class="ltx_tr">
<td id="A1.T11.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.4.3.1.1.1" class="ltx_p" style="width:390.3pt;">I’m hosting a garden party next weekend. Can you give me the 1-hour/minutely forecast for the party location? Additionally, recommend some outdoor games and decorations for the event.</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.5.4" class="ltx_tr">
<td id="A1.T11.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.5.4.1.1.1" class="ltx_p" style="width:390.3pt;">I recently discovered a new song that I really love. Can you provide me with the lyrics and related data for the song? Also, suggest some similar songs that I might enjoy.</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.6.5" class="ltx_tr">
<td id="A1.T11.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.6.5.1.1.1" class="ltx_p" style="width:390.3pt;">I’m planning a trip to Europe and I want to stay updated on the energy prices in the region. Can you fetch all the available articles from a specific region, like Europe? Additionally, provide me with a list of news sources and their corresponding regions.</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.7.6" class="ltx_tr">
<th id="A1.T11.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="5"><span id="A1.T11.1.7.6.1.1" class="ltx_text">
<span id="A1.T11.1.7.6.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:76pt;vertical-align:-35.5pt;"><span class="ltx_transformed_inner" style="width:76.0pt;transform:translate(-33.56pt,2.92pt) rotate(-90deg) ;">
<span id="A1.T11.1.7.6.1.1.1.1" class="ltx_p"><span id="A1.T11.1.7.6.1.1.1.1.1" class="ltx_text ltx_font_bold">From ToolAlpaca</span></span>
</span></span></span></th>
<td id="A1.T11.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.7.6.2.1.1" class="ltx_p" style="width:390.3pt;">Please generate an invoice for my freelance work and send it to my client.</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.8.7" class="ltx_tr">
<td id="A1.T11.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.8.7.1.1.1" class="ltx_p" style="width:390.3pt;">How can I find the best gear for my character in Guild Wars 2?</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.9.8" class="ltx_tr">
<td id="A1.T11.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.9.8.1.1.1" class="ltx_p" style="width:390.3pt;">Hey, I’m planning a road trip and I want to check for any road closures along my route. Can you help me with that?</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.10.9" class="ltx_tr">
<td id="A1.T11.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.10.9.1.1.1" class="ltx_p" style="width:390.3pt;">I need to retrieve detailed information about a specific malware sample. Can you show me how to do that?</span>
</span>
</td>
</tr>
<tr id="A1.T11.1.11.10" class="ltx_tr">
<td id="A1.T11.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="A1.T11.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T11.1.11.10.1.1.1" class="ltx_p" style="width:390.3pt;">I want to know if any of the email addresses in a list are disposable. Can you use the API to check which email addresses in the list are disposable?</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Examples of instructions which our method found as lacking <span id="A1.T11.3.1" class="ltx_text ltx_font_bold">specificity</span>, from the two examined datasets.</figcaption>
</figure>
<figure id="A1.T12" class="ltx_table">
<table id="A1.T12.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T12.1.1.1" class="ltx_tr">
<th id="A1.T12.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" colspan="2"><span id="A1.T12.1.1.1.1.1" class="ltx_text ltx_font_bold">Instruction Examples</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T12.1.2.1" class="ltx_tr">
<th id="A1.T12.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="5"><span id="A1.T12.1.2.1.1.1" class="ltx_text">
<span id="A1.T12.1.2.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:72.5pt;vertical-align:-32.8pt;"><span class="ltx_transformed_inner" style="width:72.5pt;transform:translate(-32.79pt,0pt) rotate(-90deg) ;">
<span id="A1.T12.1.2.1.1.1.1.1" class="ltx_p"><span id="A1.T12.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">From ToolBench</span></span>
</span></span></span></th>
<td id="A1.T12.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.2.1.2.1.1" class="ltx_p" style="width:390.3pt;">I’m planning a surprise birthday party for my best friend and I need some help. Can you find the email of a person named Emma Watson at google.com? Additionally, I want to find a formulated product by its registration number to use as a gift for my friend.</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.3.2" class="ltx_tr">
<td id="A1.T12.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.3.2.1.1.1" class="ltx_p" style="width:390.3pt;">My family and I are considering relocating to New York City. Can you provide us with a list of transactions for zipcode 10019? We would like to see the last sales date, last sales amount, and total records for each transaction. Additionally, could you give us the detailed historical transactions for the address 310 W 56th St, New York, NY 10019?</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.4.3" class="ltx_tr">
<td id="A1.T12.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.4.3.1.1.1" class="ltx_p" style="width:390.3pt;">I want to explore movies related to a specific genre. Can you discover movies in the genre with genreId ’80’ and provide me with the details of the first 10 results? Also, fetch the crew details for a random movie.</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.5.4" class="ltx_tr">
<td id="A1.T12.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.5.4.1.1.1" class="ltx_p" style="width:390.3pt;">I’m a basketball enthusiast and I want to know more about the players in the NBA. Can you fetch me the details of all the players? Additionally, provide me with a random Chuck Norris joke to lighten the mood.</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.6.5" class="ltx_tr">
<td id="A1.T12.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.6.5.1.1.1" class="ltx_p" style="width:390.3pt;">My friends and I are planning a trip to multiple cities and we need to estimate the cost of living. Can you provide us with a list of available currencies? Additionally, we would like to get a comprehensive list of cities, including their countries, to help us plan our itinerary.</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.7.6" class="ltx_tr">
<th id="A1.T12.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="6"><span id="A1.T12.1.7.6.1.1" class="ltx_text">
<span id="A1.T12.1.7.6.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:76pt;vertical-align:-35.5pt;"><span class="ltx_transformed_inner" style="width:76.0pt;transform:translate(-33.56pt,2.92pt) rotate(-90deg) ;">
<span id="A1.T12.1.7.6.1.1.1.1" class="ltx_p"><span id="A1.T12.1.7.6.1.1.1.1.1" class="ltx_text ltx_font_bold">From ToolAlpaca</span></span>
</span></span></span></th>
<td id="A1.T12.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.7.6.2.1.1" class="ltx_p" style="width:390.3pt;">I’m curious about quotes related to debugging. Can you find some for me? After that, please show me a list of all authors so I can learn more about their thoughts on programming.</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.8.7" class="ltx_tr">
<td id="A1.T12.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.8.7.1.1.1" class="ltx_p" style="width:390.3pt;">I want to add a catchy animation to my GitHub profile. Show me a list of font types available for use, and once I choose one, create a typing and deleting SVG with the text "I’m a software engineer" in 18-point font size, orange color, a typing speed of 80 ms, start delay of 500 ms, and a pause duration of 1 second.</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.9.8" class="ltx_tr">
<td id="A1.T12.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.9.8.1.1.1" class="ltx_p" style="width:390.3pt;">I’m thinking of going to Lansdowne Park this afternoon. Could you find nearby bus stops within a 300-meter radius with my current location at latitude 45.3967 and longitude -75.6858?</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.10.9" class="ltx_tr">
<td id="A1.T12.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.10.9.1.1.1" class="ltx_p" style="width:390.3pt;">My user profile still shows my old email address. Can you update it to my new one, "new_email@example.com"? Also, update my preferences to receive newsletters about datasets in the "economy" category.</span>
</span>
</td>
</tr>
<tr id="A1.T12.1.11.10" class="ltx_tr">
<td id="A1.T12.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="A1.T12.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T12.1.11.10.1.1.1" class="ltx_p" style="width:390.3pt;">Can you personalize the email content for my subscribers based on their names? Use the template ’Holiday Greetings’ and add subscriber data for Sarah, whose email is sarah@example.com and name is ’Sarah Smith’.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Examples of instructions which our method found as <span id="A1.T12.3.1" class="ltx_text ltx_font_bold">incoherent</span>, from the two examined datasets.</figcaption>
</figure>
</section>
<section id="A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Relationship Between Quality Criteria</h3>

<div id="A1.SS6.p1" class="ltx_para">
<p id="A1.SS6.p1.1" class="ltx_p">We additionally explored the relationship between quality criteria within the datasets. Generally, the correlations between dimensions are not particularly high. A notable analysis we conducted shows the effect of <span id="A1.SS6.p1.1.1" class="ltx_text ltx_font_italic">Specificity</span> on <span id="A1.SS6.p1.1.2" class="ltx_text ltx_font_italic">Parameter Alignment</span>. As illustrated in <a href="#A1.F5" title="Figure 5 ‣ A.6 Relationship Between Quality Criteria ‣ Appendix A Intrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>, when specificity is weak, it is also more likely that parameter alignment is weak. This might be expected behavior since low specificity means that parameter values are missing in the instruction, and the LLM hallucinates a value in order to complete its task. The correlation however is not exceedingly high, in particular we see in ToolBench that even for instances with high specificity, the parameter alignment can still be low, showing that there are examples where the parameter is present in the instruction but it does not match the parameter in the ground-truth response.</p>
</div>
<figure id="A1.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.16341/assets/figures/specificity_param_alpaca_confusion_matrix.png" id="A1.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>ToolAlpaca dataset</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.16341/assets/figures/specificity_param_bench_confusion_matrix.png" id="A1.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="396" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>ToolBench dataset</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Confusion matrices for Specificity and Parameter Alignment.</figcaption>
</figure>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>ICE</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Full Prompt</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">In <a href="#A3.F14" title="Figure 14 ‣ ToolAlpaca. ‣ C.2 Evaluation Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 14</span></a> we provide the full prompt for our proposed in-context evaluation method. The prompt is constructed as follows: a description of the task, documentation of the APIs selected, one in-context example and the test queries.</p>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>ICE Score Calculation</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">To calculate the ICE score, we follow these steps:</p>
</div>
<div id="A2.SS2.p2" class="ltx_para">
<ol id="A2.I1" class="ltx_enumerate">
<li id="A2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A2.I1.i1.p1" class="ltx_para">
<p id="A2.I1.i1.p1.1" class="ltx_p">We input to the model the ICE prompt (<a href="#A3.F14" title="Figure 14 ‣ ToolAlpaca. ‣ C.2 Evaluation Setup ‣ Appendix C Extrinsic Evaluation ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 14</span></a>), containing an in-context example from the assessed dataset, and obtain the model output for each of the 7 test instructions.</p>
</div>
</li>
<li id="A2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A2.I1.i2.p1" class="ltx_para">
<p id="A2.I1.i2.p1.1" class="ltx_p">For each test instruction, we calculate the Levenshtein distance between the generated API-call sequence and the correct API-call sequence.</p>
</div>
</li>
<li id="A2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A2.I1.i3.p1" class="ltx_para">
<p id="A2.I1.i3.p1.1" class="ltx_p">We average the Levenshtein distances calculated for all test instructions, resulting in a single score for each data instance.</p>
</div>
</li>
</ol>
</div>
<div id="A2.SS2.p3" class="ltx_para">
<p id="A2.SS2.p3.1" class="ltx_p">Steps 1 to 3 are repeated for each of the data instances in the assessed dataset. <a href="#S5.F2" title="Figure 2 ‣ 5.2 Analysis ‣ 5 In-Context Evaluation (ICE) as an Alternative Data Measurement ‣ Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a> shows the distribution of instance-level scores for the two assessed datasets.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Extrinsic Evaluation</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Training Setup</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p id="A3.SS1.p1.1" class="ltx_p">The training setup is similar for both ToolBench and ToolAlpaca benchmarks, where we train on pairs of (instruction, API-call sequence + response).</p>
</div>
<section id="A3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ToolBench.</h5>

<div id="A3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="A3.SS1.SSS0.Px1.p1.1" class="ltx_p">We fine-tune a LLaMA-7B model when working with the ToolBench dataset. The learning rate is set to <math id="A3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="5\times 10^{-5}" display="inline"><semantics id="A3.SS1.SSS0.Px1.p1.1.m1.1a"><mrow id="A3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.1" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml">×</mo><msup id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mn id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.cmml"><mo id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3a" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.2" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1"><times id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.1"></times><cn type="integer" id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.2">5</cn><apply id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2">10</cn><apply id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3"><minus id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.1.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.2.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px1.p1.1.m1.1c">5\times 10^{-5}</annotation></semantics></math>, and we use a batch size of 2. Since the tasks require relatively long inputs for the targeted model, the context length is extended using positional interpolation <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>. We increase the context length to 4096, which is twice the model’s default length of 2048. The model is trained for two epochs on 8 NVIDIA A10G Tensor Core GPUs.</p>
</div>
</section>
<section id="A3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ToolAlpaca.</h5>

<div id="A3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="A3.SS1.SSS0.Px2.p1.1" class="ltx_p">For the ToolAlpaca dataset, we fine-tune a Vicuna-7B model. We use a batch size of 2 and a learning rate of <math id="A3.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="2\times 10^{-5}" display="inline"><semantics id="A3.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="A3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml">×</mo><msup id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mn id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.cmml"><mo id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3a" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1"><times id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.1"></times><cn type="integer" id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.2">2</cn><apply id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.2">10</cn><apply id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3"><minus id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.1.m1.1c">2\times 10^{-5}</annotation></semantics></math>. The model is fine-tuned for three epochs on 4 NVIDIA A10G Tensor Core GPUs.</p>
</div>
</section>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Evaluation Setup</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p id="A3.SS2.p1.1" class="ltx_p">We adhere to the evaluation procedures outlined in the respective benchmarks for ToolBench and ToolAlpaca. Both benchmarks use a generative model for the evaluation of the API-call sequence and response. We use ChatGPT for both datasets.</p>
</div>
<section id="A3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ToolBench.</h5>

<div id="A3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="A3.SS2.SSS0.Px1.p1.1" class="ltx_p">In the ToolBench benchmark, the evaluation process begins with assessing the solvability of the given instruction. Using ChatGPT, solution paths are categorized as Pass, Fail, or Unsure based on this classification. The evaluation criteria include various rules to determine the success of a solution path. For more detailed insights into the evaluation methodology and rules, please refer to the original paper <cite class="ltx_cite ltx_citemacro_cite">Qin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
<div id="A3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="A3.SS2.SSS0.Px1.p2.1" class="ltx_p">The original evaluation procedure involves assessing the generalization ability across three levels—unseen instructions, tools, and categories—as well as three different scenarios. However, instead of splitting the test set into categories, we calculate the pass rate by averaging over all test samples. Importantly, in the human-annotation of the test set, we aimed to maintain a similar distribution across all test splits for consistency.</p>
</div>
<div id="A3.SS2.SSS0.Px1.p3" class="ltx_para">
<p id="A3.SS2.SSS0.Px1.p3.1" class="ltx_p">Regarding the retrieval of APIs during model inference, we adopt only one of the approaches tested in the original evaluation, where we directly insert the relevant APIs for each test instruction. This approach simulates the scenario where the user specifies the preferred API set.</p>
</div>
</section>
<section id="A3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ToolAlpaca.</h5>

<div id="A3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="A3.SS2.SSS0.Px2.p1.1" class="ltx_p">Similarly, in the ToolAlpaca benchmark, we use ChatGPT to evaluate the model’s output in addressing the instruction. The evaluation criteria is assessing the overall correctness, considered as the pass rate, of both the process and the response. For further details regarding the evaluation methodology, please refer to the original paper <cite class="ltx_cite ltx_citemacro_cite">Tang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="A3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="A3.SS2.SSS0.Px2.p2.1" class="ltx_p">In our study, we use the simulated subset for evaluation. This subset comprises 10 simulated tools (100 instructions) that were not part of the training toolset. While the original paper also includes a real-world subset with 11 APIs from various domains, we focused solely on the simulated data due the lack of detailed instructions on how to use the real-world data.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A3.F6" class="ltx_figure"><img src="/html/2409.16341/assets/figures/prompt_specificity_task.png" id="A3.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="621" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Prompt for instruction <span id="A3.F6.2.1" class="ltx_text ltx_font_bold">specificity</span>, as an extraction task.
</figcaption>
</figure>
<figure id="A3.F7" class="ltx_figure"><img src="/html/2409.16341/assets/figures/prompt_coherence_task.png" id="A3.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="740" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Prompt for instruction <span id="A3.F7.2.1" class="ltx_text ltx_font_bold">coherence</span>, as a next sentence coherence prediction task.
</figcaption>
</figure>
<figure id="A3.F8" class="ltx_figure"><img src="/html/2409.16341/assets/figures/prompt_solvable_direct.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="742" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Prompt for instruction <span id="A3.F8.2.1" class="ltx_text ltx_font_bold">solvability</span>. </figcaption>
</figure>
<figure id="A3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.16341/assets/figures/prompt_param_extract1.png" id="A3.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="612" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Step 1: parameter value extraction</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.16341/assets/figures/prompt_param_compare2.png" id="A3.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="612" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Step 2: comparison</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Prompts for assessing <span id="A3.F9.2.1" class="ltx_text ltx_font_bold">parameter alignment</span> in the API-call sequence, as a two-step procedure.</figcaption>
</figure>
<figure id="A3.F10" class="ltx_figure"><img src="/html/2409.16341/assets/figures/prompt_api.png" id="A3.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="695" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Prompt for <span id="A3.F10.3.1" class="ltx_text ltx_font_bold">sufficiency</span> and <span id="A3.F10.4.2" class="ltx_text ltx_font_bold">minimality</span> of the API-call sequence.
</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A3.F11" class="ltx_figure"><img src="/html/2409.16341/assets/figures/prompt_specificity_direct.png" id="A3.F11.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="765" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Prompt for <span id="A3.F11.2.1" class="ltx_text ltx_font_bold">specificity</span>, as a direct questioning task.</figcaption>
</figure>
<figure id="A3.F12" class="ltx_figure"><img src="/html/2409.16341/assets/figures/prompt_coherence_direct.png" id="A3.F12.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="742" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Prompt for <span id="A3.F12.2.1" class="ltx_text ltx_font_bold">coherence</span>, as a direct questioning task.
</figcaption>
</figure>
<figure id="A3.F13" class="ltx_figure"><img src="/html/2409.16341/assets/figures/prompt_param_direct.png" id="A3.F13.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="742" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Prompt for <span id="A3.F13.2.1" class="ltx_text ltx_font_bold">parameter alignment</span>, as a direct questioning task.
</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A3.F14" class="ltx_figure"><img src="/html/2409.16341/assets/figures/ice_prompt.png" id="A3.F14.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="568" height="837" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>The prompt used for in-context evaluation of a training instance (marked as <span id="A3.F14.2.1" class="ltx_text ltx_font_typewriter">{in_context_example}</span> in the prompt).</figcaption>
</figure>
</section>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.16340" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.16341" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.16341">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.16341" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.16343" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 20:12:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
