<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.06302] Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data</title><meta property="og:description" content="This paper aims to remove specular highlights from a single
object-level image. Although previous methods have made some
progresses, their performance remains somewhat limited, particularly
for real images with complexâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.06302">

<!--Generated on Wed Feb 28 07:07:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Towards High-Quality Specular Highlight Removal 
<br class="ltx_break">by Leveraging
Large-Scale Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gang Fu<sup id="id11.11.id1" class="ltx_sup">1</sup>, Qing Zhang<sup id="id12.12.id2" class="ltx_sup">2</sup>, Lei Zhu<sup id="id13.13.id3" class="ltx_sup"><span id="id13.13.id3.1" class="ltx_text ltx_font_italic">3,4</span></sup>, Chunxia Xiao<sup id="id14.14.id4" class="ltx_sup">5</sup>, and
Ping Li<sup id="id15.15.id5" class="ltx_sup"><span id="id15.15.id5.1" class="ltx_text ltx_font_italic">1,</span></sup>
<br class="ltx_break"><sup id="id16.16.id6" class="ltx_sup">1</sup>The Hong Kong Polytechnic University, Hong Kong 
<br class="ltx_break"><sup id="id17.17.id7" class="ltx_sup">2</sup>Sun Yat-sen University, Guangzhou, China 
<br class="ltx_break"><sup id="id18.18.id8" class="ltx_sup">3</sup>The Hong Kong University of Science and Technology
(Guangzhou), Guangzhou, China
<br class="ltx_break"><sup id="id19.19.id9" class="ltx_sup">4</sup>The Hong Kong University of Science and Technology, Hong Kong 
<br class="ltx_break"><sup id="id20.20.id10" class="ltx_sup">5</sup>School of Computer Science, Wuhan University, Wuhan, China
<br class="ltx_break">
</span><span class="ltx_author_notes">Corresponding author.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id21.id1" class="ltx_p">This paper aims to remove specular highlights from a single
object-level image. Although previous methods have made some
progresses, their performance remains somewhat limited, particularly
for real images with complex specular highlights. To this end, we
propose a three-stage network to address them. Specifically, given
an input image, we first decompose it into the albedo, shading, and
specular residue components to estimate a coarse specular-free
image. Then, we further refine the coarse result to alleviate its
visual artifacts such as color distortion. Finally, we adjust the
tone of the refined result to match that of the input as closely
as possible. In addition, to facilitate network training and
quantitative evaluation, we present a large-scale synthetic dataset
of object-level images, covering diverse objects and illumination
conditions. Extensive experiments illustrate that our network is
able to generalize well to unseen real object-level images, and even
produce good results for scene-level images with multiple background
objects and complex lighting.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Specular highlights are very common in the real world, but they are
usually undesirable in photographs, since they can degrade the image
quality. In daily life, users often want to achieve the specular-free
image from an image. For example, specular highlights in facial or
document images sweep away skin details or meaningful texture patterns
which are very important to users. Removing specular highlights from a
single image enables recovering visual content with better
perceptibility. Moreover, it has many related applications such as
recoloring <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, light source estimation
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, recognition of specular objects
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and intrinsic image decomposition
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Thus, specular highlight removal is a
long-standing and challenging problem in computer vision and computer
graphics.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address this problem, researchers have proposed various specular
highlight methods. They can be roughly divided into two categories:
traditional methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> based on intensity and chromaticity analysis
as well as optimization, and deep learning-based methods
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
However, the traditional methods often produce unsatisfactory or even
poor results with visual artifacts such as black color block and detail
missing; see FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b). The main reason is that they
fail to capture high-level semantic information to recover the missing
colors and details underneath specular highlights using those
meaningful and reliable information from the non-highlight region. In
addition, although the deep learning-based methods have achieved
certain performance improvement, they may still produce unsatisfactory
results with visual artifacts such as illumination residue and color
distortion; see FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(c)(e). It is partly attributed
to the fact that they are trained on relatively simple images in which
materials and illumination conditions are not diverse enough, leading
to their limited generalization to unseen images.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<table id="S1.F1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.F1.1.1" class="ltx_tr">
<td id="S1.F1.1.1.1" class="ltx_td ltx_align_center"><span id="S1.F1.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x1.png" id="S1.F1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="523" height="76" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Visual comparison of our method against state-of-the-art
methods on a challenging image with nearly white material
surfaces. (a) Input. (b) Yang <span id="S1.F1.5.1" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. (c) Fu <span id="S1.F1.6.2" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. (d) Wu <span id="S1.F1.7.3" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. (e) Ours.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We in this paper propose a three-stage specular highlight removal
network, consisting of (i) physics-based specular highlight removal,
(ii) specular-free refinement, and (iii) tone correction. In the first
stage, based on a physics-based image formation model, we decompose an
input image into its albedo, shading, and specular residue components,
and then estimate a coarse specular-free image. In the second stage,
we further refine the coarse result to alleviate visual artifacts for
improving the quality. In the third stage, we adjust the tone of the
refined result to produce the final result with the similar tone of
the input. In addition, to facilitate network training and
quantitative evaluation, we build a large-scale synthetic dataset
rendered by software using diverse 3D models and real HDR environment
maps. FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents the visual comparison on a real
image. As shown, our method is able to produce high-quality
specular-free images without noticeable artifacts encountered by
previous methods. Below, we summarize the major contributions of our
work.</p>
</div>
<div id="S1.p4" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.i1.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.i1.1.1.m1.1b"><mo id="S1.I1.i1.1.1.m1.1.1" xref="S1.I1.i1.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i1.1.1.m1.1c"><ci id="S1.I1.i1.1.1.m1.1.1.cmml" xref="S1.I1.i1.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a three-stage specular highlight removal network to
progressively eliminate multiple types of visual artifacts such as
color distortion and tone inconsistency.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.i2.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.i2.1.1.m1.1b"><mo id="S1.I1.i2.1.1.m1.1.1" xref="S1.I1.i2.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i2.1.1.m1.1c"><ci id="S1.I1.i2.1.1.m1.1.1.cmml" xref="S1.I1.i2.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We present a large-scale synthetic dataset of object-level
images, in which each specular highlight image has corresponding
ground truth albedo, shading, specular residue, and specular-free images.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.i3.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.i3.1.1.m1.1b"><mo id="S1.I1.i3.1.1.m1.1.1" xref="S1.I1.i3.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i3.1.1.m1.1c"><ci id="S1.I1.i3.1.1.m1.1.1.cmml" xref="S1.I1.i3.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We conduct extensive experiments on existing datasets and our new dataset,
and demonstrate that our method achieves better
quantitative and qualitative results than state-of-the-art methods.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Single-Image methods</span>. Early methods are mostly
based on chromaticity propagation or optimization. Tan and Ikeuchi
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> proposed to remove specular highlights
via iteratively comparing the intensity logarithmic differentiation of
an input image and its specular-free image. Yang <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> proposed to use the bilateral filter to
propagate information from the diffuse region to the specular
highlight region. Kim <span id="S2.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
formulated specular highlight removal as a MAP optimization problem
based on the priors of specular highlights in the real world. However,
these methods may produce unsatisfactory results with visual artifacts
such as black color block, resulting in unrealistic appearances. To
alleviate the issue, Liu <span id="S2.p1.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
proposed a two-step method in which an over-saturated specular-free
image is first produced by global chromaticity propagation, and then
recovered its saturation via an optimization framework. Guo <span id="S2.p1.1.5" class="ltx_text ltx_font_italic">et
al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> proposed a sparse and low-rank
reflection model for specular highlight removal. However, they may
fail to effectively recover the missing content underneath specular
highlights.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Subsequently, researchers have proposed various deep learning-based
methods. Shi <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> proposed a
unified framework that can simultaneously estimate the albedo,
shading, and specular residue components from a single object-level
image. However, it fails to generalize well to real images with
complex specular highlights. Yi <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> proposed to leverage multi-view image sets
(<span id="S2.p2.1.3" class="ltx_text ltx_font_italic">i.e.</span>, customer product photos) to perform specular highlight
removal in an unsupervised way. Fu <span id="S2.p2.1.4" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> proposed a multi-task network for joint
specular highlight detection and removal based on a region-aware
specular highlight image formation model. Wu <span id="S2.p2.1.5" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> proposed a GAN-based network for specular
highlight removal using specular highlight detection map as guidance.
Jin <span id="S2.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> proposed to estimate
the reflectance layer from a single image with shadows and specular
highlights. Although these methods achieve good results, their
performance is often limited, particularly for real images with adverse
factors such as achromatic material surfaces and complex illumination
conditions. In contrast, our three-stage method is able to effectively
address previous challenging images.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Multi-Image and Normal-Based Methods</span>.
Researchers have proposed various multi-image and normal-based methods
to more robustly remove specular highlights. Guo <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposed to remove specular highlights for
superimposed multiple images. Wei <span id="S2.p3.1.3" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> proposed a unified framework of specular
highlight removal and light source position estimation
by assuming that surface geometry is known.
Li <span id="S2.p3.1.4" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> proposed a method for specular highlight
removal in facial images that may contain varying illumination colors,
with the help of facial surface normals. Although these
methods can produce promising results, the requirement of multiple
images or extra auxiliary cues limits their applicability.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Benckmark Datasets</span>. Grosse <span id="S2.p4.1.2" class="ltx_text ltx_font_italic">et
al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> presented the MIT intrinsic images
dataset, including 20 object-level images and their corresponding
ground truth intrinsic images. However, these images are not
sufficient to support network training. Shi <span id="S2.p4.1.3" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> rendered a large-scale synthetic dataset for
non-Lambertian intrinsic image decomposition by software. Although
this dataset includes a large amount of images, many of them do not
have obvious and meaningful specular highlights for our task.
Recently, Fu <span id="S2.p4.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> presented a
real dataset simultaneously for specular highlight detection and
removal, produced by a series of image processing algorithms on the
multi-illumination dataset IIW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. At the
same time, Wu <span id="S2.p4.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> also built
a real paired specular-diffuse image dataset via the
cross-polarization photography technique. However, objects and
illumination conditions in these two datasets are somewhat limited for
network training, leading to the unsatisfactory generalization to
unseen images. In contrast, we present a large-scale synthetic dataset
of object-level images, which covers diverse objects and illumination
conditions, and thus contains various appearances of specular
highlights.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overview</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.8" class="ltx_p">FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the pipeline of our three-stage
framework. It consists of three stages: (i) physics-based specular
highlight removal; (ii) specular-free refinement; and (iii) tone
correction. Specifically, in the first stage (see (a)), we decompose
an input image into its albedo and shading using two encoder-decoder
networks (<math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="E_{a}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">E</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ¸</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">E_{a}</annotation></semantics></math>-<math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="D_{a}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ·</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">D_{a}</annotation></semantics></math> for albedo, and <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="E_{s}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">E</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ¸</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">E_{s}</annotation></semantics></math>-<math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="D_{s}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">ğ·</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">D_{s}</annotation></semantics></math> for shading). Then,
the specular-free image can be estimated by multiplying the albedo and
shading. In the second stage (see (b)), we feed the coarse result
along with the input into an encoder-decoder network
(<math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="E_{r}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">E</mi><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">ğ¸</ci><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">E_{r}</annotation></semantics></math>-<math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="D_{r}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">ğ·</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">D_{r}</annotation></semantics></math>) to further refine it to alleviate visual artifacts. In
the third stage (see (c)), we feed the refined result along with the
input and its specular residue image into an encoder-decoder network
(<math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="E_{c}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><msub id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">E</mi><mi id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">ğ¸</ci><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">E_{c}</annotation></semantics></math>-<math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="D_{c}" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><msub id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2" xref="S3.SS1.p1.8.m8.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2">ğ·</ci><ci id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">D_{c}</annotation></semantics></math>) to adjust its tone so that it has the similar tone as
the input as much as possible. FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 Specular-Free Refinement â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> validate
the effectiveness of each stage in our framework.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Physics-Based Specular Highlight Removal</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">According to the dichromatic reflection model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, an
input image <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">I</annotation></semantics></math> can be decomposed into its intrinsic images
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Throughout the paper we use the terms <span id="footnote1.1" class="ltx_text ltx_font_italic">albedo</span> and
<span id="footnote1.2" class="ltx_text ltx_font_italic">shading</span> loosely for simplicity. Actually, <span id="footnote1.3" class="ltx_text ltx_font_italic">albedo</span>
and <span id="footnote1.4" class="ltx_text ltx_font_italic">shading</span> refer to diffuse albedo and diffuse shading,
respectively.</span></span></span>, expressed as</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="I=A\times S+R\,," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">I</mi><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">Ã—</mo><mi id="S3.E1.m1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.3.2.3.cmml">S</mi></mrow><mo id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">+</mo><mi id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml">R</mi></mrow></mrow><mo lspace="0.170em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><ci id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2">ğ¼</ci><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><plus id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></plus><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><times id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1"></times><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">ğ´</ci><ci id="S3.E1.m1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3">ğ‘†</ci></apply><ci id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3">ğ‘…</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">I=A\times S+R\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.9" class="ltx_p">where <math id="S3.SS2.p1.2.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p1.2.m1.1a"><mi id="S3.SS2.p1.2.m1.1.1" xref="S3.SS2.p1.2.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m1.1b"><ci id="S3.SS2.p1.2.m1.1.1.cmml" xref="S3.SS2.p1.2.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m1.1c">A</annotation></semantics></math>, <math id="S3.SS2.p1.3.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS2.p1.3.m2.1a"><mi id="S3.SS2.p1.3.m2.1.1" xref="S3.SS2.p1.3.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m2.1b"><ci id="S3.SS2.p1.3.m2.1.1.cmml" xref="S3.SS2.p1.3.m2.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m2.1c">S</annotation></semantics></math>, and <math id="S3.SS2.p1.4.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS2.p1.4.m3.1a"><mi id="S3.SS2.p1.4.m3.1.1" xref="S3.SS2.p1.4.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m3.1b"><ci id="S3.SS2.p1.4.m3.1.1.cmml" xref="S3.SS2.p1.4.m3.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m3.1c">R</annotation></semantics></math> are albedo, shading, and specular residue, respectively.
Based on the physical image formation model in
Eq.Â (<a href="#S3.E1" title="In 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), we propose the Physics-based Specular
Highlight Removal stage (PSHR) to recover the intrinsic images from an
input image. FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(a) illustrates the mechanism
of PSHR. Specifically, given an input image, we use an encoder-decoder
network (<math id="S3.SS2.p1.5.m4.1" class="ltx_Math" alttext="E_{a}" display="inline"><semantics id="S3.SS2.p1.5.m4.1a"><msub id="S3.SS2.p1.5.m4.1.1" xref="S3.SS2.p1.5.m4.1.1.cmml"><mi id="S3.SS2.p1.5.m4.1.1.2" xref="S3.SS2.p1.5.m4.1.1.2.cmml">E</mi><mi id="S3.SS2.p1.5.m4.1.1.3" xref="S3.SS2.p1.5.m4.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m4.1b"><apply id="S3.SS2.p1.5.m4.1.1.cmml" xref="S3.SS2.p1.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m4.1.1.1.cmml" xref="S3.SS2.p1.5.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m4.1.1.2.cmml" xref="S3.SS2.p1.5.m4.1.1.2">ğ¸</ci><ci id="S3.SS2.p1.5.m4.1.1.3.cmml" xref="S3.SS2.p1.5.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m4.1c">E_{a}</annotation></semantics></math>-<math id="S3.SS2.p1.6.m5.1" class="ltx_Math" alttext="D_{a}" display="inline"><semantics id="S3.SS2.p1.6.m5.1a"><msub id="S3.SS2.p1.6.m5.1.1" xref="S3.SS2.p1.6.m5.1.1.cmml"><mi id="S3.SS2.p1.6.m5.1.1.2" xref="S3.SS2.p1.6.m5.1.1.2.cmml">D</mi><mi id="S3.SS2.p1.6.m5.1.1.3" xref="S3.SS2.p1.6.m5.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m5.1b"><apply id="S3.SS2.p1.6.m5.1.1.cmml" xref="S3.SS2.p1.6.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m5.1.1.1.cmml" xref="S3.SS2.p1.6.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.6.m5.1.1.2.cmml" xref="S3.SS2.p1.6.m5.1.1.2">ğ·</ci><ci id="S3.SS2.p1.6.m5.1.1.3.cmml" xref="S3.SS2.p1.6.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m5.1c">D_{a}</annotation></semantics></math>) to estimate albedo, and another one (<math id="S3.SS2.p1.7.m6.1" class="ltx_Math" alttext="E_{s}" display="inline"><semantics id="S3.SS2.p1.7.m6.1a"><msub id="S3.SS2.p1.7.m6.1.1" xref="S3.SS2.p1.7.m6.1.1.cmml"><mi id="S3.SS2.p1.7.m6.1.1.2" xref="S3.SS2.p1.7.m6.1.1.2.cmml">E</mi><mi id="S3.SS2.p1.7.m6.1.1.3" xref="S3.SS2.p1.7.m6.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m6.1b"><apply id="S3.SS2.p1.7.m6.1.1.cmml" xref="S3.SS2.p1.7.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m6.1.1.1.cmml" xref="S3.SS2.p1.7.m6.1.1">subscript</csymbol><ci id="S3.SS2.p1.7.m6.1.1.2.cmml" xref="S3.SS2.p1.7.m6.1.1.2">ğ¸</ci><ci id="S3.SS2.p1.7.m6.1.1.3.cmml" xref="S3.SS2.p1.7.m6.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m6.1c">E_{s}</annotation></semantics></math>-<math id="S3.SS2.p1.8.m7.1" class="ltx_Math" alttext="D_{s}" display="inline"><semantics id="S3.SS2.p1.8.m7.1a"><msub id="S3.SS2.p1.8.m7.1.1" xref="S3.SS2.p1.8.m7.1.1.cmml"><mi id="S3.SS2.p1.8.m7.1.1.2" xref="S3.SS2.p1.8.m7.1.1.2.cmml">D</mi><mi id="S3.SS2.p1.8.m7.1.1.3" xref="S3.SS2.p1.8.m7.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m7.1b"><apply id="S3.SS2.p1.8.m7.1.1.cmml" xref="S3.SS2.p1.8.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.8.m7.1.1.1.cmml" xref="S3.SS2.p1.8.m7.1.1">subscript</csymbol><ci id="S3.SS2.p1.8.m7.1.1.2.cmml" xref="S3.SS2.p1.8.m7.1.1.2">ğ·</ci><ci id="S3.SS2.p1.8.m7.1.1.3.cmml" xref="S3.SS2.p1.8.m7.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m7.1c">D_{s}</annotation></semantics></math>) to estimate
shading. The specular-free (<span id="S3.SS2.p1.9.1" class="ltx_text ltx_font_italic">i.e.</span>, diffuse) image <math id="S3.SS2.p1.9.m8.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.9.m8.1a"><mi id="S3.SS2.p1.9.m8.1.1" xref="S3.SS2.p1.9.m8.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m8.1b"><ci id="S3.SS2.p1.9.m8.1.1.cmml" xref="S3.SS2.p1.9.m8.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m8.1c">D</annotation></semantics></math> is
estimated by</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="D=A\times S\,," display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">D</mi><mo id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.3.1.cmml">Ã—</mo><mi id="S3.E2.m1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.3.3.cmml">S</mi></mrow></mrow><mo lspace="0.170em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"></eq><ci id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2">ğ·</ci><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1"></times><ci id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2">ğ´</ci><ci id="S3.E2.m1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3">ğ‘†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">D=A\times S\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.10" class="ltx_p">With Eqs.Â (<a href="#S3.E1" title="In 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) and
(<a href="#S3.E2" title="In 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), we can yield the specular residue <math id="S3.SS2.p1.10.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS2.p1.10.m1.1a"><mi id="S3.SS2.p1.10.m1.1.1" xref="S3.SS2.p1.10.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m1.1b"><ci id="S3.SS2.p1.10.m1.1.1.cmml" xref="S3.SS2.p1.10.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m1.1c">R</annotation></semantics></math> by</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="R=I-D\,." display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">R</mi><mo id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml">I</mi><mo id="S3.E3.m1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.3.1.cmml">âˆ’</mo><mi id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml">D</mi></mrow></mrow><mo lspace="0.170em" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"></eq><ci id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2">ğ‘…</ci><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><minus id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.1"></minus><ci id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">ğ¼</ci><ci id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">R=I-D\,.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.11" class="ltx_p">To facilitate the network training of PSHR, we present a large-scale
synthetic dataset of object-level images for specular highlight
removal (named SSHR). Now, we detail it.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<table id="S3.F2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.F2.1.1" class="ltx_tr">
<td id="S3.F2.1.1.1" class="ltx_td ltx_align_center"><span id="S3.F2.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x2.png" id="S3.F2.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="228" height="227" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The pipeline of our three-stage specular highlight removal framework.</figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Dataset</span>. To the best of our
knowledge, SHIQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and PSD
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> are only two publicly available real
datasets for specular highlight removal. However, they suffer from the
following three issues. First, the quantity of objects is quite small,
and the images were captured in controllable laboratory environments
with limited illumination conditions. Second, a pair of specular
highlight and specular-free images may not be aligned well, since the
camera shakes caused by itself or hand touch during the process of
capturing data. Third, even a well-aligned pair of specular highlight
and specular-free images may have inconsistent color and shading,
since the environmental lighting may have a subtle fluctuation over
time and the camera exposure may vary. In addition, Shi <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_italic">et
al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> presented a large-scale synthetic
dataset for non-Lambertian intrinsic image decomposition. However,
most input images in it are not with obvious and meaningful specular
highlights, and thus are not well-suited for our task. Note that this
dataset is currently not publicly available.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.2" class="ltx_p">To this end, we built a large-scale synthetic dataset tailored for
specular highlight removal. Specifically, to render the data, we first
picked up 1500 3D models with their albedo texture maps from several
common categories (such as car, bus, container, and sofa) of
the large-scale 3D shape dataset ShapeNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Then, we collected 90 HDR environment maps from the Internet
<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>http://www.hdrlabs.com/sibl/archive.html.</span></span></span>, which includes
indoor and outdoor scenes with diverse material surfaces and
illumination conditions. FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> presents example
environment maps. Finally, we used an open-source render software
Mitsuba <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and adopted the modified Phong
reflection model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> to render object
models with various environment maps to generate photo-realistic
shading and specular residue appearance. According to the rendered
results, the specular-free and input images can be obtained via
Eqs.Â (<a href="#S3.E2" title="In 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) and (<a href="#S3.E1" title="In 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>),
respectively. Finally, we randomly split the collected 1500 models
into <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="1300" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mn id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">1300</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><cn type="integer" id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">1300</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">1300</annotation></semantics></math> models for training and <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="200" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mn id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><cn type="integer" id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">200</annotation></semantics></math> for testing. In total, we
have 117,000 training images and 18,000 testing images.
FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows example image groups in our dataset.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Loss Function</span>. The total loss for
physics-based specular highlight removal <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{PSHR}}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msup id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">â„’</mi><mtext id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3a.cmml">PSHR</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">â„’</ci><ci id="S3.SS2.p4.1.m1.1.1.3a.cmml" xref="S3.SS2.p4.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3">PSHR</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathcal{L}^{\text{PSHR}}</annotation></semantics></math>
is defined as</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{PSHR}}=||A-\hat{A}||^{2}+||S-\hat{S}||^{2}+||I-D_{1}-\hat{R}||^{2}\,," display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msup id="S3.E4.m1.1.1.1.1.5" xref="S3.E4.m1.1.1.1.1.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.5.2" xref="S3.E4.m1.1.1.1.1.5.2.cmml">â„’</mi><mtext id="S3.E4.m1.1.1.1.1.5.3" xref="S3.E4.m1.1.1.1.1.5.3a.cmml">PSHR</mtext></msup><mo id="S3.E4.m1.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.4.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><msup id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml">A</mi><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mover accent="true" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">A</mi><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.E4.m1.1.1.1.1.3.4" xref="S3.E4.m1.1.1.1.1.3.4.cmml">+</mo><msup id="S3.E4.m1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.2.2.cmml"><mrow id="S3.E4.m1.1.1.1.1.2.2.1.1" xref="S3.E4.m1.1.1.1.1.2.2.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.2.2.1.1.2" xref="S3.E4.m1.1.1.1.1.2.2.1.2.1.cmml">â€–</mo><mrow id="S3.E4.m1.1.1.1.1.2.2.1.1.1" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.2.cmml">S</mi><mo id="S3.E4.m1.1.1.1.1.2.2.1.1.1.1" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.1.cmml">âˆ’</mo><mover accent="true" id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.2.cmml">S</mi><mo id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.2.2.1.1.3" xref="S3.E4.m1.1.1.1.1.2.2.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E4.m1.1.1.1.1.2.2.3" xref="S3.E4.m1.1.1.1.1.2.2.3.cmml">2</mn></msup><mo id="S3.E4.m1.1.1.1.1.3.4a" xref="S3.E4.m1.1.1.1.1.3.4.cmml">+</mo><msup id="S3.E4.m1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.cmml"><mrow id="S3.E4.m1.1.1.1.1.3.3.1.1" xref="S3.E4.m1.1.1.1.1.3.3.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.3.3.1.1.2" xref="S3.E4.m1.1.1.1.1.3.3.1.2.1.cmml">â€–</mo><mrow id="S3.E4.m1.1.1.1.1.3.3.1.1.1" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.1.1.1.2" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.2.cmml">I</mi><mo id="S3.E4.m1.1.1.1.1.3.3.1.1.1.1" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E4.m1.1.1.1.1.3.3.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.2.cmml">D</mi><mn id="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.3.cmml">1</mn></msub><mo id="S3.E4.m1.1.1.1.1.3.3.1.1.1.1a" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.1.cmml">âˆ’</mo><mover accent="true" id="S3.E4.m1.1.1.1.1.3.3.1.1.1.4" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.2" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.2.cmml">R</mi><mo id="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.1" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.3.3.1.1.3" xref="S3.E4.m1.1.1.1.1.3.3.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E4.m1.1.1.1.1.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.3.cmml">2</mn></msup></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.4"></eq><apply id="S3.E4.m1.1.1.1.1.5.cmml" xref="S3.E4.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.5.1.cmml" xref="S3.E4.m1.1.1.1.1.5">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.5.2.cmml" xref="S3.E4.m1.1.1.1.1.5.2">â„’</ci><ci id="S3.E4.m1.1.1.1.1.5.3a.cmml" xref="S3.E4.m1.1.1.1.1.5.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.1.1.5.3.cmml" xref="S3.E4.m1.1.1.1.1.5.3">PSHR</mtext></ci></apply><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><plus id="S3.E4.m1.1.1.1.1.3.4.cmml" xref="S3.E4.m1.1.1.1.1.3.4"></plus><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"></minus><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2">ğ´</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3"><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.1">^</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.2">ğ´</ci></apply></apply></apply><cn type="integer" id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">2</cn></apply><apply id="S3.E4.m1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.2.2.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.2.2.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.2">norm</csymbol><apply id="S3.E4.m1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1"><minus id="S3.E4.m1.1.1.1.1.2.2.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.1"></minus><ci id="S3.E4.m1.1.1.1.1.2.2.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.2">ğ‘†</ci><apply id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3"><ci id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.1">^</ci><ci id="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.1.1.1.3.2">ğ‘†</ci></apply></apply></apply><cn type="integer" id="S3.E4.m1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.3">2</cn></apply><apply id="S3.E4.m1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.3.3.1.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.3.3.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.2">norm</csymbol><apply id="S3.E4.m1.1.1.1.1.3.3.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1"><minus id="S3.E4.m1.1.1.1.1.3.3.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.1"></minus><ci id="S3.E4.m1.1.1.1.1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.2">ğ¼</ci><apply id="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.2">ğ·</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.3.3">1</cn></apply><apply id="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.4"><ci id="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.1">^</ci><ci id="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.1.1.4.2">ğ‘…</ci></apply></apply></apply><cn type="integer" id="S3.E4.m1.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\mathcal{L}^{\text{PSHR}}=||A-\hat{A}||^{2}+||S-\hat{S}||^{2}+||I-D_{1}-\hat{R}||^{2}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p4.9" class="ltx_p">where <math id="S3.SS2.p4.2.m1.1" class="ltx_Math" alttext="\hat{A}" display="inline"><semantics id="S3.SS2.p4.2.m1.1a"><mover accent="true" id="S3.SS2.p4.2.m1.1.1" xref="S3.SS2.p4.2.m1.1.1.cmml"><mi id="S3.SS2.p4.2.m1.1.1.2" xref="S3.SS2.p4.2.m1.1.1.2.cmml">A</mi><mo id="S3.SS2.p4.2.m1.1.1.1" xref="S3.SS2.p4.2.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m1.1b"><apply id="S3.SS2.p4.2.m1.1.1.cmml" xref="S3.SS2.p4.2.m1.1.1"><ci id="S3.SS2.p4.2.m1.1.1.1.cmml" xref="S3.SS2.p4.2.m1.1.1.1">^</ci><ci id="S3.SS2.p4.2.m1.1.1.2.cmml" xref="S3.SS2.p4.2.m1.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m1.1c">\hat{A}</annotation></semantics></math>, <math id="S3.SS2.p4.3.m2.1" class="ltx_Math" alttext="\hat{S}" display="inline"><semantics id="S3.SS2.p4.3.m2.1a"><mover accent="true" id="S3.SS2.p4.3.m2.1.1" xref="S3.SS2.p4.3.m2.1.1.cmml"><mi id="S3.SS2.p4.3.m2.1.1.2" xref="S3.SS2.p4.3.m2.1.1.2.cmml">S</mi><mo id="S3.SS2.p4.3.m2.1.1.1" xref="S3.SS2.p4.3.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m2.1b"><apply id="S3.SS2.p4.3.m2.1.1.cmml" xref="S3.SS2.p4.3.m2.1.1"><ci id="S3.SS2.p4.3.m2.1.1.1.cmml" xref="S3.SS2.p4.3.m2.1.1.1">^</ci><ci id="S3.SS2.p4.3.m2.1.1.2.cmml" xref="S3.SS2.p4.3.m2.1.1.2">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m2.1c">\hat{S}</annotation></semantics></math>, and <math id="S3.SS2.p4.4.m3.1" class="ltx_Math" alttext="\hat{R}" display="inline"><semantics id="S3.SS2.p4.4.m3.1a"><mover accent="true" id="S3.SS2.p4.4.m3.1.1" xref="S3.SS2.p4.4.m3.1.1.cmml"><mi id="S3.SS2.p4.4.m3.1.1.2" xref="S3.SS2.p4.4.m3.1.1.2.cmml">R</mi><mo id="S3.SS2.p4.4.m3.1.1.1" xref="S3.SS2.p4.4.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m3.1b"><apply id="S3.SS2.p4.4.m3.1.1.cmml" xref="S3.SS2.p4.4.m3.1.1"><ci id="S3.SS2.p4.4.m3.1.1.1.cmml" xref="S3.SS2.p4.4.m3.1.1.1">^</ci><ci id="S3.SS2.p4.4.m3.1.1.2.cmml" xref="S3.SS2.p4.4.m3.1.1.2">ğ‘…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m3.1c">\hat{R}</annotation></semantics></math> are the ground truths of the
estimated albedo <math id="S3.SS2.p4.5.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p4.5.m4.1a"><mi id="S3.SS2.p4.5.m4.1.1" xref="S3.SS2.p4.5.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m4.1b"><ci id="S3.SS2.p4.5.m4.1.1.cmml" xref="S3.SS2.p4.5.m4.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m4.1c">A</annotation></semantics></math>, shading <math id="S3.SS2.p4.6.m5.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS2.p4.6.m5.1a"><mi id="S3.SS2.p4.6.m5.1.1" xref="S3.SS2.p4.6.m5.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m5.1b"><ci id="S3.SS2.p4.6.m5.1.1.cmml" xref="S3.SS2.p4.6.m5.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m5.1c">S</annotation></semantics></math>, and specular residue <math id="S3.SS2.p4.7.m6.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS2.p4.7.m6.1a"><mi id="S3.SS2.p4.7.m6.1.1" xref="S3.SS2.p4.7.m6.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m6.1b"><ci id="S3.SS2.p4.7.m6.1.1.cmml" xref="S3.SS2.p4.7.m6.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m6.1c">R</annotation></semantics></math>, respectively;
and <math id="S3.SS2.p4.8.m7.1" class="ltx_Math" alttext="D_{1}=A\times S" display="inline"><semantics id="S3.SS2.p4.8.m7.1a"><mrow id="S3.SS2.p4.8.m7.1.1" xref="S3.SS2.p4.8.m7.1.1.cmml"><msub id="S3.SS2.p4.8.m7.1.1.2" xref="S3.SS2.p4.8.m7.1.1.2.cmml"><mi id="S3.SS2.p4.8.m7.1.1.2.2" xref="S3.SS2.p4.8.m7.1.1.2.2.cmml">D</mi><mn id="S3.SS2.p4.8.m7.1.1.2.3" xref="S3.SS2.p4.8.m7.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.p4.8.m7.1.1.1" xref="S3.SS2.p4.8.m7.1.1.1.cmml">=</mo><mrow id="S3.SS2.p4.8.m7.1.1.3" xref="S3.SS2.p4.8.m7.1.1.3.cmml"><mi id="S3.SS2.p4.8.m7.1.1.3.2" xref="S3.SS2.p4.8.m7.1.1.3.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.8.m7.1.1.3.1" xref="S3.SS2.p4.8.m7.1.1.3.1.cmml">Ã—</mo><mi id="S3.SS2.p4.8.m7.1.1.3.3" xref="S3.SS2.p4.8.m7.1.1.3.3.cmml">S</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.8.m7.1b"><apply id="S3.SS2.p4.8.m7.1.1.cmml" xref="S3.SS2.p4.8.m7.1.1"><eq id="S3.SS2.p4.8.m7.1.1.1.cmml" xref="S3.SS2.p4.8.m7.1.1.1"></eq><apply id="S3.SS2.p4.8.m7.1.1.2.cmml" xref="S3.SS2.p4.8.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.8.m7.1.1.2.1.cmml" xref="S3.SS2.p4.8.m7.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.8.m7.1.1.2.2.cmml" xref="S3.SS2.p4.8.m7.1.1.2.2">ğ·</ci><cn type="integer" id="S3.SS2.p4.8.m7.1.1.2.3.cmml" xref="S3.SS2.p4.8.m7.1.1.2.3">1</cn></apply><apply id="S3.SS2.p4.8.m7.1.1.3.cmml" xref="S3.SS2.p4.8.m7.1.1.3"><times id="S3.SS2.p4.8.m7.1.1.3.1.cmml" xref="S3.SS2.p4.8.m7.1.1.3.1"></times><ci id="S3.SS2.p4.8.m7.1.1.3.2.cmml" xref="S3.SS2.p4.8.m7.1.1.3.2">ğ´</ci><ci id="S3.SS2.p4.8.m7.1.1.3.3.cmml" xref="S3.SS2.p4.8.m7.1.1.3.3">ğ‘†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.8.m7.1c">D_{1}=A\times S</annotation></semantics></math> is the estimated specular-free image. The
rightmost term of Eq.Â (<a href="#S3.E4" title="In 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) is to encourage the estimated
specular residue image (<span id="S3.SS2.p4.9.1" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S3.SS2.p4.9.m8.1" class="ltx_Math" alttext="I-D_{1}" display="inline"><semantics id="S3.SS2.p4.9.m8.1a"><mrow id="S3.SS2.p4.9.m8.1.1" xref="S3.SS2.p4.9.m8.1.1.cmml"><mi id="S3.SS2.p4.9.m8.1.1.2" xref="S3.SS2.p4.9.m8.1.1.2.cmml">I</mi><mo id="S3.SS2.p4.9.m8.1.1.1" xref="S3.SS2.p4.9.m8.1.1.1.cmml">âˆ’</mo><msub id="S3.SS2.p4.9.m8.1.1.3" xref="S3.SS2.p4.9.m8.1.1.3.cmml"><mi id="S3.SS2.p4.9.m8.1.1.3.2" xref="S3.SS2.p4.9.m8.1.1.3.2.cmml">D</mi><mn id="S3.SS2.p4.9.m8.1.1.3.3" xref="S3.SS2.p4.9.m8.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.9.m8.1b"><apply id="S3.SS2.p4.9.m8.1.1.cmml" xref="S3.SS2.p4.9.m8.1.1"><minus id="S3.SS2.p4.9.m8.1.1.1.cmml" xref="S3.SS2.p4.9.m8.1.1.1"></minus><ci id="S3.SS2.p4.9.m8.1.1.2.cmml" xref="S3.SS2.p4.9.m8.1.1.2">ğ¼</ci><apply id="S3.SS2.p4.9.m8.1.1.3.cmml" xref="S3.SS2.p4.9.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.9.m8.1.1.3.1.cmml" xref="S3.SS2.p4.9.m8.1.1.3">subscript</csymbol><ci id="S3.SS2.p4.9.m8.1.1.3.2.cmml" xref="S3.SS2.p4.9.m8.1.1.3.2">ğ·</ci><cn type="integer" id="S3.SS2.p4.9.m8.1.1.3.3.cmml" xref="S3.SS2.p4.9.m8.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.9.m8.1c">I-D_{1}</annotation></semantics></math>) to be similar
with its ground truth as much as possible.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<table id="S3.F3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.F3.1.1" class="ltx_tr">
<td id="S3.F3.1.1.1" class="ltx_td ltx_align_center"><span id="S3.F3.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/fig_env.png" id="S3.F3.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="296" height="92" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Example environment maps for our rendering. Top:
indoor scenes. Bottom: outdoor scenes.
</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure">
<table id="S3.F4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.F4.1.1" class="ltx_tr">
<td id="S3.F4.1.1.1" class="ltx_td ltx_align_center"><span id="S3.F4.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x3.png" id="S3.F4.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="228" height="106" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Example image groups in our dataset. (a) Input. (b) Albedo.
(c) Shading. (d) Specular residue. (e) Ground truth. (f) Tone
correction version of (e).</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Specular-Free Refinement</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The first stage, PSHR, has two drawbacks. First, it tends to overly
remove specular highlights and produce visual artifacts such as color
distortion and black color block; see
FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 Specular-Free Refinement â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(b). Second, the estimation of
specular-free image by Eq.Â (<a href="#S3.E2" title="In 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) in low dynamic
range has a certain amount of error, while that in high dynamic range
is correct and accurate. In our dataset, the rendering of shading and
specular residue images, as well as the estimation of specular-free
and specular highlight images, is carried out in high dynamic range.
And all generated images are converted to be of low dynamic range for
network training.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.2" class="ltx_p">To overcome the above issues, we propose the Specular-free Refinement
stage (SR) to further refine the result from PSHR.
FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(b) illustrates the mechanism of SR. As
shown, the coarse specular-free image, along with the input, is fed
into an encoder-decoder network (<math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="E_{r}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">E</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">ğ¸</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">E_{r}</annotation></semantics></math>-<math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="D_{r}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">D</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ğ·</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">D_{r}</annotation></semantics></math>) to produce a refined
result. Compared to PSHR, SR is able to produce better results in
terms of detail preserving and natural appearances; see
FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 Specular-Free Refinement â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(c). Furthermore, the histogram
comparisons of FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 Specular-Free Refinement â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(e)(f) also validate the
performance improvement. As shown, compared to the coarse result, the
intensity distribution of the refined result is more consistent with
that of the input image over the non-highlight region.</p>
</div>
<figure id="S3.F5" class="ltx_figure">
<table id="S3.F5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.F5.1.1" class="ltx_tr">
<td id="S3.F5.1.1.1" class="ltx_td ltx_align_center"><span id="S3.F5.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x4.png" id="S3.F5.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="228" height="132" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Ablation study that demonstrates the effectiveness of each
stage in our framework. (a) Input. (b)-(d) Resulting specular-free
images produced by the first, second, and third stages in our
framework, respectively. (e)-(f) Histogram comparison between (a)
and (b)-(d), respectively. Note that the abscissa and ordinate
axes indicate the pixel intensity value and the ratio of the
number of target pixels and the total number of pixels in an image.</figcaption>
</figure>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Loss Function</span>. The loss for
specular-free refinement <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{SR}}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msup id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">â„’</mi><mtext id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3a.cmml">SR</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">â„’</ci><ci id="S3.SS3.p3.1.m1.1.1.3a.cmml" xref="S3.SS3.p3.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">SR</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathcal{L}^{\text{SR}}</annotation></semantics></math> is defined as</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{SR}}=||D_{2}-\hat{D}||^{2}\,," display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><msup id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml">â„’</mi><mtext id="S3.E5.m1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.3.3a.cmml">SR</mtext></msup><mo id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml">=</mo><msup id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml">D</mi><mn id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml">2</mn></msub><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mover accent="true" id="S3.E5.m1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml">D</mi><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S3.E5.m1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"></eq><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2">â„’</ci><ci id="S3.E5.m1.1.1.1.1.3.3a.cmml" xref="S3.E5.m1.1.1.1.1.3.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3">SR</mtext></ci></apply><apply id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1"><minus id="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2">ğ·</ci><cn type="integer" id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3">2</cn></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3"><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.1">^</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2">ğ·</ci></apply></apply></apply><cn type="integer" id="S3.E5.m1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\mathcal{L}^{\text{SR}}=||D_{2}-\hat{D}||^{2}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.3" class="ltx_p">where <math id="S3.SS3.p3.2.m1.1" class="ltx_Math" alttext="D_{2}" display="inline"><semantics id="S3.SS3.p3.2.m1.1a"><msub id="S3.SS3.p3.2.m1.1.1" xref="S3.SS3.p3.2.m1.1.1.cmml"><mi id="S3.SS3.p3.2.m1.1.1.2" xref="S3.SS3.p3.2.m1.1.1.2.cmml">D</mi><mn id="S3.SS3.p3.2.m1.1.1.3" xref="S3.SS3.p3.2.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m1.1b"><apply id="S3.SS3.p3.2.m1.1.1.cmml" xref="S3.SS3.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m1.1.1.1.cmml" xref="S3.SS3.p3.2.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m1.1.1.2.cmml" xref="S3.SS3.p3.2.m1.1.1.2">ğ·</ci><cn type="integer" id="S3.SS3.p3.2.m1.1.1.3.cmml" xref="S3.SS3.p3.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m1.1c">D_{2}</annotation></semantics></math> and <math id="S3.SS3.p3.3.m2.1" class="ltx_Math" alttext="\hat{D}" display="inline"><semantics id="S3.SS3.p3.3.m2.1a"><mover accent="true" id="S3.SS3.p3.3.m2.1.1" xref="S3.SS3.p3.3.m2.1.1.cmml"><mi id="S3.SS3.p3.3.m2.1.1.2" xref="S3.SS3.p3.3.m2.1.1.2.cmml">D</mi><mo id="S3.SS3.p3.3.m2.1.1.1" xref="S3.SS3.p3.3.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m2.1b"><apply id="S3.SS3.p3.3.m2.1.1.cmml" xref="S3.SS3.p3.3.m2.1.1"><ci id="S3.SS3.p3.3.m2.1.1.1.cmml" xref="S3.SS3.p3.3.m2.1.1.1">^</ci><ci id="S3.SS3.p3.3.m2.1.1.2.cmml" xref="S3.SS3.p3.3.m2.1.1.2">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m2.1c">\hat{D}</annotation></semantics></math> are the refined specular-free image and
its ground truth, respectively.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Tone Correction</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.2" class="ltx_p">Although the specular-free image from PSHR is further refined by SR,
its overall tone is sometimes noticeably different from the input, and
thus looks somewhat unreal; see FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 Specular-Free Refinement â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>(c). The
main reason is that the specular-free images in our training data are
of slightly lower brightness than the input images, due to the
inherent defect of software rendering; see FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
To overcome this issue, we propose the Tone Correction stage (TC) to
adjust the tone of the refined result to match that of the input as
closely as possible. FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.2 Physics-Based Specular Highlight Removal â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(c) illustrates the
mechanism of TC. As shown, the refined result, along with the input
and specular residue images, is fed into an encoder-decoder network
(<math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="E_{c}" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">E</mi><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">ğ¸</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">E_{c}</annotation></semantics></math>-<math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="D_{c}" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><msub id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">D</mi><mi id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">ğ·</ci><ci id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">D_{c}</annotation></semantics></math>) to produce a tone-corrected result.
FigureÂ <a href="#S3.F5" title="Figure 5 â€£ 3.3 Specular-Free Refinement â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> validate the effectiveness of TC in
terms of tone preservation. From it, we can see that the overall tone
of the tone-corrected result by TC is significantly closer to that of
the input than the results by PSHR and SR.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.9" class="ltx_p">The key idea of TC is to correct the tone of the ground truth
specular-free images in our dataset as new supervisions for network
training. FigureÂ <a href="#S3.F6" title="Figure 6 â€£ 3.4 Tone Correction â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates this
mechanism. Formally, given an input image <math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><mi id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">I</annotation></semantics></math>, and its ground truth
specular-free image <math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="\hat{D}" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><mover accent="true" id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><mi id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml">D</mi><mo id="S3.SS4.p2.2.m2.1.1.1" xref="S3.SS4.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><ci id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1.1">^</ci><ci id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">\hat{D}</annotation></semantics></math> and specular residue image <math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="\hat{R}" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><mover accent="true" id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><mi id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml">R</mi><mo id="S3.SS4.p2.3.m3.1.1.1" xref="S3.SS4.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><ci id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1.1">^</ci><ci id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2">ğ‘…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">\hat{R}</annotation></semantics></math>, we first use
Otsuâ€™s method on <math id="S3.SS4.p2.4.m4.1" class="ltx_Math" alttext="\hat{R}" display="inline"><semantics id="S3.SS4.p2.4.m4.1a"><mover accent="true" id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml"><mi id="S3.SS4.p2.4.m4.1.1.2" xref="S3.SS4.p2.4.m4.1.1.2.cmml">R</mi><mo id="S3.SS4.p2.4.m4.1.1.1" xref="S3.SS4.p2.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><apply id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1"><ci id="S3.SS4.p2.4.m4.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1">^</ci><ci id="S3.SS4.p2.4.m4.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.2">ğ‘…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">\hat{R}</annotation></semantics></math> to separate all pixels of <math id="S3.SS4.p2.5.m5.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS4.p2.5.m5.1a"><mi id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><ci id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">I</annotation></semantics></math> into two types of
regions, specular highlight region <math id="S3.SS4.p2.6.m6.1" class="ltx_Math" alttext="M_{h}" display="inline"><semantics id="S3.SS4.p2.6.m6.1a"><msub id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml"><mi id="S3.SS4.p2.6.m6.1.1.2" xref="S3.SS4.p2.6.m6.1.1.2.cmml">M</mi><mi id="S3.SS4.p2.6.m6.1.1.3" xref="S3.SS4.p2.6.m6.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><apply id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.6.m6.1.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS4.p2.6.m6.1.1.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2">ğ‘€</ci><ci id="S3.SS4.p2.6.m6.1.1.3.cmml" xref="S3.SS4.p2.6.m6.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">M_{h}</annotation></semantics></math> and non-highlight region
<math id="S3.SS4.p2.7.m7.1" class="ltx_Math" alttext="M_{n}" display="inline"><semantics id="S3.SS4.p2.7.m7.1a"><msub id="S3.SS4.p2.7.m7.1.1" xref="S3.SS4.p2.7.m7.1.1.cmml"><mi id="S3.SS4.p2.7.m7.1.1.2" xref="S3.SS4.p2.7.m7.1.1.2.cmml">M</mi><mi id="S3.SS4.p2.7.m7.1.1.3" xref="S3.SS4.p2.7.m7.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m7.1b"><apply id="S3.SS4.p2.7.m7.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.7.m7.1.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS4.p2.7.m7.1.1.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2">ğ‘€</ci><ci id="S3.SS4.p2.7.m7.1.1.3.cmml" xref="S3.SS4.p2.7.m7.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m7.1c">M_{n}</annotation></semantics></math>. Then, we find tone correction function <math id="S3.SS4.p2.8.m8.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS4.p2.8.m8.1a"><mi id="S3.SS4.p2.8.m8.1.1" xref="S3.SS4.p2.8.m8.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.8.m8.1b"><ci id="S3.SS4.p2.8.m8.1.1.cmml" xref="S3.SS4.p2.8.m8.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.8.m8.1c">T</annotation></semantics></math> that minimizes the
tone correction error <math id="S3.SS4.p2.9.m9.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS4.p2.9.m9.1a"><mi id="S3.SS4.p2.9.m9.1.1" xref="S3.SS4.p2.9.m9.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.9.m9.1b"><ci id="S3.SS4.p2.9.m9.1.1.cmml" xref="S3.SS4.p2.9.m9.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.9.m9.1c">E</annotation></semantics></math> between the specular-free and input images
over the non-highlight region:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.2" class="ltx_Math" alttext="E=|T(\hat{D})-I|_{\Omega_{M_{n}}}^{2}\,," display="block"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1" xref="S3.E6.m1.2.2.1.1.cmml"><mi id="S3.E6.m1.2.2.1.1.3" xref="S3.E6.m1.2.2.1.1.3.cmml">E</mi><mo id="S3.E6.m1.2.2.1.1.2" xref="S3.E6.m1.2.2.1.1.2.cmml">=</mo><msubsup id="S3.E6.m1.2.2.1.1.1" xref="S3.E6.m1.2.2.1.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3.2" xref="S3.E6.m1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3.2.1" xref="S3.E6.m1.1.1.cmml">(</mo><mover accent="true" id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><mi id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml">D</mi><mo id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E6.m1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml">I</mi></mrow><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.2.1.cmml">|</mo></mrow><msub id="S3.E6.m1.2.2.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E6.m1.2.2.1.1.1.1.3.2" xref="S3.E6.m1.2.2.1.1.1.1.3.2.cmml">Î©</mi><msub id="S3.E6.m1.2.2.1.1.1.1.3.3" xref="S3.E6.m1.2.2.1.1.1.1.3.3.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.3.3.2" xref="S3.E6.m1.2.2.1.1.1.1.3.3.2.cmml">M</mi><mi id="S3.E6.m1.2.2.1.1.1.1.3.3.3" xref="S3.E6.m1.2.2.1.1.1.1.3.3.3.cmml">n</mi></msub></msub><mn id="S3.E6.m1.2.2.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S3.E6.m1.2.2.1.2" xref="S3.E6.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.2.1.1.cmml" xref="S3.E6.m1.2.2.1"><eq id="S3.E6.m1.2.2.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.2"></eq><ci id="S3.E6.m1.2.2.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.3">ğ¸</ci><apply id="S3.E6.m1.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.E6.m1.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1">subscript</csymbol><apply id="S3.E6.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1"><abs id="S3.E6.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.2"></abs><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1"><minus id="S3.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.1"></minus><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2"><times id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.1"></times><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.2">ğ‘‡</ci><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.3.2"><ci id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1">^</ci><ci id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2">ğ·</ci></apply></apply><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3">ğ¼</ci></apply></apply><apply id="S3.E6.m1.2.2.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.2">Î©</ci><apply id="S3.E6.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.3.2">ğ‘€</ci><ci id="S3.E6.m1.2.2.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.3.3">ğ‘›</ci></apply></apply></apply><cn type="integer" id="S3.E6.m1.2.2.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">E=|T(\hat{D})-I|_{\Omega_{M_{n}}}^{2}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p2.12" class="ltx_p">where <math id="S3.SS4.p2.10.m1.1" class="ltx_Math" alttext="\Omega_{M_{n}}" display="inline"><semantics id="S3.SS4.p2.10.m1.1a"><msub id="S3.SS4.p2.10.m1.1.1" xref="S3.SS4.p2.10.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS4.p2.10.m1.1.1.2" xref="S3.SS4.p2.10.m1.1.1.2.cmml">Î©</mi><msub id="S3.SS4.p2.10.m1.1.1.3" xref="S3.SS4.p2.10.m1.1.1.3.cmml"><mi id="S3.SS4.p2.10.m1.1.1.3.2" xref="S3.SS4.p2.10.m1.1.1.3.2.cmml">M</mi><mi id="S3.SS4.p2.10.m1.1.1.3.3" xref="S3.SS4.p2.10.m1.1.1.3.3.cmml">n</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.10.m1.1b"><apply id="S3.SS4.p2.10.m1.1.1.cmml" xref="S3.SS4.p2.10.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.10.m1.1.1.1.cmml" xref="S3.SS4.p2.10.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.10.m1.1.1.2.cmml" xref="S3.SS4.p2.10.m1.1.1.2">Î©</ci><apply id="S3.SS4.p2.10.m1.1.1.3.cmml" xref="S3.SS4.p2.10.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p2.10.m1.1.1.3.1.cmml" xref="S3.SS4.p2.10.m1.1.1.3">subscript</csymbol><ci id="S3.SS4.p2.10.m1.1.1.3.2.cmml" xref="S3.SS4.p2.10.m1.1.1.3.2">ğ‘€</ci><ci id="S3.SS4.p2.10.m1.1.1.3.3.cmml" xref="S3.SS4.p2.10.m1.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.10.m1.1c">\Omega_{M_{n}}</annotation></semantics></math> denotes all pixels of <math id="S3.SS4.p2.11.m2.1" class="ltx_Math" alttext="M_{n}" display="inline"><semantics id="S3.SS4.p2.11.m2.1a"><msub id="S3.SS4.p2.11.m2.1.1" xref="S3.SS4.p2.11.m2.1.1.cmml"><mi id="S3.SS4.p2.11.m2.1.1.2" xref="S3.SS4.p2.11.m2.1.1.2.cmml">M</mi><mi id="S3.SS4.p2.11.m2.1.1.3" xref="S3.SS4.p2.11.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.11.m2.1b"><apply id="S3.SS4.p2.11.m2.1.1.cmml" xref="S3.SS4.p2.11.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.11.m2.1.1.1.cmml" xref="S3.SS4.p2.11.m2.1.1">subscript</csymbol><ci id="S3.SS4.p2.11.m2.1.1.2.cmml" xref="S3.SS4.p2.11.m2.1.1.2">ğ‘€</ci><ci id="S3.SS4.p2.11.m2.1.1.3.cmml" xref="S3.SS4.p2.11.m2.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.11.m2.1c">M_{n}</annotation></semantics></math>.
We formulate <math id="S3.SS4.p2.12.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS4.p2.12.m3.1a"><mi id="S3.SS4.p2.12.m3.1.1" xref="S3.SS4.p2.12.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.12.m3.1b"><ci id="S3.SS4.p2.12.m3.1.1.cmml" xref="S3.SS4.p2.12.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.12.m3.1c">T</annotation></semantics></math> as the following linear transformation:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="T=\mathbf{M}\ast(p_{h}\ \ p_{s}\ \ p_{v}\ \ 1)^{\prime}\,," display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.5" xref="S3.E7.m1.1.1.1.1.5.cmml">T</mi><mo id="S3.E7.m1.1.1.1.1.4" xref="S3.E7.m1.1.1.1.1.4.cmml">=</mo><mrow id="S3.E7.m1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.5" xref="S3.E7.m1.1.1.1.1.3.5.cmml">ğŒ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E7.m1.1.1.1.1.3.4" xref="S3.E7.m1.1.1.1.1.3.4.cmml">âˆ—</mo><msup id="S3.E7.m1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.3.3.cmml"><mrow id="S3.E7.m1.1.1.1.1.3.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.4.cmml"><mo stretchy="false" id="S3.E7.m1.1.1.1.1.3.3.3.3.4" xref="S3.E7.m1.1.1.1.1.3.3.3.4.cmml">(</mo><msub id="S3.E7.m1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.E7.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml">h</mi></msub><mspace width="1em" id="S3.E7.m1.1.1.1.1.3.3.3.3.5" xref="S3.E7.m1.1.1.1.1.3.3.3.4.cmml"></mspace><msub id="S3.E7.m1.1.1.1.1.2.2.2.2.2" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E7.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.cmml">p</mi><mi id="S3.E7.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.3.cmml">s</mi></msub><mspace width="1em" id="S3.E7.m1.1.1.1.1.3.3.3.3.6" xref="S3.E7.m1.1.1.1.1.3.3.3.4.cmml"></mspace><mrow id="S3.E7.m1.1.1.1.1.3.3.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.cmml"><msub id="S3.E7.m1.1.1.1.1.3.3.3.3.3.2" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.cmml"><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.2" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.2.cmml">p</mi><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.3" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.3.3.3.1" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.1.cmml">â€‹</mo><mn id="S3.E7.m1.1.1.1.1.3.3.3.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.3.cmml">  1</mn></mrow><mo stretchy="false" id="S3.E7.m1.1.1.1.1.3.3.3.3.7" xref="S3.E7.m1.1.1.1.1.3.3.3.4.cmml">)</mo></mrow><mo id="S3.E7.m1.1.1.1.1.3.3.5" xref="S3.E7.m1.1.1.1.1.3.3.5.cmml">â€²</mo></msup></mrow></mrow><mo id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><eq id="S3.E7.m1.1.1.1.1.4.cmml" xref="S3.E7.m1.1.1.1.1.4"></eq><ci id="S3.E7.m1.1.1.1.1.5.cmml" xref="S3.E7.m1.1.1.1.1.5">ğ‘‡</ci><apply id="S3.E7.m1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.3"><ci id="S3.E7.m1.1.1.1.1.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.4">âˆ—</ci><ci id="S3.E7.m1.1.1.1.1.3.5.cmml" xref="S3.E7.m1.1.1.1.1.3.5">ğŒ</ci><apply id="S3.E7.m1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.3">superscript</csymbol><list id="S3.E7.m1.1.1.1.1.3.3.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3"><apply id="S3.E7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1.1.1.3">â„</ci></apply><apply id="S3.E7.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.2">ğ‘</ci><ci id="S3.E7.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E7.m1.1.1.1.1.2.2.2.2.2.3">ğ‘ </ci></apply><apply id="S3.E7.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3"><times id="S3.E7.m1.1.1.1.1.3.3.3.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.1"></times><apply id="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.2">ğ‘</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.2.3">ğ‘£</ci></apply><cn type="integer" id="S3.E7.m1.1.1.1.1.3.3.3.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.3">1</cn></apply></list><ci id="S3.E7.m1.1.1.1.1.3.3.5.cmml" xref="S3.E7.m1.1.1.1.1.3.3.5">â€²</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">T=\mathbf{M}\ast(p_{h}\ \ p_{s}\ \ p_{v}\ \ 1)^{\prime}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p2.21" class="ltx_p">where <math id="S3.SS4.p2.13.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS4.p2.13.m1.1a"><mi id="S3.SS4.p2.13.m1.1.1" xref="S3.SS4.p2.13.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.13.m1.1b"><ci id="S3.SS4.p2.13.m1.1.1.cmml" xref="S3.SS4.p2.13.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.13.m1.1c">p</annotation></semantics></math> denotes a pixel in <math id="S3.SS4.p2.14.m2.1" class="ltx_Math" alttext="\hat{D}" display="inline"><semantics id="S3.SS4.p2.14.m2.1a"><mover accent="true" id="S3.SS4.p2.14.m2.1.1" xref="S3.SS4.p2.14.m2.1.1.cmml"><mi id="S3.SS4.p2.14.m2.1.1.2" xref="S3.SS4.p2.14.m2.1.1.2.cmml">D</mi><mo id="S3.SS4.p2.14.m2.1.1.1" xref="S3.SS4.p2.14.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.14.m2.1b"><apply id="S3.SS4.p2.14.m2.1.1.cmml" xref="S3.SS4.p2.14.m2.1.1"><ci id="S3.SS4.p2.14.m2.1.1.1.cmml" xref="S3.SS4.p2.14.m2.1.1.1">^</ci><ci id="S3.SS4.p2.14.m2.1.1.2.cmml" xref="S3.SS4.p2.14.m2.1.1.2">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.14.m2.1c">\hat{D}</annotation></semantics></math>, whose intensity value in HSV
color space is <math id="S3.SS4.p2.15.m3.3" class="ltx_Math" alttext="(p_{h},p_{s},p_{v})" display="inline"><semantics id="S3.SS4.p2.15.m3.3a"><mrow id="S3.SS4.p2.15.m3.3.3.3" xref="S3.SS4.p2.15.m3.3.3.4.cmml"><mo stretchy="false" id="S3.SS4.p2.15.m3.3.3.3.4" xref="S3.SS4.p2.15.m3.3.3.4.cmml">(</mo><msub id="S3.SS4.p2.15.m3.1.1.1.1" xref="S3.SS4.p2.15.m3.1.1.1.1.cmml"><mi id="S3.SS4.p2.15.m3.1.1.1.1.2" xref="S3.SS4.p2.15.m3.1.1.1.1.2.cmml">p</mi><mi id="S3.SS4.p2.15.m3.1.1.1.1.3" xref="S3.SS4.p2.15.m3.1.1.1.1.3.cmml">h</mi></msub><mo id="S3.SS4.p2.15.m3.3.3.3.5" xref="S3.SS4.p2.15.m3.3.3.4.cmml">,</mo><msub id="S3.SS4.p2.15.m3.2.2.2.2" xref="S3.SS4.p2.15.m3.2.2.2.2.cmml"><mi id="S3.SS4.p2.15.m3.2.2.2.2.2" xref="S3.SS4.p2.15.m3.2.2.2.2.2.cmml">p</mi><mi id="S3.SS4.p2.15.m3.2.2.2.2.3" xref="S3.SS4.p2.15.m3.2.2.2.2.3.cmml">s</mi></msub><mo id="S3.SS4.p2.15.m3.3.3.3.6" xref="S3.SS4.p2.15.m3.3.3.4.cmml">,</mo><msub id="S3.SS4.p2.15.m3.3.3.3.3" xref="S3.SS4.p2.15.m3.3.3.3.3.cmml"><mi id="S3.SS4.p2.15.m3.3.3.3.3.2" xref="S3.SS4.p2.15.m3.3.3.3.3.2.cmml">p</mi><mi id="S3.SS4.p2.15.m3.3.3.3.3.3" xref="S3.SS4.p2.15.m3.3.3.3.3.3.cmml">v</mi></msub><mo stretchy="false" id="S3.SS4.p2.15.m3.3.3.3.7" xref="S3.SS4.p2.15.m3.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.15.m3.3b"><vector id="S3.SS4.p2.15.m3.3.3.4.cmml" xref="S3.SS4.p2.15.m3.3.3.3"><apply id="S3.SS4.p2.15.m3.1.1.1.1.cmml" xref="S3.SS4.p2.15.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.15.m3.1.1.1.1.1.cmml" xref="S3.SS4.p2.15.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p2.15.m3.1.1.1.1.2.cmml" xref="S3.SS4.p2.15.m3.1.1.1.1.2">ğ‘</ci><ci id="S3.SS4.p2.15.m3.1.1.1.1.3.cmml" xref="S3.SS4.p2.15.m3.1.1.1.1.3">â„</ci></apply><apply id="S3.SS4.p2.15.m3.2.2.2.2.cmml" xref="S3.SS4.p2.15.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p2.15.m3.2.2.2.2.1.cmml" xref="S3.SS4.p2.15.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS4.p2.15.m3.2.2.2.2.2.cmml" xref="S3.SS4.p2.15.m3.2.2.2.2.2">ğ‘</ci><ci id="S3.SS4.p2.15.m3.2.2.2.2.3.cmml" xref="S3.SS4.p2.15.m3.2.2.2.2.3">ğ‘ </ci></apply><apply id="S3.SS4.p2.15.m3.3.3.3.3.cmml" xref="S3.SS4.p2.15.m3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.p2.15.m3.3.3.3.3.1.cmml" xref="S3.SS4.p2.15.m3.3.3.3.3">subscript</csymbol><ci id="S3.SS4.p2.15.m3.3.3.3.3.2.cmml" xref="S3.SS4.p2.15.m3.3.3.3.3.2">ğ‘</ci><ci id="S3.SS4.p2.15.m3.3.3.3.3.3.cmml" xref="S3.SS4.p2.15.m3.3.3.3.3.3">ğ‘£</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.15.m3.3c">(p_{h},p_{s},p_{v})</annotation></semantics></math>; <span id="S3.SS4.p2.21.1" class="ltx_text ltx_markedasmath ltx_font_bold">M</span> is a <math id="S3.SS4.p2.17.m5.1" class="ltx_Math" alttext="3\times 4" display="inline"><semantics id="S3.SS4.p2.17.m5.1a"><mrow id="S3.SS4.p2.17.m5.1.1" xref="S3.SS4.p2.17.m5.1.1.cmml"><mn id="S3.SS4.p2.17.m5.1.1.2" xref="S3.SS4.p2.17.m5.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p2.17.m5.1.1.1" xref="S3.SS4.p2.17.m5.1.1.1.cmml">Ã—</mo><mn id="S3.SS4.p2.17.m5.1.1.3" xref="S3.SS4.p2.17.m5.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.17.m5.1b"><apply id="S3.SS4.p2.17.m5.1.1.cmml" xref="S3.SS4.p2.17.m5.1.1"><times id="S3.SS4.p2.17.m5.1.1.1.cmml" xref="S3.SS4.p2.17.m5.1.1.1"></times><cn type="integer" id="S3.SS4.p2.17.m5.1.1.2.cmml" xref="S3.SS4.p2.17.m5.1.1.2">3</cn><cn type="integer" id="S3.SS4.p2.17.m5.1.1.3.cmml" xref="S3.SS4.p2.17.m5.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.17.m5.1c">3\times 4</annotation></semantics></math> matrix
which stores the parameters in the tone correction function; <math id="S3.SS4.p2.18.m6.1" class="ltx_Math" alttext="\ast" display="inline"><semantics id="S3.SS4.p2.18.m6.1a"><mo id="S3.SS4.p2.18.m6.1.1" xref="S3.SS4.p2.18.m6.1.1.cmml">âˆ—</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.18.m6.1b"><ci id="S3.SS4.p2.18.m6.1.1.cmml" xref="S3.SS4.p2.18.m6.1.1">âˆ—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.18.m6.1c">\ast</annotation></semantics></math>
denotes matrix multiplication; and <math id="S3.SS4.p2.19.m7.1" class="ltx_Math" alttext="(\cdot)^{\prime}" display="inline"><semantics id="S3.SS4.p2.19.m7.1a"><msup id="S3.SS4.p2.19.m7.1.2" xref="S3.SS4.p2.19.m7.1.2.cmml"><mrow id="S3.SS4.p2.19.m7.1.2.2.2" xref="S3.SS4.p2.19.m7.1.2.cmml"><mo stretchy="false" id="S3.SS4.p2.19.m7.1.2.2.2.1" xref="S3.SS4.p2.19.m7.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS4.p2.19.m7.1.1" xref="S3.SS4.p2.19.m7.1.1.cmml">â‹…</mo><mo stretchy="false" id="S3.SS4.p2.19.m7.1.2.2.2.2" xref="S3.SS4.p2.19.m7.1.2.cmml">)</mo></mrow><mo id="S3.SS4.p2.19.m7.1.2.3" xref="S3.SS4.p2.19.m7.1.2.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.19.m7.1b"><apply id="S3.SS4.p2.19.m7.1.2.cmml" xref="S3.SS4.p2.19.m7.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.19.m7.1.2.1.cmml" xref="S3.SS4.p2.19.m7.1.2">superscript</csymbol><ci id="S3.SS4.p2.19.m7.1.1.cmml" xref="S3.SS4.p2.19.m7.1.1">â‹…</ci><ci id="S3.SS4.p2.19.m7.1.2.3.cmml" xref="S3.SS4.p2.19.m7.1.2.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.19.m7.1c">(\cdot)^{\prime}</annotation></semantics></math> denotes matrix transpose.
The above operation in HSV instead of RGB benefits obtaining a robust
solution, because specular highlights mainly cause variations in the
saturation and value channels. We can solve the problem in
Eq.Â (<a href="#S3.E6" title="In 3.4 Tone Correction â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) using the least-squares
method. Finally, we utilize <math id="S3.SS4.p2.20.m8.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS4.p2.20.m8.1a"><mi id="S3.SS4.p2.20.m8.1.1" xref="S3.SS4.p2.20.m8.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.20.m8.1b"><ci id="S3.SS4.p2.20.m8.1.1.cmml" xref="S3.SS4.p2.20.m8.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.20.m8.1c">T</annotation></semantics></math> to correct all pixels of <math id="S3.SS4.p2.21.m9.1" class="ltx_Math" alttext="\hat{D}" display="inline"><semantics id="S3.SS4.p2.21.m9.1a"><mover accent="true" id="S3.SS4.p2.21.m9.1.1" xref="S3.SS4.p2.21.m9.1.1.cmml"><mi id="S3.SS4.p2.21.m9.1.1.2" xref="S3.SS4.p2.21.m9.1.1.2.cmml">D</mi><mo id="S3.SS4.p2.21.m9.1.1.1" xref="S3.SS4.p2.21.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.21.m9.1b"><apply id="S3.SS4.p2.21.m9.1.1.cmml" xref="S3.SS4.p2.21.m9.1.1"><ci id="S3.SS4.p2.21.m9.1.1.1.cmml" xref="S3.SS4.p2.21.m9.1.1.1">^</ci><ci id="S3.SS4.p2.21.m9.1.1.2.cmml" xref="S3.SS4.p2.21.m9.1.1.2">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.21.m9.1c">\hat{D}</annotation></semantics></math> for
each training group in our dataset, and use them as new supervisions
for network training.</p>
</div>
<figure id="S3.F6" class="ltx_figure">
<table id="S3.F6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.F6.1.1" class="ltx_tr">
<td id="S3.F6.1.1.1" class="ltx_td ltx_align_center"><span id="S3.F6.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x5.png" id="S3.F6.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="228" height="138" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Tone correction for ground truth specular-free images
in our dataset. (a) Input. (b) Ground truth specular-free
image. (c) Tone correction version of (b). (d) Specular highlight
mask of (a). (e) Histogram comparison between (a) and (b). (f)
Histogram comparison between (a) and (c). Note that the specular
highlight pixels are excluded using (d) for plotting histograms of
(a)-(c).</figcaption>
</figure>
<div id="S3.SS4.p3" class="ltx_para ltx_noindent">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_bold">Loss Function</span>. The loss for tone correction <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{TC}}" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><msup id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml">â„’</mi><mtext id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3a.cmml">TC</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2">â„’</ci><ci id="S3.SS4.p3.1.m1.1.1.3a.cmml" xref="S3.SS4.p3.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3">TC</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">\mathcal{L}^{\text{TC}}</annotation></semantics></math> is
defined as</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{TC}}=||D_{3}-\tilde{D}||^{2}\,," display="block"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><msup id="S3.E8.m1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.3.2.cmml">â„’</mi><mtext id="S3.E8.m1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.3.3a.cmml">TC</mtext></msup><mo id="S3.E8.m1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.2.cmml">=</mo><msup id="S3.E8.m1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2.2.cmml">D</mi><mn id="S3.E8.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2.3.cmml">3</mn></msub><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mover accent="true" id="S3.E8.m1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3.2.cmml">D</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3.1.cmml">~</mo></mover></mrow><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E8.m1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S3.E8.m1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><eq id="S3.E8.m1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.2"></eq><apply id="S3.E8.m1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.3.2">â„’</ci><ci id="S3.E8.m1.1.1.1.1.3.3a.cmml" xref="S3.E8.m1.1.1.1.1.3.3"><mtext mathsize="70%" id="S3.E8.m1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.3.3">TC</mtext></ci></apply><apply id="S3.E8.m1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.E8.m1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E8.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1"><minus id="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2.2">ğ·</ci><cn type="integer" id="S3.E8.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.2.3">3</cn></apply><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3"><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3.1">~</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.3.2">ğ·</ci></apply></apply></apply><cn type="integer" id="S3.E8.m1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\mathcal{L}^{\text{TC}}=||D_{3}-\tilde{D}||^{2}\,,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p3.3" class="ltx_p">where <math id="S3.SS4.p3.2.m1.1" class="ltx_Math" alttext="D_{3}" display="inline"><semantics id="S3.SS4.p3.2.m1.1a"><msub id="S3.SS4.p3.2.m1.1.1" xref="S3.SS4.p3.2.m1.1.1.cmml"><mi id="S3.SS4.p3.2.m1.1.1.2" xref="S3.SS4.p3.2.m1.1.1.2.cmml">D</mi><mn id="S3.SS4.p3.2.m1.1.1.3" xref="S3.SS4.p3.2.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m1.1b"><apply id="S3.SS4.p3.2.m1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m1.1.1.1.cmml" xref="S3.SS4.p3.2.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m1.1.1.2.cmml" xref="S3.SS4.p3.2.m1.1.1.2">ğ·</ci><cn type="integer" id="S3.SS4.p3.2.m1.1.1.3.cmml" xref="S3.SS4.p3.2.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m1.1c">D_{3}</annotation></semantics></math> and <math id="S3.SS4.p3.3.m2.1" class="ltx_Math" alttext="\tilde{D}" display="inline"><semantics id="S3.SS4.p3.3.m2.1a"><mover accent="true" id="S3.SS4.p3.3.m2.1.1" xref="S3.SS4.p3.3.m2.1.1.cmml"><mi id="S3.SS4.p3.3.m2.1.1.2" xref="S3.SS4.p3.3.m2.1.1.2.cmml">D</mi><mo id="S3.SS4.p3.3.m2.1.1.1" xref="S3.SS4.p3.3.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m2.1b"><apply id="S3.SS4.p3.3.m2.1.1.cmml" xref="S3.SS4.p3.3.m2.1.1"><ci id="S3.SS4.p3.3.m2.1.1.1.cmml" xref="S3.SS4.p3.3.m2.1.1.1">~</ci><ci id="S3.SS4.p3.3.m2.1.1.2.cmml" xref="S3.SS4.p3.3.m2.1.1.2">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m2.1c">\tilde{D}</annotation></semantics></math> are the tone-corrected specular-free
image and its ground truth, respectively.</p>
</div>
<figure id="S3.F7" class="ltx_figure">
<table id="S3.F7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.F7.1.1" class="ltx_tr">
<td id="S3.F7.1.1.1" class="ltx_td ltx_align_center"><span id="S3.F7.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x6.png" id="S3.F7.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="523" height="178" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Visual comparison of our method against state-of-the-art
methods on our synthetic testing images. (a)(g) Input. (b)(h) Yang
<span id="S3.F7.5.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. (c)(i) Fu <span id="S3.F7.6.2" class="ltx_text ltx_font_italic">et
al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. (d)(j) Wu <span id="S3.F7.7.3" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. (e)(k) Ours. (f)(l) Ground truth.</figcaption>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Network Training</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.4" class="ltx_p">The total loss <math id="S3.SS5.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS5.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><ci id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">\mathcal{L}</annotation></semantics></math> for the training of our whole network
includes <math id="S3.SS5.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}^{\text{PSHR}}" display="inline"><semantics id="S3.SS5.p1.2.m2.1a"><msup id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.2.m2.1.1.2" xref="S3.SS5.p1.2.m2.1.1.2.cmml">â„’</mi><mtext id="S3.SS5.p1.2.m2.1.1.3" xref="S3.SS5.p1.2.m2.1.1.3a.cmml">PSHR</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><apply id="S3.SS5.p1.2.m2.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS5.p1.2.m2.1.1.2.cmml" xref="S3.SS5.p1.2.m2.1.1.2">â„’</ci><ci id="S3.SS5.p1.2.m2.1.1.3a.cmml" xref="S3.SS5.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS5.p1.2.m2.1.1.3.cmml" xref="S3.SS5.p1.2.m2.1.1.3">PSHR</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">\mathcal{L}^{\text{PSHR}}</annotation></semantics></math>, <math id="S3.SS5.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}^{\text{SR}}" display="inline"><semantics id="S3.SS5.p1.3.m3.1a"><msup id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.3.m3.1.1.2" xref="S3.SS5.p1.3.m3.1.1.2.cmml">â„’</mi><mtext id="S3.SS5.p1.3.m3.1.1.3" xref="S3.SS5.p1.3.m3.1.1.3a.cmml">SR</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b"><apply id="S3.SS5.p1.3.m3.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.3.m3.1.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS5.p1.3.m3.1.1.2.cmml" xref="S3.SS5.p1.3.m3.1.1.2">â„’</ci><ci id="S3.SS5.p1.3.m3.1.1.3a.cmml" xref="S3.SS5.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S3.SS5.p1.3.m3.1.1.3.cmml" xref="S3.SS5.p1.3.m3.1.1.3">SR</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">\mathcal{L}^{\text{SR}}</annotation></semantics></math>, and
<math id="S3.SS5.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{L}^{\text{TC}}" display="inline"><semantics id="S3.SS5.p1.4.m4.1a"><msup id="S3.SS5.p1.4.m4.1.1" xref="S3.SS5.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.p1.4.m4.1.1.2" xref="S3.SS5.p1.4.m4.1.1.2.cmml">â„’</mi><mtext id="S3.SS5.p1.4.m4.1.1.3" xref="S3.SS5.p1.4.m4.1.1.3a.cmml">TC</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.4.m4.1b"><apply id="S3.SS5.p1.4.m4.1.1.cmml" xref="S3.SS5.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.4.m4.1.1.1.cmml" xref="S3.SS5.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS5.p1.4.m4.1.1.2.cmml" xref="S3.SS5.p1.4.m4.1.1.2">â„’</ci><ci id="S3.SS5.p1.4.m4.1.1.3a.cmml" xref="S3.SS5.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS5.p1.4.m4.1.1.3.cmml" xref="S3.SS5.p1.4.m4.1.1.3">TC</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.4.m4.1c">\mathcal{L}^{\text{TC}}</annotation></semantics></math>, written as</p>
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E9.m1.1" class="ltx_Math" alttext="\mathcal{L}=\lambda_{1}\mathcal{L}^{\text{PSHR}}+\lambda_{2}\mathcal{L}^{\text{SR}}+\lambda_{3}\mathcal{L}^{\text{TC}}\,." display="block"><semantics id="S3.E9.m1.1a"><mrow id="S3.E9.m1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><mrow id="S3.E9.m1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E9.m1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.cmml">â„’</mi><mo id="S3.E9.m1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E9.m1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.3.cmml"><mrow id="S3.E9.m1.1.1.1.1.3.2" xref="S3.E9.m1.1.1.1.1.3.2.cmml"><msub id="S3.E9.m1.1.1.1.1.3.2.2" xref="S3.E9.m1.1.1.1.1.3.2.2.cmml"><mi id="S3.E9.m1.1.1.1.1.3.2.2.2" xref="S3.E9.m1.1.1.1.1.3.2.2.2.cmml">Î»</mi><mn id="S3.E9.m1.1.1.1.1.3.2.2.3" xref="S3.E9.m1.1.1.1.1.3.2.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.3.2.1" xref="S3.E9.m1.1.1.1.1.3.2.1.cmml">â€‹</mo><msup id="S3.E9.m1.1.1.1.1.3.2.3" xref="S3.E9.m1.1.1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E9.m1.1.1.1.1.3.2.3.2" xref="S3.E9.m1.1.1.1.1.3.2.3.2.cmml">â„’</mi><mtext id="S3.E9.m1.1.1.1.1.3.2.3.3" xref="S3.E9.m1.1.1.1.1.3.2.3.3a.cmml">PSHR</mtext></msup></mrow><mo id="S3.E9.m1.1.1.1.1.3.1" xref="S3.E9.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E9.m1.1.1.1.1.3.3" xref="S3.E9.m1.1.1.1.1.3.3.cmml"><msub id="S3.E9.m1.1.1.1.1.3.3.2" xref="S3.E9.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E9.m1.1.1.1.1.3.3.2.2" xref="S3.E9.m1.1.1.1.1.3.3.2.2.cmml">Î»</mi><mn id="S3.E9.m1.1.1.1.1.3.3.2.3" xref="S3.E9.m1.1.1.1.1.3.3.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.3.3.1" xref="S3.E9.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><msup id="S3.E9.m1.1.1.1.1.3.3.3" xref="S3.E9.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E9.m1.1.1.1.1.3.3.3.2" xref="S3.E9.m1.1.1.1.1.3.3.3.2.cmml">â„’</mi><mtext id="S3.E9.m1.1.1.1.1.3.3.3.3" xref="S3.E9.m1.1.1.1.1.3.3.3.3a.cmml">SR</mtext></msup></mrow><mo id="S3.E9.m1.1.1.1.1.3.1a" xref="S3.E9.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E9.m1.1.1.1.1.3.4" xref="S3.E9.m1.1.1.1.1.3.4.cmml"><msub id="S3.E9.m1.1.1.1.1.3.4.2" xref="S3.E9.m1.1.1.1.1.3.4.2.cmml"><mi id="S3.E9.m1.1.1.1.1.3.4.2.2" xref="S3.E9.m1.1.1.1.1.3.4.2.2.cmml">Î»</mi><mn id="S3.E9.m1.1.1.1.1.3.4.2.3" xref="S3.E9.m1.1.1.1.1.3.4.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.3.4.1" xref="S3.E9.m1.1.1.1.1.3.4.1.cmml">â€‹</mo><msup id="S3.E9.m1.1.1.1.1.3.4.3" xref="S3.E9.m1.1.1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E9.m1.1.1.1.1.3.4.3.2" xref="S3.E9.m1.1.1.1.1.3.4.3.2.cmml">â„’</mi><mtext id="S3.E9.m1.1.1.1.1.3.4.3.3" xref="S3.E9.m1.1.1.1.1.3.4.3.3a.cmml">TC</mtext></msup></mrow></mrow></mrow><mo lspace="0em" id="S3.E9.m1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.1b"><apply id="S3.E9.m1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1"><eq id="S3.E9.m1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1"></eq><ci id="S3.E9.m1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.2">â„’</ci><apply id="S3.E9.m1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.3"><plus id="S3.E9.m1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.1.1.3.1"></plus><apply id="S3.E9.m1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.1.1.3.2"><times id="S3.E9.m1.1.1.1.1.3.2.1.cmml" xref="S3.E9.m1.1.1.1.1.3.2.1"></times><apply id="S3.E9.m1.1.1.1.1.3.2.2.cmml" xref="S3.E9.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.3.2.2.1.cmml" xref="S3.E9.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.3.2.2.2.cmml" xref="S3.E9.m1.1.1.1.1.3.2.2.2">ğœ†</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.3.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.3.2.2.3">1</cn></apply><apply id="S3.E9.m1.1.1.1.1.3.2.3.cmml" xref="S3.E9.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E9.m1.1.1.1.1.3.2.3">superscript</csymbol><ci id="S3.E9.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E9.m1.1.1.1.1.3.2.3.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.3.2.3.3a.cmml" xref="S3.E9.m1.1.1.1.1.3.2.3.3"><mtext mathsize="70%" id="S3.E9.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E9.m1.1.1.1.1.3.2.3.3">PSHR</mtext></ci></apply></apply><apply id="S3.E9.m1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.1.1.3.3"><times id="S3.E9.m1.1.1.1.1.3.3.1.cmml" xref="S3.E9.m1.1.1.1.1.3.3.1"></times><apply id="S3.E9.m1.1.1.1.1.3.3.2.cmml" xref="S3.E9.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E9.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E9.m1.1.1.1.1.3.3.2.2">ğœ†</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E9.m1.1.1.1.1.3.3.2.3">2</cn></apply><apply id="S3.E9.m1.1.1.1.1.3.3.3.cmml" xref="S3.E9.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E9.m1.1.1.1.1.3.3.3">superscript</csymbol><ci id="S3.E9.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E9.m1.1.1.1.1.3.3.3.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.3.3.3.3a.cmml" xref="S3.E9.m1.1.1.1.1.3.3.3.3"><mtext mathsize="70%" id="S3.E9.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E9.m1.1.1.1.1.3.3.3.3">SR</mtext></ci></apply></apply><apply id="S3.E9.m1.1.1.1.1.3.4.cmml" xref="S3.E9.m1.1.1.1.1.3.4"><times id="S3.E9.m1.1.1.1.1.3.4.1.cmml" xref="S3.E9.m1.1.1.1.1.3.4.1"></times><apply id="S3.E9.m1.1.1.1.1.3.4.2.cmml" xref="S3.E9.m1.1.1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.3.4.2.1.cmml" xref="S3.E9.m1.1.1.1.1.3.4.2">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.3.4.2.2.cmml" xref="S3.E9.m1.1.1.1.1.3.4.2.2">ğœ†</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.3.4.2.3.cmml" xref="S3.E9.m1.1.1.1.1.3.4.2.3">3</cn></apply><apply id="S3.E9.m1.1.1.1.1.3.4.3.cmml" xref="S3.E9.m1.1.1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.3.4.3.1.cmml" xref="S3.E9.m1.1.1.1.1.3.4.3">superscript</csymbol><ci id="S3.E9.m1.1.1.1.1.3.4.3.2.cmml" xref="S3.E9.m1.1.1.1.1.3.4.3.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.3.4.3.3a.cmml" xref="S3.E9.m1.1.1.1.1.3.4.3.3"><mtext mathsize="70%" id="S3.E9.m1.1.1.1.1.3.4.3.3.cmml" xref="S3.E9.m1.1.1.1.1.3.4.3.3">TC</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.1c">\mathcal{L}=\lambda_{1}\mathcal{L}^{\text{PSHR}}+\lambda_{2}\mathcal{L}^{\text{SR}}+\lambda_{3}\mathcal{L}^{\text{TC}}\,.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.SS5.p1.8" class="ltx_p">Here, <math id="S3.SS5.p1.5.m1.1" class="ltx_Math" alttext="\lambda_{1}" display="inline"><semantics id="S3.SS5.p1.5.m1.1a"><msub id="S3.SS5.p1.5.m1.1.1" xref="S3.SS5.p1.5.m1.1.1.cmml"><mi id="S3.SS5.p1.5.m1.1.1.2" xref="S3.SS5.p1.5.m1.1.1.2.cmml">Î»</mi><mn id="S3.SS5.p1.5.m1.1.1.3" xref="S3.SS5.p1.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.5.m1.1b"><apply id="S3.SS5.p1.5.m1.1.1.cmml" xref="S3.SS5.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.5.m1.1.1.1.cmml" xref="S3.SS5.p1.5.m1.1.1">subscript</csymbol><ci id="S3.SS5.p1.5.m1.1.1.2.cmml" xref="S3.SS5.p1.5.m1.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS5.p1.5.m1.1.1.3.cmml" xref="S3.SS5.p1.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.5.m1.1c">\lambda_{1}</annotation></semantics></math>, <math id="S3.SS5.p1.6.m2.1" class="ltx_Math" alttext="\lambda_{2}" display="inline"><semantics id="S3.SS5.p1.6.m2.1a"><msub id="S3.SS5.p1.6.m2.1.1" xref="S3.SS5.p1.6.m2.1.1.cmml"><mi id="S3.SS5.p1.6.m2.1.1.2" xref="S3.SS5.p1.6.m2.1.1.2.cmml">Î»</mi><mn id="S3.SS5.p1.6.m2.1.1.3" xref="S3.SS5.p1.6.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.6.m2.1b"><apply id="S3.SS5.p1.6.m2.1.1.cmml" xref="S3.SS5.p1.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.6.m2.1.1.1.cmml" xref="S3.SS5.p1.6.m2.1.1">subscript</csymbol><ci id="S3.SS5.p1.6.m2.1.1.2.cmml" xref="S3.SS5.p1.6.m2.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS5.p1.6.m2.1.1.3.cmml" xref="S3.SS5.p1.6.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.6.m2.1c">\lambda_{2}</annotation></semantics></math>, and <math id="S3.SS5.p1.7.m3.1" class="ltx_Math" alttext="\lambda_{3}" display="inline"><semantics id="S3.SS5.p1.7.m3.1a"><msub id="S3.SS5.p1.7.m3.1.1" xref="S3.SS5.p1.7.m3.1.1.cmml"><mi id="S3.SS5.p1.7.m3.1.1.2" xref="S3.SS5.p1.7.m3.1.1.2.cmml">Î»</mi><mn id="S3.SS5.p1.7.m3.1.1.3" xref="S3.SS5.p1.7.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.7.m3.1b"><apply id="S3.SS5.p1.7.m3.1.1.cmml" xref="S3.SS5.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.7.m3.1.1.1.cmml" xref="S3.SS5.p1.7.m3.1.1">subscript</csymbol><ci id="S3.SS5.p1.7.m3.1.1.2.cmml" xref="S3.SS5.p1.7.m3.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS5.p1.7.m3.1.1.3.cmml" xref="S3.SS5.p1.7.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.7.m3.1c">\lambda_{3}</annotation></semantics></math> are the weighting
balance parameters, which are experimentally set to <math id="S3.SS5.p1.8.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS5.p1.8.m4.1a"><mn id="S3.SS5.p1.8.m4.1.1" xref="S3.SS5.p1.8.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.8.m4.1b"><cn type="integer" id="S3.SS5.p1.8.m4.1.1.cmml" xref="S3.SS5.p1.8.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.8.m4.1c">1</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Implementation Details</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.3" class="ltx_p">The four encoder-decoder networks in our three-stage framework have
the same architecture. We adopt the U-Net architecture
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> as the default choice, known for its
conciseness and effectiveness. We implement our whole network in
PyTorch and train it for 60 epochs on a PC with NVIDIA GeForce GTX
3090Ti. The whole network is optimized using the Adam optimizer. The
initial learning rate is set to <math id="S3.SS6.p1.1.m1.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S3.SS6.p1.1.m1.1a"><mrow id="S3.SS6.p1.1.m1.1.1" xref="S3.SS6.p1.1.m1.1.1.cmml"><mn id="S3.SS6.p1.1.m1.1.1.2" xref="S3.SS6.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS6.p1.1.m1.1.1.1" xref="S3.SS6.p1.1.m1.1.1.1.cmml">Ã—</mo><msup id="S3.SS6.p1.1.m1.1.1.3" xref="S3.SS6.p1.1.m1.1.1.3.cmml"><mn id="S3.SS6.p1.1.m1.1.1.3.2" xref="S3.SS6.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S3.SS6.p1.1.m1.1.1.3.3" xref="S3.SS6.p1.1.m1.1.1.3.3.cmml"><mo id="S3.SS6.p1.1.m1.1.1.3.3a" xref="S3.SS6.p1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S3.SS6.p1.1.m1.1.1.3.3.2" xref="S3.SS6.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS6.p1.1.m1.1b"><apply id="S3.SS6.p1.1.m1.1.1.cmml" xref="S3.SS6.p1.1.m1.1.1"><times id="S3.SS6.p1.1.m1.1.1.1.cmml" xref="S3.SS6.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS6.p1.1.m1.1.1.2.cmml" xref="S3.SS6.p1.1.m1.1.1.2">1</cn><apply id="S3.SS6.p1.1.m1.1.1.3.cmml" xref="S3.SS6.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS6.p1.1.m1.1.1.3.1.cmml" xref="S3.SS6.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS6.p1.1.m1.1.1.3.2.cmml" xref="S3.SS6.p1.1.m1.1.1.3.2">10</cn><apply id="S3.SS6.p1.1.m1.1.1.3.3.cmml" xref="S3.SS6.p1.1.m1.1.1.3.3"><minus id="S3.SS6.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS6.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S3.SS6.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS6.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.p1.1.m1.1c">1\times 10^{-4}</annotation></semantics></math>, divided by <math id="S3.SS6.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS6.p1.2.m2.1a"><mn id="S3.SS6.p1.2.m2.1.1" xref="S3.SS6.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS6.p1.2.m2.1b"><cn type="integer" id="S3.SS6.p1.2.m2.1.1.cmml" xref="S3.SS6.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.p1.2.m2.1c">10</annotation></semantics></math>
after every 10 epochs, and the batch size is set to <math id="S3.SS6.p1.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S3.SS6.p1.3.m3.1a"><mn id="S3.SS6.p1.3.m3.1.1" xref="S3.SS6.p1.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.SS6.p1.3.m3.1b"><cn type="integer" id="S3.SS6.p1.3.m3.1.1.cmml" xref="S3.SS6.p1.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.p1.3.m3.1c">16</annotation></semantics></math>. Moreover, we
also adopt horizontal flip, and specular highlight attenuation and
boosting editing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> for data augmentation.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets and Evaluation Metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluate our network on three datasets, including our SSHR, SHIQ
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and PSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. We
adopt two commonly-used metrics (<span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, PSNR and SSIM) to
quantitatively evaluate the performance of our network, as in
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. In general, higher
PSNR and SSIM values indicate better results.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comparison with State-of-the-Art Methods</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We compare our method against four traditional methods
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and two recent deep
learning-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. For fair comparison, we produce removal
results for four traditional methods using publicly available
implementation provided by the authors with optimal parameter setting.
Besides, if necessary, we re-train two deep learning-based methods,
and fine-tune their key parameters to produce better results as much
as possible. We note that our network fails to be trained on SHIQ and
PSD, since they do not include ground truth intrinsic images. To
train and evaluate our network on them, we modify the
first stage of our method to estimate the specular-free and specular
residue instead of the original albedo and shading.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Quantitative Comparison</span>.
TablesÂ <a href="#S4.T1" title="Table 1 â€£ 4.2 Comparison with State-of-the-Art Methods â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> reports the quantitative
comparison result on three datasets. As shown, overall, our method
achieves higher PSNR and SSIM values,
indicating that our method is superior to state-of-the-art methods. In
addition, four traditional methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
achieve much higher PSNR and SSIM values on our synthetic dataset than
real SHIQ and PSD datasets. The reason is two-fold. First, these
methods are based on the dichromatic reflection model, and so does the
rendering of our synthetic dataset. As a result, they are capable of
addressing our synthetic images. Second, real specular highlights in
SHIQ and PSD may not be well characterized by an idealized image
formation model, while images in them are often with adverse factors
such as white material surfaces and heavy texture.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.5" class="ltx_p"><span id="S4.SS2.p3.5.1" class="ltx_text ltx_font_bold">Visual Comparison</span>.
FigureÂ <a href="#S3.F7" title="Figure 7 â€£ 3.4 Tone Correction â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> presents the visual comparison on
our testing images. We can see that for images with nearly white
material surfaces, traditional methods often produce unrealistic
results with severe visual artifacts such as color distortion (see the
<math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="4^{th}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><msup id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mn id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">4</mn><mrow id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml"><mi id="S4.SS2.p3.1.m1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.1.m1.1.1.3.1" xref="S4.SS2.p3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.1.m1.1.1.3.3" xref="S4.SS2.p3.1.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">4</cn><apply id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3"><times id="S4.SS2.p3.1.m1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3.1"></times><ci id="S4.SS2.p3.1.m1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.2">ğ‘¡</ci><ci id="S4.SS2.p3.1.m1.1.1.3.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">4^{th}</annotation></semantics></math> row in (b)) and black color block (see the <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="1^{st}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><msup id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mn id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">1</mn><mrow id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml"><mi id="S4.SS2.p3.2.m2.1.1.3.2" xref="S4.SS2.p3.2.m2.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.1.1.3.1" xref="S4.SS2.p3.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.2.m2.1.1.3.3" xref="S4.SS2.p3.2.m2.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">1</cn><apply id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3"><times id="S4.SS2.p3.2.m2.1.1.3.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3.1"></times><ci id="S4.SS2.p3.2.m2.1.1.3.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2">ğ‘ </ci><ci id="S4.SS2.p3.2.m2.1.1.3.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">1^{st}</annotation></semantics></math> row in
(h)). Although the deep learning-based method
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> is able to effectively remove specular
highlights and recover the missing details, it sometimes suffers from
color distortion artifacts (see the <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="4^{th}" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><msup id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml"><mn id="S4.SS2.p3.3.m3.1.1.2" xref="S4.SS2.p3.3.m3.1.1.2.cmml">4</mn><mrow id="S4.SS2.p3.3.m3.1.1.3" xref="S4.SS2.p3.3.m3.1.1.3.cmml"><mi id="S4.SS2.p3.3.m3.1.1.3.2" xref="S4.SS2.p3.3.m3.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.3.m3.1.1.3.1" xref="S4.SS2.p3.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.3.m3.1.1.3.3" xref="S4.SS2.p3.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><apply id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.3.m3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p3.3.m3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.1.1.2">4</cn><apply id="S4.SS2.p3.3.m3.1.1.3.cmml" xref="S4.SS2.p3.3.m3.1.1.3"><times id="S4.SS2.p3.3.m3.1.1.3.1.cmml" xref="S4.SS2.p3.3.m3.1.1.3.1"></times><ci id="S4.SS2.p3.3.m3.1.1.3.2.cmml" xref="S4.SS2.p3.3.m3.1.1.3.2">ğ‘¡</ci><ci id="S4.SS2.p3.3.m3.1.1.3.3.cmml" xref="S4.SS2.p3.3.m3.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">4^{th}</annotation></semantics></math> in (c)). Besides, the
deep learning method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> fails to effectively
remove specular highlights (see the <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="1^{st}" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><msup id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml"><mn id="S4.SS2.p3.4.m4.1.1.2" xref="S4.SS2.p3.4.m4.1.1.2.cmml">1</mn><mrow id="S4.SS2.p3.4.m4.1.1.3" xref="S4.SS2.p3.4.m4.1.1.3.cmml"><mi id="S4.SS2.p3.4.m4.1.1.3.2" xref="S4.SS2.p3.4.m4.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.4.m4.1.1.3.1" xref="S4.SS2.p3.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.4.m4.1.1.3.3" xref="S4.SS2.p3.4.m4.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><apply id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.4.m4.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p3.4.m4.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.2">1</cn><apply id="S4.SS2.p3.4.m4.1.1.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3"><times id="S4.SS2.p3.4.m4.1.1.3.1.cmml" xref="S4.SS2.p3.4.m4.1.1.3.1"></times><ci id="S4.SS2.p3.4.m4.1.1.3.2.cmml" xref="S4.SS2.p3.4.m4.1.1.3.2">ğ‘ </ci><ci id="S4.SS2.p3.4.m4.1.1.3.3.cmml" xref="S4.SS2.p3.4.m4.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">1^{st}</annotation></semantics></math> row in (d)), and may
produce unreasonable texture details (see the <math id="S4.SS2.p3.5.m5.1" class="ltx_Math" alttext="2^{nd}" display="inline"><semantics id="S4.SS2.p3.5.m5.1a"><msup id="S4.SS2.p3.5.m5.1.1" xref="S4.SS2.p3.5.m5.1.1.cmml"><mn id="S4.SS2.p3.5.m5.1.1.2" xref="S4.SS2.p3.5.m5.1.1.2.cmml">2</mn><mrow id="S4.SS2.p3.5.m5.1.1.3" xref="S4.SS2.p3.5.m5.1.1.3.cmml"><mi id="S4.SS2.p3.5.m5.1.1.3.2" xref="S4.SS2.p3.5.m5.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.5.m5.1.1.3.1" xref="S4.SS2.p3.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.p3.5.m5.1.1.3.3" xref="S4.SS2.p3.5.m5.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.1b"><apply id="S4.SS2.p3.5.m5.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.5.m5.1.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p3.5.m5.1.1.2.cmml" xref="S4.SS2.p3.5.m5.1.1.2">2</cn><apply id="S4.SS2.p3.5.m5.1.1.3.cmml" xref="S4.SS2.p3.5.m5.1.1.3"><times id="S4.SS2.p3.5.m5.1.1.3.1.cmml" xref="S4.SS2.p3.5.m5.1.1.3.1"></times><ci id="S4.SS2.p3.5.m5.1.1.3.2.cmml" xref="S4.SS2.p3.5.m5.1.1.3.2">ğ‘›</ci><ci id="S4.SS2.p3.5.m5.1.1.3.3.cmml" xref="S4.SS2.p3.5.m5.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.1c">2^{nd}</annotation></semantics></math> row in (d)). In
comparison, our method is able to produce high-quality photo-realistic
removal results without noticeable visual artifacts caused by previous
methods. Due to space limit, the visual comparisons on SHIQ and
PSD are provided in our supplementary material.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Quantitative comparison of our method with state-of-the-art
specular highlight removal methods on our SSHR,
SHIQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, and PSD
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. The best results are marked in
<span id="S4.T1.19.1" class="ltx_text ltx_font_bold">bold</span>, while the second-best results are
<span id="S4.T1.20.2" class="ltx_text ltx_framed ltx_framed_underline">underlined</span>. Ours-A, Ours-B, and Ours-C denote our
network without the specular-free refinement stage, the tone
correction stage, and both these two stages, respectively.</figcaption>
<table id="S4.T1.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.6.7.1" class="ltx_tr">
<td id="S4.T1.6.7.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.7.1.1.1" class="ltx_text" style="font-size:90%;">Dataset</span></td>
<td id="S4.T1.6.7.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;" colspan="2"><span id="S4.T1.6.7.1.2.1" class="ltx_text" style="font-size:90%;">SSHR</span></td>
<td id="S4.T1.6.7.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;" colspan="2"><span id="S4.T1.6.7.1.3.1" class="ltx_text" style="font-size:90%;">SHIQ</span></td>
<td id="S4.T1.6.7.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;" colspan="2"><span id="S4.T1.6.7.1.4.1" class="ltx_text" style="font-size:90%;">PSD</span></td>
</tr>
<tr id="S4.T1.6.6" class="ltx_tr">
<td id="S4.T1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.6.7.1" class="ltx_text" style="font-size:90%;">Metric</span></td>
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.1.1.1.1" class="ltx_text" style="font-size:90%;">PSNR</span><math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.2.2.2.1" class="ltx_text" style="font-size:90%;">SSIM</span><math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.3.3.3.1" class="ltx_text" style="font-size:90%;">PSNR</span><math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.4.4.4.1" class="ltx_text" style="font-size:90%;">SSIM</span><math id="S4.T1.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.4.4.4.m1.1.1" xref="S4.T1.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b"><ci id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.5.5.5.1" class="ltx_text" style="font-size:90%;">PSNR</span><math id="S4.T1.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.5.5.5.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.5.5.5.m1.1.1" xref="S4.T1.5.5.5.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.m1.1b"><ci id="S4.T1.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.6.6.6.1" class="ltx_text" style="font-size:90%;">SSIM</span><math id="S4.T1.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.6.6.6.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.6.6.6.m1.1.1" xref="S4.T1.6.6.6.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.m1.1b"><ci id="S4.T1.6.6.6.m1.1.1.cmml" xref="S4.T1.6.6.6.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T1.6.8.2" class="ltx_tr">
<td id="S4.T1.6.8.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.6.8.2.1.1" class="ltx_text" style="font-size:90%;">Tan </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.6.8.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S4.T1.6.8.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.6.8.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.8.2.2.1" class="ltx_text" style="font-size:90%;">24.281</span></td>
<td id="S4.T1.6.8.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.8.2.3.1" class="ltx_text" style="font-size:90%;">0.874</span></td>
<td id="S4.T1.6.8.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.8.2.4.1" class="ltx_text" style="font-size:90%;">11.041</span></td>
<td id="S4.T1.6.8.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.8.2.5.1" class="ltx_text" style="font-size:90%;">0.403</span></td>
<td id="S4.T1.6.8.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.8.2.6.1" class="ltx_text" style="font-size:90%;">11.581</span></td>
<td id="S4.T1.6.8.2.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.8.2.7.1" class="ltx_text" style="font-size:90%;">0.560</span></td>
</tr>
<tr id="S4.T1.6.9.3" class="ltx_tr">
<td id="S4.T1.6.9.3.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.6.9.3.1.1" class="ltx_text" style="font-size:90%;">Shen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.6.9.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S4.T1.6.9.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.6.9.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.9.3.2.1" class="ltx_text" style="font-size:90%;">24.388</span></td>
<td id="S4.T1.6.9.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.9.3.3.1" class="ltx_text" style="font-size:90%;">0.904</span></td>
<td id="S4.T1.6.9.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.9.3.4.1" class="ltx_text" style="font-size:90%;">13.923</span></td>
<td id="S4.T1.6.9.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.9.3.5.1" class="ltx_text" style="font-size:90%;">0.428</span></td>
<td id="S4.T1.6.9.3.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.9.3.6.1" class="ltx_text" style="font-size:90%;">13.886</span></td>
<td id="S4.T1.6.9.3.7" class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.9.3.7.1" class="ltx_text" style="font-size:90%;">0.610</span></td>
</tr>
<tr id="S4.T1.6.10.4" class="ltx_tr">
<td id="S4.T1.6.10.4.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.6.10.4.1.1" class="ltx_text" style="font-size:90%;">Yang </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.6.10.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S4.T1.6.10.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.6.10.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.10.4.2.1" class="ltx_text" style="font-size:90%;">23.243</span></td>
<td id="S4.T1.6.10.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.10.4.3.1" class="ltx_text" style="font-size:90%;">0.894</span></td>
<td id="S4.T1.6.10.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.10.4.4.1" class="ltx_text" style="font-size:90%;">14.310</span></td>
<td id="S4.T1.6.10.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.10.4.5.1" class="ltx_text" style="font-size:90%;">0.502</span></td>
<td id="S4.T1.6.10.4.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.10.4.6.1" class="ltx_text" style="font-size:90%;">12.866</span></td>
<td id="S4.T1.6.10.4.7" class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.10.4.7.1" class="ltx_text" style="font-size:90%;">0.611</span></td>
</tr>
<tr id="S4.T1.6.11.5" class="ltx_tr">
<td id="S4.T1.6.11.5.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.6.11.5.1.1" class="ltx_text" style="font-size:90%;">Fu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.6.11.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S4.T1.6.11.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.6.11.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.11.5.2.1" class="ltx_text" style="font-size:90%;">23.270</span></td>
<td id="S4.T1.6.11.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.11.5.3.1" class="ltx_text" style="font-size:90%;">0.881</span></td>
<td id="S4.T1.6.11.5.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.11.5.4.1" class="ltx_text" style="font-size:90%;">15.746</span></td>
<td id="S4.T1.6.11.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.11.5.5.1" class="ltx_text" style="font-size:90%;">0.723</span></td>
<td id="S4.T1.6.11.5.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.11.5.6.1" class="ltx_text" style="font-size:90%;">14.400</span></td>
<td id="S4.T1.6.11.5.7" class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.11.5.7.1" class="ltx_text" style="font-size:90%;">0.665</span></td>
</tr>
<tr id="S4.T1.6.12.6" class="ltx_tr">
<td id="S4.T1.6.12.6.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.6.12.6.1.1" class="ltx_text" style="font-size:90%;">Fu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.6.12.6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S4.T1.6.12.6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.6.12.6.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.12.6.2.1" class="ltx_text" style="font-size:90%;">26.979</span></td>
<td id="S4.T1.6.12.6.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.12.6.3.1" class="ltx_text" style="font-size:90%;">0.895</span></td>
<td id="S4.T1.6.12.6.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.12.6.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">34.131</span></td>
<td id="S4.T1.6.12.6.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.12.6.5.1" class="ltx_text" style="font-size:90%;">0.860</span></td>
<td id="S4.T1.6.12.6.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.12.6.6.1" class="ltx_text" style="font-size:90%;">21.516</span></td>
<td id="S4.T1.6.12.6.7" class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.12.6.7.1" class="ltx_text" style="font-size:90%;">0.883</span></td>
</tr>
<tr id="S4.T1.6.13.7" class="ltx_tr">
<td id="S4.T1.6.13.7.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;">
<span id="S4.T1.6.13.7.1.1" class="ltx_text" style="font-size:90%;">Wu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.6.13.7.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S4.T1.6.13.7.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.6.13.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.13.7.2.1" class="ltx_text" style="font-size:90%;">25.731</span></td>
<td id="S4.T1.6.13.7.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.13.7.3.1" class="ltx_text" style="font-size:90%;">0.894</span></td>
<td id="S4.T1.6.13.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.13.7.4.1" class="ltx_text" style="font-size:90%;">23.420</span></td>
<td id="S4.T1.6.13.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.13.7.5.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0.920</span></td>
<td id="S4.T1.6.13.7.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.13.7.6.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">21.801</span></td>
<td id="S4.T1.6.13.7.7" class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.13.7.7.1" class="ltx_text" style="font-size:90%;">0.880</span></td>
</tr>
<tr id="S4.T1.6.14.8" class="ltx_tr">
<td id="S4.T1.6.14.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.14.8.1.1" class="ltx_text" style="font-size:90%;">Ours-A</span></td>
<td id="S4.T1.6.14.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.14.8.2.1" class="ltx_text" style="font-size:90%;">26.083</span></td>
<td id="S4.T1.6.14.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.14.8.3.1" class="ltx_text" style="font-size:90%;">0.918</span></td>
<td id="S4.T1.6.14.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.14.8.4.1" class="ltx_text" style="font-size:90%;">24.930</span></td>
<td id="S4.T1.6.14.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.14.8.5.1" class="ltx_text" style="font-size:90%;">0.896</span></td>
<td id="S4.T1.6.14.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.14.8.6.1" class="ltx_text" style="font-size:90%;">21.263</span></td>
<td id="S4.T1.6.14.8.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.14.8.7.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0.897</span></td>
</tr>
<tr id="S4.T1.6.15.9" class="ltx_tr">
<td id="S4.T1.6.15.9.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.15.9.1.1" class="ltx_text" style="font-size:90%;">Ours-B</span></td>
<td id="S4.T1.6.15.9.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.15.9.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">28.903</span></td>
<td id="S4.T1.6.15.9.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.15.9.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.945</span></td>
<td id="S4.T1.6.15.9.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.15.9.4.1" class="ltx_text" style="font-size:90%;">22.019</span></td>
<td id="S4.T1.6.15.9.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.15.9.5.1" class="ltx_text" style="font-size:90%;">0.843</span></td>
<td id="S4.T1.6.15.9.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.15.9.6.1" class="ltx_text" style="font-size:90%;">18.932</span></td>
<td id="S4.T1.6.15.9.7" class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.15.9.7.1" class="ltx_text" style="font-size:90%;">0.830</span></td>
</tr>
<tr id="S4.T1.6.16.10" class="ltx_tr">
<td id="S4.T1.6.16.10.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.16.10.1.1" class="ltx_text" style="font-size:90%;">Ours-C</span></td>
<td id="S4.T1.6.16.10.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.16.10.2.1" class="ltx_text" style="font-size:90%;">24.231</span></td>
<td id="S4.T1.6.16.10.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.16.10.3.1" class="ltx_text" style="font-size:90%;">0.893</span></td>
<td id="S4.T1.6.16.10.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.16.10.4.1" class="ltx_text" style="font-size:90%;">20.309</span></td>
<td id="S4.T1.6.16.10.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.16.10.5.1" class="ltx_text" style="font-size:90%;">0.805</span></td>
<td id="S4.T1.6.16.10.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.16.10.6.1" class="ltx_text" style="font-size:90%;">18.301</span></td>
<td id="S4.T1.6.16.10.7" class="ltx_td ltx_align_center" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.16.10.7.1" class="ltx_text" style="font-size:90%;">0.801</span></td>
</tr>
<tr id="S4.T1.6.17.11" class="ltx_tr">
<td id="S4.T1.6.17.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.17.11.1.1" class="ltx_text" style="font-size:90%;">Ours</span></td>
<td id="S4.T1.6.17.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.17.11.2.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">28.633</span></td>
<td id="S4.T1.6.17.11.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.17.11.3.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0.940</span></td>
<td id="S4.T1.6.17.11.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.17.11.4.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">25.575</span></td>
<td id="S4.T1.6.17.11.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.17.11.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.933</span></td>
<td id="S4.T1.6.17.11.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.17.11.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">22.759</span></td>
<td id="S4.T1.6.17.11.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt" style="padding-left:2.3pt;padding-right:2.3pt;"><span id="S4.T1.6.17.11.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.903</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F8" class="ltx_figure">
<table id="S4.F8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F8.1.1" class="ltx_tr">
<td id="S4.F8.1.1.1" class="ltx_td ltx_align_center"><span id="S4.F8.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x7.png" id="S4.F8.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="522" height="244" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Visual comparison of our method against state-of-the-art
methods on real object-level images. (a)(f) Input and its
grayscale version, respectively. (b)(g) Fu <span id="S4.F8.5.1" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. (c)(h) Fu <span id="S4.F8.6.2" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. (d)(i) Wu <span id="S4.F8.7.3" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. (e)(j) Ours.</figcaption>
</figure>
<figure id="S4.F9" class="ltx_figure">
<table id="S4.F9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F9.1.1" class="ltx_tr">
<td id="S4.F9.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2309.06302/assets/x8.png" id="S4.F9.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="486" height="117" alt="Refer to caption"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>User study results on the three questions.</figcaption>
</figure>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">User Study</span>. We further conducted a
user study to evaluate the robustness and generalization capability of
our method on real images. Here, three recent state-of-the-art
methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> are compared. We first randomly downloaded
200 images from the Internet by searching the keywords â€œchairâ€,
â€œstatueâ€, â€œstorage bagâ€, and â€œdecorationâ€.
FigureÂ <a href="#S4.F8" title="Figure 8 â€£ 4.2 Comparison with State-of-the-Art Methods â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>(a) presents
several example images. Then, we produced specular-free images for all
downloaded images using our method and other compared methods, and
recruited 20 participants from a school campus for rating. Finally, we
asked the participants to score all results in a random order using a
1(worst)-to-4(best) scale (as done in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>) on the three questions: (1) Is the result free
of highlights? (denoted as Q1); (2) Are the missing details recovered?
(denoted as Q2); and (3) Is the result visually realistic? (denoted as
Q3).</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">Figure <a href="#S4.F9" title="Figure 9 â€£ 4.2 Comparison with State-of-the-Art Methods â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> summarizes the user study results, where
the average and standard deviation values of scores received by each
method are presented. As shown, our method achieves higher average
scores and lower standard deviations, indicating that our results are
more preferred by the participants with lower subjective bias.
FigureÂ <a href="#S4.F8" title="Figure 8 â€£ 4.2 Comparison with State-of-the-Art Methods â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> presents the
visual comparison on example images. As shown, our method is able to
effectively address real images and produce high-quality results with
natural appearances, although it is trained on the synthetic data.</p>
</div>
<figure id="S4.F10" class="ltx_figure">
<table id="S4.F10.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F10.1.1" class="ltx_tr">
<td id="S4.F10.1.1.1" class="ltx_td ltx_align_left"><span id="S4.F10.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x9.png" id="S4.F10.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="523" height="113" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Visual comparison of our method against
state-of-the-art methods on a challenging image with multiple
background objects. (a) Input. (b) Yang <span id="S4.F10.5.1" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. (c) Fu <span id="S4.F10.6.2" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. (d) Wu <span id="S4.F10.7.3" class="ltx_text ltx_font_italic">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. (e) Ours.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Discussions</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_bold">Ablation Study</span>. Besides the visual comparison
results shown in Figure <a href="#S3.F5" title="Figure 5 â€£ 3.3 Specular-Free Refinement â€£ 3 Methodology â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we also
quantitatively validate the effectiveness of each stage of our method
(denoted as â€œOursâ€)
by constructing the following three variants:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I1.i1.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S4.I1.i1.1.1.m1.1b"><mo id="S4.I1.i1.1.1.m1.1.1" xref="S4.I1.i1.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S4.I1.i1.1.1.m1.1c"><ci id="S4.I1.i1.1.1.m1.1.1.cmml" xref="S4.I1.i1.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Ours-A: ours without <span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">specular-free refinement</span>.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I1.i2.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S4.I1.i2.1.1.m1.1b"><mo id="S4.I1.i2.1.1.m1.1.1" xref="S4.I1.i2.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S4.I1.i2.1.1.m1.1c"><ci id="S4.I1.i2.1.1.m1.1.1.cmml" xref="S4.I1.i2.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Ours-B: ours without <span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">tone correction</span>.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S4.I1.i3.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S4.I1.i3.1.1.m1.1b"><mo id="S4.I1.i3.1.1.m1.1.1" xref="S4.I1.i3.1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S4.I1.i3.1.1.m1.1c"><ci id="S4.I1.i3.1.1.m1.1.1.cmml" xref="S4.I1.i3.1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Ours-C: ours without both <span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">specular-free refinement</span>
and <span id="S4.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">tone correction</span> (<span id="S4.I1.i3.p1.1.3" class="ltx_text ltx_font_italic">i.e.</span>, only with <span id="S4.I1.i3.p1.1.4" class="ltx_text ltx_font_italic">physics-based
specular highlight removal</span>).</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.6" class="ltx_p">Table <a href="#S4.T1" title="Table 1 â€£ 4.2 Comparison with State-of-the-Art Methods â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> reports the quantitative
results of our method and its variants on our SSHR, SHIQ, and PSD.
From the results, we can observe that the PSNR and SSIM scores of our
method and its three variants overall follow the relationship: Ours
<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mo id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><gt id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">&gt;</annotation></semantics></math> Ours-A <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mo id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><gt id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">&gt;</annotation></semantics></math> Ours-B <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mo id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><gt id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">&gt;</annotation></semantics></math> Ours-C, except for a special case: Ours-B
<math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mo id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><gt id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">&gt;</annotation></semantics></math> Ours <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mo id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><gt id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">&gt;</annotation></semantics></math> Ours-A <math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mo id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><gt id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">&gt;</annotation></semantics></math> Ours-C on our dataset. From it, we can draw
two conclusions. First, as the number of the used stages increases,
the performance of our method overall gets better and better,
illustrating the effectiveness of each stage of our method. Second,
the tone correction stage leads to a performance drop on our dataset,
due to the domain gap between our synthetic data and its tone
correction version. However, it further improves the performance on
SHIQ and PSD. This is because the resulting errors from the
differences between them and their tone correction versions can be
fully offset by the performance gain brought by further learning of
the network.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.3" class="ltx_p"><span id="S4.SS3.p3.3.1" class="ltx_text ltx_font_bold">Generalization to Grayscale Images</span>.
FigureÂ <a href="#S4.F8" title="Figure 8 â€£ 4.2 Comparison with State-of-the-Art Methods â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> presents the
visual comparison on color images (see the left column) and their
grayscale version (see the right column). As can be seen, the
traditional method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> suffers from leaking a
small amount of specular highlights into the specular-free images (see
the <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="1^{st}" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><msup id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mn id="S4.SS3.p3.1.m1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.2.cmml">1</mn><mrow id="S4.SS3.p3.1.m1.1.1.3" xref="S4.SS3.p3.1.m1.1.1.3.cmml"><mi id="S4.SS3.p3.1.m1.1.1.3.2" xref="S4.SS3.p3.1.m1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p3.1.m1.1.1.3.1" xref="S4.SS3.p3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS3.p3.1.m1.1.1.3.3" xref="S4.SS3.p3.1.m1.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.1.m1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS3.p3.1.m1.1.1.2.cmml" xref="S4.SS3.p3.1.m1.1.1.2">1</cn><apply id="S4.SS3.p3.1.m1.1.1.3.cmml" xref="S4.SS3.p3.1.m1.1.1.3"><times id="S4.SS3.p3.1.m1.1.1.3.1.cmml" xref="S4.SS3.p3.1.m1.1.1.3.1"></times><ci id="S4.SS3.p3.1.m1.1.1.3.2.cmml" xref="S4.SS3.p3.1.m1.1.1.3.2">ğ‘ </ci><ci id="S4.SS3.p3.1.m1.1.1.3.3.cmml" xref="S4.SS3.p3.1.m1.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">1^{st}</annotation></semantics></math> and <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="2^{nd}" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><msup id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mn id="S4.SS3.p3.2.m2.1.1.2" xref="S4.SS3.p3.2.m2.1.1.2.cmml">2</mn><mrow id="S4.SS3.p3.2.m2.1.1.3" xref="S4.SS3.p3.2.m2.1.1.3.cmml"><mi id="S4.SS3.p3.2.m2.1.1.3.2" xref="S4.SS3.p3.2.m2.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p3.2.m2.1.1.3.1" xref="S4.SS3.p3.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS3.p3.2.m2.1.1.3.3" xref="S4.SS3.p3.2.m2.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">superscript</csymbol><cn type="integer" id="S4.SS3.p3.2.m2.1.1.2.cmml" xref="S4.SS3.p3.2.m2.1.1.2">2</cn><apply id="S4.SS3.p3.2.m2.1.1.3.cmml" xref="S4.SS3.p3.2.m2.1.1.3"><times id="S4.SS3.p3.2.m2.1.1.3.1.cmml" xref="S4.SS3.p3.2.m2.1.1.3.1"></times><ci id="S4.SS3.p3.2.m2.1.1.3.2.cmml" xref="S4.SS3.p3.2.m2.1.1.3.2">ğ‘›</ci><ci id="S4.SS3.p3.2.m2.1.1.3.3.cmml" xref="S4.SS3.p3.2.m2.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">2^{nd}</annotation></semantics></math> rows in (g)). For two deep learning-based
methods, the method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> sometimes fails to
effectively remove specular highlights (see the <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="3^{rd}" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><msup id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml"><mn id="S4.SS3.p3.3.m3.1.1.2" xref="S4.SS3.p3.3.m3.1.1.2.cmml">3</mn><mrow id="S4.SS3.p3.3.m3.1.1.3" xref="S4.SS3.p3.3.m3.1.1.3.cmml"><mi id="S4.SS3.p3.3.m3.1.1.3.2" xref="S4.SS3.p3.3.m3.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p3.3.m3.1.1.3.1" xref="S4.SS3.p3.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS3.p3.3.m3.1.1.3.3" xref="S4.SS3.p3.3.m3.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><apply id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.3.m3.1.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">superscript</csymbol><cn type="integer" id="S4.SS3.p3.3.m3.1.1.2.cmml" xref="S4.SS3.p3.3.m3.1.1.2">3</cn><apply id="S4.SS3.p3.3.m3.1.1.3.cmml" xref="S4.SS3.p3.3.m3.1.1.3"><times id="S4.SS3.p3.3.m3.1.1.3.1.cmml" xref="S4.SS3.p3.3.m3.1.1.3.1"></times><ci id="S4.SS3.p3.3.m3.1.1.3.2.cmml" xref="S4.SS3.p3.3.m3.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.SS3.p3.3.m3.1.1.3.3.cmml" xref="S4.SS3.p3.3.m3.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">3^{rd}</annotation></semantics></math> row in (h)).
The method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> produces unsatisfactory or
even poor results with visual artifacts such as severe color distortion
and disharmonious color block. In comparison, our method trained on
our synthetic data is able to generalize well to real grayscale
images, which have almost the same performance as on color images.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para ltx_noindent">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">Generalization to Scene-Level Images</span>.
Figure <a href="#S4.F10" title="Figure 10 â€£ 4.2 Comparison with State-of-the-Art Methods â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> presents the visual
comparison on scene-level images. As can be seen, the traditional
method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> often mistakes white material
surfaces (see the circular jade in (b)) as specular highlights to be
removed, and undesirably produce black color block artifacts. For the two deep
learning-based methods, the method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> fails to
effectively recover the missing color underneath specular highlights.
The method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> often produces unsatisfactory
results with color distortion artifacts. In comparison, our method
produces good results with realistic color and clear texture
details. This illustrates that our method is able to generalize to
scene-level images with multiple background objects to a certain extent.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para ltx_noindent">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_bold">Limitations</span>. Our method has two
limitations. First, our method, as well as previous methods, all
fail to recover missing texture details and color underneath
strong (<span id="S4.SS3.p5.1.2" class="ltx_text ltx_font_italic">i.e.</span>, high-intensity and large-area) specular highlights.
FigureÂ <a href="#S4.F11" title="Figure 11 â€£ 4.3 Discussions â€£ 4 Experimental Results â€£ Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> presents an example. As can be seen, the
missing detailed patterns on the body of the wooden kitten underneath
strong specular highlights (see the red boxes) are less able to
be recovered very well. Second, although our method achieves good
results for object-level images, it may produce unsatisfactory
results, particularly for complex natural scenes often with achromatic
material surfaces, color lighting, noise, and so on.</p>
</div>
<figure id="S4.F11" class="ltx_figure">
<table id="S4.F11.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F11.1.1" class="ltx_tr">
<td id="S4.F11.1.1.1" class="ltx_td ltx_align_center"><span id="S4.F11.1.1.1.1" class="ltx_text ltx_inline-block" style="width:0.0pt;"><img src="/html/2309.06302/assets/x10.png" id="S4.F11.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="228" height="108" alt="Refer to caption"></span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>A failure case of our method. (a) Input. (b)
Specular-free image. (c) Specular residue image.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We in this paper have proposed a three-stage method for object-level
specular highlight removal. Our key idea is to progressively eliminate
multiple types of visual artifacts to produce high-quality results
with natural appearances. In addition, we have presented a large-scale
synthetic dataset of object-level images to facilitate network training
and quantitative evaluation. In our dataset, each input specular
highlight image has corresponding ground truth albedo, shading,
specular residue, and specular-free images. We have conducted
extensive experiments to illustrate the superiority of our method over
previous methods in terms of quantitative comparison (<span id="S5.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>,
higher PSNR and SSIM values), visual comparison, and a user study.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Our future work is to integrate features from inpainting
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> into our network to remove strong specular
highlights while restoring the missing texture details and color
underneath them. Another direction is to design more effective and
complex backbone networks such as diffusion models
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> to further improve the performance of our
method.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported in part by the National Natural Science
Foundation of China under Grant 61972298, in part by the CAAI-Huawei
MindSpore Open Fund, and in part by The Hong Kong Polytechnic
University under Grants P0030419, P0043906, P0042740, and P0044520.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Shida Beigpour and Joost Van DeÂ Weijer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Object recoloring based on intrinsic image estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 327â€“334, 2011.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
AngelÂ X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang,
Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Shapenet: An information-rich 3D model repository.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1512.03012</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Gang Fu, Qing Zhang, Chengfang Song, Qifeng Lin, and Chunxia Xiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Specular highlight removal for real-world images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Graphics Forum</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 38(7):253â€“263, 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Gang Fu, Qing Zhang, Lei Zhu, Ping Li, and Chunxia Xiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">A multi-task network for joint specular highlight detection and
removal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 7752â€“7761, 2021.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Roger Grosse, MicahÂ K Johnson, EdwardÂ H Adelson, and WilliamÂ T Freeman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Ground truth dataset and baseline evaluations for intrinsic image
algorithms.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 2335â€“2342, 2009.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Jie Guo, Zuojian Zhou, and Limin Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Single image highlight removal with a sparse and low-rank reflection
model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 268â€“283, 2018.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Xiaojie Guo, Xiaochun Cao, and Yi Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Robust separation of reflection from multiple images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 2187â€“2194, 2014.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Mingming He, Jing Liao, Dongdong Chen, Lu Yuan, and PedroÂ V Sander.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Progressive color transfer with dense semantic correspondences.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 38(2):1â€“18, 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NIPS</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, pages 6840â€“6851, 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Wenzel Jakob.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Mitsuba renderer, 2010.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">http://www.mitsuba-renderer.org.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Salma Jiddi, Philippe Robert, and Eric Marchand.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Detecting specular reflections and cast shadows to estimate
reflectance and illumination of dynamic indoor scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Visualization and Computer Graphics</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">,
28(2):1249â€“1260, 2020.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Yeying Jin, Ruoteng Li, Wenhan Yang, and RobbyÂ T Tan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Estimating reflectance layer from a single image: Integrating
reflectance guidance and shadow/specular aware learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">pages 1069â€“1077, 2022.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Hyeongwoo Kim, Hailin Jin, Sunil Hadap, and Inso Kweon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Specular reflection separation using dark channel prior.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 1460â€“1467, 2013.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Chen Li, Stephen Lin, Kun Zhou, and Katsushi Ikeuchi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Specular highlight removal in facial images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 3107â€“3116, 2017.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Qiankun Liu, Zhentao Tan, Dongdong Chen, Qi Chu, Xiyang Dai, Yinpeng Chen,
Mengchen Liu, Lu Yuan, and Nenghai Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Reduce information loss in transformers for pluralistic image
inpainting.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages 11347â€“11357, 2022.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Yuanliu Liu, Zejian Yuan, Nanning Zheng, and Yang Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Saturation-preserving specular reflection separation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 3725â€“3733, 2015.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Lukas Murmann, Michael Gharbi, Miika Aittala, and Fredo Durand.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">A dataset of multi-illumination images in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 4080â€“4089, 2019.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Aaron Netz and Margarita Osadchy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Recognition using specular highlights.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">,
35(3):639â€“652, 2012.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
BuiÂ Tuong Phong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Illumination for computer generated pictures.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Communications of the ACM</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 18(6):311â€“317, 1975.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">U-Net: Convolutional networks for biomedical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">MICCAI</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 234â€“241, 2015.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
StevenÂ A Shafer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Using color to separate reflection components.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Color Research and Application</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, 10(4):210â€“218, 1985.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Hui-Liang Shen and Zhi-Huan Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Real-time highlight removal using intensity ratio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Applied Optics</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 52(19):4483â€“4493, 2013.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Jian Shi, Yue Dong, Hao Su, and StellaÂ X Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Learning non-lambertian object intrinsics across shapenet categories.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 1685â€“1694, 2017.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Minjung Son, Yunjin Lee, and HyunÂ Sung Chang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Toward specular removal from natural images based on statistical
reflection models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Image Processing</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 29:4204â€“4218, 2020.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
RobbyÂ T Tan and Katsushi Ikeuchi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Separating reflection components of textured surfaces using a single
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">,
27(2):178â€“193, 2005.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Ruixing Wang, Qing Zhang, Chi-Wing Fu, Xiaoyong Shen, Wei-Shi Zheng, and Jiaya
Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Underexposed photo enhancement using deep illumination estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 6849â€“6857, 2019.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Xing Wei, Xiaobin Xu, Jiawei Zhang, and Yihong Gong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Specular highlight reduction with known surface geometry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision and Image Understanding</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 168:132â€“144, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Zhongqi Wu, Chuanqing Zhuang, Jian Shi, Jianwei Guo, Jun Xiao, Xiaopeng Zhang,
and Dong-Ming Yan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Single-image specular highlight removal via real-world dataset
construction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Multimedia</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 24:3782â€“3793, 2022.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Qingxiong Yang, Jinhui Tang, and Narendra Ahuja.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Efficient and robust specular highlight removal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">,
37(6):1304â€“1311, 2015.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Renjiao Yi, Ping Tan, and Stephen Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Leveraging multi-view image sets for unsupervised intrinsic image
decomposition and highlight separation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 12685â€“12692, 2020.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Qing Zhang, Jin Zhou, Lei Zhu, Wei Sun, Chunxia Xiao, and Wei-Shi Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Unsupervised intrinsic image decomposition using internal
self-similarity cues.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">,
44(12):9669â€“9686, 2021.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2309.06301" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2309.06302" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2309.06302">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.06302" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2309.06303" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 07:07:20 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
