<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Chapter 4 Large Language Model Driven Recommendation</title>
<!--Generated on Tue Aug 20 15:30:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.10946v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Large Language Model Driven Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS1" title="In 4.1 Introduction"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Natural Language vs. Non-Textual Interaction Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS1.SSSx1" title="In 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_title">Non-textual Interaction Data:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS1.SSSx2" title="In 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_title">Natural Language in Recommendation:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS2" title="In 4.1 Introduction"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>General vs. Specialized Recommendation Reasoning</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS2.SSSx1" title="In 4.1.2 General vs. Specialized Recommendation Reasoning ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_title">Task-specific Reasoning with Conventional RSs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS2.SSSx2" title="In 4.1.2 General vs. Specialized Recommendation Reasoning ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_title">General Recommendation Reasoning with LLMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS2.SSSx2.Px1" title="In General Recommendation Reasoning with LLMs ‣ 4.1.2 General vs. Specialized Recommendation Reasoning ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_title">Recommendation and Explanation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS2.SSSx2.Px2" title="In General Recommendation Reasoning with LLMs ‣ 4.1.2 General vs. Specialized Recommendation Reasoning ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_title">Conversational Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS2.SSSx2.Px3" title="In General Recommendation Reasoning with LLMs ‣ 4.1.2 General vs. Specialized Recommendation Reasoning ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_title">Limitations of LLM-Driven Recommendation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S1.SS3" title="In 4.1 Introduction"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Chapter Outline</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Data Sources in LLM-Driven RSs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS1" title="In 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Item Text</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS1.SSSx1" title="In 4.2.1 Item Text ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">Titles</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS1.SSSx2" title="In 4.2.1 Item Text ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">Descriptions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS1.SSSx3" title="In 4.2.1 Item Text ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">Metadata</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS1.SSSx4" title="In 4.2.1 Item Text ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">Reviews</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS2" title="In 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Interaction Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS2.SSSx1" title="In 4.2.2 Interaction Data ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">Verbalizing Non-Textual Interactions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS2.SSSx2" title="In 4.2.2 Interaction Data ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">NL Interactions</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS2.SSSx2.Px1" title="In NL Interactions ‣ 4.2.2 Interaction Data ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">Queries</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS2.SSSx2.Px2" title="In NL Interactions ‣ 4.2.2 Interaction Data ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">User-System Dialogue</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS3" title="In 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>NL User Profiles</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS3.SSS0.Px1" title="In 4.2.3 NL User Profiles ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_title">User Agency via Editable NL Profiles</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Encoder-only LLM Recommendation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3.SS1" title="In 4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Dense Retrievers</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3.SS2" title="In 4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Cross-Encoders</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Generative Recommendation and Explanation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS1" title="In 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.1 </span>Zero- and Few-Shot Recommendation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS1.SSS0.Px1" title="In 4.4.1 Zero- and Few-Shot Recommendation ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_title">Zero- and Few-Shot Prompt Engineering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS1.SSS0.Px2" title="In 4.4.1 Zero- and Few-Shot Recommendation ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_title">Initial Experimental Findings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS2" title="In 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.2 </span>LLM Tuning for Generative Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS3" title="In 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.3 </span>Generative Explanation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Retrieval Augmented Recommendation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5.SS1" title="In 4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5.1 </span>RAG in RSs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5.SS1.SSS0.Px1" title="In 4.5.1 RAG in RSs ‣ 4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_title">RAG for Recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5.SS1.SSS0.Px2" title="In 4.5.1 RAG in RSs ‣ 4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_title">RAG for Explanation and Conversational Recommendation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>LLMs Representation Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6.SS1" title="In 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6.1 </span>Text to Text</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6.SS1.SSS0.Px1" title="In 4.6.1 Text to Text ‣ 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_title">Search Queries</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6.SS1.SSS0.Px2" title="In 4.6.1 Text to Text ‣ 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_title">Prompt Elements</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6.SS2" title="In 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6.2 </span>Text to Embeddings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6.SS2.SSS0.Px1" title="In 4.6.2 Text to Embeddings ‣ 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_title">Sequential Recommendation with LLM Embeddings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6.SS2.SSS0.Px2" title="In 4.6.2 Text to Embeddings ‣ 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_title">Rating Prediction with LLM Embeddings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6.SS3" title="In 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6.3 </span>Text to Item Ratings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title=""><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7 </span>Conversational Recommendation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS0.SSS0.Px1" title="In 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title">Pre-LLM CRS Architectures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS0.SSS0.Px2" title="In 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title">LLM-Driven CRSs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS1" title="In 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7.1 </span>Belief Tracking</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS1.SSSx1" title="In 4.7.1 Belief Tracking ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title">Textual Dialogue State Components</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS1.SSSx2" title="In 4.7.1 Belief Tracking ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title">Semi-textual Dialogue States</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS2" title="In 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7.2 </span>System Response Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS2.SSSx1" title="In 4.7.2 System Response Generation ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title">Prompting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS2.SSSx2" title="In 4.7.2 System Response Generation ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title">Tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS2.SSSx3" title="In 4.7.2 System Response Generation ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_title">Tool Use</span></a></li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\addbibresource</span>
<p class="ltx_p" id="p1.2">sample-now.bib


</p>
</div>
<section class="ltx_chapter" id="Ch4">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 4 </span>Large Language Model Driven Recommendation</h2>
<div class="ltx_para ltx_noindent" id="Ch4.p1">
<p class="ltx_p" id="Ch4.p1.1"><span class="ltx_text" id="Ch4.p1.1.1" style="font-size:90%;">This is a preprint of Chapter 4 in the upcoming book <span class="ltx_text ltx_font_italic" id="Ch4.p1.1.1.1">Recommendation with Generative Models</span>
by Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner, Arnau Ramisa, Rene Vidal, Mahesh Sathiamoorthy, Atoosa Kasrizadeh, Silvia Milano, and Francesco Ricci.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.p2">
<p class="ltx_p" id="Ch4.p2.1"><span class="ltx_text ltx_font_bold" id="Ch4.p2.1.1" style="font-size:90%;">Chapter Authors:<span class="ltx_text ltx_font_medium" id="Ch4.p2.1.1.1"> Anton Korikov, Scott Sanner</span></span></p>
</div>
</section>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">While previous chapters focused on recommendation systems (RSs) based on standardized, non-verbal user feedback such as purchases, views, and clicks – the advent of LLMs has unlocked the use of natural language (NL) interactions for recommendation. This chapter discusses how LLMs’ abilities for general NL reasoning present novel opportunities to build highly personalized RSs – which can effectively connect nuanced and diverse user preferences to items, potentially via interactive dialogues. To begin this discussion, we first present a taxonomy of the key data sources for language-driven recommendation, covering item descriptions, user-system interactions, and user profiles. We then proceed to fundamental techniques for LLM recommendation, reviewing the use of encoder-only and autoregressive LLM recommendation in both tuned and untuned settings. Afterwards, we move to multi-module recommendation architectures in which LLMs interact with components such as retrievers and RSs in multi-stage pipelines. This brings us to architectures for conversational recommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where each turn presents an opportunity not only to make recommendations, but also to engage with the user in interactive preference elicitation, critiquing, and question-answering.</p>
</div>
<section class="ltx_section" id="Ch4.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.1 </span>Introduction</h3>
<div class="ltx_para" id="Ch4.S1.p1">
<p class="ltx_p" id="Ch4.S1.p1.1">The advent of LLMs has enabled conversational, natural language (NL) interactions with users – while also unlocking the rich NL data sources within recommendation systems (RSs) such as item descriptions, reviews, and queries. These advances create the opportunity for highly personalized RSs which harness the general reasoning abilities of LLMs to accommodate diverse and nuanced user preferences through customized recommendations and interactions.
Such NL-based personalization contrasts starkly to the ID-based RSs described in Chapters 2 and 3 which are highly specialized for standard recommendation tasks (e.g., rating prediction, sequential recommendation) and require large volumes of non-textual interaction data – though many synergies between these two paradigms are possible, as discussed below.
</p>
</div>
<section class="ltx_subsection" id="Ch4.S1.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1.1 </span>Natural Language vs. Non-Textual Interaction Data</h4>
<div class="ltx_para" id="Ch4.S1.SS1.p1">
<p class="ltx_p" id="Ch4.S1.SS1.p1.1">Both textual and non-textual data are important in this chapter – Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F1" title="Figure 4.1 ‣ 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_tag">4.1</span></a> illustrates how such data can represent key RS information, covering items, users, and system interactions. This figure is discussed in detail in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2" title="4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
<figure class="ltx_figure" id="Ch4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="559" id="Ch4.F1.g1" src="extracted/5803119/fig/ch4_text_data_types.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.1: </span>Sources of data in LLM-driven RSs, including item descriptions (right), user-system interactions (top/bottom), and user profiles (left).</figcaption>
</figure>
<section class="ltx_subsubsection" id="Ch4.S1.SS1.SSSx1">
<h5 class="ltx_title ltx_title_subsubsection">Non-textual Interaction Data:</h5>
<div class="ltx_para" id="Ch4.S1.SS1.SSSx1.p1">
<p class="ltx_p" id="Ch4.S1.SS1.SSSx1.p1.1">On one hand, non-textual user-item interactions such as purchases, views, clicks, or ratings facilitate the collection of large volumes of data in fixed formats (e.g., rating matrices, item ID sequences) and enable the large-scale training of conventional RSs – namely, collaborative filtering (CF) and content-based filtering (CBF) systems (c.f. Ch 2). On the other hand, these non-textual data forms only provide a narrow, highly standardized view of user-system interactions – limiting the degree of personalization that can be achieved.
</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S1.SS1.SSSx2">
<h5 class="ltx_title ltx_title_subsubsection">Natural Language in Recommendation:</h5>
<div class="ltx_para" id="Ch4.S1.SS1.SSSx2.p1">
<p class="ltx_p" id="Ch4.S1.SS1.SSSx2.p1.1">In contrast, while NL is a much more complex medium, it is also far more expressive and constitutes a unified format to represent nuanced information about items, preferences, and user-system interactions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>]</cite>. Many RSs already contain an abundance of NL data in the form of item descriptions, reviews, and user query histories, and systems can also generate new NL representations from interaction histories by using LLMs or templates <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">radlinski2022natural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite>. NL conversational recommendation dialogues are also emerging as a key source of data, capturing a variety of user and system intents in multi-turn interactions (c.f. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S1.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1.2 </span>General vs. Specialized Recommendation Reasoning</h4>
<section class="ltx_subsubsection" id="Ch4.S1.SS2.SSSx1">
<h5 class="ltx_title ltx_title_subsubsection">Task-specific Reasoning with Conventional RSs</h5>
<div class="ltx_para" id="Ch4.S1.SS2.SSSx1.p1">
<p class="ltx_p" id="Ch4.S1.SS2.SSSx1.p1.1">Conventional
RSs must be trained on large amounts of task-specific interaction data – making them highly-specialized tools that are typically optimized for either rating prediction or top-<math alttext="k" class="ltx_Math" display="inline" id="Ch4.S1.SS2.SSSx1.p1.1.m1.1"><semantics id="Ch4.S1.SS2.SSSx1.p1.1.m1.1a"><mi id="Ch4.S1.SS2.SSSx1.p1.1.m1.1.1" xref="Ch4.S1.SS2.SSSx1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.SSSx1.p1.1.m1.1b"><ci id="Ch4.S1.SS2.SSSx1.p1.1.m1.1.1.cmml" xref="Ch4.S1.SS2.SSSx1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.SSSx1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.SSSx1.p1.1.m1.1d">italic_k</annotation></semantics></math>, sequential, or page-wise recommendation. While their performance on <span class="ltx_text ltx_font_italic" id="Ch4.S1.SS2.SSSx1.p1.1.1">offline</span> benchmarks for these tasks is generally very strong (c.f. Ch. 6), these specialized systems are limited by the inability of standardized interaction data (e.g., purchases, views, clicks, etc.) to capture nuanced and diverse user preferences.
These systems also often require considerable data engineering efforts and design time to deploy.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS2.SSSx1.p2">
<p class="ltx_p" id="Ch4.S1.SS2.SSSx1.p2.1">However, despite these limitations, conventional RS remain powerful and scalable methods for predicting future interactions, able to work with millions of users and items. Therefore, as will be discussed in Sections <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5" title="4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>, many researchers are actively studying the integration of conventional RSs as specialized sub-components within larger, LLM-powered system architectures (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hou2023large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023collm</span>]</cite>).</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S1.SS2.SSSx2">
<h5 class="ltx_title ltx_title_subsubsection">General Recommendation Reasoning with LLMs</h5>
<div class="ltx_para" id="Ch4.S1.SS2.SSSx2.p1">
<p class="ltx_p" id="Ch4.S1.SS2.SSSx2.p1.1">In contrast to conventional RSs, the pretraining of LLMs on large text corpora provides them with emergent abilities for <span class="ltx_text ltx_font_italic" id="Ch4.S1.SS2.SSSx2.p1.1.1">general</span> reasoning – with LLMs achieving impressive performance on many diverse and previously unseen tasks
<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sparks_of_agi</span>]</cite>. Through pretraining, LLMs have internalized fine-grained knowledge about a wide range of entities, human preferences, and interaction patterns – knowledge which could enhance RS personalization while reducing data and design time requirements.</p>
</div>
<figure class="ltx_figure" id="Ch4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="761" id="Ch4.F2.g1" src="extracted/5803119/fig/Ch_4_organazation.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.2: </span>Outline of key techniques and publications in LLM-driven RSs.</figcaption>
</figure>
<section class="ltx_paragraph" id="Ch4.S1.SS2.SSSx2.Px1">
<h6 class="ltx_title ltx_title_paragraph">Recommendation and Explanation</h6>
<div class="ltx_para" id="Ch4.S1.SS2.SSSx2.Px1.p1">
<p class="ltx_p" id="Ch4.S1.SS2.SSSx2.Px1.p1.1">Firstly,
LLMs can use NL data (e.g., descriptions of items and a user’s preferences) to make recommendations – either by generating text (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4" title="4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a>) or via embedding-based item scoring (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3" title="4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_tag">4.3</span></a>). Further, LLMs can generate textual explanations (c.f. <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS3" title="4.4.3 Generative Explanation ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4.3</span></a>) to help users understand why recommendations were made and enable better user feedback, such as NL critiques or follow-up questions.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S1.SS2.SSSx2.Px2">
<h6 class="ltx_title ltx_title_paragraph">Conversational Recommendation</h6>
<div class="ltx_para" id="Ch4.S1.SS2.SSSx2.Px2.p1">
<p class="ltx_p" id="Ch4.S1.SS2.SSSx2.Px2.p1.1">LLMs can also drive NL recommendation dialogues where users <span class="ltx_text ltx_font_italic" id="Ch4.S1.SS2.SSSx2.Px2.p1.1.1">interactively</span> convey various intents, including: stating and refining preferences, critiquing recommendations, asking questions, or engaging in trade-off negotiations (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>). Conversational recommendation systems (CRSs) can facilitate such complex dialogues by leveraging LLMs
to generate a variety of personalized responses, including recommendations and explanations, answers to questions, and requests for more information. Thus, the general reasoning abilities of LLMs provide opportunities to better personalize not only recommendations, but also user-system interaction sessions more broadly.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S1.SS2.SSSx2.Px3">
<h6 class="ltx_title ltx_title_paragraph">Limitations of LLM-Driven Recommendation</h6>
<div class="ltx_para" id="Ch4.S1.SS2.SSSx2.Px3.p1">
<p class="ltx_p" id="Ch4.S1.SS2.SSSx2.Px3.p1.1">Unfortunately, these LLM-driven opportunities for RSs also come with new risks, biases, and limitations, as discussed further in Chapter 7. Firstly, LLMs may hallucinate, generating outputs which are incorrect or misleading <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ji2023survey</span>]</cite> which creates significant risks in settings where reliability is key. More broadly, our ability to control LLM behaviour is limited: while prompt engineering and fine-tuning influence outputs, neither approach achieves total control <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mialon2023augmented</span>]</cite>.
More optimistically however, this chapter also discusses approaches to mitigate some of these limitations, including through retrieval-augmented generation (RAG) and external tool calls to improve system control and reliability (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5" title="4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>).</p>
</div>
</section>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S1.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1.3 </span>Chapter Outline</h4>
<div class="ltx_para" id="Ch4.S1.SS3.p1">
<p class="ltx_p" id="Ch4.S1.SS3.p1.1">Before diving into recommendation methodologies, we first present a structured overview of NL data sources for describing items, users, and interactions in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2" title="4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_tag">4.2</span></a>. Then, as summarized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F2" title="Figure 4.2 ‣ General Recommendation Reasoning with LLMs ‣ 4.1.2 General vs. Specialized Recommendation Reasoning ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_tag">4.2</span></a>, the subsequent sections cover key techniques and research in LLM-driven recommendation. First, we describe single turn LLM recommendation, covering the use of both encoder-only and autoregressive models (c.f. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3" title="4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_tag">4.3</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4" title="4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a>). The next two sections focus on synergies between LLMs, conventional RSs, and information retrieval in a discussion of RAG (c.f. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5" title="4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a>) and LLM-based representation generation (c.f. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6" title="4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_tag">4.6</span></a>). Finally, we look at architectures for conversational recommendation, surveying various approaches for managing multi-turn and multi-intent dialogues (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>).</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch4.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.2 </span>Data Sources in LLM-Driven RSs</h3>
<div class="ltx_para" id="Ch4.S2.p1">
<p class="ltx_p" id="Ch4.S2.p1.1">The use of language in recommendation is not new. For instance, text has long been leveraged for content-based recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lops2011content</span>]</cite>, key-phrase explanations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2013hidden</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2019deep</span>]</cite>, and metadata-driven Dialogue State Tracking (DST, <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2017building</span>]</cite>).
However, LLM’s have enabled far more advanced NL reasoning about items, users, and their interactions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>]</cite>, creating opportunities for more nuanced and interactive RS personalization. This section thus outlines the primary data sources which could be used by LLM-era RS, covering item data, interaction data, and user profiles, summarized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F1" title="Figure 4.1 ‣ 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
<section class="ltx_subsection" id="Ch4.S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2.1 </span>Item Text</h4>
<div class="ltx_para" id="Ch4.S2.SS1.p1">
<p class="ltx_p" id="Ch4.S2.SS1.p1.1">The right side of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F1" title="Figure 4.1 ‣ 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_tag">4.1</span></a> illustrates data sources for textual item representations, including titles, descriptions, metadata, and reviews.</p>
</div>
<section class="ltx_subsubsection" id="Ch4.S2.SS1.SSSx1">
<h5 class="ltx_title ltx_title_subsubsection">Titles</h5>
<div class="ltx_para" id="Ch4.S2.SS1.SSSx1.p1">
<p class="ltx_p" id="Ch4.S2.SS1.SSSx1.p1.1">In most settings, items are assigned a <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS1.SSSx1.p1.1.1">title</span>: a short, descriptive text span which aims to distinguish the item. A title’s capacity to represent an item can vary greatly with domain and item popularity: for example while some hit movies and books can be summarized in one or two words (e.g., <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS1.SSSx1.p1.1.2">“Titanic (1999)”</span>, <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS1.SSSx1.p1.1.3">“Dune (1965)”</span>), less unique and less popular items (e.g., articles of clothing) do not have such information-dense titles. Items may even entirely lack titles in certain domains, such as user-generated social media video recommendation, though in these cases, it may be possible to generate titles from visual content and metadata with a multimodal LLM (c.f. Ch. 5).</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S2.SS1.SSSx2">
<h5 class="ltx_title ltx_title_subsubsection">Descriptions</h5>
<div class="ltx_para" id="Ch4.S2.SS1.SSSx2.p1">
<p class="ltx_p" id="Ch4.S2.SS1.SSSx2.p1.1">Items may also be associated with longer and more detailed NL content which we call <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS1.SSSx2.p1.1.1">descriptions</span>, which may be human-written or LLM generated (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">acharya2023llm</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2024llmrec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023personalized</span>]</cite>). The length and format of descriptions can vary greatly across domains, ranging from non-existent (e.g., social media videos), to short summaries (e.g., eShopping products), to many pages long (e.g., news articles and books).</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S2.SS1.SSSx3">
<h5 class="ltx_title ltx_title_subsubsection">Metadata</h5>
<div class="ltx_para" id="Ch4.S2.SS1.SSSx3.p1">
<p class="ltx_p" id="Ch4.S2.SS1.SSSx3.p1.1">Item metadata often contains <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS1.SSSx3.p1.1.1">structured</span> information about item attributes such as product categories, brands, technical specifications, price, release date, and so on. It can contain various types of information including numerical, categorical, temporal, geographical, and visual data.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S2.SS1.SSSx4">
<h5 class="ltx_title ltx_title_subsubsection">Reviews</h5>
<div class="ltx_para" id="Ch4.S2.SS1.SSSx4.p1">
<p class="ltx_p" id="Ch4.S2.SS1.SSSx4.p1.1">A plentiful source of user-generated text are often reviews – which express nuanced opinions across a diverse range of item attributes and user experiences. However, reviews are often highly subjective, especially when describing “soft” attributes such as “inexpensive”, “funny”, or “safe”
<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">radlinski2022subjective</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">balog2021interpretation</span>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2.2 </span>Interaction Data</h4>
<div class="ltx_para" id="Ch4.S2.SS2.p1">
<p class="ltx_p" id="Ch4.S2.SS2.p1.1">The top and bottom of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F1" title="Figure 4.1 ‣ 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_tag">4.1</span></a> illustrate sources of user-system interaction data, including both non-textual interactions (e.g., clicks, purchases, etc.) and NL interactions such as queries, dialogue utterances, and reviews (discussed in the previous section).</p>
</div>
<section class="ltx_subsubsection" id="Ch4.S2.SS2.SSSx1">
<h5 class="ltx_title ltx_title_subsubsection">Verbalizing Non-Textual Interactions</h5>
<div class="ltx_para" id="Ch4.S2.SS2.SSSx1.p1">
<p class="ltx_p" id="Ch4.S2.SS2.SSSx1.p1.1">Conventional non-textual user-item interaction history – such as views, clicks, likes, purchases, and ratings – can easily be represented as text. For this, a simple template may be sufficient – for instance, <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">hou2023large</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">hou2023large</span></cite>) represent a user’s movie viewing history with a template such as: <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS2.SSSx1.p1.1.1">“I’ve watched the following movies in the past in order: 1. Multiplicity, 2. Jurassic Park, … ”</span>. Alternatively, LLMs can be prompted to summarize such interaction histories <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2023heterogeneous</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2024llmrec</span>]</cite>. In either case, such verbalized histories offer an alternative to the sometimes arbitrary mapping of distinct interactions types to numerical or categorical formats, and can also cover pointwise, sequential, and bundle interactions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S2.SS2.SSSx2">
<h5 class="ltx_title ltx_title_subsubsection">NL Interactions</h5>
<div class="ltx_para" id="Ch4.S2.SS2.SSSx2.p1">
<p class="ltx_p" id="Ch4.S2.SS2.SSSx2.p1.1">Other user-system interactions are inherently text-based – for instance, reviews were already discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS1" title="4.2.1 Item Text ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_tag">4.2.1</span></a>.</p>
</div>
<section class="ltx_paragraph" id="Ch4.S2.SS2.SSSx2.Px1">
<h6 class="ltx_title ltx_title_paragraph">Queries</h6>
<div class="ltx_para" id="Ch4.S2.SS2.SSSx2.Px1.p1">
<p class="ltx_p" id="Ch4.S2.SS2.SSSx2.Px1.p1.1">While RSs have traditionally focused on query-less personalization, <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS2.SSSx2.Px1.p1.1.1">queries</span> – short text spans expressing a user’s real-time information need – are becoming a key part of language-driven RSs <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">reddy2022shopping</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">he2022query</span>]</cite>. In fact, this integration of NL queries into RSs is contributing to the convergence of the recommendation and information retrieval (IR) fields.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S2.SS2.SSSx2.Px2">
<h6 class="ltx_title ltx_title_paragraph">User-System Dialogue</h6>
<div class="ltx_para" id="Ch4.S2.SS2.SSSx2.Px2.p1">
<p class="ltx_p" id="Ch4.S2.SS2.SSSx2.Px2.p1.1">As conversational recommendation systems (CRS) develop, user-system <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS2.SSSx2.Px2.p1.1.1">dialogues</span> are emerging as a primary source of textual interaction data <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018towards</span>]</cite>.
Each user and system utterance can reflect diverse intents, including conveying preferences, recommendations, and explanations, as well as asking and answering questions about items or preferences <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lyu2021workflow</span>]</cite>, as discussed further in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S2.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2.3 </span>NL User Profiles</h4>
<div class="ltx_para" id="Ch4.S2.SS3.p1">
<p class="ltx_p" id="Ch4.S2.SS3.p1.1">The left side of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F1" title="Figure 4.1 ‣ 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_tag">4.1</span></a> illustrates various textual representations of user preferences, including metadata and NL user profiles.
Recently, <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">radlinski2022natural</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">radlinski2022natural</span></cite>) proposed that language-driven recommendation could be centered on <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS3.p1.1.1">scrutable</span> NL user profiles: textual descriptions of user preferences that are editable and understandable by humans. Such user profiles could succinctly summarize user interests through both specific examples of preferred items
and generic preference descriptions.</p>
</div>
<div class="ltx_para" id="Ch4.S2.SS3.p2">
<p class="ltx_p" id="Ch4.S2.SS3.p2.1">While research on effectively generating, editing, and leveraging these interpretable NL preference representations is still nascent, several initial studies have emerged. For instance, <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span></cite>) have users directly express generic NL item preferences in personal NL profiles, while other authors <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2023heterogeneous</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite> use and LLM to generate NL profiles based on item rating histories – both works find that recommendation performance is competitive with or better than conventional baselines in cold-start settings.</p>
</div>
<section class="ltx_paragraph" id="Ch4.S2.SS3.SSS0.Px1">
<h6 class="ltx_title ltx_title_paragraph">User Agency via Editable NL Profiles</h6>
<div class="ltx_para" id="Ch4.S2.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="Ch4.S2.SS3.SSS0.Px1.p1.1">In principle, an editable NL profile has the potential to empower users to correct system errors, safeguard their privacy, and exert natural control over their preference representations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">radlinski2022natural</span>]</cite>. It may also be well-suited to handle <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS3.SSS0.Px1.p1.1.1">preference shifts</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hosseinzadeh2015adapting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pereira2018analyzing</span>]</cite> by allowing users to delete obsolete interests or describe temporary contexts. In addition, users can express <span class="ltx_text ltx_font_italic" id="Ch4.S2.SS3.SSS0.Px1.p1.1.2">aspirations</span> - desires that do not necessarily align with past behavior, but should influence future recommendations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ekstrand2016behaviorism</span>]</cite>. Finally, user edits that result in improved recommendations can incentivize further feedback and increase user satisfaction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bostandjiev2012tasteweights</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">harper2015putting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">knijnenburg2012inspectability</span>]</cite>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="Ch4.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.3 </span>Encoder-only LLM Recommendation</h3>
<figure class="ltx_figure" id="Ch4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="311" id="Ch4.F3.g1" src="extracted/5803119/fig/ch4_dense_vs_cross.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.3: </span>Two main architectures for encoder-only LLM recommendation: a) dense retrievers (left) which encode item and preference descriptions separately and then compute a preference-item embedding similarity score and b) cross-encoders (right) which jointly encode user preference and item descriptions to predict a score.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S3.p1">
<p class="ltx_p" id="Ch4.S3.p1.1">We now begin our discussion of how textual data can be used in LLM-driven RSs – starting with recommendation with encoder-only LLMs. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F3" title="Figure 4.3 ‣ 4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_tag">4.3</span></a>, encoder-only LLMs can be used in two main architectures: as dense retrievers (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3.SS1" title="4.3.1 Dense Retrievers ‣ 4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_tag">4.3.1</span></a>) or as cross-encoders (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3.SS2" title="4.3.2 Cross-Encoders ‣ 4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_tag">4.3.2</span></a>). The key difference is that dense retrievers encode preference and item descriptions <span class="ltx_text ltx_font_italic" id="Ch4.S3.p1.1.1">separately</span> while cross-encoders encode them <span class="ltx_text ltx_font_italic" id="Ch4.S3.p1.1.2">jointly</span>, which generally makes cross-encoders slower but more accurate.</p>
</div>
<section class="ltx_subsection" id="Ch4.S3.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3.1 </span>Dense Retrievers</h4>
<div class="ltx_para" id="Ch4.S3.SS1.p1">
<p class="ltx_p" id="Ch4.S3.SS1.p1.1">First introduced in the field of information retrieval (IR), dense retrievers
produce a ranked list of documents given a query by evaluating the similarity (e.g., dot product or cosine similarity) between a document embedding and query embedding <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2022pre</span>]</cite>. Dense retrieval is highly scalable (especially with approximate search libraries like
FAISS<span class="ltx_note ltx_role_footnote" id="Ch4.footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_href" href="https://github.com/facebookresearch/faiss" title="">https://github.com/facebookresearch/faiss</a></span></span></span>) since document embeddings can be pre-computed and only the query embedding needs to calculated at query time.</p>
</div>
<div class="ltx_para" id="Ch4.S3.SS1.p2">
<p class="ltx_p" id="Ch4.S3.SS1.p2.1">To use dense retrieval for recommendation, first, a component of each item’s text content, such as its title, description, reviews, etc., is treated as a document. Then, a query is formed by some NL user preference description – for instance: an actual search query, the user’s recently liked item titles, or text generated based on a user utterance in a dialogue <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">penha2020does</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch4.S3.SS1.p3">
<p class="ltx_p" id="Ch4.S3.SS1.p3.1">Several recent works explore recommendation as standard dense retrieval, including with off-the-shelf <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">penha2020does</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">harte2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023recipe</span>]</cite> and fine-tuned <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mysore2023large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023gpt4rec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hou2023large</span>]</cite> retrievers. Dense retrieval is especially common in news recommendation since news articles are very rich in text – here, a common approach is to aggregate embeddings of a user’s recently liked articles into a query embedding, either via mean pooling <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">iana2023simplifying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">iana2024news</span>]</cite> or a multi-level encoder (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2019neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2019npa</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2022miner</span>]</cite>), before scoring with news candidate embeddings. Another line of work focuses on retrieval using item reviews, and includes studies of contrastive retriever tuning <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">abdollah2023self</span>]</cite> and multi-aspect retrieval <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">korikov2024multi</span>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S3.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3.2 </span>Cross-Encoders</h4>
<div class="ltx_para" id="Ch4.S3.SS2.p1">
<p class="ltx_p" id="Ch4.S3.SS2.p1.1">In contrast to dense retrievers, cross-encoders embed a query and document <span class="ltx_text ltx_font_italic" id="Ch4.S3.SS2.p1.1.1">jointly</span>, allowing cross-attention between query and document tokens <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2022pre</span>]</cite>. Several works approach rating prediction by jointly embedding NL item and preference descriptions in LLM cross-encoder architectures with a rating prediction head <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2021unbert</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yao2022reprbert</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2021empowering</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">qiu2021u</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023prompt</span>]</cite>. Such fusion-in-encoder methods often exhibit strong performance because they allow interaction between user and item representations, but are much more computationally expensive than dense retrieval
and thus may be best used for small item sets or as rerankers.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch4.S4">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.4 </span>Generative Recommendation and Explanation</h3>
<figure class="ltx_figure" id="Ch4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="359" id="Ch4.F4.g1" src="extracted/5803119/fig/ch4_prompts.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.4: </span>Three examples of generative recommendation with autoregressive LLMs, showing alternative user preference representations and prompting approaches. a) A ZS prompt with a user-generated NL preference description. b) A FS prompt based on sequences of liked item titles from multiple users. c) An ID-based prompt to a tuned LLM which has learned to use item and user ID tokens.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S4.p1">
<p class="ltx_p" id="Ch4.S4.p1.1">We next move beyond item-preference scoring to generative recommendation (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS1" title="4.4.1 Zero- and Few-Shot Recommendation ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4.1</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS2" title="4.4.2 LLM Tuning for Generative Recommendation ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4.2</span></a>) and explanation (c.f. Sec <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS3" title="4.4.3 Generative Explanation ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4.3</span></a>) with autoregressive LLMs. Autoregressive LLM inputs are called <span class="ltx_text ltx_font_italic" id="Ch4.S4.p1.1.1">prompts</span>, which are sequences of tokens expressing a task such as top-k recommendation, rating prediction, or explanation generation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>]</cite>. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a>, prompts typically consist of word tokens (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> a-b), but may also feature non-word tokens such as user and item IDs (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> c) that can be learned through tuning (c.f. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S4.SS2" title="4.4.2 LLM Tuning for Generative Recommendation ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4.2</span></a>). While the space of possible LLM inputs and outputs is extremely large, common tasks include generating:</p>
<ul class="ltx_itemize" id="Ch4.S4.I1">
<li class="ltx_item" id="Ch4.S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I1.i1.p1">
<p class="ltx_p" id="Ch4.S4.I1.i1.p1.1">a recommended list of item titles or ids (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2023unitrec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">harte2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sileo2022zero</span>]</cite>)</p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I1.i2.p1">
<p class="ltx_p" id="Ch4.S4.I1.i2.p1.1">item ratings (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bao2023tallrec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2023llms</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite>)</p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I1.i3.p1">
<p class="ltx_p" id="Ch4.S4.I1.i3.p1.1">explanations of recommendations (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ni2019justifying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020generate</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hada2021rexplug</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023personalized</span>]</cite>)</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="Ch4.S4.p2">
<p class="ltx_p" id="Ch4.S4.p2.1">This section further discuses such single-turn (i.e., non-conversational), autoregressive LLM recommendation and explanation, covering both untuned and tuned approaches.</p>
</div>
<section class="ltx_subsection" id="Ch4.S4.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4.1 </span>Zero- and Few-Shot Recommendation</h4>
<div class="ltx_para" id="Ch4.S4.SS1.p1">
<p class="ltx_p" id="Ch4.S4.SS1.p1.1">The simplest way an autoregressive LLMs can be used is in the <span class="ltx_text ltx_font_italic" id="Ch4.S4.SS1.p1.1.1">untuned</span> (i.e., “off-the-shelf”) setting (e.g. <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sileo2022zero</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span>]</cite>). As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a>, this includes:</p>
<ul class="ltx_itemize" id="Ch4.S4.I2">
<li class="ltx_item" id="Ch4.S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I2.i1.p1">
<p class="ltx_p" id="Ch4.S4.I2.i1.p1.1">zero-shot (ZS) approaches, which rely solely on the LLM’s pre-trained knowledge without any additional training data (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> a)</p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I2.i2.p1">
<p class="ltx_p" id="Ch4.S4.I2.i2.p1.1">few-shot (FS) approaches, which provide a small number of input-output examples in the prompt (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> b), and thus are also referred to as in-context-learning (ICL) methods.</p>
</div>
</li>
</ul>
</div>
<section class="ltx_paragraph" id="Ch4.S4.SS1.SSS0.Px1">
<h6 class="ltx_title ltx_title_paragraph">Zero- and Few-Shot Prompt Engineering</h6>
<div class="ltx_para" id="Ch4.S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="Ch4.S4.SS1.SSS0.Px1.p1.1">Clearly, there is a large design space for prompting approaches, including choices for representing user preferences, specifying task instructions, and selecting few-shot examples. Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> illustrates two specific examples from this design space <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span>]</cite>: a) a ZS prompt with a user-generated NL preference description, and b) a FS prompt based on sequences of liked movie titles from multiple users. Many other variants are possible, for instance: constructing FS examples based on interactions from the <span class="ltx_text ltx_font_italic" id="Ch4.S4.SS1.SSS0.Px1.p1.1.1">same</span> user instead of from different users, including user <span class="ltx_text ltx_font_italic" id="Ch4.S4.SS1.SSS0.Px1.p1.1.2">dis</span>preferences, or using LLM-generated user profiles <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S4.SS1.SSS0.Px2">
<h6 class="ltx_title ltx_title_paragraph">Initial Experimental Findings</h6>
<div class="ltx_para" id="Ch4.S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="Ch4.S4.SS1.SSS0.Px2.p1.1">Several recent publications have evaluated off-the-shelf LLMs for movie and book recommendation – domains where relevant knowledge is likely to be internalized during pretraining. Specifically, these methods construct prompts using NL representations of user preferences and instructions to recommend item titles <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sileo2022zero</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023chatgpt</span>]</cite> or predict ratings <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2023llms</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023chatgpt</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite>. These initial studies find that while untuned LLMs generally underperform supervised CF methods given sufficient training data <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2023llms</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sileo2022zero</span>]</cite>, they are competitive in near cold-start settings <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sileo2022zero</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sanner2023large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite>. They also suggest that FS typically outperforms ZS prompting and that LLMs struggle with negated reasoning in recommendation (e.g. reasoning about <span class="ltx_text ltx_font_italic" id="Ch4.S4.SS1.SSS0.Px2.p1.1.1">dis</span>preferences).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S4.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4.2 </span>LLM Tuning for Generative Recommendation</h4>
<div class="ltx_para" id="Ch4.S4.SS2.p1">
<p class="ltx_p" id="Ch4.S4.SS2.p1.1">To improve an LLM’s generative recommendation performance, multiple works study LLM tuning on historical RS data. First, historical data is converted into textual input-output training pairs for generative recommendation tasks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>]</cite>, which may include:</p>
<ul class="ltx_itemize" id="Ch4.S4.I3">
<li class="ltx_item" id="Ch4.S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I3.i1.p1">
<p class="ltx_p" id="Ch4.S4.I3.i1.p1.1">top-<math alttext="k" class="ltx_Math" display="inline" id="Ch4.S4.I3.i1.p1.1.m1.1"><semantics id="Ch4.S4.I3.i1.p1.1.m1.1a"><mi id="Ch4.S4.I3.i1.p1.1.m1.1.1" xref="Ch4.S4.I3.i1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch4.S4.I3.i1.p1.1.m1.1b"><ci id="Ch4.S4.I3.i1.p1.1.m1.1.1.cmml" xref="Ch4.S4.I3.i1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S4.I3.i1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch4.S4.I3.i1.p1.1.m1.1d">italic_k</annotation></semantics></math> recommendation (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023prompt</span>]</cite>), such as in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> a-b</p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I3.i2.p1">
<p class="ltx_p" id="Ch4.S4.I3.i2.p1.1">sequential recommendation (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">harte2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023prompt</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2023unitrec</span>]</cite>), such as in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> c</p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I3.i3.p1">
<p class="ltx_p" id="Ch4.S4.I3.i3.p1.1">rating prediction (e.g.,<cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bao2023tallrec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2023llms</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023collm</span>]</cite>)</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Ch4.S4.SS2.p1.2">Notably, <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span></cite> <span class="ltx_text ltx_font_italic" id="Ch4.S4.SS2.p1.2.1">et al.</span> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span></cite>) point out that text is a unifying format for training data, enabling multi-task LLM tuning on all of the above tasks. They also show that LLMs can learn to use user and item ID tokens for these tasks (e.g., Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F4" title="Figure 4.4 ‣ 4.4 Generative Recommendation and Explanation"><span class="ltx_text ltx_ref_tag">4.4</span></a> c).</p>
</div>
<div class="ltx_para" id="Ch4.S4.SS2.p2">
<p class="ltx_p" id="Ch4.S4.SS2.p2.1">Given textual RS training data, the two main approaches to LLM tuning are:</p>
<ul class="ltx_itemize" id="Ch4.S4.I4">
<li class="ltx_item" id="Ch4.S4.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I4.i1.p1">
<p class="ltx_p" id="Ch4.S4.I4.i1.p1.1"><span class="ltx_text ltx_font_italic" id="Ch4.S4.I4.i1.p1.1.1">fine-tuning</span>, where training set performance is optimized by adjusting LLM weights <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bao2023tallrec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">harte2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2023unitrec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2023llms</span>]</cite></p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I4.i2.p1">
<p class="ltx_p" id="Ch4.S4.I4.i2.p1.1"><span class="ltx_text ltx_font_italic" id="Ch4.S4.I4.i2.p1.1.1">prompt-tuning</span> where training set performance is optimized by learning prompt tokens (hard prompt-tuning) or embeddings (soft prompt-tuning) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023personalized</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">cui2022m6</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023collm</span>]</cite></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S4.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4.3 </span>Generative Explanation</h4>
<div class="ltx_para" id="Ch4.S4.SS3.p1">
<p class="ltx_p" id="Ch4.S4.SS3.p1.1">Autoregressive LLMs can also generate explanations that aim to help users comprehend why recommendations were made. Similarly to recommendation generation, explanations can be generated by prompting LLMs that are either untuned (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rahdari2024logic</span>]</cite>) or tuned (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023personalized</span>]</cite>) – though the latter is more common for academic publications. To tune LLMs for RS explanation, the typical data source for constructing textual training examples are user reviews, as these are assumed to contain justifications for users’ opinions about the reviewed items <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ni2019justifying</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch4.S4.SS3.p2">
<p class="ltx_p" id="Ch4.S4.SS3.p2.1">Broadly, recently studied techniques for RS explanation generation include:</p>
<ul class="ltx_itemize" id="Ch4.S4.I5">
<li class="ltx_item" id="Ch4.S4.I5.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I5.i1.p1">
<p class="ltx_p" id="Ch4.S4.I5.i1.p1.1">ZS and FS prompting <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rahdari2024logic</span>]</cite></p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I5.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I5.i2.p1">
<p class="ltx_p" id="Ch4.S4.I5.i2.p1.1">fine-tuning <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">geng2022recommendation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023personalized</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2024deciphering</span>]</cite></p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I5.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I5.i3.p1">
<p class="ltx_p" id="Ch4.S4.I5.i3.p1.1">prompt-tuning <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023personalized</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020generate</span>]</cite></p>
</div>
</li>
<li class="ltx_item" id="Ch4.S4.I5.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S4.I5.i4.p1">
<p class="ltx_p" id="Ch4.S4.I5.i4.p1.1">controllable decoding – where predicted parameters such as ratings steer LLM decoding <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ni2018personalized</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ni2019justifying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hada2021rexplug</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xie2023factual</span>]</cite></p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="Ch4.S5">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.5 </span>Retrieval Augmented Recommendation</h3>
<figure class="ltx_figure" id="Ch4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="351" id="Ch4.F5.g1" src="extracted/5803119/fig/ch4_rag.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.5: </span>Two examples of RAG for top-<math alttext="k" class="ltx_Math" display="inline" id="Ch4.F5.2.m1.1"><semantics id="Ch4.F5.2.m1.1b"><mi id="Ch4.F5.2.m1.1.1" xref="Ch4.F5.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch4.F5.2.m1.1c"><ci id="Ch4.F5.2.m1.1.1.cmml" xref="Ch4.F5.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.F5.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="Ch4.F5.2.m1.1e">italic_k</annotation></semantics></math> recommendation, where an external tool produces a candidate item set which an LLM is prompted to rerank given a textual description of user preferences. Top: A query is used by a retriever to search for a candidate item set, which an LLM is prompted to rerank given the query. Bottom: A user’s interaction history is used by an RS to select a candidate item set, which an LLM is prompted to rerank given the interaction history.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S5.p1">
<p class="ltx_p" id="Ch4.S5.p1.1">While the previous two sections explore the use of LLM knowledge internalized through pretraining or tuning to generate recommendations and explanations, relying solely on internal LLM knowledge has several limitations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lewis2020retrieval</span>]</cite>:</p>
<ul class="ltx_itemize" id="Ch4.S5.I1">
<li class="ltx_item" id="Ch4.S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S5.I1.i1.p1">
<p class="ltx_p" id="Ch4.S5.I1.i1.p1.1">a relatively large number of LLM weights are needed to store knowledge</p>
</div>
</li>
<li class="ltx_item" id="Ch4.S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S5.I1.i2.p1">
<p class="ltx_p" id="Ch4.S5.I1.i2.p1.1">retraining is needed for each knowledge update</p>
</div>
</li>
<li class="ltx_item" id="Ch4.S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S5.I1.i3.p1">
<p class="ltx_p" id="Ch4.S5.I1.i3.p1.1">there is no inherent source attribution mechanism</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="Ch4.S5.p2">
<p class="ltx_p" id="Ch4.S5.p2.1">To address these limitations, recent work (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lewis2020retrieval</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">izacard2020leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">borgeaud2022improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mialon2023augmented</span>]</cite>) explores a framework called retrieval-augmented generation (RAG) in which: 1) relevant content is retrieved from an external knowledge source and 2) the retrieved content is used to prompt an autoregressive LLM to generate textual output. These studies provide evidence that, in contrast to approaches relying solely on internal LLM memory, RAG can: reduce the number of LLM parameters (since knowledge can be externalized); provide a convenient mechanism for knowledge updates; improve factuality through better source attribution and by reducing hallucinations.</p>
</div>
<section class="ltx_subsection" id="Ch4.S5.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5.1 </span>RAG in RSs</h4>
<div class="ltx_para" id="Ch4.S5.SS1.p1">
<p class="ltx_p" id="Ch4.S5.SS1.p1.1">There are many opportunities to use RAG in RSs, including to generate recommendations, explanations, and question answers. More broadly, the RAG framework introduces us to modular architectures for LLM-driven RSs – a concept we’ll explore further when discussing LLM representation generation (c.f. Sec. <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:sec:LLM_4_RS_Inputs</span>) and conversational RS architectures (c.f. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>).</p>
</div>
<section class="ltx_paragraph" id="Ch4.S5.SS1.SSS0.Px1">
<h6 class="ltx_title ltx_title_paragraph">RAG for Recommendation</h6>
<div class="ltx_para" id="Ch4.S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="Ch4.S5.SS1.SSS0.Px1.p1.1">As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F5" title="Figure 4.5 ‣ 4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a>, the most commonly studied RAG recommendation method has been LLM candidate item set reranking. Specifically, this method involves: 1) selecting a candidate item set based on RS interaction data and 2) prompting an LLM to rerank the candidate set given some information about user preferences <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2022improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hou2023large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2023palr</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2023zero</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dai2023uncovering</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2024llmrec</span>]</cite>. Recall from Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2" title="4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_tag">4.2</span></a> that user preferences can be represented in diverse forms, leading to many alternatives for candidate selection and reranking methods. For instance, Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F5" title="Figure 4.5 ‣ 4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a> a) illustrates candidate selection with a retriever driven by a user query, and LLM candidate reranking given this query. As another example, Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F5" title="Figure 4.5 ‣ 4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a> b) shows candidate selection with an RS based on item interaction history, and LLM reranking given this history.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S5.SS1.SSS0.Px2">
<h6 class="ltx_title ltx_title_paragraph">RAG for Explanation and Conversational Recommendation</h6>
<div class="ltx_para" id="Ch4.S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="Ch4.S5.SS1.SSS0.Px2.p1.1">Other examples of how RAG can be used in RSs include explanation generation and as a tool for conversational recommendation. For RAG-based explanation generation, <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">xie2023factual</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">xie2023factual</span></cite>) generate queries based on interaction history to retrieve an item’s reviews, which are then used as context to generate an explanation of the recommendation. Examples of RAG in conversational recommendation, discussed further in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>, include work by <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span></cite>) to retrieve relevant user preference descriptions from a user “memory” module, and by <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span></cite>) to retrieve information from an items reviews to answer user questions.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="Ch4.S6">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.6 </span>LLMs Representation Generation</h3>
<figure class="ltx_figure" id="Ch4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="319" id="Ch4.F6.g1" src="extracted/5803119/fig/ch4_llm_feature_gen.png" width="449"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.6: </span>Examples of LLM generated-inputs for downstream modules, including embeddings and predicted item ratings for downstream RSs, and text for downstream search or LLM prompting.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S6.p1">
<p class="ltx_p" id="Ch4.S6.p1.1">While Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5" title="4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a> explored using an external module such as retrievers or RSs to select LLM inputs, this section discusses the converse setting in which LLMs generate inputs to downstream modules, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F6" title="Figure 4.6 ‣ 4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_tag">4.6</span></a>. Specifically, LLMs can be used to transform text such as item and preference descriptions into representations (e.g., embeddings, text, item ratings) that serve as inputs to modules such as RSs, retrievers, or autoregressive LLMs. Such text transformations can be interpreted as an LLM encoding step <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite>, including for the case of text-to-text transformations – such as the generation of user preference profiles based on user history.</p>
</div>
<section class="ltx_subsection" id="Ch4.S6.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6.1 </span>Text to Text</h4>
<div class="ltx_para" id="Ch4.S6.SS1.p1">
<p class="ltx_p" id="Ch4.S6.SS1.p1.1">Two common settings where an LLM generates text that serves as input to a downstream module are search queries and LLM prompt elements, with several example studies for both approaches discussed below.</p>
</div>
<section class="ltx_paragraph" id="Ch4.S6.SS1.SSS0.Px1">
<h6 class="ltx_title ltx_title_paragraph">Search Queries</h6>
<div class="ltx_para" id="Ch4.S6.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="Ch4.S6.SS1.SSS0.Px1.p1.1">Given a user’s item interaction history (and item text), MINT <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mysore2023large</span>]</cite>
and GPT4Rec <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023gpt4rec</span>]</cite> prompt an LLM to generate an search query for a dense retriever with the goal of finding new items to recommend. Similarly, recent work on conversational recommendation uses dialogue history to generate search queries to find items to recommend <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span>]</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S6.SS1.SSS0.Px2">
<h6 class="ltx_title ltx_title_paragraph">Prompt Elements</h6>
<div class="ltx_para" id="Ch4.S6.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="Ch4.S6.SS1.SSS0.Px2.p1.1">As mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S2.SS3" title="4.2.3 NL User Profiles ‣ 4.2 Data Sources in LLM-Driven RSs"><span class="ltx_text ltx_ref_tag">4.2.3</span></a>, recent work <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2023heterogeneous</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2024language</span>]</cite> first uses an LLM to generate a NL user profile based on their interaction history, then prompts an LLM to generate recommendations given this profile. In conversational recommendation, LLMs are often employed to generate prompt elements (or entire prompts) for downstream tasks based on dialogue history <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">(</span>]</cite>e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022unicrs</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2023chat</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span>]</cite>).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S6.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6.2 </span>Text to Embeddings</h4>
<div class="ltx_para" id="Ch4.S6.SS2.p1">
<p class="ltx_p" id="Ch4.S6.SS2.p1.1">As discussed in Chapters 2 and 3, many RS techniques rely on latent representations of items and user preferences. Thus, a recent line of research uses LLMs to encode semantic information from text into latent embeddings which are then used for recommendation. While encoder-only LLM recommendation was already discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S3" title="4.3 Encoder-only LLM Recommendation"><span class="ltx_text ltx_ref_tag">4.3</span></a>, this section covers multi-stage pipelines where LLM embeddings are used for downstream recommendation modules, discussed next.</p>
</div>
<section class="ltx_paragraph" id="Ch4.S6.SS2.SSS0.Px1">
<h6 class="ltx_title ltx_title_paragraph">Sequential Recommendation with LLM Embeddings</h6>
<div class="ltx_para" id="Ch4.S6.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="Ch4.S6.SS2.SSS0.Px1.p1.1">Recall that Chapter 3 discussed several attention-based sequential recommendation models (e.g., BERT4Rec <span class="ltx_text ltx_font_bold" id="Ch4.S6.SS2.SSS0.Px1.p1.1.1">REF</span>, SASRec <span class="ltx_text ltx_font_bold" id="Ch4.S6.SS2.SSS0.Px1.p1.1.2">REF</span>) which predict the next item ID to recommend given a sequence of item IDs that a user has interacted with. Recent work uses LLMs to initialize item ID embeddings based on item text <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">harte2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yuan2023go</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">rajput2024recommender</span>]</cite>, reporting significant performance gains. Similarly, Query-SeqRec <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2022query</span>]</cite> incorporates user query information into sequential recommendation by using an LLM to encode queries alongside item embeddings.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S6.SS2.SSS0.Px2">
<h6 class="ltx_title ltx_title_paragraph">Rating Prediction with LLM Embeddings</h6>
<div class="ltx_para" id="Ch4.S6.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="Ch4.S6.SS2.SSS0.Px2.p1.1">LLMs have also been used to generate latent representations of items (based on item text) and users (based on item interactions) that serve as inputs to a neural network which predicts a user-item rating <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2021empowering</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yuan2023go</span>]</cite>. These approaches essentially augment the well-known neural collaborative filtering <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2017neural</span>]</cite> framework with LLM embeddings.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S6.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6.3 </span>Text to Item Ratings</h4>
<div class="ltx_para" id="Ch4.S6.SS3.p1">
<p class="ltx_p" id="Ch4.S6.SS3.p1.1">As discussed further in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7" title="4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>, LLMs have been used to map dialogue history to item rating predictions, with these ratings then treated as observations by an RS to make recommendations. Examples include sentiment analysis towards items mentioned in a dialogue <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018conversational</span>]</cite> and natural language inference between user-stated aspect preferences and item text <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">austin2024bayesian</span>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch4.S7">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.7 </span>Conversational Recommendation</h3>
<div class="ltx_para" id="Ch4.S7.p1">
<p class="ltx_p" id="Ch4.S7.p1.1">The previous sections mostly focused on single-turn LLM recommendation personalized based on <span class="ltx_text ltx_font_italic" id="Ch4.S7.p1.1.1">pre-existing</span> user history information, such as non-verbal interactions, queries, reviews, and so on (c.f. Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F1" title="Figure 4.1 ‣ 4.1.1 Natural Language vs. Non-Textual Interaction Data ‣ 4.1 Introduction"><span class="ltx_text ltx_ref_tag">4.1</span></a>), and item text. However, LLMs provide new opportunities for multi-turn conversational recommender systems (CRSs) where each turn presents a chance for the user to clarify or revise their preferences, critique and ask questions about recommended items, or convey a variety of other real-time intents such as those shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.T1" title="Table 4.1 ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.1</span></a> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lyu2021workflow</span>]</cite>. Correspondingly, CRSs should facilitate a wide range of responses
including revising recommendations, responding to questions, and personalizing explanations. Further, each turn is also an opportunity for the CRS to generate proactive utterances such as clarifying questions or explanations focused on key topics to help elicit user preferences. As with user intents, various possible CRS actions are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.T2" title="Table 4.2 ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.2</span></a> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lyu2021workflow</span>]</cite>. LLM-driven CRSs thus present opportunities not only to personalize recommendations, but also to personalize system interactions more broadly.</p>
</div>
<figure class="ltx_table" id="Ch4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4.1: </span>The user intent conversational recommendation taxonomy of <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lyu2021workflow</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lyu2021workflow</span></cite>), with <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T1.2.m1.1"><semantics id="Ch4.T1.2.m1.1b"><mo id="Ch4.T1.2.m1.1.1" xref="Ch4.T1.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T1.2.m1.1c"><ci id="Ch4.T1.2.m1.1.1.cmml" xref="Ch4.T1.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T1.2.m1.1d">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T1.2.m1.1e">†</annotation></semantics></math> indicating a additional category to the taxonomy of <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cai2020predicting</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cai2020predicting</span></cite>).</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="Ch4.T1.5" style="width:433.6pt;height:205.7pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-182.5pt,86.4pt) scale(0.542980145069873,0.542980145069873) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Ch4.T1.5.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="Ch4.T1.5.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ch4.T1.5.3.4.1.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.4.1.1.1">Category</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ch4.T1.5.3.4.1.2"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.4.1.2.1">Description</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ch4.T1.5.3.4.1.3"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.4.1.3.1">Example</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Ch4.T1.5.3.5.1" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ch4.T1.5.3.5.1.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.5.1.1.1" style="background-color:#FFFFFF;">Ask for Recommendation</span></td>
<td class="ltx_td ltx_border_t" id="Ch4.T1.5.3.5.1.2"></td>
<td class="ltx_td ltx_border_t" id="Ch4.T1.5.3.5.1.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.6.2" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.6.2.1"><span class="ltx_text" id="Ch4.T1.5.3.6.2.1.1" style="background-color:#F2F2F2;">Initial Query</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.6.2.2"><span class="ltx_text" id="Ch4.T1.5.3.6.2.2.1" style="background-color:#F2F2F2;">User asks for a recommendation in the first query</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.6.2.3"><span class="ltx_text" id="Ch4.T1.5.3.6.2.3.1" style="background-color:#F2F2F2;">“Hi I am looking for a place to have a family brunch…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.7.3" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.7.3.1"><span class="ltx_text" id="Ch4.T1.5.3.7.3.1.1" style="background-color:#FFFFFF;">Continue</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.7.3.2"><span class="ltx_text" id="Ch4.T1.5.3.7.3.2.1" style="background-color:#FFFFFF;">User asks for another recommendation in a subsequent query</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.7.3.3"><span class="ltx_text" id="Ch4.T1.5.3.7.3.3.1" style="background-color:#FFFFFF;">“Maybe you can give me one more choice so I can pick one…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.8.4" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.8.4.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.8.4.1.1" style="background-color:#F2F2F2;">Provide Preference</span></td>
<td class="ltx_td" id="Ch4.T1.5.3.8.4.2"></td>
<td class="ltx_td" id="Ch4.T1.5.3.8.4.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.3.1.1" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.3.1.1.1"><span class="ltx_text" id="Ch4.T1.3.1.1.1.1" style="background-color:#FFFFFF;">Provide Context <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T1.3.1.1.1.1.m1.1"><semantics id="Ch4.T1.3.1.1.1.1.m1.1a"><mo id="Ch4.T1.3.1.1.1.1.m1.1.1" mathbackground="#FFFFFF" xref="Ch4.T1.3.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T1.3.1.1.1.1.m1.1b"><ci id="Ch4.T1.3.1.1.1.1.m1.1.1.cmml" xref="Ch4.T1.3.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T1.3.1.1.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T1.3.1.1.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.3.1.1.2"><span class="ltx_text" id="Ch4.T1.3.1.1.2.1" style="background-color:#FFFFFF;">User provides background information for the restaurant search</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.3.1.1.3"><span class="ltx_text" id="Ch4.T1.3.1.1.3.1" style="background-color:#FFFFFF;">“I am looking for a restaurant for my Valentine’s day dinner.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.9.5" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.9.5.1"><span class="ltx_text" id="Ch4.T1.5.3.9.5.1.1" style="background-color:#F2F2F2;">Provide Preference</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.9.5.2"><span class="ltx_text" id="Ch4.T1.5.3.9.5.2.1" style="background-color:#F2F2F2;">User provides specific preference for the desired item</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.9.5.3"><span class="ltx_text" id="Ch4.T1.5.3.9.5.3.1" style="background-color:#F2F2F2;">“I would prefer a place that has a very good scenic view.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.4.2.2" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.4.2.2.1"><span class="ltx_text" id="Ch4.T1.4.2.2.1.1" style="background-color:#FFFFFF;">Refine Preference <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T1.4.2.2.1.1.m1.1"><semantics id="Ch4.T1.4.2.2.1.1.m1.1a"><mo id="Ch4.T1.4.2.2.1.1.m1.1.1" mathbackground="#FFFFFF" xref="Ch4.T1.4.2.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T1.4.2.2.1.1.m1.1b"><ci id="Ch4.T1.4.2.2.1.1.m1.1.1.cmml" xref="Ch4.T1.4.2.2.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T1.4.2.2.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T1.4.2.2.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.4.2.2.2"><span class="ltx_text" id="Ch4.T1.4.2.2.2.1" style="background-color:#FFFFFF;">User improves over-constrained/under-constrained preferences</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.4.2.2.3"><span class="ltx_text" id="Ch4.T1.4.2.2.3.1" style="background-color:#FFFFFF;">“It does not have to be chicken fingers.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.10.6" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.10.6.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.10.6.1.1" style="background-color:#F2F2F2;">Answer</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.10.6.2"><span class="ltx_text" id="Ch4.T1.5.3.10.6.2.1" style="background-color:#F2F2F2;">User answers the question issued by the recommender</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.10.6.3"><span class="ltx_text" id="Ch4.T1.5.3.10.6.3.1" style="background-color:#F2F2F2;">“Yes that’s correct.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.3" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.3.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.3.1.1" style="background-color:#FFFFFF;">Acknowledgement <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T1.5.3.3.1.1.m1.1"><semantics id="Ch4.T1.5.3.3.1.1.m1.1a"><mo id="Ch4.T1.5.3.3.1.1.m1.1.1" mathbackground="#FFFFFF" xref="Ch4.T1.5.3.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T1.5.3.3.1.1.m1.1b"><ci id="Ch4.T1.5.3.3.1.1.m1.1.1.cmml" xref="Ch4.T1.5.3.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T1.5.3.3.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T1.5.3.3.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.3.2"><span class="ltx_text" id="Ch4.T1.5.3.3.2.1" style="background-color:#FFFFFF;">User shows understanding towards a previous recommender utterance</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.3.3"><span class="ltx_text" id="Ch4.T1.5.3.3.3.1" style="background-color:#FFFFFF;">“ I see.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.11.7" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.11.7.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.11.7.1.1" style="background-color:#F2F2F2;">Recommendation Rating</span></td>
<td class="ltx_td" id="Ch4.T1.5.3.11.7.2"></td>
<td class="ltx_td" id="Ch4.T1.5.3.11.7.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.12.8" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.12.8.1"><span class="ltx_text" id="Ch4.T1.5.3.12.8.1.1" style="background-color:#FFFFFF;">Been to (modified)</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.12.8.2"><span class="ltx_text" id="Ch4.T1.5.3.12.8.2.1" style="background-color:#FFFFFF;">User has been to the restaurant before</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.12.8.3"><span class="ltx_text" id="Ch4.T1.5.3.12.8.3.1" style="background-color:#FFFFFF;">“Oh I have been there before.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.13.9" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.13.9.1"><span class="ltx_text" id="Ch4.T1.5.3.13.9.1.1" style="background-color:#F2F2F2;">Accept</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.13.9.2"><span class="ltx_text" id="Ch4.T1.5.3.13.9.2.1" style="background-color:#F2F2F2;">User accepts the recommended item, either explicitly or implicitly</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.13.9.3"><span class="ltx_text" id="Ch4.T1.5.3.13.9.3.1" style="background-color:#F2F2F2;">“Ok our final choice will be Eggspectation.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.14.10" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.14.10.1"><span class="ltx_text" id="Ch4.T1.5.3.14.10.1.1" style="background-color:#FFFFFF;">Reject</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.14.10.2"><span class="ltx_text" id="Ch4.T1.5.3.14.10.2.1" style="background-color:#FFFFFF;">User rejects the recommended item, either explicitly or implicitly</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.14.10.3"><span class="ltx_text" id="Ch4.T1.5.3.14.10.3.1" style="background-color:#FFFFFF;">“Maybe there is a private room in the other three restaurants?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.15.11" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.15.11.1"><span class="ltx_text" id="Ch4.T1.5.3.15.11.1.1" style="background-color:#F2F2F2;">Neutral Response</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.15.11.2"><span class="ltx_text" id="Ch4.T1.5.3.15.11.2.1" style="background-color:#F2F2F2;">User does not indicate a decision with the current recommendations</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.15.11.3"><span class="ltx_text" id="Ch4.T1.5.3.15.11.3.1" style="background-color:#F2F2F2;">“I will take a look in the menu and compare and maybe ask my partner.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.16.12" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.16.12.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.16.12.1.1" style="background-color:#FFFFFF;">Inquire</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.16.12.2"><span class="ltx_text" id="Ch4.T1.5.3.16.12.2.1" style="background-color:#FFFFFF;">User requires additional information regarding the recommendation</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.16.12.3"><span class="ltx_text" id="Ch4.T1.5.3.16.12.3.1" style="background-color:#FFFFFF;">“So what about the interior design, the decorations and environment?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.17.13" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.17.13.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.17.13.1.1" style="background-color:#F2F2F2;">Critiquing</span></td>
<td class="ltx_td" id="Ch4.T1.5.3.17.13.2"></td>
<td class="ltx_td" id="Ch4.T1.5.3.17.13.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.18.14" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.18.14.1"><span class="ltx_text" id="Ch4.T1.5.3.18.14.1.1" style="background-color:#FFFFFF;">Critique - Feature</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.18.14.2"><span class="ltx_text" id="Ch4.T1.5.3.18.14.2.1" style="background-color:#FFFFFF;">User critiques on a specific feature of the recommended item</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.18.14.3"><span class="ltx_text" id="Ch4.T1.5.3.18.14.3.1" style="background-color:#FFFFFF;">“I am pretty sure it will be expensive so what is the price range?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.19.15" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.19.15.1"><span class="ltx_text" id="Ch4.T1.5.3.19.15.1.1" style="background-color:#F2F2F2;">Critique - Add</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.19.15.2"><span class="ltx_text" id="Ch4.T1.5.3.19.15.2.1" style="background-color:#F2F2F2;">User adds further constraints on top of the current recommendation</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.19.15.3"><span class="ltx_text" id="Ch4.T1.5.3.19.15.3.1" style="background-color:#F2F2F2;">“I want sushi.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.20.16" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.20.16.1"><span class="ltx_text" id="Ch4.T1.5.3.20.16.1.1" style="background-color:#FFFFFF;">Critique - Compare</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.20.16.2"><span class="ltx_text" id="Ch4.T1.5.3.20.16.2.1" style="background-color:#FFFFFF;">User requests comparison between recommended item with another item</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T1.5.3.20.16.3"><span class="ltx_text" id="Ch4.T1.5.3.20.16.3.1" style="background-color:#FFFFFF;">“How about the price compared with Miku??”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T1.5.3.21.17" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ch4.T1.5.3.21.17.1"><span class="ltx_text ltx_font_bold" id="Ch4.T1.5.3.21.17.1.1" style="background-color:#F2F2F2;">Others</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ch4.T1.5.3.21.17.2"><span class="ltx_text" id="Ch4.T1.5.3.21.17.2.1" style="background-color:#F2F2F2;">Greetings, gratitude expression, chit-chat utterance</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ch4.T1.5.3.21.17.3"><span class="ltx_text" id="Ch4.T1.5.3.21.17.3.1" style="background-color:#F2F2F2;">“Thank you so much for your recommendation.”</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="Ch4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4.2: </span>The recommender intent conversational recommendation taxonomy of <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lyu2021workflow</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lyu2021workflow</span></cite>), with <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.2.m1.1"><semantics id="Ch4.T2.2.m1.1b"><mo id="Ch4.T2.2.m1.1.1" xref="Ch4.T2.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.2.m1.1c"><ci id="Ch4.T2.2.m1.1.1.cmml" xref="Ch4.T2.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.2.m1.1d">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.2.m1.1e">†</annotation></semantics></math> indicating a additional category to the taxonomy of <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cai2020predicting</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cai2020predicting</span></cite>).</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="Ch4.T2.11" style="width:433.6pt;height:209.7pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-175.0pt,84.4pt) scale(0.553299917074288,0.553299917074288) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Ch4.T2.11.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="Ch4.T2.11.9.10.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ch4.T2.11.9.10.1.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.10.1.1.1" style="font-size:90%;">Category</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ch4.T2.11.9.10.1.2"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.10.1.2.1" style="font-size:90%;">Description</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ch4.T2.11.9.10.1.3"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.10.1.3.1" style="font-size:90%;">Example</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Ch4.T2.11.9.11.1" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ch4.T2.11.9.11.1.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.11.1.1.1" style="font-size:90%;background-color:#FFFFFF;">Request</span></td>
<td class="ltx_td ltx_border_t" id="Ch4.T2.11.9.11.1.2"></td>
<td class="ltx_td ltx_border_t" id="Ch4.T2.11.9.11.1.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.12.2" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.12.2.1"><span class="ltx_text" id="Ch4.T2.11.9.12.2.1.1" style="font-size:90%;background-color:#F2F2F2;">Request Information</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.12.2.2"><span class="ltx_text" id="Ch4.T2.11.9.12.2.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender requests the user’s preference</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.12.2.3"><span class="ltx_text" id="Ch4.T2.11.9.12.2.3.1" style="font-size:90%;background-color:#F2F2F2;">“What kind of food do you like?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.13.3" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.13.3.1"><span class="ltx_text" id="Ch4.T2.11.9.13.3.1.1" style="font-size:90%;background-color:#FFFFFF;">Clarify Question</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.13.3.2"><span class="ltx_text" id="Ch4.T2.11.9.13.3.2.1" style="font-size:90%;background-color:#FFFFFF;">Recommender asks for clarification on a previous requirement</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.13.3.3"><span class="ltx_text" id="Ch4.T2.11.9.13.3.3.1" style="font-size:90%;background-color:#FFFFFF;">“So you would like to reserve a private room?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.3.1.1" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.3.1.1.1"><span class="ltx_text" id="Ch4.T2.3.1.1.1.1" style="font-size:90%;background-color:#F2F2F2;">Ask Opinion <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.3.1.1.1.1.m1.1"><semantics id="Ch4.T2.3.1.1.1.1.m1.1a"><mo id="Ch4.T2.3.1.1.1.1.m1.1.1" mathbackground="#F2F2F2" xref="Ch4.T2.3.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.3.1.1.1.1.m1.1b"><ci id="Ch4.T2.3.1.1.1.1.m1.1.1.cmml" xref="Ch4.T2.3.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.3.1.1.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.3.1.1.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.3.1.1.2"><span class="ltx_text" id="Ch4.T2.3.1.1.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender requests the user’s opinion to a choice question (e.g., yes/no)</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.3.1.1.3"><span class="ltx_text" id="Ch4.T2.3.1.1.3.1" style="font-size:90%;background-color:#F2F2F2;">“So it is just open space but separated from others, is that ok?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.4.2.2" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.4.2.2.1"><span class="ltx_text" id="Ch4.T2.4.2.2.1.1" style="font-size:90%;background-color:#FFFFFF;">Ensure fulfillment <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.4.2.2.1.1.m1.1"><semantics id="Ch4.T2.4.2.2.1.1.m1.1a"><mo id="Ch4.T2.4.2.2.1.1.m1.1.1" mathbackground="#FFFFFF" xref="Ch4.T2.4.2.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.4.2.2.1.1.m1.1b"><ci id="Ch4.T2.4.2.2.1.1.m1.1.1.cmml" xref="Ch4.T2.4.2.2.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.4.2.2.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.4.2.2.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.4.2.2.2"><span class="ltx_text" id="Ch4.T2.4.2.2.2.1" style="font-size:90%;background-color:#FFFFFF;">Recommender confirms task fulfillment during the conversation</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.4.2.2.3"><span class="ltx_text" id="Ch4.T2.4.2.2.3.1" style="font-size:90%;background-color:#FFFFFF;">“Anything else I can do for you today?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.5.3.3" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.5.3.3.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.5.3.3.1.1" style="font-size:90%;background-color:#F2F2F2;">Inform progress <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.5.3.3.1.1.m1.1"><semantics id="Ch4.T2.5.3.3.1.1.m1.1a"><mo id="Ch4.T2.5.3.3.1.1.m1.1.1" mathbackground="#F2F2F2" xref="Ch4.T2.5.3.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.5.3.3.1.1.m1.1b"><ci id="Ch4.T2.5.3.3.1.1.m1.1.1.cmml" xref="Ch4.T2.5.3.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.5.3.3.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.5.3.3.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.5.3.3.2"><span class="ltx_text" id="Ch4.T2.5.3.3.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender discloses the current item being processed</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.5.3.3.3"><span class="ltx_text" id="Ch4.T2.5.3.3.3.1" style="font-size:90%;background-color:#F2F2F2;">“So let me just check the closest nearby parking.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.6.4.4" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.6.4.4.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.6.4.4.1.1" style="font-size:90%;background-color:#FFFFFF;">Acknowledgement <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.6.4.4.1.1.m1.1"><semantics id="Ch4.T2.6.4.4.1.1.m1.1a"><mo id="Ch4.T2.6.4.4.1.1.m1.1.1" mathbackground="#FFFFFF" xref="Ch4.T2.6.4.4.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.6.4.4.1.1.m1.1b"><ci id="Ch4.T2.6.4.4.1.1.m1.1.1.cmml" xref="Ch4.T2.6.4.4.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.6.4.4.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.6.4.4.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.6.4.4.2"><span class="ltx_text" id="Ch4.T2.6.4.4.2.1" style="font-size:90%;background-color:#FFFFFF;">Recommender shows understanding towards a previous user utterance</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.6.4.4.3"><span class="ltx_text" id="Ch4.T2.6.4.4.3.1" style="font-size:90%;background-color:#FFFFFF;">“…you mentioned that one of the attendees is vegetarian…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.14.4" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.14.4.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.14.4.1.1" style="font-size:90%;background-color:#F2F2F2;">Answer</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.14.4.2"><span class="ltx_text" id="Ch4.T2.11.9.14.4.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender answers the question issued by the user</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.14.4.3"><span class="ltx_text" id="Ch4.T2.11.9.14.4.3.1" style="font-size:90%;background-color:#F2F2F2;">“So for the Michael’s on Simcoe, the price varies a lot…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.15.5" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.15.5.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.15.5.1.1" style="font-size:90%;background-color:#FFFFFF;">Recommend</span></td>
<td class="ltx_td" id="Ch4.T2.11.9.15.5.2"></td>
<td class="ltx_td" id="Ch4.T2.11.9.15.5.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.16.6" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.16.6.1"><span class="ltx_text" id="Ch4.T2.11.9.16.6.1.1" style="font-size:90%;background-color:#F2F2F2;">Recommend - Show</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.16.6.2"><span class="ltx_text" id="Ch4.T2.11.9.16.6.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender provides recommendation by showing it directly</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.16.6.3"><span class="ltx_text" id="Ch4.T2.11.9.16.6.3.1" style="font-size:90%;background-color:#F2F2F2;">“So I found a restaurant called paramount.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.17.7" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.17.7.1"><span class="ltx_text" id="Ch4.T2.11.9.17.7.1.1" style="font-size:90%;background-color:#FFFFFF;">Recommend - Explore</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.17.7.2"><span class="ltx_text" id="Ch4.T2.11.9.17.7.2.1" style="font-size:90%;background-color:#FFFFFF;">Recommender provides recommendation and asks if the user has prior knowledge</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.17.7.3"><span class="ltx_text" id="Ch4.T2.11.9.17.7.3.1" style="font-size:90%;background-color:#FFFFFF;">“The first one that comes to mind is Miku, have you heard of it before?”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.18.8" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.18.8.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.18.8.1.1" style="font-size:90%;background-color:#F2F2F2;">Explain</span></td>
<td class="ltx_td" id="Ch4.T2.11.9.18.8.2"></td>
<td class="ltx_td" id="Ch4.T2.11.9.18.8.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.19.9" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.19.9.1"><span class="ltx_text" id="Ch4.T2.11.9.19.9.1.1" style="font-size:90%;background-color:#FFFFFF;">Preference</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.19.9.2"><span class="ltx_text" id="Ch4.T2.11.9.19.9.2.1" style="font-size:90%;background-color:#FFFFFF;">Recommender explains recommendations based on the user’s said preference</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.19.9.3"><span class="ltx_text" id="Ch4.T2.11.9.19.9.3.1" style="font-size:90%;background-color:#FFFFFF;">“Because it has vegetarian options, it has a full bar and a good view…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.7.5.5" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.7.5.5.1"><span class="ltx_text" id="Ch4.T2.7.5.5.1.1" style="font-size:90%;background-color:#F2F2F2;">Additional Information <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.7.5.5.1.1.m1.1"><semantics id="Ch4.T2.7.5.5.1.1.m1.1a"><mo id="Ch4.T2.7.5.5.1.1.m1.1.1" mathbackground="#F2F2F2" xref="Ch4.T2.7.5.5.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.7.5.5.1.1.m1.1b"><ci id="Ch4.T2.7.5.5.1.1.m1.1.1.cmml" xref="Ch4.T2.7.5.5.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.7.5.5.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.7.5.5.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.7.5.5.2"><span class="ltx_text" id="Ch4.T2.7.5.5.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender explains recommendations with features not previously discussed</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.7.5.5.3"><span class="ltx_text" id="Ch4.T2.7.5.5.3.1" style="font-size:90%;background-color:#F2F2F2;">“There are a couple different varieties (of food) that your guests might enjoy.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.20.10" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.20.10.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.20.10.1.1" style="font-size:90%;background-color:#FFFFFF;">Personal Opinion</span></td>
<td class="ltx_td" id="Ch4.T2.11.9.20.10.2"></td>
<td class="ltx_td" id="Ch4.T2.11.9.20.10.3"></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.8.6.6" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.8.6.6.1"><span class="ltx_text" id="Ch4.T2.8.6.6.1.1" style="font-size:90%;background-color:#F2F2F2;">        Comparison <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.8.6.6.1.1.m1.1"><semantics id="Ch4.T2.8.6.6.1.1.m1.1a"><mo id="Ch4.T2.8.6.6.1.1.m1.1.1" mathbackground="#F2F2F2" xref="Ch4.T2.8.6.6.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.8.6.6.1.1.m1.1b"><ci id="Ch4.T2.8.6.6.1.1.m1.1.1.cmml" xref="Ch4.T2.8.6.6.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.8.6.6.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.8.6.6.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.8.6.6.2"><span class="ltx_text" id="Ch4.T2.8.6.6.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender compares recommended item with another item</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.8.6.6.3"><span class="ltx_text" id="Ch4.T2.8.6.6.3.1" style="font-size:90%;background-color:#F2F2F2;">“I would say the price for this place is a bit higher than HY steakhouse but…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.9.7.7" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.9.7.7.1"><span class="ltx_text" id="Ch4.T2.9.7.7.1.1" style="font-size:90%;background-color:#FFFFFF;">        Persuasion <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.9.7.7.1.1.m1.1"><semantics id="Ch4.T2.9.7.7.1.1.m1.1a"><mo id="Ch4.T2.9.7.7.1.1.m1.1.1" mathbackground="#FFFFFF" xref="Ch4.T2.9.7.7.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.9.7.7.1.1.m1.1b"><ci id="Ch4.T2.9.7.7.1.1.m1.1.1.cmml" xref="Ch4.T2.9.7.7.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.9.7.7.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.9.7.7.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.9.7.7.2"><span class="ltx_text" id="Ch4.T2.9.7.7.2.1" style="font-size:90%;background-color:#FFFFFF;">Recommender provides positive comment towards the recommended item</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.9.7.7.3"><span class="ltx_text" id="Ch4.T2.9.7.7.3.1" style="font-size:90%;background-color:#FFFFFF;">“It is on the pricier side but it is worth the experience…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.10.8.8" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.10.8.8.1"><span class="ltx_text" id="Ch4.T2.10.8.8.1.1" style="font-size:90%;background-color:#F2F2F2;">        Prior Experience <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.10.8.8.1.1.m1.1"><semantics id="Ch4.T2.10.8.8.1.1.m1.1a"><mo id="Ch4.T2.10.8.8.1.1.m1.1.1" mathbackground="#F2F2F2" xref="Ch4.T2.10.8.8.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.10.8.8.1.1.m1.1b"><ci id="Ch4.T2.10.8.8.1.1.m1.1.1.cmml" xref="Ch4.T2.10.8.8.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.10.8.8.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.10.8.8.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.10.8.8.2"><span class="ltx_text" id="Ch4.T2.10.8.8.2.1" style="font-size:90%;background-color:#F2F2F2;">Recommender refers to past experience with the recommended item</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.10.8.8.3"><span class="ltx_text" id="Ch4.T2.10.8.8.3.1" style="font-size:90%;background-color:#F2F2F2;">“I have been there before during the summerlicious.”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.9" style="background-color:#FFFFFF;">
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.9.1"><span class="ltx_text" id="Ch4.T2.11.9.9.1.1" style="font-size:90%;background-color:#FFFFFF;">        Context <math alttext="{\dagger}" class="ltx_Math" display="inline" id="Ch4.T2.11.9.9.1.1.m1.1"><semantics id="Ch4.T2.11.9.9.1.1.m1.1a"><mo id="Ch4.T2.11.9.9.1.1.m1.1.1" mathbackground="#FFFFFF" xref="Ch4.T2.11.9.9.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="Ch4.T2.11.9.9.1.1.m1.1b"><ci id="Ch4.T2.11.9.9.1.1.m1.1.1.cmml" xref="Ch4.T2.11.9.9.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.T2.11.9.9.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="Ch4.T2.11.9.9.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.9.2"><span class="ltx_text" id="Ch4.T2.11.9.9.2.1" style="font-size:90%;background-color:#FFFFFF;">Recommender provides opinion considering the given context or current reality</span></td>
<td class="ltx_td ltx_align_left" id="Ch4.T2.11.9.9.3"><span class="ltx_text" id="Ch4.T2.11.9.9.3.1" style="font-size:90%;background-color:#FFFFFF;">“Since it’s summer I don’t think the weather will be that much of an issue…”</span></td>
</tr>
<tr class="ltx_tr" id="Ch4.T2.11.9.21.11" style="background-color:#F2F2F2;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ch4.T2.11.9.21.11.1"><span class="ltx_text ltx_font_bold" id="Ch4.T2.11.9.21.11.1.1" style="font-size:90%;background-color:#F2F2F2;">Others</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ch4.T2.11.9.21.11.2"><span class="ltx_text" id="Ch4.T2.11.9.21.11.2.1" style="font-size:90%;background-color:#F2F2F2;">Greetings, gratitude expression, chit-chat utterance</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ch4.T2.11.9.21.11.3"><span class="ltx_text" id="Ch4.T2.11.9.21.11.3.1" style="font-size:90%;background-color:#F2F2F2;">“Yeah a lot of people recommended me to go there.”</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section class="ltx_paragraph" id="Ch4.S7.SS0.SSS0.Px1">
<h6 class="ltx_title ltx_title_paragraph">Pre-LLM CRS Architectures</h6>
<div class="ltx_para" id="Ch4.S7.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="Ch4.S7.SS0.SSS0.Px1.p1.1">Historically, most pre-LLM CRSs followed a two-step process in each turn: 1) <span class="ltx_text ltx_font_italic" id="Ch4.S7.SS0.SSS0.Px1.p1.1.1">belief tracking</span> to maintain a dialogue state, and 2) <span class="ltx_text ltx_font_italic" id="Ch4.S7.SS0.SSS0.Px1.p1.1.2">response generation</span> to produce a system utterance <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jannach2020survey</span>]</cite>.
Belief tracking was often implemented with slot-filling techniques, where the dialogue history would be used to update a <span class="ltx_text ltx_font_italic" id="Ch4.S7.SS0.SSS0.Px1.p1.1.3">dialogue state</span> consisting of variables, or slots (e.g., “<span class="ltx_text ltx_font_italic" id="Ch4.S7.SS0.SSS0.Px1.p1.1.4">preferred_cuisine: _</span>”), that were filled from a set of predefined values (e.g., “<span class="ltx_text ltx_font_italic" id="Ch4.S7.SS0.SSS0.Px1.p1.1.5">Mexican</span>”, “<span class="ltx_text ltx_font_italic" id="Ch4.S7.SS0.SSS0.Px1.p1.1.6">French</span>”, …) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">williams2014dialog</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">budzianowski2018multiwoz</span>]</cite>. These slot-based states would then be used to determine the system response, which often used NL templates and item metadata. However, these slot-based architectures exhibited limited NL reasoning capabilities, constraining their capacity to understand and represent complex user intents and generate deeply personalized responses and recommendations.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch4.S7.SS0.SSS0.Px2">
<h6 class="ltx_title ltx_title_paragraph">LLM-Driven CRSs</h6>
<div class="ltx_para" id="Ch4.S7.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="Ch4.S7.SS0.SSS0.Px2.p1.1">In contrast to highly constrained slot-based dialogue states described above, LLMs enable rich textual representations of the dialogue state. For instance, if we consider the basic case of using a monolithic LLM <span class="ltx_text ltx_font_italic" id="Ch4.S7.SS0.SSS0.Px2.p1.1.1">as</span> a CRS (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2023large</span>]</cite>), the dialogue state simply becomes the conversation history, which preserves the full dialogue context. As discussed further in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS1" title="4.7.1 Belief Tracking ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7.1</span></a>, recent CRS research often explores more complex text-augmented dialogue states – expanding or replacing the raw conversation history with elements such as JSON-like dialogue states (e.g., Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F7" title="Figure 4.7 ‣ LLM-Driven CRSs ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>), user preference summaries <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">joko2024doing</span>]</cite>, or numerical variables (e.g., inferred item ratings). These text-augmented dialogue states are then used to form inputs to response generation modules, which may include not only LLMs but also tools such as retrievers, RSs, and KGs, as discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS2" title="4.7.2 System Response Generation ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7.2</span></a>.</p>
</div>
<figure class="ltx_figure" id="Ch4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="235" id="Ch4.F7.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.7: </span>The <span class="ltx_text ltx_font_italic" id="Ch4.F7.4.1">RA-Rec</span> prompt-driven dialogue management approach <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span>]</cite>. LLM prompting is used to maintain a JSON semi-structured NL state which tracks user preferences and intents. The predefined state keys (e.g., <span class="ltx_text ltx_font_italic" id="Ch4.F7.5.2">“cuisine_type”</span>) provide a configurable structure, while the LLM-generated state values can dynamically express nuanced concepts in NL (e.g., “<span class="ltx_text ltx_font_italic" id="Ch4.F7.6.3">“watching my weight”</span>).</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="Ch4.S7.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7.1 </span>Belief Tracking</h4>
<div class="ltx_para" id="Ch4.S7.SS1.p1">
<p class="ltx_p" id="Ch4.S7.SS1.p1.1">LLMs enable a CRS to track its beliefs about the conversation through text-augmented dialogue states. This section covers the use of purely textual components in dialogue states as well as the incorporation of non-textual elements alongside text. Both textual and non-textual dialogue state elements can form inputs to response generation modules, discussed further in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S7.SS2" title="4.7.2 System Response Generation ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7.2</span></a>.</p>
</div>
<section class="ltx_subsubsection" id="Ch4.S7.SS1.SSSx1">
<h5 class="ltx_title ltx_title_subsubsection">Textual Dialogue State Components</h5>
<div class="ltx_para" id="Ch4.S7.SS1.SSSx1.p1">
<p class="ltx_p" id="Ch4.S7.SS1.SSSx1.p1.1">The most basic form of a textual dialogue state is simply the conversation history – the default state representation when a monolithic LLM is used as a CRS (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2023large</span>]</cite>). However, the pure conversation history can also be extended or substituted with other textual state components. For instance, <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span></cite>) prompt an LLM to convert the conversation history into a JSON dialogue state, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.F7" title="Figure 4.7 ‣ LLM-Driven CRSs ‣ 4.7 Conversational Recommendation"><span class="ltx_text ltx_ref_tag">4.7</span></a>, which provides a semi-structured format to represent beliefs about the user’s item preferences (e.g., preferred cuisine type) and the dialogue flow (e.g., whether the user is expecting an answer to a question). Other authors <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">joko2024doing</span>]</cite> prompt an LLM to generate textual user preference <span class="ltx_text ltx_font_italic" id="Ch4.S7.SS1.SSSx1.p1.1.1">memories,</span> and store these memories as documents in a long-term memory corpus.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S7.SS1.SSSx2">
<h5 class="ltx_title ltx_title_subsubsection">Semi-textual Dialogue States</h5>
<div class="ltx_para" id="Ch4.S7.SS1.SSSx2.p1">
<p class="ltx_p" id="Ch4.S7.SS1.SSSx2.p1.1">In addition to textual components such as those described above, other works also feature categorical or numerical variables in the dialogue state. Specifically, the conversation history can be used to assign values to variables such as:</p>
<ul class="ltx_itemize" id="Ch4.S7.I1">
<li class="ltx_item" id="Ch4.S7.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S7.I1.i1.p1">
<p class="ltx_p" id="Ch4.S7.I1.i1.p1.1">liked/disliked item titles <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020towards</span>]</cite> or item categories <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2023recommender</span>]</cite></p>
</div>
</li>
<li class="ltx_item" id="Ch4.S7.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S7.I1.i2.p1">
<p class="ltx_p" id="Ch4.S7.I1.i2.p1.1">mentioned item-related KG entities <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2020cr</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022unicrs</span>]</cite></p>
</div>
</li>
<li class="ltx_item" id="Ch4.S7.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch4.S7.I1.i3.p1">
<p class="ltx_p" id="Ch4.S7.I1.i3.p1.1">user constraints in a constraint reasoning-based CRSs <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zeng2024automated</span>]</cite></p>
</div>
</li>
</ul>
<p class="ltx_p" id="Ch4.S7.SS1.SSSx2.p1.2">Dialogue states can also include numerical variables – for instance <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018towards</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018towards</span></cite>) use a sentiment classification module to infer a user rating towards mentioned items, while <cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">austin2024bayesian</span></cite> (<cite class="ltx_cite ltx_citemacro_citeyear"><span class="ltx_ref ltx_missing_citation ltx_ref_self">austin2024bayesian</span></cite>) maintain Bayesian beliefs over user-item preferences.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="Ch4.S7.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7.2 </span>System Response Generation</h4>
<div class="ltx_para" id="Ch4.S7.SS2.p1">
<p class="ltx_p" id="Ch4.S7.SS2.p1.1">The primary purpose of the dialogue state elements discussed above is to guide the system response by forming inputs to response generation modules. For instance, textual state components may be used for LLM prompts and/or retriever queries, while non-textual state elements such as item ratings may function as arguments to tools such as RSs. Broadly, LLM-driven CRS response generation can be guided through prompting, tuning, and interfacing with external tools.</p>
</div>
<section class="ltx_subsubsection" id="Ch4.S7.SS2.SSSx1">
<h5 class="ltx_title ltx_title_subsubsection">Prompting</h5>
<div class="ltx_para" id="Ch4.S7.SS2.SSSx1.p1">
<p class="ltx_p" id="Ch4.S7.SS2.SSSx1.p1.1">There are many diverse ways that prompting can be used to guide CRS utterance generation. Several works study <span class="ltx_text ltx_font_italic" id="Ch4.S7.SS2.SSSx1.p1.1.1">single-intent</span> systems, where the prompt is constructed using the dialogue history and an instruction to generate an utterance with a fixed intent, such as to recommend <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2023large</span>]</cite> or ask a preference elicitation query <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">handa2024bayesian</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">austin2024bayesian</span>]</cite>. Other methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">joko2024doing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span>]</cite> express hand-crafted dialogue rules through prompts, asking an LLM to select the best system action given the dialogue state and some rules (e.g., “<span class="ltx_text ltx_font_italic" id="Ch4.S7.SS2.SSSx1.p1.1.2">Ask a user for their location if they have not provided it, otherwise, recommend a restaurant.</span>”). In addition, prompts can be partially or fully system generated, for instance using the output of another LLM module, a retriever, or a reasoning tool such as an RS or KG (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022unicrs</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2023chat</span>]</cite>).</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S7.SS2.SSSx2">
<h5 class="ltx_title ltx_title_subsubsection">Tuning</h5>
<div class="ltx_para" id="Ch4.S7.SS2.SSSx2.p1">
<p class="ltx_p" id="Ch4.S7.SS2.SSSx2.p1.1">CRS dialogue policies can also be controlled by tuning LLMs on human-human or synthesized conversation data <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2019recommendation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2020cr</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2022user</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022unicrs</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">joko2024doing</span>]</cite>. While these methods cover many tuning approaches, they all lead to an LLM internalizing some knowledge about how to respond to the user in NL or execute some reasoning step such as a search or recommendation.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch4.S7.SS2.SSSx3">
<h5 class="ltx_title ltx_title_subsubsection">Tool Use</h5>
<div class="ltx_para" id="Ch4.S7.SS2.SSSx3.p1">
<p class="ltx_p" id="Ch4.S7.SS2.SSSx3.p1.1">LLM-driven CRS response generation can also be augmented by the use of external tools such as retrievers or RSs. The techniques for interfacing LLMs with such tools – discussed in Sections <a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S5" title="4.5 Retrieval Augmented Recommendation"><span class="ltx_text ltx_ref_tag">4.5</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2408.10946v1#Ch4.S6" title="4.6 LLMs Representation Generation"><span class="ltx_text ltx_ref_tag">4.6</span></a> – remain applicable in multi-turn settings, with the dialogue now state serving as the basis for representing tool inputs and outputs. In the context of retrieval-augmented CRSs, recent work <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">friedman2023leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kemper2024retrieval</span>]</cite> generates a search query based on preferences represented in the dialogue state to retrieve relevant items based on item text. Similarly, RS modules are used to make recommendation based on inferred item ratings <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">austin2024bayesian</span>]</cite> and recognized KG entities (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022unicrs</span>]</cite>).</p>
</div>
<div class="ltx_para" id="Ch4.S7.SS2.SSSx3.p2">
<span class="ltx_ERROR undefined" id="Ch4.S7.SS2.SSSx3.p2.1">\printbibliography</span>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Aug 20 15:30:03 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
