<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.02876] Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation</title><meta property="og:description" content="A growing body of work has focused on text classification methods for detecting the increasing amount of hate speech posted online. This progress has been limited to only a select number of highly-resourced languages c…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.02876">

<!--Generated on Wed Feb 28 02:16:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="hate speech,  synthetic data,  machine learning,  low-resource text classification,  digital threats,  democracy">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aman Khullar
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:amankhullar@gatech.edu">amankhullar@gatech.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Daniel Nkemelu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:dnkemelu@gatech.edu">dnkemelu@gatech.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Georgia Institute of Technology</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Atlanta</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_state">Georgia</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cuong V. Nguyen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_affiliation_institution">Georgia Institute of Technology</span><span id="id6.2.id2" class="ltx_text ltx_affiliation_city">Atlanta</span><span id="id7.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:johnny.nguyen@gatech.edu">johnny.nguyen@gatech.edu</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Michael L. Best
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id8.1.id1" class="ltx_text ltx_affiliation_institution">Georgia Institute of Technology</span><span id="id9.2.id2" class="ltx_text ltx_affiliation_city">Atlanta</span><span id="id10.3.id3" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id11.id1" class="ltx_p">A growing body of work has focused on text classification methods for detecting the increasing amount of hate speech posted online. This progress has been limited to only a select number of highly-resourced languages causing detection systems to either under-perform or not exist in limited data contexts. This is majorly caused by a lack of training data which is expensive to collect and curate in these settings. In this work, we propose a data augmentation approach that addresses the problem of lack of data for online hate speech detection in limited data contexts using synthetic data generation techniques. Given a handful of hate speech examples in a high-resource language such as English, we present three methods to synthesize new examples of hate speech data in a target language that retains the hate sentiment in the original examples but transfers the hate targets. We apply our approach to generate training data for hate speech classification tasks in Hindi and Vietnamese. Our findings show that a model trained on synthetic data performs comparably to, and in some cases outperforms, a model trained only on the samples available in the target domain. This method can be adopted to bootstrap hate speech detection models from scratch in limited data contexts. As the growth of social media within these contexts continues to outstrip response efforts, this work furthers our capacities for detection, understanding, and response to hate speech.
<span id="id11.id1.1" class="ltx_text ltx_font_bold">Disclaimer:</span> This work contains terms that are offensive and hateful. These, however, cannot be avoided due to the nature of the work.</p>
</div>
<div class="ltx_keywords">hate speech, synthetic data, machine learning, low-resource text classification, digital threats, democracy
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; Aug 16–19,
2023; Cape Town, SA</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Social and professional topics User characteristics</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing Empirical studies in collaborative and social computing</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The increase in hateful content online has motivated research in automatic approaches for detecting hate speech <cite class="ltx_cite ltx_citemacro_citep">(Schmidt and Wiegand, <a href="#bib.bib59" title="" class="ltx_ref">2019</a>; Fortuna and Nunes, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite>. Applied approaches from prior work have included heuristic (e.g., dictionaries, distance metrics, rule-based systems) and machine learning based (e.g., topic modeling <cite class="ltx_cite ltx_citemacro_citep">(Alshalan et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>, word embeddings <cite class="ltx_cite ltx_citemacro_citep">(Badri et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite>, deep learning <cite class="ltx_cite ltx_citemacro_citep">(Ziqi et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite>) methods. However, the task of detecting hate speech in limited data contexts is difficult <cite class="ltx_cite ltx_citemacro_citep">(De Gibert et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2018</a>; Madukwe et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>. There is a lack of datasets for training hate speech detection models in many languages and this presents one of the main long-standing challenges for hate speech detection <cite class="ltx_cite ltx_citemacro_citep">(Wu and Dredze, <a href="#bib.bib67" title="" class="ltx_ref">2020</a>)</cite>. This problem is exacerbated for less popular under-resourced languages <cite class="ltx_cite ltx_citemacro_citep">(Fortuna and Nunes, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>; Jahan and Oussalah, <a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Since only a small proportion of the huge amount of content generated daily is hate speech, most curated datasets have a very high class imbalance with a significantly small amount of positive hate class samples. Hate speech data collection and labeling tasks from scratch have shown to be expensive and not guaranteed to result in sufficient data for training a model <cite class="ltx_cite ltx_citemacro_citep">(NKEMELU et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>; Whang et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2023</a>)</cite>. This work explores the effectiveness of synthetic data generation techniques for limited data contexts with little to no ground truth hate speech data. Within the scope of this paper, we describe high-resource languages as languages with ample availability of digital data broadly and hate speech data specifically. Limited data contexts refer to language domains with little to no labeled hate speech examples, whether or not they have unlabeled data resources. While these languages may be reasonably represented in language modeling data, they often do not have existing hate speech repositories to support the work of hate speech detection <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>. These contexts represent the target context in this paper.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Data augmentation explores strategies for increasing the diversity of training samples without explicitly collecting new data <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2021a</a>)</cite>. Data augmentation techniques have increasingly been used for addressing imbalances or biases in training data by creating new data points through oversampling, heuristics, or geometric transformations <cite class="ltx_cite ltx_citemacro_citep">(Shorten and Khoshgoftaar, <a href="#bib.bib61" title="" class="ltx_ref">2019</a>)</cite>. This idea has been successfully applied in other domains, such as audio classification<cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2020</a>)</cite>, and video classification <cite class="ltx_cite ltx_citemacro_citep">(Yun et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2020</a>)</cite>. With considerations for the sensitive and subjective nature of hate speech, we draw on techniques from data augmentation to generate synthetic examples via context transfer from a freely available high-resource hate speech data repository to a language with limited hate speech data.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this work, we address the issue of limited hate speech data by exploiting available resources from other higher resourced languages. We propose few-shot methods for hate speech data augmentation in limited data contexts. We then compared the performance of three synthetic hate speech generation methods. The first approach involves automatic machine translation (MT) of the hateful posts in a high-resource language to the limited data language. In the second approach, we identify suitable contextual replacement tokens in the hate speech examples from the high-resource language. Our method, contextual entity substitution (CES), takes as input a handful of examples in a language such as the English language, and heuristically replaces the person or group under attack in the high-resource context with potential hate-targeted persons/groups in the target context. This semi-heuristic method retains the sentiment of hate for the target group without altering the meaning of the text, as is prone in generative approaches. We then use an open-source language model, BLOOM <cite class="ltx_cite ltx_citemacro_citep">(Scao et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite>, to synthetically generate hate speech examples in the target context. We design the prompts such that the model can generate hateful posts in the target context when given a few hate speech examples.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We conducted multiple experiments to investigate the performance of the proposed data augmentation approaches in two languages: Hindi and Vietnamese. Though these languages are not considered low-resourced (since they are fairly represented in language modeling research due to their representation in unlabeled data sources such as Wikipedia), they have very little hate speech data available making it nonetheless difficult to train hate speech detection models <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>. A systematic review of 463 hate speech research works found only 4% and ¡1% representation for the Hindi and Vietnamese languages <cite class="ltx_cite ltx_citemacro_citep">(Jahan and Oussalah, <a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite>. Our findings show that synthetic data generated via the contextual entity substitution (CES) method can further improve model performance on the target language. Our analyses indicate that the magnitude of the performance gain from CES is based on the careful curation of an entity replacement table that is sensitive to the quality of the replacement matching setup and domain drift.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In summary, the main contributions of this paper include the following:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">development of a method for employing synthetic data generation techniques to counter harmful content like hate speech on social media platforms especially in limited data contexts.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">empirical investigation of gains vs. noise trade-off in combining synthetic machine-translated hate speech data with few original hate speech posts from limited data contexts.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">development of a new use-case for multilingual large language models showing how generative language models can be used to develop models that counter hate speech.</p>
</div>
</li>
</ol>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In the following sections, we present related work, explain our synthetic data generation methodologies in detail, present the experiments that we performed along with their results, and then discuss the implications of our results. The code, data, and the entity table used for our work is present in our GitHub repository <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/TID-Lab/synthetic_dataset</span></span></span>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Hate Speech Detection in Limited Data Contexts</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Detecting hate speech content in limited data contexts remains a critical yet challenging task for machine learning (ML) systems. Publicly-available ground truth datasets for hate speech, while abundant in some languages such as English and Chinese, are limited to nonexistent in other contexts such as Burmese and Tagalog. Data unavailability hampers the development of effective hate speech detection models in these contexts <cite class="ltx_cite ltx_citemacro_citep">(Aluru et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2021</a>; Bigoulaeva et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. Previous works have explored curating hate speech datasets in low-resource languages by leveraging the knowledge of context experts <cite class="ltx_cite ltx_citemacro_citep">(NKEMELU et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite>. However, the data work required for curating hate speech datasets is often an expensive time-consuming step that is not guaranteed to return sufficient data for model training <cite class="ltx_cite ltx_citemacro_citep">(NKEMELU et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>; Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Earlier works have used SVMs, CNNs, and RNNs for hate speech and offensive language detection in limited data contexts <cite class="ltx_cite ltx_citemacro_citep">(Romim et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2021</a>; Chopra et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Demilie and Salau, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>. With the growth of large language models, researchers have leveraged pre-trained multilingual language models such as BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2018</a>)</cite> and XLM-R <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite> to perform hate speech classification for limited data contexts via few-shot learning <cite class="ltx_cite ltx_citemacro_citep">(Ali et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2022</a>; Toraman et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2022</a>; Aluru et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Aluru et al<span class="ltx_text">.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite> evaluated the effectiveness of the mBERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2018</a>)</cite> and LASER (Language-Agnostic SEntence Representations) <cite class="ltx_cite ltx_citemacro_citep">(Research, <a href="#bib.bib53" title="" class="ltx_ref">2019</a>)</cite> models in detecting hate speech content in both high-resource languages (such as English and Spanish) and low-resource languages (such as Indonesian and Polish) and found that the LASER embedding model with logistic regression performed best in the low-resource scenario, whereas BERT-based models performed better in the high-resource scenario. They also show that data from other languages tend to improve performance in low-resource settings. <cite class="ltx_cite ltx_citemacro_citet">Lauscher et al<span class="ltx_text">.</span> (<a href="#bib.bib36" title="" class="ltx_ref">2020</a>)</cite> also show that multilingual transformer models like mBERT tend to perform poorly in zero-shot transfer to distant target languages, and augmentation with few annotated samples from the distant language can help improve performance.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Other researchers have explored using transfer learning to adapt existing labeled hate speech data in English and other languages to unlabeled data in new target domains.
This often involves leveraging cross-lingual contextual embeddings to make predictions in the low-resource language<cite class="ltx_cite ltx_citemacro_citep">(Bigoulaeva et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2021</a>; Ranasinghe and Zampieri, <a href="#bib.bib52" title="" class="ltx_ref">2021</a>)</cite>. In their work, <cite class="ltx_cite ltx_citemacro_citet">Ranasinghe and Zampieri (<a href="#bib.bib52" title="" class="ltx_ref">2021</a>)</cite> analyzed how XLM-R, a cross-lingual contextual embedding architecture <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>, performs on the task of detecting offensive language in languages such as Bengali and Hindi. They implemented a transfer learning strategy by sequentially training an XLM-R model on English-language offensive speech data, then on the offensive speech data of the lower-resourced language. They found that using the model fine-tuned on Hindi training data achieves an F1 score of 0.806, and fine-tuning on both Hindi and English training data yields an improved F1 score of 0.857.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Our work builds on these existing works by combining transfer learning techniques with contextual entity substitution and language generation methods. We employ a few-shot setup to train an mBERT model on some hate speech examples and then on the augmented data to measure improvement in model performance with synthetic data.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Context Transfer Across Languages</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">A more targeted approach to improve the performance of models on tasks in limited data contexts involves employing data from higher-resourced languages related to the limited data context. Exploiting similarity in vocabulary and syntax makes insights gained from the high-resource language data reasonably transferable to the limited data context <cite class="ltx_cite ltx_citemacro_citep">(Khemchandani et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>; Xia et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2019</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Khemchandani et al<span class="ltx_text">.</span> (<a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite> proposed RelateLM, a mechanism to effectively incorporate new low-resource languages into existing pre-trained language models by aligning low-resource lexicon embeddings with their counterparts in a related high-resource language <cite class="ltx_cite ltx_citemacro_citep">(Khemchandani et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite>. They tested the effectiveness of this mechanism on Oriya and Assamese, two Indic languages whose data are unavailable in the multilingual BERT model (mBERT). In contrast to monolingual BERT, they found benefits in starting from a BERT model fine-tuned on Hindi (a higher-resourced Indic language) and then using RelateLM to incorporate Oriya and Assamese.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Within the context of hate speech, prior works have explored how models trained in one context can be transferred to a different language context <cite class="ltx_cite ltx_citemacro_citep">(Gröndahl et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2018</a>; Yoder et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Gröndahl et al<span class="ltx_text">.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2018</a>)</cite> show that hate speech models tend to perform poorly on data that differ from their initial training data. <cite class="ltx_cite ltx_citemacro_citet">Swamy et al<span class="ltx_text">.</span> (<a href="#bib.bib62" title="" class="ltx_ref">2019</a>)</cite> demonstrated that hate speech models trained on the BERT model tend to perform competitively for different datasets, though generalization depends highly on the training data used. In analyzing the generalizability of hate speech models, <cite class="ltx_cite ltx_citemacro_citet">Yoder et al<span class="ltx_text">.</span> (<a href="#bib.bib69" title="" class="ltx_ref">2022</a>)</cite> found that targeted demographic categories such as gender/sexuality and race/ethnicity play a significant role and vary from one context to another. Our work takes a data-centric, rather than a model-centric approach. To address the generalization shortcomings of pretrained models, we focus on improving the synthetic data by transferring the hate sentiment to the limited data context and substituting the contextually relevant target of hate speech to create a new dataset that fits the new domain.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Data Augmentation and Synthetic Data Generation in NLP</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Recent advancements in the field of image generation <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2020</a>; Ramesh et al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>; Saharia et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2022</a>; Yu et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2022</a>)</cite>, text generation <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2020</a>; Thoppilan et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2022</a>; Raffel et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite> and speech synthesis <cite class="ltx_cite ltx_citemacro_citep">(Oord et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2016</a>; Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2018</a>)</cite> have led to the development of an area of research in which model outputs can be used to retrain newer models. This helps reduce annotation costs, maintains data privacy, and can also help with data imbalance and scarcity issues. For audio processing, text-to-speech models are being used to provide the training data to reduce the word-error-rate of the speech recognition models <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite> and also help capture words that were not present in the training data <cite class="ltx_cite ltx_citemacro_citep">(Fazel et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>. Image generation models are being used to improve the dermatology classifiers <cite class="ltx_cite ltx_citemacro_citep">(Sagers et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>, detect floods <cite class="ltx_cite ltx_citemacro_citep">(Cardoso et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>, and action recognition <cite class="ltx_cite ltx_citemacro_citep">(Kim, <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite>. Techniques such as cropping and noise injection, are commonly applied in image and sound processing<cite class="ltx_cite ltx_citemacro_citep">(Shorten and Khoshgoftaar, <a href="#bib.bib61" title="" class="ltx_ref">2019</a>; Perez and Wang, <a href="#bib.bib49" title="" class="ltx_ref">2017</a>)</cite>. However, these techniques do not work well for text data as they can potentially change the original meaning of the input sentence. To this end, there is a growing body of work on data augmentation for natural language processing exploring tasks such as machine translation <cite class="ltx_cite ltx_citemacro_citep">(Xia et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2019</a>)</cite>, automatic speech recognition <cite class="ltx_cite ltx_citemacro_citep">(Meng et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite>, and named-entity recognition <cite class="ltx_cite ltx_citemacro_citep">(Ding et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Text generation models are helping mitigate the class imbalance problem by synthesizing new examples for classes with few-shot approaches <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite>.
A majority of these works frame the data augmentation requirement as a text generation task <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2021b</a>)</cite>. For example, <cite class="ltx_cite ltx_citemacro_citet">Xia et al<span class="ltx_text">.</span> (<a href="#bib.bib68" title="" class="ltx_ref">2019</a>)</cite> proposed a generalized framework for data augmentation for low-resourced machine translation by generating a parallel corpus between a given low-resourced language and English from a parallel corpus between a related high-resourced language and English through unsupervised machine translation <cite class="ltx_cite ltx_citemacro_citep">(Xia et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2019</a>)</cite>. This technique increased model performance by 1.5 to 8.0 BLEU points compared to the supervised back-translation baseline. The importance of diversity and naturalism has also been studied to help build better synthetic datasets <cite class="ltx_cite ltx_citemacro_citep">(Baradad Jurjo et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Data augmentation techniques have successfully been applied to construct hate speech classifiers <cite class="ltx_cite ltx_citemacro_citep">(Hartvigsen et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>; Cao and Lee, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite>. For instance, <cite class="ltx_cite ltx_citemacro_citet">Hartvigsen et al<span class="ltx_text">.</span> (<a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite> attempted to augment existing toxic content datasets by leveraging GPT-3, a text generation model, for generating large-scale data on toxic and benign statements targeted at minority identity groups. The authors found that not only was the machine-generated dataset of high quality, but toxicity detection models trained on it significantly outperformed those trained on existing human-curated toxicity datasets. Similar to these works, we aim to generate synthetic data to improve the hate-speech detection accuracy of the machine learning classifier. However, we situate our work specifically to improve hate speech detection accuracy for limited data contexts. We also present an alternative to large language models and provide a competitive synthetic data generation methodology through heuristic contextualization of hate speech for the low-resource language, which is taken from a high-resource language.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe our methodology to augment hate speech posts in limited data contexts using synthetic data generation techniques and to evaluate their performance in model training. The initial step involves curating a hate speech dataset in a high-resource language, which is a relatively easy task and is described next.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Dataset Curation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To start the synthetic data generation process, the first step is to identify a high-resource language and curate hateful posts in the selected language. The sources for the hate speech dataset are diversified to mitigate bias or over-representation of a single target group or individual. This is a relatively easy task due to the abundance of such datasets in the high-resource context. For our experiments, we use English as our high-resource language and use data curated by <cite class="ltx_cite ltx_citemacro_citet">Mathew et al<span class="ltx_text">.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2021</a>)</cite>, which covers 18 different groups targeted with hate speech in the American context. The authors built a corpus of hate-speech posts using lexicons provided by <cite class="ltx_cite ltx_citemacro_citet">Davidson et al<span class="ltx_text">.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Ousidhoum et al<span class="ltx_text">.</span> (<a href="#bib.bib48" title="" class="ltx_ref">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Mathew et al<span class="ltx_text">.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite>. To reduce ambiguity in the nature of the posts, we selected only posts labeled as <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">hateful</span> and discarded posts labeled as <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">offensive</span>. From this dataset, we use a subset of 3,000 hateful posts in English. We pre-processed this data to remove the tags, hashtags, links, and emoticons from the text. We consider only posts with a word length greater than two after this pre-processing step.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Machine Translation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">After curating the hate speech posts, we use this data to augment the hate speech data in the target language. <cite class="ltx_cite ltx_citemacro_citet">Das et al<span class="ltx_text">.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2022</a>)</cite> show automatic machine translation can boost classification performance to detect hate speech in the limited data context. For our first synthetic data generation approach, we apply a similar methodology using Microsoft Azure’s machine translation API to convert the curated hate speech posts into Hindi and Vietnamese.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Contextual Entity Substitution</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Our second synthetic data generation approach builds on automatic machine translation. In this approach, we leverage the contextual nature of hate speech to account for differences in target groups and individuals based on different geography while transferring the hate sentiment across contexts. The main idea behind this approach is to identify the target entities subjected to hate speech or hate terms that are used in the high-resource context and substitute them with entities and hate terms from the target context. Figure <a href="#S3.F1" title="Figure 1 ‣ 3.3. Contextual Entity Substitution ‣ 3. Methodology ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the framework we develop to generate synthetic hateful posts while accounting for this context shift.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2310.02876/assets/Plots/Synth_data_arch_new.png" id="S3.F1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="321" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Framework to synthetically generate hate-speech posts in the limited data context. This framework takes the English hateful dataset as input and contextually translates it to the target language of interest with the help of human-curated entity tables.</figcaption>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The next step involves building an <em id="S3.SS3.p2.1.1" class="ltx_emph ltx_font_bold ltx_font_italic">entity table</em> in the high-resource context. This entity table is an instantiation of the practice of creating lexicon lists as done in other works in the literature. For example, The PeaceTech Lab has curated hate
lexicons for languages spoken in conflict-prone countries such as Lebanon, Cameroon, and Sudan. The PeaceTech Lab Lexicons are a series of hate speech terms explaining inflammatory social media keywords and offering counter-speech suggestions to combat the spread of hate speech <cite class="ltx_cite ltx_citemacro_citep">(pea, <a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite>. However, these lexicons are only available for a handful of languages and contexts.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">To create the entity table, we categorized lexicons into target groups, target individuals, hate terms, target countries, and political groups. We also differentiated entities (such as countries) that are present in the hateful posts but might not necessarily be the targets and created another category for them. We rely on multiple sources, including lexicons collected by <cite class="ltx_cite ltx_citemacro_citet">Mathew et al<span class="ltx_text">.</span> (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite> which were derived from sources including Hatebase <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://hatebase.org</span></span></span> and the Urban Dictionary <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://www.urbandictionary.com</span></span></span>. We annotated 200 posts in the dataset to identify the most common target groups, individuals, countries, and hate terms and added them to the corresponding column in the entity table.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">Subsequently, we automatically identify candidate entities for substitution in the hate speech dataset in the high-resource language. We adopt a heuristic approach that leverages the entity table and named entity recognition (NER) models. We iterate over the hate speech posts, find the words with a Levenshtein similarity score greater than a threshold value (0.75 in our case) to the words existing in the entity-table, and then replace these words with a corresponding <span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_italic">MASK-x</span>. The <span id="S3.SS3.p4.1.2" class="ltx_text ltx_font_italic">MASK</span> corresponds to the entity we replace and the suffix <span id="S3.SS3.p4.1.3" class="ltx_text ltx_font_italic">x</span> represents the category of the entity. <span id="S3.SS3.p4.1.4" class="ltx_text ltx_font_italic">¡MASK-G¿, ¡MASK-I¿, ¡MASK-CT¿, ¡MASK-HT¿, ¡MASK-P¿</span> correspond to <span id="S3.SS3.p4.1.5" class="ltx_text ltx_font_italic">target groups, target individuals, target countries, hate-terms</span>, and <span id="S3.SS3.p4.1.6" class="ltx_text ltx_font_italic">political groups</span> respectively. For robust coverage in cases where certain names were not captured in our entity table, we used Spacy’S NER model <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://spacy.io/api/entityrecognizer</span></span></span> to identify all the entities with the tag <span id="S3.SS3.p4.1.7" class="ltx_text ltx_font_italic">PERSON</span> and replace it with <span id="S3.SS3.p4.1.8" class="ltx_text ltx_font_italic">¡MASK-I¿</span></p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p">We created a similar entity table for the target context. To create this entity table, we ask two native speakers of Hindi and Vietnamese to review a sample of hate speech posts in their respective languages and to identify the hate target entities. Using this data and their experience with the context, they created the corresponding entity table for both languages. We subsequently included a lexicon of hate terms in the ”hate-term” column of the entity table. This is the distinguishing part of the pipeline for different target contexts. We can create contextually relevant hateful posts in the target context of our interest just by modifying the contents of the entity table. Table <a href="#S3.T1" title="Table 1 ‣ 3.3. Contextual Entity Substitution ‣ 3. Methodology ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the statistics of the entity table in English, Hindi, and Vietnamese.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.1" class="ltx_p">After creating the entity table, we use the machine translation API to translate the masked English hateful posts into the target context. Our experiments showed that machine translation preserves the masks while translating the other words in the post. However, we also observed a slight loss in semantics during masked translation compared to standard translation. However, our study results show that the subsequent entity substitution was able to bridge this loss in semantic information, and the results are discussed further in section <a href="#S4" title="4. Experiments &amp; Results ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Count of lexicons in the top three categories in the entity tables for English, Hindi, and Vietnamese</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">English</th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Hindi</th>
<th id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Vietnamese</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<th id="S3.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Hate-terms</th>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56</td>
<td id="S3.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">19</td>
<td id="S3.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">23</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<th id="S3.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Target groups</th>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">140</td>
<td id="S3.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">21</td>
<td id="S3.T1.1.3.2.4" class="ltx_td ltx_align_center">26</td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<th id="S3.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Target individuals</th>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">24</td>
<td id="S3.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">28</td>
<td id="S3.T1.1.4.3.4" class="ltx_td ltx_align_center">13</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p">Creating the synthetic hate speech posts involves combining the entity table and the masked translated posts in the target context. The different <span id="S3.SS3.p7.1.1" class="ltx_text ltx_font_italic">MASK-x</span> annotations help specify entity categories to replace to maintain semantic relevance. We randomly choose an entity from the corresponding entity category and replace the <span id="S3.SS3.p7.1.2" class="ltx_text ltx_font_italic">MASK-x</span> with that entity. We could theoretically increase the replacement seed to have an exponential number of synthetic hateful posts from a single masked translated post. However, through our initial experiments, we found that setting the seed value to 1 helps us get the best results—a reasonably diversified dataset that helps avoid overfitting.</p>
</div>
<div id="S3.SS3.p8" class="ltx_para">
<p id="S3.SS3.p8.1" class="ltx_p">The entity replacement step completes our pipeline for synthetically generating hateful posts in the limited data context. Table <a href="#S3.T2" title="Table 2 ‣ 3.3. Contextual Entity Substitution ‣ 3. Methodology ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows how a machine-translated hateful post differs from a machine-translated hateful post with contextual entity substitution. In the first example in <a href="#S3.T2" title="Table 2 ‣ 3.3. Contextual Entity Substitution ‣ 3. Methodology ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we find that the word “kike” has been transliterated from Latin to Devanagari. In contrast, we find that the CES method has the name of the person, “Bhagat Singh”, referred to as “penisless”, and is contextually relevant in the Indian domain (Indian freedom fighter). In the second example, we again find the word “dyke” being transliterated from the Latin script to the Devanagari script. The CES methodology, on the other hand, substitutes this entity with “Heejra”, which stands for transgender people in India.</p>
</div>
<div id="S3.SS3.p9" class="ltx_para">
<p id="S3.SS3.p9.1" class="ltx_p">Finally, we use these synthetically generated posts to augment the hateful posts in the target context and then train the machine learning model for hate-speech detection. The results are explained in detail in section <a href="#S4.SS4" title="4.4. Synthetic hateful augmentation through contextual entity substitution ‣ 4. Experiments &amp; Results ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Qualitative difference between the synthetic hate-speech data using machine translation and the synthetic hate-speech data using contextual entity adaptation.</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r">S. No.</th>
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r">
<span id="S3.T2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.2.1.1" class="ltx_p" style="width:130.1pt;">Machine Translated</span>
</span>
</th>
<th id="S3.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column">
<span id="S3.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.3.1.1" class="ltx_p" style="width:130.1pt;">Contextual Entity Substitution</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.2.1" class="ltx_tr">
<th id="S3.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">1.</th>
<td id="S3.T2.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T2.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.2.1.1" class="ltx_p" style="width:130.1pt;">this ugly kike cunt keeps showing up on my timeline</span>
</span>
</td>
<td id="S3.T2.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.3.1.1" class="ltx_p" style="width:130.1pt;">this penisless Bhagat Singh keeps showing up on my timeline</span>
</span>
</td>
</tr>
<tr id="S3.T2.1.3.2" class="ltx_tr">
<th id="S3.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2.</th>
<td id="S3.T2.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S3.T2.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.2.1.1" class="ltx_p" style="width:130.1pt;">angry bald dyke</span>
</span>
</td>
<td id="S3.T2.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T2.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.3.1.1" class="ltx_p" style="width:130.1pt;">angry bald Heejra</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>BLOOM Language Model</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Drawing from the advancements in natural language modeling, we investigate how large language models can help improve the classification accuracy of the hate-speech detection models. We develop a third methodology for generating synthetic hate-speech posts in the target context using the BLOOM language model with 3 billion parameters <cite class="ltx_cite ltx_citemacro_citep">(Scao et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">This method is different from the previous two methods as it depends only on a sample of hateful posts in the target context, which are used as few-shot examples to help the language model generate similar posts. To generate hate speech posts, we pass a few posts from the target context and prompt the language model to generate the sixth post as shown in table <a href="#S3.T3" title="Table 3 ‣ 3.4. BLOOM Language Model ‣ 3. Methodology ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The entire prompt is a string of Devanagari text given as input to the BLOOM-LM, and then it is asked to predict the following post from the input, which it predicts in Devanagari. Inferring from our empirical analyses, we chose the number of input examples as 5, set a repetition penalty of 2 to prevent post-repetition, applied early stopping with sampling, and specified a maximum token length of 100 words for the generated prompt.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>Prompt engineering to generate the hateful posts using the BLOOM Language Model</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.1.1.1" class="ltx_p" style="width:433.6pt;"></span>
<span id="S3.T3.1.1.1.1.1.2" class="ltx_p ltx_align_center"><span id="S3.T3.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Prompt</span></span>
<span id="S3.T3.1.1.1.1.1.3" class="ltx_p"><span id="S3.T3.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Post</span>: The fiscal deficit in previous governments was at an alarming level of 3.3 per cent. The situation was that no one was ready to give loan to UP because no one gives loan at a loss of more than 3 percent. Yogi ji reduced this deficit and brought it down to the level of 2.97 per cent.</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.2.2" class="ltx_tr">
<td id="S3.T3.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S3.T3.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.2.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S3.T3.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Post</span>: Slogans of Pakistan indabad raised in Mumbai..!! Slogans of Pakistan Zindabad kept being raised in front of party’s quota minister in Thackeray government, Abu Azmi! Respected Sir, it is a request that these Pakistan lovers, traitors, traitors should be badly thrown out of the country..</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.3.3" class="ltx_tr">
<td id="S3.T3.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S3.T3.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.3.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S3.T3.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">Post</span>: If this is the condition today, then tomorrow it will definitely be seen in UP and Delhi! Rather, people from every corner of the country are settled in Delhi, from where will they show their papers!</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.4.4" class="ltx_tr">
<td id="S3.T3.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S3.T3.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.4.4.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S3.T3.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">Post</span>: People call Yogi government as casteist, it is very shameful that they have always run governments for the health of one caste.</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.5.5" class="ltx_tr">
<td id="S3.T3.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S3.T3.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.5.5.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S3.T3.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">Post</span>: In the case of rape and subsequent brutal murder of Dr. Priyanka Reddy in Hyderabad, India’s so-called secularists are refraining from raising their voice today because the accused Muslim and the locality, Asaduddin Owaisi, is it not enough to protest?</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.6.6" class="ltx_tr">
<td id="S3.T3.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S3.T3.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.6.6.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S3.T3.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">Post</span>:</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.7.7" class="ltx_tr">
<td id="S3.T3.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T3.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.7.7.1.1.1" class="ltx_p" style="width:433.6pt;"></span>
<span id="S3.T3.1.7.7.1.1.2" class="ltx_p ltx_align_center"><span id="S3.T3.1.7.7.1.1.2.1" class="ltx_text ltx_font_bold">Generated Post</span></span>
<span id="S3.T3.1.7.7.1.1.3" class="ltx_p"><span id="S3.T3.1.7.7.1.1.3.1" class="ltx_text" style="color:#000000;">Do you know that India was going to become a world leader, but by ruining it by people like Modiji, we had become the poorest nation in the world.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5. </span>Model and Metrics</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">After generating the different types of synthetic data, we fine-tune the Multilingual BERT model <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2018</a>)</cite> using them. We report the average F1 scores of three independent runs of the training step. The same methodology is adopted for Hindi and Vietnamese.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments &amp; Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We focus on generating synthetic hateful posts to reduce the data imbalance problem and bootstrap hate speech detection work in new contexts. We collected datasets from high-resource and limited data contexts to perform our experiments. The dataset collected from the high-resource domain (i.e. English) supports the translation and entity substitution steps. The other datasets (in Hindi and Vietnamese) contain non-hateful posts and a small set of hateful posts on which data augmentation is performed.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Training Data</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">For Hindi, we use the dataset curated by <cite class="ltx_cite ltx_citemacro_citet">Bhardwaj et al<span class="ltx_text">.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>, and for Vietnamese, we use the dataset curated by <cite class="ltx_cite ltx_citemacro_citet">Luu et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite>. Table <a href="#S4.T4" title="Table 4 ‣ 4.1. Training Data ‣ 4. Experiments &amp; Results ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the distribution of the hateful and non-hateful posts in each of the datasets. Since we only use hateful posts from English, we report only the amount of hateful posts available in English. As illustrated in table <a href="#S4.T4" title="Table 4 ‣ 4.1. Training Data ‣ 4. Experiments &amp; Results ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the number of hateful posts was the least in the Hindi dataset. Hence, we keep 450 posts as the upper limit for our data in the low-resource language. Using a few-shot training setup, we gradually augment the hateful posts in the low-resource language with synthetic hateful posts.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>Distribution of non-hateful and hateful posts in different data sources</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_l" colspan="2">Train Set</td>
<td id="S4.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_l" colspan="2">In-Domain Test Set</td>
<td id="S4.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_l" colspan="2">Out-Of-Domain Test Set</td>
</tr>
<tr id="S4.T4.1.2.2" class="ltx_tr">
<th id="S4.T4.1.2.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="S4.T4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Non-Hateful</td>
<td id="S4.T4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Hateful</td>
<td id="S4.T4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Non-Hateful</td>
<td id="S4.T4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Hateful</td>
<td id="S4.T4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Non-Hateful</td>
<td id="S4.T4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t">Hateful</td>
</tr>
<tr id="S4.T4.1.3.3" class="ltx_tr">
<th id="S4.T4.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">English</th>
<td id="S4.T4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5936</td>
<td id="S4.T4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T4.1.4.4" class="ltx_tr">
<th id="S4.T4.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Hindi</th>
<td id="S4.T4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">3050</td>
<td id="S4.T4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">478</td>
<td id="S4.T4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">277</td>
<td id="S4.T4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r">133</td>
<td id="S4.T4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r">1753</td>
<td id="S4.T4.1.4.4.7" class="ltx_td ltx_align_center">1017</td>
</tr>
<tr id="S4.T4.1.5.5" class="ltx_tr">
<th id="S4.T4.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Vietnamese</th>
<td id="S4.T4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">19886</td>
<td id="S4.T4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">2556</td>
<td id="S4.T4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">4344</td>
<td id="S4.T4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r">642</td>
<td id="S4.T4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T4.1.5.5.7" class="ltx_td ltx_align_center">-</td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Test Data</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">To make our experimental conditions mirror real-world scenarios, our test dataset contains only original posts curated from the limited data context. We use the test data provided by <cite class="ltx_cite ltx_citemacro_citet">Bhardwaj et al<span class="ltx_text">.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Luu et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite> in Hindi and Vietnamese respectively. Since this test data is obtained from the same source as the training data, we call this an in-domain test set. However, in field deployments, we find real-time production data varies from the dataset on which the classifier was trained. This difference could be due to the different forms of hate speech on different social media platforms, domain and narrative shifts, or dissimilarity in data curation methodologies. To observe the performance of the trained models in such a scenario, we leverage another dataset in Hindi by <cite class="ltx_cite ltx_citemacro_citet">Bohra et al<span class="ltx_text">.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite> and term this the Out-Of-Domain (OOD) test set. This data comprises Hindi-English code-mixed posts in contrast to the training data, which comprised unilingual hate speech posts in Hindi. We transliterate this code-mixed data into Devanagari to carry out our test experiments. Due to the limited availability of open-source hate-speech datasets in Vietnamese, we did not perform the OOD analysis in Vietnamese.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Comparison of contextual entity substitution and BLOOM language model synthetic data generation methodologies vs. machine translated synthetic data generation methodology for Hindi (H) and Vietnamese (V). For each run, we use a constant 450 non-hateful posts.</figcaption>
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r">S. No.</td>
<td id="S4.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">Model Type</td>
<td id="S4.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">Original hateful posts</td>
<td id="S4.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">Synthetic hateful posts</td>
<td id="S4.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r">Mean macro F1 (H)</td>
<td id="S4.T5.1.1.1.6" class="ltx_td ltx_align_center">Mean macro F1 (V)</td>
</tr>
<tr id="S4.T5.1.2.2" class="ltx_tr">
<td id="S4.T5.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.</td>
<td id="S4.T5.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Base</td>
<td id="S4.T5.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">100</td>
<td id="S4.T5.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">84.46</td>
<td id="S4.T5.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">64.29</td>
</tr>
<tr id="S4.T5.1.3.3" class="ltx_tr">
<td id="S4.T5.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2a.</td>
<td id="S4.T5.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">All-Orig</td>
<td id="S4.T5.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">150</td>
<td id="S4.T5.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.76</td>
<td id="S4.T5.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">66.58</td>
</tr>
<tr id="S4.T5.1.4.4" class="ltx_tr">
<td id="S4.T5.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r">2b.</td>
<td id="S4.T5.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">MT</td>
<td id="S4.T5.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S4.T5.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r">84.69</td>
<td id="S4.T5.1.4.4.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.4.4.6.1" class="ltx_text ltx_font_bold">63.66</span></td>
</tr>
<tr id="S4.T5.1.5.5" class="ltx_tr">
<td id="S4.T5.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r">2c.</td>
<td id="S4.T5.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">CES</td>
<td id="S4.T5.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S4.T5.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.5.5.5.1" class="ltx_text ltx_font_bold">85.62</span></td>
<td id="S4.T5.1.5.5.6" class="ltx_td ltx_align_center">63.25</td>
</tr>
<tr id="S4.T5.1.6.6" class="ltx_tr">
<td id="S4.T5.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r">2d.</td>
<td id="S4.T5.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">BLOOM-LM</td>
<td id="S4.T5.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S4.T5.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r">85.35</td>
<td id="S4.T5.1.6.6.6" class="ltx_td ltx_align_center">63.47</td>
</tr>
<tr id="S4.T5.1.7.7" class="ltx_tr">
<td id="S4.T5.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3a.</td>
<td id="S4.T5.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">All-Orig</td>
<td id="S4.T5.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">200</td>
<td id="S4.T5.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.85</td>
<td id="S4.T5.1.7.7.6" class="ltx_td ltx_align_center ltx_border_t">66.10</td>
</tr>
<tr id="S4.T5.1.8.8" class="ltx_tr">
<td id="S4.T5.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r">3b.</td>
<td id="S4.T5.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r">MT</td>
<td id="S4.T5.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r">84.07</td>
<td id="S4.T5.1.8.8.6" class="ltx_td ltx_align_center">63.33</td>
</tr>
<tr id="S4.T5.1.9.9" class="ltx_tr">
<td id="S4.T5.1.9.9.1" class="ltx_td ltx_align_center ltx_border_r">3c.</td>
<td id="S4.T5.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r">CES</td>
<td id="S4.T5.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r">84.52</td>
<td id="S4.T5.1.9.9.6" class="ltx_td ltx_align_center">63.04</td>
</tr>
<tr id="S4.T5.1.10.10" class="ltx_tr">
<td id="S4.T5.1.10.10.1" class="ltx_td ltx_align_center ltx_border_r">3d.</td>
<td id="S4.T5.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r">BLOOM-LM</td>
<td id="S4.T5.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.10.10.5.1" class="ltx_text ltx_font_bold">84.91</span></td>
<td id="S4.T5.1.10.10.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.10.10.6.1" class="ltx_text ltx_font_bold">64.48</span></td>
</tr>
<tr id="S4.T5.1.11.11" class="ltx_tr">
<td id="S4.T5.1.11.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4a.</td>
<td id="S4.T5.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">All-Orig</td>
<td id="S4.T5.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">250</td>
<td id="S4.T5.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.77</td>
<td id="S4.T5.1.11.11.6" class="ltx_td ltx_align_center ltx_border_t">66.89</td>
</tr>
<tr id="S4.T5.1.12.12" class="ltx_tr">
<td id="S4.T5.1.12.12.1" class="ltx_td ltx_align_center ltx_border_r">4b.</td>
<td id="S4.T5.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r">MT</td>
<td id="S4.T5.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r">150</td>
<td id="S4.T5.1.12.12.5" class="ltx_td ltx_align_center ltx_border_r">84.32</td>
<td id="S4.T5.1.12.12.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.12.12.6.1" class="ltx_text ltx_font_bold">63.82</span></td>
</tr>
<tr id="S4.T5.1.13.13" class="ltx_tr">
<td id="S4.T5.1.13.13.1" class="ltx_td ltx_align_center ltx_border_r">4c.</td>
<td id="S4.T5.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r">CES</td>
<td id="S4.T5.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r">150</td>
<td id="S4.T5.1.13.13.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.13.13.5.1" class="ltx_text ltx_font_bold">85.54</span></td>
<td id="S4.T5.1.13.13.6" class="ltx_td ltx_align_center">61.94</td>
</tr>
<tr id="S4.T5.1.14.14" class="ltx_tr">
<td id="S4.T5.1.14.14.1" class="ltx_td ltx_align_center ltx_border_r">4d.</td>
<td id="S4.T5.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r">BLOOM-LM</td>
<td id="S4.T5.1.14.14.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.14.14.4" class="ltx_td ltx_align_center ltx_border_r">150</td>
<td id="S4.T5.1.14.14.5" class="ltx_td ltx_align_center ltx_border_r">85.13</td>
<td id="S4.T5.1.14.14.6" class="ltx_td ltx_align_center">63.70</td>
</tr>
<tr id="S4.T5.1.15.15" class="ltx_tr">
<td id="S4.T5.1.15.15.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5a.</td>
<td id="S4.T5.1.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">All-Orig</td>
<td id="S4.T5.1.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">300</td>
<td id="S4.T5.1.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.71</td>
<td id="S4.T5.1.15.15.6" class="ltx_td ltx_align_center ltx_border_t">67.44</td>
</tr>
<tr id="S4.T5.1.16.16" class="ltx_tr">
<td id="S4.T5.1.16.16.1" class="ltx_td ltx_align_center ltx_border_r">5b.</td>
<td id="S4.T5.1.16.16.2" class="ltx_td ltx_align_center ltx_border_r">MT</td>
<td id="S4.T5.1.16.16.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.16.16.4" class="ltx_td ltx_align_center ltx_border_r">200</td>
<td id="S4.T5.1.16.16.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.16.16.5.1" class="ltx_text ltx_font_bold">85.80</span></td>
<td id="S4.T5.1.16.16.6" class="ltx_td ltx_align_center">62.48</td>
</tr>
<tr id="S4.T5.1.17.17" class="ltx_tr">
<td id="S4.T5.1.17.17.1" class="ltx_td ltx_align_center ltx_border_r">5c.</td>
<td id="S4.T5.1.17.17.2" class="ltx_td ltx_align_center ltx_border_r">CES</td>
<td id="S4.T5.1.17.17.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.17.17.4" class="ltx_td ltx_align_center ltx_border_r">200</td>
<td id="S4.T5.1.17.17.5" class="ltx_td ltx_align_center ltx_border_r">85.06</td>
<td id="S4.T5.1.17.17.6" class="ltx_td ltx_align_center">62.26</td>
</tr>
<tr id="S4.T5.1.18.18" class="ltx_tr">
<td id="S4.T5.1.18.18.1" class="ltx_td ltx_align_center ltx_border_r">5d.</td>
<td id="S4.T5.1.18.18.2" class="ltx_td ltx_align_center ltx_border_r">BLOOM-LM</td>
<td id="S4.T5.1.18.18.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.18.18.4" class="ltx_td ltx_align_center ltx_border_r">200</td>
<td id="S4.T5.1.18.18.5" class="ltx_td ltx_align_center ltx_border_r">85.25</td>
<td id="S4.T5.1.18.18.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.18.18.6.1" class="ltx_text ltx_font_bold">63.74</span></td>
</tr>
<tr id="S4.T5.1.19.19" class="ltx_tr">
<td id="S4.T5.1.19.19.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6a.</td>
<td id="S4.T5.1.19.19.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">All-Orig</td>
<td id="S4.T5.1.19.19.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">350</td>
<td id="S4.T5.1.19.19.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.19.19.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.93</td>
<td id="S4.T5.1.19.19.6" class="ltx_td ltx_align_center ltx_border_t">65.03</td>
</tr>
<tr id="S4.T5.1.20.20" class="ltx_tr">
<td id="S4.T5.1.20.20.1" class="ltx_td ltx_align_center ltx_border_r">6b.</td>
<td id="S4.T5.1.20.20.2" class="ltx_td ltx_align_center ltx_border_r">MT</td>
<td id="S4.T5.1.20.20.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.20.20.4" class="ltx_td ltx_align_center ltx_border_r">250</td>
<td id="S4.T5.1.20.20.5" class="ltx_td ltx_align_center ltx_border_r">85.62</td>
<td id="S4.T5.1.20.20.6" class="ltx_td ltx_align_center">62.16</td>
</tr>
<tr id="S4.T5.1.21.21" class="ltx_tr">
<td id="S4.T5.1.21.21.1" class="ltx_td ltx_align_center ltx_border_r">6c.</td>
<td id="S4.T5.1.21.21.2" class="ltx_td ltx_align_center ltx_border_r">CES</td>
<td id="S4.T5.1.21.21.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.21.21.4" class="ltx_td ltx_align_center ltx_border_r">250</td>
<td id="S4.T5.1.21.21.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.21.21.5.1" class="ltx_text ltx_font_bold">85.91</span></td>
<td id="S4.T5.1.21.21.6" class="ltx_td ltx_align_center">61.78</td>
</tr>
<tr id="S4.T5.1.22.22" class="ltx_tr">
<td id="S4.T5.1.22.22.1" class="ltx_td ltx_align_center ltx_border_r">6d.</td>
<td id="S4.T5.1.22.22.2" class="ltx_td ltx_align_center ltx_border_r">BLOOM-LM</td>
<td id="S4.T5.1.22.22.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.22.22.4" class="ltx_td ltx_align_center ltx_border_r">250</td>
<td id="S4.T5.1.22.22.5" class="ltx_td ltx_align_center ltx_border_r">84.25</td>
<td id="S4.T5.1.22.22.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.22.22.6.1" class="ltx_text ltx_font_bold">63.79</span></td>
</tr>
<tr id="S4.T5.1.23.23" class="ltx_tr">
<td id="S4.T5.1.23.23.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7a.</td>
<td id="S4.T5.1.23.23.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">All-Orig</td>
<td id="S4.T5.1.23.23.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">400</td>
<td id="S4.T5.1.23.23.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.23.23.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.48</td>
<td id="S4.T5.1.23.23.6" class="ltx_td ltx_align_center ltx_border_t">65.22</td>
</tr>
<tr id="S4.T5.1.24.24" class="ltx_tr">
<td id="S4.T5.1.24.24.1" class="ltx_td ltx_align_center ltx_border_r">7b.</td>
<td id="S4.T5.1.24.24.2" class="ltx_td ltx_align_center ltx_border_r">MT</td>
<td id="S4.T5.1.24.24.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.24.24.4" class="ltx_td ltx_align_center ltx_border_r">300</td>
<td id="S4.T5.1.24.24.5" class="ltx_td ltx_align_center ltx_border_r">84.05</td>
<td id="S4.T5.1.24.24.6" class="ltx_td ltx_align_center">63.34</td>
</tr>
<tr id="S4.T5.1.25.25" class="ltx_tr">
<td id="S4.T5.1.25.25.1" class="ltx_td ltx_align_center ltx_border_r">7c.</td>
<td id="S4.T5.1.25.25.2" class="ltx_td ltx_align_center ltx_border_r">CES</td>
<td id="S4.T5.1.25.25.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.25.25.4" class="ltx_td ltx_align_center ltx_border_r">300</td>
<td id="S4.T5.1.25.25.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.25.25.5.1" class="ltx_text ltx_font_bold">85.84</span></td>
<td id="S4.T5.1.25.25.6" class="ltx_td ltx_align_center">61.06</td>
</tr>
<tr id="S4.T5.1.26.26" class="ltx_tr">
<td id="S4.T5.1.26.26.1" class="ltx_td ltx_align_center ltx_border_r">7d.</td>
<td id="S4.T5.1.26.26.2" class="ltx_td ltx_align_center ltx_border_r">BLOOM-LM</td>
<td id="S4.T5.1.26.26.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.26.26.4" class="ltx_td ltx_align_center ltx_border_r">300</td>
<td id="S4.T5.1.26.26.5" class="ltx_td ltx_align_center ltx_border_r">84.92</td>
<td id="S4.T5.1.26.26.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.26.26.6.1" class="ltx_text ltx_font_bold">63.92</span></td>
</tr>
<tr id="S4.T5.1.27.27" class="ltx_tr">
<td id="S4.T5.1.27.27.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8a.</td>
<td id="S4.T5.1.27.27.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">All-Orig</td>
<td id="S4.T5.1.27.27.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">450</td>
<td id="S4.T5.1.27.27.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.1.27.27.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.61</td>
<td id="S4.T5.1.27.27.6" class="ltx_td ltx_align_center ltx_border_t">63.31</td>
</tr>
<tr id="S4.T5.1.28.28" class="ltx_tr">
<td id="S4.T5.1.28.28.1" class="ltx_td ltx_align_center ltx_border_r">8b.</td>
<td id="S4.T5.1.28.28.2" class="ltx_td ltx_align_center ltx_border_r">MT</td>
<td id="S4.T5.1.28.28.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.28.28.4" class="ltx_td ltx_align_center ltx_border_r">350</td>
<td id="S4.T5.1.28.28.5" class="ltx_td ltx_align_center ltx_border_r">84.65</td>
<td id="S4.T5.1.28.28.6" class="ltx_td ltx_align_center">62.00</td>
</tr>
<tr id="S4.T5.1.29.29" class="ltx_tr">
<td id="S4.T5.1.29.29.1" class="ltx_td ltx_align_center ltx_border_r">8c.</td>
<td id="S4.T5.1.29.29.2" class="ltx_td ltx_align_center ltx_border_r">CES</td>
<td id="S4.T5.1.29.29.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.29.29.4" class="ltx_td ltx_align_center ltx_border_r">350</td>
<td id="S4.T5.1.29.29.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.29.29.5.1" class="ltx_text ltx_font_bold">85.99</span></td>
<td id="S4.T5.1.29.29.6" class="ltx_td ltx_align_center">63.25</td>
</tr>
<tr id="S4.T5.1.30.30" class="ltx_tr">
<td id="S4.T5.1.30.30.1" class="ltx_td ltx_align_center ltx_border_r">8d.</td>
<td id="S4.T5.1.30.30.2" class="ltx_td ltx_align_center ltx_border_r">BLOOM-LM</td>
<td id="S4.T5.1.30.30.3" class="ltx_td ltx_align_center ltx_border_r">100</td>
<td id="S4.T5.1.30.30.4" class="ltx_td ltx_align_center ltx_border_r">350</td>
<td id="S4.T5.1.30.30.5" class="ltx_td ltx_align_center ltx_border_r">84.68</td>
<td id="S4.T5.1.30.30.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.30.30.6.1" class="ltx_text ltx_font_bold">64.23</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Model Details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">For all experiments, we fine-tuned the cased multilingual BERT model <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2018</a>)</cite>. We used BERT’s sub-word tokenizer to tokenize the pre-processed input post and encode it into 768 dimensions using BERT embeddings. The encoding layer is followed by a dropout layer with a probability of 0.1, followed by a linear output layer which projects the 768-dimensional embedding into a 2-dimensional vector. We use the Cross-Entropy loss function and Adam optimizer to train the model. We use a batch size of 16, learning rate of <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="1e^{-05}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">​</mo><msup id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="S4.SS2.p1.1.m1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml"><mo id="S4.SS2.p1.1.m1.1.1.3.3a" xref="S4.SS2.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.SS2.p1.1.m1.1.1.3.3.2" xref="S4.SS2.p1.1.m1.1.1.3.3.2.cmml">05</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">1</cn><apply id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.2">𝑒</ci><apply id="S4.SS2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"><minus id="S4.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.3.3.2">05</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">1e^{-05}</annotation></semantics></math> without weight decay, gradient clipping norm of <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn type="float" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">1.0</annotation></semantics></math>, and fine-tuned the model for 10 epochs. We separate 10% of the training dataset for cross-validation and use 90% of the training data during the fine-tuning step. Our model has 177M trainable parameters, and we use a Microsoft Azure Virtual Machine with 1 GPU and 8GB memory to fine-tune the model. Below, we report the experimental setup and our results.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Synthetic hateful augmentation through machine translation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We analyzed the impact of machine-translated hateful posts from English for training hate speech detection models in Hindi and Vietnamese. We use non-hateful posts available in Hindi and Vietnamese and a baseline of 100 original hateful posts in both languages. This mimics the typical real-world case where a handful of labeled hateful data is available compared to a majority of non-hateful posts. This initial split had 18% of the training data with true labels as original hate speech and about 82% for non-hate speech. This base case demonstrates a mean F1 score of 84.46 and 64.29 for Hindi and Vietnamese respectively.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">To test the effectiveness of machine-translated (MT) examples for augmentation, we increase the baseline training data by adding 50 original hateful posts to the training data and comparing the results with a training data setup of the baseline of 100 original hateful + 50 new machine-translated hateful posts. We iteratively execute this increment of original vs. synthetic for seven steps until the hateful/non-hateful split is even (50:50%). Table <a href="#S4.T5" title="Table 5 ‣ 4.1.1. Test Data ‣ 4.1. Training Data ‣ 4. Experiments &amp; Results ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the Macro F1 score of models trained on the baseline and subsequent synthetic increments. The all-original model (All-Orig) acts as an upper limit to the performance if we had a complete set of original hateful posts and did not need to perform data augmentation. Our results show that in the ideal case where additional original hateful posts are added to the training data, the model performance attained F1 scores up to 88.48 (All-Orig, 7a) and 67.44 (All-Orig, 5a), compared to the initial baseline scores of 84.46 and 64.29 for Hindi and Vietnamese respectively.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><em id="S4.SS3.p3.1.1" class="ltx_emph ltx_font_italic">Finding</em>. We observe that models trained using data augmented with machine-translated posts showed very little improvement on the baseline for Hindi (with mean F1 scores ranging from 84.05 - 85.80 vs. 84.46 baseline) but did not outperform the baseline for Vietnamese (with mean F1 scores ranging from 62.16 - 63.66 vs. 64.29 baseline). In general, the MT models did not significantly improve on the baseline as more translated data were added indicating that the MT data potentially introduced more noise and less signal to the model.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Synthetic hateful augmentation through contextual entity substitution</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We follow the setup described in <a href="#S4.SS3" title="4.3. Synthetic hateful augmentation through machine translation ‣ 4. Experiments &amp; Results ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> to compare the baseline results with synthetic examples generated from the original English hate speech dataset using our contextual entity substitution method (CES) described in <a href="#S3.SS3" title="3.3. Contextual Entity Substitution ‣ 3. Methodology ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>. Similarly, we use 450 non-hateful posts and iteratively augment the original hateful posts in Hindi and Vietnamese with synthetic CES posts in increments of 50. Table <a href="#S4.T5" title="Table 5 ‣ 4.1.1. Test Data ‣ 4.1. Training Data ‣ 4. Experiments &amp; Results ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the comparative results between the contextual entity substitution method (CES) vs. the MT and All-Orig models for Hindi and Vietnamese.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p"><em id="S4.SS4.p2.1.1" class="ltx_emph ltx_font_italic">Finding</em>. For Hindi, we find that in the majority of the steps, the CES methodology outperforms the machine-translated methodology and closes the gap with the models trained on all original hateful posts of the same quantity. The CES methodology shows a boost in performance with a mean F1 score up to 85.99 with 350 synthetic hate posts (CES, 8c) which is better than both the performance of the baseline of 100 original hate posts alone and MT-augmentation for all cases. For Vietnamese, both the MT and CES scenarios show a decrease in performance after adding more synthetic data resulting in mean F1 scores that were lower than the baseline. Broadly, we observe an increase in performance for CES-augmented models in Hindi. However, there is a surprising dominance of MT over CES methods in Vietnamese. We hypothesize that this is possibly due to the nature of the entity table for Vietnamese and discuss this in Section <a href="#S5" title="5. Discussion ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Synthetic hateful posts through hateful language generation</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Next, we again augmented the existing 100 hateful posts using hateful language generated using the BLOOM large language model <cite class="ltx_cite ltx_citemacro_citep">(Scao et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite>, BLOOM-LM. In this method, we converted the entire hate speech dataset in the low-resource language into subsets of five posts and synthetically generate a sixth hateful post for each subset. We use the 100 available hateful posts in the low-resource language to generate 20 synthetic hateful posts. Then, we randomize the 100 posts in the low-resource language to re-order and re-group the hateful posts to form a new prompt. This re-ordered dataset generates 20 more synthetic hateful posts. We iterate this step until we acquire the required number of synthetic posts.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p"><em id="S4.SS5.p2.1.1" class="ltx_emph ltx_font_italic">Finding.</em> We find that the BLOOM-LM method outperforms the MT method in both Hindi and Vietnamese as we increase the amount of synthetic data. BLOOM-LM also closes the gap in performance between the model trained on all original hateful posts of similar quantity as the BLOOM-augmented model. However, the CES method outperforms the BLOOM-LM method in Hindi in most cases while the BLOOM-LM method outperforms the CES method in most Vietnamese cases. Specifically, for Vietnamese, we observe that adding more BLOOM-LM synthetic data leads to a steady increase in performance. We hypothesize that this is potentially due to more representation of Vietnamese data in the BLOOM pretraining dataset compared to Hindi and discuss this in Section <a href="#S5" title="5. Discussion ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6. </span>Results on OOD test set</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">To test the robustness of the CES method in comparison to the All-Orig, MT, and BLOOM-LM cases, we mimic a real-world deployment scenario and test the trained models on entirely new data from a different source than the training data. This is particularly challenging for hate speech models since differences in platform sources, hate lingo, narratives, etc can lead to entirely new forms of hate speech. We only found a different dataset for our OOD test in Hindi and thus use that for our analysis.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p"><em id="S4.SS6.p2.1.1" class="ltx_emph ltx_font_italic">Finding.</em> In the base case, training with 450 non-hateful and 100 original hateful, the mean F1 was 50.81. We observe that the BLOOM-LM method performs better than CES and MT methods on OOD data. As we incrementally add synthetic data, we noticed a reduction in performance for both MT and CES methods. MT on OOD test data dropped from a mean F1 of 45.85 to 41.49, and CES from 46.20 to 41.71 but for BLOOM-LM the performance ranged from 50.91 to 51.95.</p>
</div>
<div id="S4.SS6.p3" class="ltx_para">
<p id="S4.SS6.p3.1" class="ltx_p">In general, we observe that in the OOD test, fewer training data performed better than more training data for all the methods—All-Orig, MT, CES, and BLOOM-LM. This makes sense since more data will increase the existing significant deviation between the training set and the new test set. Nonetheless, a CES approach may be more relevant for languages not represented in large language models like BLOOM. Since OOD data often represent the present state of the world at test/deployment time, we argue that incorporating newer entities from the real-world dataset into the entity table can significantly improve the performance of the CES method.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Interpretability analysis</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The performance boost obtained through training on synthetic data with the CES method helps validate our hypothesis of transferring hate speech context across languages. To develop a deeper understanding of our results and examine if the performance boost was, in fact, due to the presence of context-specific entities, we interpreted our model results using the SHapley Additive exPlanations (SHAP) framework <cite class="ltx_cite ltx_citemacro_citep">(Lundberg and Lee, <a href="#bib.bib38" title="" class="ltx_ref">2017</a>)</cite>. The SHAP framework helps us calculate the contribution of each word when the model makes its prediction.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">In our interpretability analysis, we obtained the average SHAP value for every word in the test data and sorted the words with maximum contribution across the entire dataset. We then annotated the top 20 words with respect to them being an entity or not and calculated the percentage contribution by entities across the top 20 contributing words in the test set. This analysis helps us understand whether the entities play a greater role in classifier prediction for the model trained on the synthetic data with contextual entity substitution (CES) when compared to that trained on machine-translated synthetic data (MT).</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">We observe that the average contribution of entities on classifier prediction is 31% for the MT model. On the other hand, it is 38% for the CES model in the Hindi language. We found even more promising results for Vietnamese as there was only a 13% contribution by the entities towards the final prediction with MT while there was a 59% contribution by entities in the CES model. This provides further evidence of entities playing a greater role in guiding the model prediction when the model is fine-tuned on the synthetic data with contextual entity substitution.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Implications</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The scarcity of data for hate speech detection in low-resource language contexts has been well documented <cite class="ltx_cite ltx_citemacro_citep">(Fortuna and Nunes, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>; Madukwe et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>; Jahan and Oussalah, <a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite>. Data work for machine learning (hate speech detection inclusive) is considered boring, expensive, and intensive especially when accounting for geographic and language barriers <cite class="ltx_cite ltx_citemacro_citep">(Sambasivan et al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2021</a>; NKEMELU et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite>. Our work presents three significant implications: i) by presenting methods for augmenting hate speech data in limited data contexts and comparing their performance on in-domain and out-of-domain test sets, we address a lingering question for hate speech practitioners about technical approaches for boosting limited hate speech data for real-world deployments; 2) our empirical findings highlight the important role of humans-in-the-loop of hate speech detection systems for creating and maintaining structures, managing domain drifts, and evaluating performance and 3) we motivate the need for more research in synthetic hate speech data generation, and broadly, in the inclusion of more lower-resourced languages in large language models for use in downstream applications.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Our findings show that automatically translating hate speech data from one language is not the best approach for data augmentation. This is mostly due to the loss of contextual relevance of hate targets as the model translates from one language to another. Drawing from findings in vision systems <cite class="ltx_cite ltx_citemacro_citep">(Baradad Jurjo et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite>, two key properties that make synthetic data good is naturalism and diversity. Naturalism implies that the data may not be real but it must capture certain structural properties seen in real data. We attempt to achieve this natural property by translating data from one language to another. However, prior work has shown that machine translating hate speech data is subject to the quality of the translation system, the annotation scheme used in both languages, and class balance <cite class="ltx_cite ltx_citemacro_citep">(Casula and Tonelli, <a href="#bib.bib14" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Our contextual entity substitution method addresses a major limitation of machine-translated hate speech data by infusing structure and context into the translated results. The CES method also proffers the diversity property to the synthetic data generated. We have shown that this method outperforms simple machine translation and performs comparably to models trained using only original data or generative methods. However, since this method is heavily reliant on a finite set of entities in the entity table, we see no remarkable improvements as more CES synthetic data are generated. For instance, our analysis of the entity table in Hindi and Vietnamese from Table <a href="#S3.T1" title="Table 1 ‣ 3.3. Contextual Entity Substitution ‣ 3. Methodology ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows that the Hindi entity table having more target individuals than Vietnamese led to a more diverse synthetic data generation. The success of this method is dependent on the continuous update of the entity table to account for domain drifts and to improve the diversity of the generated synthetic data. This offers support to previous claims to include context experts as part of effective hate speech detection and tracking projects <cite class="ltx_cite ltx_citemacro_citep">(NKEMELU et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">The BLOOM large language model used in this work has been trained on 46 natural languages <cite class="ltx_cite ltx_citemacro_citep">(Scao et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite> and our findings show that the level of language representation can play a role in the quality of the sentences generated by the model. For instance, since Vietnamese had twice the size of Hindi language data in the BLOOM pretraining dataset, we observe that the quality of synthetic data generated in Vietnamese is better than for Hindi. As models include more diverse languages in their pre-training setup, these methods can be extended to newer contexts. Future work can also explore the potential benefits of further finetuning the language models on data from the languages of interest prior to generating synthetic examples. Furthermore, our findings motivate the need for additional work in prompt engineering for synthetic hate speech data. Our initial experimentation with target-guided prompting (see Table <a href="#S5.T6" title="Table 6 ‣ 5.3. Limitation and Future Work ‣ 5. Discussion ‣ Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) seeks to generate hate speech targeting a specific group. This approach could potentially improve the quality of synthetic data generated to train machine learning models.</p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">Overall, we find that there is no single recipe for augmenting hate speech data in low-resource contexts. When the entity table is comprehensive, the CES method shines; when the language is well-represented in a generative large language model, the language generation technique performs well. In general, adapting hate speech from one context to another is bound to introduce noise and domain shift, choosing whether to perform contextual substitution or language generation will depend on the constraints in the limited data context of preference.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Limitation and Future Work</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We recognize that this work presents some limitations, and some of them suggest promising directions for future work. Our present analyses have investigated the performance of our proposed methods on Hindi and Vietnamese even though these languages have reasonably decent representation in many language models. This selection bias might have influenced the performance of the proposed methods. Though within the context of hate speech detection research, there are very few resources in Hindi and Vietnamese <cite class="ltx_cite ltx_citemacro_citep">(Jahan and Oussalah, <a href="#bib.bib31" title="" class="ltx_ref">2023</a>; Joshi et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>, it is unclear whether our methods will work for many less-resourced languages. We believe that approaches for hate speech detection using synthetic data generation should be extended to lesser-resourced languages and future work should consider this.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Our methodology adopts a random matching mechanism for selecting substituted entities from the table. Further work is needed to explore other matching methods. For example, exploring the effectiveness of adding another layer of semantic understanding to adapt the entities more closely to their corresponding replacement. This semantic coherence could potentially increase the quality of the hateful posts and further boost the performance of the models.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6. </span>Target group-specific prompt engineering to generate targeted hateful posts using the BLOOM Language Model</figcaption>
<table id="S5.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T6.1.1.1" class="ltx_tr">
<td id="S5.T6.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.1.1.1" class="ltx_p" style="width:433.6pt;"></span>
<span id="S5.T6.1.1.1.1.1.2" class="ltx_p ltx_align_center"><span id="S5.T6.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Prompt</span></span>
<span id="S5.T6.1.1.1.1.1.3" class="ltx_p"><span id="S5.T6.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Target group</span>: Muslim <span id="S5.T6.1.1.1.1.1.3.2" class="ltx_text ltx_font_bold">Post</span>: If you are a Muslim, you are a criminal, end of the matter!</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.2.2" class="ltx_tr">
<td id="S5.T6.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S5.T6.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.2.2.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S5.T6.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Target group</span>: Muslim <span id="S5.T6.1.2.2.1.1.1.2" class="ltx_text ltx_font_bold">Post</span>: There is only one similarity between Kashmir and Palestine, Muslims are being openly oppressed in both the places and the world is silent!</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.3.3" class="ltx_tr">
<td id="S5.T6.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S5.T6.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.3.3.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S5.T6.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">Target group</span>: Muslim <span id="S5.T6.1.3.3.1.1.1.2" class="ltx_text ltx_font_bold">Post</span>: The video of slogan of Pakistan Zindabad in the presence of Samajwadi Party MLA Abu Asim Azmi in Shramik Special train running from Wadala in Mumbai is going viral</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.4.4" class="ltx_tr">
<td id="S5.T6.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S5.T6.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.4.4.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S5.T6.1.4.4.1.1.1.1" class="ltx_text ltx_font_bold">Target group</span>: Muslim <span id="S5.T6.1.4.4.1.1.1.2" class="ltx_text ltx_font_bold">Post</span>: If you are a Muslim then you are a criminal, and if you are anti-BJP then you are a straight terrorist.</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.5.5" class="ltx_tr">
<td id="S5.T6.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S5.T6.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.5.5.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S5.T6.1.5.5.1.1.1.1" class="ltx_text ltx_font_bold">Target group</span>: Muslim <span id="S5.T6.1.5.5.1.1.1.2" class="ltx_text ltx_font_bold">Post</span>: In the case of rape and subsequent brutal murder of Dr. Priyanka Reddy in Hyderabad, India’s so-called secularists are refraining from raising their voice today because the accused Muslim and the locality, Asaduddin Owaisi, is it not enough to protest?</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.6.6" class="ltx_tr">
<td id="S5.T6.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S5.T6.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.6.6.1.1.1" class="ltx_p" style="width:433.6pt;"><span id="S5.T6.1.6.6.1.1.1.1" class="ltx_text ltx_font_bold">Target group</span>: Muslim <span id="S5.T6.1.6.6.1.1.1.2" class="ltx_text ltx_font_bold">Post</span>:</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.7.7" class="ltx_tr">
<td id="S5.T6.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S5.T6.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.7.7.1.1.1" class="ltx_p" style="width:433.6pt;"></span>
<span id="S5.T6.1.7.7.1.1.2" class="ltx_p ltx_align_center"><span id="S5.T6.1.7.7.1.1.2.1" class="ltx_text ltx_font_bold">Generated Post</span></span>
<span id="S5.T6.1.7.7.1.1.3" class="ltx_p"><span id="S5.T6.1.7.7.1.1.3.1" class="ltx_text" style="color:#000000;">If you are a Muslim or not a Hindu, you will have to leave the country.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">An ethical concern with researching hate speech detection methodologies using synthetically generated data is the possibility for bad actors to adopt these strategies for propagating synthetically generated hateful content on social media. While we unequivocally denounce such use, we argue that responsible use of the proposed methodologies can be deployed to inhibit the spread of such content from such malicious use. A model trained on synthetic data could even be more astute in detecting synthetic hate speech because of the distribution similarity with the data. The proposed methods could also be extended to incorporate techniques such as watermarking <cite class="ltx_cite ltx_citemacro_citep">(Kirchenbauer et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2023</a>)</cite> to detect synthetically generated texts while retaining the benefits of data augmentation.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we address the issue of data imbalance and data unavailability affecting the performance of automatic hate speech detection systems in limited data contexts. We investigated three approaches to generate synthetic hate speech data and presented a novel methodology for transferring hateful sentiment across languages while retaining contextual relevance in the target domains. We augmented a small number of hateful posts in Hindi and Vietnamese with synthetically generated hateful posts and trained machine learning models in a few-shot setup. Our findings show significant benefits of our proposed methods under different scenarios. Our contribution will help practitioners and researchers working on hate speech detection in limited data contexts build more robust machine learning systems to further their capacity to counter hate speech.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We thank Microsoft for providing compute for the experiment in Azure credits, and the Computing For Good Fellowship at Georgia Institute of Technology, which partially funded the first author’s work on this project. We would also like to thank our partners at The Carter Center for their support in the project. Finally, we would like to thank our Technologies and International Development Lab colleagues and the anonymous reviewers who provided critical feedback to help improve this paper.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">pea (2021)</span>
<span class="ltx_bibblock">
2021.

</span>
<span class="ltx_bibblock">PeaceTech Lab — Hate Speech Lexicons.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.peacetechlab.org/hate-speech" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.peacetechlab.org/hate-speech</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ali et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Raza Ali, Umar Farooq, Umair Arshad, Waseem Shahzad, and Mirza Omer Beg. 2022.

</span>
<span class="ltx_bibblock">Hate speech detection on Twitter using transfer learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em> 74 (2022), 101365.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alshalan et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Raghad Alshalan, Hend Al-Khalifa, Duaa Alsaeed, Heyam Al-Baity, and Shahad Alshalan. 2020.

</span>
<span class="ltx_bibblock">Detection of hate speech in covid-19–related tweets in the arab region: Deep learning and topic modeling approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">Journal of Medical Internet Research</em> 22, 12 (2020), e22609.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aluru et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sai Saketh Aluru, Binny Mathew, Punyajoy Saha, and Animesh Mukherjee. 2021.

</span>
<span class="ltx_bibblock">A deep dive into multilingual hate speech classification. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Machine Learning and Knowledge Discovery in Databases. Applied Data Science and Demo Track: European Conference, ECML PKDD 2020, Ghent, Belgium, September 14–18, 2020, Proceedings, Part V</em>. Springer, 423–439.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Badri et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Nabil Badri, Ferihane Kboubi, and Anja Habacha Chaibi. 2022.

</span>
<span class="ltx_bibblock">Combining FastText and Glove word embedding for offensive and hate speech text detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Procedia Computer Science</em> 207 (2022), 769–778.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baradad Jurjo et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Manel Baradad Jurjo, Jonas Wulff, Tongzhou Wang, Phillip Isola, and Antonio Torralba. 2021.

</span>
<span class="ltx_bibblock">Learning to see by looking at noise.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em> 34 (2021), 2556–2569.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhardwaj et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mohit Bhardwaj, Md Shad Akhtar, Asif Ekbal, Amitava Das, and Tanmoy Chakraborty. 2020.

</span>
<span class="ltx_bibblock">Hostility detection dataset in Hindi.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.03588</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bigoulaeva et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Irina Bigoulaeva, Viktor Hangya, and Alexander Fraser. 2021.

</span>
<span class="ltx_bibblock">Cross-lingual transfer learning for hate speech detection. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion</em>. 15–25.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bohra et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Aditya Bohra, Deepanshu Vijay, Vinay Singh, Syed Sarfaraz Akhtar, and Manish Shrivastava. 2018.

</span>
<span class="ltx_bibblock">A dataset of Hindi-English code-mixed social media text for hate speech detection. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proceedings of the second workshop on computational modeling of people’s opinions, personality, and emotions in social media</em>. 36–41.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al<span id="bib.bib11.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.4.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em> 33 (2020), 1877–1901.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao and Lee (2020)</span>
<span class="ltx_bibblock">
Rui Cao and Roy Ka-Wei Lee. 2020.

</span>
<span class="ltx_bibblock">HateGAN: Adversarial generative-based data augmentation for hate speech detection. In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Computational Linguistics</em>. 6327–6338.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cardoso et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Renato Cardoso, Sofia Vallecorsa, and Edoardo Nemni. 2022.

</span>
<span class="ltx_bibblock">Conditional Progressive Generative Adversarial Network for satellite image generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.15303</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Casula and Tonelli (2020)</span>
<span class="ltx_bibblock">
Camilla Casula and Sara Tonelli. 2020.

</span>
<span class="ltx_bibblock">Hate speech detection with machine-translated data: the role of annotation scheme, class imbalance and undersampling. In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Italian Conference on Computational Linguistics, CLiC-it 2020</em>, Vol. 2769. CEUR-WS. org.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chopra et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Shivang Chopra, Ramit Sawhney, Puneet Mathur, and Rajiv Ratn Shah. 2020.

</span>
<span class="ltx_bibblock">Hindi-english hate speech detection: Author profiling, debiasing, and practical perspectives. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</em>, Vol. 34. 386–393.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.02116</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Das et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mithun Das, Somnath Banerjee, and Animesh Mukherjee. 2022.

</span>
<span class="ltx_bibblock">Data bootstrapping approaches to improve low resource abusive language detection for indic languages. In <em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 33rd ACM Conference on Hypertext and Social Media</em>. 32–42.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Davidson et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017.

</span>
<span class="ltx_bibblock">Automated hate speech detection and the problem of offensive language. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Proceedings of the International AAAI Conference on Web and Social Media</em>, Vol. 11. 512–515.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Gibert et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ona De Gibert, Naiara Perez, Aitor García-Pablos, and Montse Cuadros. 2018.

</span>
<span class="ltx_bibblock">Hate speech dataset from a white supremacy forum.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1809.04444</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Demilie and Salau (2022)</span>
<span class="ltx_bibblock">
Wubetu Barud Demilie and Ayodeji Olalekan Salau. 2022.

</span>
<span class="ltx_bibblock">Detection of fake news and hate speech for Ethiopian languages: a systematic review of the approaches.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Journal of big Data</em> 9, 1 (2022), 66.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.04805</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bosheng Ding, Linlin Liu, Lidong Bing, Canasai Kruengkrai, Thien Hai Nguyen, Shafiq R. Joty, Luo Si, and Chunyan Miao. 2020.

</span>
<span class="ltx_bibblock">DAGA: Data Augmentation with a Generation Approach for Low-resource Tagging Tasks. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language Processing</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fazel et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Amin Fazel, Wei Yang, Yulan Liu, Roberto Barra-Chicote, Yixiong Meng, Roland Maas, and Jasha Droppo. 2021.

</span>
<span class="ltx_bibblock">Synthasr: Unlocking synthetic data for speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.07803</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, and Eduard Hovy. 2021a.

</span>
<span class="ltx_bibblock">A survey of data augmentation approaches for nlp.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2105.03075</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, Teruko Mitamura, and Eduard H. Hovy. 2021b.

</span>
<span class="ltx_bibblock">A Survey of Data Augmentation Approaches for NLP.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2105.03075 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fortuna and Nunes (2018)</span>
<span class="ltx_bibblock">
Paula Fortuna and Sérgio Nunes. 2018.

</span>
<span class="ltx_bibblock">A survey on automatic detection of hate speech in text.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em> 51, 4 (2018), 1–30.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020.

</span>
<span class="ltx_bibblock">Generative adversarial networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 63, 11 (2020), 139–144.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gröndahl et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Tommi Gröndahl, Luca Pajola, Mika Juuti, Mauro Conti, and N Asokan. 2018.

</span>
<span class="ltx_bibblock">All you need is” love” evading hate speech detection. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 11th ACM workshop on artificial intelligence and security</em>. 2–12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartvigsen et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. 2022.

</span>
<span class="ltx_bibblock">ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2203.09509 (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ting-Yao Hu, Mohammadreza Armandpour, Ashish Shrivastava, Jen-Hao Rick Chang, Hema Koppula, and Oncel Tuzel. 2022.

</span>
<span class="ltx_bibblock">Synt++: Utilizing imperfect synthetic data to improve speech recognition. In <em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 7682–7686.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jahan and Oussalah (2023)</span>
<span class="ltx_bibblock">
Md Saroar Jahan and Mourad Oussalah. 2023.

</span>
<span class="ltx_bibblock">A systematic review of Hate Speech automatic detection using Natural Language Processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em> (2023), 126232.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. 2020.

</span>
<span class="ltx_bibblock">The state and fate of linguistic diversity and inclusion in the NLP world.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.09095</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khemchandani et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yash Khemchandani, Sarvesh Mehtani, Vaidehi Patil, Abhijeet Awasthi, Partha Pratim Talukdar, and Sunita Sarawagi. 2021.

</span>
<span class="ltx_bibblock">Exploiting Language Relatedness for Low Web-Resource Language Model Adaptation: An Indic Languages Study. In <em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim (2022)</span>
<span class="ltx_bibblock">
Yo-whan Kim. 2022.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">How Transferable are Video Representations Based on Synthetic Data?</em>

</span>
<span class="ltx_bibblock">Ph. D. Dissertation. Massachusetts Institute of Technology.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirchenbauer et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. 2023.

</span>
<span class="ltx_bibblock">A Watermark for Large Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.10226</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lauscher et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Anne Lauscher, Vinit Ravishankar, Ivan Vulic, and Goran Glavas. 2020.

</span>
<span class="ltx_bibblock">From Zero to Hero: On the Limitations of Zero-Shot Cross-Lingual Transfer with Multilingual Transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2005.00633 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Kenton Lee, Kelvin Guu, Luheng He, Tim Dozat, and Hyung Won Chung. 2021.

</span>
<span class="ltx_bibblock">Neural data augmentation via example extrapolation.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.01335</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lundberg and Lee (2017)</span>
<span class="ltx_bibblock">
Scott M Lundberg and Su-In Lee. 2017.

</span>
<span class="ltx_bibblock">A unified approach to interpreting model predictions.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luu et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Son T Luu, Kiet Van Nguyen, and Ngan Luu-Thuy Nguyen. 2021.

</span>
<span class="ltx_bibblock">A large-scale dataset for hate speech detection on vietnamese social media texts. In <em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part I 34</em>. Springer, 415–426.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madukwe et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Kosisochukwu Madukwe, Xiaoying Gao, and Bing Xue. 2020.

</span>
<span class="ltx_bibblock">In data we trust: A critical analysis of hate speech detection datasets. In <em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourth Workshop on Online Abuse and Harms</em>. 150–161.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madukwe et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Kosisochukwu Judith Madukwe, Xiaoying Gao, and Bing Xue. 2022.

</span>
<span class="ltx_bibblock">Token replacement-based data augmentation methods for hate speech detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">World Wide Web</em> (2022), 1–22.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Binny Mathew, Ritam Dutt, Pawan Goyal, and Animesh Mukherjee. 2019.

</span>
<span class="ltx_bibblock">Spread of hate speech in online social media. In <em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th ACM conference on web science</em>. 173–182.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Binny Mathew, Anurag Illendula, Punyajoy Saha, Soumya Sarkar, Pawan Goyal, and Animesh Mukherjee. 2020.

</span>
<span class="ltx_bibblock">Hate begets hate: A temporal study of hate speech.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM on Human-Computer Interaction</em> 4, CSCW2 (2020), 1–24.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Binny Mathew, Punyajoy Saha, Seid Muhie Yimam, Chris Biemann, Pawan Goyal, and Animesh Mukherjee. 2021.

</span>
<span class="ltx_bibblock">Hatexplain: A benchmark dataset for explainable hate speech detection. In <em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, Vol. 35. 14867–14875.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Linghui Meng, Jin Xu, Xu Tan, Jindong Wang, Tao Qin, and Bo Xu. 2021.

</span>
<span class="ltx_bibblock">MixSpeech: Data Augmentation for Low-Resource Automatic Speech Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> (2021), 7008–7012.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NKEMELU et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
DANIEL NKEMELU, HARSHIL SHAH, IRFAN ESSA, and MICHAEL L BEST. 2022.

</span>
<span class="ltx_bibblock">Tackling Hate Speech in Low-resource Languages with Context Experts.

</span>
<span class="ltx_bibblock">(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016.

</span>
<span class="ltx_bibblock">Wavenet: A generative model for raw audio.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1609.03499</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ousidhoum et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Nedjma Ousidhoum, Zizheng Lin, Hongming Zhang, Yangqiu Song, and Dit-Yan Yeung. 2019.

</span>
<span class="ltx_bibblock">Multilingual and multi-aspect hate speech analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1908.11049</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perez and Wang (2017)</span>
<span class="ltx_bibblock">
Luis Perez and Jason Wang. 2017.

</span>
<span class="ltx_bibblock">The Effectiveness of Data Augmentation in Image Classification using Deep Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/1712.04621 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em> 21, 1 (2020), 5485–5551.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022.

</span>
<span class="ltx_bibblock">Hierarchical text-conditional image generation with clip latents.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.06125</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranasinghe and Zampieri (2021)</span>
<span class="ltx_bibblock">
Tharindu Ranasinghe and Marcos Zampieri. 2021.

</span>
<span class="ltx_bibblock">Multilingual offensive language identification for low-resource languages.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Transactions on Asian and Low-Resource Language Information Processing</em> 21, 1 (2021), 1–13.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Research (2019)</span>
<span class="ltx_bibblock">
Facebook Research. 2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">LASER: Language-Agnostic SEntence Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Romim et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Nauros Romim, Mosahed Ahmed, Hriteshwar Talukder, and Md Saiful Islam. 2021.

</span>
<span class="ltx_bibblock">Hate speech detection in the bengali language: A dataset and its baseline evaluation. In <em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Proceedings of International Joint Conference on Advances in Computational Intelligence: IJCACI 2020</em>. Springer, 457–468.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sagers et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Luke W Sagers, James A Diao, Matthew Groh, Pranav Rajpurkar, Adewole S Adamson, and Arjun K Manrai. 2022.

</span>
<span class="ltx_bibblock">Improving dermatology classifiers across populations using images generated by large diffusion models.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.13352</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saharia et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, et al<span id="bib.bib56.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Photorealistic text-to-image diffusion models with deep language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.11487</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sambasivan et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo. 2021.

</span>
<span class="ltx_bibblock">“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI. In <em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</em>. 1–15.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al<span id="bib.bib58.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.05100</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schmidt and Wiegand (2019)</span>
<span class="ltx_bibblock">
Anna Schmidt and Michael Wiegand. 2019.

</span>
<span class="ltx_bibblock">A survey on hate speech detection using natural language processing. In <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media, April 3, 2017, Valencia, Spain</em>. Association for Computational Linguistics, 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jonathan Shen, Ruoming Pang, Ron J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, Rj Skerrv-Ryan, et al<span id="bib.bib60.3.1" class="ltx_text">.</span> 2018.

</span>
<span class="ltx_bibblock">Natural tts synthesis by conditioning wavenet on mel spectrogram predictions. In <em id="bib.bib60.4.1" class="ltx_emph ltx_font_italic">2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>. IEEE, 4779–4783.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shorten and Khoshgoftaar (2019)</span>
<span class="ltx_bibblock">
Connor Shorten and Taghi M Khoshgoftaar. 2019.

</span>
<span class="ltx_bibblock">A survey on image data augmentation for deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Journal of big data</em> 6, 1 (2019), 1–48.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Swamy et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Steve Durairaj Swamy, Anupam Jamatia, and Björn Gambäck. 2019.

</span>
<span class="ltx_bibblock">Studying generalisability across abusive language detection datasets. In <em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd conference on computational natural language learning (CoNLL)</em>. 940–950.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thoppilan et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al<span id="bib.bib63.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Lamda: Language models for dialog applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.08239</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Toraman et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Cagri Toraman, Furkan Şahinuç, and Eyup Halit Yılmaz. 2022.

</span>
<span class="ltx_bibblock">Large-scale hate speech detection with cross-domain transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.01111</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Shengyun Wei, Shun Zou, Feifan Liao, et al<span id="bib.bib65.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">A comparison on data augmentation methods based on deep learning for audio classification. In <em id="bib.bib65.4.1" class="ltx_emph ltx_font_italic">Journal of Physics: Conference Series</em>, Vol. 1453. IOP Publishing, 012085.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Whang et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Steven Euijong Whang, Yuji Roh, Hwanjun Song, and Jae-Gil Lee. 2023.

</span>
<span class="ltx_bibblock">Data collection and quality challenges in deep learning: A data-centric ai perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">The VLDB Journal</em> (2023), 1–23.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu and Dredze (2020)</span>
<span class="ltx_bibblock">
Shijie Wu and Mark Dredze. 2020.

</span>
<span class="ltx_bibblock">Are all languages created equal in multilingual BERT?

</span>
<span class="ltx_bibblock"><em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.09093</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
M. Xia, X. Kong, Antonios Anastasopoulos, and Graham Neubig. 2019.

</span>
<span class="ltx_bibblock">Generalized Data Augmentation for Low-Resource Translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/1906.03785 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoder et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Michael Miller Yoder, Lynnette Hui Xian Ng, David West Brown, and Kathleen M Carley. 2022.

</span>
<span class="ltx_bibblock">How Hate Speech Varies by Target Identity: A Computational Analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.10839</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al<span id="bib.bib70.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Scaling autoregressive models for content-rich text-to-image generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.10789</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yun et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Sangdoo Yun, Seong Joon Oh, Byeongho Heo, Dongyoon Han, and Jinhyung Kim. 2020.

</span>
<span class="ltx_bibblock">Videomix: Rethinking data augmentation for video classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.03457</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ziqi et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Z Ziqi, D Robinson, and T Jonathan. 2019.

</span>
<span class="ltx_bibblock">Hate speech detection using a convolution-LSTM based deep neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">IJCCS</em> 11816 (2019), 2546–2553.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.02875" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.02876" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.02876">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.02876" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.02877" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 02:16:49 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
