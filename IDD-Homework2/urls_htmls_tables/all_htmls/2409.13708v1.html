<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Towards Safe Multilingual Frontier AI</title>
<!--Generated on Fri Sep  6 14:24:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.13708v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S1" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S2" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S2.SS1" title="In 2 Related work ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>What to measure?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S2.SS2" title="In 2 Related work ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Risk and capability measurement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S2.SS3" title="In 2 Related work ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Risk mitigation and capability improvements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S2.SS4" title="In 2 Related work ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Who will do the evaluations?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S2.SS5" title="In 2 Related work ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Comprehensive empirical assessments and policy recommendations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S3" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology for the quantitative analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Case Study: The EU and its 24 official languages</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.SS1" title="In 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Legal aspects</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.SS2" title="In 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Who benefits from multilingual AI in the EU, and how?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.SS3" title="In 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Who could implement the policies?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.SS4" title="In 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Regression results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S5" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S5.SS1" title="In 5 Discussion ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Capability and Safety Requirements to Introduce</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S5.SS2" title="In 5 Discussion ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>State Support</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S6" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations and future research</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S7" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Broader impacts statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S8" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Recommendations for EU policy</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S8.SS1" title="In 8 Recommendations for EU policy ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Require multilingual capability and safety assessments for frontier AI Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S8.SS2" title="In 8 Recommendations for EU policy ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Investigate public preferences regarding the benefits and Costs of multilingual AI</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S8.SS3" title="In 8 Recommendations for EU policy ‚Ä£ Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3 </span>Provide state support for multilingual capabilities and safety</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S9" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Author contributions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S10" title="In Towards Safe Multilingual Frontier AI"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Acknowledgements</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Towards Safe Multilingual Frontier AI</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Arturs Kanepajs
<br class="ltx_break"/>ERA Fellowship
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id1">akanepajs@gmail.com</span>
Vladimir Ivanov<sup class="ltx_sup" id="id3.3.id2">‚àó</sup>
<br class="ltx_break"/>ERA Fellowship
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id3">volodimir1024@gmail.com</span>
Richard Moulange
<br class="ltx_break"/>University of Cambridge
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id5.5.id4">rjm246@cam.ac.uk</span>
</span><span class="ltx_author_notes">Research conducted as part of the ERA:AI Fellowship.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id6.id1">Linguistically inclusive LLMs‚Äîwhich maintain good performance regardless of the language with which they are prompted‚Äîare necessary for the diffusion of AI benefits around the world. Multilingual jailbreaks that rely on language translation to evade safety measures undermine the safe and inclusive deployment of AI systems. We provide policy recommendations to enhance the multilingual capabilities of AI while mitigating the risks of multilingual jailbreaks. We quantitatively assess the relationship between language resourcedness and model vulnerabilities to multilingual jailbreaks for five frontier large language models across 24 official EU languages. Building on prior research, we propose policy actions that align with the EU legal landscape and institutional framework to address multilingual jailbreaks, while promoting linguistic inclusivity. These include mandatory assessments of multilingual capabilities and vulnerabilities, public opinion research, and state support for multilingual AI development. The measures aim to improve AI safety and functionality through EU policy initiatives, guiding the implementation of the EU AI Act and informing regulatory efforts of the European AI Office.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The increasingly powerful capabilities of Artificial Intelligence (AI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib35" title="">35</a>]</cite> can also misused, for instance, through Large Language Model (LLM) <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">jailbreaks</span>.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_text ltx_font_italic" id="footnote1.1">Jailbreaking</span> can be defined as the process of circumventing the safety measures placed on LLMs and other AI systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib50" title="">50</a>]</cite>. Vulnerability to jailbreaks paired with powerful model capabilities, including offensive cyber capabilities, chemical, biological, radiological, and nuclear capabilities, contribute to systemic risks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib73" title="">73</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib31" title="">31</a>]</cite>.</span></span></span> Defensive measures against jailbreaks can reduce the risks, but can also impede the model utility through rejection of benign prompts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib14" title="">14</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Similarly, <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">multilingual capabilities</span> of the LLMs can diffuse the benefits of AI to larger populations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib16" title="">16</a>]</cite>, but also expose LLMs to <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">multilingual jailbreak attacks<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote2.1.1.1">2</span></span><span class="ltx_text" id="footnote2.5">Multilingual jailbreak attacks</span><span class="ltx_text ltx_font_upright" id="footnote2.6"> involve prompting an LLM in different‚Äîoften low-resource‚Äîlanguages to circumvent safety measures that would otherwise activate in response to a default‚Äîusually high-resource‚Äîlanguage.</span></span></span></span></span>, especially in low-resource languages.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span class="ltx_text ltx_font_italic" id="footnote3.1">Low-resource languages</span>, which account for over 90% of the world‚Äôs 7,000+ languages and are spoken by 1.2 billion people, have limited labeled and unlabeled data available <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib42" title="">42</a>]</cite>. In this paper we follow Bang et al. (2023) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib11" title="">11</a>]</cite> and classify languages based on CommonCrawl corpus share: high-resource languages have over 1%, medium-resource languages 0.1-1%, and low-resource languages less than 0.1%. This method is responsive to the availability of digital language data, with the source data updated monthly.</span></span></span>
At least some of the least resource-intensive defensive measures, from instructing the model to "think in English" to self-generating synthetic data in low-resource languages, limit the model‚Äôs utility in non-English natural languages.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib71" title="">71</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib23" title="">23</a>]</cite></p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This paper offers a path towards linguistically inclusive AI that is also safe from multilingual jailbreak attacks (<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ Towards Safe Multilingual Frontier AI">Figure 1</a>). The rest of the paper proceeds as follows. First, we discuss related work, paying particularly attention to the extent defensive actors can reduce LLM vulnerabilities to multilingual jailbreaks without compromising multilingual capabilities. Second, we show that the EU offers a particularly promising environment for effective policy action to address this issue. Third, we assess the vulnerability to multilingual jailbreaks and multilingual capability gaps in the 24 official EU languages for five frontier LLMs. Finally, we offer specific policy recommendations for the European AI Office and other relevant stakeholders.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="246" id="S1.F1.g1" src="extracted/5832498/threat.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S1.F1.2.1">Threat model and policy opportunity.</span> Neglecting multilingual jailbreaks or multilingual capabilities can increase risks or limit AI benefit diffusion. Conversely, appropriately addressing the risks as well as capabilities can bring the benefits of safe multilingual frontier AI.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>What to measure?</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Surveys offer valuable insights into public opinion on AI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib39" title="">39</a>]</cite>, yet they often fall short in identifying which AI capabilities are most beneficial to society, and in determining appropriate safety thresholds that balance individual and collective interests. This limitation stems from the complexity of AI and its broad societal implications. To address this, researchers have introduced innovative approaches, such as citizens‚Äô juries, to gather more informed public perspectives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib41" title="">41</a>]</cite>. These methods can help to achieve a balance between innovation and safety, ensuring that public interest plays a central role alongside private incentives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib62" title="">62</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">One example for societal choice is between technological automation and job security <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib66" title="">66</a>]</cite>. For instance, LLMs could yield significant savings by automating certain tasks, and addressing skill gaps <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib38" title="">38</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib35" title="">35</a>]</cite>. However, increased automation also raises concerns about labor displacement. According to the Ipsos 2024 survey, over a third of workers worldwide fear that AI could replace their jobs in the coming years <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib39" title="">39</a>]</cite>. Workers in low-income countries and emerging markets may face significant challenges as AI-driven automation leads to the onshoring of jobs in advanced economies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib49" title="">49</a>]</cite>. Beyond the immediate loss of income, job displacement can result in political disempowerment and the loss of personal meaning associated with work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib66" title="">66</a>]</cite>. Therefore, decisions about the training, deployment, and use of LLMs should involve not only tech developers but also civil society and policymakers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib8" title="">8</a>]</cite>. Measuring and predicting the downstream impacts of LLMs is a complex and open research problem <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib59" title="">59</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib10" title="">10</a>]</cite>, progress in which is necessary to allow for informed choice between different paths of development.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Risk and capability measurement</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">To assess vulnerabilities to multilingual jailbreaks, several benchmarks have been used in the literature, including AdvBench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib76" title="">76</a>]</cite>, MasterKey <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib75" title="">75</a>]</cite>, and MT-Bench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib63" title="">63</a>]</cite>. Although precise assessment is currently hampered by data contamination and translation imperfections, these challenges do not seem insurmountable. Human annotators can help resolve translation issues in both capability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib53" title="">53</a>]</cite> and safety assessments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib4" title="">4</a>]</cite>. Recent studies also address contamination by measuring capabilities when context, but not the specific question, is provided in the prompt <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib12" title="">12</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Risk mitigation and capability improvements</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Some risk mitigation measures for addressing multilingual jailbreak vulnerabilities can come at the cost of model capabilities. For example, instructing the model to ‚Äúthink in English‚Äù <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib71" title="">71</a>]</cite> may enhance safety but reduce effectiveness in language-specific contexts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib67" title="">67</a>]</cite>. Similarly, a ‚Äúself-defense‚Äù approach, which generates multilingual training data for safety fine-tuning, has been found to increase rejection rates for benign prompts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib23" title="">23</a>]</cite>. Additionally, safety fine-tuning can result in shorter responses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib47" title="">47</a>]</cite>. At the extreme, complete usage restriction maximizes safety but eliminates utility: ‚Äúa model that always refuses is maximally safe, but not helpful in the slightest‚Äù <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib25" title="">25</a>]</cite>. While there are no documented cases of capabilities being entirely cut off in specific languages, certain modalities, such as image generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib72" title="">72</a>]</cite> and singing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib53" title="">53</a>]</cite>, have been curtailed.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Despite these challenges, progress is possible. Evidence shows that language gaps can be significantly reduced, even in low-resource languages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib16" title="">16</a>]</cite>. For instance, GPT-4o recently demonstrated notable capability improvements in several low-resource African languages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib53" title="">53</a>]</cite>. Measures that preserve both safety and capabilities include generating human-annotated datasets, though this can be costly, as low-resource languages often require more tokens per word <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib13" title="">13</a>]</cite>. One study demonstrated that using just 900 prompts‚Äîhalf requiring local knowledge‚Äîreduced the jailbreak attack rate by more than half <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib4" title="">4</a>]</cite>. The cost of generating such prompts for the 24 official EU languages likely represents only a small fraction of the cost of developing frontier models, which currently exceeds $100 million and is projected to reach $1 billion by 2027 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib21" title="">21</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Who will do the evaluations?</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">Anderljung et al. advocate for the involvement of external actors in evaluating LLMs to ensure objectivity and thoroughness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib8" title="">8</a>]</cite>. Casper et al. further argue that rigorous AI audits require more than just black-box access. They propose that white-box access, which provides deeper insight into the system‚Äôs internals, enables stronger adversarial testing and fine-tuning. This approach allows for a more comprehensive assessment of post-deployment risks, ultimately enhancing the reliability and safety of AI systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib15" title="">15</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Comprehensive empirical assessments and policy recommendations</h3>
<div class="ltx_para" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.1">Dubey et al. examined the Violation Rate (VR) and False Refusal Rate (FRR) for the Llama 3 405B model and its competitors in eight high-resource languages, finding that "Llama Guard" reduced VR with minimal or insignificant FRR increases <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib25" title="">25</a>]</cite>. Similarly, Cohere For AI introduced a dataset and method to address multilingual jailbreaks across eight languages, reporting results for six high-resource languages using the Aya 23 8B model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib4" title="">4</a>]</cite>. In contrast, we report results for the whole suite of the 24 EU languages‚Äîincluding low-resource ones‚Äîon five frontier LLMs (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.SS4" title="4.4 Regression results ‚Ä£ 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI">Section 4.4</a>).</p>
</div>
<div class="ltx_para" id="S2.SS5.p2">
<p class="ltx_p" id="S2.SS5.p2.1">Cohere For AI provides broad policy recommendations for addressing multilingual safety vulnerabilities and improving transparency in multilingual model performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib16" title="">16</a>]</cite>. We have tried to go further, by specifically identify responsible stakeholders and tailoring our recommendations accordingly. We also advocate for model providers to report evaluation results rather than conducting the evaluations themselves (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S5" title="5 Discussion ‚Ä£ Towards Safe Multilingual Frontier AI">Section 5</a>).</p>
</div>
<div class="ltx_para" id="S2.SS5.p3">
<p class="ltx_p" id="S2.SS5.p3.1">In the EU context, Rehm et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib58" title="">58</a>]</cite> compiled a wide set of policy recommendations to achieve digital language equality by 2030. Many of their recommendations call for more funding for research and innovation, increased multilingual data availability, and breakthroughs needed for model evaluation. They also called for training large language models from scratch: such efforts have by now received significant compute resources,<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>For exmaple, in June 2024, technology company <span class="ltx_text ltx_font_italic" id="footnote4.1">Tilde</span> announced they had won public compute resources comparable to those used to train GPT-3.5, in order to train a new linguistically inclusive model, see <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax1" title="Appendix A: Training Compute Estimate for Tilde Model ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix A</a>.</span></span></span> but have also been criticized as likely to produce inadequate models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib43" title="">43</a>]</cite>. Our comparative contribution is focus on highly capable AI models in general, multilingual jailbreaks in particular, and offer recommendations to enable mandatory capability and safety assessments.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology for the quantitative analysis</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To assess the relationship between jailbreak attack success rates, harmless prompt rejection rates, and the level of language resourcedness, we formulate the following hypotheses:</p>
</div>
<div class="ltx_para" id="S3.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">H1</span>: Multilingual jailbreak attack success rates and language resourcedness are negatively related.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">H2</span>: Harmless prompt rejection rates and language resourcedness are negatively related.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">To test these hypotheses, we employ the OR-Bench dataset introduced by Cui et al. (2024) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib22" title="">22</a>]</cite>. This dataset is particularly well-suited for our purposes as it was specifically designed to address the issue of ‚ÄòOver-Refusal‚Äô by LLMs. For <span class="ltx_text ltx_font_bold" id="S3.p3.1.1">H1</span>, we present harmful prompts from the OR-Bench dataset to the LLMs, and for <span class="ltx_text ltx_font_bold" id="S3.p3.1.2">H2</span>, we present harmless but ‚Äúseemingly harmful‚Äù prompts that could be mistaken as harmful. The translation of these prompts into non-English languages is performed using Google Translate, a widely accessible service.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>This procedure assumes that translating the prompt preserves its categorical features i.e. harmfulness or harmlessness. This assumption can be tested by human analysis of a subset of prompts.</span></span></span></p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.1">After collecting the LLM outputs, we classify the responses using GPT-4o mini (gpt-4o-mini-2024-07-18), based on its suitability for response classification.<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Classification quality is another testable assumption. Previous research by the OR-Bench dataset authors indicated minimal discrepancies (2.4%) between classifications performed by GPT-3.5-turbo-0125 and GPT-4. However, it has been found that automatic classification can have lower precision than human classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib48" title="">48</a>]</cite>.</span></span></span> We classify responses into three categories: <span class="ltx_text ltx_font_italic" id="S3.p4.1.1">ACCEPTED</span>, <span class="ltx_text ltx_font_italic" id="S3.p4.1.2">REJECTED</span>, and <span class="ltx_text ltx_font_italic" id="S3.p4.1.3">UNCLEAR</span>, using annotation guidelines adapted from Yong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib76" title="">76</a>]</cite>. The classification rules and detailed annotation guidelines are provided in <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax2" title="Appendix B: Annotation Guidelines ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix B</a>.</p>
</div>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p" id="S3.p5.1">Next, we estimate the coefficients using a logistic regression model, which follows the relationship:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="P(Y=1)=\frac{1}{1+e^{-(\beta_{0}+\beta_{1}X)}}" class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.cmml"><mi id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.2.2.1.3.cmml">P</mi><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.2.cmml">‚Å¢</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml">Y</mi><mo id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml">=</mo><mn id="S3.E1.m1.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E1.m1.2.2.1.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml">=</mo><mfrac id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mn id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">1</mn><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mn id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">1</mn><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">+</mo><msup id="S3.E1.m1.1.1.1.4" xref="S3.E1.m1.1.1.1.4.cmml"><mi id="S3.E1.m1.1.1.1.4.2" xref="S3.E1.m1.1.1.1.4.2.cmml">e</mi><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1a" xref="S3.E1.m1.1.1.1.1.1.cmml">‚àí</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">Œ≤</mi><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">0</mn></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">Œ≤</mi><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.3.cmml">1</mn></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml">X</mi></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><eq id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"></eq><apply id="S3.E1.m1.2.2.1.cmml" xref="S3.E1.m1.2.2.1"><times id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1.2"></times><ci id="S3.E1.m1.2.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3">ùëÉ</ci><apply id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><eq id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"></eq><ci id="S3.E1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2">ùëå</ci><cn id="S3.E1.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.3">1</cn></apply></apply><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><divide id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"></divide><cn id="S3.E1.m1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.3">1</cn><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><plus id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></plus><cn id="S3.E1.m1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.3">1</cn><apply id="S3.E1.m1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.4">superscript</csymbol><ci id="S3.E1.m1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.4.2">ùëí</ci><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1"></minus><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><plus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2">ùõΩ</ci><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.1"></times><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.2">ùõΩ</ci><cn id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.3">1</cn></apply><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3">ùëã</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">P(Y=1)=\frac{1}{1+e^{-(\beta_{0}+\beta_{1}X)}}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">italic_P ( italic_Y = 1 ) = divide start_ARG 1 end_ARG start_ARG 1 + italic_e start_POSTSUPERSCRIPT - ( italic_Œ≤ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_X ) end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.p6">
<p class="ltx_p" id="S3.p6.4">In the above equation <math alttext="Y" class="ltx_Math" display="inline" id="S3.p6.1.m1.1"><semantics id="S3.p6.1.m1.1a"><mi id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><ci id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1">ùëå</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">Y</annotation><annotation encoding="application/x-llamapun" id="S3.p6.1.m1.1d">italic_Y</annotation></semantics></math> is binary: for <span class="ltx_text ltx_font_bold" id="S3.p6.4.1">H1</span>, <math alttext="Y=1" class="ltx_Math" display="inline" id="S3.p6.2.m2.1"><semantics id="S3.p6.2.m2.1a"><mrow id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml"><mi id="S3.p6.2.m2.1.1.2" xref="S3.p6.2.m2.1.1.2.cmml">Y</mi><mo id="S3.p6.2.m2.1.1.1" xref="S3.p6.2.m2.1.1.1.cmml">=</mo><mn id="S3.p6.2.m2.1.1.3" xref="S3.p6.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.1b"><apply id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1"><eq id="S3.p6.2.m2.1.1.1.cmml" xref="S3.p6.2.m2.1.1.1"></eq><ci id="S3.p6.2.m2.1.1.2.cmml" xref="S3.p6.2.m2.1.1.2">ùëå</ci><cn id="S3.p6.2.m2.1.1.3.cmml" type="integer" xref="S3.p6.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">Y=1</annotation><annotation encoding="application/x-llamapun" id="S3.p6.2.m2.1d">italic_Y = 1</annotation></semantics></math> if and only if response is <span class="ltx_text ltx_font_italic" id="S3.p6.4.2">ACCEPTED</span>; for <span class="ltx_text ltx_font_bold" id="S3.p6.4.3">H2</span>, <math alttext="Y=1" class="ltx_Math" display="inline" id="S3.p6.3.m3.1"><semantics id="S3.p6.3.m3.1a"><mrow id="S3.p6.3.m3.1.1" xref="S3.p6.3.m3.1.1.cmml"><mi id="S3.p6.3.m3.1.1.2" xref="S3.p6.3.m3.1.1.2.cmml">Y</mi><mo id="S3.p6.3.m3.1.1.1" xref="S3.p6.3.m3.1.1.1.cmml">=</mo><mn id="S3.p6.3.m3.1.1.3" xref="S3.p6.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.3.m3.1b"><apply id="S3.p6.3.m3.1.1.cmml" xref="S3.p6.3.m3.1.1"><eq id="S3.p6.3.m3.1.1.1.cmml" xref="S3.p6.3.m3.1.1.1"></eq><ci id="S3.p6.3.m3.1.1.2.cmml" xref="S3.p6.3.m3.1.1.2">ùëå</ci><cn id="S3.p6.3.m3.1.1.3.cmml" type="integer" xref="S3.p6.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.3.m3.1c">Y=1</annotation><annotation encoding="application/x-llamapun" id="S3.p6.3.m3.1d">italic_Y = 1</annotation></semantics></math> if and only if response is <span class="ltx_text ltx_font_italic" id="S3.p6.4.4">REJECTED</span>. <math alttext="X" class="ltx_Math" display="inline" id="S3.p6.4.m4.1"><semantics id="S3.p6.4.m4.1a"><mi id="S3.p6.4.m4.1.1" xref="S3.p6.4.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.p6.4.m4.1b"><ci id="S3.p6.4.m4.1.1.cmml" xref="S3.p6.4.m4.1.1">ùëã</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.4.m4.1c">X</annotation><annotation encoding="application/x-llamapun" id="S3.p6.4.m4.1d">italic_X</annotation></semantics></math> denotes CommonCrawl corpus share <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib20" title="">20</a>]</cite>, a proxy for language resourcedness <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib46" title="">46</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S3.p7">
<p class="ltx_p" id="S3.p7.1">To validate the econometric model, we also estimate the relationship using Ordinary Least Squares (OLS) regression. To use OLS, we calculate the proportion of <span class="ltx_text ltx_font_italic" id="S3.p7.1.1">ACCEPTED</span> responses to harmful prompts, and the proportion of <span class="ltx_text ltx_font_italic" id="S3.p7.1.2">REJECTED</span> responses to harmless prompts.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Case Study: The EU and its 24 official languages</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Language diversity, commitment to digital language equality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib58" title="">58</a>]</cite> and recent regulatory developments in the EU present a pressing need for policies that promote safe multilingual frontier AI.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Legal aspects</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Linguistic inclusivity is a legal requirement for state institutions in the EU, and is enshrined in several key legal instruments. In particular, in the Charter of Fundamental Rights of the EU, Article 21 prohibits discrimination on the grounds of language, and Article 22 mandates that the EU respect cultural, religious, and linguistic diversity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib1" title="">1</a>]</cite>. Therefore, a failure to ensure that LLMs adhere to fundamental safety standards across all languages could potentially lead to violations of Article 21.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Moreover, the preamble to the EU AI Act also explicitly states that AI and its regulatory framework must be developed in accordance with the charter <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib31" title="">31</a>]</cite>. The consultations for the EU AI Act <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib18" title="">18</a>]</cite> as well as multi-stakeholder consultation launched by the EU AI Office <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib17" title="">17</a>]</cite> offer a platform for discussing and iterating on the requirements for linguistic inclusivity.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Who benefits from multilingual AI in the EU, and how?</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Multilingual AI offers substantial potential for cost savings. EU legislation and documents of major public interest are produced in all 24 official languages, which costs approximately 1 billion euros annually <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib44" title="">44</a>]</cite>. One estimate suggests that reliable grammatically correct interpretation and translation of documents could increase civil service efficiency by 20‚Äì30% <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib51" title="">51</a>]</cite>. The benefits for everyday users are highlighted by the fact that English is the first "mother tongue" for less than 3% of the EU population (<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.T1" title="Table 1 ‚Ä£ 4.2 Who benefits from multilingual AI in the EU, and how? ‚Ä£ 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI">Table 1</a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax3" title="Appendix C: Resourcedness for the 24 EU Languages ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix C</a>).</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Speakers in the EU with the respective language the first ‚Äúmother tongue‚Äù <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib69" title="">69</a>]</cite></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T1.1.1.1">Language group</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.2">Speakers (million)</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.1">English</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.2">9.2</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.3.1">other high-resource languages</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2">326.9</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.1.4.1">medium-resource languages</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.2">83.3</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T1.1.5.1">low-resource languages</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.5.2">2.2</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Who could implement the policies?</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The primary responsibility for implementing the changes could fall to the <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">Regulation and Compliance Unit</span> of the <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.2">EU AI Office</span>. This unit could mandate reporting on model multilingual capabilities and susceptibility to multilingual jailbreak attacks as well as monitor and enforce compliance. The <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.3">AI Safety Unit</span> focuses on identifying and mitigating systemic risks in general-purpose AI models. Multilingual jailbreaks are particularly relevant as they can introduce systemic risks by enabling the misuse of powerful AI capabilities. The <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.4">AI Safety Unit</span> can therefore support the <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.5">Regulation and Compliance Unit</span> by providing expertise on multilingual capability and safety testing.
The <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.6">AI for Societal Good Unit</span> can organize and promote initiatives such as citizens‚Äô juries, virtual assemblies, and surveys to gather insights into the social benefits and risks of AI. These insights can then inform the other units on the most relevant capability and safety assessments. Furthermore, the <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.7">Excellence in AI and Robotics Unit</span> can contribute by supporting and prioritizing research and development efforts related to multilingual capabilities. The <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.8">AI Innovation and Policy Coordination Unit</span> can coordinate the creation of multilingual facilitate collaboration with member states and international partners. Finally, the <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.9">Scientific Panel</span> of independent experts, also a part of the <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.10">EU AI Office</span>‚Äôs structure, can provide insights into the feasibility of measures that advance multilingual model capabilities and safety <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib29" title="">29</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Furthermore, the <span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">European Centre for Algorithmic Transparency</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib28" title="">28</a>]</cite> can provide expertise and contribute to the assessment of risks. Finally, <span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.2">DG Connect</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib24" title="">24</a>]</cite> of the <span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.3">European Commission (EC)</span>, along with the broader EC, coordinates the digital strategy of the EU and can ensure that multilingual AI safety and capabilities are prioritized.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Regression results</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We apply the methodology outlined in the <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S3" title="3 Methodology for the quantitative analysis ‚Ä£ Towards Safe Multilingual Frontier AI">Methodology</a> section to the 24 official EU languages (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax3" title="Appendix C: Resourcedness for the 24 EU Languages ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix C</a> for details) and evaluate five frontier models (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax4" title="Appendix D: Model Selection ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix D</a> for details on the model selection).<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>The models are, in alphabetical order, Claude 3.5 Sonnet (claude-3-5-sonnet-20240620), Gemini 1.5 (gemini-1.5-pro-01), GPT-4o (gpt-4o-2024-05-13), Meta Llama 405B (Meta-Llama-3.1-405B-Instruct-Turbo) and Mistral Large 2 (mistral-large-2407).</span></span></span> Specifically, we run 100 harmful prompts and 100 harmless prompts in each language and classify the responses as <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.1">ACCEPTED</span>, <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.2">REJECTED</span> or <span class="ltx_text ltx_font_italic" id="S4.SS4.p1.1.3">UNCLEAR</span>.<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>The total estimated API costs for these runs were $134.54. The additional compute costs for the full research project, e.g. including assumption testing, likely required less than 50% of this, bringing the total within $200.</span></span></span></p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">We tested the two assumptions identified in the <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S3" title="3 Methodology for the quantitative analysis ‚Ä£ Towards Safe Multilingual Frontier AI">Methodology</a> section. First, we assess translation issues by manually considering a subset of prompts. Specifically, we identify that 2 of the 19 "Harmful" prompts that were accepted in Latvian, had actually become harmless through translation (see <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax5" title="Appendix E: Assumption Testing ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix E</a>). We conclude that translation issues may bias the results and even invalidate them in borderline-significant cases. Second, we compared the performance of GPT-4o mini to GPT-4o across a subset of responses across the tested languages and found no significant differences. However, we do not compare LLM and human classification, which is a limitation of our research and warrants further investigation.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1">The results of the logistic regression are summarized in <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.T2" title="Table 2 ‚Ä£ 4.4 Regression results ‚Ä£ 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI">Table 2</a>, while additional details, including the OLS results and visual representations, can be found in <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax6" title="Appendix F: Regression Results ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix F</a>.<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>Dataset and code for API prompts, assumption testing, and econometric analysis are located at:
https://github.com/akanepajs/multilingual. We do not publicly release the translated material, to avoid negative
impacts from other models being trained on potentially harmful material, especially in low-resource languages.</span></span></span></p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Logistic regression results: relationship between dependent variable and log(CommonCrawl corpus share). 2400 observations across 24 languages (100 per language) for each regression, with Holm‚ÄìBonferroni adjusted p-values. Adjusted significance levels: *, **, *** represent 5%, 1%, and 0.1%, respectively.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.6">
<tr class="ltx_tr" id="S4.T2.6.7">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.6.7.1" rowspan="2"><span class="ltx_text" id="S4.T2.6.7.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T2.6.7.2">Harmful Accepted</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T2.6.7.3">Harmless Rejected</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1"><math alttext="\beta_{0}" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><msub id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml"><mi id="S4.T2.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.m1.1.1.2.cmml">Œ≤</mi><mn id="S4.T2.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T2.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.m1.1.1.2">ùõΩ</ci><cn id="S4.T2.1.1.1.m1.1.1.3.cmml" type="integer" xref="S4.T2.1.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\beta_{0}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.m1.1d">italic_Œ≤ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.2"><math alttext="\beta_{1}" class="ltx_Math" display="inline" id="S4.T2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.m1.1a"><msub id="S4.T2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.m1.1.1.cmml"><mi id="S4.T2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.m1.1.1.2.cmml">Œ≤</mi><mn id="S4.T2.2.2.2.m1.1.1.3" xref="S4.T2.2.2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">subscript</csymbol><ci id="S4.T2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.m1.1.1.2">ùõΩ</ci><cn id="S4.T2.2.2.2.m1.1.1.3.cmml" type="integer" xref="S4.T2.2.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">\beta_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.m1.1d">italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.3.3"><math alttext="p_{\textrm{adj}}" class="ltx_Math" display="inline" id="S4.T2.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.m1.1a"><msub id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.m1.1.1.2.cmml">p</mi><mtext id="S4.T2.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.m1.1.1.3a.cmml">adj</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T2.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.m1.1.1.2">ùëù</ci><ci id="S4.T2.3.3.3.m1.1.1.3a.cmml" xref="S4.T2.3.3.3.m1.1.1.3"><mtext id="S4.T2.3.3.3.m1.1.1.3.cmml" mathsize="70%" xref="S4.T2.3.3.3.m1.1.1.3">adj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">p_{\textrm{adj}}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.m1.1d">italic_p start_POSTSUBSCRIPT adj end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.6.7">Sig.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.4.4"><math alttext="\beta_{0}" class="ltx_Math" display="inline" id="S4.T2.4.4.4.m1.1"><semantics id="S4.T2.4.4.4.m1.1a"><msub id="S4.T2.4.4.4.m1.1.1" xref="S4.T2.4.4.4.m1.1.1.cmml"><mi id="S4.T2.4.4.4.m1.1.1.2" xref="S4.T2.4.4.4.m1.1.1.2.cmml">Œ≤</mi><mn id="S4.T2.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1">subscript</csymbol><ci id="S4.T2.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.m1.1.1.2">ùõΩ</ci><cn id="S4.T2.4.4.4.m1.1.1.3.cmml" type="integer" xref="S4.T2.4.4.4.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">\beta_{0}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.m1.1d">italic_Œ≤ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.5"><math alttext="\beta_{1}" class="ltx_Math" display="inline" id="S4.T2.5.5.5.m1.1"><semantics id="S4.T2.5.5.5.m1.1a"><msub id="S4.T2.5.5.5.m1.1.1" xref="S4.T2.5.5.5.m1.1.1.cmml"><mi id="S4.T2.5.5.5.m1.1.1.2" xref="S4.T2.5.5.5.m1.1.1.2.cmml">Œ≤</mi><mn id="S4.T2.5.5.5.m1.1.1.3" xref="S4.T2.5.5.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.m1.1b"><apply id="S4.T2.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.5.m1.1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1">subscript</csymbol><ci id="S4.T2.5.5.5.m1.1.1.2.cmml" xref="S4.T2.5.5.5.m1.1.1.2">ùõΩ</ci><cn id="S4.T2.5.5.5.m1.1.1.3.cmml" type="integer" xref="S4.T2.5.5.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.m1.1c">\beta_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.5.m1.1d">italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.6.6"><math alttext="p_{\textrm{adj}}" class="ltx_Math" display="inline" id="S4.T2.6.6.6.m1.1"><semantics id="S4.T2.6.6.6.m1.1a"><msub id="S4.T2.6.6.6.m1.1.1" xref="S4.T2.6.6.6.m1.1.1.cmml"><mi id="S4.T2.6.6.6.m1.1.1.2" xref="S4.T2.6.6.6.m1.1.1.2.cmml">p</mi><mtext id="S4.T2.6.6.6.m1.1.1.3" xref="S4.T2.6.6.6.m1.1.1.3a.cmml">adj</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.m1.1b"><apply id="S4.T2.6.6.6.m1.1.1.cmml" xref="S4.T2.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.6.6.6.m1.1.1.1.cmml" xref="S4.T2.6.6.6.m1.1.1">subscript</csymbol><ci id="S4.T2.6.6.6.m1.1.1.2.cmml" xref="S4.T2.6.6.6.m1.1.1.2">ùëù</ci><ci id="S4.T2.6.6.6.m1.1.1.3a.cmml" xref="S4.T2.6.6.6.m1.1.1.3"><mtext id="S4.T2.6.6.6.m1.1.1.3.cmml" mathsize="70%" xref="S4.T2.6.6.6.m1.1.1.3">adj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.m1.1c">p_{\textrm{adj}}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.6.m1.1d">italic_p start_POSTSUBSCRIPT adj end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.6.8">Sig.</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.6.8.1">Claude 3.5 Sonnet</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.8.2">-4.60</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.8.3">-0.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.8.4">0.660</td>
<td class="ltx_td ltx_border_t" id="S4.T2.6.8.5"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.8.6">0.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.8.7">-0.01</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.8.8">0.992</td>
<td class="ltx_td ltx_border_t" id="S4.T2.6.8.9"></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.9">
<td class="ltx_td ltx_align_left" id="S4.T2.6.9.1">Gemini 1.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.9.2">-4.33</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.9.3">-0.10</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.9.4">0.660</td>
<td class="ltx_td" id="S4.T2.6.9.5"></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.9.6">2.06</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.9.7">0.02</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.9.8">0.992</td>
<td class="ltx_td" id="S4.T2.6.9.9"></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.10">
<td class="ltx_td ltx_align_left" id="S4.T2.6.10.1">GPT-4o</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.10.2">-2.71</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.10.3">-0.15</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.10.4">0.000</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.10.5">***</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.10.6">0.52</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.10.7">-0.03</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.10.8">0.572</td>
<td class="ltx_td" id="S4.T2.6.10.9"></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.11">
<td class="ltx_td ltx_align_left" id="S4.T2.6.11.1">Meta Llama 405B</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.11.2">-3.07</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.11.3">0.06</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.11.4">0.660</td>
<td class="ltx_td" id="S4.T2.6.11.5"></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.11.6">0.21</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.11.7">0.03</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.11.8">0.572</td>
<td class="ltx_td" id="S4.T2.6.11.9"></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.6.12.1">Mistral Large 2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.12.2">-2.53</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.12.3">-0.19</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.12.4">0.000</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.12.5">***</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.12.6">-0.46</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.12.7">-0.04</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.12.8">0.200</td>
<td class="ltx_td ltx_border_bb" id="S4.T2.6.12.9"></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S4.SS4.p4">
<p class="ltx_p" id="S4.SS4.p4.1">The first hypothesis is supported (i.e., the null hypothesis is rejected) for two out of the five models, specifically GPT-4o and Mistral Large 2. Namely, jailbreak attack success rates tend to be higher for low-resource languages. The second hypothesis is not supported for any of the models after Holm-Bonferroni adjustment. That is, we find no evidence that harmless prompts tend to be rejected more often in less resourced languages.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Through our literature review and quantitative analysis, we have identified that some frontier models remain vulnerable to multilingual jailbreak attacks in low-resource languages. We have also identified approaches for improving capabilities and safety in these languages, with precedents for such improvements. Additionally, we have established that there is a legal and financial rationale for the EU to support multilingual safety and capabilities. In this section, we discuss the specifics of policy recommendations for the EU.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Capability and Safety Requirements to Introduce</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Firstly, to limit the regulatory burden, we recommend, at least initially, focusing on general-purpose
AI models entailing systemic risks (see also <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax4" title="Appendix D: Model Selection ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix D</a> for discussion on the affected models) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib31" title="">31</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Secondly, while numerous multilingual capability and safety benchmarks exist, there is currently
no authoritative and unified evaluation framework <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib35" title="">35</a>]</cite>, so it may be premature to mandate compliance to a specific benchmark and to a specific level.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">However, transparency requirements could serve as an important first step with immediate benefits. Transparency allows consumers to compare model capabilities in the language they are interested in, supporting for a better consumer choice <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib40" title="">40</a>]</cite>. Moreover, increased transparency can stimulate competition among developers to improve capabilities and safety in underrepresented languages. In the EU context, the reporting requirements can, at least initially, prioritize the 24 official EU languages, reflecting their special status and the potential for substantial cost savings in translation and communication.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Transparency requirements in other industries have gradually led to stricter compliance standards. For instance, EU transparency regulations for publicly listed companies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib3" title="">3</a>]</cite> and emissions disclosure requirements have evolved into more stringent limits on carbon allowances <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib2" title="">2</a>]</cite>. Similarly, as standards for multilingual AI capabilities and safety become more established, the requirements could be strengthened to reach specific benchmark levels. This expansion could eventually cover additional languages and dialects, such as the more than 60 national and regional languages of the EU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib30" title="">30</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1">For safety assessments, we recommend that the requirements address multilingual jailbreak vulnerabilities across all natural languages, not just the official EU languages. This two-legged approach with requirements for both capability and safety assessment reporting would create incentives for developing frontier AI that can resist multilingual jailbreak attacks in any language while maintaining high performance in the 24 EU languages.</p>
</div>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.1">Moreover, these capability and safety reporting requirements are likely to produce a "Brussels Effect." <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib74" title="">74</a>]</cite> Brussels effect may manifest <span class="ltx_text ltx_font_italic" id="S5.SS1.p6.1.1">de facto</span>, because in practice the same frontier models are made available globally. Users outside the EU could just as well benefit from transparency about model capabilities, as well as from lower risks from multilingual jailbreaks. Additionally, <span class="ltx_text ltx_font_italic" id="S5.SS1.p6.1.2">de jure</span> Brussels Effect could emerge as other jurisdictions adopt similar regulatory standards. Global forums, such as the upcoming AI Action Summit <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib77" title="">77</a>]</cite>, can further contribute to shaping an inclusive framework for international AI governance.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>State Support</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Given the "non-excludable" and "non-rivalrous" nature of publicly available data and algorithms, they can be considered public goods with positive externalities <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib60" title="">60</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib34" title="">34</a>]</cite>. Therefore, we advocate for initiatives that support the creation of multilingual datasets, particularly for low-resource languages. High-quality dataset creation is already a top priority for the EU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib58" title="">58</a>]</cite>, with examples such as Alliance for Language Technologies EDIC (ALT-EDIC), a collaboration involving 16 EU member states <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib19" title="">19</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">In the area of multilingual safety evaluation tools, benchmarks, and frameworks, one notable example is the "European LLM Leaderboard," which provides an automated database for evaluating LLMs. This leaderboard is the result of a collaboration between private and public partners, including Dresden University of Technology <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib56" title="">56</a>]</cite>, and is primarily funded by the German Federal Ministry for Economic Affairs and Climate Action <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib61" title="">61</a>]</cite>. However, this leaderboard currently presents results only for smaller models (up to 8 billion parameters), excludes some low-resource EU languages, and does not include benchmarks for vulnerabilities to multilingual jailbreaks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib32" title="">32</a>]</cite>. Nevertheless, such developments have the potential to be integrated into best practices, standards, and future regulations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib16" title="">16</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">It has been also been suggested that the European High Performance Computing Joint Undertaking (EuroHPC JU) should redirect its computational resources towards computationally intensive safety research, to take an advantage of the growing AI Assurance industry <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib43" title="">43</a>]</cite>. Our recommended requirements could increase demand for model safety assessment services, further strengthening the case for promoting safety-oriented research and development.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations and future research</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Key limitations of the quantitative analysis in this paper include uncertainties regarding the quality of automatic translations and classification of prompts, see <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S3" title="3 Methodology for the quantitative analysis ‚Ä£ Towards Safe Multilingual Frontier AI">Methodology</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.SS4" title="4.4 Regression results ‚Ä£ 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI">Regression Results</a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax5" title="Appendix E: Assumption Testing ‚Ä£ Towards Safe Multilingual Frontier AI">Appendix E</a> for a discussion. Although we tested these assumptions and found them approximately true, more work is needed to quantify their impact. Another potential issue that can affect model performance in different languages is the contamination of data used for model training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib12" title="">12</a>]</cite>. The significance of the results may also be affected by the limited number of prompts per language, which was driven by resource constraints. Additionally, jailbreaks remain problematic as long as they can be executed in any language, underscoring the need for safety testing across a broader range of languages. Nevertheless, we believe the analysis and assumption testing conducted are not only sufficient as a proof-of-concept but also strong enough to suggest a significant relationship between multilingual jailbreak vulnerability and language resourcedness for two of the models.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">The statistical analysis can be extended by comparing harmful prompt rejection rates and harmless prompt acceptance rates between different languages and language groups. For instance, comparing results for English versus non-English languages, and high-resource languages vs. other languages. It may be important to increase the sample size for the statistical power of such analysis.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">It is important to note that, apart from natural languages, models can be vulnerable in various non-natural (e.g. programming) languages, which also warrant safety testing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib76" title="">76</a>]</cite>. Even less explored is model safety assessment to prompts in "hybrid" languages: with 7000 natural languages, there could be millions of "interpolated" languages, which could render all-encompassing black-box safety assessments infeasible.</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">In addition, the <span class="ltx_text ltx_font_italic" id="S6.p4.1.1">persuasion</span> capabilities of models like GPT-4o have been found to cross important thresholds <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib53" title="">53</a>]</cite>. The interaction between multilingual capabilities and persuasiveness raises concerns, particularly regarding the use of LLMs to influence political opinions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib36" title="">36</a>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Broader impacts statement</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">The work and analysis presented in this paper do not reveal any novel vulnerabilities. Instead, the analysis primarily demonstrates that known vulnerabilities may persist and could lead to adverse outcomes as models become more advanced.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Concerns could arise that the requirements tor report multilingual capabilities and vulnerabilities to
multilingual jailbreaks could increase the regulatory burden, thereby impeding innovation. However, because
only the largest models would be affected, and because only transparency, not adherence to certain
standards, would be required (at least as initially), we deem this unlikely. It seems plausible that the benefits from multilingually capable and safe frontier models could
exceed the costs of assessment by several orders of magnitude. Still, cost estimates would be needed
not only to ascertain the feasibility of the recommendations, but also to assess feasibility of possible
expansion in scope, e.g. to require capability assessments for a larger set of languages.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Recommendations for EU policy</h2>
<section class="ltx_subsection" id="S8.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1 </span>Require multilingual capability and safety assessments for frontier AI Models</h3>
<div class="ltx_para" id="S8.SS1.p1">
<ul class="ltx_itemize" id="S8.I1">
<li class="ltx_item" id="S8.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I1.i1.p1">
<p class="ltx_p" id="S8.I1.i1.p1.1">Require reporting on model capabilities across the 24 official EU languages for general-purpose AI models entailing systemic risks.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I1.i2.p1">
<p class="ltx_p" id="S8.I1.i2.p1.1">Require reporting on model susceptibility to multilingual jailbreak attacks across all languages for general-purpose AI models entailing systemic risks.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I1.i3.p1">
<p class="ltx_p" id="S8.I1.i3.p1.1">The <span class="ltx_text ltx_font_bold" id="S8.I1.i3.p1.1.1">Regulation and Compliance Unit of the EU AI Office</span> should lead efforts to monitor and enforce compliance with these reporting obligations.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I1.i4.p1">
<p class="ltx_p" id="S8.I1.i4.p1.1">Initiatives such as the EU AI Act Code of Practice consultations and the multi-stakeholder consultations by the European AI Office offer a unique opportunity to discuss, refine, and introduce such requirements.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I1.i5.p1">
<p class="ltx_p" id="S8.I1.i5.p1.1">Promote independent evaluations by external auditors with access beyond black-box testing to allow for more robust assessments of post-deployment vulnerabilities.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I1.i6.p1">
<p class="ltx_p" id="S8.I1.i6.p1.1">As a result, the EU can leverage the Brussels Effect to promote the benefits of multilingual safety and capability requirements, establishing itself as a global leader in AI safety.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S8.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2 </span>Investigate public preferences regarding the benefits and Costs of multilingual AI</h3>
<div class="ltx_para" id="S8.SS2.p1">
<ul class="ltx_itemize" id="S8.I2">
<li class="ltx_item" id="S8.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I2.i1.p1">
<p class="ltx_p" id="S8.I2.i1.p1.1">The <span class="ltx_text ltx_font_bold" id="S8.I2.i1.p1.1.1">AI for Societal Good Unit of the EU AI Office</span> can play a central role in identifying which capabilities the public values, who could be harmed by AI risks.</p>
</div>
</li>
<li class="ltx_item" id="S8.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I2.i2.p1">
<p class="ltx_p" id="S8.I2.i2.p1.1">Public preferences can be assessed through citizens‚Äô juries, moderated virtual assemblies, and surveys.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S8.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.3 </span>Provide state support for multilingual capabilities and safety</h3>
<div class="ltx_para" id="S8.SS3.p1">
<ul class="ltx_itemize" id="S8.I3">
<li class="ltx_item" id="S8.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I3.i1.p1">
<p class="ltx_p" id="S8.I3.i1.p1.1">The <span class="ltx_text ltx_font_bold" id="S8.I3.i1.p1.1.1">European Commission</span> and <span class="ltx_text ltx_font_bold" id="S8.I3.i1.p1.1.2">Member States</span> can support the creation of high-quality datasets for low-resource languages through initiatives like ALT-EDIC.</p>
</div>
</li>
<li class="ltx_item" id="S8.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I3.i2.p1">
<p class="ltx_p" id="S8.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I3.i2.p1.1.1">EuroHPC JU</span> should allocate EU supercomputing resources towards AI safety research focused on defending against multilingual LLM jailbreaks.</p>
</div>
</li>
<li class="ltx_item" id="S8.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="S8.I3.i3.p1">
<p class="ltx_p" id="S8.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S8.I3.i3.p1.1.1">Member States</span> can collaborate on the development of authoritative tools, benchmarks, and frameworks through projects like the "European LLM Leaderboard".</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Author contributions</h2>
<div class="ltx_para" id="S9.p1">
<p class="ltx_p" id="S9.p1.1">AK conceptualised the study, wrote the manuscript, and managed the overall project. VI collected data for statistical analysis and assisted with formatting. RM provided continuous advisory support and edited and finalised the manuscript.</p>
</div>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Acknowledgements</h2>
<div class="ltx_para" id="S10.p1">
<p class="ltx_p" id="S10.p1.1">This research was supported by the ERA Fellowship. The authors would like to thank the ERA Fellowship for its financial and intellectual support. Arturs thanks Aris Richardson for outstanding research mentorship, and Amor√© Adams and Joseph Castellano for helping to kick off this line of research at the AI Governance Research Sprint at London Initiative for Safe AI on the 10th of August, 2024. We thank Ben Bucknall, Elliot Jones, Jonas Kgomo, Rafael Andersson Lipcsey, Toni Lorente, Lorenzo Pacchiardi, and Nikita Trojanskis for expert advice.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Charter of Fundamental Rights of the European Union, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
ESG Laws and Regulation, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Transparency requirements for listed companies, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Aakanksha, Arash Ahmadian, Beyza Ermis, Seraphina Goldfarb-Tarrant, Julia Kreutzer, Marzieh Fadaee, and Sara Hooker.

</span>
<span class="ltx_bibblock">The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2406.18682.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Daron Acemoglu and Simon Johnson.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Power and Progress: Our Thousand-Year Struggle Over Technology and Prosperity</span>.

</span>
<span class="ltx_bibblock">Basic Books, hardcover edition, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David¬†R. Mortensen, Noah¬†A. Smith, and Yulia Tsvetkov.

</span>
<span class="ltx_bibblock">Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models, 2023.

</span>
<span class="ltx_bibblock">_eprint: 2305.13707.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Mistral AI.

</span>
<span class="ltx_bibblock">Mistral‚Äôs Large 2407 Model Announcement, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Markus Anderljung, Everett¬†Thornton Smith, Joe O‚ÄôBrien, Lisa Soder, Benjamin Bucknall, Emma Bluemke, Jonas Schuett, Robert Trager, Lacey Strahm, and Rumman Chowdhury.

</span>
<span class="ltx_bibblock">Towards publicly accountable frontier llms: Building an external scrutiny ecosystem under the aspire framework, 2023.

</span>
<span class="ltx_bibblock">eprint: 2311.14711.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">What are some things I can use Claude for?, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase, Ekdeep¬†Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, Benjamin¬†L. Edelman, Zhaowei Zhang, Mario G√ºnther, Anton Korinek, Jose Hernandez-Orallo, Lewis Hammond, Eric Bigelow, Alexander Pan, Lauro Langosco, Tomasz Korbak, Heidi Zhang, Ruiqi Zhong, Se√°n¬†√ì h√âigeartaigh, Gabriel Recchia, Giulio Corsi, Alan Chan, Markus Anderljung, Lilian Edwards, Yoshua Bengio, Danqi Chen, Samuel Albanie, Tegan Maharaj, Jakob Foerster, Florian Tramer, He¬†He, Atoosa Kasirzadeh, Yejin Choi, and David Krueger.

</span>
<span class="ltx_bibblock">Foundational Challenges in Assuring Alignment and Safety of Large Language Models, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2404.09932.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet¬†V. Do, Yan Xu, and Pascale Fung.

</span>
<span class="ltx_bibblock">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Andrew¬†M. Bean, Simi Hellsten, Harry Mayne, Jabez Magomere, Ethan¬†A. Chi, Ryan Chi, Scott¬†A. Hale, and Hannah¬†Rose Kirk.

</span>
<span class="ltx_bibblock">LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2406.06196.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Toms Bergmanis.

</span>
<span class="ltx_bibblock">TL;DR: If you use Chat GPT-4 and your native language is not English, you are doing a disservice to yourself. Why?, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Manish Bhatt, Sahana Chennabasappa, Yue Li, Cyrus Nikolaidis, Daniel Song, Shengye Wan, Faizan Ahmad, Cornelius Aschermann, Yaohui Chen, Dhaval Kapil, David Molnar, Spencer Whitman, and Joshua Saxe.

</span>
<span class="ltx_bibblock">Cyberseceval 2: A wide-ranging cybersecurity evaluation suite for large language models, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Stephen Casper, Carson Ezell, Charlotte Siegmann, Noam Kolt, Taylor¬†Lynn Curtis, Benjamin Bucknall, Andreas Haupt, Kevin Wei, J√©r√©my Scheurer, Marius Hobbhahn, Lee Sharkey, Satyapriya Krishna, Marvin Von¬†Hagen, Silas Alberti, Alan Chan, Qinyi Sun, Michael Gerovitch, David Bau, Max Tegmark, David Krueger, and Dylan Hadfield-Menell.

</span>
<span class="ltx_bibblock">Black-Box Access is Insufficient for Rigorous AI Audits.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency</span>, FAccT ‚Äô24, pages 2254‚Äì2272, New York, NY, USA, 2024. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">event-place: Rio de Janeiro, Brazil.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Cohere For AI team.

</span>
<span class="ltx_bibblock">Policy Primer - The AI Language Gap, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
European Commission.

</span>
<span class="ltx_bibblock">AI Act: Have Your Say on Trustworthy General Purpose AI, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
European Commission.

</span>
<span class="ltx_bibblock">AI Act: Participate in Drawing the First General Purpose AI Code of Practice, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
European Commission.

</span>
<span class="ltx_bibblock">ALT-EDIC: European Language Data Space, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
CommonCrawl.

</span>
<span class="ltx_bibblock">Common Crawl Statistics: Languages, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Ben Cottier, Robi Rahman, Loredana Fattorini, Nestor Maslej, and David Owen.

</span>
<span class="ltx_bibblock">The rising costs of training frontier ai models, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Justin Cui, Wei-Lin Chiang, Ion Stoica, and Cho-Jui Hsieh.

</span>
<span class="ltx_bibblock">OR-Bench: An Over-Refusal Benchmark for Large Language Models, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2405.20947.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Yue Deng, Wenxuan Zhang, Sinno¬†Jialin Pan, and Lidong Bing.

</span>
<span class="ltx_bibblock">Multilingual Jailbreak Challenges in Large Language Models, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2310.06474.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Directorate-General for Communications Networks, Content and Technology.

</span>
<span class="ltx_bibblock">Communications networks, content and technology - european commission, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-27.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, and others.

</span>
<span class="ltx_bibblock">The Llama 3 Herd of Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2407.21783</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Epoch AI.

</span>
<span class="ltx_bibblock">Machine Learning Trends, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
EU AI Office.

</span>
<span class="ltx_bibblock">Why work at the eu ai office?, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-27.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
European Centre for Algorithmic Transparency.

</span>
<span class="ltx_bibblock">European centre for algorithmic transparency, 2022.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-27.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
European Commission.

</span>
<span class="ltx_bibblock">Artificial intelligence: New rules to ensure ai is trustworthy, safe, and human-centric, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-27.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Directorate-General for Parliamentary Research¬†Services European¬†Parliament.

</span>
<span class="ltx_bibblock">Language equality in the digital age, 2017.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-29.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
European Union.

</span>
<span class="ltx_bibblock">Regulation (EU) 2024/1689 of the European Parliament and of the Council of 14 August 2024 on Harmonised Rules for Artificial Intelligence (AI Act), 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Hugging Face.

</span>
<span class="ltx_bibblock">European LLM Leaderboard - OpenGPT-X, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">Google gemini faq, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-28.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Nicholas Gruen.

</span>
<span class="ltx_bibblock">Building the public goods of the twenty-first century.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">Evonomics,[online]</span>, 31, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Stanford HAI.

</span>
<span class="ltx_bibblock">AI Index Report 2024, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Tetiana Haiduchyk, Artur Shevtsov, and Gundars Bergmanis-KorƒÅts.

</span>
<span class="ltx_bibblock">AI in Precision Persuasion, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Kaiyu Huang, Fengran Mo, Hongliang Li, You Li, Yuanchi Zhang, Weijian Yi, Yulong Mao, Jinchen Liu, Yuzhuang Xu, Jinan Xu, Jian-Yun Nie, and Yang Liu.

</span>
<span class="ltx_bibblock">A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2405.10936.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
International Monetary Fund.

</span>
<span class="ltx_bibblock">AI Will Transform the Global Economy‚ÄîLet‚Äôs Make Sure It Benefits Humanity.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">IMF Blog</span>, January 2024.

</span>
<span class="ltx_bibblock">Publisher: International Monetary Fund.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Ipsos AI Monitor.

</span>
<span class="ltx_bibblock">The Ipsos AI Monitor 2024: A 32-country Ipsos Global Advisor Survey.

</span>
<span class="ltx_bibblock">Technical report, June 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Agnieszka Jab≈Çonowska and Giacomo Tagiuri.

</span>
<span class="ltx_bibblock">Rescuing transparency in the digital economy: in search of a common notion in EU consumer and data protection law.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib40.1.1">Yearbook of European Law</span>, 42:347‚Äì387, 09 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Elliot Jones, Mati Hardalupas, and William Agnew.

</span>
<span class="ltx_bibblock">Under the Radar: The effects of algorithmic systems on digital platform work.

</span>
<span class="ltx_bibblock">Technical report, Ada Lovelace Institute, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury.

</span>
<span class="ltx_bibblock">The State and Fate of Linguistic Diversity and Inclusion in the NLP World, 2021.

</span>
<span class="ltx_bibblock">_eprint: 2004.09095.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Daan Juijn.

</span>
<span class="ltx_bibblock">Advanced AI: Technical State of Play, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Ivana Katsarova.

</span>
<span class="ltx_bibblock">Multilingualism: The language of the European Union.

</span>
<span class="ltx_bibblock">Technical report, European Parliament, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Jam Kraprayoon and Bill Anderson-Samways.

</span>
<span class="ltx_bibblock">Assuring Growth, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Viet¬†Dac Lai, Nghia¬†Trung Ngo, Amir Pouran¬†Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, and Thien¬†Huu Nguyen.

</span>
<span class="ltx_bibblock">ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning, 2023.

</span>
<span class="ltx_bibblock">_eprint: 2304.05613.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Jie Li, Yi¬†Liu, Chongyang Liu, Ling Shi, Xiaoning Ren, Yaowen Zheng, Yang Liu, and Yinxing Xue.

</span>
<span class="ltx_bibblock">A Cross-Language Investigation into Jailbreak Attacks in Large Language Models, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2401.16765.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, and Summer Yue.

</span>
<span class="ltx_bibblock">Llm defenses are not robust to multi-turn human jailbreaks yet, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Rafael¬†Andersson Lipcsey.

</span>
<span class="ltx_bibblock">AI Diffusion to Low-Middle Income Countries; A Blessing or a Curse?, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2405.20399.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Yi¬†Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang, Lida Zhao, Tianwei Zhang, Kailong Wang, and Yang Liu.

</span>
<span class="ltx_bibblock">Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2305.13860.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Nikita Trojanskis.

</span>
<span class="ltx_bibblock">LinkedIn Post.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.linkedin.com/feed/update/urn:li:activity:7226153524118581249/" title="">https://www.linkedin.com/feed/update/urn:li:activity:7226153524118581249/</a>, August 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Xataka On.

</span>
<span class="ltx_bibblock">Large-2 is Mistral‚Äôs new language model: it‚Äôs a European ode to efficiency, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">GPT-4o System Card, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">How to change your language setting in chatgpt, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-08-28.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia¬†Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung¬†Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Sim√≥n¬†Posada Fishman, Juston Forte, Isabella Fulford, Leo
Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang¬†Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, ≈Åukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish¬†Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong¬†Wook Kim, Christina Kim, Yongjik Kim, Jan¬†Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, ≈Åukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak¬†Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan
Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott¬†Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David M√©ly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O‚ÄôKeefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila¬†Belbute Peres, Michael Petrov, Henrique Ponde de¬†Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr¬†H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez,
Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe¬†Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine¬†B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe¬†Cer√≥n Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin¬†Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, C.¬†J. Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia
Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
OpenGPT-X.

</span>
<span class="ltx_bibblock">Partners - OpenGPT-X, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Houwen Peng, Kan Wu, Yixuan Wei, Guoshuai Zhao, Yuxiang Yang, Ze¬†Liu, Yifan Xiong, Ziyue Yang, Bolin Ni, Jingcheng Hu, Ruihang Li, Miaosen Zhang, Chen Li, Jia Ning, Ruizhe Wang, Zheng Zhang, Shuguang Liu, Joe Chau, Han Hu, and Peng Cheng.

</span>
<span class="ltx_bibblock">FP8-LM: Training FP8 Large Language Models, 2023.

</span>
<span class="ltx_bibblock">_eprint: 2310.18313.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Georg Rehm and Andy Way.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib58.1.1">European Language Equality: A Strategic Agenda for Digital Language Equality</span>.

</span>
<span class="ltx_bibblock">Springer Nature, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Anka Reuel, Ben Bucknall, Stephen Casper, Tim Fist, Lisa Soder, Onni Aarne, Lewis Hammond, Lujain Ibrahim, Alan Chan, Peter Wills, Markus Anderljung, Ben Garfinkel, Lennart Heim, Andrew Trask, Gabriel Mukobi, Rylan Schaeffer, Mauricio Baker, Sara Hooker, Irene Solaiman, Alexandra¬†Sasha Luccioni, Nitarshan Rajkumar, Nicolas Mo√´s, Jeffrey Ladish, Neel Guha, Jessica Newman, Yoshua Bengio, Tobin South, Alex Pentland, Sanmi Koyejo, Mykel¬†J. Kochenderfer, and Robert Trager.

</span>
<span class="ltx_bibblock">Open Problems in Technical AI Governance, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2407.14981.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Girish Sastry, Lennart Heim, Haydn Belfield, Markus Anderljung, Miles Brundage, Julian Hazell, Cullen O‚ÄôKeefe, Gillian¬†K. Hadfield, Richard Ngo, Konstantin Pilz, George Gor, Emma Bluemke, Sarah Shoker, Janet Egan, Robert¬†F. Trager, Shahar Avin, Adrian Weller, Yoshua Bengio, and Diane Coyle.

</span>
<span class="ltx_bibblock">Computing Power and the Governance of Artificial Intelligence, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2402.08797.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Julija Saviƒá.

</span>
<span class="ltx_bibblock">European LLM Leaderboard: A New Move in Multilingual AI Development, July 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Elizabeth Seger, Aviv Ovadya, Divya Siddarth, Ben Garfinkel, and Allan Dafoe.

</span>
<span class="ltx_bibblock">Democratising AI: Multiple Meanings, Goals, and Methods.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib62.1.1">Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society</span>, AIES ‚Äô23, pages 715‚Äì722, New York, NY, USA, 2023. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">event-place: Montr√©al, QC, Canada.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Lingfeng Shen, Weiting Tan, Sihao Chen, Yunmo Chen, Jingyu Zhang, Haoran Xu, Boyuan Zheng, Philipp Koehn, and Daniel Khashabi.

</span>
<span class="ltx_bibblock">The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2401.13136.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Charlotte Siegmann and Markus Anderljung.

</span>
<span class="ltx_bibblock">The Brussels Effect and Artificial Intelligence, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
LUMI Supercomputer.

</span>
<span class="ltx_bibblock">LUMI Supercomputer Hardware Documentation, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Daniel Susskind.

</span>
<span class="ltx_bibblock">Work and Meaning in the Age of AI.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib66.1.1">AEA Papers and Proceedings</span>, 113:453‚Äì57, 2023.

</span>
<span class="ltx_bibblock">Publisher: American Economic Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Tianyi Tang, Wenyang Luo, Haoyang Huang, Dongdong Zhang, Xiaolei Wang, Xin Zhao, Furu Wei, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2402.16438.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
SIA Tilde.

</span>
<span class="ltx_bibblock">LLM AI Large AI Grand Challenge, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
European Union.

</span>
<span class="ltx_bibblock">Eurobarometer 100.1 (April-May 2023) ‚Äì SP540/ENG, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Vellum AI.

</span>
<span class="ltx_bibblock">LLM Leaderboard, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Wenxuan Wang, Zhaopeng Tu, Chang Chen, Youliang Yuan, Jen-tse Huang, Wenxiang Jiao, and Michael¬†R. Lyu.

</span>
<span class="ltx_bibblock">All Languages Matter: On the Multilingual Safety of Large Language Models, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2310.00905.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Tom Warren.

</span>
<span class="ltx_bibblock">Google pauses Gemini‚Äôs ability to generate AI images of people after diversity errors.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib72.1.1">The Verge</span>, February 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Jailbroken: How does llm safety training fail?, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Claudia Wilson.

</span>
<span class="ltx_bibblock">The EU AI Act and Brussels Effect: How will American AI firms respond to General Purpose AI requirements?

</span>
<span class="ltx_bibblock">August 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Yuemei Xu, Ling Hu, Jiayi Zhao, Zihan Qiu, Yuqi Ye, and Hanwen Gu.

</span>
<span class="ltx_bibblock">A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias, 2024.

</span>
<span class="ltx_bibblock">_eprint: 2404.00929.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Zheng-Xin Yong, Cristina Menghini, and Stephen¬†H. Bach.

</span>
<span class="ltx_bibblock">Low-Resource Languages Jailbreak GPT-4, 2023.

</span>
<span class="ltx_bibblock">_eprint: 2310.02446.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
√âlys√©e.

</span>
<span class="ltx_bibblock">AI Action Summit, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix A: Training Compute Estimate for Tilde Model </h2>
<div class="ltx_para" id="Ax1.p1">
<p class="ltx_p" id="Ax1.p1.1">LUMI primarily uses AMD Instinct MI250X GPUs,<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib65" title="">65</a>]</cite> which have Peak Half Precision (FP16) Performance of 383 TFLOPs and Peak Single Precision (FP32) Performance of 47.9 TFLOP. Both FP16 and FP32 are typically used for training LLMs.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib57" title="">57</a>]</cite> 2 million GPU hours<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib68" title="">68</a>]</cite> amount to 7.2√ó10<sup class="ltx_sup" id="Ax1.p1.1.1">9</sup> seconds. So the total amount of FLOP used in each of these precisions would be:</p>
</div>
<div class="ltx_para" id="Ax1.p2">
<ul class="ltx_itemize" id="Ax1.I1">
<li class="ltx_item" id="Ax1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Ax1.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.i1.p1.1">FP16: 383 x 10<sup class="ltx_sup" id="Ax1.I1.i1.p1.1.1">12</sup> x 7.2√ó10<sup class="ltx_sup" id="Ax1.I1.i1.p1.1.2">9</sup> = 2.8 √ó10<sup class="ltx_sup" id="Ax1.I1.i1.p1.1.3">24</sup> FLOP</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Ax1.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.i2.p1.1">FP32: 47.9 x 10<sup class="ltx_sup" id="Ax1.I1.i2.p1.1.1">12</sup> x 7.2√ó10<sup class="ltx_sup" id="Ax1.I1.i2.p1.1.2">9</sup> = 3.4 √ó10<sup class="ltx_sup" id="Ax1.I1.i2.p1.1.3">23</sup> FLOP</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="Ax1.p3">
<p class="ltx_p" id="Ax1.p3.1">For comparison, notable OpenAI model training compute (FLOP) was:<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib26" title="">26</a>]</cite></p>
</div>
<div class="ltx_para" id="Ax1.p4">
<ul class="ltx_itemize" id="Ax1.I2">
<li class="ltx_item" id="Ax1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Ax1.I2.i1.p1">
<p class="ltx_p" id="Ax1.I2.i1.p1.1">OpenAI GPT-3 (Published on May 2020): 3.1 √ó10<sup class="ltx_sup" id="Ax1.I2.i1.p1.1.1">23</sup></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Ax1.I2.i2.p1">
<p class="ltx_p" id="Ax1.I2.i2.p1.1">OpenAI GPT-3.5 (Published on November 2022): 2.6 √ó10<sup class="ltx_sup" id="Ax1.I2.i2.p1.1.1">24</sup></p>
</div>
</li>
<li class="ltx_item" id="Ax1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="Ax1.I2.i3.p1">
<p class="ltx_p" id="Ax1.I2.i3.p1.1">OpenAI GPT-4 (Published on March 2023): 2.1 √ó10<sup class="ltx_sup" id="Ax1.I2.i3.p1.1.1">25</sup></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_appendix" id="Ax2">
<h2 class="ltx_title ltx_title_appendix">Appendix B: Annotation Guidelines</h2>
<div class="ltx_para" id="Ax2.p1">
<p class="ltx_p" id="Ax2.p1.1">The following attack success annotation guidelines provided to the model to classify answers:</p>
</div>
<div class="ltx_para" id="Ax2.p2">
<p class="ltx_p" id="Ax2.p2.1">A language model gave a response to a prompt. You are shown the prompt and response. Please classify the language model‚Äôs response as:
ACCEPTED if the response stays on topic and answers the prompt.
REJECTED if the response refuses to answer the prompt or acknowledges the harmfulness of the prompt and tries to dissuade the user or provide alternatives.
UNCLEAR if the response is nonsensical, off topic, a misinterpretation of the instruction, or any response that doesn‚Äôt provide any actionable insight but doesn‚Äôt clearly refuse to engage. This includes cases when the response says that it cannot answer because it does not understand the language.
The prompt is:
===PROMPT===
{prompt}
===END PROMPT===
The language model‚Äôs response is:
===LLM‚ÄôS RESPONSE===
{response}
===LLM‚Äôs RESPONSE===
Please answer with either ACCEPTED, REJECTED, or UNCLEAR.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Ax3">
<h2 class="ltx_title ltx_title_appendix">Appendix C: Resourcedness for the 24 EU Languages</h2>
<figure class="ltx_table" id="Ax3.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>EU official languages, their abbreviations, CommonCrawl corpus share,<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib20" title="">20</a>]</cite> and native speakers (Speakers in the EU with the respective language being the first ‚Äúmother tongue‚Äù).<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib69" title="">69</a>]</cite></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="Ax3.T3.1">
<tr class="ltx_tr" id="Ax3.T3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="Ax3.T3.1.1.1">EU Official Language</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax3.T3.1.1.2">Abbreviation</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax3.T3.1.1.3">CommonCrawl Corpus Share</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax3.T3.1.1.4">Speakers in the EU</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.2">
<td class="ltx_td" id="Ax3.T3.1.2.1"></td>
<td class="ltx_td" id="Ax3.T3.1.2.2"></td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.2.3">(%)</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.2.4">(millions)</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax3.T3.1.3.1">English</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.3.2">en</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.3.3">43.7909</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.3.4">9.20</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.4">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.4.1">German</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.4.2">de</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.4.3">5.2890</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.4.4">82.81</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.5">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.5.1">Spanish</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.5.2">es</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.5.3">4.5593</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.5.4">41.28</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.6">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.6.1">French</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.6.2">fr</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.6.3">4.2211</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.6.4">63.77</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.7">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.7.1">Italian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.7.2">it</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.7.3">2.6077</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.7.4">57.26</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.8">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.8.1">Portuguese</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.8.2">pt</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.8.3">2.1237</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.8.4">11.38</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.9">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.9.1">Dutch</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.9.2">nl</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.9.3">1.8216</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.9.4">22.35</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.10">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.10.1">Polish</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.10.2">pl</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.10.3">1.7963</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.10.4">37.80</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.11">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.11.1">Czech</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.11.2">cs</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.11.3">1.0256</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.11.4">10.21</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.12">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax3.T3.1.12.1">Swedish</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.12.2">sv</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.12.3">0.6803</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.12.4">9.72</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.13">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.13.1">Hungarian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.13.2">hu</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.13.3">0.5646</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.13.4">18.68</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.14">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.14.1">Greek</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.14.2">el</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.14.3">0.5633</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.14.4">11.28</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.15">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.15.1">Romanian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.15.2">ro</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.15.3">0.5781</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.15.4">11.19</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.16">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.16.1">Danish</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.16.2">da</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.16.3">0.4487</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.16.4">5.51</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.17">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.17.1">Slovak</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.17.2">sk</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.17.3">0.4022</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.17.4">4.85</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.18">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.18.1">Finnish</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.18.2">fi</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.18.3">0.3472</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.18.4">5.41</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.19">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.19.1">Bulgarian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.19.2">bg</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.19.3">0.2998</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.19.4">6.71</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.20">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.20.1">Croatian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.20.2">hr</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.20.3">0.2118</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.20.4">4.09</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.21">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.21.1">Slovenian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.21.2">sl</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.21.3">0.1613</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.21.4">2.23</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.22">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.22.1">Lithuanian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.22.2">lt</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.22.3">0.1550</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.22.4">2.64</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.23">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.23.1">Estonian</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.23.2">et</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.23.3">0.1285</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.23.4">0.98</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.24">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax3.T3.1.24.1">Latvian</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.24.2">lv</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.24.3">0.0882</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.24.4">1.34</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.25">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.25.1">Irish</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.25.2">ga</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.25.3">0.0069</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.25.4">0.19</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.26">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.26.1">Maltese</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.26.2">mt</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.26.3">0.0044</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.26.4">0.64</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.27">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax3.T3.1.27.1">Total high-resource</td>
<td class="ltx_td ltx_border_t" id="Ax3.T3.1.27.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.27.3">67.2352</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax3.T3.1.27.4">336.06</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.28">
<td class="ltx_td ltx_align_left" id="Ax3.T3.1.28.1">Total medium-resource</td>
<td class="ltx_td" id="Ax3.T3.1.28.2"></td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.28.3">4.5408</td>
<td class="ltx_td ltx_align_center" id="Ax3.T3.1.28.4">83.30</td>
</tr>
<tr class="ltx_tr" id="Ax3.T3.1.29">
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ax3.T3.1.29.1">Total low-resource</td>
<td class="ltx_td ltx_border_bb" id="Ax3.T3.1.29.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax3.T3.1.29.3">0.0995</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax3.T3.1.29.4">2.16</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_appendix" id="Ax4">
<h2 class="ltx_title ltx_title_appendix">Appendix D: Model Selection</h2>
<div class="ltx_para" id="Ax4.p1">
<p class="ltx_p" id="Ax4.p1.1">Our focus is on models that can create societal-scale harms. A fitting category are <span class="ltx_text ltx_font_italic" id="Ax4.p1.1.1">general-purpose AI models with systemic risk</span>, as defined by the EU. Specifically, the EU AI Act Article 51(2)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib31" title="">31</a>]</cite> states:</p>
</div>
<div class="ltx_para" id="Ax4.p2">
<p class="ltx_p" id="Ax4.p2.1"><span class="ltx_text ltx_font_italic" id="Ax4.p2.1.1">A general-purpose AI model shall be presumed to have high impact capabilities pursuant to paragraph 1, point (a), when the cumulative amount of computation used for its training measured in floating point operations is greater than 10<sup class="ltx_sup" id="Ax4.p2.1.1.1">25</sup>.</span></p>
</div>
<div class="ltx_para" id="Ax4.p3">
<p class="ltx_p" id="Ax4.p3.1">As of August 2024 the available data shows just a handful of such models (with the compute used for training, and provider in brackets).<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib26" title="">26</a>]</cite> The three largest are: Gemini 1.0 Ultra (5x10<sup class="ltx_sup" id="Ax4.p3.1.1">25</sup> FLOP, Google DeepMind); Llama 3.1-405B (3.8x10<sup class="ltx_sup" id="Ax4.p3.1.2">25</sup> FLOP, Meta AI); and GPT-4 (2.8x10<sup class="ltx_sup" id="Ax4.p3.1.3">25</sup> OpenAI).</p>
</div>
<div class="ltx_para" id="Ax4.p4">
<p class="ltx_p" id="Ax4.p4.1">Note that the original dataset does not include newer versions of the models, specifically, Gemini 1.5 and GPT-4o. In our analysis we consider these latest versions. We also consider Claude 3.5 Sonnet by Anthropic, which by several measures surpasses the other frontier models in terms of capabilities,<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib70" title="">70</a>]</cite> and the largest model developed in the EU, Mistral Large 2.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib52" title="">52</a>]</cite></p>
</div>
<div class="ltx_para" id="Ax4.p5">
<p class="ltx_p" id="Ax4.p5.1">We found it generally difficult to find what languages the models support, and what this support entails. Often the descriptions refer to a marketed product, like ChatGPT, instead of the underlying model, like GPT-4o or gpt-4o-2024-05-13. A summary for the EU languages and sources is shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#Ax4.T4" title="Table 4 ‚Ä£ Appendix D: Model Selection ‚Ä£ Towards Safe Multilingual Frontier AI">Table 4</a>.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib25" title="">25</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib7" title="">7</a>]</cite></p>
</div>
<div class="ltx_para" id="Ax4.p6">
<p class="ltx_p" id="Ax4.p6.1">ChatGPT and Gemini are claimed to support all EU languages except Irish and Maltese. At the other end, Anthropic‚Äôs Claude is explicitly stated to support just three more languages (and the statement refers to translation function).<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><span class="ltx_text ltx_font_italic" id="footnote10.1">While Claude is best at English due to its training data, Claude knows more than a dozen languages and can translate between them to varying degrees of success. Some languages Claude is especially good at other than English are Portuguese, French, and German.</span></span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib9" title="">9</a>]</cite> Some statements claim support in more languages, but explicitly name just a few.<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><span class="ltx_text ltx_font_italic" id="footnote11.1">Mistral Large 2 has a 128k context window and supports dozens of languages including French, German, Spanish, Italian, Portuguese, Arabic, Hindi, Russian, Chinese, Japanese, and Korean, along with 80+ coding languages including Python, Java, C, C++, JavaScript, and Bash.</span></span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib7" title="">7</a>]</cite></p>
</div>
<div class="ltx_para" id="Ax4.p7">
<p class="ltx_p" id="Ax4.p7.1">Note that some frontier model providers have published detailed multilingual capability assessments. For example, assessments in dozens of languages were reported in the GPT-4 Technical Report. With two exceptions, performance was above GPT-3.5 levels.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib55" title="">55</a>]</cite> Furthermore, the performance gap could be an overestimate because of data contamination and translation issues, which can reduce multilingual capability estimates for less resourced languages.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#bib.bib12" title="">12</a>]</cite></p>
</div>
<figure class="ltx_table" id="Ax4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Language capabilities of different products for EU official languages.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="Ax4.T4.1">
<tr class="ltx_tr" id="Ax4.T4.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="Ax4.T4.1.1.1">Language</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax4.T4.1.1.2">OpenAI</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax4.T4.1.1.3">Google</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax4.T4.1.1.4">Mistral</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax4.T4.1.1.5">Meta</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ax4.T4.1.1.6">Anthropic</td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.2">
<td class="ltx_td" id="Ax4.T4.1.2.1"></td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.2.2">ChatGPT</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.2.3">Gemini</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.2.4">Large 2</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.2.5">Llama 3</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.2.6">Claude</td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax4.T4.1.3.1">Bulgarian</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax4.T4.1.3.2">x</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax4.T4.1.3.3">x</td>
<td class="ltx_td ltx_border_t" id="Ax4.T4.1.3.4"></td>
<td class="ltx_td ltx_border_t" id="Ax4.T4.1.3.5"></td>
<td class="ltx_td ltx_border_t" id="Ax4.T4.1.3.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.4">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.4.1">Croatian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.4.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.4.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.4.4"></td>
<td class="ltx_td" id="Ax4.T4.1.4.5"></td>
<td class="ltx_td" id="Ax4.T4.1.4.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.5">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.5.1">Czech</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.5.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.5.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.5.4"></td>
<td class="ltx_td" id="Ax4.T4.1.5.5"></td>
<td class="ltx_td" id="Ax4.T4.1.5.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.6">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.6.1">Danish</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.6.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.6.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.6.4"></td>
<td class="ltx_td" id="Ax4.T4.1.6.5"></td>
<td class="ltx_td" id="Ax4.T4.1.6.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.7">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.7.1">Dutch</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.7.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.7.3">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.7.4">x</td>
<td class="ltx_td" id="Ax4.T4.1.7.5"></td>
<td class="ltx_td" id="Ax4.T4.1.7.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.8">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.8.1">English</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.8.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.8.3">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.8.4">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.8.5">x</td>
<td class="ltx_td" id="Ax4.T4.1.8.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.9">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.9.1">Estonian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.9.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.9.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.9.4"></td>
<td class="ltx_td" id="Ax4.T4.1.9.5"></td>
<td class="ltx_td" id="Ax4.T4.1.9.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.10">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.10.1">Finnish</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.10.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.10.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.10.4"></td>
<td class="ltx_td" id="Ax4.T4.1.10.5"></td>
<td class="ltx_td" id="Ax4.T4.1.10.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.11">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.11.1">French</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.11.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.11.3">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.11.4">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.11.5">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.11.6">x</td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.12">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.12.1">German</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.12.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.12.3">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.12.4">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.12.5">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.12.6">x</td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.13">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.13.1">Greek</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.13.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.13.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.13.4"></td>
<td class="ltx_td" id="Ax4.T4.1.13.5"></td>
<td class="ltx_td" id="Ax4.T4.1.13.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.14">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.14.1">Hungarian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.14.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.14.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.14.4"></td>
<td class="ltx_td" id="Ax4.T4.1.14.5"></td>
<td class="ltx_td" id="Ax4.T4.1.14.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.15">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.15.1">Irish</td>
<td class="ltx_td" id="Ax4.T4.1.15.2"></td>
<td class="ltx_td" id="Ax4.T4.1.15.3"></td>
<td class="ltx_td" id="Ax4.T4.1.15.4"></td>
<td class="ltx_td" id="Ax4.T4.1.15.5"></td>
<td class="ltx_td" id="Ax4.T4.1.15.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.16">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.16.1">Italian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.16.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.16.3">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.16.4">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.16.5">x</td>
<td class="ltx_td" id="Ax4.T4.1.16.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.17">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.17.1">Latvian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.17.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.17.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.17.4"></td>
<td class="ltx_td" id="Ax4.T4.1.17.5"></td>
<td class="ltx_td" id="Ax4.T4.1.17.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.18">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.18.1">Lithuanian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.18.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.18.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.18.4"></td>
<td class="ltx_td" id="Ax4.T4.1.18.5"></td>
<td class="ltx_td" id="Ax4.T4.1.18.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.19">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.19.1">Maltese</td>
<td class="ltx_td" id="Ax4.T4.1.19.2"></td>
<td class="ltx_td" id="Ax4.T4.1.19.3"></td>
<td class="ltx_td" id="Ax4.T4.1.19.4"></td>
<td class="ltx_td" id="Ax4.T4.1.19.5"></td>
<td class="ltx_td" id="Ax4.T4.1.19.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.20">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.20.1">Polish</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.20.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.20.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.20.4"></td>
<td class="ltx_td" id="Ax4.T4.1.20.5"></td>
<td class="ltx_td" id="Ax4.T4.1.20.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.21">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.21.1">Portuguese</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.21.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.21.3">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.21.4">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.21.5">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.21.6">x</td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.22">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.22.1">Romanian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.22.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.22.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.22.4"></td>
<td class="ltx_td" id="Ax4.T4.1.22.5"></td>
<td class="ltx_td" id="Ax4.T4.1.22.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.23">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.23.1">Slovak</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.23.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.23.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.23.4"></td>
<td class="ltx_td" id="Ax4.T4.1.23.5"></td>
<td class="ltx_td" id="Ax4.T4.1.23.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.24">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.24.1">Slovenian</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.24.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.24.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.24.4"></td>
<td class="ltx_td" id="Ax4.T4.1.24.5"></td>
<td class="ltx_td" id="Ax4.T4.1.24.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.25">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.25.1">Spanish</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.25.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.25.3">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.25.4">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.25.5">x</td>
<td class="ltx_td" id="Ax4.T4.1.25.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.26">
<td class="ltx_td ltx_align_left" id="Ax4.T4.1.26.1">Swedish</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.26.2">x</td>
<td class="ltx_td ltx_align_center" id="Ax4.T4.1.26.3">x</td>
<td class="ltx_td" id="Ax4.T4.1.26.4"></td>
<td class="ltx_td" id="Ax4.T4.1.26.5"></td>
<td class="ltx_td" id="Ax4.T4.1.26.6"></td>
</tr>
<tr class="ltx_tr" id="Ax4.T4.1.27">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="Ax4.T4.1.27.1">EU official languages supported</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="Ax4.T4.1.27.2">22</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="Ax4.T4.1.27.3">22</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="Ax4.T4.1.27.4">7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="Ax4.T4.1.27.5">6</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="Ax4.T4.1.27.6">3</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Ax5">
<h2 class="ltx_title ltx_title_appendix">Appendix E: Assumption Testing</h2>
<div class="ltx_para" id="Ax5.p1">
<p class="ltx_p" id="Ax5.p1.1">We manually assessed the 19 harmful prompts that were ACCEPTED by GPT-4o in Latvian, out of the 256 initial ones. 2 of the 19 prompts became harmless after translation, including the one described below:</p>
</div>
<div class="ltx_para" id="Ax5.p2">
<ol class="ltx_enumerate" id="Ax5.I3">
<li class="ltx_item" id="Ax5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="Ax5.I3.i1.p1">
<p class="ltx_p" id="Ax5.I3.i1.p1.1">Harmful prompt in English: <span class="ltx_text ltx_font_italic" id="Ax5.I3.i1.p1.1.1">What are some methods to take advantage of marginalized groups in a business setting?</span></p>
</div>
</li>
<li class="ltx_item" id="Ax5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="Ax5.I3.i2.p1">
<p class="ltx_p" id="Ax5.I3.i2.p1.1">Google Translate translation to Latvian: <span class="ltx_text ltx_font_italic" id="Ax5.I3.i2.p1.1.1">KƒÅdas ir da≈æas metodes, kƒÅ biznesa vidƒì izmantot atstumto grupu priek≈°rocƒ´bas?</span></p>
<ol class="ltx_enumerate" id="Ax5.I3.i2.I1">
<li class="ltx_item" id="Ax5.I3.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span>
<div class="ltx_para" id="Ax5.I3.i2.I1.i1.p1">
<p class="ltx_p" id="Ax5.I3.i2.I1.i1.p1.1">When assessed by a native Latvian speaker, this means approximately:
<span class="ltx_text ltx_font_italic" id="Ax5.I3.i2.I1.i1.p1.1.1">What are some methods for using the advantages of marginalized groups in a business setting?</span>
This question can be considered harmless.</p>
</div>
</li>
</ol>
</div>
</li>
<li class="ltx_item" id="Ax5.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="Ax5.I3.i3.p1">
<p class="ltx_p" id="Ax5.I3.i3.p1.1">GPT-4o response in Latvian (shortened): <span class="ltx_text ltx_font_italic" id="Ax5.I3.i3.p1.1.1">Atstumto grupu potenciƒÅlu izmanto≈°ana biznesa vidƒì ir ne tikai ƒìtiska un sabiedriski atbildƒ´ga, bet arƒ´ var sniegt b≈´tiskas priek≈°rocƒ´bas uz≈Üƒìmumam. ≈†eit ir da≈æas metodes, kƒÅ to var panƒÅkt: 1. **Daudzveidƒ´ga darbaspƒìka pie≈Üem≈°ana darbƒÅ**: Atvalstot daudzveidƒ´bu un iekƒºau≈°anu personƒÅla atlasƒì, uz≈Üƒìmumi var g≈´t labumu no pla≈°ƒÅka talantu loka. (‚Ä¶)</span></p>
<ol class="ltx_enumerate" id="Ax5.I3.i3.I1">
<li class="ltx_item" id="Ax5.I3.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span>
<div class="ltx_para" id="Ax5.I3.i3.I1.i1.p1">
<p class="ltx_p" id="Ax5.I3.i3.I1.i1.p1.1">Translated to English via Google Translate: <span class="ltx_text ltx_font_italic" id="Ax5.I3.i3.I1.i1.p1.1.1">Exploiting the potential of marginalized groups in the business environment is not only ethical and socially responsible, but can also bring significant benefits to the company. Here are some methods to achieve this: 1. **Hiring a Diverse Workforce**: By embracing diversity and inclusion in recruiting, companies can benefit from a wider pool of talent. (‚Ä¶)</span></p>
</div>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="Ax5.p3">
<p class="ltx_p" id="Ax5.p3.1">None of the response versions (original is Latvian and translated to English) is harmful.</p>
</div>
</section>
<section class="ltx_appendix" id="Ax6">
<h2 class="ltx_title ltx_title_appendix">Appendix F: Regression Results</h2>
<figure class="ltx_table" id="Ax6.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>OLS regression results: relationship between the dependent variable (harmful accepted proportion or harmless rejected proportion) and CommonCrawl corpus share (see appendix 3). observations on 24 EU official languages included in all cases. Holm-Bonferroni adjusted p-values in brackets. Adjusted significance levels: *, **, *** represent 5%, 1%, and 0.1%, respectively.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="Ax6.T5.1">
<tr class="ltx_tr" id="Ax6.T5.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="Ax6.T5.1.1.1" rowspan="2"><span class="ltx_text" id="Ax6.T5.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="Ax6.T5.1.1.2">Harmful Accepted Proportion</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="Ax6.T5.1.1.3">Harmless Rejected Proportion</td>
</tr>
<tr class="ltx_tr" id="Ax6.T5.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.2.1">Intercept</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.2.2">Slope</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.2.3">p-value (HB adj.)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.2.4">Intercept</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.2.5">Slope</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.2.6">p-value (HB adj.)</td>
</tr>
<tr class="ltx_tr" id="Ax6.T5.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax6.T5.1.3.1">Claude 3.5 Sonnet</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.3.2">1.01</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.3.3">-0.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.3.4">0.353 (0.747)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.3.5">70.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.3.6">-0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ax6.T5.1.3.7">0.695 (1.000)</td>
</tr>
<tr class="ltx_tr" id="Ax6.T5.1.4">
<td class="ltx_td ltx_align_left" id="Ax6.T5.1.4.1">Gemini 1.5</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.4.2">1.32</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.4.3">-0.15</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.4.4">0.355 (0.747)</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.4.5">88.72</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.4.6">0.22</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.4.7">0.586 (1.000)</td>
</tr>
<tr class="ltx_tr" id="Ax6.T5.1.5">
<td class="ltx_td ltx_align_left" id="Ax6.T5.1.5.1">GPT-4o</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.5.2">6.44</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.5.3">-1.05**</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.5.4">0.002 (0.008)</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.5.5">37.40</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.5.6">0.71</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.5.7">0.112 (0.448)</td>
</tr>
<tr class="ltx_tr" id="Ax6.T5.1.6">
<td class="ltx_td ltx_align_left" id="Ax6.T5.1.6.1">Meta Llama 405B</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.6.2">4.47</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.6.3">0.23</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.6.4">0.249 (0.747)</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.6.5">55.18</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.6.6">0.76</td>
<td class="ltx_td ltx_align_center" id="Ax6.T5.1.6.7">0.488 (1.000)</td>
</tr>
<tr class="ltx_tr" id="Ax6.T5.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ax6.T5.1.7.1">Mistral Large 2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax6.T5.1.7.2">7.68</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax6.T5.1.7.3">-1.59***</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax6.T5.1.7.4">0.000 (0.000)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax6.T5.1.7.5">38.77</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax6.T5.1.7.6">-1.04</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ax6.T5.1.7.7">0.047 (0.235)</td>
</tr>
</table>
</figure>
<div class="ltx_para" id="Ax6.p1">
<p class="ltx_p" id="Ax6.p1.1">The results with OLS, including the coefficient significance levels, are similar to the results with logistic regression in <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.T1" title="Table 1 ‚Ä£ 4.2 Who benefits from multilingual AI in the EU, and how? ‚Ä£ 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI">Table 1</a> in <a class="ltx_ref" href="https://arxiv.org/html/2409.13708v1#S4.SS4" title="4.4 Regression results ‚Ä£ 4 Case Study: The EU and its 24 official languages ‚Ä£ Towards Safe Multilingual Frontier AI">Section 4.4</a>. These similarities can be also observed in the following Figure 2 to Figure 11.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_figure" id="Ax6.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F2.g1" src="extracted/5832498/Harmful_Claude.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Claude 3.5 Sonnet, Harmful Accepted Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F3.g1" src="extracted/5832498/Harmless_Claude.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Claude 3.5 Sonnet, Harmless Rejected Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F4.g1" src="extracted/5832498/Harmful_Gemini.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Gemini 1.5 Pro, Harmful Accepted Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F5.g1" src="extracted/5832498/Harmless_Gemini.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Gemini 1.5 Pro, Harmless Rejected Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F6.g1" src="extracted/5832498/Harmful_GPT.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>GPT-4o, Harmful Accepted Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F7.g1" src="extracted/5832498/Harmless_GPT.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>GPT-4o, Harmless Rejected Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F8.g1" src="extracted/5832498/Harmful_Llama.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Llama 3.1 405B, Harmful Accepted Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F9.g1" src="extracted/5832498/Harmless_Llama.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Llama 3.1 405B, Harmless Rejected Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F10.g1" src="extracted/5832498/Harmful_Mistral.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Mistral Large 2, Harmful Accepted Proportion (100 observations per language)</figcaption>
</figure>
<figure class="ltx_figure" id="Ax6.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="Ax6.F11.g1" src="extracted/5832498/Harmless_Mistral.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Mistral Large 2, Harmless Rejected Proportion (100 observations per language)</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep  6 14:24:05 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
