<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2207.08869] FLAIR: Federated Learning Annotated Image Repository</title><meta property="og:description" content="Cross-device federated learning is an emerging machine learning (ML) paradigm where a large population of devices collectively train an ML model while the data remains on the devices.
This research field has a unique s…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FLAIR: Federated Learning Annotated Image Repository">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FLAIR: Federated Learning Annotated Image Repository">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2207.08869">

<!--Generated on Wed Mar 13 14:47:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FLAIR: Federated Learning Annotated Image Repository</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Congzheng Song 
<br class="ltx_break">Apple
<br class="ltx_break"><span id="id2.2.id1" class="ltx_text ltx_font_typewriter">csong4@apple.com</span>
&amp;Filip Granqvist<sup id="id3.3.id2" class="ltx_sup">∗</sup> 
<br class="ltx_break">Apple 
<br class="ltx_break"><span id="id4.4.id3" class="ltx_text ltx_font_typewriter">fgranqvist@apple.com</span>
&amp;Kunal Talwar 
<br class="ltx_break">Apple
<br class="ltx_break"><span id="id5.5.id4" class="ltx_text ltx_font_typewriter">ktalwar@apple.com</span>
</span><span class="ltx_author_notes">Equal contribution</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Cross-device federated learning is an emerging machine learning (ML) paradigm where a large population of devices collectively train an ML model while the data remains on the devices.
This research field has a unique set of practical challenges, and to systematically make advances, new datasets curated to be compatible with this paradigm are needed.
Existing federated learning benchmarks in the image domain do not accurately capture the scale and heterogeneity of many real-world use cases.
We introduce FLAIR, a challenging large-scale annotated image dataset for multi-label classification suitable for federated learning.
FLAIR has 429,078 images from 51,414 Flickr users and captures many of the intricacies typically encountered in federated learning, such as heterogeneous user data and a long-tailed label distribution.
We implement multiple baselines in different learning setups for different tasks on this dataset.
We believe FLAIR can serve as a challenging benchmark for advancing the state-of-the art in federated learning.
Dataset access and the code for the benchmark are available at <a target="_blank" href="https://github.com/apple/ml-flair" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/apple/ml-flair</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Remote devices connected to the internet, such as mobile phones, can capture data about their environment. Machine learning algorithms trained on such data can help improve user experience on these devices. However, it is often infeasible to upload this data to servers because of privacy, bandwidth, or other concerns.
</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Federated learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> has been proposed as an approach to collaboratively train a machine learning model with coordination by a central server while keeping all the training data on device. Coupled with differential privacy, it can allow learning of a model with strong privacy guarantees. Models trained via private federated learning have successfully improved existing on-device applications while preserving users’ privacy <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">This has led to a lot of ongoing research on designing better algorithms for federated learning applications. Centralized (non-federated) machine learning has benefited tremendously from standardized datasets and benchmarks, such as Imagenet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. To evaluate and accelerate progress in (private) federated learning research, the community needs similarly high quality large-scale datasets, with benchmarks. Ideally, the dataset would be representative of the challenges identified as important by the community <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Additionally, the benchmark should provide common, agreed-upon metrics to allow comparison of privacy, utility, and efficiency of various approaches.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">Federated data may have various non-IID characteristics that are seldom encountered in traditional ML <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
These include shifts in feature and label distribution, imbalanced user dataset sizes, drift in feature distribution conditioned on the labels and shift in the labeling function itself. This is caused by the independent and diverse user-specific contexts that predicate the data generation process.
For example, the style and content of a written message may differ depending on the author’s age, culture, and geographical location. Indeed such heterogeneity can be seen in text datasets commonly used as benchmarks (see Section <a href="#S2" title="2 Related Work ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">However the image domain suffers from a limited selection of large-scale datasets with realistic user partitions to benchmark algorithms and models (see Section <a href="#S2" title="2 Related Work ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
When new hypotheses are tested, researchers typically use centrally available data to simulate the federated setting.
For example, many works are evaluated by repurposing traditional benchmarks, such as MNIST <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and CIFAR10 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, by creating artificial user partitions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
It is unclear if such artificial partitions are realistic enough to give confidence that hypotheses evaluated on these will transfer to federated learning in a real-world scenario.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S1.F1.pic1" class="ltx_picture ltx_centering ltx_figure_panel" height="667.48" overflow="visible" version="1.1" width="609.9"><g transform="translate(0,667.48) matrix(1 0 0 -1 0 0) translate(4.95,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.97 L 0 665.51 C 0 666.6 0.88 667.48 1.97 667.48 L 598.03 667.48 C 599.12 667.48 600 666.6 600 665.51 L 600 1.97 C 600 0.88 599.12 0 598.03 0 L 1.97 0 C 0.88 0 0 0.88 0 1.97 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 653.93 L 598.03 653.93 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 655.9)"><foreignObject width="609.9" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S1.F1.pic1.8.8.8.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic1.8.8.8.1.1.1" class="ltx_p">Flickr user 9334511@N06</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 3.35)"><foreignObject width="609.9" height="649.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S1.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_figure"><img src="/html/2207.08869/assets/assets/user1/15264759153.jpeg" id="S1.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">jack russell 
<br class="ltx_break">terrier,
<br class="ltx_break">land</span>
</span>
<span id="S1.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user1/16166156963.jpeg" id="S1.F1.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">dog,
<br class="ltx_break">material,
<br class="ltx_break">structure</span>
</span>
<span id="S1.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user1/16803949745.jpeg" id="S1.F1.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">dog,
<br class="ltx_break">interior room,
<br class="ltx_break">structure</span>
</span>
<span id="S1.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user1/15356403858.jpeg" id="S1.F1.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">raw metal,
<br class="ltx_break">spider,
<br class="ltx_break">spiderweb</span>
</span>
<span id="S1.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user1/15021617924.jpeg" id="S1.F1.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">clothing,
<br class="ltx_break">pillar,
<br class="ltx_break">rocks,
<br class="ltx_break">terrier</span>
</span>
<span id="S1.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user1/15960058775.jpeg" id="S1.F1.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">cage,
<br class="ltx_break">dachshund,
<br class="ltx_break">document,
<br class="ltx_break">door</span>
</span>
<span id="S1.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user1/15708324371.jpeg" id="S1.F1.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">equipment,
<br class="ltx_break">interior room,
<br class="ltx_break">material,
<br class="ltx_break">terrier</span>
</span></span></foreignObject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S1.F1.pic2" class="ltx_picture ltx_centering ltx_figure_panel" height="667.48" overflow="visible" version="1.1" width="609.9"><g transform="translate(0,667.48) matrix(1 0 0 -1 0 0) translate(4.95,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.97 L 0 665.51 C 0 666.6 0.88 667.48 1.97 667.48 L 598.03 667.48 C 599.12 667.48 600 666.6 600 665.51 L 600 1.97 C 600 0.88 599.12 0 598.03 0 L 1.97 0 C 0.88 0 0 0.88 0 1.97 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 653.93 L 598.03 653.93 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 655.9)"><foreignObject width="609.9" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S1.F1.pic2.8.8.8.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic2.8.8.8.1.1.1" class="ltx_p">Flickr user 129851880@N07</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 3.35)"><foreignObject width="609.9" height="649.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S1.F1.pic2.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_figure"><img src="/html/2207.08869/assets/assets/user5/22761096918.jpeg" id="S1.F1.pic2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">food,
<br class="ltx_break">logo other,
<br class="ltx_break">soup,
<br class="ltx_break">spoon</span>
</span>
<span id="S1.F1.pic2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user5/27942033974.jpeg" id="S1.F1.pic2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">baked goods,
<br class="ltx_break">fork</span>
</span>
<span id="S1.F1.pic2.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user5/29387913900.jpeg" id="S1.F1.pic2.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">bowl,
<br class="ltx_break">food,
<br class="ltx_break">meat,
<br class="ltx_break">soup</span>
</span>
<span id="S1.F1.pic2.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user5/21678881101.jpeg" id="S1.F1.pic2.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">bowl,
<br class="ltx_break">cup,
<br class="ltx_break">ladle,
<br class="ltx_break">material</span>
</span>
<span id="S1.F1.pic2.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user5/27795027774.jpeg" id="S1.F1.pic2.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">drink,
<br class="ltx_break">glass,
<br class="ltx_break">lime,
<br class="ltx_break">material</span>
</span>
<span id="S1.F1.pic2.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user5/26641744630.jpeg" id="S1.F1.pic2.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">container,
<br class="ltx_break">ice cream,
<br class="ltx_break">spoon</span>
</span>
<span id="S1.F1.pic2.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user5/26427203523.jpeg" id="S1.F1.pic2.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">food,
<br class="ltx_break">meat,
<br class="ltx_break">rice</span>
</span></span></foreignObject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S1.F1.pic3" class="ltx_picture ltx_centering ltx_figure_panel" height="667.48" overflow="visible" version="1.1" width="609.9"><g transform="translate(0,667.48) matrix(1 0 0 -1 0 0) translate(4.95,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.97 L 0 665.51 C 0 666.6 0.88 667.48 1.97 667.48 L 598.03 667.48 C 599.12 667.48 600 666.6 600 665.51 L 600 1.97 C 600 0.88 599.12 0 598.03 0 L 1.97 0 C 0.88 0 0 0.88 0 1.97 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 653.93 L 598.03 653.93 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 655.9)"><foreignObject width="609.9" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S1.F1.pic3.8.8.8.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic3.8.8.8.1.1.1" class="ltx_p">Flickr user 29694550@N06</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 3.35)"><foreignObject width="609.9" height="649.2" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S1.F1.pic3.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_figure"><img src="/html/2207.08869/assets/assets/user4/2612354594.jpeg" id="S1.F1.pic3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">bicycle,
<br class="ltx_break">book,
<br class="ltx_break">laptop,
<br class="ltx_break">printed page</span>
</span>
<span id="S1.F1.pic3.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user4/15128527383.jpeg" id="S1.F1.pic3.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">electronics,
<br class="ltx_break">gamepad,
<br class="ltx_break">joystick,
<br class="ltx_break">wire</span>
</span>
<span id="S1.F1.pic3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user4/16849079920.jpeg" id="S1.F1.pic3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">arch,
<br class="ltx_break">cave,
<br class="ltx_break">waterways</span>
</span>
<span id="S1.F1.pic3.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user4/3211312112.jpeg" id="S1.F1.pic3.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">herb other,
<br class="ltx_break">material,
<br class="ltx_break">seafood,
<br class="ltx_break">tableware</span>
</span>
<span id="S1.F1.pic3.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user4/5885925046.jpeg" id="S1.F1.pic3.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">document,
<br class="ltx_break">raw glass,
<br class="ltx_break">structure,
<br class="ltx_break">textile</span>
</span>
<span id="S1.F1.pic3.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user4/4395089570.jpeg" id="S1.F1.pic3.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">baked goods,
<br class="ltx_break">plate,
<br class="ltx_break">rice</span>
</span>
<span id="S1.F1.pic3.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user4/5748140693.jpeg" id="S1.F1.pic3.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">baked goods,
<br class="ltx_break">calzone,
<br class="ltx_break">container,
<br class="ltx_break">drink</span>
</span></span></foreignObject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S1.F1.pic4" class="ltx_picture ltx_centering ltx_figure_panel" height="684.08" overflow="visible" version="1.1" width="609.9"><g transform="translate(0,684.08) matrix(1 0 0 -1 0 0) translate(4.95,0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 1.97 L 0 682.11 C 0 683.2 0.88 684.08 1.97 684.08 L 598.03 684.08 C 599.12 684.08 600 683.2 600 682.11 L 600 1.97 C 600 0.88 599.12 0 598.03 0 L 1.97 0 C 0.88 0 0 0.88 0 1.97 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 670.54 L 598.03 670.54 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 672.51)"><foreignObject width="609.9" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S1.F1.pic4.8.8.8.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic4.8.8.8.1.1.1" class="ltx_p">Flickr user 40164909@N00</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 -4.95 3.35)"><foreignObject width="609.9" height="665.8" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S1.F1.pic4.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" style="width:440.8pt;">
<span id="S1.F1.pic4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_figure"><img src="/html/2207.08869/assets/assets/user3/16894740550.jpeg" id="S1.F1.pic4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">bag,
<br class="ltx_break">container,
<br class="ltx_break">document,
<br class="ltx_break">material</span>
</span>
<span id="S1.F1.pic4.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user3/26528212593.jpeg" id="S1.F1.pic4.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">basket,
<br class="ltx_break">bottle,
<br class="ltx_break">document,
<br class="ltx_break">jar</span>
</span>
<span id="S1.F1.pic4.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user3/17248988951.jpeg" id="S1.F1.pic4.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">cord,
<br class="ltx_break">equipment,
<br class="ltx_break">logo,
<br class="ltx_break">material</span>
</span>
<span id="S1.F1.pic4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user3/33798583922.jpeg" id="S1.F1.pic4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">cardboard,
<br class="ltx_break">container,
<br class="ltx_break">logo,
<br class="ltx_break">material</span>
</span>
<span id="S1.F1.pic4.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user3/25792715516.jpeg" id="S1.F1.pic4.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">bag,
<br class="ltx_break">carton,
<br class="ltx_break">container,
<br class="ltx_break">document</span>
</span>
<span id="S1.F1.pic4.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user3/8519276294.jpeg" id="S1.F1.pic4.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">bag,
<br class="ltx_break">container,
<br class="ltx_break">interior shop,
<br class="ltx_break">raw glass</span>
</span>
<span id="S1.F1.pic4.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7" class="ltx_figure ltx_align_center"><img src="/html/2207.08869/assets/assets/user3/17249440365.jpeg" id="S1.F1.pic4.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
<span class="ltx_caption">container,
<br class="ltx_break">hose,
<br class="ltx_break">logo,
<br class="ltx_break">pulley</span>
</span></span></foreignObject></g></g></svg></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>FLAIR sample images and labels. Images in the same row are from the same Flickr user. Captions below each image are the annotated fine-grained labels.</figcaption>
</figure>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p">We introduce FLAIR, a large-scale multi-label image classification dataset, for benchmarking federated learning algorithms and models. The datast has a total of 429,078 images originating from Flickr <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and partitioned by 51,414 real user IDs. The images are annotated with labels from a two-level hierarchy, allowing us to define benchmarks with two levels of difficulty: the easier task has <math id="S1.p6.1.m1.1" class="ltx_Math" alttext="17" display="inline"><semantics id="S1.p6.1.m1.1a"><mn id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml">17</mn><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><cn type="integer" id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1">17</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">17</annotation></semantics></math> coarse-grained classes and the harder task has 1,628 fine-grained classes.
FLAIR also inherits many of the aforementioned non-IID characteristics:</p>
</div>
<div id="S1.p7" class="ltx_para ltx_noindent">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Imbalanced partitions — Users have different number of images. The majority of users have only 1-10 images, but the most active users have hundreds of images.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Feature distribution skew — Users have different cameras, camera settings, which affect pixel generation.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Label distribution skew — Users take photos of objects that align with their interests, which vary across photographers.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Conditional feature distribution skew — Photos of the same category of objects can look very different due to weather conditions, cultural and geographical differences.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i5.p1.1" class="ltx_p">Label shifts — There are no significant discrepancies in how the labels are used. However, the label generating process consisted of multiple human annotators, which may result in slight differences in how labeling decisions were made.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p8" class="ltx_para ltx_noindent">
<p id="S1.p8.1" class="ltx_p">We provide benchmarks and analyze the performance of different settings of interest for FLAIR: centralized learning; federated learning; federated learning with central differential privacy; using random initialization of model parameters; and using model parameters pretrained on ImageNet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Previous work has mainly used two methods for preparing federated datasets: artificial partitioning of existing open-source datasets not originally purposed for federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, and
constructing realistic partitions using real user identifiers preserved from the data generation process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.
The former approach requires fewer resources but more assumptions, and has been used with MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, CIFAR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, and CelebA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> datasets.
These experimental setups rely on artificially inducing some of the characteristics of real federated datasets during the sampling process.
Pachinko allocation based sampling method was proposed to generate more realistic heterogeneous partitions, but it requires a hierarchy of coarse labels such as present in CIFAR100 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.
Yet, there is no clear way for measuring how realistic the splits are.
In fact, federated data partitions in the wild are usually more heavy tailed than the artificial partitions previous work has used (see Section <a href="#S4.SS2" title="4.2 FLAIR dataset statistics ‣ 4 FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>).</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.2" class="ltx_p">The latter approach relies on datasets generated from a collection of users, with the user identifiers preserved.
Previous works have extensively used text datasets that have this property: Sentiment140 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, Shakespeare <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, Reddit<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and StackOverflow <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Realistic image datasets commonly used in the federated learning community are EMNIST <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, iNaturalist-User-120k and Landmarks-User-160k <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The landmarks dataset is the largest of them, with <math id="S2.p2.1.m1.2" class="ltx_Math" alttext="164,172" display="inline"><semantics id="S2.p2.1.m1.2a"><mrow id="S2.p2.1.m1.2.3.2" xref="S2.p2.1.m1.2.3.1.cmml"><mn id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">164</mn><mo id="S2.p2.1.m1.2.3.2.1" xref="S2.p2.1.m1.2.3.1.cmml">,</mo><mn id="S2.p2.1.m1.2.2" xref="S2.p2.1.m1.2.2.cmml">172</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.2b"><list id="S2.p2.1.m1.2.3.1.cmml" xref="S2.p2.1.m1.2.3.2"><cn type="integer" id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">164</cn><cn type="integer" id="S2.p2.1.m1.2.2.cmml" xref="S2.p2.1.m1.2.2">172</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.2c">164,172</annotation></semantics></math> images, but has only <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="1262" display="inline"><semantics id="S2.p2.2.m2.1a"><mn id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">1262</mn><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><cn type="integer" id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">1262</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">1262</annotation></semantics></math> users, making it ill-suited for large-scale federated learning, especially for private federated learning where large batch sizes are typically needed.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">Meta-learning is a ML paradigm closely related to federated learning, hence requiring similar kinds of datasets. Popular image datasets for meta-learning include Mini-Imagenet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, CUB-200-2011 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> and Omniglot <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
These datasets are relatively small and low-resolution, with either artificial task partitioning or easy tasks, e.g. the original model-agnostic meta-learning algorithm already achieves <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="99.9\%" display="inline"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mn id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">99.9</mn><mo id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><csymbol cd="latexml" id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2">99.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">99.9\%</annotation></semantics></math> accuracy with 5-way 5-shot classification on Omniglot <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">Testing a hypothesis with a standardized benchmark agreed upon by the research community is essential for systematically making progress in the field of machine learning.
There are several benchmark suites that attempt to do this for federated learning: LEAF <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, FedML <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, OARF <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and FedScale <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
FedScale proposes a benchmark for image classification on Flickr images, which is similar to FLAIR.
This however is a multiclass dataset, where image-label pairs are constructed by cropping single objects from bounding box annotations; this results in many duplicate images with different labels because the bounding boxes commonly overlap.
As explored more thoroughly in Section <a href="#S4.F2" title="Figure 2 ‣ 4.2 FLAIR dataset statistics ‣ 4 FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, FLAIR also has a more diverse set of classes and includes two levels of difficulty.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Preliminaries</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text ltx_font_bold">Federated learning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> enables training on users’ data without collecting or storing the data on a centralized server.
In each round of federated learning, the server samples a cohort of users and sends the current model to the sampled users’ devices.
The sampled users train the model locally with SGD and share the gradient updates back to the server after local training.
The server updates the global model, treating the aggregate of the per-user updates in lieu of a gradient estimate in an optimization algorithm such as SGD or Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Differential Privacy.</span>
Even though user data is not shared with the server in the federated setting, the shared gradient updates can still reveal sensitive information about user data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Differential privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> can be used to provide a formal privacy guarantee to prevent such data leakage in the federated setting.</p>
</div>
<div id="Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition 1</span></span><span id="Thmdefinition1.2.2" class="ltx_text ltx_font_bold"> (Differential privacy)</span>
</h6>
<div id="Thmdefinition1.p1" class="ltx_para">
<p id="Thmdefinition1.p1.7" class="ltx_p"><span id="Thmdefinition1.p1.7.7" class="ltx_text ltx_font_italic">A randomized mechanism <math id="Thmdefinition1.p1.1.1.m1.1" class="ltx_Math" alttext="{\mathcal{M}}:{\mathcal{D}}\mapsto{\mathcal{R}}" display="inline"><semantics id="Thmdefinition1.p1.1.1.m1.1a"><mrow id="Thmdefinition1.p1.1.1.m1.1.1" xref="Thmdefinition1.p1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.1.1.m1.1.1.2" xref="Thmdefinition1.p1.1.1.m1.1.1.2.cmml">ℳ</mi><mo lspace="0.278em" rspace="0.278em" id="Thmdefinition1.p1.1.1.m1.1.1.1" xref="Thmdefinition1.p1.1.1.m1.1.1.1.cmml">:</mo><mrow id="Thmdefinition1.p1.1.1.m1.1.1.3" xref="Thmdefinition1.p1.1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.1.1.m1.1.1.3.2" xref="Thmdefinition1.p1.1.1.m1.1.1.3.2.cmml">𝒟</mi><mo stretchy="false" id="Thmdefinition1.p1.1.1.m1.1.1.3.1" xref="Thmdefinition1.p1.1.1.m1.1.1.3.1.cmml">↦</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.1.1.m1.1.1.3.3" xref="Thmdefinition1.p1.1.1.m1.1.1.3.3.cmml">ℛ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.1.1.m1.1b"><apply id="Thmdefinition1.p1.1.1.m1.1.1.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1"><ci id="Thmdefinition1.p1.1.1.m1.1.1.1.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1.1">:</ci><ci id="Thmdefinition1.p1.1.1.m1.1.1.2.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1.2">ℳ</ci><apply id="Thmdefinition1.p1.1.1.m1.1.1.3.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1.3"><csymbol cd="latexml" id="Thmdefinition1.p1.1.1.m1.1.1.3.1.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1.3.1">maps-to</csymbol><ci id="Thmdefinition1.p1.1.1.m1.1.1.3.2.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1.3.2">𝒟</ci><ci id="Thmdefinition1.p1.1.1.m1.1.1.3.3.cmml" xref="Thmdefinition1.p1.1.1.m1.1.1.3.3">ℛ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.1.1.m1.1c">{\mathcal{M}}:{\mathcal{D}}\mapsto{\mathcal{R}}</annotation></semantics></math> with a domain <math id="Thmdefinition1.p1.2.2.m2.1" class="ltx_Math" alttext="{\mathcal{D}}" display="inline"><semantics id="Thmdefinition1.p1.2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.2.2.m2.1.1" xref="Thmdefinition1.p1.2.2.m2.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.2.2.m2.1b"><ci id="Thmdefinition1.p1.2.2.m2.1.1.cmml" xref="Thmdefinition1.p1.2.2.m2.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.2.2.m2.1c">{\mathcal{D}}</annotation></semantics></math> and range <math id="Thmdefinition1.p1.3.3.m3.1" class="ltx_Math" alttext="{\mathcal{R}}" display="inline"><semantics id="Thmdefinition1.p1.3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.3.3.m3.1.1" xref="Thmdefinition1.p1.3.3.m3.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.3.3.m3.1b"><ci id="Thmdefinition1.p1.3.3.m3.1.1.cmml" xref="Thmdefinition1.p1.3.3.m3.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.3.3.m3.1c">{\mathcal{R}}</annotation></semantics></math> satisfies <math id="Thmdefinition1.p1.4.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="Thmdefinition1.p1.4.4.m4.2a"><mrow id="Thmdefinition1.p1.4.4.m4.2.3.2" xref="Thmdefinition1.p1.4.4.m4.2.3.1.cmml"><mo stretchy="false" id="Thmdefinition1.p1.4.4.m4.2.3.2.1" xref="Thmdefinition1.p1.4.4.m4.2.3.1.cmml">(</mo><mi id="Thmdefinition1.p1.4.4.m4.1.1" xref="Thmdefinition1.p1.4.4.m4.1.1.cmml">ϵ</mi><mo id="Thmdefinition1.p1.4.4.m4.2.3.2.2" xref="Thmdefinition1.p1.4.4.m4.2.3.1.cmml">,</mo><mi id="Thmdefinition1.p1.4.4.m4.2.2" xref="Thmdefinition1.p1.4.4.m4.2.2.cmml">δ</mi><mo stretchy="false" id="Thmdefinition1.p1.4.4.m4.2.3.2.3" xref="Thmdefinition1.p1.4.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.4.4.m4.2b"><interval closure="open" id="Thmdefinition1.p1.4.4.m4.2.3.1.cmml" xref="Thmdefinition1.p1.4.4.m4.2.3.2"><ci id="Thmdefinition1.p1.4.4.m4.1.1.cmml" xref="Thmdefinition1.p1.4.4.m4.1.1">italic-ϵ</ci><ci id="Thmdefinition1.p1.4.4.m4.2.2.cmml" xref="Thmdefinition1.p1.4.4.m4.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.4.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-differential privacy if for any two adjacent datasets <math id="Thmdefinition1.p1.5.5.m5.2" class="ltx_Math" alttext="d,d^{\prime}\in{\mathcal{D}}" display="inline"><semantics id="Thmdefinition1.p1.5.5.m5.2a"><mrow id="Thmdefinition1.p1.5.5.m5.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.cmml"><mrow id="Thmdefinition1.p1.5.5.m5.2.2.1.1" xref="Thmdefinition1.p1.5.5.m5.2.2.1.2.cmml"><mi id="Thmdefinition1.p1.5.5.m5.1.1" xref="Thmdefinition1.p1.5.5.m5.1.1.cmml">d</mi><mo id="Thmdefinition1.p1.5.5.m5.2.2.1.1.2" xref="Thmdefinition1.p1.5.5.m5.2.2.1.2.cmml">,</mo><msup id="Thmdefinition1.p1.5.5.m5.2.2.1.1.1" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.cmml"><mi id="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.2" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.2.cmml">d</mi><mo id="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.3" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.3.cmml">′</mo></msup></mrow><mo id="Thmdefinition1.p1.5.5.m5.2.2.2" xref="Thmdefinition1.p1.5.5.m5.2.2.2.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.5.5.m5.2.2.3" xref="Thmdefinition1.p1.5.5.m5.2.2.3.cmml">𝒟</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.5.5.m5.2b"><apply id="Thmdefinition1.p1.5.5.m5.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2"><in id="Thmdefinition1.p1.5.5.m5.2.2.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.2"></in><list id="Thmdefinition1.p1.5.5.m5.2.2.1.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1"><ci id="Thmdefinition1.p1.5.5.m5.1.1.cmml" xref="Thmdefinition1.p1.5.5.m5.1.1">𝑑</ci><apply id="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.1.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1.1">superscript</csymbol><ci id="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.2.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.2">𝑑</ci><ci id="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.3.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.1.1.1.3">′</ci></apply></list><ci id="Thmdefinition1.p1.5.5.m5.2.2.3.cmml" xref="Thmdefinition1.p1.5.5.m5.2.2.3">𝒟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.5.5.m5.2c">d,d^{\prime}\in{\mathcal{D}}</annotation></semantics></math> and for any subset of outputs <math id="Thmdefinition1.p1.6.6.m6.1" class="ltx_Math" alttext="S\subseteq{\mathcal{R}}" display="inline"><semantics id="Thmdefinition1.p1.6.6.m6.1a"><mrow id="Thmdefinition1.p1.6.6.m6.1.1" xref="Thmdefinition1.p1.6.6.m6.1.1.cmml"><mi id="Thmdefinition1.p1.6.6.m6.1.1.2" xref="Thmdefinition1.p1.6.6.m6.1.1.2.cmml">S</mi><mo id="Thmdefinition1.p1.6.6.m6.1.1.1" xref="Thmdefinition1.p1.6.6.m6.1.1.1.cmml">⊆</mo><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.6.6.m6.1.1.3" xref="Thmdefinition1.p1.6.6.m6.1.1.3.cmml">ℛ</mi></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.6.6.m6.1b"><apply id="Thmdefinition1.p1.6.6.m6.1.1.cmml" xref="Thmdefinition1.p1.6.6.m6.1.1"><subset id="Thmdefinition1.p1.6.6.m6.1.1.1.cmml" xref="Thmdefinition1.p1.6.6.m6.1.1.1"></subset><ci id="Thmdefinition1.p1.6.6.m6.1.1.2.cmml" xref="Thmdefinition1.p1.6.6.m6.1.1.2">𝑆</ci><ci id="Thmdefinition1.p1.6.6.m6.1.1.3.cmml" xref="Thmdefinition1.p1.6.6.m6.1.1.3">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.6.6.m6.1c">S\subseteq{\mathcal{R}}</annotation></semantics></math> it holds that <math id="Thmdefinition1.p1.7.7.m7.3" class="ltx_Math" alttext="\mathrm{Pr}[M(d)\in S]\leq e^{\epsilon}\mathrm{Pr}[{\mathcal{M}}(d^{\prime})\in S]+\delta" display="inline"><semantics id="Thmdefinition1.p1.7.7.m7.3a"><mrow id="Thmdefinition1.p1.7.7.m7.3.3" xref="Thmdefinition1.p1.7.7.m7.3.3.cmml"><mrow id="Thmdefinition1.p1.7.7.m7.2.2.1" xref="Thmdefinition1.p1.7.7.m7.2.2.1.cmml"><mi id="Thmdefinition1.p1.7.7.m7.2.2.1.3" xref="Thmdefinition1.p1.7.7.m7.2.2.1.3.cmml">Pr</mi><mo lspace="0em" rspace="0em" id="Thmdefinition1.p1.7.7.m7.2.2.1.2" xref="Thmdefinition1.p1.7.7.m7.2.2.1.2.cmml">​</mo><mrow id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.2.cmml"><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.2" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.2.1.cmml">[</mo><mrow id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.cmml"><mrow id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.cmml"><mi id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.2" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.1" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.1.cmml">​</mo><mrow id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.3.2" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.3.2.1" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.cmml">(</mo><mi id="Thmdefinition1.p1.7.7.m7.1.1" xref="Thmdefinition1.p1.7.7.m7.1.1.cmml">d</mi><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.3.2.2" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.1" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.1.cmml">∈</mo><mi id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.3" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.3" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="Thmdefinition1.p1.7.7.m7.3.3.3" xref="Thmdefinition1.p1.7.7.m7.3.3.3.cmml">≤</mo><mrow id="Thmdefinition1.p1.7.7.m7.3.3.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.cmml"><mrow id="Thmdefinition1.p1.7.7.m7.3.3.2.1" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.cmml"><msup id="Thmdefinition1.p1.7.7.m7.3.3.2.1.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.cmml"><mi id="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.2.cmml">e</mi><mi id="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.3.cmml">ϵ</mi></msup><mo lspace="0em" rspace="0em" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.2.cmml">​</mo><mi id="Thmdefinition1.p1.7.7.m7.3.3.2.1.4" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.4.cmml">Pr</mi><mo lspace="0em" rspace="0em" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.2a" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.2.cmml">​</mo><mrow id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.2.cmml"><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.2.1.cmml">[</mo><mrow id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.cmml"><mrow id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.2.cmml">​</mo><mrow id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.cmml"><mi id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.2.cmml">d</mi><mo id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.2.cmml">∈</mo><mi id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="Thmdefinition1.p1.7.7.m7.3.3.2.2" xref="Thmdefinition1.p1.7.7.m7.3.3.2.2.cmml">+</mo><mi id="Thmdefinition1.p1.7.7.m7.3.3.2.3" xref="Thmdefinition1.p1.7.7.m7.3.3.2.3.cmml">δ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="Thmdefinition1.p1.7.7.m7.3b"><apply id="Thmdefinition1.p1.7.7.m7.3.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3"><leq id="Thmdefinition1.p1.7.7.m7.3.3.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.3"></leq><apply id="Thmdefinition1.p1.7.7.m7.2.2.1.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1"><times id="Thmdefinition1.p1.7.7.m7.2.2.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.2"></times><ci id="Thmdefinition1.p1.7.7.m7.2.2.1.3.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.3">Pr</ci><apply id="Thmdefinition1.p1.7.7.m7.2.2.1.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1"><csymbol cd="latexml" id="Thmdefinition1.p1.7.7.m7.2.2.1.1.2.1.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.2">delimited-[]</csymbol><apply id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1"><in id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.1"></in><apply id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2"><times id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.1.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.1"></times><ci id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.2.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.2.2">𝑀</ci><ci id="Thmdefinition1.p1.7.7.m7.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.1.1">𝑑</ci></apply><ci id="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.3.cmml" xref="Thmdefinition1.p1.7.7.m7.2.2.1.1.1.1.3">𝑆</ci></apply></apply></apply><apply id="Thmdefinition1.p1.7.7.m7.3.3.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2"><plus id="Thmdefinition1.p1.7.7.m7.3.3.2.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.2"></plus><apply id="Thmdefinition1.p1.7.7.m7.3.3.2.1.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1"><times id="Thmdefinition1.p1.7.7.m7.3.3.2.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.2"></times><apply id="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.3"><csymbol cd="ambiguous" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.1.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.3">superscript</csymbol><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.2">𝑒</ci><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.3.3">italic-ϵ</ci></apply><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.1.4.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.4">Pr</ci><apply id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1"><csymbol cd="latexml" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.2.1.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.2">delimited-[]</csymbol><apply id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1"><in id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.2"></in><apply id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1"><times id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.2"></times><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.3">ℳ</ci><apply id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.1.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.2.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.2">𝑑</ci><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.1.1.1.1.3">𝑆</ci></apply></apply></apply><ci id="Thmdefinition1.p1.7.7.m7.3.3.2.3.cmml" xref="Thmdefinition1.p1.7.7.m7.3.3.2.3">𝛿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Thmdefinition1.p1.7.7.m7.3c">\mathrm{Pr}[M(d)\in S]\leq e^{\epsilon}\mathrm{Pr}[{\mathcal{M}}(d^{\prime})\in S]+\delta</annotation></semantics></math>.</span></p>
</div>
</div>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.5" class="ltx_p">In the context of DP federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="{\mathcal{D}}" display="inline"><semantics id="S3.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">{\mathcal{D}}</annotation></semantics></math> is the set of all possible datasets with examples associated with users, range <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="{\mathcal{R}}" display="inline"><semantics id="S3.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><ci id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">{\mathcal{R}}</annotation></semantics></math> is the set of all possible models, and two datasets <math id="S3.p3.3.m3.2" class="ltx_Math" alttext="d,d^{\prime}" display="inline"><semantics id="S3.p3.3.m3.2a"><mrow id="S3.p3.3.m3.2.2.1" xref="S3.p3.3.m3.2.2.2.cmml"><mi id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml">d</mi><mo id="S3.p3.3.m3.2.2.1.2" xref="S3.p3.3.m3.2.2.2.cmml">,</mo><msup id="S3.p3.3.m3.2.2.1.1" xref="S3.p3.3.m3.2.2.1.1.cmml"><mi id="S3.p3.3.m3.2.2.1.1.2" xref="S3.p3.3.m3.2.2.1.1.2.cmml">d</mi><mo id="S3.p3.3.m3.2.2.1.1.3" xref="S3.p3.3.m3.2.2.1.1.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.2b"><list id="S3.p3.3.m3.2.2.2.cmml" xref="S3.p3.3.m3.2.2.1"><ci id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1">𝑑</ci><apply id="S3.p3.3.m3.2.2.1.1.cmml" xref="S3.p3.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m3.2.2.1.1.1.cmml" xref="S3.p3.3.m3.2.2.1.1">superscript</csymbol><ci id="S3.p3.3.m3.2.2.1.1.2.cmml" xref="S3.p3.3.m3.2.2.1.1.2">𝑑</ci><ci id="S3.p3.3.m3.2.2.1.1.3.cmml" xref="S3.p3.3.m3.2.2.1.1.3">′</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.2c">d,d^{\prime}</annotation></semantics></math> are adjacent if <math id="S3.p3.4.m4.1" class="ltx_Math" alttext="d^{\prime}" display="inline"><semantics id="S3.p3.4.m4.1a"><msup id="S3.p3.4.m4.1.1" xref="S3.p3.4.m4.1.1.cmml"><mi id="S3.p3.4.m4.1.1.2" xref="S3.p3.4.m4.1.1.2.cmml">d</mi><mo id="S3.p3.4.m4.1.1.3" xref="S3.p3.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.1b"><apply id="S3.p3.4.m4.1.1.cmml" xref="S3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p3.4.m4.1.1.1.cmml" xref="S3.p3.4.m4.1.1">superscript</csymbol><ci id="S3.p3.4.m4.1.1.2.cmml" xref="S3.p3.4.m4.1.1.2">𝑑</ci><ci id="S3.p3.4.m4.1.1.3.cmml" xref="S3.p3.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m4.1c">d^{\prime}</annotation></semantics></math> can be formed by adding or removing all of the examples associated with a single user from <math id="S3.p3.5.m5.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.p3.5.m5.1a"><mi id="S3.p3.5.m5.1.1" xref="S3.p3.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.1b"><ci id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.5.m5.1c">d</annotation></semantics></math>.</p>
</div>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.1" class="ltx_p">When a federated learning model is trained with DP, the model distribution is close to what it would be if a particular user did not participate in the training. Following prior works in DP-SGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> in the federated learning context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>,
two modifications are made to the federated learning algorithm to provide a DP guarantee: 1) model updates from each user are clipped so that their <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S3.p4.1.m1.1a"><msub id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mi id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">L</mi><mn id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">L_{2}</annotation></semantics></math> norm is bounded, and 2) Gaussian noise is added to the aggregated model updates from all sampled users.
For the purpose of privacy accounting, we assume that each cohort is formed by sampling each user uniformly and independently, and that this sample is hidden from the adversary.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>FLAIR Dataset</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset collection</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">The initial set of images was curated with the Flickr API <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.flickr.com/services/api/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.flickr.com/services/api/</a></span></span></span>.
The corresponding Flickr user IDs were preserved so that the images were naturally grouped by users.
All curated images are publicly shared by the Flickr users and permissively licensed (detailed in Appendix <a href="#A1" title="Appendix A Datasheets for FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>).</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Filtering.</span>
We enforce strict filtering criteria to remove images that may contain personally identifiable information (PII).
We use a two stage filtering approach: 1) we apply a face detection model to automatically remove images with faces, and; 2) we rely on human annotators to filter the remaining images that contains PII.
Specifically, two annotators were assigned for filtering each image where the first annotator flags whether an image contains PII and the second annotator validates the results.
See Appendix <a href="#A1" title="Appendix A Datasheets for FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for detailed filtering guideline.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Annotation.</span>

The images from Flickr API were initially unlabeled.
We annotated the images with the main objects present in the images using a taxonomy of 1,628 fine-grained classes.
We also defined 17 coarse-grained classes in the taxonomy, where each fine-grained class is associated with a coarse-grained class.
Similar to filtering, two annotators were assigned for labeling and validating each image.
If there was an ambiguous object present in the image and the annotator could not tell which fine-grained label to assign, a coarse-grained label was added instead.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>FLAIR dataset statistics</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">After filtering and annotation, the finalized FLAIR dataset contain 429,078 images from 51,414 Flickr users, with 17 coarse-grained labels and 1,628 fine-grained labels.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">User data statistics.</span></p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2207.08869/assets/assets/dataset-stats/data-length.png" id="S4.F2.1.g1" class="ltx_graphics ltx_img_square" width="598" height="492" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2207.08869/assets/assets/dataset-stats/emd.png" id="S4.F2.2.g1" class="ltx_graphics ltx_img_square" width="598" height="488" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S4.F2.6.1" class="ltx_text ltx_font_bold">Left:</span> Cumulative dataset length of users in descending order of quantity, normalized by number of users on x-axis and number of datapoints on y-axis.
<span id="S4.F2.7.2" class="ltx_text ltx_font_bold">Right:</span> Earth mover’s distance (EMD) between users pixel histogram and the overall average pixel histogram from class <em id="S4.F2.8.3" class="ltx_emph ltx_font_italic">structure</em>. Blue line is from simulating user splits with equal dataset size, green line is simulating user splits by sampling from the real dataset size distribution, and purple line is the actual split.</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.2" class="ltx_p">The number of images per user is significantly skewed, where the largest <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="2.3\%" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mn id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">2.3</mn><mo id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">2.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">2.3\%</annotation></semantics></math> of users collectively have as many images as the bottom <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="97.7\%" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mn id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">97.7</mn><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">97.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">97.7\%</annotation></semantics></math> of users. The left of Figure <a href="#S4.F2" title="Figure 2 ‣ 4.2 FLAIR dataset statistics ‣ 4 FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> compares the quantity skew for FLAIR and other image classification benchmarks for federated learning.
In the case of CIFAR, there is a straight line because there is no skew.
The figure indicates that FLAIR has the second largest quantity skew, after iNaturalist-User-120k.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p">To visualize the feature distribution skew in FLAIR, we show in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.2 FLAIR dataset statistics ‣ 4 FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (right) the earthmover distance (EMD) between the average pixel histogram of a user’s images, to the population average pixel histogram. EMD is computed on the images from the most common label, <em id="S4.SS2.p4.1.1" class="ltx_emph ltx_font_italic">structure</em>, to remove any skew that the class imbalance might cause.
The quantity skew also causes feature distribution skew (comparing blue line to green line), and the real non-iid partitioning slightly increases the skew compared to the average simulated non-iid partitioning (comparing green line to purple line).</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">Label statistics.</span></p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2207.08869/assets/assets/dataset-stats/coarse-label-dist.png" id="S4.F3.1.g1" class="ltx_graphics ltx_img_square" width="598" height="543" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.2" class="ltx_figure ltx_figure_panel ltx_align_center">
<p id="S4.F3.2.1" class="ltx_p"><span id="S4.F3.2.1.1" class="ltx_text" style="position:relative; bottom:392.4pt;"><img src="/html/2207.08869/assets/assets/dataset-stats/fine-label-dist.png" id="S4.F3.2.1.1.g1" class="ltx_graphics ltx_img_square" width="598" height="496" alt="Refer to caption"></span></p>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>FLAIR label distribution for coarse-grained and fine-grained taxonomies. </figcaption>
</figure>
<div id="S4.SS2.p6" class="ltx_para ltx_noindent">
<p id="S4.SS2.p6.1" class="ltx_p">Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2 FLAIR dataset statistics ‣ 4 FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the total count of all labels across all users, revealing a significant class imbalance.
The most common coarse-grained class, <em id="S4.SS2.p6.1.1" class="ltx_emph ltx_font_italic">structure</em>, occurs 228,923 times on a total of 87% of users. The least common coarse-grained class, <em id="S4.SS2.p6.1.2" class="ltx_emph ltx_font_italic">religion</em>, occurs 866 times on a total of 1.4% of users.
The fine-grained labels similarly have a skewed distribution, with 1255 out of the 1628 classes being present on less than <math id="S4.SS2.p6.1.m1.1" class="ltx_Math" alttext="0.1\%" display="inline"><semantics id="S4.SS2.p6.1.m1.1a"><mrow id="S4.SS2.p6.1.m1.1.1" xref="S4.SS2.p6.1.m1.1.1.cmml"><mn id="S4.SS2.p6.1.m1.1.1.2" xref="S4.SS2.p6.1.m1.1.1.2.cmml">0.1</mn><mo id="S4.SS2.p6.1.m1.1.1.1" xref="S4.SS2.p6.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.1.m1.1b"><apply id="S4.SS2.p6.1.m1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p6.1.m1.1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p6.1.m1.1.1.2.cmml" xref="S4.SS2.p6.1.m1.1.1.2">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.1.m1.1c">0.1\%</annotation></semantics></math> of users.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para ltx_noindent">
<p id="S4.SS2.p7.3" class="ltx_p"><span id="S4.SS2.p7.3.1" class="ltx_text ltx_font_bold">Dataset split.</span>
For comparable and reproducible benchmarks on the FLAIR dataset, we provide a train-test split based on Flickr user IDs, such that the data of a particular user is only present in one of three partitions of the data.
Out of 51,414 Flickr users, <math id="S4.SS2.p7.1.m1.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="S4.SS2.p7.1.m1.1a"><mrow id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml"><mn id="S4.SS2.p7.1.m1.1.1.2" xref="S4.SS2.p7.1.m1.1.1.2.cmml">80</mn><mo id="S4.SS2.p7.1.m1.1.1.1" xref="S4.SS2.p7.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.1b"><apply id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p7.1.m1.1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p7.1.m1.1.1.2.cmml" xref="S4.SS2.p7.1.m1.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.1c">80\%</annotation></semantics></math> are in the training set, <math id="S4.SS2.p7.2.m2.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S4.SS2.p7.2.m2.1a"><mrow id="S4.SS2.p7.2.m2.1.1" xref="S4.SS2.p7.2.m2.1.1.cmml"><mn id="S4.SS2.p7.2.m2.1.1.2" xref="S4.SS2.p7.2.m2.1.1.2.cmml">10</mn><mo id="S4.SS2.p7.2.m2.1.1.1" xref="S4.SS2.p7.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.2.m2.1b"><apply id="S4.SS2.p7.2.m2.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p7.2.m2.1.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p7.2.m2.1.1.2.cmml" xref="S4.SS2.p7.2.m2.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.2.m2.1c">10\%</annotation></semantics></math> in the validation set and <math id="S4.SS2.p7.3.m3.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S4.SS2.p7.3.m3.1a"><mrow id="S4.SS2.p7.3.m3.1.1" xref="S4.SS2.p7.3.m3.1.1.cmml"><mn id="S4.SS2.p7.3.m3.1.1.2" xref="S4.SS2.p7.3.m3.1.1.2.cmml">10</mn><mo id="S4.SS2.p7.3.m3.1.1.1" xref="S4.SS2.p7.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.3.m3.1b"><apply id="S4.SS2.p7.3.m3.1.1.cmml" xref="S4.SS2.p7.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.p7.3.m3.1.1.1.cmml" xref="S4.SS2.p7.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p7.3.m3.1.1.2.cmml" xref="S4.SS2.p7.3.m3.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.3.m3.1c">10\%</annotation></semantics></math> in the test set.
There are 345,879 images in total in the training set, 39,239 in the validation set and 43,960 in the test set.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Benchmark setups</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold">Learning settings.</span> We benchmark the FLAIR dataset in three different learning settings: centralized learning, non-private and private federated learning. Comparing these settings demonstrates how heterogeneity of the user data distribution and providing user privacy guarantees affect model convergence. In the centralized learning setting, training data is the union of images from all users in the training split and user ID is ignored.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">ML tasks and models.</span>
As described in Section <a href="#S4.SS1" title="4.1 Dataset collection ‣ 4 FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, the main objects in each image were annotated into coarse-grained and fine-grained taxonomies.
We consider multi-label classification task on these two taxonomies, i.e. predicting if a class is presented in an image for each class in the taxonomy.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.1" class="ltx_p">We use a ResNet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> model for all benchmark experiments.
The final classification layer is a 17-way logistic regression for the coarse-grained taxonomy and 1,628-way for the fine-grained.
The model has more than 11M parameters in total.
We consider both training from scratch (i.e. from a random initialization) and fine-tuning from a pretrained model.
The pretrained ResNet-18 model is obtained from the Torchvision repository <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/pytorch/vision" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/pytorch/vision</a></span></span></span> and was trained on the ImageNet dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.p4.1" class="ltx_p">For models trained from scratch, we further replace all batch normalization (BN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> layers with group normalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> to avoid sharing the sensitive states in BN with the server in federated settings.
For the pretrained ResNet-18 model, we freeze the BN states during fine-tuning and only update the scale and bias parameters.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.p5.1" class="ltx_p"><span id="S5.SS1.p5.1.1" class="ltx_text ltx_font_bold">Evaluation metrics.</span>
We use standard multi-label classification metrics for the benchmark, including precision (percentage of predicted objects that are actually in the images), recall (percentage of objects in the images are predicted), F1 score, and averaged precision (AP) score. We report overall (micro-averaged) metrics, obtained by averaging over all examples, and per-class (macro-averaged) metrics, obtained by taking the average over classes of the average over examples restricted to a specific class.</p>
</div>
<div id="S5.SS1.p6" class="ltx_para ltx_noindent">
<p id="S5.SS1.p6.2" class="ltx_p"><span id="S5.SS1.p6.2.1" class="ltx_text ltx_font_bold">Simulating large cohort noise-level with small cohort.</span>
When training with DP, increasing cohort size <math id="S5.SS1.p6.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S5.SS1.p6.1.m1.1a"><mi id="S5.SS1.p6.1.m1.1.1" xref="S5.SS1.p6.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.1.m1.1b"><ci id="S5.SS1.p6.1.m1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.1.m1.1c">C</annotation></semantics></math> will monotonically increase the signal-to-noise ratio (SNR) of the averaged noisy aggregates as the DP noise will be reduced by averaging.
As we will show later in Section <a href="#S5.SS2" title="5.2 Results ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>, the minimum SNR required for training large neural networks such as ResNet corresponds to a <math id="S5.SS1.p6.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S5.SS1.p6.2.m2.1a"><mi id="S5.SS1.p6.2.m2.1.1" xref="S5.SS1.p6.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.2.m2.1b"><ci id="S5.SS1.p6.2.m2.1.1.cmml" xref="S5.SS1.p6.2.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.2.m2.1c">C</annotation></semantics></math> in the thousands, which is compute-intensive with current federated learning frameworks.</p>
</div>
<div id="S5.SS1.p7" class="ltx_para ltx_noindent">
<p id="S5.SS1.p7.11" class="ltx_p">Following prior work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, we simulate the SNR effect of a large cohort <math id="S5.SS1.p7.1.m1.1" class="ltx_Math" alttext="C_{\mathrm{lg}}" display="inline"><semantics id="S5.SS1.p7.1.m1.1a"><msub id="S5.SS1.p7.1.m1.1.1" xref="S5.SS1.p7.1.m1.1.1.cmml"><mi id="S5.SS1.p7.1.m1.1.1.2" xref="S5.SS1.p7.1.m1.1.1.2.cmml">C</mi><mi id="S5.SS1.p7.1.m1.1.1.3" xref="S5.SS1.p7.1.m1.1.1.3.cmml">lg</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.1.m1.1b"><apply id="S5.SS1.p7.1.m1.1.1.cmml" xref="S5.SS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.1.m1.1.1.1.cmml" xref="S5.SS1.p7.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p7.1.m1.1.1.2.cmml" xref="S5.SS1.p7.1.m1.1.1.2">𝐶</ci><ci id="S5.SS1.p7.1.m1.1.1.3.cmml" xref="S5.SS1.p7.1.m1.1.1.3">lg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.1.m1.1c">C_{\mathrm{lg}}</annotation></semantics></math> using a small cohort <math id="S5.SS1.p7.2.m2.1" class="ltx_Math" alttext="C_{\mathrm{sm}}" display="inline"><semantics id="S5.SS1.p7.2.m2.1a"><msub id="S5.SS1.p7.2.m2.1.1" xref="S5.SS1.p7.2.m2.1.1.cmml"><mi id="S5.SS1.p7.2.m2.1.1.2" xref="S5.SS1.p7.2.m2.1.1.2.cmml">C</mi><mi id="S5.SS1.p7.2.m2.1.1.3" xref="S5.SS1.p7.2.m2.1.1.3.cmml">sm</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.2.m2.1b"><apply id="S5.SS1.p7.2.m2.1.1.cmml" xref="S5.SS1.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.2.m2.1.1.1.cmml" xref="S5.SS1.p7.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p7.2.m2.1.1.2.cmml" xref="S5.SS1.p7.2.m2.1.1.2">𝐶</ci><ci id="S5.SS1.p7.2.m2.1.1.3.cmml" xref="S5.SS1.p7.2.m2.1.1.3">sm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.2.m2.1c">C_{\mathrm{sm}}</annotation></semantics></math> so that we can efficiently experiment with different noise-levels.
Let <math id="S5.SS1.p7.3.m3.2" class="ltx_Math" alttext="\sigma={\mathcal{M}}(\cdot,C)" display="inline"><semantics id="S5.SS1.p7.3.m3.2a"><mrow id="S5.SS1.p7.3.m3.2.3" xref="S5.SS1.p7.3.m3.2.3.cmml"><mi id="S5.SS1.p7.3.m3.2.3.2" xref="S5.SS1.p7.3.m3.2.3.2.cmml">σ</mi><mo id="S5.SS1.p7.3.m3.2.3.1" xref="S5.SS1.p7.3.m3.2.3.1.cmml">=</mo><mrow id="S5.SS1.p7.3.m3.2.3.3" xref="S5.SS1.p7.3.m3.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p7.3.m3.2.3.3.2" xref="S5.SS1.p7.3.m3.2.3.3.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p7.3.m3.2.3.3.1" xref="S5.SS1.p7.3.m3.2.3.3.1.cmml">​</mo><mrow id="S5.SS1.p7.3.m3.2.3.3.3.2" xref="S5.SS1.p7.3.m3.2.3.3.3.1.cmml"><mo stretchy="false" id="S5.SS1.p7.3.m3.2.3.3.3.2.1" xref="S5.SS1.p7.3.m3.2.3.3.3.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S5.SS1.p7.3.m3.1.1" xref="S5.SS1.p7.3.m3.1.1.cmml">⋅</mo><mo id="S5.SS1.p7.3.m3.2.3.3.3.2.2" xref="S5.SS1.p7.3.m3.2.3.3.3.1.cmml">,</mo><mi id="S5.SS1.p7.3.m3.2.2" xref="S5.SS1.p7.3.m3.2.2.cmml">C</mi><mo stretchy="false" id="S5.SS1.p7.3.m3.2.3.3.3.2.3" xref="S5.SS1.p7.3.m3.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.3.m3.2b"><apply id="S5.SS1.p7.3.m3.2.3.cmml" xref="S5.SS1.p7.3.m3.2.3"><eq id="S5.SS1.p7.3.m3.2.3.1.cmml" xref="S5.SS1.p7.3.m3.2.3.1"></eq><ci id="S5.SS1.p7.3.m3.2.3.2.cmml" xref="S5.SS1.p7.3.m3.2.3.2">𝜎</ci><apply id="S5.SS1.p7.3.m3.2.3.3.cmml" xref="S5.SS1.p7.3.m3.2.3.3"><times id="S5.SS1.p7.3.m3.2.3.3.1.cmml" xref="S5.SS1.p7.3.m3.2.3.3.1"></times><ci id="S5.SS1.p7.3.m3.2.3.3.2.cmml" xref="S5.SS1.p7.3.m3.2.3.3.2">ℳ</ci><interval closure="open" id="S5.SS1.p7.3.m3.2.3.3.3.1.cmml" xref="S5.SS1.p7.3.m3.2.3.3.3.2"><ci id="S5.SS1.p7.3.m3.1.1.cmml" xref="S5.SS1.p7.3.m3.1.1">⋅</ci><ci id="S5.SS1.p7.3.m3.2.2.cmml" xref="S5.SS1.p7.3.m3.2.2">𝐶</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.3.m3.2c">\sigma={\mathcal{M}}(\cdot,C)</annotation></semantics></math> be the noise multiplier calculated by moments accountant <math id="S5.SS1.p7.4.m4.1" class="ltx_Math" alttext="{\mathcal{M}}" display="inline"><semantics id="S5.SS1.p7.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p7.4.m4.1.1" xref="S5.SS1.p7.4.m4.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.4.m4.1b"><ci id="S5.SS1.p7.4.m4.1.1.cmml" xref="S5.SS1.p7.4.m4.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.4.m4.1c">{\mathcal{M}}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> for cohort size <math id="S5.SS1.p7.5.m5.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S5.SS1.p7.5.m5.1a"><mi id="S5.SS1.p7.5.m5.1.1" xref="S5.SS1.p7.5.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.5.m5.1b"><ci id="S5.SS1.p7.5.m5.1.1.cmml" xref="S5.SS1.p7.5.m5.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.5.m5.1c">C</annotation></semantics></math> and other privacy parameters.
We use <math id="S5.SS1.p7.6.m6.1" class="ltx_Math" alttext="C_{\mathrm{sm}}" display="inline"><semantics id="S5.SS1.p7.6.m6.1a"><msub id="S5.SS1.p7.6.m6.1.1" xref="S5.SS1.p7.6.m6.1.1.cmml"><mi id="S5.SS1.p7.6.m6.1.1.2" xref="S5.SS1.p7.6.m6.1.1.2.cmml">C</mi><mi id="S5.SS1.p7.6.m6.1.1.3" xref="S5.SS1.p7.6.m6.1.1.3.cmml">sm</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.6.m6.1b"><apply id="S5.SS1.p7.6.m6.1.1.cmml" xref="S5.SS1.p7.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.6.m6.1.1.1.cmml" xref="S5.SS1.p7.6.m6.1.1">subscript</csymbol><ci id="S5.SS1.p7.6.m6.1.1.2.cmml" xref="S5.SS1.p7.6.m6.1.1.2">𝐶</ci><ci id="S5.SS1.p7.6.m6.1.1.3.cmml" xref="S5.SS1.p7.6.m6.1.1.3">sm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.6.m6.1c">C_{\mathrm{sm}}</annotation></semantics></math> and noise multiplier <math id="S5.SS1.p7.7.m7.1" class="ltx_Math" alttext="\sigma_{\mathrm{sm}}" display="inline"><semantics id="S5.SS1.p7.7.m7.1a"><msub id="S5.SS1.p7.7.m7.1.1" xref="S5.SS1.p7.7.m7.1.1.cmml"><mi id="S5.SS1.p7.7.m7.1.1.2" xref="S5.SS1.p7.7.m7.1.1.2.cmml">σ</mi><mi id="S5.SS1.p7.7.m7.1.1.3" xref="S5.SS1.p7.7.m7.1.1.3.cmml">sm</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.7.m7.1b"><apply id="S5.SS1.p7.7.m7.1.1.cmml" xref="S5.SS1.p7.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.7.m7.1.1.1.cmml" xref="S5.SS1.p7.7.m7.1.1">subscript</csymbol><ci id="S5.SS1.p7.7.m7.1.1.2.cmml" xref="S5.SS1.p7.7.m7.1.1.2">𝜎</ci><ci id="S5.SS1.p7.7.m7.1.1.3.cmml" xref="S5.SS1.p7.7.m7.1.1.3">sm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.7.m7.1c">\sigma_{\mathrm{sm}}</annotation></semantics></math> for experiments, where
<math id="S5.SS1.p7.8.m8.2" class="ltx_Math" alttext="\sigma_{\mathrm{sm}}=\frac{C_{\mathrm{sm}}}{C_{\mathrm{lg}}}{\mathcal{M}}(\cdot,C_{\mathrm{lg}})." display="inline"><semantics id="S5.SS1.p7.8.m8.2a"><mrow id="S5.SS1.p7.8.m8.2.2.1" xref="S5.SS1.p7.8.m8.2.2.1.1.cmml"><mrow id="S5.SS1.p7.8.m8.2.2.1.1" xref="S5.SS1.p7.8.m8.2.2.1.1.cmml"><msub id="S5.SS1.p7.8.m8.2.2.1.1.3" xref="S5.SS1.p7.8.m8.2.2.1.1.3.cmml"><mi id="S5.SS1.p7.8.m8.2.2.1.1.3.2" xref="S5.SS1.p7.8.m8.2.2.1.1.3.2.cmml">σ</mi><mi id="S5.SS1.p7.8.m8.2.2.1.1.3.3" xref="S5.SS1.p7.8.m8.2.2.1.1.3.3.cmml">sm</mi></msub><mo id="S5.SS1.p7.8.m8.2.2.1.1.2" xref="S5.SS1.p7.8.m8.2.2.1.1.2.cmml">=</mo><mrow id="S5.SS1.p7.8.m8.2.2.1.1.1" xref="S5.SS1.p7.8.m8.2.2.1.1.1.cmml"><mfrac id="S5.SS1.p7.8.m8.2.2.1.1.1.3" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.cmml"><msub id="S5.SS1.p7.8.m8.2.2.1.1.1.3.2" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.cmml"><mi id="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.2" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.2.cmml">C</mi><mi id="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.3" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.3.cmml">sm</mi></msub><msub id="S5.SS1.p7.8.m8.2.2.1.1.1.3.3" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.cmml"><mi id="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.2" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.2.cmml">C</mi><mi id="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.3" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.3.cmml">lg</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S5.SS1.p7.8.m8.2.2.1.1.1.2" xref="S5.SS1.p7.8.m8.2.2.1.1.1.2.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p7.8.m8.2.2.1.1.1.4" xref="S5.SS1.p7.8.m8.2.2.1.1.1.4.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p7.8.m8.2.2.1.1.1.2a" xref="S5.SS1.p7.8.m8.2.2.1.1.1.2.cmml">​</mo><mrow id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.2" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S5.SS1.p7.8.m8.1.1" xref="S5.SS1.p7.8.m8.1.1.cmml">⋅</mo><mo id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.3" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.2.cmml">,</mo><msub id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.cmml"><mi id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.2" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.2.cmml">C</mi><mi id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.3" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.3.cmml">lg</mi></msub><mo stretchy="false" id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.4" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S5.SS1.p7.8.m8.2.2.1.2" xref="S5.SS1.p7.8.m8.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.8.m8.2b"><apply id="S5.SS1.p7.8.m8.2.2.1.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1"><eq id="S5.SS1.p7.8.m8.2.2.1.1.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.2"></eq><apply id="S5.SS1.p7.8.m8.2.2.1.1.3.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p7.8.m8.2.2.1.1.3.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.3">subscript</csymbol><ci id="S5.SS1.p7.8.m8.2.2.1.1.3.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.3.2">𝜎</ci><ci id="S5.SS1.p7.8.m8.2.2.1.1.3.3.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.3.3">sm</ci></apply><apply id="S5.SS1.p7.8.m8.2.2.1.1.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1"><times id="S5.SS1.p7.8.m8.2.2.1.1.1.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.2"></times><apply id="S5.SS1.p7.8.m8.2.2.1.1.1.3.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3"><divide id="S5.SS1.p7.8.m8.2.2.1.1.1.3.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3"></divide><apply id="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.2">subscript</csymbol><ci id="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.2">𝐶</ci><ci id="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.3.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.2.3">sm</ci></apply><apply id="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.3"><csymbol cd="ambiguous" id="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.3">subscript</csymbol><ci id="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.2">𝐶</ci><ci id="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.3.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.3.3.3">lg</ci></apply></apply><ci id="S5.SS1.p7.8.m8.2.2.1.1.1.4.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.4">ℳ</ci><interval closure="open" id="S5.SS1.p7.8.m8.2.2.1.1.1.1.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1"><ci id="S5.SS1.p7.8.m8.1.1.cmml" xref="S5.SS1.p7.8.m8.1.1">⋅</ci><apply id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.1.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.2.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.2">𝐶</ci><ci id="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.3.cmml" xref="S5.SS1.p7.8.m8.2.2.1.1.1.1.1.1.3">lg</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.8.m8.2c">\sigma_{\mathrm{sm}}=\frac{C_{\mathrm{sm}}}{C_{\mathrm{lg}}}{\mathcal{M}}(\cdot,C_{\mathrm{lg}}).</annotation></semantics></math>
The noise applied to the averaged <math id="S5.SS1.p7.9.m9.1" class="ltx_Math" alttext="C_{\mathrm{sm}}" display="inline"><semantics id="S5.SS1.p7.9.m9.1a"><msub id="S5.SS1.p7.9.m9.1.1" xref="S5.SS1.p7.9.m9.1.1.cmml"><mi id="S5.SS1.p7.9.m9.1.1.2" xref="S5.SS1.p7.9.m9.1.1.2.cmml">C</mi><mi id="S5.SS1.p7.9.m9.1.1.3" xref="S5.SS1.p7.9.m9.1.1.3.cmml">sm</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.9.m9.1b"><apply id="S5.SS1.p7.9.m9.1.1.cmml" xref="S5.SS1.p7.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.9.m9.1.1.1.cmml" xref="S5.SS1.p7.9.m9.1.1">subscript</csymbol><ci id="S5.SS1.p7.9.m9.1.1.2.cmml" xref="S5.SS1.p7.9.m9.1.1.2">𝐶</ci><ci id="S5.SS1.p7.9.m9.1.1.3.cmml" xref="S5.SS1.p7.9.m9.1.1.3">sm</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.9.m9.1c">C_{\mathrm{sm}}</annotation></semantics></math> model updates has standard deviation <math id="S5.SS1.p7.10.m10.2" class="ltx_Math" alttext="\frac{\sigma_{\mathrm{sm}}}{C_{\mathrm{sm}}}=\frac{{\mathcal{M}}(\cdot,C_{\mathrm{lg}})}{C_{\mathrm{lg}}}" display="inline"><semantics id="S5.SS1.p7.10.m10.2a"><mrow id="S5.SS1.p7.10.m10.2.3" xref="S5.SS1.p7.10.m10.2.3.cmml"><mfrac id="S5.SS1.p7.10.m10.2.3.2" xref="S5.SS1.p7.10.m10.2.3.2.cmml"><msub id="S5.SS1.p7.10.m10.2.3.2.2" xref="S5.SS1.p7.10.m10.2.3.2.2.cmml"><mi id="S5.SS1.p7.10.m10.2.3.2.2.2" xref="S5.SS1.p7.10.m10.2.3.2.2.2.cmml">σ</mi><mi id="S5.SS1.p7.10.m10.2.3.2.2.3" xref="S5.SS1.p7.10.m10.2.3.2.2.3.cmml">sm</mi></msub><msub id="S5.SS1.p7.10.m10.2.3.2.3" xref="S5.SS1.p7.10.m10.2.3.2.3.cmml"><mi id="S5.SS1.p7.10.m10.2.3.2.3.2" xref="S5.SS1.p7.10.m10.2.3.2.3.2.cmml">C</mi><mi id="S5.SS1.p7.10.m10.2.3.2.3.3" xref="S5.SS1.p7.10.m10.2.3.2.3.3.cmml">sm</mi></msub></mfrac><mo id="S5.SS1.p7.10.m10.2.3.1" xref="S5.SS1.p7.10.m10.2.3.1.cmml">=</mo><mfrac id="S5.SS1.p7.10.m10.2.2" xref="S5.SS1.p7.10.m10.2.2.cmml"><mrow id="S5.SS1.p7.10.m10.2.2.2" xref="S5.SS1.p7.10.m10.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p7.10.m10.2.2.2.4" xref="S5.SS1.p7.10.m10.2.2.2.4.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p7.10.m10.2.2.2.3" xref="S5.SS1.p7.10.m10.2.2.2.3.cmml">​</mo><mrow id="S5.SS1.p7.10.m10.2.2.2.2.1" xref="S5.SS1.p7.10.m10.2.2.2.2.2.cmml"><mo stretchy="false" id="S5.SS1.p7.10.m10.2.2.2.2.1.2" xref="S5.SS1.p7.10.m10.2.2.2.2.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S5.SS1.p7.10.m10.1.1.1.1" xref="S5.SS1.p7.10.m10.1.1.1.1.cmml">⋅</mo><mo id="S5.SS1.p7.10.m10.2.2.2.2.1.3" xref="S5.SS1.p7.10.m10.2.2.2.2.2.cmml">,</mo><msub id="S5.SS1.p7.10.m10.2.2.2.2.1.1" xref="S5.SS1.p7.10.m10.2.2.2.2.1.1.cmml"><mi id="S5.SS1.p7.10.m10.2.2.2.2.1.1.2" xref="S5.SS1.p7.10.m10.2.2.2.2.1.1.2.cmml">C</mi><mi id="S5.SS1.p7.10.m10.2.2.2.2.1.1.3" xref="S5.SS1.p7.10.m10.2.2.2.2.1.1.3.cmml">lg</mi></msub><mo stretchy="false" id="S5.SS1.p7.10.m10.2.2.2.2.1.4" xref="S5.SS1.p7.10.m10.2.2.2.2.2.cmml">)</mo></mrow></mrow><msub id="S5.SS1.p7.10.m10.2.2.4" xref="S5.SS1.p7.10.m10.2.2.4.cmml"><mi id="S5.SS1.p7.10.m10.2.2.4.2" xref="S5.SS1.p7.10.m10.2.2.4.2.cmml">C</mi><mi id="S5.SS1.p7.10.m10.2.2.4.3" xref="S5.SS1.p7.10.m10.2.2.4.3.cmml">lg</mi></msub></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.10.m10.2b"><apply id="S5.SS1.p7.10.m10.2.3.cmml" xref="S5.SS1.p7.10.m10.2.3"><eq id="S5.SS1.p7.10.m10.2.3.1.cmml" xref="S5.SS1.p7.10.m10.2.3.1"></eq><apply id="S5.SS1.p7.10.m10.2.3.2.cmml" xref="S5.SS1.p7.10.m10.2.3.2"><divide id="S5.SS1.p7.10.m10.2.3.2.1.cmml" xref="S5.SS1.p7.10.m10.2.3.2"></divide><apply id="S5.SS1.p7.10.m10.2.3.2.2.cmml" xref="S5.SS1.p7.10.m10.2.3.2.2"><csymbol cd="ambiguous" id="S5.SS1.p7.10.m10.2.3.2.2.1.cmml" xref="S5.SS1.p7.10.m10.2.3.2.2">subscript</csymbol><ci id="S5.SS1.p7.10.m10.2.3.2.2.2.cmml" xref="S5.SS1.p7.10.m10.2.3.2.2.2">𝜎</ci><ci id="S5.SS1.p7.10.m10.2.3.2.2.3.cmml" xref="S5.SS1.p7.10.m10.2.3.2.2.3">sm</ci></apply><apply id="S5.SS1.p7.10.m10.2.3.2.3.cmml" xref="S5.SS1.p7.10.m10.2.3.2.3"><csymbol cd="ambiguous" id="S5.SS1.p7.10.m10.2.3.2.3.1.cmml" xref="S5.SS1.p7.10.m10.2.3.2.3">subscript</csymbol><ci id="S5.SS1.p7.10.m10.2.3.2.3.2.cmml" xref="S5.SS1.p7.10.m10.2.3.2.3.2">𝐶</ci><ci id="S5.SS1.p7.10.m10.2.3.2.3.3.cmml" xref="S5.SS1.p7.10.m10.2.3.2.3.3">sm</ci></apply></apply><apply id="S5.SS1.p7.10.m10.2.2.cmml" xref="S5.SS1.p7.10.m10.2.2"><divide id="S5.SS1.p7.10.m10.2.2.3.cmml" xref="S5.SS1.p7.10.m10.2.2"></divide><apply id="S5.SS1.p7.10.m10.2.2.2.cmml" xref="S5.SS1.p7.10.m10.2.2.2"><times id="S5.SS1.p7.10.m10.2.2.2.3.cmml" xref="S5.SS1.p7.10.m10.2.2.2.3"></times><ci id="S5.SS1.p7.10.m10.2.2.2.4.cmml" xref="S5.SS1.p7.10.m10.2.2.2.4">ℳ</ci><interval closure="open" id="S5.SS1.p7.10.m10.2.2.2.2.2.cmml" xref="S5.SS1.p7.10.m10.2.2.2.2.1"><ci id="S5.SS1.p7.10.m10.1.1.1.1.cmml" xref="S5.SS1.p7.10.m10.1.1.1.1">⋅</ci><apply id="S5.SS1.p7.10.m10.2.2.2.2.1.1.cmml" xref="S5.SS1.p7.10.m10.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.10.m10.2.2.2.2.1.1.1.cmml" xref="S5.SS1.p7.10.m10.2.2.2.2.1.1">subscript</csymbol><ci id="S5.SS1.p7.10.m10.2.2.2.2.1.1.2.cmml" xref="S5.SS1.p7.10.m10.2.2.2.2.1.1.2">𝐶</ci><ci id="S5.SS1.p7.10.m10.2.2.2.2.1.1.3.cmml" xref="S5.SS1.p7.10.m10.2.2.2.2.1.1.3">lg</ci></apply></interval></apply><apply id="S5.SS1.p7.10.m10.2.2.4.cmml" xref="S5.SS1.p7.10.m10.2.2.4"><csymbol cd="ambiguous" id="S5.SS1.p7.10.m10.2.2.4.1.cmml" xref="S5.SS1.p7.10.m10.2.2.4">subscript</csymbol><ci id="S5.SS1.p7.10.m10.2.2.4.2.cmml" xref="S5.SS1.p7.10.m10.2.2.4.2">𝐶</ci><ci id="S5.SS1.p7.10.m10.2.2.4.3.cmml" xref="S5.SS1.p7.10.m10.2.2.4.3">lg</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.10.m10.2c">\frac{\sigma_{\mathrm{sm}}}{C_{\mathrm{sm}}}=\frac{{\mathcal{M}}(\cdot,C_{\mathrm{lg}})}{C_{\mathrm{lg}}}</annotation></semantics></math>, which is the same as if we are training with <math id="S5.SS1.p7.11.m11.1" class="ltx_Math" alttext="C_{\mathrm{lg}}" display="inline"><semantics id="S5.SS1.p7.11.m11.1a"><msub id="S5.SS1.p7.11.m11.1.1" xref="S5.SS1.p7.11.m11.1.1.cmml"><mi id="S5.SS1.p7.11.m11.1.1.2" xref="S5.SS1.p7.11.m11.1.1.2.cmml">C</mi><mi id="S5.SS1.p7.11.m11.1.1.3" xref="S5.SS1.p7.11.m11.1.1.3.cmml">lg</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p7.11.m11.1b"><apply id="S5.SS1.p7.11.m11.1.1.cmml" xref="S5.SS1.p7.11.m11.1.1"><csymbol cd="ambiguous" id="S5.SS1.p7.11.m11.1.1.1.cmml" xref="S5.SS1.p7.11.m11.1.1">subscript</csymbol><ci id="S5.SS1.p7.11.m11.1.1.2.cmml" xref="S5.SS1.p7.11.m11.1.1.2">𝐶</ci><ci id="S5.SS1.p7.11.m11.1.1.3.cmml" xref="S5.SS1.p7.11.m11.1.1.3">lg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p7.11.m11.1c">C_{\mathrm{lg}}</annotation></semantics></math> users.</p>
</div>
<div id="S5.SS1.p8" class="ltx_para ltx_noindent">
<p id="S5.SS1.p8.2" class="ltx_p"><span id="S5.SS1.p8.2.1" class="ltx_text ltx_font_bold">Hyperparameters.</span>
For all experiments, we use Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
as the server-side optimizer.
During training, each image is randomly cropped to size <math id="S5.SS1.p8.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S5.SS1.p8.1.m1.1a"><mrow id="S5.SS1.p8.1.m1.1.1" xref="S5.SS1.p8.1.m1.1.1.cmml"><mn id="S5.SS1.p8.1.m1.1.1.2" xref="S5.SS1.p8.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p8.1.m1.1.1.1" xref="S5.SS1.p8.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS1.p8.1.m1.1.1.3" xref="S5.SS1.p8.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p8.1.m1.1b"><apply id="S5.SS1.p8.1.m1.1.1.cmml" xref="S5.SS1.p8.1.m1.1.1"><times id="S5.SS1.p8.1.m1.1.1.1.cmml" xref="S5.SS1.p8.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p8.1.m1.1.1.2.cmml" xref="S5.SS1.p8.1.m1.1.1.2">224</cn><cn type="integer" id="S5.SS1.p8.1.m1.1.1.3.cmml" xref="S5.SS1.p8.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p8.1.m1.1c">224\times 224</annotation></semantics></math> and randomly flipped horizontally or vertically.
During evaluation, each image is resized to <math id="S5.SS1.p8.2.m2.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S5.SS1.p8.2.m2.1a"><mrow id="S5.SS1.p8.2.m2.1.1" xref="S5.SS1.p8.2.m2.1.1.cmml"><mn id="S5.SS1.p8.2.m2.1.1.2" xref="S5.SS1.p8.2.m2.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p8.2.m2.1.1.1" xref="S5.SS1.p8.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS1.p8.2.m2.1.1.3" xref="S5.SS1.p8.2.m2.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p8.2.m2.1b"><apply id="S5.SS1.p8.2.m2.1.1.cmml" xref="S5.SS1.p8.2.m2.1.1"><times id="S5.SS1.p8.2.m2.1.1.1.cmml" xref="S5.SS1.p8.2.m2.1.1.1"></times><cn type="integer" id="S5.SS1.p8.2.m2.1.1.2.cmml" xref="S5.SS1.p8.2.m2.1.1.2">224</cn><cn type="integer" id="S5.SS1.p8.2.m2.1.1.3.cmml" xref="S5.SS1.p8.2.m2.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p8.2.m2.1c">224\times 224</annotation></semantics></math>.
We performed a grid search on the hyperparameters and report the values that yield best performance on the validation set. See Appendix <a href="#A2.SS2" title="B.2 Hyper-parameters grids ‣ Appendix B Benchmark Setup Details ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B.2</span></a> for hyperparameters grids.</p>
</div>
<div id="S5.SS1.p9" class="ltx_para ltx_noindent">
<p id="S5.SS1.p9.1" class="ltx_p">For the centralized setting, we set the number of epochs to be 100 and the learning rate to be 5e-4 if training from scratch, and number of epochs to be 50 and learning rate to be 1e-4 when fine-tuning. We use a mini-batch size of 512.</p>
</div>
<div id="S5.SS1.p10" class="ltx_para ltx_noindent">
<p id="S5.SS1.p10.1" class="ltx_p">For the federated learning setting, we train the model for 5,000 rounds with a cohort size of 200.
We set the server learning rate to 0.1.
Each sampled user trains the model locally with SGD for 2 epochs with local batch size set to 16 and local learning rate set to 0.1 when training from scratch and 0.01 when fine-tuning.
We limit the maximum number of images for each user to be 512 and if a user has more images, we randomly sample 512 images to train.</p>
</div>
<div id="S5.SS1.p11" class="ltx_para ltx_noindent">
<p id="S5.SS1.p11.3" class="ltx_p">For federated learning with differential privacy, we use <math id="S5.SS1.p11.1.m1.2" class="ltx_Math" alttext="\epsilon=2.0,\delta=N^{-1.1}" display="inline"><semantics id="S5.SS1.p11.1.m1.2a"><mrow id="S5.SS1.p11.1.m1.2.2.2" xref="S5.SS1.p11.1.m1.2.2.3.cmml"><mrow id="S5.SS1.p11.1.m1.1.1.1.1" xref="S5.SS1.p11.1.m1.1.1.1.1.cmml"><mi id="S5.SS1.p11.1.m1.1.1.1.1.2" xref="S5.SS1.p11.1.m1.1.1.1.1.2.cmml">ϵ</mi><mo id="S5.SS1.p11.1.m1.1.1.1.1.1" xref="S5.SS1.p11.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S5.SS1.p11.1.m1.1.1.1.1.3" xref="S5.SS1.p11.1.m1.1.1.1.1.3.cmml">2.0</mn></mrow><mo id="S5.SS1.p11.1.m1.2.2.2.3" xref="S5.SS1.p11.1.m1.2.2.3a.cmml">,</mo><mrow id="S5.SS1.p11.1.m1.2.2.2.2" xref="S5.SS1.p11.1.m1.2.2.2.2.cmml"><mi id="S5.SS1.p11.1.m1.2.2.2.2.2" xref="S5.SS1.p11.1.m1.2.2.2.2.2.cmml">δ</mi><mo id="S5.SS1.p11.1.m1.2.2.2.2.1" xref="S5.SS1.p11.1.m1.2.2.2.2.1.cmml">=</mo><msup id="S5.SS1.p11.1.m1.2.2.2.2.3" xref="S5.SS1.p11.1.m1.2.2.2.2.3.cmml"><mi id="S5.SS1.p11.1.m1.2.2.2.2.3.2" xref="S5.SS1.p11.1.m1.2.2.2.2.3.2.cmml">N</mi><mrow id="S5.SS1.p11.1.m1.2.2.2.2.3.3" xref="S5.SS1.p11.1.m1.2.2.2.2.3.3.cmml"><mo id="S5.SS1.p11.1.m1.2.2.2.2.3.3a" xref="S5.SS1.p11.1.m1.2.2.2.2.3.3.cmml">−</mo><mn id="S5.SS1.p11.1.m1.2.2.2.2.3.3.2" xref="S5.SS1.p11.1.m1.2.2.2.2.3.3.2.cmml">1.1</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p11.1.m1.2b"><apply id="S5.SS1.p11.1.m1.2.2.3.cmml" xref="S5.SS1.p11.1.m1.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.p11.1.m1.2.2.3a.cmml" xref="S5.SS1.p11.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S5.SS1.p11.1.m1.1.1.1.1.cmml" xref="S5.SS1.p11.1.m1.1.1.1.1"><eq id="S5.SS1.p11.1.m1.1.1.1.1.1.cmml" xref="S5.SS1.p11.1.m1.1.1.1.1.1"></eq><ci id="S5.SS1.p11.1.m1.1.1.1.1.2.cmml" xref="S5.SS1.p11.1.m1.1.1.1.1.2">italic-ϵ</ci><cn type="float" id="S5.SS1.p11.1.m1.1.1.1.1.3.cmml" xref="S5.SS1.p11.1.m1.1.1.1.1.3">2.0</cn></apply><apply id="S5.SS1.p11.1.m1.2.2.2.2.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2"><eq id="S5.SS1.p11.1.m1.2.2.2.2.1.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.1"></eq><ci id="S5.SS1.p11.1.m1.2.2.2.2.2.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.2">𝛿</ci><apply id="S5.SS1.p11.1.m1.2.2.2.2.3.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S5.SS1.p11.1.m1.2.2.2.2.3.1.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.3">superscript</csymbol><ci id="S5.SS1.p11.1.m1.2.2.2.2.3.2.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.3.2">𝑁</ci><apply id="S5.SS1.p11.1.m1.2.2.2.2.3.3.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.3.3"><minus id="S5.SS1.p11.1.m1.2.2.2.2.3.3.1.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.3.3"></minus><cn type="float" id="S5.SS1.p11.1.m1.2.2.2.2.3.3.2.cmml" xref="S5.SS1.p11.1.m1.2.2.2.2.3.3.2">1.1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p11.1.m1.2c">\epsilon=2.0,\delta=N^{-1.1}</annotation></semantics></math> where <math id="S5.SS1.p11.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S5.SS1.p11.2.m2.1a"><mi id="S5.SS1.p11.2.m2.1.1" xref="S5.SS1.p11.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p11.2.m2.1b"><ci id="S5.SS1.p11.2.m2.1.1.cmml" xref="S5.SS1.p11.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p11.2.m2.1c">N</annotation></semantics></math> is the number of training users.
We set the server learning rate to 0.02.
We use an adaptive clipping algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> to tune the clipping bound, with the <math id="S5.SS1.p11.3.m3.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S5.SS1.p11.3.m3.1a"><msub id="S5.SS1.p11.3.m3.1.1" xref="S5.SS1.p11.3.m3.1.1.cmml"><mi id="S5.SS1.p11.3.m3.1.1.2" xref="S5.SS1.p11.3.m3.1.1.2.cmml">L</mi><mn id="S5.SS1.p11.3.m3.1.1.3" xref="S5.SS1.p11.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p11.3.m3.1b"><apply id="S5.SS1.p11.3.m3.1.1.cmml" xref="S5.SS1.p11.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p11.3.m3.1.1.1.cmml" xref="S5.SS1.p11.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p11.3.m3.1.1.2.cmml" xref="S5.SS1.p11.3.m3.1.1.2">𝐿</ci><cn type="integer" id="S5.SS1.p11.3.m3.1.1.3.cmml" xref="S5.SS1.p11.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p11.3.m3.1c">L_{2}</annotation></semantics></math> norm quantile set to 0.1.
We use 200 users sampled per round to simulate the noise-level with a cohort size of 5,000, and we also analyze the effect of different cohort sizes in Section <a href="#S5.SS2" title="5.2 Results ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results</h3>

<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>FLAIR benchmark results on test set. For setting, C, FL, PFL stands for centralized, federated and private federated learning. C and O denotes whether the metrics are per-class or overall. AP denotes averaged precision; P denotes precision; R denotes recall; and F1 denotes F1 score.</figcaption>
<table id="S5.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.1.1.1" class="ltx_tr">
<th id="S5.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Setting</th>
<th id="S5.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Init</th>
<th id="S5.T1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Label</th>
<th id="S5.T1.1.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">C-AP</th>
<th id="S5.T1.1.1.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">C-P</th>
<th id="S5.T1.1.1.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">C-R</th>
<th id="S5.T1.1.1.1.7" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_tt">C-F1</th>
<th id="S5.T1.1.1.1.8" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">O-AP</th>
<th id="S5.T1.1.1.1.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">O-P</th>
<th id="S5.T1.1.1.1.10" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">O-R</th>
<th id="S5.T1.1.1.1.11" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">O-F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.1.2.1" class="ltx_tr">
<th id="S5.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">C</th>
<th id="S5.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Random</th>
<th id="S5.T1.1.2.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Coarse</th>
<td id="S5.T1.1.2.1.4" class="ltx_td ltx_align_right ltx_border_t">60.40</td>
<td id="S5.T1.1.2.1.5" class="ltx_td ltx_align_right ltx_border_t">72.79</td>
<td id="S5.T1.1.2.1.6" class="ltx_td ltx_align_right ltx_border_t">48.24</td>
<td id="S5.T1.1.2.1.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">58.03</td>
<td id="S5.T1.1.2.1.8" class="ltx_td ltx_align_right ltx_border_t">87.61</td>
<td id="S5.T1.1.2.1.9" class="ltx_td ltx_align_right ltx_border_t">81.43</td>
<td id="S5.T1.1.2.1.10" class="ltx_td ltx_align_right ltx_border_t">75.06</td>
<td id="S5.T1.1.2.1.11" class="ltx_td ltx_align_right ltx_border_t">78.11</td>
</tr>
<tr id="S5.T1.1.3.2" class="ltx_tr">
<th id="S5.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">FL</th>
<th id="S5.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Random</th>
<th id="S5.T1.1.3.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Coarse</th>
<td id="S5.T1.1.3.2.4" class="ltx_td ltx_align_right">50.41</td>
<td id="S5.T1.1.3.2.5" class="ltx_td ltx_align_right">59.74</td>
<td id="S5.T1.1.3.2.6" class="ltx_td ltx_align_right">37.46</td>
<td id="S5.T1.1.3.2.7" class="ltx_td ltx_align_right ltx_border_r">46.04</td>
<td id="S5.T1.1.3.2.8" class="ltx_td ltx_align_right">82.87</td>
<td id="S5.T1.1.3.2.9" class="ltx_td ltx_align_right">78.25</td>
<td id="S5.T1.1.3.2.10" class="ltx_td ltx_align_right">69.02</td>
<td id="S5.T1.1.3.2.11" class="ltx_td ltx_align_right">73.35</td>
</tr>
<tr id="S5.T1.1.4.3" class="ltx_tr">
<th id="S5.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PFL</th>
<th id="S5.T1.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Random</th>
<th id="S5.T1.1.4.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Coarse</th>
<td id="S5.T1.1.4.3.4" class="ltx_td ltx_align_right">28.80</td>
<td id="S5.T1.1.4.3.5" class="ltx_td ltx_align_right">30.02</td>
<td id="S5.T1.1.4.3.6" class="ltx_td ltx_align_right">17.85</td>
<td id="S5.T1.1.4.3.7" class="ltx_td ltx_align_right ltx_border_r">22.39</td>
<td id="S5.T1.1.4.3.8" class="ltx_td ltx_align_right">63.19</td>
<td id="S5.T1.1.4.3.9" class="ltx_td ltx_align_right">68.67</td>
<td id="S5.T1.1.4.3.10" class="ltx_td ltx_align_right">43.42</td>
<td id="S5.T1.1.4.3.11" class="ltx_td ltx_align_right">53.20</td>
</tr>
<tr id="S5.T1.1.5.4" class="ltx_tr">
<th id="S5.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">C</th>
<th id="S5.T1.1.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ImageNet</th>
<th id="S5.T1.1.5.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Coarse</th>
<td id="S5.T1.1.5.4.4" class="ltx_td ltx_align_right ltx_border_t">67.71</td>
<td id="S5.T1.1.5.4.5" class="ltx_td ltx_align_right ltx_border_t">75.71</td>
<td id="S5.T1.1.5.4.6" class="ltx_td ltx_align_right ltx_border_t">55.42</td>
<td id="S5.T1.1.5.4.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">64.00</td>
<td id="S5.T1.1.5.4.8" class="ltx_td ltx_align_right ltx_border_t">90.40</td>
<td id="S5.T1.1.5.4.9" class="ltx_td ltx_align_right ltx_border_t">84.09</td>
<td id="S5.T1.1.5.4.10" class="ltx_td ltx_align_right ltx_border_t">78.96</td>
<td id="S5.T1.1.5.4.11" class="ltx_td ltx_align_right ltx_border_t">81.44</td>
</tr>
<tr id="S5.T1.1.6.5" class="ltx_tr">
<th id="S5.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">FL</th>
<th id="S5.T1.1.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ImageNet</th>
<th id="S5.T1.1.6.5.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Coarse</th>
<td id="S5.T1.1.6.5.4" class="ltx_td ltx_align_right">62.09</td>
<td id="S5.T1.1.6.5.5" class="ltx_td ltx_align_right">71.81</td>
<td id="S5.T1.1.6.5.6" class="ltx_td ltx_align_right">48.60</td>
<td id="S5.T1.1.6.5.7" class="ltx_td ltx_align_right ltx_border_r">57.97</td>
<td id="S5.T1.1.6.5.8" class="ltx_td ltx_align_right">88.77</td>
<td id="S5.T1.1.6.5.9" class="ltx_td ltx_align_right">83.50</td>
<td id="S5.T1.1.6.5.10" class="ltx_td ltx_align_right">75.95</td>
<td id="S5.T1.1.6.5.11" class="ltx_td ltx_align_right">79.54</td>
</tr>
<tr id="S5.T1.1.7.6" class="ltx_tr">
<th id="S5.T1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PFL</th>
<th id="S5.T1.1.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ImageNet</th>
<th id="S5.T1.1.7.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Coarse</th>
<td id="S5.T1.1.7.6.4" class="ltx_td ltx_align_right">44.28</td>
<td id="S5.T1.1.7.6.5" class="ltx_td ltx_align_right">47.25</td>
<td id="S5.T1.1.7.6.6" class="ltx_td ltx_align_right">32.30</td>
<td id="S5.T1.1.7.6.7" class="ltx_td ltx_align_right ltx_border_r">38.37</td>
<td id="S5.T1.1.7.6.8" class="ltx_td ltx_align_right">80.20</td>
<td id="S5.T1.1.7.6.9" class="ltx_td ltx_align_right">77.51</td>
<td id="S5.T1.1.7.6.10" class="ltx_td ltx_align_right">64.37</td>
<td id="S5.T1.1.7.6.11" class="ltx_td ltx_align_right">70.33</td>
</tr>
<tr id="S5.T1.1.8.7" class="ltx_tr">
<th id="S5.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">C</th>
<th id="S5.T1.1.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Random</th>
<th id="S5.T1.1.8.7.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Fine</th>
<td id="S5.T1.1.8.7.4" class="ltx_td ltx_align_right ltx_border_t">14.90</td>
<td id="S5.T1.1.8.7.5" class="ltx_td ltx_align_right ltx_border_t">26.25</td>
<td id="S5.T1.1.8.7.6" class="ltx_td ltx_align_right ltx_border_t">7.18</td>
<td id="S5.T1.1.8.7.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">11.27</td>
<td id="S5.T1.1.8.7.8" class="ltx_td ltx_align_right ltx_border_t">43.15</td>
<td id="S5.T1.1.8.7.9" class="ltx_td ltx_align_right ltx_border_t">66.38</td>
<td id="S5.T1.1.8.7.10" class="ltx_td ltx_align_right ltx_border_t">26.02</td>
<td id="S5.T1.1.8.7.11" class="ltx_td ltx_align_right ltx_border_t">37.38</td>
</tr>
<tr id="S5.T1.1.9.8" class="ltx_tr">
<th id="S5.T1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">FL</th>
<th id="S5.T1.1.9.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Random</th>
<th id="S5.T1.1.9.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Fine</th>
<td id="S5.T1.1.9.8.4" class="ltx_td ltx_align_right">1.53</td>
<td id="S5.T1.1.9.8.5" class="ltx_td ltx_align_right">0.91</td>
<td id="S5.T1.1.9.8.6" class="ltx_td ltx_align_right">0.28</td>
<td id="S5.T1.1.9.8.7" class="ltx_td ltx_align_right ltx_border_r">0.43</td>
<td id="S5.T1.1.9.8.8" class="ltx_td ltx_align_right">22.68</td>
<td id="S5.T1.1.9.8.9" class="ltx_td ltx_align_right">58.99</td>
<td id="S5.T1.1.9.8.10" class="ltx_td ltx_align_right">8.38</td>
<td id="S5.T1.1.9.8.11" class="ltx_td ltx_align_right">14.68</td>
</tr>
<tr id="S5.T1.1.10.9" class="ltx_tr">
<th id="S5.T1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PFL</th>
<th id="S5.T1.1.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Random</th>
<th id="S5.T1.1.10.9.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Fine</th>
<td id="S5.T1.1.10.9.4" class="ltx_td ltx_align_right">0.29</td>
<td id="S5.T1.1.10.9.5" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T1.1.10.9.6" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T1.1.10.9.7" class="ltx_td ltx_align_right ltx_border_r">0.00</td>
<td id="S5.T1.1.10.9.8" class="ltx_td ltx_align_right">7.03</td>
<td id="S5.T1.1.10.9.9" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T1.1.10.9.10" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T1.1.10.9.11" class="ltx_td ltx_align_right">0.00</td>
</tr>
<tr id="S5.T1.1.11.10" class="ltx_tr">
<th id="S5.T1.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">C</th>
<th id="S5.T1.1.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ImageNet</th>
<th id="S5.T1.1.11.10.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Fine</th>
<td id="S5.T1.1.11.10.4" class="ltx_td ltx_align_right ltx_border_t">20.26</td>
<td id="S5.T1.1.11.10.5" class="ltx_td ltx_align_right ltx_border_t">32.97</td>
<td id="S5.T1.1.11.10.6" class="ltx_td ltx_align_right ltx_border_t">10.92</td>
<td id="S5.T1.1.11.10.7" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">16.40</td>
<td id="S5.T1.1.11.10.8" class="ltx_td ltx_align_right ltx_border_t">47.95</td>
<td id="S5.T1.1.11.10.9" class="ltx_td ltx_align_right ltx_border_t">68.73</td>
<td id="S5.T1.1.11.10.10" class="ltx_td ltx_align_right ltx_border_t">30.04</td>
<td id="S5.T1.1.11.10.11" class="ltx_td ltx_align_right ltx_border_t">41.81</td>
</tr>
<tr id="S5.T1.1.12.11" class="ltx_tr">
<th id="S5.T1.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">FL</th>
<th id="S5.T1.1.12.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">ImageNet</th>
<th id="S5.T1.1.12.11.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Fine</th>
<td id="S5.T1.1.12.11.4" class="ltx_td ltx_align_right">2.03</td>
<td id="S5.T1.1.12.11.5" class="ltx_td ltx_align_right">1.99</td>
<td id="S5.T1.1.12.11.6" class="ltx_td ltx_align_right">0.40</td>
<td id="S5.T1.1.12.11.7" class="ltx_td ltx_align_right ltx_border_r">0.66</td>
<td id="S5.T1.1.12.11.8" class="ltx_td ltx_align_right">27.31</td>
<td id="S5.T1.1.12.11.9" class="ltx_td ltx_align_right">65.47</td>
<td id="S5.T1.1.12.11.10" class="ltx_td ltx_align_right">10.50</td>
<td id="S5.T1.1.12.11.11" class="ltx_td ltx_align_right">18.10</td>
</tr>
<tr id="S5.T1.1.13.12" class="ltx_tr">
<th id="S5.T1.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">PFL</th>
<th id="S5.T1.1.13.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">ImageNet</th>
<th id="S5.T1.1.13.12.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Fine</th>
<td id="S5.T1.1.13.12.4" class="ltx_td ltx_align_right ltx_border_bb">0.53</td>
<td id="S5.T1.1.13.12.5" class="ltx_td ltx_align_right ltx_border_bb">0.22</td>
<td id="S5.T1.1.13.12.6" class="ltx_td ltx_align_right ltx_border_bb">0.01</td>
<td id="S5.T1.1.13.12.7" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r">0.01</td>
<td id="S5.T1.1.13.12.8" class="ltx_td ltx_align_right ltx_border_bb">12.67</td>
<td id="S5.T1.1.13.12.9" class="ltx_td ltx_align_right ltx_border_bb">57.01</td>
<td id="S5.T1.1.13.12.10" class="ltx_td ltx_align_right ltx_border_bb">0.27</td>
<td id="S5.T1.1.13.12.11" class="ltx_td ltx_align_right ltx_border_bb">0.54</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p">Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Results ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the benchmark results on the FLAIR test set.
For the coarse-grained taxonomy, we observe that the performance gap between centralized and federated setting is about 20% on the per class metrics and 6% on the overall metrics if the models are trained from scratch.
These gaps are reduced to 8% and 2% if models are fine-tuned from pretrained ResNet.
When DP is applied, the per class metrics drop about 40% and overall metrics 24% from non-private federated learning if training from scratch.
When fine-tuning with DP, the drop is less significant, about 30% for per class metrics and 10% for overall metrics.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.1" class="ltx_p">For the fine-grained taxonomy, federated learning performance is much worse than the centralized baseline.
The gaps are around 90% and 50% for per-class and overall metrics regardless whether the model is trained from scratch or started from a pretrained model.
DP model has even worse performance compared to non-private one due to the extra noise introduced, which indicates long-tailed prediction tasks are especially hard in private federated learning setting due to the sparse label distribution among users.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Averaged precision for each coarse-grained class. C, FL, PFL stands for centralized, federated and private federated learning. R and F stands for training from scratch and fine-tuning. Columns are sorted by decreasing order of class frequency.</figcaption>
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.1.1.1" class="ltx_p" style="width:21.7pt;">Setting</span>
</span>
</th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.2.1.1" class="ltx_p" style="width:17.3pt;">struc-ture</span>
</span>
</th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.3.1.1" class="ltx_p" style="width:17.3pt;">equip-ment</span>
</span>
</th>
<th id="S5.T2.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.4.1.1" class="ltx_p" style="width:17.3pt;">mate-rial</span>
</span>
</th>
<th id="S5.T2.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.5.1.1" class="ltx_p" style="width:17.3pt;">out-door</span>
</span>
</th>
<th id="S5.T2.1.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.6.1.1" class="ltx_p" style="width:17.3pt;">plant</span>
</span>
</th>
<th id="S5.T2.1.1.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.7.1.1" class="ltx_p" style="width:17.3pt;">food</span>
</span>
</th>
<th id="S5.T2.1.1.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.8.1.1" class="ltx_p" style="width:17.3pt;">animal</span>
</span>
</th>
<th id="S5.T2.1.1.1.9" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.9.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.9.1.1" class="ltx_p" style="width:17.3pt;">liquid</span>
</span>
</th>
<th id="S5.T2.1.1.1.10" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.10.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.10.1.1" class="ltx_p" style="width:17.3pt;">art</span>
</span>
</th>
<th id="S5.T2.1.1.1.11" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.11.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.11.1.1" class="ltx_p" style="width:17.3pt;">interior room</span>
</span>
</th>
<th id="S5.T2.1.1.1.12" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.12.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.12.1.1" class="ltx_p" style="width:17.3pt;">light</span>
</span>
</th>
<th id="S5.T2.1.1.1.13" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.13.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.13.1.1" class="ltx_p" style="width:17.3pt;">recrea-tion</span>
</span>
</th>
<th id="S5.T2.1.1.1.14" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.14.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.14.1.1" class="ltx_p" style="width:17.3pt;">celeb-ration</span>
</span>
</th>
<th id="S5.T2.1.1.1.15" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.15.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.15.1.1" class="ltx_p" style="width:17.3pt;">fire</span>
</span>
</th>
<th id="S5.T2.1.1.1.16" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.16.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.16.1.1" class="ltx_p" style="width:17.3pt;">music</span>
</span>
</th>
<th id="S5.T2.1.1.1.17" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.17.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.17.1.1" class="ltx_p" style="width:17.3pt;">games</span>
</span>
</th>
<th id="S5.T2.1.1.1.18" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.1.1.18.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.18.1.1" class="ltx_p" style="width:17.3pt;">reli-gion</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.2.1" class="ltx_tr">
<th id="S5.T2.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.1.1.1" class="ltx_p" style="width:21.7pt;">C-R</span>
</span>
</th>
<td id="S5.T2.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.2.1.1" class="ltx_p" style="width:17.3pt;">90.1</span>
</span>
</td>
<td id="S5.T2.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.3.1.1" class="ltx_p" style="width:17.3pt;">92.8</span>
</span>
</td>
<td id="S5.T2.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.4.1.1" class="ltx_p" style="width:17.3pt;">66.9</span>
</span>
</td>
<td id="S5.T2.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.5.1.1" class="ltx_p" style="width:17.3pt;">95.1</span>
</span>
</td>
<td id="S5.T2.1.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.6.1.1" class="ltx_p" style="width:17.3pt;">93.0</span>
</span>
</td>
<td id="S5.T2.1.2.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.7.1.1" class="ltx_p" style="width:17.3pt;">95.0</span>
</span>
</td>
<td id="S5.T2.1.2.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.8.1.1" class="ltx_p" style="width:17.3pt;">87.0</span>
</span>
</td>
<td id="S5.T2.1.2.1.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.9.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.9.1.1" class="ltx_p" style="width:17.3pt;">78.6</span>
</span>
</td>
<td id="S5.T2.1.2.1.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.10.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.10.1.1" class="ltx_p" style="width:17.3pt;">43.0</span>
</span>
</td>
<td id="S5.T2.1.2.1.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.11.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.11.1.1" class="ltx_p" style="width:17.3pt;">65.5</span>
</span>
</td>
<td id="S5.T2.1.2.1.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.12.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.12.1.1" class="ltx_p" style="width:17.3pt;">35.6</span>
</span>
</td>
<td id="S5.T2.1.2.1.13" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.13.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.13.1.1" class="ltx_p" style="width:17.3pt;">30.2</span>
</span>
</td>
<td id="S5.T2.1.2.1.14" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.14.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.14.1.1" class="ltx_p" style="width:17.3pt;">36.2</span>
</span>
</td>
<td id="S5.T2.1.2.1.15" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.15.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.15.1.1" class="ltx_p" style="width:17.3pt;">63.4</span>
</span>
</td>
<td id="S5.T2.1.2.1.16" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.16.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.16.1.1" class="ltx_p" style="width:17.3pt;">14.8</span>
</span>
</td>
<td id="S5.T2.1.2.1.17" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.17.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.17.1.1" class="ltx_p" style="width:17.3pt;">19.6</span>
</span>
</td>
<td id="S5.T2.1.2.1.18" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.2.1.18.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.2.1.18.1.1" class="ltx_p" style="width:17.3pt;">19.9</span>
</span>
</td>
</tr>
<tr id="S5.T2.1.3.2" class="ltx_tr">
<th id="S5.T2.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.1.1.1" class="ltx_p" style="width:21.7pt;">FL-R</span>
</span>
</th>
<td id="S5.T2.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.2.1.1" class="ltx_p" style="width:17.3pt;">86.0</span>
</span>
</td>
<td id="S5.T2.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.3.1.1" class="ltx_p" style="width:17.3pt;">90.0</span>
</span>
</td>
<td id="S5.T2.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.4.1.1" class="ltx_p" style="width:17.3pt;">61.3</span>
</span>
</td>
<td id="S5.T2.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.5.1.1" class="ltx_p" style="width:17.3pt;">92.6</span>
</span>
</td>
<td id="S5.T2.1.3.2.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.6.1.1" class="ltx_p" style="width:17.3pt;">89.7</span>
</span>
</td>
<td id="S5.T2.1.3.2.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.7.1.1" class="ltx_p" style="width:17.3pt;">91.1</span>
</span>
</td>
<td id="S5.T2.1.3.2.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.8.1.1" class="ltx_p" style="width:17.3pt;">75.0</span>
</span>
</td>
<td id="S5.T2.1.3.2.9" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.9.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.9.1.1" class="ltx_p" style="width:17.3pt;">67.5</span>
</span>
</td>
<td id="S5.T2.1.3.2.10" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.10.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.10.1.1" class="ltx_p" style="width:17.3pt;">31.0</span>
</span>
</td>
<td id="S5.T2.1.3.2.11" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.11.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.11.1.1" class="ltx_p" style="width:17.3pt;">56.7</span>
</span>
</td>
<td id="S5.T2.1.3.2.12" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.12.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.12.1.1" class="ltx_p" style="width:17.3pt;">25.8</span>
</span>
</td>
<td id="S5.T2.1.3.2.13" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.13.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.13.1.1" class="ltx_p" style="width:17.3pt;">17.4</span>
</span>
</td>
<td id="S5.T2.1.3.2.14" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.14.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.14.1.1" class="ltx_p" style="width:17.3pt;">19.4</span>
</span>
</td>
<td id="S5.T2.1.3.2.15" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.15.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.15.1.1" class="ltx_p" style="width:17.3pt;">37.8</span>
</span>
</td>
<td id="S5.T2.1.3.2.16" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.16.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.16.1.1" class="ltx_p" style="width:17.3pt;">5.3</span>
</span>
</td>
<td id="S5.T2.1.3.2.17" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.17.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.17.1.1" class="ltx_p" style="width:17.3pt;">2.3</span>
</span>
</td>
<td id="S5.T2.1.3.2.18" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.3.2.18.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.3.2.18.1.1" class="ltx_p" style="width:17.3pt;">8.2</span>
</span>
</td>
</tr>
<tr id="S5.T2.1.4.3" class="ltx_tr">
<th id="S5.T2.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.1.1.1" class="ltx_p" style="width:21.7pt;">PFL-R</span>
</span>
</th>
<td id="S5.T2.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.2.1.1" class="ltx_p" style="width:17.3pt;">65.9</span>
</span>
</td>
<td id="S5.T2.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.3.1.1" class="ltx_p" style="width:17.3pt;">73.5</span>
</span>
</td>
<td id="S5.T2.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.4.1.1" class="ltx_p" style="width:17.3pt;">43.1</span>
</span>
</td>
<td id="S5.T2.1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.5.1.1" class="ltx_p" style="width:17.3pt;">77.3</span>
</span>
</td>
<td id="S5.T2.1.4.3.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.6.1.1" class="ltx_p" style="width:17.3pt;">65.9</span>
</span>
</td>
<td id="S5.T2.1.4.3.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.7.1.1" class="ltx_p" style="width:17.3pt;">67.7</span>
</span>
</td>
<td id="S5.T2.1.4.3.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.8.1.1" class="ltx_p" style="width:17.3pt;">26.1</span>
</span>
</td>
<td id="S5.T2.1.4.3.9" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.9.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.9.1.1" class="ltx_p" style="width:17.3pt;">34.6</span>
</span>
</td>
<td id="S5.T2.1.4.3.10" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.10.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.10.1.1" class="ltx_p" style="width:17.3pt;">10.8</span>
</span>
</td>
<td id="S5.T2.1.4.3.11" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.11.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.11.1.1" class="ltx_p" style="width:17.3pt;">12.8</span>
</span>
</td>
<td id="S5.T2.1.4.3.12" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.12.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.12.1.1" class="ltx_p" style="width:17.3pt;">5.3</span>
</span>
</td>
<td id="S5.T2.1.4.3.13" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.13.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.13.1.1" class="ltx_p" style="width:17.3pt;">2.5</span>
</span>
</td>
<td id="S5.T2.1.4.3.14" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.14.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.14.1.1" class="ltx_p" style="width:17.3pt;">1.2</span>
</span>
</td>
<td id="S5.T2.1.4.3.15" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.15.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.15.1.1" class="ltx_p" style="width:17.3pt;">1.7</span>
</span>
</td>
<td id="S5.T2.1.4.3.16" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.16.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.16.1.1" class="ltx_p" style="width:17.3pt;">0.7</span>
</span>
</td>
<td id="S5.T2.1.4.3.17" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.17.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.17.1.1" class="ltx_p" style="width:17.3pt;">0.3</span>
</span>
</td>
<td id="S5.T2.1.4.3.18" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.4.3.18.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.4.3.18.1.1" class="ltx_p" style="width:17.3pt;">0.2</span>
</span>
</td>
</tr>
<tr id="S5.T2.1.5.4" class="ltx_tr">
<th id="S5.T2.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.1.1.1" class="ltx_p" style="width:21.7pt;">C-F</span>
</span>
</th>
<td id="S5.T2.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.2.1.1" class="ltx_p" style="width:17.3pt;">92.5</span>
</span>
</td>
<td id="S5.T2.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.3.1.1" class="ltx_p" style="width:17.3pt;">94.6</span>
</span>
</td>
<td id="S5.T2.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.4.1.1" class="ltx_p" style="width:17.3pt;">70.8</span>
</span>
</td>
<td id="S5.T2.1.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.5.1.1" class="ltx_p" style="width:17.3pt;">96.3</span>
</span>
</td>
<td id="S5.T2.1.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.6.1.1" class="ltx_p" style="width:17.3pt;">94.0</span>
</span>
</td>
<td id="S5.T2.1.5.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.7.1.1" class="ltx_p" style="width:17.3pt;">96.6</span>
</span>
</td>
<td id="S5.T2.1.5.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.8.1.1" class="ltx_p" style="width:17.3pt;">93.5</span>
</span>
</td>
<td id="S5.T2.1.5.4.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.9.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.9.1.1" class="ltx_p" style="width:17.3pt;">84.5</span>
</span>
</td>
<td id="S5.T2.1.5.4.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.10.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.10.1.1" class="ltx_p" style="width:17.3pt;">55.5</span>
</span>
</td>
<td id="S5.T2.1.5.4.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.11.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.11.1.1" class="ltx_p" style="width:17.3pt;">71.4</span>
</span>
</td>
<td id="S5.T2.1.5.4.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.12.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.12.1.1" class="ltx_p" style="width:17.3pt;">40.8</span>
</span>
</td>
<td id="S5.T2.1.5.4.13" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.13.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.13.1.1" class="ltx_p" style="width:17.3pt;">41.1</span>
</span>
</td>
<td id="S5.T2.1.5.4.14" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.14.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.14.1.1" class="ltx_p" style="width:17.3pt;">46.5</span>
</span>
</td>
<td id="S5.T2.1.5.4.15" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.15.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.15.1.1" class="ltx_p" style="width:17.3pt;">70.3</span>
</span>
</td>
<td id="S5.T2.1.5.4.16" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.16.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.16.1.1" class="ltx_p" style="width:17.3pt;">39.3</span>
</span>
</td>
<td id="S5.T2.1.5.4.17" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.17.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.17.1.1" class="ltx_p" style="width:17.3pt;">42.4</span>
</span>
</td>
<td id="S5.T2.1.5.4.18" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.5.4.18.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.5.4.18.1.1" class="ltx_p" style="width:17.3pt;">21.1</span>
</span>
</td>
</tr>
<tr id="S5.T2.1.6.5" class="ltx_tr">
<th id="S5.T2.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.1.1.1" class="ltx_p" style="width:21.7pt;">FL-F</span>
</span>
</th>
<td id="S5.T2.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.2.1.1" class="ltx_p" style="width:17.3pt;">91.2</span>
</span>
</td>
<td id="S5.T2.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.3.1.1" class="ltx_p" style="width:17.3pt;">93.6</span>
</span>
</td>
<td id="S5.T2.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.4.1.1" class="ltx_p" style="width:17.3pt;">68.8</span>
</span>
</td>
<td id="S5.T2.1.6.5.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.5.1.1" class="ltx_p" style="width:17.3pt;">95.6</span>
</span>
</td>
<td id="S5.T2.1.6.5.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.6.1.1" class="ltx_p" style="width:17.3pt;">92.7</span>
</span>
</td>
<td id="S5.T2.1.6.5.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.7.1.1" class="ltx_p" style="width:17.3pt;">95.7</span>
</span>
</td>
<td id="S5.T2.1.6.5.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.8.1.1" class="ltx_p" style="width:17.3pt;">90.2</span>
</span>
</td>
<td id="S5.T2.1.6.5.9" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.9.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.9.1.1" class="ltx_p" style="width:17.3pt;">79.5</span>
</span>
</td>
<td id="S5.T2.1.6.5.10" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.10.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.10.1.1" class="ltx_p" style="width:17.3pt;">48.6</span>
</span>
</td>
<td id="S5.T2.1.6.5.11" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.11.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.11.1.1" class="ltx_p" style="width:17.3pt;">68.4</span>
</span>
</td>
<td id="S5.T2.1.6.5.12" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.12.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.12.1.1" class="ltx_p" style="width:17.3pt;">34.5</span>
</span>
</td>
<td id="S5.T2.1.6.5.13" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.13.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.13.1.1" class="ltx_p" style="width:17.3pt;">18.3</span>
</span>
</td>
<td id="S5.T2.1.6.5.14" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.14.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.14.1.1" class="ltx_p" style="width:17.3pt;">35.0</span>
</span>
</td>
<td id="S5.T2.1.6.5.15" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.15.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.15.1.1" class="ltx_p" style="width:17.3pt;">61.1</span>
</span>
</td>
<td id="S5.T2.1.6.5.16" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.16.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.16.1.1" class="ltx_p" style="width:17.3pt;">15.5</span>
</span>
</td>
<td id="S5.T2.1.6.5.17" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.17.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.17.1.1" class="ltx_p" style="width:17.3pt;">17.0</span>
</span>
</td>
<td id="S5.T2.1.6.5.18" class="ltx_td ltx_align_justify ltx_align_top" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.6.5.18.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.6.5.18.1.1" class="ltx_p" style="width:17.3pt;">7.6</span>
</span>
</td>
</tr>
<tr id="S5.T2.1.7.6" class="ltx_tr">
<th id="S5.T2.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.1.1.1" class="ltx_p" style="width:21.7pt;">PFL-F</span>
</span>
</th>
<td id="S5.T2.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.2.1.1" class="ltx_p" style="width:17.3pt;">84.1</span>
</span>
</td>
<td id="S5.T2.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.3.1.1" class="ltx_p" style="width:17.3pt;">88.4</span>
</span>
</td>
<td id="S5.T2.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.4.1.1" class="ltx_p" style="width:17.3pt;">56.3</span>
</span>
</td>
<td id="S5.T2.1.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.5.1.1" class="ltx_p" style="width:17.3pt;">89.6</span>
</span>
</td>
<td id="S5.T2.1.7.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.6.1.1" class="ltx_p" style="width:17.3pt;">86.3</span>
</span>
</td>
<td id="S5.T2.1.7.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.7.1.1" class="ltx_p" style="width:17.3pt;">89.8</span>
</span>
</td>
<td id="S5.T2.1.7.6.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.8.1.1" class="ltx_p" style="width:17.3pt;">76.8</span>
</span>
</td>
<td id="S5.T2.1.7.6.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.9.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.9.1.1" class="ltx_p" style="width:17.3pt;">56.7</span>
</span>
</td>
<td id="S5.T2.1.7.6.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.10.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.10.1.1" class="ltx_p" style="width:17.3pt;">25.1</span>
</span>
</td>
<td id="S5.T2.1.7.6.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.11.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.11.1.1" class="ltx_p" style="width:17.3pt;">52.5</span>
</span>
</td>
<td id="S5.T2.1.7.6.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.12.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.12.1.1" class="ltx_p" style="width:17.3pt;">17.9</span>
</span>
</td>
<td id="S5.T2.1.7.6.13" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.13.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.13.1.1" class="ltx_p" style="width:17.3pt;">4.0</span>
</span>
</td>
<td id="S5.T2.1.7.6.14" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.14.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.14.1.1" class="ltx_p" style="width:17.3pt;">3.9</span>
</span>
</td>
<td id="S5.T2.1.7.6.15" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.15.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.15.1.1" class="ltx_p" style="width:17.3pt;">18.6</span>
</span>
</td>
<td id="S5.T2.1.7.6.16" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.16.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.16.1.1" class="ltx_p" style="width:17.3pt;">2.0</span>
</span>
</td>
<td id="S5.T2.1.7.6.17" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.17.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.17.1.1" class="ltx_p" style="width:17.3pt;">0.2</span>
</span>
</td>
<td id="S5.T2.1.7.6.18" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="S5.T2.1.7.6.18.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.7.6.18.1.1" class="ltx_p" style="width:17.3pt;">0.7</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.p3.1" class="ltx_p">Table <a href="#S5.T2" title="Table 2 ‣ 5.2 Results ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes averaged precision scores on FLAIR test set for each class in the coarse-grained taxonomy.
The performances are different for different classes and there is a positive correlation between the frequency of the class and its performance.
Noticeably, the gaps between classes are enlarged if models are trained with federated learning and DP.
For instance, the gap between <span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_italic">recreation</span> and <span id="S5.SS2.p3.1.2" class="ltx_text ltx_font_italic">outdoor</span> is about 68% in centralized setting while the gap increases to 81% in the federated setting and 96% in the federated setting with DP.
In other words, the decrease in performance is worse for classes that are less frequent in federated learning, especially when DP is applied. This observation was also noted in prior works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para ltx_noindent">
<p id="S5.SS2.p4.1" class="ltx_p"><span id="S5.SS2.p4.1.1" class="ltx_text ltx_font_bold">Effect of cohort size on PFL.</span>
As described in Section <a href="#S5.SS1" title="5.1 Benchmark setups ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>, cohort size controls the noise-level of PFL, and thus we further examine the impact of cohort size on the performance of DP models.
Figure <a href="#S5.F4" title="Figure 4 ‣ 5.2 Results ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the per-class AP on the validation set in different rounds of PFL training.
For both training from scratch and fine-tuning, increasing cohort size yields faster and better generalization.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2207.08869/assets/assets/experiment-plot/cohort_random.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="287" height="213" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2207.08869/assets/assets/experiment-plot/cohort_finetune.png" id="S5.F4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="287" height="213" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Effect of cohort size in PFL training. x-axis is the number of rounds of federated learning and y-axis is the per-class AP on the validation set.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Research directions</h3>

<div id="S6.SS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.p1.1" class="ltx_p"><span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_bold">Imbalanced classes.</span> For the coarse-grained taxonomy, models performed differently on different classes and the performance is correlated to the frequency of the class.
This difference is enlarged in federated learning, especially when DP is applied, indicating that the heterogeneity and DP noise worsened the imbalance problem.
Given its heterogeneous nature, we believe FLAIR is a suitable dataset with which researchers can study the class imbalance problem in the distributed setting.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS1.p2.1" class="ltx_p"><span id="S6.SS1.p2.1.1" class="ltx_text ltx_font_bold">Few-shot and zero-shot federated learning.</span> As demonstrated in Section <a href="#S5.SS2" title="5.2 Results ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>, federated learning models perform worse on FLAIR fine-grained taxonomy compared to coarse-grained.
Out of 1,628 fine-grained classes, 11 present in the validation and test dataset are unseen and 134 have less than 20 positive examples in the training set.
Predicting these few-shot and zero-shot labels can be very difficult even in the centralized training setting.
Indeed the signals for the tail classes in fine-grained taxonomy are extremely sparse and the sparsity is strengthened in federated learning as the infrequent classes are concentrated in only a few users.
Furthermore, DP exacerbates the performance of infrequent classes due to poor SNR of sparse gradients.
We believe the long-tailed label distribution in FLAIR fosters research interests in few-shot and zero-shot learning in the private federated setting.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS1.p3.1" class="ltx_p"><span id="S6.SS1.p3.1.1" class="ltx_text ltx_font_bold">Noise-robust and efficient federated learning with DP.</span>
As shown in Figure <a href="#S5.F4" title="Figure 4 ‣ 5.2 Results ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the larger the cohort size, the smaller the noise on the aggregated model updates and thus the better the model when trained with DP, especially for deep neural networks with tens of millions of parameters.
Larger cohorts increase the latency of federated learning with DP and may become impractical when the number of iterations required to converge is also large.
We believe the scale and complexity of FLAIR will inspire research in designing model architectures and optimization algorithms which are more robust to DP noise and also more efficient to train.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para ltx_noindent">
<p id="S6.SS1.p4.1" class="ltx_p"><span id="S6.SS1.p4.1.1" class="ltx_text ltx_font_bold">Personalization.</span>
Personalization in federated learning is an active research area as a single model is unlikely to generalize equally well among all users.
Meta learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and local adaptation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> are some of the attractive approaches for personalized federated learning.
We did not benchmark FLAIR with personalization in this work and leave it for future works.</p>
</div>
<div id="S6.SS1.p5" class="ltx_para ltx_noindent">
<p id="S6.SS1.p5.1" class="ltx_p"><span id="S6.SS1.p5.1.1" class="ltx_text ltx_font_bold">Advanced vision models.</span>
As an initial benchmark, we only explored one model architecture, ResNet18.
There are many more advanced architectures or pretrained models such as vision transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, SimCLR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, or CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> that we did not use for experiments.
It is also an interesting research topic to search for the optimal model architectures in federated learning with DP.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Limitations</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.p1.1" class="ltx_p">Due to our strict filtering criteria, images with faces or identifiable human bodies are removed from FLAIR.
Thus, FLAIR is not suitable for any facial recognition or person identification vision tasks.
This filtering also reduced the size of the dataset, and may have changed the distributions of the number of images per user.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.1" class="ltx_p">More generally, Federated Learning applications are diverse and various heterogeneity properties can vary a lot across applications. Any single dataset thus will not accurately represent all relevant properties of a specific application. Evaluating algorithms on a collection of datasets is thus important.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">In this work, we presented FLAIR, a large-scale image dataset suitable for federated learning.
We compared FLAIR with existing federated learning image datasets and discussed the advantages of FLAIR.
We described how the images in FLAIR were curated and annotated.
We provided reproducible benchmarks for centralized, federated and differentially private settings.
We have open-sourced both the FLAIR dataset and the benchmark code for the community to use with the aim of in advancing the research in federated learning.</p>
</div>
<section id="S7.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Acknowledgement</h3>

<div id="S7.SSx1.p1" class="ltx_para ltx_noindent">
<p id="S7.SSx1.p1.1" class="ltx_p">We thank Flickr and the Flickr community for providing the set of images that made this dataset possible; Ulfar Erlingsson and Matt Seigel for their guidance during the early stages of this project; Yasmin Alameddine and Sophie Ostlund for their invaluable help throughout the project; multiple annotators for helping filter the dataset; Hanlin Goh and Aine Cahill for valuable feedback on the paper draft; Arjun Rangarajan, Plamena Gerovska, Katy Linksy, Wonhee Park, Vojta Jina, Mona Chitnis, Yulia Shuvkashvili, Julien Freudiger, Rogier van Dalen, Abhishek Bhowmick, Hillary Strickland, Subhash Sudan, Mya Exum, Laura Snarr, Guillaume Tartavel, Piotr Maj, Laurent Duchesne and Mark Faridani for their help with this effort.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Flickr.

</span>
<span class="ltx_bibblock"><a href="flickr.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">flickr.com</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal
Talwar, and Li Zhang.

</span>
<span class="ltx_bibblock">Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2016 ACM SIGSAC conference on computer
and communications security (CCS)</span>, pages 308–318, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Galen Andrew, Om Thakkar, Brendan McMahan, and Swaroop Ramaswamy.

</span>
<span class="ltx_bibblock">Differentially private learning with adaptive clipping.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 34, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
The TensorFlow Federated Authors.

</span>
<span class="ltx_bibblock">Tensorflow federated stack overflow dataset.
<a target="_blank" href="https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/stackoverflow/load_data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/stackoverflow/load_data</a>,
2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan, Omid Poursaeed, and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Differential privacy has disparate impact on model accuracy.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 32, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub
Konečnỳ, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.01097</span>, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">A simple framework for contrastive learning of visual
representations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages
1597–1607. PMLR, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.

</span>
<span class="ltx_bibblock">Imagenet: A large-scale hierarchical image database.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">2009 IEEE Conference on Computer Vision and Pattern
Recognition</span>, pages 248–255, 2009.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.

</span>
<span class="ltx_bibblock">Imagenet: A large-scale hierarchical image database.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">2009 IEEE conference on computer vision and pattern
recognition</span>, pages 248–255. Ieee, 2009.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi.

</span>
<span class="ltx_bibblock">Adaptive personalized federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.13461</span>, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et al.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at
scale.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.

</span>
<span class="ltx_bibblock">Calibrating noise to sensitivity in private data analysis.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Theory of cryptography conference</span>, pages 265–284. Springer,
2006.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.

</span>
<span class="ltx_bibblock">Personalized federated learning: A meta-learning approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.07948</span>, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Chelsea Finn, Pieter Abbeel, and Sergey Levine.

</span>
<span class="ltx_bibblock">Model-agnostic meta-learning for fast adaptation of deep networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages
1126–1135. PMLR, 2017.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Alec Go, Richa Bhayani, and Lei Huang.

</span>
<span class="ltx_bibblock">Twitter sentiment classification using distant supervision.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Filip Granqvist, Matt Seigel, Rogier van Dalen, Áine Cahill, Stephen Shum,
and Matthias Paulik.

</span>
<span class="ltx_bibblock">Improving on-device speaker verification using federated learning
with privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2008.02651</span>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Françoise
Beaufays, Sean Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel
Ramage.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1811.03604</span>, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, Mi Zhang, Hongyi Wang, Xiaoyang
Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, et al.

</span>
<span class="ltx_bibblock">Fedml: A research library and benchmark for federated machine
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.13518</span>, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 770–778, 2016.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.

</span>
<span class="ltx_bibblock">Measuring the effects of non-identical data distribution for
federated visual classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.06335</span>, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.

</span>
<span class="ltx_bibblock">Federated visual classification with real-world data distribution.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, pages 76–92.
Springer, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Sixu Hu, Yuan Li, Xu Liu, Qinbin Li, Zhaomin Wu, and Bingsheng He.

</span>
<span class="ltx_bibblock">The oarf benchmark suite: Characterization and implications for
federated learning systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.07856</span>, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Sergey Ioffe and Christian Szegedy.

</span>
<span class="ltx_bibblock">Batch normalization: Accelerating deep network training by reducing
internal covariate shift.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">International conference on machine learning</span>, pages
448–456. PMLR, 2015.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
Cormode, Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Foundations and Trends® in Machine Learning</span>,
14(1–2):1–210, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Diederik P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2015.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">2009.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Fan Lai, Yinwei Dai, Xiangfeng Zhu, Harsha V Madhyastha, and Mosharaf
Chowdhury.

</span>
<span class="ltx_bibblock">Fedscale: Benchmarking model and system performance of federated
learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Proceedings of the First Workshop on Systems Challenges in
Reliable and Secure Federated Learning</span>, pages 1–3, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum.

</span>
<span class="ltx_bibblock">Human-level concept learning through probabilistic program induction.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Science</span>, 350(6266):1332–1338, 2015.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Yann LeCun.

</span>
<span class="ltx_bibblock">The mnist database of handwritten digits.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">http://yann. lecun. com/exdb/mnist/</span>, 1998.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.

</span>
<span class="ltx_bibblock">Deep learning face attributes in the wild.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Proceedings of International Conference on Computer Vision
(ICCV)</span>, December 2015.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Agüera y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics (AISTATS)</span>, pages 1273–1282. PMLR,
2017.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Brendan McMahan and Abhradeep Thakurta.

</span>
<span class="ltx_bibblock">Federated learning with formal differential privacy guarantees.
google ai blog, 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ai.googleblog.com/2022/02/federated-learning-with-formal.html%5BAccessed:Jun2022%5D" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ai.googleblog.com/2022/02/federated-learning-with-formal.html[Accessed:Jun2022]</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang.

</span>
<span class="ltx_bibblock">Learning differentially private recurrent language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Exploiting unintended feature leakage in collaborative learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">2019 IEEE Symposium on Security and Privacy (SP)</span>, pages
691–706. IEEE, 2019.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language
supervision.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
8748–8763. PMLR, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.

</span>
<span class="ltx_bibblock">Do imagenet classifiers generalize to imagenet?

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
5389–5400. PMLR, 2019.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
Jakub Konečnỳ, Sanjiv Kumar, and H Brendan McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.00295</span>, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Congzheng Song and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Auditing data provenance in text-generation models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery &amp; Data Mining</span>, pages 196–206, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al.

</span>
<span class="ltx_bibblock">Matching networks for one shot learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 29, 2016.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge
Belongie.

</span>
<span class="ltx_bibblock">The caltech-ucsd birds-200-2011 dataset.

</span>
<span class="ltx_bibblock">2011.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Yuxin Wu and Kaiming He.

</span>
<span class="ltx_bibblock">Group normalization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Proceedings of the European conference on computer vision
(ECCV)</span>, pages 3–19, 2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Tao Yu, Eugene Bagdasaryan, and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Salvaging federated learning by local adaptation.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.04758</span>, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Ligeng Zhu, Zhijian Liu, and Song Han.

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 32, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Datasheets for FLAIR Dataset</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Motivation</h3>

<div id="A1.SS1.p1" class="ltx_para ltx_noindent">
<p id="A1.SS1.p1.1" class="ltx_p">The questions in this section are primarily intended to encourage
dataset creators to clearly articulate their reasons for creating the
dataset and to promote transparency about funding interests.
The latter may be particularly relevant for datasets created for
research purposes.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para ltx_noindent">
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I1.i1.p1.1" class="ltx_p"><span id="A1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">For what purpose was the dataset created?</span> Was there a specific task in mind? Was there a specific gap that needed to be filled? Please provide a description.

<br class="ltx_break"><span id="A1.I1.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">FLAIR dataset was created for the purpose of providing the community a benchmark in the vision domain to accelerate federated learning research.
FLAIR is suitable for multi-label image classification tasks, where the input is an image and output is a set of objects presented in the image.</span></p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I1.i2.p1.1" class="ltx_p"><span id="A1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)?</span>

<br class="ltx_break"><span id="A1.I1.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Apple ML privacy team and ML research team created dataset on behalf of Apple Inc.</span></p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I1.i3.p1.1" class="ltx_p"><span id="A1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Who funded the creation of the dataset?</span> If there is an associated grant, please provide the name of the grantor and the grant name and number.

<br class="ltx_break"><span id="A1.I1.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Apple Inc.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Composition</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS2.p1.1" class="ltx_p">Dataset creators should read through these questions prior to
any data collection and then provide answers once data collection is
complete. Most of the questions in this section are intended to
provide dataset consumers with the information they need to make
informed decisions about using the dataset for their chosen
tasks. Some of the questions are designed to elicit information
about compliance with the EU’s General Data Protection Regulation
(GDPR) or comparable regulations in other jurisdictions.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para ltx_noindent">
<p id="A1.SS2.p2.1" class="ltx_p">Questions that apply only to datasets that relate to people are
grouped together at the end of the section. We recommend taking a
broad interpretation of whether a dataset relates to people. For
example, any dataset containing text that was written by people
relates to people.</p>
</div>
<div id="A1.SS2.p3" class="ltx_para ltx_noindent">
<ul id="A1.I2" class="ltx_itemize">
<li id="A1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i1.p1.1" class="ltx_p"><span id="A1.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">What do the instances that comprise the dataset
represent (e.g., documents, photos, people, countries)?</span> Are there
multiple types of instances (e.g., movies, users, and ratings;
people and interactions between them; nodes and edges)? Please
provide a description.

<br class="ltx_break"><span id="A1.I2.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The instances are Flickr images with annotation and metadata. </span></p>
</div>
</li>
<li id="A1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i2.p1.1" class="ltx_p"><span id="A1.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">How many instances are there in total (of each type, if appropriate)?</span>

<br class="ltx_break"><span id="A1.I2.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">There are 429,078 images in total.</span></p>
</div>
</li>
<li id="A1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i3.p1.1" class="ltx_p"><span id="A1.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Does the dataset contain all possible instances or is it
a sample (not necessarily random) of instances from a larger set?</span>
If the dataset is a sample, then what is the larger set? Is the
sample representative of the larger set (e.g., geographic coverage)?
If so, please describe how this representativeness was
validated/verified. If it is not representative of the larger set,
please describe why not (e.g., to cover a more diverse range of
instances, because instances were withheld or unavailable).

<br class="ltx_break"><span id="A1.I2.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The instances in FLAIR dataset is a subset of the larger set, which is all Flickr images.
Not all Flickr images are suitable for research use, i.e. images with personal identifiable information and images without permissive license were excluded. </span></p>
</div>
</li>
<li id="A1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i4.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i4.p1.1" class="ltx_p"><span id="A1.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">What data does each instance consist of?</span> “Raw” data
(e.g., unprocessed text or images) or features? In either case,
please provide a description.

<br class="ltx_break"><span id="A1.I2.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Each instance consists of an image.</span></p>
</div>
</li>
<li id="A1.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i5.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i5.p1.1" class="ltx_p"><span id="A1.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">Is there a label or target associated with each
instance?</span> If so, please provide a description.

<br class="ltx_break"><span id="A1.I2.i5.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Each image has two sets of annotated labels from two taxonomies. Each image also has the associated Flickr user ID and image ID.</span></p>
</div>
</li>
<li id="A1.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i6.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i6.p1.1" class="ltx_p"><span id="A1.I2.i6.p1.1.1" class="ltx_text ltx_font_bold">Is any information missing from individual instances?</span>
If so, please provide a description, explaining why this information
is missing (e.g., because it was unavailable). This does not include
intentionally removed information, but might include, e.g., redacted
text.

<br class="ltx_break"><span id="A1.I2.i6.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No.</span></p>
</div>
</li>
<li id="A1.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i7.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i7.p1.1" class="ltx_p"><span id="A1.I2.i7.p1.1.1" class="ltx_text ltx_font_bold">Are relationships between individual instances made
explicit (e.g., users’ movie ratings, social network links)?</span> If
so, please describe how these relationships are made explicit.

<br class="ltx_break"><span id="A1.I2.i7.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Yes, individual images from the same Flickr user have the same Flickr user ID.</span></p>
</div>
</li>
<li id="A1.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i8.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i8.p1.3" class="ltx_p"><span id="A1.I2.i8.p1.3.4" class="ltx_text ltx_font_bold">Are there recommended data splits (e.g., training,
development/validation, testing)?</span> If so, please provide a
description of these splits, explaining the rationale behind them.

<br class="ltx_break"><span id="A1.I2.i8.p1.3.3" class="ltx_text" style="color:#1A0DF5;">Yes.
FLAIR data is partitioned based on Flickr user IDs, such that the data of a particular user is present in only one of three splits.
Out of 51,414 Flickr users, <math id="A1.I2.i8.p1.1.1.m1.1" class="ltx_Math" alttext="80\%" display="inline"><semantics id="A1.I2.i8.p1.1.1.m1.1a"><mrow id="A1.I2.i8.p1.1.1.m1.1.1" xref="A1.I2.i8.p1.1.1.m1.1.1.cmml"><mn mathcolor="#1A0DF5" id="A1.I2.i8.p1.1.1.m1.1.1.2" xref="A1.I2.i8.p1.1.1.m1.1.1.2.cmml">80</mn><mo mathcolor="#1A0DF5" id="A1.I2.i8.p1.1.1.m1.1.1.1" xref="A1.I2.i8.p1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.I2.i8.p1.1.1.m1.1b"><apply id="A1.I2.i8.p1.1.1.m1.1.1.cmml" xref="A1.I2.i8.p1.1.1.m1.1.1"><csymbol cd="latexml" id="A1.I2.i8.p1.1.1.m1.1.1.1.cmml" xref="A1.I2.i8.p1.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A1.I2.i8.p1.1.1.m1.1.1.2.cmml" xref="A1.I2.i8.p1.1.1.m1.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i8.p1.1.1.m1.1c">80\%</annotation></semantics></math> are in the training set, <math id="A1.I2.i8.p1.2.2.m2.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="A1.I2.i8.p1.2.2.m2.1a"><mrow id="A1.I2.i8.p1.2.2.m2.1.1" xref="A1.I2.i8.p1.2.2.m2.1.1.cmml"><mn mathcolor="#1A0DF5" id="A1.I2.i8.p1.2.2.m2.1.1.2" xref="A1.I2.i8.p1.2.2.m2.1.1.2.cmml">10</mn><mo mathcolor="#1A0DF5" id="A1.I2.i8.p1.2.2.m2.1.1.1" xref="A1.I2.i8.p1.2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.I2.i8.p1.2.2.m2.1b"><apply id="A1.I2.i8.p1.2.2.m2.1.1.cmml" xref="A1.I2.i8.p1.2.2.m2.1.1"><csymbol cd="latexml" id="A1.I2.i8.p1.2.2.m2.1.1.1.cmml" xref="A1.I2.i8.p1.2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="A1.I2.i8.p1.2.2.m2.1.1.2.cmml" xref="A1.I2.i8.p1.2.2.m2.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i8.p1.2.2.m2.1c">10\%</annotation></semantics></math> in the validation set and <math id="A1.I2.i8.p1.3.3.m3.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="A1.I2.i8.p1.3.3.m3.1a"><mrow id="A1.I2.i8.p1.3.3.m3.1.1" xref="A1.I2.i8.p1.3.3.m3.1.1.cmml"><mn mathcolor="#1A0DF5" id="A1.I2.i8.p1.3.3.m3.1.1.2" xref="A1.I2.i8.p1.3.3.m3.1.1.2.cmml">10</mn><mo mathcolor="#1A0DF5" id="A1.I2.i8.p1.3.3.m3.1.1.1" xref="A1.I2.i8.p1.3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.I2.i8.p1.3.3.m3.1b"><apply id="A1.I2.i8.p1.3.3.m3.1.1.cmml" xref="A1.I2.i8.p1.3.3.m3.1.1"><csymbol cd="latexml" id="A1.I2.i8.p1.3.3.m3.1.1.1.cmml" xref="A1.I2.i8.p1.3.3.m3.1.1.1">percent</csymbol><cn type="integer" id="A1.I2.i8.p1.3.3.m3.1.1.2.cmml" xref="A1.I2.i8.p1.3.3.m3.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i8.p1.3.3.m3.1c">10\%</annotation></semantics></math> in the test set.
There are 345,879 images in total in the training set, 39,239 in the validation set and 43,960 in the test set.</span></p>
</div>
</li>
<li id="A1.I2.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i9.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i9.p1.1" class="ltx_p"><span id="A1.I2.i9.p1.1.1" class="ltx_text ltx_font_bold">Are there any errors, sources of noise, or redundancies
in the dataset?</span> If so, please provide a description.

<br class="ltx_break"><span id="A1.I2.i9.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I2.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i10.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i10.p1.1" class="ltx_p"><span id="A1.I2.i10.p1.1.1" class="ltx_text ltx_font_bold">Is the dataset self-contained, or does it link to or
otherwise rely on external resources (e.g., websites, tweets,
other datasets)?</span> If it links to or relies on external resources,
a) are there guarantees that they will exist, and remain constant,
over time; b) are there official archival versions of the complete
dataset (i.e., including the external resources as they existed at
the time the dataset was created); c) are there any restrictions
(e.g., licenses, fees) associated with any of the external
resources that might apply to a dataset consumer? Please provide
descriptions of all external resources and any restrictions
associated with them, as well as links or other access points, as
appropriate.

<br class="ltx_break"><span id="A1.I2.i10.p1.1.2" class="ltx_text" style="color:#1A0DF5;">FLAIR is self-contained.</span></p>
</div>
</li>
<li id="A1.I2.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i11.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i11.p1.1" class="ltx_p"><span id="A1.I2.i11.p1.1.1" class="ltx_text ltx_font_bold">Does the dataset contain data that might be considered
confidential (e.g., data that is protected by legal privilege or
by doctor–patient confidentiality, data that includes the content
of individuals’ non-public communications)?</span> If so, please provide
a description.

<br class="ltx_break"><span id="A1.I2.i11.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No.</span></p>
</div>
</li>
<li id="A1.I2.i12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i12.p1" class="ltx_para ltx_noindent">
<p id="A1.I2.i12.p1.1" class="ltx_p"><span id="A1.I2.i12.p1.1.1" class="ltx_text ltx_font_bold">Does the dataset contain data that, if viewed directly,
might be offensive, insulting, threatening, or might otherwise
cause anxiety?</span> If so, please describe why.

<br class="ltx_break"><span id="A1.I2.i12.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No. Images with offensive and other inappropriate materials have been removed from FLAIR.</span></p>
</div>
</li>
</ul>
</div>
<div id="A1.SS2.p4" class="ltx_para ltx_noindent">
<p id="A1.SS2.p4.1" class="ltx_p">If the dataset does not relate to people, you may skip the remaining questions in this section.</p>
</div>
<div id="A1.SS2.p5" class="ltx_para ltx_noindent">
<ul id="A1.I3" class="ltx_itemize">
<li id="A1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I3.i1.p1.1" class="ltx_p"><span id="A1.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Does the dataset identify any subpopulations (e.g., by
age, gender)?</span> If so, please describe how these subpopulations are
identified and provide a description of their respective
distributions within the dataset.

<br class="ltx_break"><span id="A1.I3.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">FLAIR data is only annotated with the Flickr user id and does not explicitly identify any traits.</span></p>
</div>
</li>
<li id="A1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I3.i2.p1.1" class="ltx_p"><span id="A1.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Is it possible to identify individuals (i.e., one or
more natural persons), either directly or indirectly (i.e., in
combination with other data) from the dataset?</span> If so, please
describe how.

<br class="ltx_break"><span id="A1.I3.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No. Images with personal identifiable information have been removed from FLAIR.</span></p>
</div>
</li>
<li id="A1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I3.i3.p1.1" class="ltx_p"><span id="A1.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Does the dataset contain data that might be considered
sensitive in any way (e.g., data that reveals race or ethnic
origins, sexual orientations, religious beliefs, political
opinions or union memberships, or locations; financial or health
data; biometric or genetic data; forms of government
identification, such as social security numbers; criminal
history)?</span> If so, please provide a description.

<br class="ltx_break"><span id="A1.I3.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Collection Process</h3>

<div id="A1.SS3.p1" class="ltx_para ltx_noindent">
<p id="A1.SS3.p1.1" class="ltx_p">As with the questions in the previous section, dataset creators should
read through these questions prior to any data collection to flag
potential issues and then provide answers once collection is complete.
In addition to the goals outlined in the previous section, the
questions in this section are designed to elicit information that may
help researchers and practitioners to create alternative datasets with
similar characteristics. Again, questions that apply only to datasets
that relate to people are grouped together at the end of the
section.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para ltx_noindent">
<ul id="A1.I4" class="ltx_itemize">
<li id="A1.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I4.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I4.i1.p1.1" class="ltx_p"><span id="A1.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">How was the data associated with each instance
acquired?</span> Was the data directly observable (e.g., raw text, movie
ratings), reported by subjects (e.g., survey responses), or
indirectly inferred/derived from other data (e.g., part-of-speech
tags, model-based guesses for age or language)? If the data was reported
by subjects or indirectly inferred/derived from other data, was the
data validated/verified? If so, please describe how.

<br class="ltx_break"><span id="A1.I4.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Images and associated image ID and user ID were acquired from the Flickr website. The data was directly observable.</span></p>
</div>
</li>
<li id="A1.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I4.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I4.i2.p1.1" class="ltx_p"><span id="A1.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">What mechanisms or procedures were used to collect the
data (e.g., hardware apparatuses or sensors, manual human
curation, software programs, software APIs)?</span> How were these
mechanisms or procedures validated?

<br class="ltx_break"><span id="A1.I4.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Software API provided by Flickr.</span></p>
</div>
</li>
<li id="A1.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I4.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I4.i3.p1.1" class="ltx_p"><span id="A1.I4.i3.p1.1.1" class="ltx_text ltx_font_bold">If the dataset is a sample from a larger set, what was
the sampling strategy (e.g., deterministic, probabilistic with
specific sampling probabilities)?</span>

<br class="ltx_break"><span id="A1.I4.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I4.i4.p1" class="ltx_para ltx_noindent">
<p id="A1.I4.i4.p1.1" class="ltx_p"><span id="A1.I4.i4.p1.1.1" class="ltx_text ltx_font_bold">Who was involved in the data collection process (e.g.,
students, crowdworkers, contractors) and how were they compensated
(e.g., how much were crowdworkers paid)?</span>

<br class="ltx_break"><span id="A1.I4.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I4.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I4.i5.p1" class="ltx_para ltx_noindent">
<p id="A1.I4.i5.p1.1" class="ltx_p"><span id="A1.I4.i5.p1.1.1" class="ltx_text ltx_font_bold">Over what timeframe was the data collected?</span> Does this
timeframe match the creation timeframe of the data associated with
the instances (e.g., recent crawl of old news articles)? If not,
please describe the timeframe in which the data associated with the
instances was created.

<br class="ltx_break"><span id="A1.I4.i5.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The images were collected from late 2017 to early 2018.</span></p>
</div>
</li>
<li id="A1.I4.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I4.i6.p1" class="ltx_para ltx_noindent">
<p id="A1.I4.i6.p1.1" class="ltx_p"><span id="A1.I4.i6.p1.1.1" class="ltx_text ltx_font_bold">Were any ethical review processes conducted (e.g., by an
institutional review board)?</span> If so, please provide a description
of these review processes, including the outcomes, as well as a link
or other access point to any supporting documentation.

<br class="ltx_break"><span id="A1.I4.i6.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No.</span></p>
</div>
</li>
</ul>
</div>
<div id="A1.SS3.p3" class="ltx_para ltx_noindent">
<p id="A1.SS3.p3.1" class="ltx_p">If the dataset does not relate to people, you may skip the remaining questions in this section.</p>
</div>
<div id="A1.SS3.p4" class="ltx_para ltx_noindent">
<ul id="A1.I5" class="ltx_itemize">
<li id="A1.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I5.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I5.i1.p1.1" class="ltx_p"><span id="A1.I5.i1.p1.1.1" class="ltx_text ltx_font_bold">Did you collect the data from the individuals in
question directly, or obtain it via third parties or other sources
(e.g., websites)?</span>

<br class="ltx_break"><span id="A1.I5.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The data was collected from the Flickr website.</span></p>
</div>
</li>
<li id="A1.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I5.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I5.i2.p1.1" class="ltx_p"><span id="A1.I5.i2.p1.1.1" class="ltx_text ltx_font_bold">Were the individuals in question notified about the data
collection?</span> If so, please describe (or show with screenshots or
other information) how notice was provided, and provide a link or
other access point to, or otherwise reproduce, the exact language of
the notification itself.

<br class="ltx_break"><span id="A1.I5.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I5.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I5.i3.p1.1" class="ltx_p"><span id="A1.I5.i3.p1.1.1" class="ltx_text ltx_font_bold">Did the individuals in question consent to the
collection and use of their data?</span> If so, please describe (or show
with screenshots or other information) how consent was requested and
provided, and provide a link or other access point to, or otherwise
reproduce, the exact language to which the individuals consented.

<br class="ltx_break"><span id="A1.I5.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Each image has an associated license chosen by the Flickr user.
FLAIR only contain images with one of the following permissive licenses:</span></p>
<ul id="A1.I5.i3.I1" class="ltx_itemize">
<li id="A1.I5.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i3.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i3.I1.i1.p1" class="ltx_para">
<p id="A1.I5.i3.I1.i1.p1.1" class="ltx_p"><span id="A1.I5.i3.I1.i1.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Attribution 2.0 Generic (CC BY 2.0)</span><span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://creativecommons.org/licenses/by/2.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by/2.0/</a></span></span></span><span id="A1.I5.i3.I1.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;"></span></p>
</div>
</li>
<li id="A1.I5.i3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i3.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i3.I1.i2.p1" class="ltx_para">
<p id="A1.I5.i3.I1.i2.p1.1" class="ltx_p"><span id="A1.I5.i3.I1.i2.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Attribution-ShareAlike 2.0 Generic (CC BY-SA 2.0) </span><span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://creativecommons.org/licenses/by-sa/2.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by-sa/2.0/</a></span></span></span><span id="A1.I5.i3.I1.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;"></span></p>
</div>
</li>
<li id="A1.I5.i3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i3.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i3.I1.i3.p1" class="ltx_para">
<p id="A1.I5.i3.I1.i3.p1.1" class="ltx_p"><span id="A1.I5.i3.I1.i3.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Attribution-NoDerivs 2.0 Generic (CC BY-ND 2.0)</span><span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://creativecommons.org/licenses/by-nd/2.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by-nd/2.0/</a></span></span></span><span id="A1.I5.i3.I1.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;"></span></p>
</div>
</li>
<li id="A1.I5.i3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i3.I1.i4.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i3.I1.i4.p1" class="ltx_para">
<p id="A1.I5.i3.I1.i4.p1.1" class="ltx_p"><span id="A1.I5.i3.I1.i4.p1.1.1" class="ltx_text" style="color:#1A0DF5;">U.S. Government Works </span><span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="http://www.usa.gov/copyright.shtml" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.usa.gov/copyright.shtml</a></span></span></span><span id="A1.I5.i3.I1.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;"></span></p>
</div>
</li>
<li id="A1.I5.i3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i3.I1.i5.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i3.I1.i5.p1" class="ltx_para">
<p id="A1.I5.i3.I1.i5.p1.1" class="ltx_p"><span id="A1.I5.i3.I1.i5.p1.1.1" class="ltx_text" style="color:#1A0DF5;">CC0 1.0 Universal (CC0 1.0)
Public Domain Dedication </span><span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://creativecommons.org/publicdomain/zero/1.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/publicdomain/zero/1.0/</a></span></span></span><span id="A1.I5.i3.I1.i5.p1.1.2" class="ltx_text" style="color:#1A0DF5;"></span></p>
</div>
</li>
<li id="A1.I5.i3.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i3.I1.i6.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i3.I1.i6.p1" class="ltx_para ltx_noindent">
<p id="A1.I5.i3.I1.i6.p1.1" class="ltx_p"><span id="A1.I5.i3.I1.i6.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Public Domain Mark 1.0 </span><span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://creativecommons.org/publicdomain/mark/1.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/publicdomain/mark/1.0/</a></span></span></span><span id="A1.I5.i3.I1.i6.p1.1.2" class="ltx_text" style="color:#1A0DF5;"></span></p>
</div>
</li>
</ul>
</div>
</li>
<li id="A1.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I5.i4.p1" class="ltx_para ltx_noindent">
<p id="A1.I5.i4.p1.1" class="ltx_p"><span id="A1.I5.i4.p1.1.1" class="ltx_text ltx_font_bold">If consent was obtained, were the consenting individuals
provided with a mechanism to revoke their consent in the future or
for certain uses?</span> If so, please provide a description, as well as
a link or other access point to the mechanism (if appropriate).

<br class="ltx_break"><span id="A1.I5.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I5.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I5.i5.p1" class="ltx_para">
<p id="A1.I5.i5.p1.1" class="ltx_p"><span id="A1.I5.i5.p1.1.1" class="ltx_text ltx_font_bold">Has an analysis of the potential impact of the dataset
and its use on data subjects (e.g., a data protection impact
analysis) been conducted?</span> If so, please provide a description of
this analysis, including the outcomes, as well as a link or other
access point to any supporting documentation.

<br class="ltx_break"><span id="A1.I5.i5.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I5.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I5.i6.p1" class="ltx_para ltx_noindent">
<p id="A1.I5.i6.p1.1" class="ltx_p"><span id="A1.I5.i6.p1.1.1" class="ltx_text ltx_font_bold">Any other comments?</span>

<br class="ltx_break"><span id="A1.I5.i6.p1.1.2" class="ltx_text" style="color:#1A0DF5;">
After initial collection, we applied a two-stage filtering approach to remove images with personal identifiable information and sensitive materials.
In the first stage, we used a face detector to automatically remove images with faces.
In the second stage, we asked human annotators to filter out images with identifiable human and sensitive materials.
Specifically, images with any of the following will be removed from FLAIR:</span></p>
<ul id="A1.I5.i6.I1" class="ltx_itemize">
<li id="A1.I5.i6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i6.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i6.I1.i1.p1" class="ltx_para">
<p id="A1.I5.i6.I1.i1.p1.1" class="ltx_p"><span id="A1.I5.i6.I1.i1.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Visible faces or part of visible faces.</span></p>
</div>
</li>
<li id="A1.I5.i6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i6.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i6.I1.i2.p1" class="ltx_para">
<p id="A1.I5.i6.I1.i2.p1.1" class="ltx_p"><span id="A1.I5.i6.I1.i2.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Visible facial features or part of visible facial features, such as hair, eye, eyebrow, mouth, nose, ear, etc.</span></p>
</div>
</li>
<li id="A1.I5.i6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i6.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i6.I1.i3.p1" class="ltx_para">
<p id="A1.I5.i6.I1.i3.p1.1" class="ltx_p"><span id="A1.I5.i6.I1.i3.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Human body or part of body has identifiable feature, such as tatto, disabilities, injuries, scars, birthmarks, unique moles, etc.</span></p>
</div>
</li>
<li id="A1.I5.i6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i6.I1.i4.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i6.I1.i4.p1" class="ltx_para">
<p id="A1.I5.i6.I1.i4.p1.1" class="ltx_p"><span id="A1.I5.i6.I1.i4.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Rude statements and expressions.</span></p>
</div>
</li>
<li id="A1.I5.i6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i6.I1.i5.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i6.I1.i5.p1" class="ltx_para">
<p id="A1.I5.i6.I1.i5.p1.1" class="ltx_p"><span id="A1.I5.i6.I1.i5.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Profanity, racial, gender, ethnic, or religious slurs.</span></p>
</div>
</li>
<li id="A1.I5.i6.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i6.I1.i6.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i6.I1.i6.p1" class="ltx_para">
<p id="A1.I5.i6.I1.i6.p1.1" class="ltx_p"><span id="A1.I5.i6.I1.i6.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Sexually explicit or pornographic materials.</span></p>
</div>
</li>
<li id="A1.I5.i6.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="A1.I5.i6.I1.i7.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="A1.I5.i6.I1.i7.p1" class="ltx_para ltx_noindent">
<p id="A1.I5.i6.I1.i7.p1.1" class="ltx_p"><span id="A1.I5.i6.I1.i7.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Violent, obscene, graphic or disturbing materials.</span></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Preprocessing/cleaning/labeling</h3>

<div id="A1.SS4.p1" class="ltx_para ltx_noindent">
<p id="A1.SS4.p1.1" class="ltx_p">Dataset creators should read through these questions prior to any
preprocessing, cleaning, or labeling and then provide answers once
these tasks are complete. The questions in this section are intended
to provide dataset consumers with the information they need to
determine whether the “raw” data has been processed in ways that are
compatible with their chosen tasks. For example, text that has been
converted into a “bag-of-words” is not suitable for tasks involving
word order.</p>
</div>
<div id="A1.SS4.p2" class="ltx_para ltx_noindent">
<ul id="A1.I6" class="ltx_itemize">
<li id="A1.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I6.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I6.i1.p1.1" class="ltx_p"><span id="A1.I6.i1.p1.1.1" class="ltx_text ltx_font_bold">Was any preprocessing/cleaning/labeling of the data done
(e.g., discretization or bucketing, tokenization, part-of-speech
tagging, SIFT feature extraction, removal of instances, processing
of missing values)?</span> If so, please provide a description. If not,
you may skip the remaining questions in this section.

<br class="ltx_break"><span id="A1.I6.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Yes.
Labeling was done by human annotators where one annotator labeled the objects presented in an image and another annotator validate the labeling.
The taxonomy of the labels were constructed as following:</span></p>
<ol id="A1.I6.i1.I1" class="ltx_enumerate">
<li id="A1.I6.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A1.I6.i1.I1.i1.p1" class="ltx_para">
<p id="A1.I6.i1.I1.i1.p1.1" class="ltx_p"><span id="A1.I6.i1.I1.i1.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Retrieve all keywords from ShutterStock </span><span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://www.shutterstock.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.shutterstock.com/</a></span></span></span><span id="A1.I6.i1.I1.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;"> attached to 1000 images or more.</span></p>
</div>
</li>
<li id="A1.I6.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A1.I6.i1.I1.i2.p1" class="ltx_para">
<p id="A1.I6.i1.I1.i2.p1.1" class="ltx_p"><span id="A1.I6.i1.I1.i2.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Remove keywords that are illicit substances, sexual content, negative connotations, adjectives, proper names, places, organizations, occupations, abstract concepts, references to ethnicity, culture, religion, skin color, all body parts, and most animal parts.</span></p>
</div>
</li>
<li id="A1.I6.i1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A1.I6.i1.I1.i3.p1" class="ltx_para">
<p id="A1.I6.i1.I1.i3.p1.1" class="ltx_p"><span id="A1.I6.i1.I1.i3.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Remove plurals, alternative spellings and synonyms.</span></p>
</div>
</li>
<li id="A1.I6.i1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A1.I6.i1.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="A1.I6.i1.I1.i4.p1.1" class="ltx_p"><span id="A1.I6.i1.I1.i4.p1.1.1" class="ltx_text" style="color:#1A0DF5;">Leverage WordNet </span><span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://wordnet.princeton.edu/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://wordnet.princeton.edu/</a></span></span></span><span id="A1.I6.i1.I1.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;"> to construct coarse-grained labels.</span></p>
</div>
</li>
</ol>
<p id="A1.I6.i1.p1.2" class="ltx_p"><span id="A1.I6.i1.p1.2.1" class="ltx_text" style="color:#1A0DF5;">Unqualified images are removed as described in Appendix <a href="#A1.SS3" title="A.3 Collection Process ‣ Appendix A Datasheets for FLAIR Dataset ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>.
</span></p>
</div>
</li>
<li id="A1.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I6.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I6.i2.p1.1" class="ltx_p"><span id="A1.I6.i2.p1.1.1" class="ltx_text ltx_font_bold">Was the “raw” data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)?</span> If so, please provide a link or other access point to the “raw” data.

<br class="ltx_break"><span id="A1.I6.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No.</span></p>
</div>
</li>
<li id="A1.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I6.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I6.i3.p1.1" class="ltx_p"><span id="A1.I6.i3.p1.1.1" class="ltx_text ltx_font_bold">Is the software that was used to preprocess/clean/label the data available?</span> If so, please provide a link or other access point.

<br class="ltx_break"><span id="A1.I6.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The script to process data for training is provided at <a target="_blank" href="https://github.com/apple/ml-flair" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/apple/ml-flair</a>.
</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Uses</h3>

<div id="A1.SS5.p1" class="ltx_para ltx_noindent">
<p id="A1.SS5.p1.1" class="ltx_p">The questions in this section are intended to encourage dataset
creators to reflect on the tasks for which the dataset should and
should not be used. By explicitly highlighting these tasks, dataset
creators can help dataset consumers to make informed decisions,
thereby avoiding potential risks or harms.</p>
</div>
<div id="A1.SS5.p2" class="ltx_para ltx_noindent">
<ul id="A1.I7" class="ltx_itemize">
<li id="A1.I7.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I7.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I7.i1.p1.1" class="ltx_p"><span id="A1.I7.i1.p1.1.1" class="ltx_text ltx_font_bold">Has the dataset been used for any tasks already?</span> If so, please provide a description.

<br class="ltx_break"><span id="A1.I7.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">FLAIR has been used to benchmark federated learning and differential privacy on multi-label classification task, in this current paper.</span></p>
</div>
</li>
<li id="A1.I7.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I7.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I7.i2.p1.1" class="ltx_p"><span id="A1.I7.i2.p1.1.1" class="ltx_text ltx_font_bold">Is there a repository that links to any or all papers or systems that use the dataset?</span> If so, please provide a link or other access point.

<br class="ltx_break"><span id="A1.I7.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The current paper and the code used for experiments are available at <a target="_blank" href="https://github.com/apple/ml-flair" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/apple/ml-flair</a></span></p>
</div>
</li>
<li id="A1.I7.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I7.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I7.i3.p1.1" class="ltx_p"><span id="A1.I7.i3.p1.1.1" class="ltx_text ltx_font_bold">What (other) tasks could the dataset be used for?</span>

<br class="ltx_break"><span id="A1.I7.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">FLAIR could be used for other image classification tasks.</span></p>
</div>
</li>
<li id="A1.I7.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I7.i4.p1" class="ltx_para ltx_noindent">
<p id="A1.I7.i4.p1.1" class="ltx_p"><span id="A1.I7.i4.p1.1.1" class="ltx_text ltx_font_bold">Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses?</span> For example, is there anything that a dataset consumer might need to know to avoid uses that could result in unfair treatment of individuals or groups (e.g., stereotyping, quality of service issues) or other risks or harms (e.g., legal risks, financial harms)? If so, please provide a description. Is there anything a dataset consumer could do to mitigate these risks or harms?

<br class="ltx_break"><span id="A1.I7.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;">This dataset contains a limited number of object classes and is intended to create a benchmark to evaluate and compare algorithms for (private) federated learning. </span></p>
</div>
</li>
<li id="A1.I7.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I7.i5.p1" class="ltx_para ltx_noindent">
<p id="A1.I7.i5.p1.1" class="ltx_p"><span id="A1.I7.i5.p1.1.1" class="ltx_text ltx_font_bold">Are there tasks for which the dataset should not be used?</span> If so, please provide a description.

<br class="ltx_break"><span id="A1.I7.i5.p1.1.2" class="ltx_text" style="color:#1A0DF5;">It being a subset of images from Flickr, it is not expected to be representative of all images in the world.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Distribution</h3>

<div id="A1.SS6.p1" class="ltx_para ltx_noindent">
<p id="A1.SS6.p1.1" class="ltx_p">Dataset creators should provide answers to these questions prior to
distributing the dataset either internally within the entity on behalf
of which the dataset was created or externally to third parties.</p>
</div>
<div id="A1.SS6.p2" class="ltx_para ltx_noindent">
<ul id="A1.I8" class="ltx_itemize">
<li id="A1.I8.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I8.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I8.i1.p1.1" class="ltx_p"><span id="A1.I8.i1.p1.1.1" class="ltx_text ltx_font_bold">Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created?</span> If so, please provide a description.

<br class="ltx_break"><span id="A1.I8.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Yes.</span></p>
</div>
</li>
<li id="A1.I8.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I8.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I8.i2.p1.1" class="ltx_p"><span id="A1.I8.i2.p1.1.1" class="ltx_text ltx_font_bold">How will the dataset will be distributed (e.g., tarball on website, API, GitHub)?</span> Does the dataset have a digital object identifier (DOI)?

<br class="ltx_break"><span id="A1.I8.i2.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The dataset will be distributed on AWS S3.</span></p>
</div>
</li>
<li id="A1.I8.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I8.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I8.i3.p1.1" class="ltx_p"><span id="A1.I8.i3.p1.1.1" class="ltx_text ltx_font_bold">When will the dataset be distributed?</span>

<br class="ltx_break"><span id="A1.I8.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The dataset will be distributed on June 16th, 2022.</span></p>
</div>
</li>
<li id="A1.I8.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I8.i4.p1" class="ltx_para ltx_noindent">
<p id="A1.I8.i4.p1.1" class="ltx_p"><span id="A1.I8.i4.p1.1.1" class="ltx_text ltx_font_bold">Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?</span> If so, please describe this license and/or ToU, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms or ToU, as well as any fees associated with these restrictions.

<br class="ltx_break"><span id="A1.I8.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Please see license for FLAIR at <a target="_blank" href="https://github.com/apple/ml-flair/blob/master/LICENSE.md" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/apple/ml-flair/blob/master/LICENSE.md</a></span></p>
</div>
</li>
<li id="A1.I8.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I8.i5.p1" class="ltx_para ltx_noindent">
<p id="A1.I8.i5.p1.1" class="ltx_p"><span id="A1.I8.i5.p1.1.1" class="ltx_text ltx_font_bold">Have any third parties imposed IP-based or other restrictions on the data associated with the instances?</span> If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms, as well as any fees associated with these restrictions.

<br class="ltx_break"><span id="A1.I8.i5.p1.1.2" class="ltx_text" style="color:#1A0DF5;">No.</span></p>
</div>
</li>
<li id="A1.I8.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I8.i6.p1" class="ltx_para ltx_noindent">
<p id="A1.I8.i6.p1.1" class="ltx_p"><span id="A1.I8.i6.p1.1.1" class="ltx_text ltx_font_bold">Do any export controls or other regulatory restrictions apply to the dataset or to individual instances?</span> If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any supporting documentation.

<br class="ltx_break"><span id="A1.I8.i6.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>Maintenance</h3>

<div id="A1.SS7.p1" class="ltx_para ltx_noindent">
<p id="A1.SS7.p1.1" class="ltx_p">As with the questions in the previous section, dataset creators
should provide answers to these questions prior to distributing the
dataset. The questions in this section are intended to
encourage dataset creators to plan for dataset maintenance and
communicate this plan to dataset consumers.</p>
</div>
<div id="A1.SS7.p2" class="ltx_para ltx_noindent">
<ul id="A1.I9" class="ltx_itemize">
<li id="A1.I9.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i1.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i1.p1.1" class="ltx_p"><span id="A1.I9.i1.p1.1.1" class="ltx_text ltx_font_bold">Who will be supporting/hosting/maintaining the dataset?</span>

<br class="ltx_break"><span id="A1.I9.i1.p1.1.2" class="ltx_text" style="color:#1A0DF5;">Apple ML Privacy team.</span></p>
</div>
</li>
<li id="A1.I9.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i2.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i2.p1.1" class="ltx_p"><span id="A1.I9.i2.p1.1.1" class="ltx_text ltx_font_bold">How can the owner/curator/manager of the dataset be contacted (e.g., email address)?</span>

<br class="ltx_break"><a href="pfl-dev@group.apple.com" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="color:#1A0DF5;">pfl-dev@group.apple.com</a></p>
</div>
</li>
<li id="A1.I9.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i3.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i3.p1.1" class="ltx_p"><span id="A1.I9.i3.p1.1.1" class="ltx_text ltx_font_bold">Is there an erratum?</span> If so, please provide a link or other access point.

<br class="ltx_break"><span id="A1.I9.i3.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I9.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i4.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i4.p1.1" class="ltx_p"><span id="A1.I9.i4.p1.1.1" class="ltx_text ltx_font_bold">Will the dataset be updated (e.g., to correct labeling
errors, add new instances, delete instances)?</span> If so, please
describe how often, by whom, and how updates will be communicated to
dataset consumers (e.g., mailing list, GitHub)?

<br class="ltx_break"><span id="A1.I9.i4.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I9.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i5.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i5.p1.1" class="ltx_p"><span id="A1.I9.i5.p1.1.1" class="ltx_text ltx_font_bold">If the dataset relates to people, are there applicable
limits on the retention of the data associated with the instances
(e.g., were the individuals in question told that their data would
be retained for a fixed period of time and then deleted)?</span> If so,
please describe these limits and explain how they will be
enforced.

<br class="ltx_break"><span id="A1.I9.i5.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I9.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i6.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i6.p1.1" class="ltx_p"><span id="A1.I9.i6.p1.1.1" class="ltx_text ltx_font_bold">Will older versions of the dataset continue to be
supported/hosted/maintained?</span> If so, please describe how. If not,
please describe how its obsolescence will be communicated to dataset
consumers.

<br class="ltx_break"><span id="A1.I9.i6.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I9.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i7.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i7.p1.1" class="ltx_p"><span id="A1.I9.i7.p1.1.1" class="ltx_text ltx_font_bold">If others want to extend/augment/build on/contribute to
the dataset, is there a mechanism for them to do so?</span> If so,
please provide a description. Will these contributions be
validated/verified? If so, please describe how. If not, why not? Is
there a process for communicating/distributing these contributions
to dataset consumers? If so, please provide a description.

<br class="ltx_break"><span id="A1.I9.i7.p1.1.2" class="ltx_text" style="color:#1A0DF5;">N/A.</span></p>
</div>
</li>
<li id="A1.I9.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I9.i8.p1" class="ltx_para ltx_noindent">
<p id="A1.I9.i8.p1.1" class="ltx_p"><span id="A1.I9.i8.p1.1.1" class="ltx_text ltx_font_bold">Any other comments?</span>

<br class="ltx_break"><span id="A1.I9.i8.p1.1.2" class="ltx_text" style="color:#1A0DF5;">The annotations and Apple’s other rights in the dataset are licensed under CC-BY-NC 4.0 license. The images are copyright of the respective owners, the license terms of which can be found using the links provided in <a target="_blank" href="https://github.com/apple/ml-flair/blob/master/ATTRIBUTION.txt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/apple/ml-flair/blob/master/ATTRIBUTION.txt</a> (by matching the Image ID). Apple makes no representations or warranties regarding the license status of each image and you should verify the license for each image yourself.</span></p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Benchmark Setup Details</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Computational resources</h3>

<div id="A2.SS1.p1" class="ltx_para ltx_noindent">
<p id="A2.SS1.p1.1" class="ltx_p">All experiments are conducted on a cluster with 32 CPU cores and 4 NVIDIA Tesla V100 GPUs.</p>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Hyper-parameters grids</h3>

<div id="A2.SS2.p1" class="ltx_para ltx_noindent">
<p id="A2.SS2.p1.1" class="ltx_p">Below are the hyper-parameter grids that we searched on for benchmarking FLAIR:</p>
<ul id="A2.I1" class="ltx_itemize">
<li id="A2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i1.p1" class="ltx_para">
<p id="A2.I1.i1.p1.1" class="ltx_p">Server learning rate <math id="A2.I1.i1.p1.1.m1.4" class="ltx_Math" alttext="\in\{0.01,0.02,0.05,0.1\}" display="inline"><semantics id="A2.I1.i1.p1.1.m1.4a"><mrow id="A2.I1.i1.p1.1.m1.4.5" xref="A2.I1.i1.p1.1.m1.4.5.cmml"><mi id="A2.I1.i1.p1.1.m1.4.5.2" xref="A2.I1.i1.p1.1.m1.4.5.2.cmml"></mi><mo id="A2.I1.i1.p1.1.m1.4.5.1" xref="A2.I1.i1.p1.1.m1.4.5.1.cmml">∈</mo><mrow id="A2.I1.i1.p1.1.m1.4.5.3.2" xref="A2.I1.i1.p1.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="A2.I1.i1.p1.1.m1.4.5.3.2.1" xref="A2.I1.i1.p1.1.m1.4.5.3.1.cmml">{</mo><mn id="A2.I1.i1.p1.1.m1.1.1" xref="A2.I1.i1.p1.1.m1.1.1.cmml">0.01</mn><mo id="A2.I1.i1.p1.1.m1.4.5.3.2.2" xref="A2.I1.i1.p1.1.m1.4.5.3.1.cmml">,</mo><mn id="A2.I1.i1.p1.1.m1.2.2" xref="A2.I1.i1.p1.1.m1.2.2.cmml">0.02</mn><mo id="A2.I1.i1.p1.1.m1.4.5.3.2.3" xref="A2.I1.i1.p1.1.m1.4.5.3.1.cmml">,</mo><mn id="A2.I1.i1.p1.1.m1.3.3" xref="A2.I1.i1.p1.1.m1.3.3.cmml">0.05</mn><mo id="A2.I1.i1.p1.1.m1.4.5.3.2.4" xref="A2.I1.i1.p1.1.m1.4.5.3.1.cmml">,</mo><mn id="A2.I1.i1.p1.1.m1.4.4" xref="A2.I1.i1.p1.1.m1.4.4.cmml">0.1</mn><mo stretchy="false" id="A2.I1.i1.p1.1.m1.4.5.3.2.5" xref="A2.I1.i1.p1.1.m1.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.1.m1.4b"><apply id="A2.I1.i1.p1.1.m1.4.5.cmml" xref="A2.I1.i1.p1.1.m1.4.5"><in id="A2.I1.i1.p1.1.m1.4.5.1.cmml" xref="A2.I1.i1.p1.1.m1.4.5.1"></in><csymbol cd="latexml" id="A2.I1.i1.p1.1.m1.4.5.2.cmml" xref="A2.I1.i1.p1.1.m1.4.5.2">absent</csymbol><set id="A2.I1.i1.p1.1.m1.4.5.3.1.cmml" xref="A2.I1.i1.p1.1.m1.4.5.3.2"><cn type="float" id="A2.I1.i1.p1.1.m1.1.1.cmml" xref="A2.I1.i1.p1.1.m1.1.1">0.01</cn><cn type="float" id="A2.I1.i1.p1.1.m1.2.2.cmml" xref="A2.I1.i1.p1.1.m1.2.2">0.02</cn><cn type="float" id="A2.I1.i1.p1.1.m1.3.3.cmml" xref="A2.I1.i1.p1.1.m1.3.3">0.05</cn><cn type="float" id="A2.I1.i1.p1.1.m1.4.4.cmml" xref="A2.I1.i1.p1.1.m1.4.4">0.1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.1.m1.4c">\in\{0.01,0.02,0.05,0.1\}</annotation></semantics></math></p>
</div>
</li>
<li id="A2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i2.p1" class="ltx_para">
<p id="A2.I1.i2.p1.1" class="ltx_p">Server number of rounds <math id="A2.I1.i2.p1.1.m1.2" class="ltx_Math" alttext="\in\{2000,5000\}" display="inline"><semantics id="A2.I1.i2.p1.1.m1.2a"><mrow id="A2.I1.i2.p1.1.m1.2.3" xref="A2.I1.i2.p1.1.m1.2.3.cmml"><mi id="A2.I1.i2.p1.1.m1.2.3.2" xref="A2.I1.i2.p1.1.m1.2.3.2.cmml"></mi><mo id="A2.I1.i2.p1.1.m1.2.3.1" xref="A2.I1.i2.p1.1.m1.2.3.1.cmml">∈</mo><mrow id="A2.I1.i2.p1.1.m1.2.3.3.2" xref="A2.I1.i2.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="A2.I1.i2.p1.1.m1.2.3.3.2.1" xref="A2.I1.i2.p1.1.m1.2.3.3.1.cmml">{</mo><mn id="A2.I1.i2.p1.1.m1.1.1" xref="A2.I1.i2.p1.1.m1.1.1.cmml">2000</mn><mo id="A2.I1.i2.p1.1.m1.2.3.3.2.2" xref="A2.I1.i2.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="A2.I1.i2.p1.1.m1.2.2" xref="A2.I1.i2.p1.1.m1.2.2.cmml">5000</mn><mo stretchy="false" id="A2.I1.i2.p1.1.m1.2.3.3.2.3" xref="A2.I1.i2.p1.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.1.m1.2b"><apply id="A2.I1.i2.p1.1.m1.2.3.cmml" xref="A2.I1.i2.p1.1.m1.2.3"><in id="A2.I1.i2.p1.1.m1.2.3.1.cmml" xref="A2.I1.i2.p1.1.m1.2.3.1"></in><csymbol cd="latexml" id="A2.I1.i2.p1.1.m1.2.3.2.cmml" xref="A2.I1.i2.p1.1.m1.2.3.2">absent</csymbol><set id="A2.I1.i2.p1.1.m1.2.3.3.1.cmml" xref="A2.I1.i2.p1.1.m1.2.3.3.2"><cn type="integer" id="A2.I1.i2.p1.1.m1.1.1.cmml" xref="A2.I1.i2.p1.1.m1.1.1">2000</cn><cn type="integer" id="A2.I1.i2.p1.1.m1.2.2.cmml" xref="A2.I1.i2.p1.1.m1.2.2">5000</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.1.m1.2c">\in\{2000,5000\}</annotation></semantics></math></p>
</div>
</li>
<li id="A2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i3.p1" class="ltx_para">
<p id="A2.I1.i3.p1.1" class="ltx_p">Client local learning rate <math id="A2.I1.i3.p1.1.m1.2" class="ltx_Math" alttext="\in\{0.01,0.1\}" display="inline"><semantics id="A2.I1.i3.p1.1.m1.2a"><mrow id="A2.I1.i3.p1.1.m1.2.3" xref="A2.I1.i3.p1.1.m1.2.3.cmml"><mi id="A2.I1.i3.p1.1.m1.2.3.2" xref="A2.I1.i3.p1.1.m1.2.3.2.cmml"></mi><mo id="A2.I1.i3.p1.1.m1.2.3.1" xref="A2.I1.i3.p1.1.m1.2.3.1.cmml">∈</mo><mrow id="A2.I1.i3.p1.1.m1.2.3.3.2" xref="A2.I1.i3.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="A2.I1.i3.p1.1.m1.2.3.3.2.1" xref="A2.I1.i3.p1.1.m1.2.3.3.1.cmml">{</mo><mn id="A2.I1.i3.p1.1.m1.1.1" xref="A2.I1.i3.p1.1.m1.1.1.cmml">0.01</mn><mo id="A2.I1.i3.p1.1.m1.2.3.3.2.2" xref="A2.I1.i3.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="A2.I1.i3.p1.1.m1.2.2" xref="A2.I1.i3.p1.1.m1.2.2.cmml">0.1</mn><mo stretchy="false" id="A2.I1.i3.p1.1.m1.2.3.3.2.3" xref="A2.I1.i3.p1.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.1.m1.2b"><apply id="A2.I1.i3.p1.1.m1.2.3.cmml" xref="A2.I1.i3.p1.1.m1.2.3"><in id="A2.I1.i3.p1.1.m1.2.3.1.cmml" xref="A2.I1.i3.p1.1.m1.2.3.1"></in><csymbol cd="latexml" id="A2.I1.i3.p1.1.m1.2.3.2.cmml" xref="A2.I1.i3.p1.1.m1.2.3.2">absent</csymbol><set id="A2.I1.i3.p1.1.m1.2.3.3.1.cmml" xref="A2.I1.i3.p1.1.m1.2.3.3.2"><cn type="float" id="A2.I1.i3.p1.1.m1.1.1.cmml" xref="A2.I1.i3.p1.1.m1.1.1">0.01</cn><cn type="float" id="A2.I1.i3.p1.1.m1.2.2.cmml" xref="A2.I1.i3.p1.1.m1.2.2">0.1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.1.m1.2c">\in\{0.01,0.1\}</annotation></semantics></math></p>
</div>
</li>
<li id="A2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i4.p1" class="ltx_para">
<p id="A2.I1.i4.p1.1" class="ltx_p">Client number of epochs <math id="A2.I1.i4.p1.1.m1.5" class="ltx_Math" alttext="\in\{1,2,3,4,5\}" display="inline"><semantics id="A2.I1.i4.p1.1.m1.5a"><mrow id="A2.I1.i4.p1.1.m1.5.6" xref="A2.I1.i4.p1.1.m1.5.6.cmml"><mi id="A2.I1.i4.p1.1.m1.5.6.2" xref="A2.I1.i4.p1.1.m1.5.6.2.cmml"></mi><mo id="A2.I1.i4.p1.1.m1.5.6.1" xref="A2.I1.i4.p1.1.m1.5.6.1.cmml">∈</mo><mrow id="A2.I1.i4.p1.1.m1.5.6.3.2" xref="A2.I1.i4.p1.1.m1.5.6.3.1.cmml"><mo stretchy="false" id="A2.I1.i4.p1.1.m1.5.6.3.2.1" xref="A2.I1.i4.p1.1.m1.5.6.3.1.cmml">{</mo><mn id="A2.I1.i4.p1.1.m1.1.1" xref="A2.I1.i4.p1.1.m1.1.1.cmml">1</mn><mo id="A2.I1.i4.p1.1.m1.5.6.3.2.2" xref="A2.I1.i4.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.I1.i4.p1.1.m1.2.2" xref="A2.I1.i4.p1.1.m1.2.2.cmml">2</mn><mo id="A2.I1.i4.p1.1.m1.5.6.3.2.3" xref="A2.I1.i4.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.I1.i4.p1.1.m1.3.3" xref="A2.I1.i4.p1.1.m1.3.3.cmml">3</mn><mo id="A2.I1.i4.p1.1.m1.5.6.3.2.4" xref="A2.I1.i4.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.I1.i4.p1.1.m1.4.4" xref="A2.I1.i4.p1.1.m1.4.4.cmml">4</mn><mo id="A2.I1.i4.p1.1.m1.5.6.3.2.5" xref="A2.I1.i4.p1.1.m1.5.6.3.1.cmml">,</mo><mn id="A2.I1.i4.p1.1.m1.5.5" xref="A2.I1.i4.p1.1.m1.5.5.cmml">5</mn><mo stretchy="false" id="A2.I1.i4.p1.1.m1.5.6.3.2.6" xref="A2.I1.i4.p1.1.m1.5.6.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i4.p1.1.m1.5b"><apply id="A2.I1.i4.p1.1.m1.5.6.cmml" xref="A2.I1.i4.p1.1.m1.5.6"><in id="A2.I1.i4.p1.1.m1.5.6.1.cmml" xref="A2.I1.i4.p1.1.m1.5.6.1"></in><csymbol cd="latexml" id="A2.I1.i4.p1.1.m1.5.6.2.cmml" xref="A2.I1.i4.p1.1.m1.5.6.2">absent</csymbol><set id="A2.I1.i4.p1.1.m1.5.6.3.1.cmml" xref="A2.I1.i4.p1.1.m1.5.6.3.2"><cn type="integer" id="A2.I1.i4.p1.1.m1.1.1.cmml" xref="A2.I1.i4.p1.1.m1.1.1">1</cn><cn type="integer" id="A2.I1.i4.p1.1.m1.2.2.cmml" xref="A2.I1.i4.p1.1.m1.2.2">2</cn><cn type="integer" id="A2.I1.i4.p1.1.m1.3.3.cmml" xref="A2.I1.i4.p1.1.m1.3.3">3</cn><cn type="integer" id="A2.I1.i4.p1.1.m1.4.4.cmml" xref="A2.I1.i4.p1.1.m1.4.4">4</cn><cn type="integer" id="A2.I1.i4.p1.1.m1.5.5.cmml" xref="A2.I1.i4.p1.1.m1.5.5">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i4.p1.1.m1.5c">\in\{1,2,3,4,5\}</annotation></semantics></math></p>
</div>
</li>
<li id="A2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="A2.I1.i5.p1.1" class="ltx_p">Target unclipped quantile for adaptive clipping <math id="A2.I1.i5.p1.1.m1.2" class="ltx_Math" alttext="\in\{0.1,0.2\}" display="inline"><semantics id="A2.I1.i5.p1.1.m1.2a"><mrow id="A2.I1.i5.p1.1.m1.2.3" xref="A2.I1.i5.p1.1.m1.2.3.cmml"><mi id="A2.I1.i5.p1.1.m1.2.3.2" xref="A2.I1.i5.p1.1.m1.2.3.2.cmml"></mi><mo id="A2.I1.i5.p1.1.m1.2.3.1" xref="A2.I1.i5.p1.1.m1.2.3.1.cmml">∈</mo><mrow id="A2.I1.i5.p1.1.m1.2.3.3.2" xref="A2.I1.i5.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="A2.I1.i5.p1.1.m1.2.3.3.2.1" xref="A2.I1.i5.p1.1.m1.2.3.3.1.cmml">{</mo><mn id="A2.I1.i5.p1.1.m1.1.1" xref="A2.I1.i5.p1.1.m1.1.1.cmml">0.1</mn><mo id="A2.I1.i5.p1.1.m1.2.3.3.2.2" xref="A2.I1.i5.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="A2.I1.i5.p1.1.m1.2.2" xref="A2.I1.i5.p1.1.m1.2.2.cmml">0.2</mn><mo stretchy="false" id="A2.I1.i5.p1.1.m1.2.3.3.2.3" xref="A2.I1.i5.p1.1.m1.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i5.p1.1.m1.2b"><apply id="A2.I1.i5.p1.1.m1.2.3.cmml" xref="A2.I1.i5.p1.1.m1.2.3"><in id="A2.I1.i5.p1.1.m1.2.3.1.cmml" xref="A2.I1.i5.p1.1.m1.2.3.1"></in><csymbol cd="latexml" id="A2.I1.i5.p1.1.m1.2.3.2.cmml" xref="A2.I1.i5.p1.1.m1.2.3.2">absent</csymbol><set id="A2.I1.i5.p1.1.m1.2.3.3.1.cmml" xref="A2.I1.i5.p1.1.m1.2.3.3.2"><cn type="float" id="A2.I1.i5.p1.1.m1.1.1.cmml" xref="A2.I1.i5.p1.1.m1.1.1">0.1</cn><cn type="float" id="A2.I1.i5.p1.1.m1.2.2.cmml" xref="A2.I1.i5.p1.1.m1.2.2">0.2</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i5.p1.1.m1.2c">\in\{0.1,0.2\}</annotation></semantics></math></p>
</div>
</li>
</ul>
</div>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Additional binary classification benchmark</h3>

<figure id="A2.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>FLAIR binary classification benchmark results on test set for <em id="A2.T3.2.1" class="ltx_emph ltx_font_italic">structure</em> label. AP stands for averaged precision.</figcaption>
<table id="A2.T3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T3.3.1.1" class="ltx_tr">
<th id="A2.T3.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Setting</th>
<th id="A2.T3.3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Initialization</th>
<th id="A2.T3.3.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">AP</th>
<th id="A2.T3.3.1.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Precision</th>
<th id="A2.T3.3.1.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Recall</th>
<th id="A2.T3.3.1.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T3.3.2.1" class="ltx_tr">
<th id="A2.T3.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Centralized</th>
<th id="A2.T3.3.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Random</th>
<td id="A2.T3.3.2.1.3" class="ltx_td ltx_align_right ltx_border_t">87.72</td>
<td id="A2.T3.3.2.1.4" class="ltx_td ltx_align_right ltx_border_t">79.76</td>
<td id="A2.T3.3.2.1.5" class="ltx_td ltx_align_right ltx_border_t">78.38</td>
<td id="A2.T3.3.2.1.6" class="ltx_td ltx_align_right ltx_border_t">79.06</td>
</tr>
<tr id="A2.T3.3.3.2" class="ltx_tr">
<th id="A2.T3.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Federated</th>
<th id="A2.T3.3.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Random</th>
<td id="A2.T3.3.3.2.3" class="ltx_td ltx_align_right">84.22</td>
<td id="A2.T3.3.3.2.4" class="ltx_td ltx_align_right">77.18</td>
<td id="A2.T3.3.3.2.5" class="ltx_td ltx_align_right">73.42</td>
<td id="A2.T3.3.3.2.6" class="ltx_td ltx_align_right">75.25</td>
</tr>
<tr id="A2.T3.3.4.3" class="ltx_tr">
<th id="A2.T3.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Private federated</th>
<th id="A2.T3.3.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Random</th>
<td id="A2.T3.3.4.3.3" class="ltx_td ltx_align_right">68.56</td>
<td id="A2.T3.3.4.3.4" class="ltx_td ltx_align_right">64.33</td>
<td id="A2.T3.3.4.3.5" class="ltx_td ltx_align_right">76.08</td>
<td id="A2.T3.3.4.3.6" class="ltx_td ltx_align_right">69.71</td>
</tr>
<tr id="A2.T3.3.5.4" class="ltx_tr">
<th id="A2.T3.3.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Centralized</th>
<th id="A2.T3.3.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">ImageNet</th>
<td id="A2.T3.3.5.4.3" class="ltx_td ltx_align_right ltx_border_t">92.80</td>
<td id="A2.T3.3.5.4.4" class="ltx_td ltx_align_right ltx_border_t">84.58</td>
<td id="A2.T3.3.5.4.5" class="ltx_td ltx_align_right ltx_border_t">83.99</td>
<td id="A2.T3.3.5.4.6" class="ltx_td ltx_align_right ltx_border_t">84.28</td>
</tr>
<tr id="A2.T3.3.6.5" class="ltx_tr">
<th id="A2.T3.3.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Federated</th>
<th id="A2.T3.3.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ImageNet</th>
<td id="A2.T3.3.6.5.3" class="ltx_td ltx_align_right">90.49</td>
<td id="A2.T3.3.6.5.4" class="ltx_td ltx_align_right">81.98</td>
<td id="A2.T3.3.6.5.5" class="ltx_td ltx_align_right">81.65</td>
<td id="A2.T3.3.6.5.6" class="ltx_td ltx_align_right">81.81</td>
</tr>
<tr id="A2.T3.3.7.6" class="ltx_tr">
<th id="A2.T3.3.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Private federated</th>
<th id="A2.T3.3.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">ImageNet</th>
<td id="A2.T3.3.7.6.3" class="ltx_td ltx_align_right ltx_border_bb">83.41</td>
<td id="A2.T3.3.7.6.4" class="ltx_td ltx_align_right ltx_border_bb">76.95</td>
<td id="A2.T3.3.7.6.5" class="ltx_td ltx_align_right ltx_border_bb">71.90</td>
<td id="A2.T3.3.7.6.6" class="ltx_td ltx_align_right ltx_border_bb">74.34</td>
</tr>
</tbody>
</table>
</figure>
<div id="A2.SS3.p1" class="ltx_para ltx_noindent">
<p id="A2.SS3.p1.1" class="ltx_p">We provide additional binary classification benchmark on the most common <em id="A2.SS3.p1.1.1" class="ltx_emph ltx_font_italic">structure</em> label, using the same hyperparameters as in Section <a href="#S5.SS1" title="5.1 Benchmark setups ‣ 5 Experiments ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
Table <a href="#A2.T3" title="Table 3 ‣ B.3 Additional binary classification benchmark ‣ Appendix B Benchmark Setup Details ‣ FLAIR: Federated Learning Annotated Image Repository" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes the results.
The performance of models trained in federated setting and private federated setting are much closer to the centralized setting, especially when the models were pretrained on ImageNet.
We believe that this simple binary classification baseline could help researchers to quickly verify their proposed algorithms and methods in (private) federated learning setting.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2207.08868" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2207.08869" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2207.08869">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2207.08869" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2207.08870" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 14:47:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
