<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Digital Twin Ecosystem for Oncology Clinical Operations</title>
<!--Generated on Thu Sep 26 08:52:56 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.17650v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S1" title="In Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S2" title="In Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S3" title="In Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S3.SS1" title="In 3 Methodology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Cancer Care Path</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S3.SS2" title="In 3 Methodology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Digital Twin Framework</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4" title="In Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Twin Applications for Oncology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4.SS1" title="In 4 Twin Applications for Oncology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Medical Necessity Twin</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4.SS2" title="In 4 Twin Applications for Oncology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Clinical History Twin</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4.SS3" title="In 4 Twin Applications for Oncology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Care Navigator Twin</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S5" title="In Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Case Study: Ovarian Cancer Diagnosis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S5.SS1" title="In 5 Case Study: Ovarian Cancer Diagnosis ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Cancer Care Graph</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S5.SS2" title="In 5 Case Study: Ovarian Cancer Diagnosis ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Diagnosis Journey</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S6" title="In Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S7" title="In Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Future Work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Digital Twin Ecosystem for Oncology Clinical Operations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Himanshu Pandey 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">himanshu@risalabs.ai</span>
&amp;Akhil Amod 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">akhil@risalabs.ai</span>
&amp;Shivang 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">shivang@risalabs.ai</span>
&amp;Kshitij Jaggi 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id4">kj@risalabs.ai</span>
<span class="ltx_ERROR undefined" id="id5.5.id5">\AND</span>Dr. Ruchi Garg 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id6.6.id6">docruchi@risalabs.ai</span>
&amp;Abheet Jain 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id7.7.id7">abheet@risalabs.ai</span>
&amp;Vinayak Tantia 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id8.8.id8">vinayak@risalabs.ai</span>
<span class="ltx_ERROR undefined" id="id9.9.id9">\AND</span>RISA Labs Inc
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id10.id1">Artificial Intelligence (AI) and Large Language Models (LLMs) hold significant promise in revolutionizing healthcare, especially in clinical applications. Simultaneously, Digital Twin technology, which models and simulates complex systems, has gained traction in enhancing patient care. However, despite the advances in experimental clinical settings, the potential of AI and digital twins to streamline clinical operations remains largely untapped. This paper introduces a novel digital twin framework specifically designed to enhance oncology clinical operations. We propose the integration of multiple specialized digital twins, such as the Medical Necessity Twin, Care Navigator Twin, and Clinical History Twin, to enhance workflow efficiency and personalize care for each patient based on their unique data. Furthermore, by synthesizing multiple data sources and aligning them with the National Comprehensive Cancer Network (NCCN) guidelines, we create a dynamic Cancer Care Path—a continuously evolving knowledge base that enables these digital twins to provide precise, tailored clinical recommendations.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Delivering optimal oncology care presents several challenges that complicate decision-making for healthcare providers. Although Electronic Health Records (EHRs) contain extensive patient data, there is often no user-friendly tool to easily access a patient’s complete treatment and medication history. This lack of accessibility makes it difficult for providers to review past treatments and make informed decisions about future care. Additionally, aligning a patient’s specific condition with the National Comprehensive Cancer Network (NCCN) guidelines poses another challenge. While the guidelines provide evidence-based recommendations, they must be personalized to each patient’s unique circumstances, such as their diagnosis, treatment history, and underlying conditions. Furthermore, even after identifying the appropriate treatment, it must adhere to payer-specific Prior Authorization (PA) criteria, adding administrative complexity and potentially delaying care.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Artificial Intelligence (AI) and Large Language Models (LLMs) have greatly impacted healthcare by enabling faster, more precise care across various applications, including surgery, medical consultations, administrative workflows, treatment planning, diagnosis, and more <cite class="ltx_cite ltx_citemacro_cite">Väänänen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib37" title="">2021</a>)</cite>. A notable advancement in this field is the development of digital twin technology, which facilitates personalized treatment simulations and predictive modeling, directly impacting patient-specific outcomes. The concept of a Digital Twin (DT) is well-established and refers to a dynamic, real-time digital counterpart of a physical object or system, with continuous data exchange and interaction—distinguishing it from a static <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">digital model</span> that lacks real-time data integration between the digital and physical systems <cite class="ltx_cite ltx_citemacro_cite">Kritzinger et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib20" title="">2018</a>)</cite>. Advances in AI and LLMs have significantly accelerated the adoption of digital twins in healthcare <cite class="ltx_cite ltx_citemacro_cite">Erol et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib13" title="">2020</a>); Makarov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib27" title="">2024</a>)</cite>. In this context, digital twins can model human organs, tissues, and cells, constantly updating with new data to predict future states. Moreover, precision medicine harnesses these technologies to tailor disease treatment and prevention based on individual genetic, environmental, and lifestyle factors, leading to the creation of virtual human models that enhance clinicians’ ability to understand, diagnose, and treat diseases effectively <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib34" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">While digital twin technology has revolutionized clinical applications in various medical specialties, its potential in enhancing healthcare operations remains largely under-explored. Digital twins can greatly assist in care coordination by helping providers create tailored care plans based on individual conditions. For instance, a coordinator digital twin could streamline communication between stakeholders, such as laboratories and healthcare providers, ensuring seamless information flow throughout the cancer care journey. Building upon the foundation of digital twins, agent-based models integrate AI and LLMs to create sophisticated multi-agent systems (MAS) that can simulate complex interactions within healthcare operations. These agent-based digital twins serve as digital counterparts for various assets in healthcare operations, enhancing accuracy and efficiency. Digital twins can model not only physiological elements like heart functions but also complex processes, such as clinical decision support and workflows like prior authorization <cite class="ltx_cite ltx_citemacro_cite">Croatti et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib9" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This paper examines the concept of agent-based digital twins and their role in building LLM-based multi-agent systems for oncology operations. The objectives of this paper are as follows:</p>
</div>
<div class="ltx_para" id="S1.p5">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Define the digital twin framework, highlighting various capabilities and demonstrating its use cases in oncology.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Establish a <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">Cancer Care Path</span> as a knowledge base to support digital twins in making clinical recommendations.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Present a case study illustrating how different agents collaborate using various knowledge bases to streamline workflows.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">AI and LLMs have revolutionized healthcare in recent years. Models like ChatGPT <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib31" title="">2024</a>)</cite> have matured to a point where they can significantly influence clinical decision-making <cite class="ltx_cite ltx_citemacro_cite">Wójcik et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib42" title="">2023</a>)</cite>, enhancing the care provided by human healthcare professionals and improving patient outcomes <cite class="ltx_cite ltx_citemacro_cite">Javaid et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib17" title="">2023</a>)</cite>. LLM-based frameworks enable the creation of healthcare agents that integrate data sources, knowledge bases, and analytical models into their LLM-driven solutions <cite class="ltx_cite ltx_citemacro_cite">Abbasian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib1" title="">2024</a>)</cite>. Open-source models like LLaMA <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib36" title="">2023</a>)</cite> have demonstrated performance comparable to proprietary models, particularly in radiology examination questions <cite class="ltx_cite ltx_citemacro_cite">Adams et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib2" title="">2024</a>)</cite>. LLMs show potential in generating accurate, concise, and comprehensive responses to patient queries with minimal risk of harm <cite class="ltx_cite ltx_citemacro_cite">Yalamanchili et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib43" title="">2024</a>)</cite>. Recent advancements in prompting techniques, such as Chain of Thought (CoT) <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib39" title="">2022</a>)</cite> and In-Context Learning (ICL) <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib11" title="">2022</a>)</cite>, enable models to think step-by-step based on provided examples, improving both transparency and answer quality. Prompt optimization techniques <cite class="ltx_cite ltx_citemacro_cite">Wen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib40" title="">2024</a>); Pryzant et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib33" title="">2023</a>)</cite> have further boosted performance on specialized tasks. Additionally, self-consistency <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib38" title="">2023</a>)</cite> has increased the reliability of LLM-generated outputs.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">LLMs have made a significant impact on healthcare, delivering remarkable results across various applications. They have been utilized in generating discharge summaries <cite class="ltx_cite ltx_citemacro_cite">Ellershaw et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib12" title="">2024</a>); Williams et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib41" title="">2024</a>)</cite> and improving care coordination <cite class="ltx_cite ltx_citemacro_cite">Nashwan and Hani (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib30" title="">2023</a>); Jung et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib18" title="">2024</a>)</cite>. Many studies have focused on EHR-based applications, including information extraction <cite class="ltx_cite ltx_citemacro_cite">Gu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib14" title="">2024</a>); Cui et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib10" title="">2024</a>); Ahsan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib3" title="">2023</a>)</cite>, question-answering <cite class="ltx_cite ltx_citemacro_cite">Yan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib44" title="">2024</a>)</cite>, and text-to-SQL parsing <cite class="ltx_cite ltx_citemacro_cite">Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib22" title="">2022</a>)</cite>. In oncology, LLMs have been extensively employed. Domain-specific LLM development has been explored, particularly for prostate cancer <cite class="ltx_cite ltx_citemacro_cite">Tariq et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib35" title="">2024</a>)</cite>, and they have been used for decision support in personalized oncology care <cite class="ltx_cite ltx_citemacro_cite">Benary et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib6" title="">2023</a>)</cite>. GPT-4 has demonstrated the ability to answer 85% of examination-style multiple-choice questions from the American Society of Oncology <cite class="ltx_cite ltx_citemacro_cite">Longwell et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib26" title="">2024</a>)</cite>. LLMs have been applied to breast cancer report generation <cite class="ltx_cite ltx_citemacro_cite">Naik et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib29" title="">2023</a>)</cite> and to extract clinical information from radiology reports, such as breast ultrasounds <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib7" title="">2024</a>)</cite> and lung lesions from medical images <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib25" title="">2024</a>)</cite>. Additionally, LLMs have been used to interpret ESMO<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Refer: https://www.esmo.org/guidelines</span></span></span> and NCCN guidelines for lung cancer <cite class="ltx_cite ltx_citemacro_cite">Iivanainen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib16" title="">2024</a>)</cite>, as well as to generate clinical guidance trees for decision-making <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib24" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Digital Twins have been applied in oncology for predicting cancer progression and detecting metastases <cite class="ltx_cite ltx_citemacro_cite">Batch et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib5" title="">2022</a>); Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib19" title="">2022</a>)</cite>, as well as in cardiology, where they simulate heart functions to optimize treatments through predictive modeling <cite class="ltx_cite ltx_citemacro_cite">Corral-Acero et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib8" title="">2020</a>)</cite>. In neurology, digital twins assist in therapy planning and patient monitoring for conditions such as Alzheimer’s and epilepsy <cite class="ltx_cite ltx_citemacro_cite">Ashraf et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib4" title="">2024</a>)</cite>. AI and Digital Twins also contribute to fields like stress management <cite class="ltx_cite ltx_citemacro_cite">Kumi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib21" title="">2024</a>)</cite>, nephrology <cite class="ltx_cite ltx_citemacro_cite">Miao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib28" title="">2023</a>)</cite>, and autism care <cite class="ltx_cite ltx_citemacro_cite">Iannone and Giansanti (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib15" title="">2024</a>)</cite>, illustrating their impact across medical disciplines.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="294" id="S2.F1.g1" src="extracted/5873438/twin.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An illustration of the Digital Twin Framework highlighting its various capabilities and their integration with the knowledge base. </figcaption>
</figure>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Before delving into the practical applications, it is essential to introduce two key concepts that form the foundation of our approach. First is the <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">Cancer Care Path</span>, which outlines the ideal sequence of care a patient should follow throughout their oncology journey. This serves as the benchmark for optimal patient care. Second, is the <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">Digital Twin framework</span>, which defines the structure and functionality of our digital twins. It outlines the capabilities and inputs of each digital twin, as well as their interactions and collaboration with other agents to achieve desired outcomes. These principles collectively inform the design and implementation of digital twins in oncology care.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Cancer Care Path</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">Cancer Care Path</span> represents a comprehensive, structured approach of managing patient’s journey, right from cancer diagnosis through treatment and beyond. It is designed to act as a knowledge graph or decision tree that outlines the ideal flow of care for a cancer patient. This path incorporates all the critical stages, starting from the early detection of symptoms, to the diagnostic tests that can be prescribed, and further to the available treatment options and medications. Each step or entity within this path is represented as an object in itself, having its own guidelines that dictate when and how it should be used. These guidelines ensure that decision-making is streamlined, reducing variability in care while improving patient outcomes by adhering to best practices. For example, an entity within the care path may represent a specific diagnostic test or treatment modality, and it comes with associated guidelines that help determine whether it is appropriate for a given patient. An agent, interacting with this path, can check whether all clinical criteria for proceeding to the next step are fulfilled. This system facilitates efficient, evidence-based care management.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">NCCN Guidelines form the foundation of <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1">Cancer Care Path</span>. These evidence-based, research-backed, recommendations provide authoritative guidance on the treatment, management, and prevention of cancer. Developed by the <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.2">National Comprehensive Cancer Network</span> (NCCN), these guidelines are widely regarded as gold standard in oncology for clinical decision-making. Furthermore, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.3">Cancer Care Path</span> has been developed in consultation with expert oncologists to ensure that it integrates practical clinical insights alongside NCCN’s evidence-based recommendations. This comprehensive approach ensures that patients receive optimal care at every stage of their cancer journey, in alignment with the latest advancements in cancer treatment.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Digital Twin Framework</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In our framework, a digital twin represents a virtual replica of a real-world entity or process within oncology care. This digital twin processes multiple input modalities—including text, audio, imaging, and structured medical data—and generates outputs based on predefined knowledge sources and embedded intelligence. These knowledge sources may include the cancer care path, NCCN guidelines, and payer guidelines for treatment acceptance. The digital twin’s functionality is driven by dynamically generated prompts, which are augmented through techniques like In-Context Learning (ICL) <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib11" title="">2022</a>)</cite> and Chain-of-Thought (CoT) reasoning <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib39" title="">2022</a>)</cite>. In-Context Learning adapts to input data by retrieving examples from a vector database that stores relevant cases, utilizing Retrieval-Augmented Generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib23" title="">2020</a>)</cite> to enhance decision-making processes. This retrieval ensures that the prompts remain contextually relevant to each individual patient case, thereby improving the twin’s ability to generate accurate and patient-specific insights.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Multimodal large language models (LLMs), potentially fine-tuned for oncology-specific tasks, process the dynamically generated prompts. By generating explicit reasoning logs, the digital twin’s outputs are made interpretable to healthcare professionals, offering insight into the rationale behind each prediction, recommendation, or simulation. To handle more complex tasks that go beyond the capabilities of large language models (LLMs), the digital twin ecosystem often integrates software engineering techniques. This integration transforms digital twins into sophisticated software programs that incorporate LLMs as core components, but extend their functionality through symbolic reasoning and algorithmic processes. For instance, these engineering techniques can be used to simulate the likelihood of a prior authorization request being approved by a payer, modeling not just probabilistic outcomes but also deterministic, rule-based logic such as payer-specific criteria.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">In addition to its core functionality, the digital twin is capable of <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.1.1">agent collaboration</span>, wherein it communicates and delegates tasks to other specialized agents via function calling. This distributed architecture ensures that complex, multi-step workflows are handled efficiently. For instance, if a twin requires verification of whether a treatment aligns with payer guidelines, it can delegate this task to another twin specifically designed to handle payer-related queries. This collaborative approach, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4.F3" title="Figure 3 ‣ 4.1 Medical Necessity Twin ‣ 4 Twin Applications for Oncology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_tag">3</span></a>, allows the ecosystem to manage interconnected processes in parallel, ensuring scalability and reducing the cognitive load on any single digital twin. By leveraging both multimodal data inputs and state-of-the-art machine learning techniques, the digital twin framework in oncology care provides an advanced, adaptive, and explainable system capable of supporting complex clinical decision-making.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Twin Applications for Oncology</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The application of digital twins in oncology helps enhancing patient care by integrating advanced data analysis, clinical guidelines, and real-time decision support. Each twin is designed to handle specific aspects of the oncology care journey, from determining the medical necessity of treatments to visualizing a patient’s clinical history and guiding the overall care pathway. Together, these digital twins form a cohesive system that supports healthcare providers in making informed, evidence-based decisions at every stage of a patient’s treatment as depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4.F3" title="Figure 3 ‣ 4.1 Medical Necessity Twin ‣ 4 Twin Applications for Oncology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Medical Necessity Twin</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">Medical Necessity Twin</span> assists healthcare providers in determining the medical necessity of treatments and diagnostic tests in oncology care. By evaluating the patient’s clinical data—such as symptoms, diagnostic tests, and prior treatments in conjunction with established guidelines such as the NCCN guidelines and payer-specific criteria, this twin ensures that proposed treatments are appropriate and justified based on the patient’s medical history and condition.</p>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="262" id="S4.F2.g1" src="extracted/5873438/candidates.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustrating the various agents that comprise the <span class="ltx_text ltx_font_italic" id="S4.F2.2.1">Medical Necessity Twin</span>, highlighting how they interact and address each item on the clinical guideline checklist.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="266" id="S4.F3.g1" src="extracted/5873438/ecosystem.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Different twins in Digital Twin ecosystem leveraging knowledge base and interacting with other twins for optimal efficiency</figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">As demonstrated in previous research, the Medical Necessity Twin achieves 86% accuracy in automating the determination of medical necessity <cite class="ltx_cite ltx_citemacro_cite">Pandey et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#bib.bib32" title="">2024</a>)</cite>. Additionally, the Medical Necessity Twin supports other twins by providing real-time assessments of treatment eligibility. This ensures that any recommendations made by other twins meet the specific criteria required for payer approval, thereby improving the overall efficiency of patient care.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Clinical History Twin</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The <span class="ltx_text ltx_font_italic" id="S4.SS2.p1.1.1">Clinical History Twin</span> is designed to visualize the complete timeline of a patient’s tests, treatments, and clinical interventions in a chronological format. By presenting this data in a clear, time-sequenced manner, this twin allows healthcare providers to quickly and efficiently interpret the progression of care. This visualization aids in identifying patterns, understanding the effectiveness of previous treatments, and determining the next steps in care. Furthermore, it allows healthcare professionals to spot gaps or delays in care and assess how well the treatment plan has been followed.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">To implement the <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">Clinical History Twin</span>, a combination of structured and unstructured data is extracted from the patient’s EHR. LLM-based agents are used to extract and convert key clinical events into structured formats identifying important events, such as treatment milestones or changes in a patient’s condition, and organizing them within the timeline. Additionally, these agents map relationships between various clinical events—such as linking a diagnosis to subsequent treatments—thereby ensuring the timeline offers a comprehensive, interconnected view of the patient’s care history. Experiments to validate this approach are ongoing, and the results with a detailed architecture will be discussed in a future paper.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Care Navigator Twin</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The <span class="ltx_text ltx_font_italic" id="S4.SS3.p1.1.1">Care Navigator Twin</span> plays a pivotal role in guiding a patient’s oncology care journey by leveraging the cancer care path. By analyzing patient-specific data, including their EHR and clinical history, it predicts the next optimal steps in the care journey, ensuring that each decision follows the most current clinical guidelines. This involves identifying which diagnostic tests, treatments, or medications should be recommended at each stage of the patient’s journey, based on both historical data and current best practices.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The Care Navigator Twin can anticipate potential challenges or deviations from the expected care path by comparing the ideal cancer care path with the patient’s actual care journey using input from the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS3.p2.1.1">Clinical History Twin</span>. Additionally, its predictions are further strengthened by real-time data from the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS3.p2.1.2">Medical Necessity Twin</span>, ensuring that treatment decisions are both clinically sound and meet payer-specific guidelines, increasing the likelihood of treatment approval.</p>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="365" id="S4.F4.g1" src="extracted/5873438/diagnosis_half.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>A visual representation of Cancer Care Graph built for Ovarian Cancer Diagnosis</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Case Study: Ovarian Cancer Diagnosis</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We present a case study of ovarian cancer, demonstrating the use of the previously mentioned twins at various points in the care process. First, we constructed the cancer care graph using a variety of guidelines and online resources, particularly adhering to NCCN guidelines. We then illustrate how and where different agents interact throughout the patient’s oncology care journey.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Cancer Care Graph</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Using the ovarian cancer NCCN guidelines<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Refer: https://www.nccn.org/guidelines/category_1</span></span></span>, we extracted key diagnostic tests and tools employed in diagnosing ovarian cancer. Our focus is primarily on the initial symptoms and the diagnostic process that progresses to a clinical determination of ovarian cancer a hown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4.F4" title="Figure 4 ‣ 4.3 Care Navigator Twin ‣ 4 Twin Applications for Oncology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_tag">4</span></a>. Similar graphs can be developed for treatment and follow-up monitoring, and can be extended to other cancer types.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Diagnosis Journey</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The journey begins when a patient presents to a primary care provider with symptoms such as bloating, pelvic or abdominal pain, difficulty eating or feeling full quickly, or urinary symptoms. If the provider suspects ovarian cancer after reviewing the patient’s history and conducting a physical exam, the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.SS2.p1.1.1">Care Navigator Agent</span> suggests a series of preliminary tests based on NCCN guidelines. These tests typically include CA-125 or other tumor marker tests, a Complete Blood Count (CBC) with Liver Function Tests (LFT), and/or a transvaginal ultrasound. At this point, the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.SS2.p1.1.2">Medical Necessity Twin</span> identifies the patient’s payer from the EHR and retrieves the payer’s guidelines for each recommended test. It then runs simulations to determine which of these tests are likely to be approved based on the patient’s medical condition and the clinical examinations already performed by the provider. A sample CA-125 guideline from Anthem<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Refer: https://www.anthem.com/dam/medpolicies/abc/ active/guidelines/gl_pw_e002881.html</span></span></span> is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S5.F5" title="Figure 5 ‣ 5.2 Diagnosis Journey ‣ 5 Case Study: Ovarian Cancer Diagnosis ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_tag">5</span></a>. The Medical Necessity Twin evaluates the relevant data, checks if the clinical guidelines are satisfied, and does the same for all recommended tests. The provider can then see, in real-time, which tests are eligible for recommendation based on the results provided by the Medical Necessity Twin.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Based on the preliminary test results, the Care Navigator Twin interprets the cancer care graph and recommends the next steps, which could include an abdominal/pelvic CT scan. It also recommends that the CT scan be conducted with oral and IV contrast, following NCCN guidelines. Once again, the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.SS2.p2.1.1">Medical Necessity Twin</span> becomes active, identifies the correct CPT code for this test—74177 (CT of the abdomen and pelvis with contrast) versus 74176 (without contrast)—retrieves the relevant guidelines, and determines if the test will be approved.</p>
</div>
<figure class="ltx_figure ltx_figure_panel" id="S5.F5"><svg class="ltx_picture ltx_figure_panel" height="129.05" id="S5.SS2.1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,129.05) matrix(1 0 0 -1 0 0)"><g fill="#999999" fill-opacity="1.0"><path d="M 0 4.63 L 0 124.42 C 0 126.97 2.07 129.05 4.63 129.05 L 595.37 129.05 C 597.93 129.05 600 126.97 600 124.42 L 600 4.63 C 600 2.07 597.93 0 595.37 0 L 4.63 0 C 2.07 0 0 2.07 0 4.63 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.69 4.63 L 0.69 105.95 L 599.31 105.95 L 599.31 4.63 C 599.31 2.45 597.55 0.69 595.37 0.69 L 4.63 0.69 C 2.45 0.69 0.69 2.45 0.69 4.63 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.44 110.58)"><foreignobject color="#FFFFFF" height="13.84" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="567.12">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.1.pic1.1.1.1.1.1" style="width:409.9pt;">
<span class="ltx_p" id="S5.SS2.1.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.1.pic1.1.1.1.1.1.1.1">Tumor Marker Cancer Antigen 125 (CA-125) Testing</span></span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 16.44 12.5)"><foreignobject color="#000000" height="81.64" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="567.12">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS2.1.pic1.2.2.2.1.1" style="width:409.9pt;">
<span class="ltx_p ltx_align_left" id="S5.SS2.1.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.SS2.1.pic1.2.2.2.1.1.1.1">CA-125 testing is considered medically necessary for any of the following:<span class="ltx_text ltx_font_medium" id="S5.SS2.1.pic1.2.2.2.1.1.1.1.1"></span></span></span>
<span class="ltx_enumerate ltx_align_left" id="S5.I1">
<span class="ltx_item" id="S5.I1.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">1.</span>
<span class="ltx_para" id="S5.I1.i1.p1">
<span class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_typewriter" id="S5.I1.i1.p1.1.1">Evaluation of a pelvic or abdominal mass in postmenopausal individuals; or</span></span>
</span></span>
<span class="ltx_item" id="S5.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">2.</span>
<span class="ltx_para" id="S5.I1.i2.p1">
<span class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_typewriter" id="S5.I1.i2.p1.1.1">Evaluation of a pelvic or abdominal mass suspicious for an epithelial ovarian cancer or other specified malignancy in premenopausal individuals; or</span></span>
</span></span>
<span class="ltx_item" id="S5.I1.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">3.</span>
<span class="ltx_para" id="S5.I1.i3.p1">
<span class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_typewriter" id="S5.I1.i3.p1.1.1">Evaluation of an individual with signs or symptoms suggestive of ovarian cancer (for example, ascites, abdominal distention, bloating, pelvic/abdominal pain, difficulty eating or feeling full quickly, urinary symptoms);</span></span>
</span></span>
</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>An example checklist from Anthem listing medical necessity conditions for CA-125 testing</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">Similarly, for all other tests and treatments, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.17650v1#S4.F3" title="Figure 3 ‣ 4.1 Medical Necessity Twin ‣ 4 Twin Applications for Oncology ‣ Digital Twin Ecosystem for Oncology Clinical Operations"><span class="ltx_text ltx_ref_tag">3</span></a>, the Medical Necessity Twin fetches the appropriate guidelines from both the payer and NCCN sources. Based on simulations, it provides results to the provider. During each encounter with the provider, the <span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.SS2.p3.1.1">Clinical History Twin</span> continues to accumulate data, offering insights from prior test results to both the provider and the Care Navigator Twin, thus enhancing the decision-making process.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we introduced a framework for creating digital twins and demonstrated its use cases in oncology. Specifically, we presented three key twins: the Medical Necessity Twin, the Care Navigator Twin, and the Clinical History Twin. We showcased how these twins will collaborate to enhance the efficiency of care delivery. Additionally, we introduced the concept of the Cancer Care Path, which supports the twins in knowledge retrieval tasks. Combined with NCCN guidelines and payer-specific criteria, this forms a comprehensive knowledge base that the twins can leverage. This led to the creation of a collaborative ecosystem, where the twins operate within and are enriched by their environment. Each agent generates logs through chain-of-thought prompting, contributing to the explainability of the entire twin ecosystem. Finally, we presented a case study to illustrate the structure of the Cancer Care Path and how these agents work together to successfully navigate the care process for optimal outcomes in ovarian cancer.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Future Work</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We have introduced an ecosystem that supports clinical decision-making and operations in oncology. While we defined a set of preliminary twins within this ecosystem, there is potential to expand the number of twins to support a broader range of operations. Each twin will adhere to the digital twin framework, enabling seamless collaboration and interaction within the ecosystem. The framework itself can also evolve to incorporate additional features that streamline collaboration and workflow management. One such enhancement could be the implementation of self-verification mechanisms, such as self-consistency or fact-checking, to minimize hallucination and ensure high-quality results.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Future twins could focus on tasks such as ambient note-taking, patient education, self-care best practices, and patient scheduling, each of which would benefit from the collaborative ecosystem. The knowledge base, which the twins rely on, must also become more sophisticated. It should not only include clinical guidelines but also practical insights, providing comprehensive and exhaustive knowledge tailored to specific use cases. Further work is needed to improve how knowledge is organized and presented to these agents, ensuring that the system produces accurate and reliable outputs.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">While Chain of Thought (CoT) prompting enhances explainability at the agent level, there is a need for additional tools to provide transparency at the twin and ecosystem levels. This would help make the entire ecosystem more interpretable and trusted by the medical community, fostering broader acceptance of this technology in clinical settings.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abbasian et al. (2024)</span>
<span class="ltx_bibblock">
Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, and Ramesh Jain. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.02374" title="">Conversational health agents: A personalized llm-powered agent framework</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adams et al. (2024)</span>
<span class="ltx_bibblock">
Lisa C Adams, Daniel Truhn, Felix Busch, Felix Dorfner, Jawed Nawabi, Marcus R Makowski, and Keno K Bressem. 2024.

</span>
<span class="ltx_bibblock">Llama 3 challenges proprietary state-of-the-art large language models in radiology board–style examination questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Radiology</em>, 312(2):e241191.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahsan et al. (2023)</span>
<span class="ltx_bibblock">
Hiba Ahsan, Denis Jered McInerney, Jisoo Kim, Christopher Potter, Geoffrey Young, Silvio Amir, and Byron C Wallace. 2023.

</span>
<span class="ltx_bibblock">Retrieving evidence from ehrs with llms: Possibilities and challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2309.04550</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ashraf et al. (2024)</span>
<span class="ltx_bibblock">
Taniya Ashraf, Mohammad Ahsan Chisti, and Mohamed Mahees Raheem. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/LT60077.2024.10469438" title="">Digital twin for neurology: An introduction to a new frontier in healthcare</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">2024 21st Learning and Technology Conference (L&amp;T)</em>, pages 284–289.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Batch et al. (2022)</span>
<span class="ltx_bibblock">
Karen E. Batch, Jianwei Yue, Alex Darcovich, Kaelan Lupton, Corinne C. Liu, David P. Woodlock, Mohammad Ali K. El Amine, Pamela I. Causa-Andrieu, Lior Gazit, Gary H. Nguyen, Farhana Zulkernine, Richard K. G. Do, and Amber L. Simpson. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3389/frai.2022.826402" title="">Developing a cancer digital twin: Supervised metastases detection from consecutive structured radiology reports</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Frontiers in Artificial Intelligence</em>, 5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benary et al. (2023)</span>
<span class="ltx_bibblock">
Manuela Benary, Xing David Wang, Max Schmidt, Dominik Soll, Georg Hilfenhaus, Mani Nassir, Christian Sigler, Maren Knödler, Ulrich Keller, Dieter Beule, Ulrich Keilholz, Ulf Leser, and Damian T. Rieke. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1001/jamanetworkopen.2023.43689" title="">Leveraging Large Language Models for Decision Support in Personalized Oncology</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">JAMA Network Open</em>, 6(11):e2343689–e2343689.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Yuxuan Chen, Haoyan Yang, Hengkai Pan, Fardeen Siddiqui, Antonio Verdone, Qingyang Zhang, Sumit Chopra, Chen Zhao, and Yiqiu Shen. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2408.11334" title="">Burextract-llama: An llm for clinical concept extraction in breast ultrasound reports</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corral-Acero et al. (2020)</span>
<span class="ltx_bibblock">
Jorge Corral-Acero, Francesca Margara, Maciej Marciniak, Cristobal Rodero, Filip Loncaric, Yingjing Feng, Andrew Gilbert, Joao F Fernandes, Hassaan A Bukhari, Ali Wajdan, et al. 2020.

</span>
<span class="ltx_bibblock">The ‘digital twin’to enable the vision of precision cardiology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">European heart journal</em>, 41(48):4556–4564.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Croatti et al. (2020)</span>
<span class="ltx_bibblock">
Angelo Croatti, Matteo Gabellini, Sara Montagna, and Alessandro Ricci. 2020.

</span>
<span class="ltx_bibblock">On the integration of agents and digital twins in healthcare.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Journal of Medical Systems</em>, 44(9):161.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al. (2024)</span>
<span class="ltx_bibblock">
Hejie Cui, Xinyu Fang, Ran Xu, Xuan Kan, Joyce C Ho, and Carl Yang. 2024.

</span>
<span class="ltx_bibblock">Multimodal fusion of ehr in structures and semantics: Integrating clinical records and notes with hypergraph and llm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2403.08818</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2022)</span>
<span class="ltx_bibblock">
Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022.

</span>
<span class="ltx_bibblock">A survey on in-context learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2301.00234</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ellershaw et al. (2024)</span>
<span class="ltx_bibblock">
Simon Ellershaw, Christopher Tomlinson, Oliver E Burton, Thomas Frost, John Gerrard Hanrahan, Danyal Zaman Khan, Hugo Layard Horsfall, Mollie Little, Evaleen Malgapo, Joachim Starup-Hansen, et al. 2024.

</span>
<span class="ltx_bibblock">Automated generation of hospital discharge summaries using clinical guidelines and large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">AAAI 2024 Spring Symposium on Clinical Foundation Models</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Erol et al. (2020)</span>
<span class="ltx_bibblock">
Tolga Erol, Arif Furkan Mendi, and Dilara Doğan. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ISMSIT50672.2020.9255249" title="">The digital twin revolution in healthcare</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">2020 4th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)</em>, pages 1–7.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2024)</span>
<span class="ltx_bibblock">
Bowen Gu, Vivian Shao, Ziqian Liao, Valentina Carducci, Santiago Romero-Brufau, Jie Yang, and Rishi Desai. 2024.

</span>
<span class="ltx_bibblock">Scalable information extraction from free text electronic health records using large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">medRxiv</em>, pages 2024–08.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iannone and Giansanti (2024)</span>
<span class="ltx_bibblock">
Antonio Iannone and Daniele Giansanti. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3390/jpm14010041" title="">Breaking barriers—the intersection of ai and assistive technology in autism care: A narrative review</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Journal of Personalized Medicine</em>, 14(1):41.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iivanainen et al. (2024)</span>
<span class="ltx_bibblock">
Sanna Iivanainen, Jarkko Lagus, Henri Viertolahti, Lauri Sippola, and Jussi Koivunen. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1200/JCO.2024.42.16_suppl.e13637" title="">Investigating large language model (llm) performance using in-context learning (icl) for interpretation of esmo and nccn guidelines for lung cancer.</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Journal of Clinical Oncology</em>, 42(16_suppl):e13637–e13637.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Javaid et al. (2023)</span>
<span class="ltx_bibblock">
Mohd Javaid, Abid Haleem, and Ravi Pratap Singh. 2023.

</span>
<span class="ltx_bibblock">Chatgpt for healthcare services: An emerging stage for an innovative perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">BenchCouncil Transactions on Benchmarks, Standards and Evaluations</em>, 3(1):100105.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jung et al. (2024)</span>
<span class="ltx_bibblock">
HyoJe Jung, Yunha Kim, Heejung Choi, Hyeram Seo, Minkyoung Kim, JiYe Han, Gaeun Kee, Seohyun Park, Soyoung Ko, Byeolhee Kim, et al. 2024.

</span>
<span class="ltx_bibblock">Enhancing clinical efficiency through llm: Discharge note generation for cardiac patients.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2404.05144</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2022)</span>
<span class="ltx_bibblock">
Jae-Kwon Kim, Sun-Jung Lee, Sung-Hoo Hong, and In-Young Choi. 2022.

</span>
<span class="ltx_bibblock">Machine-learning-based digital twin system for predicting the progression of prostate cancer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Applied Sciences</em>, 12(16):8156.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kritzinger et al. (2018)</span>
<span class="ltx_bibblock">
Werner Kritzinger, Matthias Karner, Georg Traar, Jan Henjes, and Wilfried Sihn. 2018.

</span>
<span class="ltx_bibblock">Digital twin in manufacturing: A categorical literature review and classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Ifac-PapersOnline</em>, 51(11):1016–1022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumi et al. (2024)</span>
<span class="ltx_bibblock">
Sandra Kumi, Madhurima Ray, Sanskriti Walia, Richard K Lomotey, and Ralph Deters. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/AIIoT61789.2024.10579038" title="">Digital twins for stress management utilizing synthetic data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">2024 IEEE World AI IoT Congress (AIIoT)</em>, pages 329–335.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2022)</span>
<span class="ltx_bibblock">
Gyubok Lee, Hyeonji Hwang, Seongsu Bae, Yeonsu Kwon, Woncheol Shin, Seongjun Yang, Minjoon Seo, Jong-Yeup Kim, and Edward Choi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/643e347250cf9289e5a2a6c1ed5ee42e-Paper-Datasets_and_Benchmarks.pdf" title="">Ehrsql: A practical text-to-sql benchmark for electronic health records</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Advances in Neural Information Processing Systems</em>, volume 35, pages 15589–15601. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf" title="">Retrieval-augmented generation for knowledge-intensive nlp tasks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Advances in Neural Information Processing Systems</em>, volume 33, pages 9459–9474. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Binbin Li, Tianxin Meng, Xiaoming Shi, Jie Zhai, and Tong Ruan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2312.02441" title="">Meddm:llm-executable clinical guidance tree for clinical decision-making</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Diya Li, Asim Kadav, Aijing Gao, Rui Li, and Richard Bourgon. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2406.18027" title="">Automated clinical data extraction with knowledge conditioned llms</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longwell et al. (2024)</span>
<span class="ltx_bibblock">
Jack B. Longwell, Ian Hirsch, Fernando Binder, Galileo Arturo Gonzalez Conchas, Daniel Mau, Raymond Jang, Rahul G. Krishnan, and Robert C. Grant. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1001/jamanetworkopen.2024.17641" title="">Performance of Large Language Models on Medical Oncology Examination Questions</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">JAMA Network Open</em>, 7(6):e2417641–e2417641.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Makarov et al. (2024)</span>
<span class="ltx_bibblock">
Nikita Makarov, Maria Bordukova, Raul Rodriguez-Esteban, Fabian Schmich, and Michael P Menden. 2024.

</span>
<span class="ltx_bibblock">Large language models forecast patient health trajectories enabling digital twins.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">medRxiv</em>, pages 2024–07.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miao et al. (2023)</span>
<span class="ltx_bibblock">
J. Miao, C. Thongprayoon, S. Suppadungsuk, O.A. Garcia Valencia, F. Qureshi, and W. Cheungpasitporn. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3390/jpm13121681" title="">Innovating personalized nephrology care: Exploring the potential utilization of chatgpt</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Journal of Personalized Medicine</em>, 13(12):1681.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naik et al. (2023)</span>
<span class="ltx_bibblock">
HR Naik, AD Prather, and GT Gurda. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.7759/cureus.37587" title="">Synchronous bilateral breast cancer: A case report piloting and evaluating the implementation of the ai-powered large language model (llm) chatgpt</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Cureus</em>, 15(4):e37587.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nashwan and Hani (2023)</span>
<span class="ltx_bibblock">
Abdulqadir J Nashwan and Salam Bani Hani. 2023.

</span>
<span class="ltx_bibblock">Enhancing oncology nursing care planning for patients with cancer through harnessing large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Asia-Pacific Journal of Oncology Nursing</em>, 10(9).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.08774" title="">Gpt-4 technical report</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pandey et al. (2024)</span>
<span class="ltx_bibblock">
Himanshu Gautam Pandey, Akhil Amod, and Shivang Kumar. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.bionlp-1.4" title="">Advancing healthcare automation: Multi-agent system for medical necessity justification</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 23rd Workshop on Biomedical Natural Language Processing</em>, pages 39–49, Bangkok, Thailand. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pryzant et al. (2023)</span>
<span class="ltx_bibblock">
Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.03495" title="">Automatic prompt optimization with "gradient descent" and beam search</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023)</span>
<span class="ltx_bibblock">
Tianze Sun, Xiwang He, and Zhonghai Li. 2023.

</span>
<span class="ltx_bibblock">Digital twin in healthcare: Recent updates and challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Digital Health</em>, 9:20552076221149651.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tariq et al. (2024)</span>
<span class="ltx_bibblock">
Amara Tariq, Man Luo, Aisha Urooj, Avisha Das, Jiwoong Jeong, Shubham Trivedi, Bhavik Patel, and Imon Banerjee. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1101/2024.03.15.24304362" title="">Domain-specific llm development and evaluation – a case-study for prostate cancer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">medRxiv</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2302.13971" title="">Llama: Open and efficient foundation language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Väänänen et al. (2021)</span>
<span class="ltx_bibblock">
A Väänänen, K Haataja, K Vehviläinen-Julkunen, and P Toivanen. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.12688/f1000research.26997.2" title="">Ai in healthcare: A narrative review [version 2; peer review: 1 approved, 1 not approved]</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">F1000Research</em>, 10:6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2203.11171" title="">Self-consistency improves chain of thought reasoning in language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf" title="">Chain-of-thought prompting elicits reasoning in large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Advances in Neural Information Processing Systems</em>, volume 35, pages 24824–24837. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2024)</span>
<span class="ltx_bibblock">
Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Goldblum, Jonas Geiping, and Tom Goldstein. 2024.

</span>
<span class="ltx_bibblock">Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams et al. (2024)</span>
<span class="ltx_bibblock">
Christopher YK Williams, Jaskaran Bains, Tianyu Tang, Kishan Patel, Alexa N Lucas, Fiona Chen, Brenda Y Miao, Atul J Butte, and Aaron E Kornblith. 2024.

</span>
<span class="ltx_bibblock">Evaluating large language models for drafting emergency department discharge summaries.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">medRxiv</em>, pages 2024–04.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wójcik et al. (2023)</span>
<span class="ltx_bibblock">
Simona Wójcik, Anna Rulkiewicz, Piotr Pruszczyk, Wojciech Lisik, Marcin Poboży, and Justyna Domienik-Karłowicz. 2023.

</span>
<span class="ltx_bibblock">Beyond chatgpt: What does gpt-4 add to healthcare? the dawn of a new era.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Cardiology journal</em>, 30(6):1018–1025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yalamanchili et al. (2024)</span>
<span class="ltx_bibblock">
Amulya Yalamanchili, Bishwambhar Sengupta, Joshua Song, Sara Lim, Tarita O. Thomas, Bharat B. Mittal, Mohamed E. Abazeed, and P. Troy Teo. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1001/jamanetworkopen.2024.4630" title="">Quality of Large Language Model Responses to Radiation Oncology Patient Care Questions</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">JAMA Network Open</em>, 7(4):e244630–e244630.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. (2024)</span>
<span class="ltx_bibblock">
Chao Yan, Henry H Ong, Monika E Grabowska, Matthew S Krantz, Wu-Chen Su, Alyson L Dickson, Josh F Peterson, QiPing Feng, Dan M Roden, C Michael Stein, et al. 2024.

</span>
<span class="ltx_bibblock">Large language models facilitate the generation of electronic health record phenotyping algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Journal of the American Medical Informatics Association</em>, page ocae072.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 26 08:52:56 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
