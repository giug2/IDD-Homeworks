<article class="ltx_document ltx_authors_1line ltx_leqno">
 <h1 class="ltx_title ltx_title_document">
  Can Large Language Models Serve as Data Analysts?
  <br class="ltx_break"/>
  A Multi-Agent Assisted Approach for Qualitative Data Analysis
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Zeeshan Rasheed, Muhammad Waseem, Aakash Ahmad, Kai-Kristian Kemell, Wang Xiaofeng, Anh Nguyen Duc, Pekka Abrahamsson
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">
      Faculty of Information Technology and Communication Science, Tampere University
      <br class="ltx_break"/>
      Faculty of Information Technology, Jyväskylä University
      <br class="ltx_break"/>
      Faculty of Mathematics and Natural Sciences, University of Helsinki
      <br class="ltx_break"/>
      Faculty of Computing and Communications, Lancaster University Leipzig
      <br class="ltx_break"/>
      Faculty of Engineering, Free University of Bozen Bolzano
     </span>
     <span class="ltx_text ltx_affiliation_city" id="id2.2.id2">
      Tampere, Helsinki, Jyväskylä, Leipzig, and Bolzano
     </span>
     <br class="ltx_break"/>
     <span class="ltx_text ltx_affiliation_country" id="id3.3.id3">
      Finland, Germany, and Italy
     </span>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:zeeshan.rasheed@tuni.fi">
      zeeshan.rasheed@tuni.fi
     </a>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:muhammad.m.waseem@jyu.fi">
      muhammad.m.waseem@jyu.fi
     </a>
    </span>
    <span class="ltx_contact ltx_role_email">
     <a href="mailto:pekka.abrahamsson@tuni.fi">
      pekka.abrahamsson@tuni.fi
     </a>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_dates">
  (2018)
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract.
  </h6>
  <p class="ltx_p" id="id4.id1">
   Recent advancements in Large Language Models (LLMs) have enabled collaborative human-bot interactions in Software Engineering (SE), similar to many other professions. However, the potential benefits and implications of incorporating LLMs into qualitative data analysis in SE have not been completely explored. For instance, conducting qualitative data analysis manually can be a time-consuming, effort-intensive, and error-prone task for researchers. LLM-based solutions, such as generative AI models trained on massive datasets, can be utilized to automate tasks in software development as well as in qualitative data analysis. To this end, we utilized LLMs to automate and expedite the qualitative data analysis processes. We employed a multi-agent model, where each agent was tasked with executing distinct, individual research related activities. Our proposed model interpreted large quantities of textual documents and interview transcripts to perform several common tasks used in qualitative analysis. The results show that this technical assistant speeds up significantly the data analysis process, enabling researchers to manage larger datasets much more effectively. Furthermore, this approach introduces a new dimension of scalability and accuracy in qualitative research, potentially transforming data interpretation methodologies in SE.
  </p>
 </div>
 <div class="ltx_keywords">
  OpenAI, AutoGPT, Qualitative Data Analysis, Artificial Intelligence, Natural Language Processing, Generative AI, Software Engineering
 </div>
 <span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     copyright:
    </span>
    acmcopyright
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     journalyear:
    </span>
    2018
   </span>
  </span>
 </span>
 <span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <span class="ltx_note_type">
     doi:
    </span>
    XXXXXXX.XXXXXXX
   </span>
  </span>
 </span>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1.
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    The recent developments in Large Language Models (LLMs) have significantly transformed the academic world and various other fields
    <cite class="ltx_cite ltx_citemacro_citep">
     (Hou et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2023
     </a>
     )
    </cite>
    . LLMs have emerged as key areas of study. For instance, LLMs like OpenAI’s GPT and Google’s BERT have shown remarkable capabilities in understanding, interpreting, and generating human-like text, making them invaluable tools across various sectors
    <cite class="ltx_cite ltx_citemacro_citep">
     (Fan et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib14" title="">
      2023
     </a>
     )
    </cite>
    . Their significance lies not only in their technological prowess but also in their ability to process and analyze large volumes of data with unprecedented efficiency. This transformative technology has opened new frontiers in research and application, especially in Software Engineering (SE)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib43" title="">
      2023
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    In past years, SE has traditionally been a highly manual, human-driven process that involves a range of activities
    <cite class="ltx_cite ltx_citemacro_citep">
     (Belzner et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib4" title="">
      2023
     </a>
     )
    </cite>
    . Recent advances in LLMs have opened a wide array of applications in various SE domains. The adoption of LLMs in SE is primarily driven by an innovative approach where many SE tasks are effectively transformed into activities involving data, code, or text analysis. LLMs have shown a wealth of potential breakthroughs in performing various SE tasks.
    <cite class="ltx_cite ltx_citemacro_citep">
     (Radford et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib31" title="">
      2018
     </a>
     )
    </cite>
    ,
    <cite class="ltx_cite ltx_citemacro_citep">
     (Cao et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2023
     </a>
     )
    </cite>
    ,
    <cite class="ltx_cite ltx_citemacro_citep">
     (Peng et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib30" title="">
      2023
     </a>
     )
    </cite>
    ,
    <cite class="ltx_cite ltx_citemacro_citep">
     (Finnie-Ansley et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2022
     </a>
     )
    </cite>
    ,
    <cite class="ltx_cite ltx_citemacro_citep">
     (Rasheed et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib33" title="">
      2023
     </a>
     )
    </cite>
    . For instance, The applicability of LLMs is particularly pronounced in tasks such as code generation, understanding, execution, and reasoning and natural language interactions with codebases, etc.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    In the domain of qualitative data analysis in SE, LLMs play an important role. LLMs can significantly benefit qualitative data analysis by automating the extraction and interpretation of insights from large volumes of text data
    <cite class="ltx_cite ltx_citemacro_citep">
     (Xiao et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib44" title="">
      2023
     </a>
     )
    </cite>
    . For instance, the traditional approach to data analysis is highly dependent on human expertise, which consumes more time and human effort. Qualitative data analysis is significantly reliant on primary data in the form of unstructured text or recordings from interviews. Software tools commonly employed for this purpose include MAXQDA
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kuckartz and Rädiker,
     <a class="ltx_ref" href="#bib.bib25" title="">
      2019
     </a>
     )
    </cite>
    , Nvivo
    <cite class="ltx_cite ltx_citemacro_citep">
     (Hilal and Alabri,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2013
     </a>
     )
    </cite>
    , Atlas.ti
    <cite class="ltx_cite ltx_citemacro_citep">
     (Smit,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2002
     </a>
     )
    </cite>
    , Dedoose
    <cite class="ltx_cite ltx_citemacro_citep">
     (Salmona et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib36" title="">
      2019
     </a>
     )
    </cite>
    , WebQDA
    <cite class="ltx_cite ltx_citemacro_citep">
     (Costa et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2018
     </a>
     )
    </cite>
    , and QDAMiner
    <cite class="ltx_cite ltx_citemacro_citep">
     (Rietz and Maedche,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2021
     </a>
     )
    </cite>
    . However, these qualitative data analysis tools require significant human input. They facilitate analysis but don’t eliminate the need for manual coding, interpretation, and decision-making by researchers. This can be time-consuming and requires a high level of expertise.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    These traditional approaches to data analysis depend on human expertise. However, with LLMs, there is a paradigm shift towards more automated, intelligent systems. These models offer the potential to sift through extensive qualitative data, such as user feedback, software documentation, and development logs, to extract valuable insights. By doing so, LLMs not only enhance the efficiency of data analysis but also bring a level of depth and nuance to the interpretation of qualitative data, which was previously challenging to achieve. Several researchers, including Chew
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">
     et al
    </span>
    .
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chew et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2023
     </a>
     )
    </cite>
    , Dai
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">
     et al
    </span>
    .
    <cite class="ltx_cite ltx_citemacro_citep">
     (Dai et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib10" title="">
      2023
     </a>
     )
    </cite>
    , and Xiao
    <span class="ltx_text ltx_font_italic" id="S1.p4.1.3">
     et al
    </span>
    .
    <cite class="ltx_cite ltx_citemacro_citep">
     (Xiao et al
     <span class="ltx_text">
      .
     </span>
     ,
     <a class="ltx_ref" href="#bib.bib44" title="">
      2023
     </a>
     )
    </cite>
    explored the potential of LLMs in qualitative data analysis. However, their efforts primarily focus on automating thematic analysis and content analysis approaches to generate initial codes. Despite these advancements, a notable gap persists in the development of LLM-based models that can autonomously perform all types of qualitative data analysis processes. Further exploration and innovation are required to bridge this gap and unlock the full potential of LLMs in qualitative research.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    In this paper, we address these gaps by designing LLM based multi agent model to automate the qualitative data analysis processes. The model adeptly interprets massive volumes of textual data and interview transcripts to autonomously perform the chosen approach for qualitative data analysis. This technical advancement markedly accelerates the data analysis process, allowing researchers to handle larger datasets with greater efficacy. Moreover, this wide-ranging capability not only speeds up data analysis but also extends its use, making it a crucial model for researchers handling diverse set of qualitative data. We conducted a thorough evaluation of our developed model by involving ten practitioners with diverse professional backgrounds. We carefully analyzed all the feedback provided by the practitioners, and 87% of them expressed satisfaction with the model’s performance.
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    Our contribution can be summarized as follow:
   </p>
  </div>
  <div class="ltx_para" id="S1.p7">
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       The proposed LLM based multi agent model automates various qualitative data analysis approaches, including thematic analysis, grounded theory, content analysis, narrative analysis, and discourse analysis.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p8">
   <ul class="ltx_itemize" id="S1.I2">
    <li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I2.i1.p1">
      <p class="ltx_p" id="S1.I2.i1.p1.1">
       The proposed model efficiently analyzes large amounts of unstructured textual data, to autonomously perform chosen approach of qualitative data analysis within a minute. The innovative model integrates advanced language modeling techniques to facilitate and streamline qualitative data analysis. This model can significantly expedites processes while enhancing scalability and accuracy in SE research.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p9">
   <ul class="ltx_itemize" id="S1.I3">
    <li class="ltx_item" id="S1.I3.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I3.i1.p1">
      <p class="ltx_p" id="S1.I3.i1.p1.1">
       We further validated the performance of the developed model by engaging practitioners from diverse backgrounds. The results indicate that 87% of practitioners expressed satisfaction with our proposed model.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p10">
   <p class="ltx_p" id="S1.p10.1">
    The rest of the paper is organized as follows. We review related work in Section
    <a class="ltx_ref" href="#S2" title="2. Related Work ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    and describe the study methodology in Section
    <a class="ltx_ref" href="#S3" title="3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    . The results of this study are presented in Section
    <a class="ltx_ref" href="#S4" title="4. Results ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      4
     </span>
    </a>
    with a discussion in Section
    <a class="ltx_ref" href="#S5" title="5. Discussion ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    , and the study is concluded with future work in Section
    <a class="ltx_ref" href="#S6" title="6. Conclusions ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    .
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2.
   </span>
   Related Work
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    In this section, we briefly present the related work of the study with a focus on existing research. Section
    <a class="ltx_ref" href="#S2.SS1" title="2.1. Large Language Models in Software Engineering ‣ 2. Related Work ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      2.1
     </span>
    </a>
    provides an overview of studies concerning LLMs and SE. Section
    <a class="ltx_ref" href="#S2.SS2" title="2.2. Large Language Models in Qualitative Research ‣ 2. Related Work ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      2.2
     </span>
    </a>
    examines works that have utilized LLMs for qualitative data analysis.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1.
    </span>
    Large Language Models in Software Engineering
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     In recent years, LLMs have shown promise in various SE applications
     <cite class="ltx_cite ltx_citemacro_citep">
      (Feng et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib15" title="">
       2023
      </a>
      )
     </cite>
     . LLMs are language models consisting of billions of parameters trained from a significant amount of data and have impressive performance in language processing tasks, including both natural languages and programming languages
     <cite class="ltx_cite ltx_citemacro_citep">
      (Feng et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib16" title="">
       2020
      </a>
      )
     </cite>
     ,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Guo et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib19" title="">
       2022
      </a>
      )
     </cite>
     . LLMs designed for processing and generating human-like text, and GPT (Generative Pre-trained Transformer) is a prominent example within this category
     <cite class="ltx_cite ltx_citemacro_citep">
      (Eloundou et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2023
      </a>
      )
     </cite>
     . GPT models are particularly notable for their ability to perform a wide range of language tasks, from translation and summarizing to question-answering and creative writing, without needing task-specific training. As such, GPT stands as a flagship example of LLMs, showcasing the potential of these models in various applications that require nuanced language understanding and generation
     <cite class="ltx_cite ltx_citemacro_citep">
      (Valmeekam et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib42" title="">
       2022
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.1">
     As Treude
     <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.1">
      et al
     </span>
     .
     <cite class="ltx_cite ltx_citemacro_citep">
      (Treude,
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023
      </a>
      )
     </cite>
     mentioned, the GPT model and SE are related by applying NLP techniques to various tasks within the software development lifecycle. GPT’s language generation capabilities offer valuable assistance and enhancements to SE processes
     <cite class="ltx_cite ltx_citemacro_citep">
      (Thiergart et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2021
      </a>
      )
     </cite>
     ,
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hörnemalm,
      <a class="ltx_ref" href="#bib.bib22" title="">
       2023
      </a>
      )
     </cite>
     .
The integration of LLMs into SE has marked a significant paradigm shift in this field
     <cite class="ltx_cite ltx_citemacro_citep">
      (Allamanis et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib2" title="">
       2017
      </a>
      )
     </cite>
     . LLMs have demonstrated significant benefits compared to traditional methods like models guided by domain-specific languages, probabilistic grammars, and basic neural language models. Nowadays, LLMs have been applied to various field of SE. These include data analysis
     <cite class="ltx_cite ltx_citemacro_citep">
      (Rae et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib32" title="">
       2021
      </a>
      )
     </cite>
     , text classification
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chae and Davidson,
      <a class="ltx_ref" href="#bib.bib7" title="">
       2023
      </a>
      )
     </cite>
     , software development
     <cite class="ltx_cite ltx_citemacro_citep">
      (Rasheed et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib33" title="">
       2023
      </a>
      )
     </cite>
     , code search
     <cite class="ltx_cite ltx_citemacro_citep">
      (Gu et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib18" title="">
       2018
      </a>
      )
     </cite>
     , unit test case generation
     <cite class="ltx_cite ltx_citemacro_citep">
      (Tufano et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib41" title="">
       2020
      </a>
      )
     </cite>
     , automated program repair
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib27" title="">
       2022
      </a>
      )
     </cite>
     , etc.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2.
    </span>
    Large Language Models in Qualitative Research
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Qualitative research is a type or research that focuses on collecting and analyzing non-numerical data (e.g., text, video, or audio) to understand concepts, opinions, or experiences
     <cite class="ltx_cite ltx_citemacro_citep">
      (Bailey,
      <a class="ltx_ref" href="#bib.bib3" title="">
       2008
      </a>
      )
     </cite>
     . The history of qualitative research is marked by a gradual evolution, beginning with traditional methods that heavily relied on manual analysis and interpretation
     <cite class="ltx_cite ltx_citemacro_citep">
      (Halfpenny,
      <a class="ltx_ref" href="#bib.bib20" title="">
       1979
      </a>
      )
     </cite>
     . Qualitative data analysis for large data was manually conduct by researchers. Researchers manually code and analyze data, a process that was often time-consuming and limited by their capacity to manage large volumes of information
     <cite class="ltx_cite ltx_citemacro_citep">
      (Richards and Hemphill,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2018
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     As technology advanced, the late 20th and early 21st centuries saw the introduction of software tools like NVivo
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hilal and Alabri,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2013
      </a>
      )
     </cite>
     , ATLAS.ti
     <cite class="ltx_cite ltx_citemacro_citep">
      (Smit,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2002
      </a>
      )
     </cite>
     , and MAXQDA
     <cite class="ltx_cite ltx_citemacro_citep">
      (Kuckartz and Rädiker,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2019
      </a>
      )
     </cite>
     , designed to aid in qualitative data analysis. These tools allowed researchers to organize, code, and analyze data more efficiently, handling larger datasets and complex coding schemes
     <cite class="ltx_cite ltx_citemacro_citep">
      (Oliveira et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib29" title="">
       2013
      </a>
      )
     </cite>
     . They also provided new ways to visualize data and identify patterns, which were particularly useful in thematic analysis and theory building
     <cite class="ltx_cite ltx_citemacro_citep">
      (Oliveira et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib29" title="">
       2013
      </a>
      )
     </cite>
     . The real transformation, however, came with the boom of AI technology in recent years. AI and machine learning have revolutionized qualitative research by automating text analysis by using supervised machine learning and natural language processing (NLP).
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p3">
    <p class="ltx_p" id="S2.SS2.p3.1">
     In recent studies, LLMs have demonstrated their capability in tasks similar to deductive coding, offering promising alternatives to traditional supervised learning methods
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xiao et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib44" title="">
       2023
      </a>
      )
     </cite>
     . These models excel in both zero-shot (no examples) and few-shot (few examples) learning scenarios, addressing some of the limitations inherent in conventional approaches
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chew et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib8" title="">
       2023
      </a>
      )
     </cite>
     . Tornberg
     <cite class="ltx_cite ltx_citemacro_citep">
      (Törnberg,
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      )
     </cite>
     observed that zero-shot GPT-4 annotations outperformed both crowd-workers and experts in terms of accuracy and inter-rater reliability when identifying the political affiliation of tweets from U.S. politicians. A study closely aligned with our research by Xiao
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.1">
      et al
     </span>
     .
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xiao et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib44" title="">
       2023
      </a>
      )
     </cite>
     and Dai
     <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.2">
      et al
     </span>
     .
     <cite class="ltx_cite ltx_citemacro_citep">
      (Dai et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023
      </a>
      )
     </cite>
     explored the potential of LLMs in deductive coding. However they just automate the thematic analysis and content analysis approaches to generate initial codes. Their findings suggested that prompts based on existing codebooks were more effective than those with exemplar coding decisions, though both approaches fell short of expert coder performance. Building upon these foundations, our work extends the use of LLMs in qualitative research by employing a multi-agent model based on advanced LLMs to automate all types of qualitative data analysis, representing a comprehensive leap beyond existing applications in both scope and complexity. There is a lack of comprehensive platform that encompasses all facets of qualitative analysis. This gap represents a significant opportunity for innovation. The present study aims to bridge this void by introducing a pioneering platform that integrates LLMs with a multi-agent model. This novel approach promises to automate and streamline the complete spectrum of qualitative data analysis, addressing a critical need in the field and marking a substantial leap forward in research technology.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3.
   </span>
   Research Method
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    This research aims to investigate the efficacy of LLMs in automating and enhancing qualitative data analysis in SE. Our methodology is structured into several key phases, each designed to rigorously test and analyze the capabilities of LLMs in this context. Below we discuss how our LLM based multi agent model collaborate with each other and perform such tasks. We formulate the following research questions (RQs):
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p2">
   <svg class="ltx_picture" height="56.46" id="S3.p2.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,56.46) matrix(1 0 0 -1 0 0)">
     <g fill="#000000" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 50.56 C 0 53.82 2.64 56.46 5.91 56.46 L 594.09 56.46 C 597.36 56.46 600 53.82 600 50.56 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#FAFFFA" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 50.56 C 1.97 52.73 3.73 54.49 5.91 54.49 L 594.09 54.49 C 596.27 54.49 598.03 52.73 598.03 50.56 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="S3.p2.pic1.1.1.1.1.1.1">
         <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p2.pic1.1.1.1.1.1.1.1">
          RQ1.
          <span class="ltx_text ltx_font_medium" id="S3.p2.pic1.1.1.1.1.1.1.1.1">
           How does an LLM-based multi-agent model transform traditional methodologies to automate the qualitative data analysis approach in SE?
          </span>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
  </div>
  <div class="ltx_para" id="S3.p3">
   <p class="ltx_p" id="S3.p3.1">
    <span class="ltx_text ltx_font_bold" id="S3.p3.1.1">
     Motivation
    </span>
    : The motivation to explore how the multi-agent model, utilizing LLMs, transforms traditional methodologies of data interpretation in SE arises from the urgent need to advance and adapt SE practices in the era of big data and AI. Traditional data interpretation methods in SE often struggle with the scale and complexity of contemporary datasets. The LLMs based multi-agent model promises a paradigm shift in how data is analyzed, offering enhanced scalability, accuracy, and efficiency. Investigating this transformation is crucial for understanding the practical implications and potential of AI-driven models in SE. This research will not only elucidate the effectiveness of such models in handling large-scale, complex data but also highlight how they can innovate traditional data interpretation methods, leading to more informed and accurate decision-making processes in SE. Moreover, this exploration is pivotal for guiding future advancements in SE, ensuring that the field evolves in tandem with technological progress in AI.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S3.p4">
   <svg class="ltx_picture" height="56.46" id="S3.p4.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,56.46) matrix(1 0 0 -1 0 0)">
     <g fill="#000000" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 50.56 C 0 53.82 2.64 56.46 5.91 56.46 L 594.09 56.46 C 597.36 56.46 600 53.82 600 50.56 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#FAFFFA" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 50.56 C 1.97 52.73 3.73 54.49 5.91 54.49 L 594.09 54.49 C 596.27 54.49 598.03 52.73 598.03 50.56 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.p4.pic1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="S3.p4.pic1.1.1.1.1.1.1">
         <span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.p4.pic1.1.1.1.1.1.1.1">
          RQ2.
          <span class="ltx_text ltx_font_medium" id="S3.p4.pic1.1.1.1.1.1.1.1.1">
           How does the proposed LLM-based multi-agent model enhance the efficiency and accuracy of qualitative data analysis in SE?
          </span>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
  </div>
  <div class="ltx_para" id="S3.p5">
   <p class="ltx_p" id="S3.p5.1">
    <span class="ltx_text ltx_font_bold" id="S3.p5.1.1">
     Motivation
    </span>
    : The main aim of RQ2 is to investigate the efficiency and accuracy of a proposed LLM-based multi-agent model. As previously mentioned, traditional manual methods for qualitative data analysis in software projects are time-consuming, susceptible to human error, and often struggle to keep up with the rapidly evolving demands of modern software development. The employment of an LLM-based multi-agent approach holds the potential to significantly enhance the speed and accuracy of data analysis. This improvement can lead to more informed decision-making and, consequently, better software quality. To achieve this objective, RQ2 focuses on validating the efficiency and accuracy of the proposed model. To this end, we have engaged 10 practitioners from a variety of industries. This diverse group of professionals ensures a thorough evaluation, as they contribute their unique perspectives and expertise to the assessment process. Their participation is crucial for testing the model in different real-world scenarios, which encompass a spectrum of industry-specific challenges and requirements. This method not only assists in determining the model’s effectiveness across various applications but also in identifying any necessary industry-specific modifications. The feedback and insights provided by these practitioners are invaluable. They play a key role in refining the model, ensuring that it is robust, adaptable, and capable of delivering accurate and efficient results in a wide range of professional contexts.
   </p>
  </div>
  <figure class="ltx_figure" id="S3.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="416" id="S3.F1.g1" src="/html/2402.01386/assets/x1.jpg" width="465"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1.
    </span>
    A workflow overview of the proposed system for automation of qualitative data analysis
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1.
    </span>
    LLM-Based Assisted Qualitative Data Analysis
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     We proposed an LLM based multi agent model to automate the whole process of qualitative data analysis.
Each agent in the system is a specialized instance of an LLM, trained to handle different aspects of qualitative analysis. These agents interact within a text-only environment, processing input data and performing classification tasks relevant to their specialized domains of analysis. Through the API environment, the agents exchange information and collaborate to ensure a comprehensive analysis.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     As is shown in Figure
     <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , the workflow of our proposed model involves receiving a diverse set of datasets from various sources. Subsequently, the multi-agent system collaborates by sending requests to the API environment. Finally, in this system, a response is generated by the environment. Using this approach, each LLM agent is assigned and autonomously executes a specific task, contributing to the overall qualitative data analysis process. This is achieved by utilizing the intrinsic capabilities of LLMs to understand and interpret complex language structures, making it possible to automate even the most intricate aspects of qualitative analysis such as discourse analysis and grounded theory generation. As a result, the system not only streamlines the data analysis process but also enhances the depth and accuracy of the findings, empowering researchers to tackle larger and more complex datasets with unprecedented efficiency. For a more in-depth understanding, we refer to Table
     <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3.1. LLM-Based Assisted Qualitative Data Analysis ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     , illustrating the diverse datasets employed in our experiment. In our experiment, as input we used links to online discussions, raw datasets, textual prompts, or by directly uploading files. This adaptability ensures that the model can accommodate a wide range of user preferences and data sources. Additionally, the proposed model autonomously performs various types of qualitative data analysis. Users can initiate the process by either selecting the provided button or entering text in the designated box. Moreover, our model provides output in multiple formats, including a CSV file, an output area, and documents or PDF files. This flexibility in both input and output options enhances the user experience and widens the applicability of the model in diverse scenarios. Below, we discuss multiple types of qualitative data analysis and also explore how the multi-agent system interacts to generate a response for a given request.
    </p>
   </div>
   <figure class="ltx_table" id="S3.T1">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 1.
     </span>
     Workflow of the proposed model: Application across diverse datasets and output formats
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S3.T1.1.1.1">
       <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1">
        <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">
         ID
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.1.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.2.1">
         <span class="ltx_p" id="S3.T1.1.1.1.2.1.1" style="width:85.4pt;">
          <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1.1.1">
           Type of diverse data
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.3.1">
         <span class="ltx_p" id="S3.T1.1.1.1.3.1.1" style="width:56.9pt;">
          <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1.1.1">
           Dataset
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.1.4">
        <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.4.1">
         QDA Method
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.1.1.5">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.1.1.5.1">
         <span class="ltx_p" id="S3.T1.1.1.1.5.1.1" style="width:85.4pt;">
          <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.5.1.1.1">
           Note
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.1.6">
        <span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.6.1">
         Output File
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.1.2.2">
       <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.2.2.1">
        1
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.2.2.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.2.2.1">
         <span class="ltx_p" id="S3.T1.1.2.2.2.1.1" style="width:85.4pt;">
          Links
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.2.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.2.3.1">
         <span class="ltx_p" id="S3.T1.1.2.2.3.1.1" style="width:56.9pt;">
          Github Developer Discussion
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.2.4">
        Thematic Analysis
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.2.2.5">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.2.2.5.1">
         <span class="ltx_p" id="S3.T1.1.2.2.5.1.1" style="width:85.4pt;">
          Code, Subcategory, Category
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.2.2.6">
        CSV File
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.1.3.3">
       <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.3.3.1">
        2
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.3.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.3.2.1">
         <span class="ltx_p" id="S3.T1.1.3.3.2.1.1" style="width:85.4pt;">
          Prompt
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.3.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.3.3.1">
         <span class="ltx_p" id="S3.T1.1.3.3.3.1.1" style="width:56.9pt;">
          BBC News
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.3.3.4">
        Content Analysis
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.3.3.5">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.3.3.5.1">
         <span class="ltx_p" id="S3.T1.1.3.3.5.1.1" style="width:85.4pt;">
          Codes, Category, Themes, Pattern
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.3.3.6">
        Output Area
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.1.4.4">
       <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.4.4.1">
        3
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.4.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.4.2.1">
         <span class="ltx_p" id="S3.T1.1.4.4.2.1.1" style="width:85.4pt;">
          Upload Files
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.4.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.4.3.1">
         <span class="ltx_p" id="S3.T1.1.4.4.3.1.1" style="width:56.9pt;">
          Story
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.4.4.4">
        Narrative Analysis
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.4.4.5">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.4.4.5.1">
         <span class="ltx_p" id="S3.T1.1.4.4.5.1.1" style="width:85.4pt;">
          Story Summarized, Codes, Category
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.4.4.6">
        Output Area
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.1.5.5">
       <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.5.5.1">
        4
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.5.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.5.2.1">
         <span class="ltx_p" id="S3.T1.1.5.5.2.1.1" style="width:85.4pt;">
          Links
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.5.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.5.3.1">
         <span class="ltx_p" id="S3.T1.1.5.5.3.1.1" style="width:56.9pt;">
          Social Media Conversation
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.5.5.4">
        Discourse Analysis
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T1.1.5.5.5">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.5.5.5.1">
         <span class="ltx_p" id="S3.T1.1.5.5.5.1.1" style="width:85.4pt;">
          Key Pattern, Language, Broader Context
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.5.5.6">
        Doc file
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.1.6.6">
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.1.6.6.1">
        5
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.6.2.1">
         <span class="ltx_p" id="S3.T1.1.6.6.2.1.1" style="width:85.4pt;">
          Voice Recording
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.6.3.1">
         <span class="ltx_p" id="S3.T1.1.6.6.3.1.1" style="width:56.9pt;">
          In-depth Interview
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.6.4">
        Grounded Theory
       </td>
       <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.6.5">
        <span class="ltx_inline-block ltx_align_top" id="S3.T1.1.6.6.5.1">
         <span class="ltx_p" id="S3.T1.1.6.6.5.1.1" style="width:85.4pt;">
          Codes, Category, Pattern, Core Coding
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.1.6.6.6">
        Output Area
       </td>
      </tr>
     </tbody>
    </table>
   </figure>
   <section class="ltx_subsubsection" id="S3.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.1.
     </span>
     Thematic Analysis
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS1.p1">
     <p class="ltx_p" id="S3.SS1.SSS1.p1.1">
      Thematic analysis is a method used in qualitative research to identify, analyze, and report patterns (themes) within data
      <cite class="ltx_cite ltx_citemacro_citep">
       (Castleberry and Nolen,
       <a class="ltx_ref" href="#bib.bib6" title="">
        2018
       </a>
       )
      </cite>
      . It minimally organizes and describes dataset in (rich) detail. It is usually applied to a set of texts. Our proposed model utilizes six agents that work collaboratively to automatically perform thematic analysis on a given text. The first agent, named ’Analyzer,’ is responsible for receiving the input text. Its primary task is to summarize the text, remove any unnecessary data, and then forward the condensed text to the ’Coder’ agent. The Coder agent systematically generates initial codes and then forwards these codes to the subsequent agent for further categorization.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.2.
     </span>
     Narrative Analysis
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS2.p1">
     <p class="ltx_p" id="S3.SS1.SSS2.p1.1">
      Narrative analysis is a qualitative research method used to analyze personal stories, to understand how individuals make sense of events and actions in their lives
      <cite class="ltx_cite ltx_citemacro_citep">
       (Earthy and Cronin,
       <a class="ltx_ref" href="#bib.bib12" title="">
        2008
       </a>
       )
      </cite>
      . In this model, we used four AI agents to understanding the context in which data is generated. The first agent is tasked with summarizing the story. The next agent generates initial codes from the summarized text. Then, the last two agents further break down these codes to generate corresponding sub-categories and categories. The generated output comprises well-defined summarized text, initial codes, and associated sub-categories and categories.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.3.
     </span>
     Content Analysis
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS3.p1">
     <p class="ltx_p" id="S3.SS1.SSS3.p1.1">
      Content analysis is a research technique used to analyze media interviews, open-ended surveys, and other forms of text data
      <cite class="ltx_cite ltx_citemacro_citep">
       (Drisko and Maschi,
       <a class="ltx_ref" href="#bib.bib11" title="">
        2016
       </a>
       )
      </cite>
      . Researchers use content analysis to track changes over time, compare media content, understand the perspectives of different groups, or identify the prevalence of themes or perspectives in discussions. To autonomously perform content analysis on given data, we utilized three AI agents to perform such a task. The first agent summarizes the text, the second agent generates codes from the summarized text, and the next agent extracts the patterns and themes.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.4.
     </span>
     Discourse Analysis
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS4.p1">
     <p class="ltx_p" id="S3.SS1.SSS4.p1.1">
      Discourse analysis is a qualitative and interpretive method used in linguistics, social sciences, and anthropology, among other fields, to study the ways in which language is used in context
      <cite class="ltx_cite ltx_citemacro_citep">
       (Johnstone and Andrus,
       <a class="ltx_ref" href="#bib.bib24" title="">
        2024
       </a>
       )
      </cite>
      . Researchers use this method to analyse the conversation in depth by examining any written or spoken text. In this approach, we used three agents to perform discourse analysis on the provided data. The first agent identifies key patterns and statements, while the second agent focuses on analyzing language use and communication patterns. Simultaneously, the third agent interprets the broader context and implications of the discourse. Together, these agents provide a holistic understanding, examining recurrent themes, linguistic nuances, and contextual influences within the dataset.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.5.
     </span>
     Grounded Theory
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS5.p1">
     <p class="ltx_p" id="S3.SS1.SSS5.p1.1">
      Grounded theory involves in the construction of theories through the methodical gathering and analysis of data
      <cite class="ltx_cite ltx_citemacro_citep">
       (Oktay,
       <a class="ltx_ref" href="#bib.bib28" title="">
        2012
       </a>
       )
      </cite>
      . Grounded Theory is different from other research methods because it does not rely on a pre-existing theory to dictate the direction of the research. Instead, it allows the researcher to develop a new theory that is grounded in the data that has been collected. It is a particularly useful method for understanding complex social processes that are poorly understood. To autonomously perform a grounded theory approach on our given input data, we utilized five AI agents that work collaboratively to perform such tasks. For instance, the first agent generates initial codes, then the second agent categorizes the generated codes. Subsequently, the third and fourth agents generate patterns and themes from the given concepts. Finally, the last agent identifies the core coding concept, which is a coherent narrative or theory that explains the relationships among the identified categories.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2.
    </span>
    Performance Validation
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     In this project, we diligently engaged the expertise of 10 practitioners to thoroughly evaluate the efficiency and performance of our proposed model. The selection of 10 participants for this study aligns with the variability in sample size recommendations within research methodologies. While there’s no definitive rule for the optimal number of participants
     <cite class="ltx_cite ltx_citemacro_citep">
      (Levitt et al
      <span class="ltx_text">
       .
      </span>
      ,
      <a class="ltx_ref" href="#bib.bib26" title="">
       2018
      </a>
      )
     </cite>
     . The evaluation process is grounded in a professional-based approach, whereby the model’s applicability and effectiveness are critically examined by industry experts. This method ensures a comprehensive and insightful assessment, considering the practical implications and requirements of professionals within the relevant industry.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="443" id="S3.F2.g1" src="/html/2402.01386/assets/Demo_Result_for_QDA_tool.jpg" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2.
     </span>
     Generated response from proposed model
    </figcaption>
   </figure>
   <section class="ltx_subsubsection" id="S3.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.1.
     </span>
     Practitioners-based evaluation
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS1.p1">
     <p class="ltx_p" id="S3.SS2.SSS1.p1.1">
      In the validation phase of our methodology, we engaged ten practitioners from diverse professional backgrounds, including academia and industries, to assess the practicality and effectiveness of our LLM-based qualitative data analysis model. This selection aimed to garner a wide array of perspectives and insights into the model’s functionality across various fields. Each practitioner was provided with the model and briefed on its intended use and features, ensuring they were well-equipped to test it comprehensively in their respective domains.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS1.p2">
     <p class="ltx_p" id="S3.SS2.SSS1.p2.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p2.1.1">
       Practitioner’s selection
      </span>
      :
We initially searched for relevant practitioners from various organizations and also approached individuals through social contacts. We contacted seven organizations to request the participation of their practitioners, and three agreed to evaluate the performance of the proposed model. The remaining seven practitioners were identified through social networking and professional contacts. In total, ten practitioners, denoted by P1 to P10 in Table
      <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.2.1. Practitioners-based evaluation ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , were selected to evaluate the proposed model. As indicated in Table
      <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.2.1. Practitioners-based evaluation ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , these practitioners hail from diverse domains, including Software Engineering, Qualitative Data Analysis, and Machine Learning/Deep Learning Development.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS1.p3">
     <p class="ltx_p" id="S3.SS2.SSS1.p3.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p3.1.1">
       Data collection
      </span>
      :
The methodology involved a structured approach for feedback data collection. Practitioners were instructed to integrate the model into their standard qualitative data analysis workflows over a specified period. We developed a systematic feedback mechanism that allowed them to record their experiences, observations, and critiques. This mechanism focused on capturing detailed responses regarding the model’s efficiency, user-friendliness, accuracy in data analysis, and its adaptability to different types of qualitative data. The feedback format was specifically designed to elicit detailed qualitative insights, allowing for the evaluation of measurable aspects of the model’s performance.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS1.p4">
     <p class="ltx_p" id="S3.SS2.SSS1.p4.1">
      <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p4.1.1">
       Data analysis
      </span>
      :
The final step in our validation methodology was the analysis of the feedback, which was crucial for iterative development. Participant were free to used any data source as input. We collated and examined the feedback to identify the model’s performance across different use cases. For the performance evaluation of the proposed model, we employed a comprehensive Likert scale, including the following options: Not Satisfied, Fair, Satisfactory, Good, Very Good, and Excellent. This scale offers a detailed range for assessment, allowing for a thorough and clear grading of the model’s performance. The iterative process was guided by a commitment to enhance functionality, user experience, and the overall effectiveness of the model, ensuring it meets the diverse needs and expectations of practitioners in the field of qualitative data analysis.
     </p>
    </div>
    <figure class="ltx_table" id="S3.T2">
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 2.
      </span>
      Practitioners’ demography and their assessment
     </figcaption>
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S3.T2.1.1.1">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.1.1.1">
         <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1">
          ID
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.1.1.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.1.1.2.1">
          <span class="ltx_p" id="S3.T2.1.1.1.2.1.1" style="width:56.9pt;">
           <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.2.1.1.1">
            Role of Practitioner
           </span>
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.3">
         <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.3.1">
          Experience (Years)
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.1.1.4">
         <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.4.1">
          Overall Performance
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.1.1.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.1.1.5.1">
          <span class="ltx_p" id="S3.T2.1.1.1.5.1.1" style="width:113.8pt;">
           <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.5.1.1.1">
            Feedback
           </span>
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.1.1.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.1.1.6.1">
          <span class="ltx_p" id="S3.T2.1.1.1.6.1.1" style="width:113.8pt;">
           <span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.6.1.1.1">
            Suggestion
           </span>
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.2.2">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.2.2.1">
         P1
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.2.2.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.2.2.2.1">
          <span class="ltx_p" id="S3.T2.1.2.2.2.1.1" style="width:56.9pt;">
           Researcher
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.2.2.3">
         5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.2.2.4">
         Very Good
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.2.2.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.2.2.5.1">
          <span class="ltx_p" id="S3.T2.1.2.2.5.1.1" style="width:113.8pt;">
           Suggested enhanced discourse analysis capabilities.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.2.2.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.2.2.6.1">
          <span class="ltx_p" id="S3.T2.1.2.2.6.1.1" style="width:113.8pt;">
           Include more diverse datasets.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.3.3">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.3.3.1">
         P2
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.3.3.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.3.3.2.1">
          <span class="ltx_p" id="S3.T2.1.3.3.2.1.1" style="width:56.9pt;">
           ML/DL developer
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.3.3">
         8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.3.4">
         Excellent
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.3.3.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.3.3.5.1">
          <span class="ltx_p" id="S3.T2.1.3.3.5.1.1" style="width:113.8pt;">
           Impressed with accuracy, recommended UI improvements.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.3.3.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.3.3.6.1">
          <span class="ltx_p" id="S3.T2.1.3.3.6.1.1" style="width:113.8pt;">
           User interface could be more intuitive.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.4.4">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.4.4.1">
         P3
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.4.4.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.4.4.2.1">
          <span class="ltx_p" id="S3.T2.1.4.4.2.1.1" style="width:56.9pt;">
           Big Data Analyst
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.3">
         10
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.4.4.4">
         Good
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.4.4.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.4.4.5.1">
          <span class="ltx_p" id="S3.T2.1.4.4.5.1.1" style="width:113.8pt;">
           Advised on incorporating general terminology support.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.4.4.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.4.4.6.1">
          <span class="ltx_p" id="S3.T2.1.4.4.6.1.1" style="width:113.8pt;">
           Incorporate more diverse datasets.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.5.5">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.5.5.1">
         P4
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.5.5.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.5.5.2.1">
          <span class="ltx_p" id="S3.T2.1.5.5.2.1.1" style="width:56.9pt;">
           UX Designer
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.3">
         3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.5.5.4">
         Satisfactory
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.5.5.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.5.5.5.1">
          <span class="ltx_p" id="S3.T2.1.5.5.5.1.1" style="width:113.8pt;">
           Requested more intuitive code-generation features.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.5.5.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.5.5.6.1">
          <span class="ltx_p" id="S3.T2.1.5.5.6.1.1" style="width:113.8pt;">
           Improve the code generation interface.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.6.6">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.6.6.1">
         P5
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.6.6.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.6.6.2.1">
          <span class="ltx_p" id="S3.T2.1.6.6.2.1.1" style="width:56.9pt;">
           Software Engineer
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.3">
         6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.6.4">
         Very Good
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.6.6.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.6.6.5.1">
          <span class="ltx_p" id="S3.T2.1.6.6.5.1.1" style="width:113.8pt;">
           Pleased with narrative analysis, suggested speed optimizations.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.6.6.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.6.6.6.1">
          <span class="ltx_p" id="S3.T2.1.6.6.6.1.1" style="width:113.8pt;">
           Increase processing speed.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.7.7">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.7.7.1">
         P6
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.7.7.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.7.7.2.1">
          <span class="ltx_p" id="S3.T2.1.7.7.2.1.1" style="width:56.9pt;">
           Software Developer
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.3">
         12
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.7.7.4">
         Excellent
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.7.7.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.7.7.5.1">
          <span class="ltx_p" id="S3.T2.1.7.7.5.1.1" style="width:113.8pt;">
           Recommended additional case study templates.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.7.7.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.7.7.6.1">
          <span class="ltx_p" id="S3.T2.1.7.7.6.1.1" style="width:113.8pt;">
           Provide templates for various business scenarios.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.8.8">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.8.8.1">
         P7
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.8.8.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.8.8.2.1">
          <span class="ltx_p" id="S3.T2.1.8.8.2.1.1" style="width:56.9pt;">
           ML developer
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.3">
         7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.8.8.4">
         Not Satisfied
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.8.8.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.8.8.5.1">
          <span class="ltx_p" id="S3.T2.1.8.8.5.1.1" style="width:113.8pt;">
           Provided result was not expected.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.8.8.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.8.8.6.1">
          <span class="ltx_p" id="S3.T2.1.8.8.6.1.1" style="width:113.8pt;">
           Need to improve the tool scalability.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.9.9">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.9.9.1">
         P8
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.9.9.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.9.9.2.1">
          <span class="ltx_p" id="S3.T2.1.9.9.2.1.1" style="width:56.9pt;">
           AI developer
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.3">
         9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.9.9.4">
         Very Good
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.9.9.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.9.9.5.1">
          <span class="ltx_p" id="S3.T2.1.9.9.5.1.1" style="width:113.8pt;">
           Requested support for more languages.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.9.9.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.9.9.6.1">
          <span class="ltx_p" id="S3.T2.1.9.9.6.1.1" style="width:113.8pt;">
           Add additional language capabilities.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.10.10">
        <td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.10.10.1">
         P9
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.10.10.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.10.10.2.1">
          <span class="ltx_p" id="S3.T2.1.10.10.2.1.1" style="width:56.9pt;">
           Content Strategist
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.3">
         4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.10.10.4">
         Excellent
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.10.10.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.10.10.5.1">
          <span class="ltx_p" id="S3.T2.1.10.10.5.1.1" style="width:113.8pt;">
           Impressed with multi-method approach.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="S3.T2.1.10.10.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.10.10.6.1">
          <span class="ltx_p" id="S3.T2.1.10.10.6.1.1" style="width:113.8pt;">
           Continue to refine multi-method capabilities.
          </span>
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S3.T2.1.11.11">
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.1.11.11.1">
         P10
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.11.11.2">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.11.11.2.1">
          <span class="ltx_p" id="S3.T2.1.11.11.2.1.1" style="width:56.9pt;">
           Senior Software Engineer
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.11.11.3">
         15
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.11.11.4">
         Fair
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.11.11.5">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.11.11.5.1">
          <span class="ltx_p" id="S3.T2.1.11.11.5.1.1" style="width:113.8pt;">
           Suggested a feature for better integration with existing coding platforms.
          </span>
         </span>
        </td>
        <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.1.11.11.6">
         <span class="ltx_inline-block ltx_align_top" id="S3.T2.1.11.11.6.1">
          <span class="ltx_p" id="S3.T2.1.11.11.6.1.1" style="width:113.8pt;">
           Create plugins for popular IDEs.
          </span>
         </span>
        </td>
       </tr>
      </tbody>
     </table>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4.
   </span>
   Results
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    In this section, we present the study results of the proposed LLM-based multi-agent model for qualitative data analysis. Our findings indicate that the proposed model achieved comprehensive and rapid interpretation of extensive qualitative datasets. Below, we present the results of our LLM-based proposed model in Section
    <a class="ltx_ref" href="#S4.SS1" title="4.1. LLM Based Multi Agent Model (RQ1) ‣ 4. Results ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      4.1
     </span>
    </a>
    , specifically reporting the outcomes of RQ1. Additionally, we conducted an extensive evaluation of the proposed model by engaging practitioners from diverse backgrounds to assess its performance, as detailed in Section
    <a class="ltx_ref" href="#S4.SS2" title="4.2. Performance Evaluation (RQ2) ‣ 4. Results ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      4.2
     </span>
    </a>
    .
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1.
    </span>
    LLM Based Multi Agent Model (RQ1)
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     Our proposed LLM based multi agent model has transformed traditional qualitative research. Our model has the ability to process and analyze large and diverse data sets, which goes beyond the capacity of traditional manual methods and providing more comprehensive insights. The model’s adaptability to various types of qualitative data showcases its flexibility, a significant advancement over more rigid traditional methodologies. The proposed model for automating and expediting the qualitative data analysis processes has yielded significant results across five types of qualitative analysis approaches.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS1.p2">
    <p class="ltx_p" id="S4.SS1.p2.1">
     The primary objective of the model is to autonomously perform qualitative data analysis based on the user-specified method. The results indicate that the model effectively executes the chosen qualitative data analysis method on the provided divers set of input datasets. This autonomous capability streamlines the analysis process, reducing the need for extensive manual intervention and accelerating the overall analysis workflow. Our developed model is flexible and works well with different kinds of inputs and data, which is important because it can handle various challenges that come with complex data. Its easy-to-use interface makes it accessible for people with different technical skills, allowing them to use advanced qualitative data analysis tools in SE.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S4.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.1.
     </span>
     Demo
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS1.p1">
     <p class="ltx_p" id="S4.SS1.SSS1.p1.1">
      The developed LLM-based multi-agent model has been successfully implemented and tested for autonomous qualitative data analysis. In Figure
      <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , we present a demonstration of our proposed model. As depicted, we input GitHub links and select thematic analysis to prompt the system to identify issues from the text and perform thematic analysis. The generated output is then obtained in a CSV file. The model exhibits remarkable versatility in handling various input formats. Users can seamlessly choose their preferred method of input, allowing for a flexible and user-friendly interaction. Furthermore, we incorporate text extracted from Stack Overflow into our prompt. Specifically, we opt for thematic analysis to guide the system in identifying the cause from the provided text. As illustrated in Figure
      <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , the process begins by summarizing the text and identifying the cause. Subsequently, the model proceeds to generate initial codes, which are then broken down into subcategories and categories. This time we get final results in output box. This systematic approach allows for a comprehensive and structured analysis of the input text. In this project, users have the autonomy to define and articulate the specific analysis they wish to perform. This customization feature enhances the versatility and adaptability of our analytical model, allowing users to tailor their investigations according to their unique requirements and objectives. This streamlined process allows for efficient and automated exploration of the underlying concepts and themes within the given data, showcasing the model’s ability to deliver insightful outcomes without manual intervention.
Our results demonstrate the model’s capability to autonomously execute qualitative data analysis methods on diverse datasets, streamlining the analysis process and reducing the need for manual intervention.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS1.SSS1.p2">
     <p class="ltx_p" id="S4.SS1.SSS1.p2.1">
      In our proposed model, we have implemented an additional feature allowing users to upload text, document (doc), and Portable Document Format (pdf) files as input. The model subsequently autonomously generates responses by activating specific qualitative analysis approaches, thereby facilitating a comprehensive examination of the provided data. This functionality extends the utility of our proposed model, making it accessible for practitioners and researchers alike. Moreover, the model is versatile enough to be employed for interview analysis, enabling practitioners and researchers to utilize it for conducting interviews and summarizing the interview text efficiently.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2.
    </span>
    Performance Evaluation (RQ2)
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     In our research, we assessed the performance of our LLM-based multi-agent model by involving practitioners from diverse backgrounds, as highlighted in Table
     <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.2.1. Practitioners-based evaluation ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     . We shared our proposed model with field experts and sought their feedback. We carefully analyzed all the feedback provided by the practitioners, and 87% of them expressed satisfaction with the model’s performance. This approach has offered valuable real-world insights into the model’s applicability and effectiveness in practical settings.
The provided feedback highlights the strengths and areas for improvement in our proposed model, showcasing its potential in automated qualitative data analysis while also underscoring the need for further refinement in certain analysis types.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S4.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.2.1.
     </span>
     Evaluation results
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS1.p1">
     <p class="ltx_p" id="S4.SS2.SSS1.p1.1">
      We present feedback from practitioners in Table
      <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.2.1. Practitioners-based evaluation ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , which summarizes their responses from various disciplines regarding the performance of our developed model. Machine learning and data specialists rated the model as ’Excellent’ and ’Good,’ appreciating its analytical capabilities yet suggesting enhancements in user interface and data diversity. Meanwhile, UX Designers, with their critical eye for user interaction, deemed the model ’Satisfactory,’ advocating for improvements in the code-generation interface to elevate the user experience.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS2.SSS1.p2">
     <p class="ltx_p" id="S4.SS2.SSS1.p2.1">
      Software professionals, encompassing engineers and developers with a broad spectrum of experience from 6 to 15 years, generally perceived the model’s performance as favorable, with ratings ranging from ’Very Good’ to ’Excellent.’ They highlighted the need for speed optimizations and additional templates tailored to varied business scenarios, emphasizing functionality that aligns with industry workflows. However, a notable outlier — an ML Developer with 7 years of experience — reported dissatisfaction, suggesting that the model’s output failed to meet expert expectations, indicating room for substantive refinement.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS2.SSS1.p3">
     <p class="ltx_p" id="S4.SS2.SSS1.p3.1">
      In contrast, AI Developers and Content Strategists acknowledged the model’s strengths in multi-method approaches, yet advised further expansion of language support and methodological refinement. The Senior Software Engineer, with the most experience, labeled performance as ’Fair’ and recommended better integration with existing platforms, pointing towards a necessity for the model to seamlessly mesh with established developer ecosystems.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5.
   </span>
   Discussion
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In this paper, we proposed LLM based multi agent model to automate qualitative analysis process. Our proposed model shows remarkable efficiency and scalability of research processes. The multi-agent model adeptly interpreted a large range of textual and audio data, autonomously perform all kinds of qualitative data analysis, which signifies a transformative step forward in the domain of qualitative research by enhancing both the speed and depth of data analysis.
   </p>
  </div>
  <div class="ltx_para" id="S5.p2">
   <p class="ltx_p" id="S5.p2.1">
    The
    <span class="ltx_text ltx_font_bold" id="S5.p2.1.1">
     implications
    </span>
    of our results, as derived from the utilization of LLMs for automating qualitative data analysis, are profound and diverse. The implementation of a multi-agent model that successfully interprets vast quantities of textual and audio data stands as a testament to the potential of AI in enhancing the efficiency and scale of qualitative research. Our model’s ability to autonomously identify themes, patterns, and generate structured coding underscores a pivotal shift towards more agile and data-driven research methodologies in SE and beyond. The automation of these processes not only streamlines the analysis but also allows for the management of datasets that would have been prohibitively large or complex for manual analysis. This signifies a leap in the capabilities of researchers, who can now dig into richer data without the constraints of time and resource intensity typically associated with qualitative research. Moreover, the scalability and accuracy introduced by our model pave the way for a new standard in data interpretation, where the breadth of data does not compromise the depth of analysis. These improvements can offer more detailed and specific insights, ultimately improving the quality of qualitative research results.
   </p>
  </div>
  <div class="ltx_para" id="S5.p3">
   <p class="ltx_p" id="S5.p3.1">
    Looking towards the
    <span class="ltx_text ltx_font_bold" id="S5.p3.1.1">
     future
    </span>
    , there are several avenues for further work. The model’s adaptability across different data types and analysis methodologies suggests the possibility of its application in diverse fields beyond SE, where qualitative data plays a crucial role. Future work could also explore the integration of more sophisticated natural language processing (NLP) techniques to enhance the model’s interpretive accuracy. Additionally, investigating the models’s performance in multilingual settings could significantly broaden its applicability in global research contexts. The feedback loop from domain experts, as highlighted in Section
    <a class="ltx_ref" href="#S3.SS2.SSS1" title="3.2.1. Practitioners-based evaluation ‣ 3.2. Performance Validation ‣ 3. Research Method ‣ Can Large Language Models Serve as Data Analysts? A Multi-Agent Assisted Approach for Qualitative Data Analysis">
     <span class="ltx_text ltx_ref_tag">
      3.2.1
     </span>
    </a>
    , will be critical in this iterative process, ensuring that the model not only meets but exceeds the multifaceted demands of qualitative analysis. There is also a compelling need to address any limitations identified, such as improving user interface design and expanding the model’s processing capabilities, to ensure that the model remains on the cutting edge of qualitative data analysis technology. In summary, the LLM-based multi-agent model emerges as a valuable model for researchers, analysts, and practitioners seeking an automated and user-friendly solution for qualitative data analysis tasks.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6.
   </span>
   Conclusions
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    In this paper, we introduce an LLM-based multi-agent model designed to automate various types of qualitative data analysis, including thematic analysis, content analysis, narrative analysis, discourse analysis, and grounded theory. The model’s flexibility is clear as it can understand a variety of inputs, including written documents, interview transcripts, web links, prompts, or text and PDF files that we upload. This comprehensive coverage not only accelerates data analysis but also broadens its applicability, making it a valuable model for researchers working with various qualitative data sources. Our proposed model significantly expedites processes while enhancing scalability and accuracy in SE research.
   </p>
  </div>
  <div class="ltx_para" id="S6.p2">
   <p class="ltx_p" id="S6.p2.1">
    Furthermore, we conducted an extensive evaluation of the proposed model, involving practitioners from different backgrounds. Our research entailed a rigorous assessment with ten professionals, each representing a unique professional field. The findings revealed a notable level of satisfaction, with 87% expressing contentment with the model’s performance. This positive response underscores the effectiveness of our model in meeting the diverse needs of practitioners across various domains. However, despite these encouraging results, we acknowledge the importance of ongoing refinement to address potential areas for improvement.
   </p>
  </div>
  <div class="ltx_para" id="S6.p3">
   <p class="ltx_p" id="S6.p3.1">
    Our future goal is to focus on exploring the model’s performance in multilingual settings to extend its applicability in diverse global research contexts. Additionally, we will continue to emphasize the importance of maintaining a feedback loop with domain experts to ensure the ongoing refinement and enhancement of the model’s capabilities.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7.
   </span>
   Acknowledgment
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    We express our sincere gratitude to Business Finland for their generous support and funding of our project. Their commitment to fostering innovation and supporting research initiatives has been instrumental in the success of our work.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (1)
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Allamanis et al
     <span class="ltx_text" id="bib.bib2.2.2.1">
      .
     </span>
     (2017)
    </span>
    <span class="ltx_bibblock">
     Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. 2017.
    </span>
    <span class="ltx_bibblock">
     Learning to represent programs with graphs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">
      arXiv preprint arXiv:1711.00740
     </em>
     (2017).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bailey (2008)
    </span>
    <span class="ltx_bibblock">
     Julia Bailey. 2008.
    </span>
    <span class="ltx_bibblock">
     First steps in qualitative data analysis: transcribing.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      Family practice
     </em>
     25, 2 (2008), 127–131.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Belzner et al
     <span class="ltx_text" id="bib.bib4.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Lenz Belzner, Thomas Gabor, and Martin Wirsing. 2023.
    </span>
    <span class="ltx_bibblock">
     Large language model assisted software engineering: prospects, challenges, and a case study. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">
      International Conference on Bridging the Gap between AI and Reality
     </em>
     . Springer, 355–374.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cao et al
     <span class="ltx_text" id="bib.bib5.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S Yu, and Lichao Sun. 2023.
    </span>
    <span class="ltx_bibblock">
     A comprehensive survey of ai-generated content (aigc): A history of generative ai from gan to chatgpt.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">
      arXiv preprint arXiv:2303.04226
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Castleberry and Nolen (2018)
    </span>
    <span class="ltx_bibblock">
     Ashley Castleberry and Amanda Nolen. 2018.
    </span>
    <span class="ltx_bibblock">
     Thematic analysis of qualitative research data: Is it as easy as it sounds?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      Currents in pharmacy teaching and learning
     </em>
     10, 6 (2018), 807–815.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chae and Davidson (2023)
    </span>
    <span class="ltx_bibblock">
     Youngjin Chae and Thomas Davidson. 2023.
    </span>
    <span class="ltx_bibblock">
     Large Language Models for Text Classification: From Zero-shot Learning to Fine-Tuning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      Open Science Foundation
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chew et al
     <span class="ltx_text" id="bib.bib8.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Robert Chew, John Bollenbacher, Michael Wenger, Jessica Speer, and Annice Kim. 2023.
    </span>
    <span class="ltx_bibblock">
     LLM-Assisted Content Analysis: Using Large Language Models to Support Deductive Coding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">
      arXiv preprint arXiv:2306.14924
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Costa et al
     <span class="ltx_text" id="bib.bib9.2.2.1">
      .
     </span>
     (2018)
    </span>
    <span class="ltx_bibblock">
     António Pedro Costa, Francislê Neri de Souza, António Moreira, and Dayse Neri de Souza. 2018.
    </span>
    <span class="ltx_bibblock">
     webQDA 2.0 Versus webQDA 3.0: a comparative study about usability of qualitative data analysis software. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">
      Developments and Advances in Intelligent Systems and Applications
     </em>
     . Springer, 229–240.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dai et al
     <span class="ltx_text" id="bib.bib10.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Shih-Chieh Dai, Aiping Xiong, and Lun-Wei Ku. 2023.
    </span>
    <span class="ltx_bibblock">
     LLM-in-the-loop: Leveraging large language model for thematic analysis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">
      arXiv preprint arXiv:2310.15100
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Drisko and Maschi (2016)
    </span>
    <span class="ltx_bibblock">
     James W Drisko and Tina Maschi. 2016.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      Content analysis
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Pocket Guide to Social Work Re.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Earthy and Cronin (2008)
    </span>
    <span class="ltx_bibblock">
     Sarah Earthy and Ann Cronin. 2008.
    </span>
    <span class="ltx_bibblock">
     Narrative analysis.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      Researching social life
     </em>
     . Sage.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Eloundou et al
     <span class="ltx_text" id="bib.bib13.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. 2023.
    </span>
    <span class="ltx_bibblock">
     Gpts are gpts: An early look at the labor market impact potential of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">
      arXiv preprint arXiv:2303.10130
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fan et al
     <span class="ltx_text" id="bib.bib14.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Zhiyu Fan, Xiang Gao, Martin Mirchev, Abhik Roychoudhury, and Shin Hwei Tan. 2023.
    </span>
    <span class="ltx_bibblock">
     Automated repair of programs from large language models. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">
      2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)
     </em>
     . IEEE, 1469–1481.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al
     <span class="ltx_text" id="bib.bib15.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Yunhe Feng, Sreecharan Vanam, Manasa Cherukupally, Weijian Zheng, Meikang Qiu, and Haihua Chen. 2023.
    </span>
    <span class="ltx_bibblock">
     Investigating Code Generation Performance of Chat-GPT with Crowdsourcing Social Data. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">
      Proceedings of the 47th IEEE Computer Software and Applications Conference
     </em>
     . 1–10.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al
     <span class="ltx_text" id="bib.bib16.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al
     <span class="ltx_text" id="bib.bib16.3.1">
      .
     </span>
     2020.
    </span>
    <span class="ltx_bibblock">
     Codebert: A pre-trained model for programming and natural languages.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.4.1">
      arXiv preprint arXiv:2002.08155
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Finnie-Ansley et al
     <span class="ltx_text" id="bib.bib17.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     James Finnie-Ansley, Paul Denny, Brett A Becker, Andrew Luxton-Reilly, and James Prather. 2022.
    </span>
    <span class="ltx_bibblock">
     The robots are coming: Exploring the implications of openai codex on introductory programming. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">
      Proceedings of the 24th Australasian Computing Education Conference
     </em>
     . 10–19.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gu et al
     <span class="ltx_text" id="bib.bib18.2.2.1">
      .
     </span>
     (2018)
    </span>
    <span class="ltx_bibblock">
     Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018.
    </span>
    <span class="ltx_bibblock">
     Deep code search. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">
      Proceedings of the 40th International Conference on Software Engineering
     </em>
     . 933–944.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo et al
     <span class="ltx_text" id="bib.bib19.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, and Jian Yin. 2022.
    </span>
    <span class="ltx_bibblock">
     Unixcoder: Unified cross-modal pre-training for code representation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">
      arXiv preprint arXiv:2203.03850
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Halfpenny (1979)
    </span>
    <span class="ltx_bibblock">
     Peter Halfpenny. 1979.
    </span>
    <span class="ltx_bibblock">
     The analysis of qualitative data.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      The Sociological Review
     </em>
     27, 4 (1979), 799–827.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hilal and Alabri (2013)
    </span>
    <span class="ltx_bibblock">
     AlYahmady Hamed Hilal and Saleh Said Alabri. 2013.
    </span>
    <span class="ltx_bibblock">
     Using NVivo for data analysis in qualitative research.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      International interdisciplinary journal of education
     </em>
     2, 2 (2013), 181–186.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hörnemalm (2023)
    </span>
    <span class="ltx_bibblock">
     Adam Hörnemalm. 2023.
    </span>
    <span class="ltx_bibblock">
     ChatGPT as a Software Development Tool: The Future of Development.
    </span>
    <span class="ltx_bibblock">
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hou et al
     <span class="ltx_text" id="bib.bib23.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John Grundy, and Haoyu Wang. 2023.
    </span>
    <span class="ltx_bibblock">
     Large language models for software engineering: A systematic literature review.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">
      arXiv preprint arXiv:2308.10620
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Johnstone and Andrus (2024)
    </span>
    <span class="ltx_bibblock">
     Barbara Johnstone and Jennifer Andrus. 2024.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      Discourse analysis
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     John Wiley &amp; Sons.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kuckartz and Rädiker (2019)
    </span>
    <span class="ltx_bibblock">
     Udo Kuckartz and Stefan Rädiker. 2019.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      Analyzing qualitative data with MAXQDA
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Springer.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Levitt et al
     <span class="ltx_text" id="bib.bib26.2.2.1">
      .
     </span>
     (2018)
    </span>
    <span class="ltx_bibblock">
     Heidi M Levitt, Michael Bamberg, John W Creswell, David M Frost, Ruthellen Josselson, and Carola Suárez-Orozco. 2018.
    </span>
    <span class="ltx_bibblock">
     Journal article reporting standards for qualitative primary, qualitative meta-analytic, and mixed methods research in psychology: The APA Publications and Communications Board task force report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">
      American Psychologist
     </em>
     73, 1 (2018), 26.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al
     <span class="ltx_text" id="bib.bib27.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al
     <span class="ltx_text" id="bib.bib27.3.1">
      .
     </span>
     2022.
    </span>
    <span class="ltx_bibblock">
     Competition-level code generation with alphacode.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.4.1">
      Science
     </em>
     378, 6624 (2022), 1092–1097.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Oktay (2012)
    </span>
    <span class="ltx_bibblock">
     Julianne S Oktay. 2012.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Grounded theory
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Pocket Guide to Social Work Re.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Oliveira et al
     <span class="ltx_text" id="bib.bib29.2.2.1">
      .
     </span>
     (2013)
    </span>
    <span class="ltx_bibblock">
     Mirian Oliveira, Claudia Bitencourt, Eduardo Teixeira, and Ana Clarissa Santos. 2013.
    </span>
    <span class="ltx_bibblock">
     Thematic content analysis: Is there a difference between the support provided by the MAXQDA® and NVivo® software packages. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">
      Proceedings of the 12th European Conference on Research Methods for Business and Management Studies
     </em>
     . 304–314.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Peng et al
     <span class="ltx_text" id="bib.bib30.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Sida Peng, Eirini Kalliamvakou, Peter Cihon, and Mert Demirer. 2023.
    </span>
    <span class="ltx_bibblock">
     The impact of ai on developer productivity: Evidence from github copilot.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">
      arXiv preprint arXiv:2302.06590
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Radford et al
     <span class="ltx_text" id="bib.bib31.2.2.1">
      .
     </span>
     (2018)
    </span>
    <span class="ltx_bibblock">
     Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al
     <span class="ltx_text" id="bib.bib31.3.1">
      .
     </span>
     2018.
    </span>
    <span class="ltx_bibblock">
     Improving language understanding by generative pre-training.
    </span>
    <span class="ltx_bibblock">
     (2018).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rae et al
     <span class="ltx_text" id="bib.bib32.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al
     <span class="ltx_text" id="bib.bib32.3.1">
      .
     </span>
     2021.
    </span>
    <span class="ltx_bibblock">
     Scaling language models: Methods, analysis &amp; insights from training gopher.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.4.1">
      arXiv preprint arXiv:2112.11446
     </em>
     (2021).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rasheed et al
     <span class="ltx_text" id="bib.bib33.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Zeeshan Rasheed, Muhammad Waseem, Kai-Kristian Kemell, Wang Xiaofeng, Anh Nguyen Duc, Kari Systä, and Pekka Abrahamsson. 2023.
    </span>
    <span class="ltx_bibblock">
     Autonomous Agents in Software Development: A Vision Paper.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">
      arXiv preprint arXiv:2311.18440
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Richards and Hemphill (2018)
    </span>
    <span class="ltx_bibblock">
     K Andrew R Richards and Michael A Hemphill. 2018.
    </span>
    <span class="ltx_bibblock">
     A practical guide to collaborative qualitative data analysis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      Journal of Teaching in Physical education
     </em>
     37, 2 (2018), 225–231.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rietz and Maedche (2021)
    </span>
    <span class="ltx_bibblock">
     Tim Rietz and Alexander Maedche. 2021.
    </span>
    <span class="ltx_bibblock">
     Cody: An AI-based system to semi-automate coding for qualitative research. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
     </em>
     . 1–14.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Salmona et al
     <span class="ltx_text" id="bib.bib36.2.2.1">
      .
     </span>
     (2019)
    </span>
    <span class="ltx_bibblock">
     Michelle Salmona, Eli Lieber, and Dan Kaczynski. 2019.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">
      Qualitative and mixed methods data analysis using Dedoose: A practical approach for research across the social sciences
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Sage Publications.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Smit (2002)
    </span>
    <span class="ltx_bibblock">
     Brigitte Smit. 2002.
    </span>
    <span class="ltx_bibblock">
     Atlas. ti for qualitative data analysis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      Perspectives in education
     </em>
     20, 3 (2002), 65–75.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Thiergart et al
     <span class="ltx_text" id="bib.bib38.2.2.1">
      .
     </span>
     (2021)
    </span>
    <span class="ltx_bibblock">
     Jonas Thiergart, Stefan Huber, and Thomas Übellacker. 2021.
    </span>
    <span class="ltx_bibblock">
     Understanding emails and drafting responses–An approach using GPT-3.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">
      arXiv preprint arXiv:2102.03062
     </em>
     (2021).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Törnberg (2023)
    </span>
    <span class="ltx_bibblock">
     Petter Törnberg. 2023.
    </span>
    <span class="ltx_bibblock">
     Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2304.06588
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Treude (2023)
    </span>
    <span class="ltx_bibblock">
     Christoph Treude. 2023.
    </span>
    <span class="ltx_bibblock">
     Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2301.12169
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tufano et al
     <span class="ltx_text" id="bib.bib41.2.2.1">
      .
     </span>
     (2020)
    </span>
    <span class="ltx_bibblock">
     Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, and Neel Sundaresan. 2020.
    </span>
    <span class="ltx_bibblock">
     Unit test case generation with transformers and focal context.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">
      arXiv preprint arXiv:2009.05617
     </em>
     (2020).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Valmeekam et al
     <span class="ltx_text" id="bib.bib42.2.2.1">
      .
     </span>
     (2022)
    </span>
    <span class="ltx_bibblock">
     Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. 2022.
    </span>
    <span class="ltx_bibblock">
     Large Language Models Still Can’t Plan (A Benchmark for LLMs on Planning and Reasoning about Change).
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">
      arXiv preprint arXiv:2206.10498
     </em>
     (2022).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al
     <span class="ltx_text" id="bib.bib43.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, and Qing Wang. 2023.
    </span>
    <span class="ltx_bibblock">
     Software testing with large language model: Survey, landscape, and vision.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">
      arXiv preprint arXiv:2307.07221
     </em>
     (2023).
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xiao et al
     <span class="ltx_text" id="bib.bib44.2.2.1">
      .
     </span>
     (2023)
    </span>
    <span class="ltx_bibblock">
     Ziang Xiao, Xingdi Yuan, Q Vera Liao, Rania Abdelghani, and Pierre-Yves Oudeyer. 2023.
    </span>
    <span class="ltx_bibblock">
     Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding. In
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">
      Companion Proceedings of the 28th International Conference on Intelligent User Interfaces
     </em>
     . 75–78.
    </span>
    <span class="ltx_bibblock">
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
