<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering</title>
<!--Generated on Tue Sep 10 15:24:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.06595v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S1" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S2" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S2.SS0.SSS0.Px1" title="In 2 Related work ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">LLM-as-a-Judge.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S2.SS0.SSS0.Px2" title="In 2 Related work ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">RAG evaluation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S3" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Problem statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Rethinking Grounded QA Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.SS1" title="In 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Grounded QA failure modes</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.SS2" title="In 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Meta-evaluation with unit-testing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.SS3" title="In 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Evaluating existing Answer Relevancy and Faithfulness implementations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.SS4" title="In 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Enhancing existing frameworks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.SS4.SSS0.Px1" title="In 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Pipeline strategy.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.SS4.SSS0.Px2" title="In 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Prompts.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.SS4.SSS0.Px3" title="In 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Evaluators benchmark.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.SS1" title="In 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experimental setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.SS1.SSS0.Px1" title="In 5.1 Experimental setup ‣ 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Dataset.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.SS1.SSS0.Px2" title="In 5.1 Experimental setup ‣ 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Finetuning.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.SS2" title="In 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Experimental results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.SS2.SSS0.Px1" title="In 5.2 Experimental results ‣ 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Finetuning on GPT-4 judgement boosts evaluation capabilities.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.SS2.SSS0.Px2" title="In 5.2 Experimental results ‣ 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Strong correlation with GPT-4 does not imply good pass rate on unit tests.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S6" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S7" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S8" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Ethical considerations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A1" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Unit test characteristics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A2" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Annotation procedures</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A2.SS0.SSS0.Px1" title="In Appendix B Annotation procedures ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">GroUSE Dataset.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A2.SS0.SSS0.Px2" title="In Appendix B Annotation procedures ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">RAGAS and DeepEval.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A2.SS0.SSS0.Px3" title="In Appendix B Annotation procedures ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Human performance on GroUSE.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A2.SS0.SSS0.Px4" title="In Appendix B Annotation procedures ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"></span> ‣ <span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Annotation procedures</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Prompt templates used for evaluating a grounded answer</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.SS0.SSS0.Px1" title="In Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Prompt engineering.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.SS0.SSS0.Px2" title="In Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Prompt template.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.SS0.SSS0.Px3" title="In Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Ablation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A4" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Detailed unit test results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A5" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Dataset constitution</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A5.SS0.SSS0.Px1" title="In Appendix E Dataset constitution ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Fine-tuning prompt format.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A5.SS0.SSS0.Px2" title="In Appendix E Dataset constitution ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Models used for inference.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A6" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Training and inference hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A7" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Finetuning results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8" title="In GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Ablation: balancing the training dataset to reduce judgement biases</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.SS0.SSS0.Px1" title="In Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Dataset balance.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.SS0.SSS0.Px2" title="In Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_title">Impact of training dataset imbalance.</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sacha Muller  António Loison  Bilel Omrani  Gautier Viaud 
<br class="ltx_break"/>Illuin Technology

<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{ sacha.muller, antonio.loison, bilel.omrani, gautier.viaud }@illuin.tech.fr</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use Large Language Models (LLMs) alongside private and up-to-date knowledge bases. In this work, we address the challenges of using LLM-as-a-Judge when evaluating grounded answers generated by RAG systems. To assess the calibration and discrimination capabilities of judge models, we identify 7 generator failure modes and introduce GroUSE <span class="ltx_text ltx_font_italic" id="id2.id1.1">(Grounded QA Unitary Scoring of Evaluators)</span>, a meta-evaluation benchmark of 144 unit tests. This benchmark reveals that existing automated RAG evaluation frameworks often overlook important failure modes, even when using <span class="ltx_text" id="id2.id1.2">GPT-4</span> as a judge.</p>
<p class="ltx_p" id="id3.id2">To improve on the current design of automated RAG evaluation frameworks, we propose a novel pipeline and find that while closed models perform well on GroUSE, state-of-the-art open-source judges do not generalize to our proposed criteria, despite strong correlation with GPT-4’s judgement. Our findings suggest that correlation with GPT-4 is an incomplete proxy for the practical performance of judge models and should be supplemented with evaluations on unit tests for precise failure mode detection.</p>
<p class="ltx_p" id="id4.id3">We further show that finetuning <span class="ltx_text" id="id4.id3.1">Llama-3</span> on GPT-4’s reasoning traces significantly boosts its evaluation capabilities, improving upon both correlation with GPT-4’s evaluations and calibration on reference situations.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/illuin-tech/grouse" title="">https://github.com/illuin-tech/grouse</a></span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tr" id="p1.1.2.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1">Sacha Muller  António Loison  Bilel Omrani  Gautier Viaud</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.1">Illuin Technology</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.1.1">{ sacha.muller, antonio.loison, bilel.omrani, gautier.viaud }@illuin.tech.fr</span></span></span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<figure class="ltx_figure" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="434" id="S0.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Simplified extract of four unit tests, all sharing the same question but testing different failure modes thanks to slight variations in the answer and references. The typology of all 16 test types are detailed in Annex <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A1" title="Appendix A Unit test characteristics ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">A</span></a>.</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Retrieval-Augmented Generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">Lewis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib13" title="">2020</a>)</cite> is increasingly used to build user-facing applications. A RAG system first matches a user’s question with a subset of relevant documents using an information retrieval system. This contextual knowledge is then fed to a language model and used to generate an answer. To enable interpretability and fact-checking, the model is typically required to only use the provided contextual information and thus asked to ground its answer in the provided documents. In the following, we will denote this task as <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">grounded question answering</span>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Manually evaluating the quality of an answer grounded in multiple documents is a tedious and expensive task. LLM-as-a-Judge <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib28" title="">2023b</a>); Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib33" title="">2023</a>); Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib11" title="">2023</a>)</cite> uses a strong LLM to automatically assess the quality of a candidate model’s open-ended generation. Prior works show that LLM judges like GPT-4 align well with human preferences for various tasks <cite class="ltx_cite ltx_citemacro_cite">Faysse et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib6" title="">2023</a>); Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib32" title="">2024</a>)</cite>. However, using proprietary models is often impractical due to privacy concerns. <cite class="ltx_cite ltx_citemacro_citet">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib11" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib12" title="">2024</a>)</cite> propose Prometheus, an open-source evaluator distilled from GPT-4’s outputs. While Prometheus performs well on in-domain tasks, <cite class="ltx_cite ltx_citemacro_citet">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib9" title="">2024</a>)</cite> show it overfits to its training distribution and fails to generalize on out-of-domain test sets.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">There is currently no consensus around the evaluation criteria to use when evaluating a grounded answer. RAGAS <cite class="ltx_cite ltx_citemacro_cite">Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib5" title="">2023</a>)</cite> proposes to evaluate the answer quality using two criteria, <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">faithfulness</span> and <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">answer relevancy</span>. However, we find that grounded question answering can in practice feature a wide range of failure modes and edge-cases that are not well-captured by this pair of metrics.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we thoroughly examine the various failure modes of grounded question answering and investigate the evaluation capabilities of current judge models and automated RAG evaluation frameworks. Our contributions are the following:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">Contribution 1:</span> We systematically review the various failure modes of grounded question answering and propose an automated evaluation pipeline using GPT-4-as-a-Judge to assess the quality of a grounded answer, encompassing all failure modes.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text ltx_font_bold" id="S1.p6.1.1">Contribution 2:</span> We publicly release GroUSE <span class="ltx_text ltx_font_italic" id="S1.p6.1.2">(Grounded QA Unitary Scoring of Evaluators)</span>, a challenging and granular suite of 144 manually curated unit tests designed to assess whether a judge model is well-calibrated and capable of detecting and discriminating between different answer failure modes across 16 various situations. Using this new meta-evaluation benchmark, we compare our proposed pipeline with current automated evaluation frameworks and demonstrate that our approach achieves higher error detection accuracy.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text ltx_font_bold" id="S1.p7.1.1">Contribution 3:</span> We assess the evaluation capabilities of state-of-the-art closed-source and open-source judges and show that despite strong correlation with GPT-4’s judgement, open-source judge models fail to detect some failure modes, despite being instructed with detailed guidelines. This result suggests that relying on GPT-4 correlation as a proxy for measuring the performance of judge models is insufficient, as it does not imply good calibration on reference cases.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p8">
<p class="ltx_p" id="S1.p8.1"><span class="ltx_text ltx_font_bold" id="S1.p8.1.1">Contribution 4:</span> We show that finetuning Llama-3 on GPT-4’s evaluation traces significantly enhances its evaluation capabilities. The resulting model closely aligns with GPT-4 and surpasses state-of-the-art open-source evaluators on our test suite.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">LLM-as-a-Judge.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib14" title="">2023</a>); Faysse et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib6" title="">2023</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib27" title="">2023a</a>)</cite> show that strong commercial models can effectively critique candidate model responses, with higher correlation to human evaluations than rule-based or model-based methods. <cite class="ltx_cite ltx_citemacro_citet">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib32" title="">2024</a>)</cite> coined the term <span class="ltx_text ltx_inline-quote ltx_outerquote" id="S2.SS0.SSS0.Px1.p1.1.1">“LLM-as-a-Judge”</span> and systematically study GPT-4, highlighting its biases and showing that GPT-4 matches human evaluation. While encouraging, using proprietary models for evaluation is often impractical if not impossible for privacy reasons. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib28" title="">2023b</a>)</cite> introduced Shepherd, a 7B model specifically trained to critique model responses, reaching performance on par with GPT-3.5-Turbo. <cite class="ltx_cite ltx_citemacro_citet">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib33" title="">2023</a>)</cite> presented JudgeLM, a family of judges trained on a variety of evaluation tasks, achieving a high agreement with human preference. <cite class="ltx_cite ltx_citemacro_citet">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib11" title="">2023</a>)</cite> proposed Prometheus, an open-source fine-grained evaluator shown to generalize to diverse evaluation criteria and outperforming GPT-3.5 Turbo in terms of correlation with <span class="ltx_text" id="S2.SS0.SSS0.Px1.p1.1.2">GPT-4</span> preference. The authors demonstrate that integrating reference materials such as a reference answer and fine-grained score rubrics helps inducing better evaluation capabilities. <cite class="ltx_cite ltx_citemacro_citet">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib12" title="">2024</a>)</cite> later improve Prometheus by unifying direct assessment and pairwise preference ranking into a single model and demonstrate superior performance on both of these evaluation paradigms. <cite class="ltx_cite ltx_citemacro_citet">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib9" title="">2024</a>)</cite> conducted an empirical study of the evaluation capabilities of judge models and showed that finetuned evaluators indeed perform well on their training distributions but tend to overfit to their in-domain evaluation schemes.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">RAG evaluation.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Several prior works have explored methods for evaluating the generator module in RAG systems. Various sets of metrics have been proposed to measure different failure modes, but there is no consensus on a common set of criteria for evaluating grounded question answering. <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib3" title="">2024</a>)</cite> propose and evaluate 4 abilities required for RAG: <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.1">noise robustness</span>, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.2">negative rejection</span>, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.3">information integration</span> and <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.4">counterfactual robustness</span>. <cite class="ltx_cite ltx_citemacro_citet">Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib5" title="">2023</a>)</cite> propose two other criteria: <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.5">faithfulness</span> and <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.6">answer relevancy</span>. <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.7">Faithfulness</span> evaluates the factual consistency of the answer given the grounding contexts by decomposing the answer into several statements and calculating the proportion of facts that are supported by the contexts. <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.8">Answer relevancy</span> measures how well the provided answer addresses the original question. An LLM is used to generate several questions from the answer, the answer relevancy score is then given by the average cosine similarity between dense embeddings of the generated questions and the original question. In Deepeval<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/confident-ai/deepeval" title="">https://github.com/confident-ai/deepeval</a></span></span></span>, answer relevancy is computed by using a judge LLM to divide the answer into several atomic facts and computed as the proportion of facts that are relevant to the question. <cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib31" title="">2024</a>)</cite> survey several prior works and propose to add <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.9">correctness</span> to this pair of metrics, which measures the accuracy of the generated response against a ground truth response. <cite class="ltx_cite ltx_citemacro_citet"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib16" title="">Magesh et al. </a></cite> focus on the legal domain and propose a more fine-grained measure of <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.10">faithfulness</span>, by distinguishing between the factual accuracy of the response and the validity of the accompanying citations. <cite class="ltx_cite ltx_citemacro_citet">Thakur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib25" title="">2023</a>)</cite> introduce NoMIRACL, a human-labeled dataset of multilingual queries and both relevant and non-relevant subsets to evaluate if the generator correctly refrains from answering with non-relevant passages and correctly recognizes the relevant passage otherwise.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">Given the significant amount of tuning necessary, several prior works have studied automating the evaluation of such systems. RAGAS <cite class="ltx_cite ltx_citemacro_cite">Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib5" title="">2023</a>)</cite> is a popular framework to automate the evaluation of an entire RAG system and show that the proposed automated metrics correlate well with their human-labeled counterparts. DeepEval proposes to evaluate RAG outputs using a unit-testing paradigm, and provides readily-available <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p2.1.1">faithfulness</span> and <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p2.1.2">answer relevancy</span> prompt chains. <cite class="ltx_cite ltx_citemacro_citet">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib7" title="">2023</a>)</cite> propose ALCE, a benchmark to evaluate the ability of LLMs to correctly provide citations for any statement. The authors use a NLI model to measure <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p2.1.3">citation precision</span> and <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p2.1.4">citation recall</span> and show that this automated evaluation correlates well with human judgement.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem statement</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we introduce more precisely the problem of <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">grounded question answering<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote3.1.1.1">3</span></span><span class="ltx_text ltx_font_upright" id="footnote3.9">Prior works often use the term RAG to denote the question answering task but this term is commonly used to refer to the broader pattern of combining retrieval and generation. To avoid confusion, we coin the term </span><span class="ltx_text" id="footnote3.10">grounded question answering</span><span class="ltx_text ltx_font_upright" id="footnote3.11"> to denote the last step in RAG.</span></span></span></span></span> studied in this work. Given a question, RAG systems use information retrieval to match the question with a subset of documents from a knowledge base and then use an LLM to generate an answer grounded in the provided documents. LLMs have been shown to learn and store factual knowledge from data during their unsupervised pretraining <cite class="ltx_cite ltx_citemacro_cite">Petroni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib21" title="">2019</a>)</cite>, but this knowledge is static and can get outdated. Contrary to <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib3" title="">2024</a>)</cite>, we thus require the LLM to stay faithful to the sources even if the documents contain information contradicting the LLM intrinsic knowledge. As interpretability and fact-checking are crucial in many domains for both the system developers and users, the LLM is also instructed to explicitly cite the reference for each affirmation in its answer as illustrated in the answers of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S0.F1" title="Figure 1 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The information from the retrieved documents that helps answer the question is termed <span class="ltx_text ltx_font_italic" id="S3.p2.1.1">relevant information</span>. When the documents are insufficient to provide an answer, these situations are referred to as <span class="ltx_text ltx_font_italic" id="S3.p2.1.2">adversarial</span>. In such instances, the LLM should explicitly state that the question cannot be answered with the provided material. To avoid frustrating the user and to keep them engaged, it is common to include information related to the question, even if it does not directly answer it, as can be shown in type 2 ground truth answer in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S0.F1" title="Figure 1 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a>. This will be referred as <span class="ltx_text ltx_font_italic" id="S3.p2.1.3">related information</span>. Adversarial cases are evaluated using <span class="ltx_text ltx_font_italic" id="S3.p2.1.4">negative rejection</span> in <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib3" title="">2024</a>)</cite> but receive no special treatment in existing RAG automated evaluation frameworks.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Rethinking Grounded QA Evaluation</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Grounded QA failure modes</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Various failure modes in grounded question answering have been studied. Building on this prior research, we expand the scope of these studies based on our problem formulation. Given a set of retrieved documents, we introduce 7 failure modes:</p>
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.1.1.1">FM1</span></span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">The question is answerable but the answer contains irrelevant information.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.1.1.1">FM2</span></span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">The question is not answerable but the language model fails to refrain from answering.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.1.1.1">FM3</span></span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">The answer misses relevant information provided by the documents.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.1.1.1">FM4</span></span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">The language model wrongly claims that the question cannot be answered.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.i5.1.1.1">FM5</span></span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">The language model correctly claims that the question cannot be answered but then includes unrelated additional information.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.i6.1.1.1">FM6</span></span>
<div class="ltx_para" id="S4.I1.i6.p1">
<p class="ltx_p" id="S4.I1.i6.p1.1">The language model correctly reports a fact from a document but the corresponding citation is missing or incorrect.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S4.I1.i7.1.1.1">FM7</span></span>
<div class="ltx_para" id="S4.I1.i7.p1">
<p class="ltx_p" id="S4.I1.i7.p1.1">The language model distorts a fact from a document or presents a claim that is not supported by the provided documents.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S4.SS1.p1.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.T1" title="Table 1 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a> relates the failure modes presented in our work with existing failure modes presented and reported by prior works. To quantify these seven failure modes, we introduce specific evaluation criteria for grounded question answering. <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.1">Answer relevancy</span> assesses the relevance of the information provided in the answer regarding the question, using a Likert scale (1 to 5), which helps to measure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i1" title="Item FM1 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM1</span></a>. <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.2">Completeness</span> also uses a Likert scale to evaluate whether <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.2.3">all</span> relevant information from the documents is present in the answer, thus measuring <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i3" title="Item FM3 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM3</span></a>. <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.4">Faithfulness</span> is a binary score that checks if all facts in the answer are accurate and correctly attributed to the corresponding document, addressing <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i6" title="Item FM6 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM6</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i7" title="Item FM7 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM7</span></a>. In adversarial cases and when additional information is provided, <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.5">Usefulness</span> is a binary score that determines if the provided additional information is indeed useful and relevant to the question, measuring <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i5" title="Item FM5 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM5</span></a>. Usefulness can be considered a form of <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.2.6">soft relevancy</span> in adversarial cases. Lastly, <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.7">Positive Acceptance</span> and <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.8">Negative Rejection</span> are binary scores indicating a true positive and a true negative respectively in identifying whether the question is answerable, thereby measuring <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i4" title="Item FM4 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM4</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i2" title="Item FM2 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM2</span></a>. Not all failure modes can occur in all situations: Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F2" title="Figure 2 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">2</span></a> clarifies the conditions under which each metric is defined, depending on whether the references contain an answer, if the answer provides a response, or if it adds related information when it does not provide a direct response.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_align_top ltx_border_tt" id="S4.T1.1.1.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_text" id="S4.T1.1.1.2.1"></span> <span class="ltx_text" id="S4.T1.1.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.1.1.2.2.1">
<span class="ltx_tr" id="S4.T1.1.1.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.2.2.1.1.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.2.1.1.1.1">RAGAS</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.2.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.2.2.1.2.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><cite class="ltx_cite ltx_citemacro_cite">Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib5" title="">2023</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T1.1.1.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.3" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_text" id="S4.T1.1.1.3.1"></span> <span class="ltx_text" id="S4.T1.1.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.1.1.3.2.1">
<span class="ltx_tr" id="S4.T1.1.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.3.2.1.1.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.3.2.1.1.1.1">RGB</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.3.2.1.2.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib3" title="">2024</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T1.1.1.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.4" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_text" id="S4.T1.1.1.4.1"></span> <span class="ltx_text" id="S4.T1.1.1.4.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.1.1.4.2.1">
<span class="ltx_tr" id="S4.T1.1.1.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.4.2.1.1.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.4.2.1.1.1.1">NoMIRACL</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.4.2.1.2.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><cite class="ltx_cite ltx_citemacro_cite">Thakur et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib25" title="">2023</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T1.1.1.4.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.5" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_text" id="S4.T1.1.1.5.1"></span> <span class="ltx_text" id="S4.T1.1.1.5.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.1.1.5.2.1">
<span class="ltx_tr" id="S4.T1.1.1.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.5.2.1.1.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.5.2.1.1.1.1">ALCE</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.5.2.1.2.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><cite class="ltx_cite ltx_citemacro_cite">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib7" title="">2023</a>)</cite></span></span>
</span></span><span class="ltx_text" id="S4.T1.1.1.5.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.1.1.6" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_text" id="S4.T1.1.1.6.1"></span> <span class="ltx_text" id="S4.T1.1.1.6.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.1.1.6.2.1">
<span class="ltx_tr" id="S4.T1.1.1.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.6.2.1.1.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.6.2.1.1.1.1">GroUSE</span></span></span>
<span class="ltx_tr" id="S4.T1.1.1.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T1.1.1.6.2.1.2.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">(this work)</span></span>
</span></span><span class="ltx_text" id="S4.T1.1.1.6.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.2.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.2.1.1">
<span class="ltx_p" id="S4.T1.1.2.1.1.1" style="width:142.3pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i1" title="Item FM1 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM1</span></a> – Lack of relevancy</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.3" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.2.4" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.5" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.6" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.3.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.3.1.1">
<span class="ltx_p" id="S4.T1.1.3.1.1.1" style="width:142.3pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i2" title="Item FM2 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM2</span></a> – Failure to refrain from answering in adversarial cases</span>
</span>
</td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.3.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.3" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text" id="S4.T1.1.3.3.1">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.4" rowspan="2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text" id="S4.T1.1.3.4.1">✓</span></td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.3.5" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.6" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text" id="S4.T1.1.3.6.1">✓</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.4.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.4.1.1">
<span class="ltx_p" id="S4.T1.1.4.1.1.1" style="width:142.3pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i3" title="Item FM3 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM3</span></a> – Some relevant information is missing from the answer</span>
</span>
</td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.4.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.4.3" rowspan="2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text" id="S4.T1.1.4.3.1">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.4.4" rowspan="2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text" id="S4.T1.1.4.4.1">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.4.5" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text" id="S4.T1.1.4.5.1">✓</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.5.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.5.1.1">
<span class="ltx_p" id="S4.T1.1.5.1.1.1" style="width:142.3pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i4" title="Item FM4 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM4</span></a> – Wrongly refrain from answering</span>
</span>
</td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.5.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.5.3" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.5.4" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.6.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.6.1.1">
<span class="ltx_p" id="S4.T1.1.6.1.1.1" style="width:142.3pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i5" title="Item FM5 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM5</span></a> – In adversarial cases, unrelated additional information is included</span>
</span>
</td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.6.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.6.3" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.6.4" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.6.5" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.6.6" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"><span class="ltx_text" id="S4.T1.1.6.6.1">✓</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T1.1.7.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.7.1.1">
<span class="ltx_p" id="S4.T1.1.7.1.1.1" style="width:142.3pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i6" title="Item FM6 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM6</span></a> – Missing or incorrect citation</span>
</span>
</td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.7.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.7.3" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T1.1.7.4" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.7.5" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.7.6" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T1.1.8.1" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="S4.T1.1.8.1.1">
<span class="ltx_p" id="S4.T1.1.8.1.1.1" style="width:142.3pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i7" title="Item FM7 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM7</span></a> – Distorted or unsupported claim</span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.8.2" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="S4.T1.1.8.3" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="S4.T1.1.8.4" style="padding-top:-0.5pt;padding-bottom:-0.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.8.5" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.8.6" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">✓</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Equivalent failure modes studied and reported in prior works. Existing studies focus on detecting and evaluating a subset of failure modes. For instance <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i1" title="Item FM1 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM1</span></a> is related to answer relevancy in <cite class="ltx_cite ltx_citemacro_citet">Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib5" title="">2023</a>)</cite>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i2" title="Item FM2 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM2</span></a> is related to negative rejection in <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib3" title="">2024</a>)</cite> <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i6" title="Item FM6 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM6</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i7" title="Item FM7 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM7</span></a> are related to faithfulness and more specifically to correctness and groundedness respectively in <cite class="ltx_cite ltx_citemacro_citet"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib16" title="">Magesh et al. </a></cite>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i6" title="Item FM6 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM6</span></a> is related to <span class="ltx_text ltx_font_italic" id="S4.T1.3.1">citation recall</span> in <cite class="ltx_cite ltx_citemacro_citet">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib7" title="">2023</a>)</cite>.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="229" id="S4.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Metrics and their applicable situations. <span class="ltx_text ltx_font_bold" id="S4.F2.4.1">Answer relevancy</span> is defined only when the answer includes a response. <span class="ltx_text ltx_font_bold" id="S4.F2.5.2">Completeness</span> is evaluated only when the references actually contain an answer to the question. <span class="ltx_text ltx_font_bold" id="S4.F2.6.3">Faithfulness</span> is assessed whenever the answer includes any information (direct response or related information).</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Meta-evaluation with unit-testing</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Our goal is to propose a benchmark to verify whether the evaluator’s assessments align with the defined metrics. We propose a typology of 16 test types designed to assess whether an evaluator appropriately penalizes all failure modes and rewards accurate answers across a diverse range of scenarios (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S0.F1" title="Figure 1 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a>). Each test type specifies the expected characteristics for both references and answers, and defines an acceptable range of scores for each metric to be deemed valid. The tests focus primarily on edge cases or the detection of subtle errors.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We introduce GroUSE <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.1">(Grounded QA Unitary Scoring of Evaluators)</span>, a benchmark consisting of 144 tests divided into 9 sets of 16 tests. All tests within a given set share the same question, with the references and answers slightly modified to fit each of the 16 test types. An additional set of 16 tests is available as a <span class="ltx_text ltx_inline-quote ltx_outerquote" id="S4.SS2.p2.1.2">“training set”</span> to assist in engineering the prompt for the judge model being tested. The references are primarily handpicked excerpts from Wikipedia or newspaper articles. The themes of the sets span various domains, including history, science, zoology, cinematography, and the medical field. See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A1" title="Appendix A Unit test characteristics ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">A</span></a> for details.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Evaluating existing Answer Relevancy and Faithfulness implementations</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">This subsection highlights the limitations of current automatic implementations, specifically RAGAS and DeepEval. Therefore, <span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">in this subsection only, we will refer to answer relevancy and faithfulness using the RAGAS definitions (see <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S2" title="2 Related work ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">section</span> <span class="ltx_text ltx_ref_tag">2</span></a>)</span>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Since our definitions of answer relevancy and faithfulness differ, we propose a method to evaluate RAGAS’ and DeepEval’s performance on GroUSE. Each test sample in GroUSE was annotated by three human annotators, who assessed the expected answer relevancy and faithfulness according to the following definitions: annotators were asked to rate the proportion of relevant facts as a proxy for answer relevancy, and the proportion of faithful facts as a proxy for faithfulness. We then compared the average human-reported metrics with the automatic scores computed by RAGAS and DeepEval with GPT-4. A test is a success if the difference between the human and automatic scores is less than 0.2<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>This threshold is conservative; the largest difference between annotations from two different annotators on the same sample is 0.125 and on average around 0.05</span></span></span>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">While <cite class="ltx_cite ltx_citemacro_citet">Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib5" title="">2023</a>)</cite> showed that RAGAS metrics correlate with human judgment, our evaluation of their implementations on GroUSE reveals that they do not perform well on many individual tests, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.T2" title="In 4.3 Evaluating existing Answer Relevancy and Faithfulness implementations ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F3" title="Figure 3 ‣ 4.3 Evaluating existing Answer Relevancy and Faithfulness implementations ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">3</span></a>. This observation suggests that correlation on judgement does not necessarily implies good calibration of grades on edge cases and thus good error detection. This hypothesis will be further explored in <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.SS1" title="5.1 Experimental setup ‣ 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">section</span> <span class="ltx_text ltx_ref_tag">5.1</span></a>. The proposed automatic metrics rely on several sequential LLM calls, which can increase the likelihood of errors and reduce the robustness of the evaluation across samples. Interestingly, different implementations of the same metrics can yield very different results. For instance, although faithfulness is defined similarly in RAGAS and DeepEval, the unit test results differ significantly due to differences in the prompts used in their respective implementations, showcasing the judge’ sensitivity to prompt details <cite class="ltx_cite ltx_citemacro_cite">Sclar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib22" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
<tr class="ltx_tr" id="S4.T2.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T2.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.1.1">
<span class="ltx_p" id="S4.T2.1.1.1.1.1" style="width:39.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1.1">Issues</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T2.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.2.1">
<span class="ltx_p" id="S4.T2.1.1.2.1.1" style="width:187.9pt;"><span class="ltx_text" id="S4.T2.1.1.2.1.1.1"></span> <span class="ltx_text" id="S4.T2.1.1.2.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.2.1.1.2.1">
<span class="ltx_tr" id="S4.T2.1.1.2.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.2.1.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.1.1.2.1.1.1.1">RAGAS Faithfulness is influenced by</span></span></span>
<span class="ltx_tr" id="S4.T2.1.1.2.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.2.1.1.2.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.1.1.2.1.2.1.1">additional irrelevant information</span></span></span>
</span></span><span class="ltx_text" id="S4.T2.1.1.2.1.1.3"></span></span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt" id="S4.T2.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.1.3.1">
<span class="ltx_p" id="S4.T2.1.1.3.1.1" style="width:202.4pt;"><span class="ltx_text" id="S4.T2.1.1.3.1.1.1"></span> <span class="ltx_text" id="S4.T2.1.1.3.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.3.1.1.2.1">
<span class="ltx_tr" id="S4.T2.1.1.3.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.3.1.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.3.1.1.2.1.1.1.1">RAGAS Answer Relevancy gets submerged by</span></span></span>
<span class="ltx_tr" id="S4.T2.1.1.3.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.3.1.1.2.1.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.3.1.1.2.1.2.1.1">many relevant predicted statements</span></span></span>
</span></span><span class="ltx_text" id="S4.T2.1.1.3.1.1.3"></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.1.1">
<span class="ltx_p" id="S4.T2.1.2.1.1.1" style="width:39.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.1.1.1.1">Question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.2.1">
<span class="ltx_p" id="S4.T2.1.2.2.1.1" style="width:187.9pt;">What is the relationship between Pluto and Neptune?</span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.3.1">
<span class="ltx_p" id="S4.T2.1.2.3.1.1" style="width:202.4pt;">How can we explain the solidity of the Pantheon’s dome?</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.1.1">
<span class="ltx_p" id="S4.T2.1.3.1.1.1" style="width:39.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.1.1.1">Answer</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.1">
<span class="ltx_p" id="S4.T2.1.3.2.1.1" style="width:187.9pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_top" id="S4.T2.1.3.2.1.1.1" style="width:187.9pt;">
<span class="ltx_p" id="S4.T2.1.3.2.1.1.1.1">Pluto and Neptune have a 3:2 orbital resonance relationship, which means that Pluto completes 2 revolutions around the Sun while Neptune completes 3 [5][8]. Their orbits never intersect due to the high inclination of Pluto’s orbit relative to the plane of the ecliptic [5]. In 1936, British mathematician Raymond Lyttleton suggested that Pluto previously orbited around Neptune, and that a gravitational disturbance had ejected Pluto from the planetary orbit [6].
<span class="ltx_text" id="S4.T2.1.3.2.1.1.1.1.1" style="color:#FF0000;">It was during its migration period that Neptune might have captured one of the largest objects in the Kuiper Belt, the current moon Triton [10].</span></span>
</span></span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.3.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.3.1">
<span class="ltx_p" id="S4.T2.1.3.3.1.1" style="width:202.4pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_top" id="S4.T2.1.3.3.1.1.1" style="width:202.4pt;">
<span class="ltx_p" id="S4.T2.1.3.3.1.1.1.1">To ensure resistance to all stresses, Roman builders opted for a meticulous selection of materials and precise management of the orientation of thrusts [1]. Regarding materials, the abundant use of concrete ensures robustness against deformation forces [2], especially since the mortar of Roman concrete tends to calcify as it ages, thus guaranteeing its durability through the ages [6].
As for the thrusts, they are diverted towards the pillars of
the rotunda through large relieving arches [3]. A series of seven concrete rings arranged in a staircase at the base of the dome helps to redirect the lateral centrifugal thrusts through a vertical push [4]. Finally, the outer wall extends 8.40 m beyond the base of the dome, serving as a buttress to stabilize the dome [5].</span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.4.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.1.1">
<span class="ltx_p" id="S4.T2.1.4.1.1.1" style="width:39.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.4.1.1.1.1">Answer</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.4.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S4.T2.1.4.3"></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.1.1">
<span class="ltx_p" id="S4.T2.1.5.1.1.1" style="width:39.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.1.1.1.1">Relevancy</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S4.T2.1.5.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.2.1">
<span class="ltx_p" id="S4.T2.1.5.2.1.1" style="width:187.9pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_top" id="S4.T2.1.5.2.1.1.1" style="width:173.4pt;">
<span class="ltx_p" id="S4.T2.1.5.2.1.1.1.1"><span class="ltx_text" id="S4.T2.1.5.2.1.1.1.1.1" style="color:#FF8000;">Predicted: 0.673</span> Expected: 0.802</span>
</span></span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T2.1.5.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.3.1">
<span class="ltx_p" id="S4.T2.1.5.3.1.1" style="width:202.4pt;">
<span class="ltx_inline-block ltx_parbox ltx_align_top" id="S4.T2.1.5.3.1.1.1" style="width:195.1pt;">
<span class="ltx_p" id="S4.T2.1.5.3.1.1.1.1"><span class="ltx_text" id="S4.T2.1.5.3.1.1.1.1.1" style="color:#FF0000;">Predicted: 0.723</span> Expected: 1.0</span>
</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T2.1.6.1">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.1.1">
<span class="ltx_p" id="S4.T2.1.6.1.1.1" style="width:39.8pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.6.1.1.1.1">Faithfulness</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T2.1.6.2">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.2.1">
<span class="ltx_p" id="S4.T2.1.6.2.1.1" style="width:187.9pt;"><span class="ltx_text" id="S4.T2.1.6.2.1.1.1"></span><span class="ltx_text" id="S4.T2.1.6.2.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.6.2.1.1.2.1">
<span class="ltx_tr" id="S4.T2.1.6.2.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.1.6.2.1.1.2.1.1.1"><span class="ltx_text" id="S4.T2.1.6.2.1.1.2.1.1.1.1" style="color:#FF0000;">Predicted: 0.75</span> Expected: 1</span></span>
</span></span><span class="ltx_text" id="S4.T2.1.6.2.1.1.3"></span></span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S4.T2.1.6.3">
<span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.3.1">
<span class="ltx_p" id="S4.T2.1.6.3.1.1" style="width:202.4pt;"><span class="ltx_text" id="S4.T2.1.6.3.1.1.1"></span><span class="ltx_text" id="S4.T2.1.6.3.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.6.3.1.1.2.1">
<span class="ltx_tr" id="S4.T2.1.6.3.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.1.6.3.1.1.2.1.1.1"><span class="ltx_text" id="S4.T2.1.6.3.1.1.2.1.1.1.1" style="color:#228B22;">Predicted: 1.0</span> Expected: 1.0</span></span>
</span></span><span class="ltx_text" id="S4.T2.1.6.3.1.1.3"></span></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Example limitations of RAGAS on GroUSE unit tests. <span class="ltx_text ltx_font_italic" id="S4.T2.4.1">Left:</span> While the answer contain extra irrelevant but faithful statements, RAGAS wrongly penalizes the answer’s faithfulness . <span class="ltx_text ltx_font_italic" id="S4.T2.5.2">Right:</span> While all the provided information is relevant, RAGAS wrongly penalizes the answer relevancy.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="819" id="S4.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>GroUSE unit-testing of existing solutions for automatic grounded question answering evaluation</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Enhancing existing frameworks</h3>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="464" id="S4.F4.g1" src="x4.png" width="831"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Evaluation pipeline. Each <span class="ltx_text" id="S4.F4.5.1" style="color:#18AE9F;">green square</span> represents a call to an LLM, while the <span class="ltx_text" id="S4.F4.6.2" style="color:#2D88D9;">blue dotted square</span> denotes a straightforward computation based on the call’s results. The <span class="ltx_text ltx_font_bold" id="S4.F4.7.3">Usefulness</span> and <span class="ltx_text ltx_font_bold" id="S4.F4.8.4">Faithfulness</span> evaluations may be omitted if preceding calls suggest these metrics are not applicable.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We demonstrated that both RAGAS and DeepEval fail to cover all the presented cases, even when they purport to. In this section, we propose a new pipeline to automatically evaluate grounded question answering across all situations and all six metrics previously defined. We then test the performances of this pipeline on GroUSE, for a various set of closed and open-source models.</p>
</div>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Pipeline strategy.</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">The metrics’ applicability being highly dependent on whether we are in an adversarial situation, and whether the answer provides a response, a straightforward strategy could involve first identifying which of the situations presented in <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F2" title="In 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a> corresponds to the sample to evaluate. Identifying this scenario would allow to get the list of defined metrics and launch their evaluations consequently. However, to save on LLM calls, we decided to directly include instructions to set the score at <span class="ltx_text ltx_font_typewriter" id="S4.SS4.SSS0.Px1.p1.1.1">null</span> if we are in a situation in which the metric is undefined in the evaluation prompts of the <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px1.p1.1.2">Answer relevancy</span> and <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px1.p1.1.3">Completeness</span>. Based on whether these metrics values are <span class="ltx_text ltx_font_typewriter" id="S4.SS4.SSS0.Px1.p1.1.4">null</span>, it is easy to deduct the situation in which we are, and infer the value of <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px1.p1.1.5">Positive Acceptance</span> and <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px1.p1.1.6">Negative Rejection</span> at the same time. A similar strategy is also applied to detect the presence or absence of related information when evaluating the <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px1.p1.1.7">Usefulness</span>. Ultimately, this optimized pipeline requires at most four LLM calls, with some calls being skipped when the situation is not appropriate (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F4" title="Figure 4 ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Prompts.</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px2.p1.1">Each prompt was engineered to fit the specific metric being evaluated, but for all metrics we ask the model to rate two answers, the first one being a reference answer. The model’s reasoning is also guided by the expected format of the JSON output. Following best practices recommendations from <cite class="ltx_cite ltx_citemacro_citet">Biderman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib2" title="">2024</a>)</cite>, details about the prompts format and the prompt engineering process are available in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3" title="Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Evaluators benchmark.</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px3.p1.3">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.T3" title="Table 3 ‣ Evaluators benchmark. ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">3</span></a> shows the performances of various models on GroUSE, across the six metrics, as well as all metrics combined. GPT-4 is the best evaluator, with an overall score of <math alttext="95\%" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS4.SSS0.Px3.p1.1.m1.1a"><mrow id="S4.SS4.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.cmml"><mn id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2.cmml">95</mn><mo id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1">percent</csymbol><cn id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2">95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px3.p1.1.m1.1c">95\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS0.Px3.p1.1.m1.1d">95 %</annotation></semantics></math>, while the best open-source evaluator is Llama-3 70b with a score of <math alttext="79\%" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px3.p1.2.m2.1"><semantics id="S4.SS4.SSS0.Px3.p1.2.m2.1a"><mrow id="S4.SS4.SSS0.Px3.p1.2.m2.1.1" xref="S4.SS4.SSS0.Px3.p1.2.m2.1.1.cmml"><mn id="S4.SS4.SSS0.Px3.p1.2.m2.1.1.2" xref="S4.SS4.SSS0.Px3.p1.2.m2.1.1.2.cmml">79</mn><mo id="S4.SS4.SSS0.Px3.p1.2.m2.1.1.1" xref="S4.SS4.SSS0.Px3.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px3.p1.2.m2.1b"><apply id="S4.SS4.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.2.m2.1.1.1">percent</csymbol><cn id="S4.SS4.SSS0.Px3.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.SS4.SSS0.Px3.p1.2.m2.1.1.2">79</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px3.p1.2.m2.1c">79\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS0.Px3.p1.2.m2.1d">79 %</annotation></semantics></math>. The gap between closed and open-source models thus remains wide, with a <math alttext="15.85\%" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px3.p1.3.m3.1"><semantics id="S4.SS4.SSS0.Px3.p1.3.m3.1a"><mrow id="S4.SS4.SSS0.Px3.p1.3.m3.1.1" xref="S4.SS4.SSS0.Px3.p1.3.m3.1.1.cmml"><mn id="S4.SS4.SSS0.Px3.p1.3.m3.1.1.2" xref="S4.SS4.SSS0.Px3.p1.3.m3.1.1.2.cmml">15.85</mn><mo id="S4.SS4.SSS0.Px3.p1.3.m3.1.1.1" xref="S4.SS4.SSS0.Px3.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px3.p1.3.m3.1b"><apply id="S4.SS4.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.3.m3.1.1.1">percent</csymbol><cn id="S4.SS4.SSS0.Px3.p1.3.m3.1.1.2.cmml" type="float" xref="S4.SS4.SSS0.Px3.p1.3.m3.1.1.2">15.85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px3.p1.3.m3.1c">15.85\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS0.Px3.p1.3.m3.1d">15.85 %</annotation></semantics></math> difference on the tests results. Interestingly, Prometheus 2 8x7b does not outperform Mixtral 8x7b, despite Prometheus 2 being specialized in evaluation tasks. It’s worth noting however that Prometheus 2 was trained to predict Likert scores ranging from 1 to 5, whereas our evaluation metrics include boolean and nullable scores, which is outside its intended scope.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.1">
<tr class="ltx_tr" id="S4.T3.1.1">
<td class="ltx_td ltx_border_tt" id="S4.T3.1.1.1"></td>
<td class="ltx_td ltx_border_tt" id="S4.T3.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="6" id="S4.T3.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.1">Agreement rate of metrics</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.1.1.4" rowspan="2"><span class="ltx_text" id="S4.T3.1.1.4.1"><span class="ltx_text" id="S4.T3.1.1.4.1.1"></span> <span class="ltx_text" id="S4.T3.1.1.4.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.1.4.1.2.1">
<span class="ltx_tr" id="S4.T3.1.1.4.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.1.4.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.1.2.1.1.1.1">Total</span></span></span>
<span class="ltx_tr" id="S4.T3.1.1.4.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.1.4.1.2.1.2.1">test pass</span></span>
<span class="ltx_tr" id="S4.T3.1.1.4.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.1.4.1.2.1.3.1">rate</span></span>
</span></span> <span class="ltx_text" id="S4.T3.1.1.4.1.3"></span></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.2">
<td class="ltx_td" id="S4.T3.1.2.1"></td>
<td class="ltx_td" id="S4.T3.1.2.2"></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.3">
<span class="ltx_text" id="S4.T3.1.2.3.1"></span> <span class="ltx_text" id="S4.T3.1.2.3.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.2.3.2.1">
<span class="ltx_tr" id="S4.T3.1.2.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.3.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.3.2.1.1.1.1">Answer relevancy</span></span></span>
</span></span><span class="ltx_text" id="S4.T3.1.2.3.3"></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.4">
<span class="ltx_text" id="S4.T3.1.2.4.1"></span> <span class="ltx_text" id="S4.T3.1.2.4.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.2.4.2.1">
<span class="ltx_tr" id="S4.T3.1.2.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.4.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.4.2.1.1.1.1">Completeness</span></span></span>
</span></span><span class="ltx_text" id="S4.T3.1.2.4.3"></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.5">
<span class="ltx_text" id="S4.T3.1.2.5.1"></span> <span class="ltx_text" id="S4.T3.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.2.5.2.1">
<span class="ltx_tr" id="S4.T3.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.5.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.5.2.1.1.1.1">Usefulness</span></span></span>
</span></span><span class="ltx_text" id="S4.T3.1.2.5.3"></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.6">
<span class="ltx_text" id="S4.T3.1.2.6.1"></span> <span class="ltx_text" id="S4.T3.1.2.6.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.2.6.2.1">
<span class="ltx_tr" id="S4.T3.1.2.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.6.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.6.2.1.1.1.1">Faithfulness</span></span></span>
</span></span><span class="ltx_text" id="S4.T3.1.2.6.3"></span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.7">
<span class="ltx_text" id="S4.T3.1.2.7.1"></span> <span class="ltx_text" id="S4.T3.1.2.7.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.2.7.2.1">
<span class="ltx_tr" id="S4.T3.1.2.7.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.7.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.7.2.1.1.1.1">Positive</span></span></span>
<span class="ltx_tr" id="S4.T3.1.2.7.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.7.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.7.2.1.2.1.1">acceptance</span></span></span>
</span></span><span class="ltx_text" id="S4.T3.1.2.7.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.2.8">
<span class="ltx_text" id="S4.T3.1.2.8.1"></span> <span class="ltx_text" id="S4.T3.1.2.8.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.2.8.2.1">
<span class="ltx_tr" id="S4.T3.1.2.8.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.8.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.8.2.1.1.1.1">Negative</span></span></span>
<span class="ltx_tr" id="S4.T3.1.2.8.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.2.8.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.2.8.2.1.2.1.1">rejection</span></span></span>
</span></span><span class="ltx_text" id="S4.T3.1.2.8.3"></span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.3.1" rowspan="11"><span class="ltx_text" id="S4.T3.1.3.1.1"><span class="ltx_text" id="S4.T3.1.3.1.1.1"></span> <span class="ltx_text" id="S4.T3.1.3.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.3.1.1.2.1">
<span class="ltx_tr" id="S4.T3.1.3.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.3.1.1.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.3.1.1.2.1.1.1.1">Evaluated</span></span></span>
<span class="ltx_tr" id="S4.T3.1.3.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.3.1.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.3.1.1.2.1.2.1.1">with Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F4" title="Figure 4 ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a></span></span></span>
<span class="ltx_tr" id="S4.T3.1.3.1.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.3.1.1.2.1.3.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.3.1.1.2.1.3.1.1">pipeline</span></span></span>
</span></span> <span class="ltx_text" id="S4.T3.1.3.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.3.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.3.1">91.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.4.1">88.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.5.1">100.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.6">92.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.7.1">98.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.3.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.8.1">98.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.9.1">95.02</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4">
<td class="ltx_td ltx_align_left" id="S4.T3.1.4.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.4.1.1">GPT-4o</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.2">79.17</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.3">77.08</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4">97.92</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.5">92.36</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.6">83.33</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.4.7">83.33</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.8">85.53</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5">
<td class="ltx_td ltx_align_left" id="S4.T3.1.5.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.5.1.1">GPT-4-turbo</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2">90.28</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.3">85.42</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.4">97.22</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.5.5.1">93.75</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.6">94.44</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.5.7">94.44</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.8">92.59</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6">
<td class="ltx_td ltx_align_left" id="S4.T3.1.6.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.6.1.1">GPT-3.5-turbo</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.2">88.89</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3">50.00</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.4">80.56</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.5">68.06</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6">77.78</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.6.7">61.81</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.8">71.18</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7">
<td class="ltx_td ltx_align_left" id="S4.T3.1.7.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.1.1">Gemini 1.0 Pro</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.2">78.47</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.3">75.69</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4">97.22</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.5">78.47</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.6">84.72</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.7.7">84.72</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.8">83.22</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.8.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.1.1">Mixtral 8x7b Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.8.2">81.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.8.3">61.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.8.4">81.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.8.5">72.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.8.6">76.39</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.8.7">75.69</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.8.8">74.65</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.9">
<td class="ltx_td ltx_align_left" id="S4.T3.1.9.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.9.1.1">Mixtral 8x22b Instruct</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.2">80.56</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.3">68.75</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.4">81.94</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.5">83.33</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.6">76.39</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.9.7">72.22</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.8">77.20</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.10">
<td class="ltx_td ltx_align_left" id="S4.T3.1.10.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.10.1.1">Prometheus 2 7b</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.2">72.22</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.3">41.67</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.4">16.67</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.5">38.19</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.6">73.61</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.10.7">74.31</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.8">52.78</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.11">
<td class="ltx_td ltx_align_left" id="S4.T3.1.11.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.11.1.1">Prometheus 2 8x7b</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.2">61.81</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.3">25.00</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.4">34.03</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.5">72.22</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.6">67.36</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.11.7">69.44</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.8">54.98</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.12">
<td class="ltx_td ltx_align_left" id="S4.T3.1.12.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.12.1.1">Llama-3 70b Instruct</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.2">90.28</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.3">63.89</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.4">76.39</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.5">73.61</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.6">85.42</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.12.7">85.42</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.8">79.17</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.13">
<td class="ltx_td ltx_align_left" id="S4.T3.1.13.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.13.1.1">Llama-3 8b Instruct</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.2">85.42</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.3">49.31</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.4">80.56</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.5">59.72</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.6">72.92</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.13.7">68.06</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.8">69.33</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.14">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.14.1" rowspan="2"><span class="ltx_text" id="S4.T3.1.14.1.1"><span class="ltx_text" id="S4.T3.1.14.1.1.1"></span> <span class="ltx_text" id="S4.T3.1.14.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S4.T3.1.14.1.1.2.1">
<span class="ltx_tr" id="S4.T3.1.14.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.14.1.1.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.14.1.1.2.1.1.1.1">All metrics</span></span></span>
<span class="ltx_tr" id="S4.T3.1.14.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T3.1.14.1.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.14.1.1.2.1.2.1.1">with one prompt</span></span></span>
</span></span> <span class="ltx_text" id="S4.T3.1.14.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.14.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.2.1">Llama-3 8b Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.14.3">31.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.14.4">18.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.14.5">34.03</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.14.6">56.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.14.7">52.78</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.14.8">46.53</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.14.9">39.93</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.15">
<td class="ltx_td ltx_align_left" id="S4.T3.1.15.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.15.1.1">Finetuned Llama 3 8b</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.15.2">88.89</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.15.3">81.94</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.15.4">81.25</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.15.5">52.78</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.15.6">91.67</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.15.7">91.67</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.15.8">81.37</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.16">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T3.1.16.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.16.1.1">Annex <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A2.SS0.SSS0.Px3" title="Human performance on GroUSE. ‣ Appendix B Annotation procedures ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">B</span></a> protocol</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T3.1.16.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.16.2.1">Human annotators</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.16.3">98.61</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.16.4">95.14</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.16.5">98.61</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.16.6">97.92</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.16.7">98.61</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.1.16.8">99.31</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.16.9">98.03</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Percentage of tests passed for various models. The highest score in each column is highlighted in bold.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Inspired by prior works <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib30" title="">2024</a>); Mukherjee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib20" title="">2023</a>); Mitra et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib19" title="">2023</a>)</cite>, we demonstrate that the gap in evaluation skills between open-source and closed-source models can be narrowed via finetuning on traces of evaluations made by GPT-4.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental setup</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Dataset.</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">Aiming to develop a model capable of solving the task in a single call, we concatenated the four responses from GPT-4 into a single output. The input of the model is also a combination of the four prompts used for GPT-4, detailing each metrics’ characteristics. We used extracts of Wikipedia articles, as well as other open data sources as reference material. Queries were synthetically generated from the references, creating a dataset of 1200 grounded QA statements.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Finetuning.</h4>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">We finetuned a Llama-3 8b on 1k samples of this dataset, and used the rest as a test set. We refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A6" title="Appendix F Training and inference hyperparameters ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">F</span></a> for details on the finetuning configuration. To measure the model’s progress, we tested its performances on GroUSE. Following <cite class="ltx_cite ltx_citemacro_citet">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib11" title="">2023</a>)</cite>, we also report the correlation between GPT-4’s grades and the finetuned model’s grades on the test set. For metrics using a Likert scale, alignment is measured using the Spearman correlation. Other metrics are measured using nullable boolean values, their alignment is evaluated using a three-class macro F1-score.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experimental results</h3>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.1">
<tr class="ltx_tr" id="S5.T4.1.1">
<td class="ltx_td ltx_border_tt" id="S5.T4.1.1.1"></td>
<td class="ltx_td ltx_border_tt" id="S5.T4.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S5.T4.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.3.1">Spearman correlation</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S5.T4.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.4.1">F1-score</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2">
<td class="ltx_td" id="S5.T4.1.2.1"></td>
<td class="ltx_td" id="S5.T4.1.2.2"></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.2.3">
<span class="ltx_text" id="S5.T4.1.2.3.1"></span> <span class="ltx_text" id="S5.T4.1.2.3.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.2.3.2.1">
<span class="ltx_tr" id="S5.T4.1.2.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.2.3.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.3.2.1.1.1.1">Answer relevancy</span></span></span>
</span></span><span class="ltx_text" id="S5.T4.1.2.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.1.2.4"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.4.1">Completeness</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.2.5">
<span class="ltx_text" id="S5.T4.1.2.5.1"></span> <span class="ltx_text" id="S5.T4.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.2.5.2.1">
<span class="ltx_tr" id="S5.T4.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.2.5.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.5.2.1.1.1.1">Usefulness</span></span></span>
</span></span><span class="ltx_text" id="S5.T4.1.2.5.3"></span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.2.6">
<span class="ltx_text" id="S5.T4.1.2.6.1"></span> <span class="ltx_text" id="S5.T4.1.2.6.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.2.6.2.1">
<span class="ltx_tr" id="S5.T4.1.2.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.2.6.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.6.2.1.1.1.1">Faithfulness</span></span></span>
</span></span><span class="ltx_text" id="S5.T4.1.2.6.3"></span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.2.7">
<span class="ltx_text" id="S5.T4.1.2.7.1"></span> <span class="ltx_text" id="S5.T4.1.2.7.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.2.7.2.1">
<span class="ltx_tr" id="S5.T4.1.2.7.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.2.7.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.7.2.1.1.1.1">Positive</span></span></span>
<span class="ltx_tr" id="S5.T4.1.2.7.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.2.7.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.7.2.1.2.1.1">acceptance</span></span></span>
</span></span><span class="ltx_text" id="S5.T4.1.2.7.3"></span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.2.8">
<span class="ltx_text" id="S5.T4.1.2.8.1"></span> <span class="ltx_text" id="S5.T4.1.2.8.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.2.8.2.1">
<span class="ltx_tr" id="S5.T4.1.2.8.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.2.8.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.8.2.1.1.1.1">Negative</span></span></span>
<span class="ltx_tr" id="S5.T4.1.2.8.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.2.8.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.2.8.2.1.2.1.1">rejection</span></span></span>
</span></span><span class="ltx_text" id="S5.T4.1.2.8.3"></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.3.1" rowspan="8"><span class="ltx_text" id="S5.T4.1.3.1.1"><span class="ltx_text" id="S5.T4.1.3.1.1.1"></span> <span class="ltx_text" id="S5.T4.1.3.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.3.1.1.2.1">
<span class="ltx_tr" id="S5.T4.1.3.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.3.1.1.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.3.1.1.2.1.1.1.1">Evaluated</span></span></span>
<span class="ltx_tr" id="S5.T4.1.3.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.3.1.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.3.1.1.2.1.2.1.1">with Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F4" title="Figure 4 ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a></span></span></span>
<span class="ltx_tr" id="S5.T4.1.3.1.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.3.1.1.2.1.3.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.3.1.1.2.1.3.1.1">pipeline</span></span></span>
</span></span> <span class="ltx_text" id="S5.T4.1.3.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.3.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.3.2.1">GPT-3.5-turbo</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.3">0.55</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.4">0.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.5">0.76</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.6">0.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.7">0.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.3.8">0.47</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4">
<td class="ltx_td ltx_align_left" id="S5.T4.1.4.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.4.1.1">Gemini 1.0 Pro</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.2">0.63</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.3">0.68</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.4">0.48</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.5">0.67</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.6">0.78</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.4.7">0.74</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5">
<td class="ltx_td ltx_align_left" id="S5.T4.1.5.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.1.1">Mixtral 8x7b Instruct</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.2">0.59</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.3">0.43</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.4">0.70</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.5">0.61</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.6">0.63</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.5.7">0.57</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.6">
<td class="ltx_td ltx_align_left" id="S5.T4.1.6.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.1.1">Mixtral 8x22b Instruct</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.2">0.70</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.3">0.66</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.4">0.61</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.5"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.5.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.6"><span class="ltx_text ltx_font_bold" id="S5.T4.1.6.6.1">0.83</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.6.7">0.70</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.7">
<td class="ltx_td ltx_align_left" id="S5.T4.1.7.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.7.1.1">Prometheus 2 (7b)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.2">0.60</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.3">0.51</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.4">0.29</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.5">0.55</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.6">0.55</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.7.7">0.49</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.8">
<td class="ltx_td ltx_align_left" id="S5.T4.1.8.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.8.1.1">Prometheus 2 (8x7b)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.2">0.64</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.3">0.62</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.4">0.30</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.5">0.75</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.6">0.69</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.8.7">0.50</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.9">
<td class="ltx_td ltx_align_left" id="S5.T4.1.9.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.1.1">Llama-3 70b Instruct</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.2.1">0.74</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.3"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.3.1">0.74</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.4"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.4.1">0.93</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.5">0.78</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.6">0.75</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.9.7"><span class="ltx_text ltx_font_bold" id="S5.T4.1.9.7.1">0.79</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.10">
<td class="ltx_td ltx_align_left" id="S5.T4.1.10.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.10.1.1">Llama-3 8b Instruct</span></td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.2">0.63</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.3">0.71</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.4">0.42</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.5">0.72</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.6">0.54</td>
<td class="ltx_td ltx_align_center" id="S5.T4.1.10.7">0.44</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.11">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S5.T4.1.11.1" rowspan="2"><span class="ltx_text" id="S5.T4.1.11.1.1"><span class="ltx_text" id="S5.T4.1.11.1.1.1"></span> <span class="ltx_text" id="S5.T4.1.11.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S5.T4.1.11.1.1.2.1">
<span class="ltx_tr" id="S5.T4.1.11.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.11.1.1.2.1.1.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.11.1.1.2.1.1.1.1">All metrics</span></span></span>
<span class="ltx_tr" id="S5.T4.1.11.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T4.1.11.1.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="S5.T4.1.11.1.1.2.1.2.1.1">with one prompt</span></span></span>
</span></span> <span class="ltx_text" id="S5.T4.1.11.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.1.11.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.11.2.1">Llama-3 8b Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.11.3">0.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.11.4">0.23</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.11.5">0.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.11.6">0.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.11.7">0.40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.11.8">0.46</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T4.1.12.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.12.1.1">Finetuned Llama-3 8b</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.12.2">0.62</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.12.3">0.57</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.12.4">0.41</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.12.5">0.57</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.12.6">0.79</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.12.7">0.74</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Alignment with the ground truth (GPT-4) evaluations on the test set of 200 samples.</figcaption>
</figure>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Finetuning on GPT-4 judgement boosts evaluation capabilities.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.T3" title="Table 3 ‣ Evaluators benchmark. ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">3</span></a> presents the pass rate of various judge models on GroUSE, including Llama-3 8b (zero-shot) and our finetuned Llama-3 8b judge model. Finetuning significantly enhances the evaluation capabilities of Llama-3, as evidenced by the substantial improvement in pass rates. Despite extensive prompt engineering and intermediate CoT reasoning (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3" title="Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">C</span></a>), the non-finetuned Llama-3 8b passes only 40% of the unit tests. However, after finetuning, its pass rate increases to 83%, surpassing all other open-source judges, including Prometheus 2 8x7b (except in the category of faithfulness), despite its smaller size.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Strong correlation with GPT-4 does not imply good pass rate on unit tests.</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">Interestingly, our results reveal a disconnect between the pass rate on GroUSE and the correlation with GPT-4’s grades. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S5.T4" title="Table 4 ‣ 5.2 Experimental results ‣ 5 Improving Grounded QA Evaluation via distilling evaluation traces of GPT-4 ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a>, Prometheus 2 7b and the finetuned Llama-3 8b exhibit similar correlations with GPT-4’s judgments across all metrics. However, when evaluated on GroUSE, the two models show very different pass rates, with the finetuned Llama-3 consistently and significantly outperforming Prometheus 2 7b. Similarly, we observe higher correlation with GPT-4 in answer relevancy and completeness with Prometheus 2 8x7b than with its base model, Mixtral 8x7b, in accordance to what has been observed in <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib12" title="">2024</a>)</cite>. However, this does not translate to better pass rates on the associated metrics on GroUSE: for answer relevancy, Mixtral 8x7b solves 81.25% of the tests versus 61.81% for Prometheus 2 8x7b, despite its intended use on evaluating Likert scores. For completeness, Mixtral 8x7b solves 61.11% of the tests versus 25% for Prometheus 2 8x7b.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p2.1">This finding suggests that a high correlation with GPT-4’s judgments does not necessarily translate to a high unit test pass rate. A judge model can share the same <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px2.p2.1.1">relative preferences</span> as GPT-4 (indicated by strong rank correlation) while lacking the same <span class="ltx_text ltx_font_italic" id="S5.SS2.SSS0.Px2.p2.1.2">calibration</span> on precise reference cases (very good answers, subtle mistakes, etc.), resulting in poor performance on judgement unit tests. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S6.F5" title="Figure 5 ‣ 6 Conclusion ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates this difference with Prometheus 2 7b and the finetuned Llama-3 8b: while Prometheus 2 confusion matrix entries are closer to the diagonal, it features more confusions on extreme cases (1, 5 and NaN cases) when compared to the finetuned Llama-3. On the contrary, the finetuned Llama-3 has better exact agreement with GPT-4 on extreme case, but lacks correlation on intermediate cases.</p>
</div>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p3">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p3.1">Overall, these measures are complementary: correlation with GPT-4 indicates agreement in relative preference, while GroUSE pass rate measures precise calibration on practical reference cases. Unlike Prometheus 2, Llama-3 70b demonstrates both good correlation with GPT-4’s judgments and a strong pass rate on GroUSE, suggesting that correlation and unit test pass rates are indeed orthogonal measures of a judge model’s quality.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we addressed the challenges of evaluating grounded answers in Retrieval-Augmented Generation systems using LLM-as-a-Judge frameworks. We systematically reviewed various failure modes in grounded question answering and proposed a complete set of automated metrics to holistically evaluate a grounded answer. We introduced GroUSE, a comprehensive meta-evaluation benchmark, and demonstrated that existing automated evaluation methods, including those using GPT-4, often overlook critical failure modes.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Our findings reveal that relying solely on correlation with GPT-4’s judgments as a performance measure for judge models is insufficient, as it doesn’t ensure proper calibration on reference cases. By supplementing the evaluation with unit tests across a wide range of scenarios, we can ensure that the judge model effectively detects failures, even in subtle situations.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">By finetuning Llama-3 on GPT-4’s reasoning traces, we significantly enhanced its evaluation capabilities, achieving closer alignment with GPT-4’s judgments, improved detection of errors and better calibration on reference scenarios.</p>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="780" id="S6.F5.g1" src="x5.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Confusion matrices for <span class="ltx_text ltx_font_bold" id="S6.F5.2.1">Answer relevancy</span>.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">While our work advances the evaluation of grounded answers in RAG systems, several limitations remain. Firstly, our unit tests are designed to identify edge cases but do not account for intermediate performance levels. This focus on extreme scenarios might overlook nuances in model performance that are critical for a comprehensive evaluation. Secondly, when finetuning, we opted to perform a single evaluation call to assess the generated answers. While this approach simplifies the evaluation process, it would be valuable to decompose the evaluation into multiple steps to gain a more detailed understanding of the model’s capabilities. Thirdly, our experiments were conducted within a single domain, specifically using Wikipedia as the knowledge base. Consequently, our findings may not generalize to out-of-domain scenarios. Future work should include diverse domains to test the robustness and adaptability of our evaluation framework. Lastly, we finetuned a smaller open-source language model. Although this approach demonstrated significant improvements, it would be beneficial to explore the effects of finetuning larger models, which could potentially yield even better performance. Addressing these limitations in future research will further enhance the effectiveness and generalizability of automated evaluation frameworks for RAG systems.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Ethical considerations</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">Our work focuses on evaluating language models within the practical context of Retrieval-Augmented Generation systems. This is significant as RAG systems are increasingly used in real-world applications, where the accuracy and reliability of generated answers are important. Ensuring that these systems produce trustworthy and factually correct responses is critical for their safe deployment on real use cases.</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">One of the main ethical concerns in using language models for information-seeking tasks is the risk of hallucinations, irrelevant answers, missing attributions, and incomplete responses. These issues can lead to important information being overlooked or misused and potentially bias the user. By developing meta-evaluation benchmarks like GroUSE, our work aims to mitigate these risks by improving existing automated evaluation frameworks and making sure they are better calibrated to detect this wide range of failure modes.</p>
</div>
<div class="ltx_para" id="S8.p3">
<p class="ltx_p" id="S8.p3.1">While our unit tests and evaluation criteria are designed to identify edge cases, we acknowledge the need for continuous improvement to cover a broader range of scenarios and hope that our work will inspire further research and development in this area, leading to more robust, accurate, and sound evaluation practices.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This research work is supported by Illuin Technology. We would like to express our gratitude to Stanislas Dozias for the insightful discussions and exchange of ideas that contributed to the development of this paper. Special thanks to Quentin Lutz and Manuel Faysse for their valuable feedback and support throughout the research process. Additionally, we would like to thank Noa Grollimund, Florian Muller, Benoît Muller, Max Conti, and Paul Boulenger for their assistance in evaluating the human performance on GroUSE.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman et al. (2024)</span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Lintang Sutawika, Leo Gao, Jonathan Tow, Baber Abbasi, Alham Fikri Aji, Pawan Sasanka Ammanamanchi, Sidney Black, Jordan Clive, et al. 2024.

</span>
<span class="ltx_bibblock">Lessons from the trenches on reproducible evaluation of language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2405.14782</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun. 2024.

</span>
<span class="ltx_bibblock">Benchmarking large language models in retrieval-augmented generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 38, pages 17754–17762.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chern et al. (2023)</span>
<span class="ltx_bibblock">
I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, and Pengfei Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.13528" title="">Factool: Factuality detection in generative ai – a tool augmented framework for multi-task and multi-domain scenarios</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Preprint</em>, arXiv:2307.13528.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Es et al. (2023)</span>
<span class="ltx_bibblock">
Shahul Es, Jithin James, Luis Espinosa-Anke, and Steven Schockaert. 2023.

</span>
<span class="ltx_bibblock">Ragas: Automated evaluation of retrieval augmented generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2309.15217</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faysse et al. (2023)</span>
<span class="ltx_bibblock">
Manuel Faysse, Gautier Viaud, Céline Hudelot, and Pierre Colombo. 2023.

</span>
<span class="ltx_bibblock">Revisiting instruction fine-tuned model evaluation to guide industrial applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2310.14103</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen. 2023.

</span>
<span class="ltx_bibblock">Enabling large language models to generate text with citations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2305.14627</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">LoRA: Low-rank adaptation of large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2024)</span>
<span class="ltx_bibblock">
Hui Huang, Yingqi Qu, Jing Liu, Muyun Yang, and Tiejun Zhao. 2024.

</span>
<span class="ltx_bibblock">An empirical study of llm-as-a-judge for llm evaluation: Fine-tuned judge models are task-specific classifiers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2403.02839</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. 2024.

</span>
<span class="ltx_bibblock">Mixtral of experts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2401.04088</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023)</span>
<span class="ltx_bibblock">
Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, et al. 2023.

</span>
<span class="ltx_bibblock">Prometheus: Inducing fine-grained evaluation capability in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2310.08491</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2024)</span>
<span class="ltx_bibblock">
Seungone Kim, Juyoung Suk, Shayne Longpre, Bill Yuchen Lin, Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, and Minjoon Seo. 2024.

</span>
<span class="ltx_bibblock">Prometheus 2: An open source language model specialized in evaluating other language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2405.01535</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Advances in Neural Information Processing Systems</em>, 33:9459–9474.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023.

</span>
<span class="ltx_bibblock">Gpteval: Nlg evaluation using gpt-4 with better human alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2303.16634</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="">Decoupled weight decay regularization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
Varun Magesh, Faiz Surani, Matthew Dahl, Mirac Suzgun, Christopher D Manning, and Daniel E Ho.

</span>
<span class="ltx_bibblock">Hallucination-free? assessing the reliability of leading ai legal research tools.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MetaAI (2024)</span>
<span class="ltx_bibblock">
MetaAI. 2024.

</span>
<span class="ltx_bibblock">Introducing meta llama 3: The most capable openly available llm to date.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/blog/meta-llama-3/" title="">https://ai.meta.com/blog/meta-llama-3/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et al. (2023)</span>
<span class="ltx_bibblock">
Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock">Factscore: Fine-grained atomic evaluation of factual precision in long form text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2305.14251</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra et al. (2023)</span>
<span class="ltx_bibblock">
Arindam Mitra, Luciano Del Corro, Shweti Mahajan, Andres Codas, Clarisse Simoes, Sahaj Agarwal, Xuxi Chen, Anastasia Razdaibiedina, Erik Jones, Kriti Aggarwal, et al. 2023.

</span>
<span class="ltx_bibblock">Orca 2: Teaching small language models how to reason.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2311.11045</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee et al. (2023)</span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock">Orca: Progressive learning from complex explanation traces of gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2306.02707</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et al. (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. 2019.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:1909.01066</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sclar et al. (2023)</span>
<span class="ltx_bibblock">
Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr. 2023.

</span>
<span class="ltx_bibblock">Quantifying language models’ sensitivity to spurious features in prompt design or: How i learned to start worrying about prompt formatting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2310.11324</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2023)</span>
<span class="ltx_bibblock">
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023.

</span>
<span class="ltx_bibblock">Gemini: a family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2312.11805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2024)</span>
<span class="ltx_bibblock">
Mistral AI Team. 2024.

</span>
<span class="ltx_bibblock">Mistral 8x22b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://mistral.ai/news/mixtral-8x22b/" title="">https://mistral.ai/news/mixtral-8x22b/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thakur et al. (2023)</span>
<span class="ltx_bibblock">
Nandan Thakur, Luiz Bonifacio, Xinyu Zhang, Odunayo Ogundepo, Ehsan Kamalloo, David Alfonso-Hermelo, Xiaoguang Li, Qun Liu, Boxing Chen, Mehdi Rezagholizadeh, et al. 2023.

</span>
<span class="ltx_bibblock">Nomiracl: Knowing when you don’t know for robust multilingual retrieval-augmented generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2312.11361</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2302.13971" title="">Llama: Open and efficient foundation language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Preprint</em>, arXiv:2302.13971.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
Jiaan Wang, Yunlong Liang, Fandong Meng, Zengkui Sun, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou. 2023a.

</span>
<span class="ltx_bibblock">Is chatgpt a good nlg evaluator? a preliminary study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2303.04048</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Tianlu Wang, Ping Yu, Xiaoqing Ellen Tan, Sean O’Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-Zarandi, and Asli Celikyilmaz. 2023b.

</span>
<span class="ltx_bibblock">Shepherd: A critic for language model generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2308.04592</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Workshop et al. (2023)</span>
<span class="ltx_bibblock">
BigScience Workshop, :, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, Jonathan Tow, Alexander M. Rush, Stella Biderman, Albert Webson, Pawan Sasanka Ammanamanchi, Thomas Wang, Benoît Sagot, Niklas Muennighoff, Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Laurençon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David Ifeoluwa Adelani, Dragomir Radev, Eduardo González Ponferrada, Efrat Levkovizh, Ethan Kim, Eyal Bar Natan, Francesco De Toni, Gérard Dupont, Germán Kruszewski, Giada Pistilli, Hady Elsahar, Hamza Benyamina, Hieu Tran,
Ian Yu, Idris Abdulmumin, Isaac Johnson, Itziar Gonzalez-Dios, Javier de la Rosa, Jenny Chim, Jesse Dodge, Jian Zhu, Jonathan Chang, Jörg Frohberg, Joseph Tobing, Joydeep Bhattacharjee, Khalid Almubarak, Kimbo Chen, Kyle Lo, Leandro Von Werra, Leon Weber, Long Phan, Loubna Ben allal, Ludovic Tanguy, Manan Dey, Manuel Romero Muñoz, Maraim Masoud, María Grandury, Mario Šaško, Max Huang, Maximin Coavoux, Mayank Singh, Mike Tian-Jian Jiang, Minh Chien Vu, Mohammad A. Jauhar, Mustafa Ghaleb, Nishant Subramani, Nora Kassner, Nurulaqilla Khamis, Olivier Nguyen, Omar Espejel, Ona de Gibert, Paulo Villegas, Peter Henderson, Pierre Colombo, Priscilla Amuok, Quentin Lhoest, Rheza Harliman, Rishi Bommasani, Roberto Luis López, Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Sebastian Nagel, Shamik Bose, Shamsuddeen Hassan Muhammad, Shanya Sharma, Shayne Longpre, Somaieh Nikpoor, Stanislav Silberberg, Suhas Pai, Sydney Zink, Tiago Timponi Torrent, Timo Schick, Tristan Thrush, Valentin Danchev, Vassilina Nikoulina,
Veronika Laippala, Violette Lepercq, Vrinda Prabhu, Zaid Alyafeai, Zeerak Talat, Arun Raja, Benjamin Heinzerling, Chenglei Si, Davut Emre Taşar, Elizabeth Salesky, Sabrina J. Mielke, Wilson Y. Lee, Abheesht Sharma, Andrea Santilli, Antoine Chaffin, Arnaud Stiegler, Debajyoti Datta, Eliza Szczechla, Gunjan Chhablani, Han Wang, Harshit Pandey, Hendrik Strobelt, Jason Alan Fries, Jos Rozen, Leo Gao, Lintang Sutawika, M Saiful Bari, Maged S. Al-shaibani, Matteo Manica, Nihal Nayak, Ryan Teehan, Samuel Albanie, Sheng Shen, Srulik Ben-David, Stephen H. Bach, Taewoon Kim, Tali Bers, Thibault Fevry, Trishala Neeraj, Urmish Thakker, Vikas Raunak, Xiangru Tang, Zheng-Xin Yong, Zhiqing Sun, Shaked Brody, Yallow Uri, Hadar Tojarieh, Adam Roberts, Hyung Won Chung, Jaesung Tae, Jason Phang, Ofir Press, Conglong Li, Deepak Narayanan, Hatim Bourfoune, Jared Casper, Jeff Rasley, Max Ryabinin, Mayank Mishra, Minjia Zhang, Mohammad Shoeybi, Myriam Peyrounette, Nicolas Patry, Nouamane Tazi, Omar Sanseviero, Patrick von
Platen, Pierre Cornette, Pierre François Lavallée, Rémi Lacroix, Samyam Rajbhandari, Sanchit Gandhi, Shaden Smith, Stéphane Requena, Suraj Patil, Tim Dettmers, Ahmed Baruwa, Amanpreet Singh, Anastasia Cheveleva, Anne-Laure Ligozat, Arjun Subramonian, Aurélie Névéol, Charles Lovering, Dan Garrette, Deepak Tunuguntla, Ehud Reiter, Ekaterina Taktasheva, Ekaterina Voloshina, Eli Bogdanov, Genta Indra Winata, Hailey Schoelkopf, Jan-Christoph Kalo, Jekaterina Novikova, Jessica Zosa Forde, Jordan Clive, Jungo Kasai, Ken Kawamura, Liam Hazan, Marine Carpuat, Miruna Clinciu, Najoung Kim, Newton Cheng, Oleg Serikov, Omer Antverg, Oskar van der Wal, Rui Zhang, Ruochen Zhang, Sebastian Gehrmann, Shachar Mirkin, Shani Pais, Tatiana Shavrina, Thomas Scialom, Tian Yun, Tomasz Limisiewicz, Verena Rieser, Vitaly Protasov, Vladislav Mikhailov, Yada Pruksachatkun, Yonatan Belinkov, Zachary Bamberger, Zdeněk Kasner, Alice Rueda, Amanda Pestana, Amir Feizpour, Ammar Khan, Amy Faranak, Ana Santos, Anthony Hevia, Antigona
Unldreaj, Arash Aghagol, Arezoo Abdollahi, Aycha Tammour, Azadeh HajiHosseini, Bahareh Behroozi, Benjamin Ajibade, Bharat Saxena, Carlos Muñoz Ferrandis, Daniel McDuff, Danish Contractor, David Lansky, Davis David, Douwe Kiela, Duong A. Nguyen, Edward Tan, Emi Baylor, Ezinwanne Ozoani, Fatima Mirza, Frankline Ononiwu, Habib Rezanejad, Hessie Jones, Indrani Bhattacharya, Irene Solaiman, Irina Sedenko, Isar Nejadgholi, Jesse Passmore, Josh Seltzer, Julio Bonis Sanz, Livia Dutra, Mairon Samagaio, Maraim Elbadri, Margot Mieskes, Marissa Gerchick, Martha Akinlolu, Michael McKenna, Mike Qiu, Muhammed Ghauri, Mykola Burynok, Nafis Abrar, Nazneen Rajani, Nour Elkott, Nour Fahmy, Olanrewaju Samuel, Ran An, Rasmus Kromann, Ryan Hao, Samira Alizadeh, Sarmad Shubber, Silas Wang, Sourav Roy, Sylvain Viguier, Thanh Le, Tobi Oyebade, Trieu Le, Yoyo Yang, Zach Nguyen, Abhinav Ramesh Kashyap, Alfredo Palasciano, Alison Callahan, Anima Shukla, Antonio Miranda-Escalada, Ayush Singh, Benjamin Beilharz, Bo Wang, Caio Brito,
Chenxi Zhou, Chirag Jain, Chuxin Xu, Clémentine Fourrier, Daniel León Periñán, Daniel Molano, Dian Yu, Enrique Manjavacas, Fabio Barth, Florian Fuhrimann, Gabriel Altay, Giyaseddin Bayrak, Gully Burns, Helena U. Vrabec, Imane Bello, Ishani Dash, Jihyun Kang, John Giorgi, Jonas Golde, Jose David Posada, Karthik Rangasai Sivaraman, Lokesh Bulchandani, Lu Liu, Luisa Shinzato, Madeleine Hahn de Bykhovetz, Maiko Takeuchi, Marc Pàmies, Maria A Castillo, Marianna Nezhurina, Mario Sänger, Matthias Samwald, Michael Cullan, Michael Weinberg, Michiel De Wolf, Mina Mihaljcic, Minna Liu, Moritz Freidank, Myungsun Kang, Natasha Seelam, Nathan Dahlberg, Nicholas Michio Broad, Nikolaus Muellner, Pascale Fung, Patrick Haller, Ramya Chandrasekhar, Renata Eisenberg, Robert Martin, Rodrigo Canalli, Rosaline Su, Ruisi Su, Samuel Cahyawijaya, Samuele Garda, Shlok S Deshmukh, Shubhanshu Mishra, Sid Kiblawi, Simon Ott, Sinee Sang-aroonsiri, Srishti Kumar, Stefan Schweter, Sushil Bharati, Tanmay Laud, Théo Gigant, Tomoya
Kainuma, Wojciech Kusa, Yanis Labrak, Yash Shailesh Bajaj, Yash Venkatraman, Yifan Xu, Yingxin Xu, Yu Xu, Zhe Tan, Zhongli Xie, Zifan Ye, Mathilde Bras, Younes Belkada, and Thomas Wolf. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2211.05100" title="">Bloom: A 176b-parameter open-access multilingual language model</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Preprint</em>, arXiv:2211.05100.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024)</span>
<span class="ltx_bibblock">
Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng Tao, and Tianyi Zhou. 2024.

</span>
<span class="ltx_bibblock">A survey on knowledge distillation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2402.13116</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2024)</span>
<span class="ltx_bibblock">
Hao Yu, Aoran Gan, Kai Zhang, Shiwei Tong, Qi Liu, and Zhaofeng Liu. 2024.

</span>
<span class="ltx_bibblock">Evaluation of retrieval-augmented generation: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2405.07437</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2024)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2023)</span>
<span class="ltx_bibblock">
Lianghui Zhu, Xinggang Wang, and Xinlong Wang. 2023.

</span>
<span class="ltx_bibblock">Judgelm: Fine-tuned large language models are scalable judges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2310.17631</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Unit test characteristics</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">A detailed listing of the unit tests, including the expected mark for each test, is available in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.T6" title="Table 6 ‣ Ablation. ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">6</span></a>.
The queries of the sets are:</p>
<ol class="ltx_enumerate" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1">How can we explain the solidity of the Pantheon’s dome?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1">What is the relationship between Pluto and Neptune?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1">Slow-motion effects and inspiration from Peckinpah?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1">What are the differences and similarities between the Bay Cat and the Temminck’s Cat?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="A1.I1.i5.p1">
<p class="ltx_p" id="A1.I1.i5.p1.1">When should a blood gas test be performed during an apnea test?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para" id="A1.I1.i6.p1">
<p class="ltx_p" id="A1.I1.i6.p1.1">Physical characteristics of the Pyrenean goat</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span>
<div class="ltx_para" id="A1.I1.i7.p1">
<p class="ltx_p" id="A1.I1.i7.p1.1">Why did Audrey Dana direct the film "French Women"?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">8.</span>
<div class="ltx_para" id="A1.I1.i8.p1">
<p class="ltx_p" id="A1.I1.i8.p1.1">What is the influence of Jackie Robinson on American society?</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">9.</span>
<div class="ltx_para" id="A1.I1.i9.p1">
<p class="ltx_p" id="A1.I1.i9.p1.1">How was cuneiform deciphered?</p>
</div>
</li>
</ol>
<p class="ltx_p" id="A1.p1.2">The query of the additional <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.p1.2.1">“training set”</span> is: <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.p1.2.2">“Impacts of Sumbawa pony breeding on the environment?”</span></p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Annotation procedures</h2>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">GroUSE Dataset.</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p1.1">The grounding documents primarily consist of excerpts from Wikipedia, supplemented with manually scraped content from various sources such as news articles, popular science pieces, and medical papers. To simulate retrieval system noise, the references were intentionally altered by truncating sentences, mimicking poorly parsed tables, and including irrelevant headers or footers. To further replicate real-world retrieval challenges, are included in the dataset completely off topic documents as well as incomplete but contextually relevant references. As for the answers, those with perfect expected marks were written from scratch, and then slightly modified to match the other test types, sometimes with the help of an AI writing assistant, but always with final human corrections. The GroUSE dataset was constructed by a single annotator who speaks fluent English.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">RAGAS and DeepEval.</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p1.1">To reannotate the GroUSE unit tests for RAGAS and DeepEval, three labelers computed the answer relevancy and faithfulness. The three labelers speak English fluently, but their primary language is French. A detailed annotation methodology was given to the annotators. This methodology details the definition of answer relevancy and faithfulness so that they can accurately compute the metrics by hand. Annotators were asked to rate the proportion of relevant facts as a proxy for answer relevancy, and the proportion of faithful facts as a proxy for faithfulness.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Human performance on GroUSE.</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px3.p1.1">Six annotators were asked to assess the relevancy, completeness, usefulness, and faithfulness of answers. Each annotator was tasked with evaluating all 16 answers for one or more questions, depending on their availability. If they annotated several sets, the samples of the sets annotated subsequent to the first were shuffled. They were provided with definitions of each metric adapted from GPT-4 prompts, along with the question, the references, a reference answer, and the answer to be evaluated. All annotators are fluent English speakers, one of them is familiar with the evaluated task, two have general knowledge of RAG, while the remaining three had no prior knowledge of the subject.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph"></h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px4.p1.1">All labelers consented to share their annotations.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Prompt templates used for evaluating a grounded answer</h2>
<figure class="ltx_figure" id="A3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="660" id="A3.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Matrixes representing the amount of prompt engineering, for each metric and each model. Each column in a matrix represents the results of one prompt on the training set of GroUSE, the number of column thus represents the number of prompts tested for a given model and metric.</figcaption>
</figure>
<section class="ltx_paragraph" id="A3.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Prompt engineering.</h4>
<div class="ltx_para" id="A3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS0.SSS0.Px1.p1.1">We measured the performances of eleven models on GroUSE, half of them closed-source, the other half open-source. For <span class="ltx_text" id="A3.SS0.SSS0.Px1.p1.1.1">GPT-4</span> <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib1" title="">2023</a>)</cite>, Gemini 1.0 Pro <cite class="ltx_cite ltx_citemacro_cite">Team et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib23" title="">2023</a>)</cite>, Mixtral 8x7b <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib10" title="">2024</a>)</cite>, Prometheus 2 7b and Prometheus 2 8x7b <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib12" title="">2024</a>)</cite>, we iterated on the prompts, making our best effort to achieve the best possible results on the training set of GroUSE. These engineered prompts are then used to test the other models: the GPT-4 prompt is used for the whole GPT family and the Mixtral 8x7b prompt is used for Mixtral 8x22b <cite class="ltx_cite ltx_citemacro_cite">Team (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib24" title="">2024</a>)</cite> and the Llama 3 models <cite class="ltx_cite ltx_citemacro_cite">MetaAI (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib17" title="">2024</a>)</cite>. To engineer a prompt, we begin with a basic instruction and evaluate how many tests in the training set it passes. We then qualitatively analyze the errors and craft a new prompt aimed at eliminating those errors. This iterative process continues until all tests pass or further progress becomes challenging. The amount of prompt tested for each model is visible Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.F6" title="Figure 6 ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Prompt template.</h4>
<div class="ltx_para" id="A3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A3.SS0.SSS0.Px2.p1.1">Each metric is evaluated with a separate prompt specifying its definition, however all prompts share the same template. We always ask the model to rate two answers, the first one being the ground truth and the second one being the answer we truly seek to evaluate: even without specifying that the first answer is the ground truth, this gives the evaluator model a point of comparison. The prompt format is as follow:</p>
<ul class="ltx_itemize" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.1"><span class="ltx_text" id="A3.I1.i1.p1.1.1" style="color:#BE1E2D;">Task introduction:</span> Brief explanation of the grounded question answering task, and the expected citation format</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.1"><span class="ltx_text" id="A3.I1.i2.p1.1.1" style="color:#662D91;">Evaluation instructions:</span></p>
<ul class="ltx_itemize" id="A3.I1.i2.I1">
<li class="ltx_item" id="A3.I1.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="A3.I1.i2.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i2.I1.i1.p1.1">Context explanation: The model is required to assign a score to two answers.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="A3.I1.i2.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.I1.i2.p1.1">Description of the metric: criteria to take into account to evaluate it, a rating scale detailing what each note entails, and a step by step explanation of the reasoning to follow.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="A3.I1.i2.I1.i3.p1">
<p class="ltx_p" id="A3.I1.i2.I1.i3.p1.1">Presentation of the architecture of the JSON expected as an answer: The JSON keys include chain-of-thought keys specific to the metric being evaluated (to compel the model to adhere to the reasoning steps), a free-form justification field, and the assignment of the score. The chain-of-thought keys include a boolean indicating whether the situation is adversarial or not in the <span class="ltx_text ltx_font_bold" id="A3.I1.i2.I1.i3.p1.1.1">Answer relevancy</span> and <span class="ltx_text ltx_font_bold" id="A3.I1.i2.I1.i3.p1.1.2">Usefulness</span> prompts, while the <span class="ltx_text ltx_font_bold" id="A3.I1.i2.I1.i3.p1.1.3">Faithfulness</span> prompts asks for a sentence by sentence analysis, building on <cite class="ltx_cite ltx_citemacro_citet">Chern et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib4" title="">2023</a>); Min et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib18" title="">2023</a>); Es et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib5" title="">2023</a>)</cite>. All these fields are repeated twice, once for each answer to evaluate. This step is absent in the <span class="ltx_text ltx_font_smallcaps" id="A3.I1.i2.I1.i3.p1.1.4">Prometheus 2</span> prompts as the output of the model is imposed.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i3.p1">
<p class="ltx_p" id="A3.I1.i3.p1.1"><span class="ltx_text" id="A3.I1.i3.p1.1.1" style="color:#00AEEF;">Sample:</span> The query and references.</p>
</div>
</li>
<li class="ltx_item" id="A3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A3.I1.i4.p1">
<p class="ltx_p" id="A3.I1.i4.p1.1"><span class="ltx_text" id="A3.I1.i4.p1.1.1" style="color:#8DC63F;">The two answers to evaluate:</span> The first one is always the ground truth, even though we never specify it in the prompt. The second one is the real answer we want to evaluate, and in practice we only look at the evaluation score of the second answer.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A3.SS0.SSS0.Px2.p1.2">The prompts used for GPT-4 are available on <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.F7" title="In Ablation. ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">Figures</span> <span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.F8" title="Figure 8 ‣ Ablation. ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">8</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.F9" title="Figure 9 ‣ Ablation. ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">9</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.F10" title="Figure 10 ‣ Ablation. ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Ablation.</h4>
<div class="ltx_para" id="A3.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A3.SS0.SSS0.Px3.p1.1">We conduct an ablation experiment by measuring GPT-4’s performance on GroUSE with different prompts: removing the ground truth and having the model rate only one answer, removing the justification field, and removing the chain-of-thought field. The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.T5" title="Table 5 ‣ Ablation. ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">5</span></a>: the best agreement rates are obtained for the prompt without the justification, nonetheless removing the ground truth or the chain-of-thought lowers the performances.</p>
</div>
<figure class="ltx_table" id="A3.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T5.1">
<tr class="ltx_tr" id="A3.T5.1.2">
<td class="ltx_td ltx_border_tt" id="A3.T5.1.2.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="6" id="A3.T5.1.2.2"><span class="ltx_text ltx_font_bold" id="A3.T5.1.2.2.1">Agreement rate of metrics</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T5.1.2.3" rowspan="2"><span class="ltx_text" id="A3.T5.1.2.3.1"><span class="ltx_text" id="A3.T5.1.2.3.1.1"></span> <span class="ltx_text" id="A3.T5.1.2.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="A3.T5.1.2.3.1.2.1">
<span class="ltx_tr" id="A3.T5.1.2.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.2.3.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T5.1.2.3.1.2.1.1.1.1">Total</span></span></span>
<span class="ltx_tr" id="A3.T5.1.2.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.2.3.1.2.1.2.1">test pass</span></span>
<span class="ltx_tr" id="A3.T5.1.2.3.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.2.3.1.2.1.3.1">rate</span></span>
</span></span> <span class="ltx_text" id="A3.T5.1.2.3.1.3"></span></span></td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.3">
<td class="ltx_td" id="A3.T5.1.3.1"></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.3.2">
<span class="ltx_text" id="A3.T5.1.3.2.1"></span> <span class="ltx_text" id="A3.T5.1.3.2.2">
<span class="ltx_tabular ltx_align_middle" id="A3.T5.1.3.2.2.1">
<span class="ltx_tr" id="A3.T5.1.3.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.2.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.2.2.1.1.1.1">Answer</span></span></span>
<span class="ltx_tr" id="A3.T5.1.3.2.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.2.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.2.2.1.2.1.1">relevancy</span></span></span>
</span></span><span class="ltx_text" id="A3.T5.1.3.2.3"></span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.3.3">
<span class="ltx_text" id="A3.T5.1.3.3.1"></span> <span class="ltx_text" id="A3.T5.1.3.3.2">
<span class="ltx_tabular ltx_align_middle" id="A3.T5.1.3.3.2.1">
<span class="ltx_tr" id="A3.T5.1.3.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.3.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.3.2.1.1.1.1">Completeness</span></span></span>
</span></span><span class="ltx_text" id="A3.T5.1.3.3.3"></span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.3.4">
<span class="ltx_text" id="A3.T5.1.3.4.1"></span> <span class="ltx_text" id="A3.T5.1.3.4.2">
<span class="ltx_tabular ltx_align_middle" id="A3.T5.1.3.4.2.1">
<span class="ltx_tr" id="A3.T5.1.3.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.4.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.4.2.1.1.1.1">Usefulness</span></span></span>
</span></span><span class="ltx_text" id="A3.T5.1.3.4.3"></span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.3.5">
<span class="ltx_text" id="A3.T5.1.3.5.1"></span> <span class="ltx_text" id="A3.T5.1.3.5.2">
<span class="ltx_tabular ltx_align_middle" id="A3.T5.1.3.5.2.1">
<span class="ltx_tr" id="A3.T5.1.3.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.5.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.5.2.1.1.1.1">Faithfulness</span></span></span>
</span></span><span class="ltx_text" id="A3.T5.1.3.5.3"></span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.3.6">
<span class="ltx_text" id="A3.T5.1.3.6.1"></span> <span class="ltx_text" id="A3.T5.1.3.6.2">
<span class="ltx_tabular ltx_align_middle" id="A3.T5.1.3.6.2.1">
<span class="ltx_tr" id="A3.T5.1.3.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.6.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.6.2.1.1.1.1">Positive</span></span></span>
<span class="ltx_tr" id="A3.T5.1.3.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.6.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.6.2.1.2.1.1">acceptance</span></span></span>
</span></span><span class="ltx_text" id="A3.T5.1.3.6.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.1.3.7">
<span class="ltx_text" id="A3.T5.1.3.7.1"></span> <span class="ltx_text" id="A3.T5.1.3.7.2">
<span class="ltx_tabular ltx_align_middle" id="A3.T5.1.3.7.2.1">
<span class="ltx_tr" id="A3.T5.1.3.7.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.7.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.7.2.1.1.1.1">Negative</span></span></span>
<span class="ltx_tr" id="A3.T5.1.3.7.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A3.T5.1.3.7.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A3.T5.1.3.7.2.1.2.1.1">rejection</span></span></span>
</span></span><span class="ltx_text" id="A3.T5.1.3.7.3"></span></td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="A3.T5.1.4.1"><span class="ltx_text ltx_font_bold" id="A3.T5.1.4.1.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.4.2">92.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.4.3">84.72</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.4.4"><span class="ltx_text ltx_font_bold" id="A3.T5.1.4.4.1">100.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.4.5"><span class="ltx_text ltx_font_bold" id="A3.T5.1.4.5.1">93.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.4.6">92.36</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.4.7">92.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.4.8">92.59</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.5">
<td class="ltx_td ltx_align_left" id="A3.T5.1.5.1">w/o ground truth</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.5.2"><span class="ltx_text ltx_font_bold" id="A3.T5.1.5.2.1">93.75</span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.5.3">84.72</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.5.4">98.61</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.5.5">90.97</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.5.6">31.25</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.1.5.7">31.25</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.5.8">71.76</td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.6">
<td class="ltx_td ltx_align_left" id="A3.T5.1.6.1">w/o justification</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.6.2">91.67</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.6.3"><span class="ltx_text ltx_font_bold" id="A3.T5.1.6.3.1">88.89</span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.6.4"><span class="ltx_text ltx_font_bold" id="A3.T5.1.6.4.1">100.0</span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.6.5">92.36</td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.6.6"><span class="ltx_text ltx_font_bold" id="A3.T5.1.6.6.1">98.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.1.6.7"><span class="ltx_text ltx_font_bold" id="A3.T5.1.6.7.1">98.61</span></td>
<td class="ltx_td ltx_align_center" id="A3.T5.1.6.8"><span class="ltx_text ltx_font_bold" id="A3.T5.1.6.8.1">95.02</span></td>
</tr>
<tr class="ltx_tr" id="A3.T5.1.1">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A3.T5.1.1.2">w/o chain of thought</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.3">90.28</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.1"><math alttext="84.72^{*}" class="ltx_Math" display="inline" id="A3.T5.1.1.1.m1.1"><semantics id="A3.T5.1.1.1.m1.1a"><msup id="A3.T5.1.1.1.m1.1.1" xref="A3.T5.1.1.1.m1.1.1.cmml"><mn id="A3.T5.1.1.1.m1.1.1.2" xref="A3.T5.1.1.1.m1.1.1.2.cmml">84.72</mn><mo id="A3.T5.1.1.1.m1.1.1.3" xref="A3.T5.1.1.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="A3.T5.1.1.1.m1.1b"><apply id="A3.T5.1.1.1.m1.1.1.cmml" xref="A3.T5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.T5.1.1.1.m1.1.1.1.cmml" xref="A3.T5.1.1.1.m1.1.1">superscript</csymbol><cn id="A3.T5.1.1.1.m1.1.1.2.cmml" type="float" xref="A3.T5.1.1.1.m1.1.1.2">84.72</cn><times id="A3.T5.1.1.1.m1.1.1.3.cmml" xref="A3.T5.1.1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.1.1.1.m1.1c">84.72^{*}</annotation><annotation encoding="application/x-llamapun" id="A3.T5.1.1.1.m1.1d">84.72 start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.4">98.61</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.5">91.67</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.6">92.36</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A3.T5.1.1.7">92.36</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T5.1.1.8">91.67</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Percentage of tests passed for different prompts. The highest score in each column is highlighted in bold. The completeness base prompt did not involve any chain of thought, so the reported result is the same as with the base prompt for this ablation, as marked by an asterisk.</figcaption>
</figure>
<figure class="ltx_figure" id="A3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="887" id="A3.F7.g1" src="x7.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Prompt used for <span class="ltx_text ltx_font_bold" id="A3.F7.2.1">Answer relevancy</span> metric with GPT models.</figcaption>
</figure>
<figure class="ltx_figure" id="A3.F8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="887" id="A3.F8.g1" src="x8.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Prompt used for <span class="ltx_text ltx_font_bold" id="A3.F8.2.1">Completeness</span> metric with GPT models.</figcaption>
</figure>
<figure class="ltx_figure" id="A3.F9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="760" id="A3.F9.g1" src="x9.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Prompt used for <span class="ltx_text ltx_font_bold" id="A3.F9.2.1">Usefulness</span> metric with GPT models.</figcaption>
</figure>
<figure class="ltx_figure" id="A3.F10"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="1093" id="A3.F10.g1" src="x10.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Prompt used for <span class="ltx_text ltx_font_bold" id="A3.F10.2.1">Faithfulness</span> metric with GPT models.</figcaption>
</figure>
<figure class="ltx_table" id="A3.T6">
<table class="ltx_tabular ltx_align_middle" id="A3.T6.96">
<tr class="ltx_tr" id="A3.T6.96.97">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.1.1">
<span class="ltx_p" id="A3.T6.96.97.1.1.1" style="width:17.1pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.1.1.1.1">Test type</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.2.1">
<span class="ltx_p" id="A3.T6.96.97.2.1.1" style="width:68.3pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.2.1.1.1">Test name</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A3.T6.96.97.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.3.1">
<span class="ltx_p" id="A3.T6.96.97.3.1.1"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.3.1.1.1">Goal of the test</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.4.1">
<span class="ltx_p" id="A3.T6.96.97.4.1.1" style="width:17.1pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.4.1.1.1">Failure mode</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A3.T6.96.97.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.5.1">
<span class="ltx_p" id="A3.T6.96.97.5.1.1"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.5.1.1.1">References content</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A3.T6.96.97.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.6.1">
<span class="ltx_p" id="A3.T6.96.97.6.1.1"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.6.1.1.1">Answer content</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.7.1">
<span class="ltx_p" id="A3.T6.96.97.7.1.1" style="width:31.3pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.7.1.1.1">Answer relevancy</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.8.1">
<span class="ltx_p" id="A3.T6.96.97.8.1.1" style="width:31.3pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.8.1.1.1">Complete-ness</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.9.1">
<span class="ltx_p" id="A3.T6.96.97.9.1.1" style="width:31.3pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.9.1.1.1">Usefulness</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.10.1">
<span class="ltx_p" id="A3.T6.96.97.10.1.1" style="width:31.3pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.10.1.1.1">Faith-fulness</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.11.1">
<span class="ltx_p" id="A3.T6.96.97.11.1.1" style="width:31.3pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.11.1.1.1">Positive Accept.</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A3.T6.96.97.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.97.12.1">
<span class="ltx_p" id="A3.T6.96.97.12.1.1" style="width:31.3pt;"><span class="ltx_text ltx_font_bold" id="A3.T6.96.97.12.1.1.1">Negative Rejection</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.6.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.6.6.7.1">
<span class="ltx_p" id="A3.T6.6.6.7.1.1" style="width:17.1pt;">1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.6.6.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.6.6.8.1">
<span class="ltx_p" id="A3.T6.6.6.8.1.1" style="width:68.3pt;">Highest marks 1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.6.6.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.6.6.9.1">
<span class="ltx_p" id="A3.T6.6.6.9.1.1">A correct answer should receive good grades.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.6.6.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.6.6.10.1">
<span class="ltx_p" id="A3.T6.6.6.10.1.1" style="width:17.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.6.6.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.6.6.11.1">
<span class="ltx_p" id="A3.T6.6.6.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.6.6.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.6.6.12.1">
<span class="ltx_p" id="A3.T6.6.6.12.1.1">Answer contains correct response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.1.1.1.1">
<span class="ltx_p" id="A3.T6.1.1.1.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.1.1.1.1.1.m1.1"><semantics id="A3.T6.1.1.1.1.1.m1.1a"><mrow id="A3.T6.1.1.1.1.1.m1.1.1" xref="A3.T6.1.1.1.1.1.m1.1.1.cmml"><mi id="A3.T6.1.1.1.1.1.m1.1.1.2" xref="A3.T6.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.1.1.1.1.1.m1.1.1.1" xref="A3.T6.1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.1.1.1.1.1.m1.1.1.3" xref="A3.T6.1.1.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.1.1.1.1.1.m1.1b"><apply id="A3.T6.1.1.1.1.1.m1.1.1.cmml" xref="A3.T6.1.1.1.1.1.m1.1.1"><eq id="A3.T6.1.1.1.1.1.m1.1.1.1.cmml" xref="A3.T6.1.1.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.1.1.1.1.1.m1.1.1.2.cmml" xref="A3.T6.1.1.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.1.1.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.1.1.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.1.1.1.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.1.1.1.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.2.2.2.1">
<span class="ltx_p" id="A3.T6.2.2.2.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.2.2.2.1.1.m1.1"><semantics id="A3.T6.2.2.2.1.1.m1.1a"><mrow id="A3.T6.2.2.2.1.1.m1.1.1" xref="A3.T6.2.2.2.1.1.m1.1.1.cmml"><mi id="A3.T6.2.2.2.1.1.m1.1.1.2" xref="A3.T6.2.2.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.2.2.2.1.1.m1.1.1.1" xref="A3.T6.2.2.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.2.2.2.1.1.m1.1.1.3" xref="A3.T6.2.2.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.2.2.2.1.1.m1.1b"><apply id="A3.T6.2.2.2.1.1.m1.1.1.cmml" xref="A3.T6.2.2.2.1.1.m1.1.1"><eq id="A3.T6.2.2.2.1.1.m1.1.1.1.cmml" xref="A3.T6.2.2.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.2.2.2.1.1.m1.1.1.2.cmml" xref="A3.T6.2.2.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.2.2.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.2.2.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.2.2.2.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.2.2.2.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.3.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.3.3.3.1">
<span class="ltx_p" id="A3.T6.3.3.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.3.3.3.1.1.m1.1"><semantics id="A3.T6.3.3.3.1.1.m1.1a"><mrow id="A3.T6.3.3.3.1.1.m1.1.1" xref="A3.T6.3.3.3.1.1.m1.1.1.cmml"><mi id="A3.T6.3.3.3.1.1.m1.1.1.2" xref="A3.T6.3.3.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.3.3.3.1.1.m1.1.1.1" xref="A3.T6.3.3.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.3.3.3.1.1.m1.1.1.3" xref="A3.T6.3.3.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.3.3.3.1.1.m1.1b"><apply id="A3.T6.3.3.3.1.1.m1.1.1.cmml" xref="A3.T6.3.3.3.1.1.m1.1.1"><eq id="A3.T6.3.3.3.1.1.m1.1.1.1.cmml" xref="A3.T6.3.3.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.3.3.3.1.1.m1.1.1.2.cmml" xref="A3.T6.3.3.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.3.3.3.1.1.m1.1.1.3.cmml" xref="A3.T6.3.3.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.3.3.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.3.3.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.4.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.4.4.4.1">
<span class="ltx_p" id="A3.T6.4.4.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.4.4.4.1.1.m1.1"><semantics id="A3.T6.4.4.4.1.1.m1.1a"><mrow id="A3.T6.4.4.4.1.1.m1.1.1" xref="A3.T6.4.4.4.1.1.m1.1.1.cmml"><mi id="A3.T6.4.4.4.1.1.m1.1.1.2" xref="A3.T6.4.4.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.4.4.4.1.1.m1.1.1.1" xref="A3.T6.4.4.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.4.4.4.1.1.m1.1.1.3" xref="A3.T6.4.4.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.4.4.4.1.1.m1.1b"><apply id="A3.T6.4.4.4.1.1.m1.1.1.cmml" xref="A3.T6.4.4.4.1.1.m1.1.1"><eq id="A3.T6.4.4.4.1.1.m1.1.1.1.cmml" xref="A3.T6.4.4.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.4.4.4.1.1.m1.1.1.2.cmml" xref="A3.T6.4.4.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.4.4.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.4.4.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.4.4.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.4.4.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.5.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.5.5.5.1">
<span class="ltx_p" id="A3.T6.5.5.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.5.5.5.1.1.m1.1"><semantics id="A3.T6.5.5.5.1.1.m1.1a"><mrow id="A3.T6.5.5.5.1.1.m1.1.1" xref="A3.T6.5.5.5.1.1.m1.1.1.cmml"><mi id="A3.T6.5.5.5.1.1.m1.1.1.2" xref="A3.T6.5.5.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.5.5.5.1.1.m1.1.1.1" xref="A3.T6.5.5.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.5.5.5.1.1.m1.1.1.3" xref="A3.T6.5.5.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.5.5.5.1.1.m1.1b"><apply id="A3.T6.5.5.5.1.1.m1.1.1.cmml" xref="A3.T6.5.5.5.1.1.m1.1.1"><eq id="A3.T6.5.5.5.1.1.m1.1.1.1.cmml" xref="A3.T6.5.5.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.5.5.5.1.1.m1.1.1.2.cmml" xref="A3.T6.5.5.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.5.5.5.1.1.m1.1.1.3.cmml" xref="A3.T6.5.5.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.5.5.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.5.5.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T6.6.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.6.6.6.1">
<span class="ltx_p" id="A3.T6.6.6.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.6.6.6.1.1.m1.1"><semantics id="A3.T6.6.6.6.1.1.m1.1a"><mrow id="A3.T6.6.6.6.1.1.m1.1.1" xref="A3.T6.6.6.6.1.1.m1.1.1.cmml"><mi id="A3.T6.6.6.6.1.1.m1.1.1.2" xref="A3.T6.6.6.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.6.6.6.1.1.m1.1.1.1" xref="A3.T6.6.6.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.6.6.6.1.1.m1.1.1.3" xref="A3.T6.6.6.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.6.6.6.1.1.m1.1b"><apply id="A3.T6.6.6.6.1.1.m1.1.1.cmml" xref="A3.T6.6.6.6.1.1.m1.1.1"><eq id="A3.T6.6.6.6.1.1.m1.1.1.1.cmml" xref="A3.T6.6.6.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.6.6.6.1.1.m1.1.1.2.cmml" xref="A3.T6.6.6.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.6.6.6.1.1.m1.1.1.3.cmml" xref="A3.T6.6.6.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.6.6.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.6.6.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.12.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.12.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.12.12.7.1">
<span class="ltx_p" id="A3.T6.12.12.7.1.1" style="width:17.1pt;">2</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.12.12.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.12.12.8.1">
<span class="ltx_p" id="A3.T6.12.12.8.1.1" style="width:68.3pt;">Highest marks 2</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.12.12.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.12.12.9.1">
<span class="ltx_p" id="A3.T6.12.12.9.1.1">A correct adversarial answer with no related information should receive good grades.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.12.12.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.12.12.10.1">
<span class="ltx_p" id="A3.T6.12.12.10.1.1" style="width:17.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.12.12.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.12.12.11.1">
<span class="ltx_p" id="A3.T6.12.12.11.1.1">References contain no response but related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.12.12.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.12.12.12.1">
<span class="ltx_p" id="A3.T6.12.12.12.1.1">Answer claims there is no response in the references.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.7.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.7.7.1.1">
<span class="ltx_p" id="A3.T6.7.7.1.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.7.7.1.1.1.m1.1"><semantics id="A3.T6.7.7.1.1.1.m1.1a"><mrow id="A3.T6.7.7.1.1.1.m1.1.1" xref="A3.T6.7.7.1.1.1.m1.1.1.cmml"><mi id="A3.T6.7.7.1.1.1.m1.1.1.2" xref="A3.T6.7.7.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.7.7.1.1.1.m1.1.1.1" xref="A3.T6.7.7.1.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.7.7.1.1.1.m1.1.1.3" xref="A3.T6.7.7.1.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.7.7.1.1.1.m1.1b"><apply id="A3.T6.7.7.1.1.1.m1.1.1.cmml" xref="A3.T6.7.7.1.1.1.m1.1.1"><eq id="A3.T6.7.7.1.1.1.m1.1.1.1.cmml" xref="A3.T6.7.7.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.7.7.1.1.1.m1.1.1.2.cmml" xref="A3.T6.7.7.1.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.7.7.1.1.1.m1.1.1.3.cmml" xref="A3.T6.7.7.1.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.7.7.1.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.7.7.1.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.8.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.8.8.2.1">
<span class="ltx_p" id="A3.T6.8.8.2.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.8.8.2.1.1.m1.1"><semantics id="A3.T6.8.8.2.1.1.m1.1a"><mrow id="A3.T6.8.8.2.1.1.m1.1.1" xref="A3.T6.8.8.2.1.1.m1.1.1.cmml"><mi id="A3.T6.8.8.2.1.1.m1.1.1.2" xref="A3.T6.8.8.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.8.8.2.1.1.m1.1.1.1" xref="A3.T6.8.8.2.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.8.8.2.1.1.m1.1.1.3" xref="A3.T6.8.8.2.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.8.8.2.1.1.m1.1b"><apply id="A3.T6.8.8.2.1.1.m1.1.1.cmml" xref="A3.T6.8.8.2.1.1.m1.1.1"><eq id="A3.T6.8.8.2.1.1.m1.1.1.1.cmml" xref="A3.T6.8.8.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.8.8.2.1.1.m1.1.1.2.cmml" xref="A3.T6.8.8.2.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.8.8.2.1.1.m1.1.1.3.cmml" xref="A3.T6.8.8.2.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.8.8.2.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.8.8.2.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.9.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.9.9.3.1">
<span class="ltx_p" id="A3.T6.9.9.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.9.9.3.1.1.m1.1"><semantics id="A3.T6.9.9.3.1.1.m1.1a"><mrow id="A3.T6.9.9.3.1.1.m1.1.1" xref="A3.T6.9.9.3.1.1.m1.1.1.cmml"><mi id="A3.T6.9.9.3.1.1.m1.1.1.2" xref="A3.T6.9.9.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.9.9.3.1.1.m1.1.1.1" xref="A3.T6.9.9.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.9.9.3.1.1.m1.1.1.3" xref="A3.T6.9.9.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.9.9.3.1.1.m1.1b"><apply id="A3.T6.9.9.3.1.1.m1.1.1.cmml" xref="A3.T6.9.9.3.1.1.m1.1.1"><eq id="A3.T6.9.9.3.1.1.m1.1.1.1.cmml" xref="A3.T6.9.9.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.9.9.3.1.1.m1.1.1.2.cmml" xref="A3.T6.9.9.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.9.9.3.1.1.m1.1.1.3.cmml" xref="A3.T6.9.9.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.9.9.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.9.9.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.10.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.10.10.4.1">
<span class="ltx_p" id="A3.T6.10.10.4.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.10.10.4.1.1.m1.1"><semantics id="A3.T6.10.10.4.1.1.m1.1a"><mrow id="A3.T6.10.10.4.1.1.m1.1.1" xref="A3.T6.10.10.4.1.1.m1.1.1.cmml"><mi id="A3.T6.10.10.4.1.1.m1.1.1.2" xref="A3.T6.10.10.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.10.10.4.1.1.m1.1.1.1" xref="A3.T6.10.10.4.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.10.10.4.1.1.m1.1.1.3" xref="A3.T6.10.10.4.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.10.10.4.1.1.m1.1b"><apply id="A3.T6.10.10.4.1.1.m1.1.1.cmml" xref="A3.T6.10.10.4.1.1.m1.1.1"><eq id="A3.T6.10.10.4.1.1.m1.1.1.1.cmml" xref="A3.T6.10.10.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.10.10.4.1.1.m1.1.1.2.cmml" xref="A3.T6.10.10.4.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.10.10.4.1.1.m1.1.1.3.cmml" xref="A3.T6.10.10.4.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.10.10.4.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.10.10.4.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.11.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.11.11.5.1">
<span class="ltx_p" id="A3.T6.11.11.5.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.11.11.5.1.1.m1.1"><semantics id="A3.T6.11.11.5.1.1.m1.1a"><mrow id="A3.T6.11.11.5.1.1.m1.1.1" xref="A3.T6.11.11.5.1.1.m1.1.1.cmml"><mi id="A3.T6.11.11.5.1.1.m1.1.1.2" xref="A3.T6.11.11.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.11.11.5.1.1.m1.1.1.1" xref="A3.T6.11.11.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.11.11.5.1.1.m1.1.1.3" xref="A3.T6.11.11.5.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.11.11.5.1.1.m1.1b"><apply id="A3.T6.11.11.5.1.1.m1.1.1.cmml" xref="A3.T6.11.11.5.1.1.m1.1.1"><eq id="A3.T6.11.11.5.1.1.m1.1.1.1.cmml" xref="A3.T6.11.11.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.11.11.5.1.1.m1.1.1.2.cmml" xref="A3.T6.11.11.5.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.11.11.5.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.11.11.5.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.11.11.5.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.11.11.5.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.12.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.12.12.6.1">
<span class="ltx_p" id="A3.T6.12.12.6.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.12.12.6.1.1.m1.1"><semantics id="A3.T6.12.12.6.1.1.m1.1a"><mrow id="A3.T6.12.12.6.1.1.m1.1.1" xref="A3.T6.12.12.6.1.1.m1.1.1.cmml"><mi id="A3.T6.12.12.6.1.1.m1.1.1.2" xref="A3.T6.12.12.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.12.12.6.1.1.m1.1.1.1" xref="A3.T6.12.12.6.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.12.12.6.1.1.m1.1.1.3" xref="A3.T6.12.12.6.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.12.12.6.1.1.m1.1b"><apply id="A3.T6.12.12.6.1.1.m1.1.1.cmml" xref="A3.T6.12.12.6.1.1.m1.1.1"><eq id="A3.T6.12.12.6.1.1.m1.1.1.1.cmml" xref="A3.T6.12.12.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.12.12.6.1.1.m1.1.1.2.cmml" xref="A3.T6.12.12.6.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.12.12.6.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.12.12.6.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.12.12.6.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.12.12.6.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.18.18">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.18.18.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.18.18.7.1">
<span class="ltx_p" id="A3.T6.18.18.7.1.1" style="width:17.1pt;">3</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.18.18.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.18.18.8.1">
<span class="ltx_p" id="A3.T6.18.18.8.1.1" style="width:68.3pt;">Highest marks 3</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.18.18.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.18.18.9.1">
<span class="ltx_p" id="A3.T6.18.18.9.1.1">A correct adversarial answer, providing related information should receive good grades.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.18.18.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.18.18.10.1">
<span class="ltx_p" id="A3.T6.18.18.10.1.1" style="width:17.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.18.18.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.18.18.11.1">
<span class="ltx_p" id="A3.T6.18.18.11.1.1">References contain no response but related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.18.18.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.18.18.12.1">
<span class="ltx_p" id="A3.T6.18.18.12.1.1">Answer claims there is no response in the references and completes with related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.13.13.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.13.13.1.1">
<span class="ltx_p" id="A3.T6.13.13.1.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.13.13.1.1.1.m1.1"><semantics id="A3.T6.13.13.1.1.1.m1.1a"><mrow id="A3.T6.13.13.1.1.1.m1.1.1" xref="A3.T6.13.13.1.1.1.m1.1.1.cmml"><mi id="A3.T6.13.13.1.1.1.m1.1.1.2" xref="A3.T6.13.13.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.13.13.1.1.1.m1.1.1.1" xref="A3.T6.13.13.1.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.13.13.1.1.1.m1.1.1.3" xref="A3.T6.13.13.1.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.13.13.1.1.1.m1.1b"><apply id="A3.T6.13.13.1.1.1.m1.1.1.cmml" xref="A3.T6.13.13.1.1.1.m1.1.1"><eq id="A3.T6.13.13.1.1.1.m1.1.1.1.cmml" xref="A3.T6.13.13.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.13.13.1.1.1.m1.1.1.2.cmml" xref="A3.T6.13.13.1.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.13.13.1.1.1.m1.1.1.3.cmml" xref="A3.T6.13.13.1.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.13.13.1.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.13.13.1.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.14.14.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.14.14.2.1">
<span class="ltx_p" id="A3.T6.14.14.2.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.14.14.2.1.1.m1.1"><semantics id="A3.T6.14.14.2.1.1.m1.1a"><mrow id="A3.T6.14.14.2.1.1.m1.1.1" xref="A3.T6.14.14.2.1.1.m1.1.1.cmml"><mi id="A3.T6.14.14.2.1.1.m1.1.1.2" xref="A3.T6.14.14.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.14.14.2.1.1.m1.1.1.1" xref="A3.T6.14.14.2.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.14.14.2.1.1.m1.1.1.3" xref="A3.T6.14.14.2.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.14.14.2.1.1.m1.1b"><apply id="A3.T6.14.14.2.1.1.m1.1.1.cmml" xref="A3.T6.14.14.2.1.1.m1.1.1"><eq id="A3.T6.14.14.2.1.1.m1.1.1.1.cmml" xref="A3.T6.14.14.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.14.14.2.1.1.m1.1.1.2.cmml" xref="A3.T6.14.14.2.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.14.14.2.1.1.m1.1.1.3.cmml" xref="A3.T6.14.14.2.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.14.14.2.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.14.14.2.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.15.15.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.15.15.3.1">
<span class="ltx_p" id="A3.T6.15.15.3.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.15.15.3.1.1.m1.1"><semantics id="A3.T6.15.15.3.1.1.m1.1a"><mrow id="A3.T6.15.15.3.1.1.m1.1.1" xref="A3.T6.15.15.3.1.1.m1.1.1.cmml"><mi id="A3.T6.15.15.3.1.1.m1.1.1.2" xref="A3.T6.15.15.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.15.15.3.1.1.m1.1.1.1" xref="A3.T6.15.15.3.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.15.15.3.1.1.m1.1.1.3" xref="A3.T6.15.15.3.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.15.15.3.1.1.m1.1b"><apply id="A3.T6.15.15.3.1.1.m1.1.1.cmml" xref="A3.T6.15.15.3.1.1.m1.1.1"><eq id="A3.T6.15.15.3.1.1.m1.1.1.1.cmml" xref="A3.T6.15.15.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.15.15.3.1.1.m1.1.1.2.cmml" xref="A3.T6.15.15.3.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.15.15.3.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.15.15.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.15.15.3.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.15.15.3.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.16.16.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.16.16.4.1">
<span class="ltx_p" id="A3.T6.16.16.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.16.16.4.1.1.m1.1"><semantics id="A3.T6.16.16.4.1.1.m1.1a"><mrow id="A3.T6.16.16.4.1.1.m1.1.1" xref="A3.T6.16.16.4.1.1.m1.1.1.cmml"><mi id="A3.T6.16.16.4.1.1.m1.1.1.2" xref="A3.T6.16.16.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.16.16.4.1.1.m1.1.1.1" xref="A3.T6.16.16.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.16.16.4.1.1.m1.1.1.3" xref="A3.T6.16.16.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.16.16.4.1.1.m1.1b"><apply id="A3.T6.16.16.4.1.1.m1.1.1.cmml" xref="A3.T6.16.16.4.1.1.m1.1.1"><eq id="A3.T6.16.16.4.1.1.m1.1.1.1.cmml" xref="A3.T6.16.16.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.16.16.4.1.1.m1.1.1.2.cmml" xref="A3.T6.16.16.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.16.16.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.16.16.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.16.16.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.16.16.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.17.17.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.17.17.5.1">
<span class="ltx_p" id="A3.T6.17.17.5.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.17.17.5.1.1.m1.1"><semantics id="A3.T6.17.17.5.1.1.m1.1a"><mrow id="A3.T6.17.17.5.1.1.m1.1.1" xref="A3.T6.17.17.5.1.1.m1.1.1.cmml"><mi id="A3.T6.17.17.5.1.1.m1.1.1.2" xref="A3.T6.17.17.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.17.17.5.1.1.m1.1.1.1" xref="A3.T6.17.17.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.17.17.5.1.1.m1.1.1.3" xref="A3.T6.17.17.5.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.17.17.5.1.1.m1.1b"><apply id="A3.T6.17.17.5.1.1.m1.1.1.cmml" xref="A3.T6.17.17.5.1.1.m1.1.1"><eq id="A3.T6.17.17.5.1.1.m1.1.1.1.cmml" xref="A3.T6.17.17.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.17.17.5.1.1.m1.1.1.2.cmml" xref="A3.T6.17.17.5.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.17.17.5.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.17.17.5.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.17.17.5.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.17.17.5.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.18.18.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.18.18.6.1">
<span class="ltx_p" id="A3.T6.18.18.6.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.18.18.6.1.1.m1.1"><semantics id="A3.T6.18.18.6.1.1.m1.1a"><mrow id="A3.T6.18.18.6.1.1.m1.1.1" xref="A3.T6.18.18.6.1.1.m1.1.1.cmml"><mi id="A3.T6.18.18.6.1.1.m1.1.1.2" xref="A3.T6.18.18.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.18.18.6.1.1.m1.1.1.1" xref="A3.T6.18.18.6.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.18.18.6.1.1.m1.1.1.3" xref="A3.T6.18.18.6.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.18.18.6.1.1.m1.1b"><apply id="A3.T6.18.18.6.1.1.m1.1.1.cmml" xref="A3.T6.18.18.6.1.1.m1.1.1"><eq id="A3.T6.18.18.6.1.1.m1.1.1.1.cmml" xref="A3.T6.18.18.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.18.18.6.1.1.m1.1.1.2.cmml" xref="A3.T6.18.18.6.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.18.18.6.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.18.18.6.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.18.18.6.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.18.18.6.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.24.24">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.24.24.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.24.24.7.1">
<span class="ltx_p" id="A3.T6.24.24.7.1.1" style="width:17.1pt;">4</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.24.24.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.24.24.8.1">
<span class="ltx_p" id="A3.T6.24.24.8.1.1" style="width:68.3pt;">Highest marks 4</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.24.24.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.24.24.9.1">
<span class="ltx_p" id="A3.T6.24.24.9.1.1">A dense answer with lots of relevant information retrieved should receive good grades.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.24.24.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.24.24.10.1">
<span class="ltx_p" id="A3.T6.24.24.10.1.1" style="width:17.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.24.24.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.24.24.11.1">
<span class="ltx_p" id="A3.T6.24.24.11.1.1">References contain lots of precise information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.24.24.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.24.24.12.1">
<span class="ltx_p" id="A3.T6.24.24.12.1.1">Answer gives a correct response, more densely than the ground truth.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.19.19.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.19.19.1.1">
<span class="ltx_p" id="A3.T6.19.19.1.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.19.19.1.1.1.m1.1"><semantics id="A3.T6.19.19.1.1.1.m1.1a"><mrow id="A3.T6.19.19.1.1.1.m1.1.1" xref="A3.T6.19.19.1.1.1.m1.1.1.cmml"><mi id="A3.T6.19.19.1.1.1.m1.1.1.2" xref="A3.T6.19.19.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.19.19.1.1.1.m1.1.1.1" xref="A3.T6.19.19.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.19.19.1.1.1.m1.1.1.3" xref="A3.T6.19.19.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.19.19.1.1.1.m1.1b"><apply id="A3.T6.19.19.1.1.1.m1.1.1.cmml" xref="A3.T6.19.19.1.1.1.m1.1.1"><eq id="A3.T6.19.19.1.1.1.m1.1.1.1.cmml" xref="A3.T6.19.19.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.19.19.1.1.1.m1.1.1.2.cmml" xref="A3.T6.19.19.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.19.19.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.19.19.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.19.19.1.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.19.19.1.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.20.20.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.20.20.2.1">
<span class="ltx_p" id="A3.T6.20.20.2.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.20.20.2.1.1.m1.1"><semantics id="A3.T6.20.20.2.1.1.m1.1a"><mrow id="A3.T6.20.20.2.1.1.m1.1.1" xref="A3.T6.20.20.2.1.1.m1.1.1.cmml"><mi id="A3.T6.20.20.2.1.1.m1.1.1.2" xref="A3.T6.20.20.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.20.20.2.1.1.m1.1.1.1" xref="A3.T6.20.20.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.20.20.2.1.1.m1.1.1.3" xref="A3.T6.20.20.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.20.20.2.1.1.m1.1b"><apply id="A3.T6.20.20.2.1.1.m1.1.1.cmml" xref="A3.T6.20.20.2.1.1.m1.1.1"><eq id="A3.T6.20.20.2.1.1.m1.1.1.1.cmml" xref="A3.T6.20.20.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.20.20.2.1.1.m1.1.1.2.cmml" xref="A3.T6.20.20.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.20.20.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.20.20.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.20.20.2.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.20.20.2.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.21.21.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.21.21.3.1">
<span class="ltx_p" id="A3.T6.21.21.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.21.21.3.1.1.m1.1"><semantics id="A3.T6.21.21.3.1.1.m1.1a"><mrow id="A3.T6.21.21.3.1.1.m1.1.1" xref="A3.T6.21.21.3.1.1.m1.1.1.cmml"><mi id="A3.T6.21.21.3.1.1.m1.1.1.2" xref="A3.T6.21.21.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.21.21.3.1.1.m1.1.1.1" xref="A3.T6.21.21.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.21.21.3.1.1.m1.1.1.3" xref="A3.T6.21.21.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.21.21.3.1.1.m1.1b"><apply id="A3.T6.21.21.3.1.1.m1.1.1.cmml" xref="A3.T6.21.21.3.1.1.m1.1.1"><eq id="A3.T6.21.21.3.1.1.m1.1.1.1.cmml" xref="A3.T6.21.21.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.21.21.3.1.1.m1.1.1.2.cmml" xref="A3.T6.21.21.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.21.21.3.1.1.m1.1.1.3.cmml" xref="A3.T6.21.21.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.21.21.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.21.21.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.22.22.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.22.22.4.1">
<span class="ltx_p" id="A3.T6.22.22.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.22.22.4.1.1.m1.1"><semantics id="A3.T6.22.22.4.1.1.m1.1a"><mrow id="A3.T6.22.22.4.1.1.m1.1.1" xref="A3.T6.22.22.4.1.1.m1.1.1.cmml"><mi id="A3.T6.22.22.4.1.1.m1.1.1.2" xref="A3.T6.22.22.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.22.22.4.1.1.m1.1.1.1" xref="A3.T6.22.22.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.22.22.4.1.1.m1.1.1.3" xref="A3.T6.22.22.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.22.22.4.1.1.m1.1b"><apply id="A3.T6.22.22.4.1.1.m1.1.1.cmml" xref="A3.T6.22.22.4.1.1.m1.1.1"><eq id="A3.T6.22.22.4.1.1.m1.1.1.1.cmml" xref="A3.T6.22.22.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.22.22.4.1.1.m1.1.1.2.cmml" xref="A3.T6.22.22.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.22.22.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.22.22.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.22.22.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.22.22.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.23.23.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.23.23.5.1">
<span class="ltx_p" id="A3.T6.23.23.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.23.23.5.1.1.m1.1"><semantics id="A3.T6.23.23.5.1.1.m1.1a"><mrow id="A3.T6.23.23.5.1.1.m1.1.1" xref="A3.T6.23.23.5.1.1.m1.1.1.cmml"><mi id="A3.T6.23.23.5.1.1.m1.1.1.2" xref="A3.T6.23.23.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.23.23.5.1.1.m1.1.1.1" xref="A3.T6.23.23.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.23.23.5.1.1.m1.1.1.3" xref="A3.T6.23.23.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.23.23.5.1.1.m1.1b"><apply id="A3.T6.23.23.5.1.1.m1.1.1.cmml" xref="A3.T6.23.23.5.1.1.m1.1.1"><eq id="A3.T6.23.23.5.1.1.m1.1.1.1.cmml" xref="A3.T6.23.23.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.23.23.5.1.1.m1.1.1.2.cmml" xref="A3.T6.23.23.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.23.23.5.1.1.m1.1.1.3.cmml" xref="A3.T6.23.23.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.23.23.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.23.23.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.24.24.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.24.24.6.1">
<span class="ltx_p" id="A3.T6.24.24.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.24.24.6.1.1.m1.1"><semantics id="A3.T6.24.24.6.1.1.m1.1a"><mrow id="A3.T6.24.24.6.1.1.m1.1.1" xref="A3.T6.24.24.6.1.1.m1.1.1.cmml"><mi id="A3.T6.24.24.6.1.1.m1.1.1.2" xref="A3.T6.24.24.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.24.24.6.1.1.m1.1.1.1" xref="A3.T6.24.24.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.24.24.6.1.1.m1.1.1.3" xref="A3.T6.24.24.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.24.24.6.1.1.m1.1b"><apply id="A3.T6.24.24.6.1.1.m1.1.1.cmml" xref="A3.T6.24.24.6.1.1.m1.1.1"><eq id="A3.T6.24.24.6.1.1.m1.1.1.1.cmml" xref="A3.T6.24.24.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.24.24.6.1.1.m1.1.1.2.cmml" xref="A3.T6.24.24.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.24.24.6.1.1.m1.1.1.3.cmml" xref="A3.T6.24.24.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.24.24.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.24.24.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.30.30">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.30.30.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.30.30.7.1">
<span class="ltx_p" id="A3.T6.30.30.7.1.1" style="width:17.1pt;">5</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.30.30.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.30.30.8.1">
<span class="ltx_p" id="A3.T6.30.30.8.1.1" style="width:68.3pt;">Highest marks 5</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.30.30.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.30.30.9.1">
<span class="ltx_p" id="A3.T6.30.30.9.1.1">Same as <span class="ltx_text ltx_font_italic" id="A3.T6.30.30.9.1.1.1">Highest mark 2</span> but the references contain no related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.30.30.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.30.30.10.1">
<span class="ltx_p" id="A3.T6.30.30.10.1.1" style="width:17.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.30.30.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.30.30.11.1">
<span class="ltx_p" id="A3.T6.30.30.11.1.1">References are completely off-topic.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.30.30.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.30.30.12.1">
<span class="ltx_p" id="A3.T6.30.30.12.1.1">Answer claims there is no response in the references.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.25.25.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.25.25.1.1">
<span class="ltx_p" id="A3.T6.25.25.1.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.25.25.1.1.1.m1.1"><semantics id="A3.T6.25.25.1.1.1.m1.1a"><mrow id="A3.T6.25.25.1.1.1.m1.1.1" xref="A3.T6.25.25.1.1.1.m1.1.1.cmml"><mi id="A3.T6.25.25.1.1.1.m1.1.1.2" xref="A3.T6.25.25.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.25.25.1.1.1.m1.1.1.1" xref="A3.T6.25.25.1.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.25.25.1.1.1.m1.1.1.3" xref="A3.T6.25.25.1.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.25.25.1.1.1.m1.1b"><apply id="A3.T6.25.25.1.1.1.m1.1.1.cmml" xref="A3.T6.25.25.1.1.1.m1.1.1"><eq id="A3.T6.25.25.1.1.1.m1.1.1.1.cmml" xref="A3.T6.25.25.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.25.25.1.1.1.m1.1.1.2.cmml" xref="A3.T6.25.25.1.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.25.25.1.1.1.m1.1.1.3.cmml" xref="A3.T6.25.25.1.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.25.25.1.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.25.25.1.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.26.26.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.26.26.2.1">
<span class="ltx_p" id="A3.T6.26.26.2.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.26.26.2.1.1.m1.1"><semantics id="A3.T6.26.26.2.1.1.m1.1a"><mrow id="A3.T6.26.26.2.1.1.m1.1.1" xref="A3.T6.26.26.2.1.1.m1.1.1.cmml"><mi id="A3.T6.26.26.2.1.1.m1.1.1.2" xref="A3.T6.26.26.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.26.26.2.1.1.m1.1.1.1" xref="A3.T6.26.26.2.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.26.26.2.1.1.m1.1.1.3" xref="A3.T6.26.26.2.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.26.26.2.1.1.m1.1b"><apply id="A3.T6.26.26.2.1.1.m1.1.1.cmml" xref="A3.T6.26.26.2.1.1.m1.1.1"><eq id="A3.T6.26.26.2.1.1.m1.1.1.1.cmml" xref="A3.T6.26.26.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.26.26.2.1.1.m1.1.1.2.cmml" xref="A3.T6.26.26.2.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.26.26.2.1.1.m1.1.1.3.cmml" xref="A3.T6.26.26.2.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.26.26.2.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.26.26.2.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.27.27.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.27.27.3.1">
<span class="ltx_p" id="A3.T6.27.27.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.27.27.3.1.1.m1.1"><semantics id="A3.T6.27.27.3.1.1.m1.1a"><mrow id="A3.T6.27.27.3.1.1.m1.1.1" xref="A3.T6.27.27.3.1.1.m1.1.1.cmml"><mi id="A3.T6.27.27.3.1.1.m1.1.1.2" xref="A3.T6.27.27.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.27.27.3.1.1.m1.1.1.1" xref="A3.T6.27.27.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.27.27.3.1.1.m1.1.1.3" xref="A3.T6.27.27.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.27.27.3.1.1.m1.1b"><apply id="A3.T6.27.27.3.1.1.m1.1.1.cmml" xref="A3.T6.27.27.3.1.1.m1.1.1"><eq id="A3.T6.27.27.3.1.1.m1.1.1.1.cmml" xref="A3.T6.27.27.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.27.27.3.1.1.m1.1.1.2.cmml" xref="A3.T6.27.27.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.27.27.3.1.1.m1.1.1.3.cmml" xref="A3.T6.27.27.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.27.27.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.27.27.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.28.28.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.28.28.4.1">
<span class="ltx_p" id="A3.T6.28.28.4.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.28.28.4.1.1.m1.1"><semantics id="A3.T6.28.28.4.1.1.m1.1a"><mrow id="A3.T6.28.28.4.1.1.m1.1.1" xref="A3.T6.28.28.4.1.1.m1.1.1.cmml"><mi id="A3.T6.28.28.4.1.1.m1.1.1.2" xref="A3.T6.28.28.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.28.28.4.1.1.m1.1.1.1" xref="A3.T6.28.28.4.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.28.28.4.1.1.m1.1.1.3" xref="A3.T6.28.28.4.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.28.28.4.1.1.m1.1b"><apply id="A3.T6.28.28.4.1.1.m1.1.1.cmml" xref="A3.T6.28.28.4.1.1.m1.1.1"><eq id="A3.T6.28.28.4.1.1.m1.1.1.1.cmml" xref="A3.T6.28.28.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.28.28.4.1.1.m1.1.1.2.cmml" xref="A3.T6.28.28.4.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.28.28.4.1.1.m1.1.1.3.cmml" xref="A3.T6.28.28.4.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.28.28.4.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.28.28.4.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.29.29.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.29.29.5.1">
<span class="ltx_p" id="A3.T6.29.29.5.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.29.29.5.1.1.m1.1"><semantics id="A3.T6.29.29.5.1.1.m1.1a"><mrow id="A3.T6.29.29.5.1.1.m1.1.1" xref="A3.T6.29.29.5.1.1.m1.1.1.cmml"><mi id="A3.T6.29.29.5.1.1.m1.1.1.2" xref="A3.T6.29.29.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.29.29.5.1.1.m1.1.1.1" xref="A3.T6.29.29.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.29.29.5.1.1.m1.1.1.3" xref="A3.T6.29.29.5.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.29.29.5.1.1.m1.1b"><apply id="A3.T6.29.29.5.1.1.m1.1.1.cmml" xref="A3.T6.29.29.5.1.1.m1.1.1"><eq id="A3.T6.29.29.5.1.1.m1.1.1.1.cmml" xref="A3.T6.29.29.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.29.29.5.1.1.m1.1.1.2.cmml" xref="A3.T6.29.29.5.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.29.29.5.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.29.29.5.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.29.29.5.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.29.29.5.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.30.30.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.30.30.6.1">
<span class="ltx_p" id="A3.T6.30.30.6.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.30.30.6.1.1.m1.1"><semantics id="A3.T6.30.30.6.1.1.m1.1a"><mrow id="A3.T6.30.30.6.1.1.m1.1.1" xref="A3.T6.30.30.6.1.1.m1.1.1.cmml"><mi id="A3.T6.30.30.6.1.1.m1.1.1.2" xref="A3.T6.30.30.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.30.30.6.1.1.m1.1.1.1" xref="A3.T6.30.30.6.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.30.30.6.1.1.m1.1.1.3" xref="A3.T6.30.30.6.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.30.30.6.1.1.m1.1b"><apply id="A3.T6.30.30.6.1.1.m1.1.1.cmml" xref="A3.T6.30.30.6.1.1.m1.1.1"><eq id="A3.T6.30.30.6.1.1.m1.1.1.1.cmml" xref="A3.T6.30.30.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.30.30.6.1.1.m1.1.1.2.cmml" xref="A3.T6.30.30.6.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.30.30.6.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.30.30.6.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.30.30.6.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.30.30.6.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.36.36">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.36.36.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.36.36.7.1">
<span class="ltx_p" id="A3.T6.36.36.7.1.1" style="width:17.1pt;">6</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.36.36.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.36.36.8.1">
<span class="ltx_p" id="A3.T6.36.36.8.1.1" style="width:68.3pt;">Highest marks 6</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.36.36.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.36.36.9.1">
<span class="ltx_p" id="A3.T6.36.36.9.1.1">Checks that a model does not use its internal knowledge to evaluate the plausibility of the answer.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.36.36.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.36.36.10.1">
<span class="ltx_p" id="A3.T6.36.36.10.1.1" style="width:17.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.36.36.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.36.36.11.1">
<span class="ltx_p" id="A3.T6.36.36.11.1.1">The references contain absurd information which answers the question.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.36.36.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.36.36.12.1">
<span class="ltx_p" id="A3.T6.36.36.12.1.1">Answer contains correct response, quoting absurd information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.31.31.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.31.31.1.1">
<span class="ltx_p" id="A3.T6.31.31.1.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.31.31.1.1.1.m1.1"><semantics id="A3.T6.31.31.1.1.1.m1.1a"><mrow id="A3.T6.31.31.1.1.1.m1.1.1" xref="A3.T6.31.31.1.1.1.m1.1.1.cmml"><mi id="A3.T6.31.31.1.1.1.m1.1.1.2" xref="A3.T6.31.31.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.31.31.1.1.1.m1.1.1.1" xref="A3.T6.31.31.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.31.31.1.1.1.m1.1.1.3" xref="A3.T6.31.31.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.31.31.1.1.1.m1.1b"><apply id="A3.T6.31.31.1.1.1.m1.1.1.cmml" xref="A3.T6.31.31.1.1.1.m1.1.1"><eq id="A3.T6.31.31.1.1.1.m1.1.1.1.cmml" xref="A3.T6.31.31.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.31.31.1.1.1.m1.1.1.2.cmml" xref="A3.T6.31.31.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.31.31.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.31.31.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.31.31.1.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.31.31.1.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.32.32.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.32.32.2.1">
<span class="ltx_p" id="A3.T6.32.32.2.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.32.32.2.1.1.m1.1"><semantics id="A3.T6.32.32.2.1.1.m1.1a"><mrow id="A3.T6.32.32.2.1.1.m1.1.1" xref="A3.T6.32.32.2.1.1.m1.1.1.cmml"><mi id="A3.T6.32.32.2.1.1.m1.1.1.2" xref="A3.T6.32.32.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.32.32.2.1.1.m1.1.1.1" xref="A3.T6.32.32.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.32.32.2.1.1.m1.1.1.3" xref="A3.T6.32.32.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.32.32.2.1.1.m1.1b"><apply id="A3.T6.32.32.2.1.1.m1.1.1.cmml" xref="A3.T6.32.32.2.1.1.m1.1.1"><eq id="A3.T6.32.32.2.1.1.m1.1.1.1.cmml" xref="A3.T6.32.32.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.32.32.2.1.1.m1.1.1.2.cmml" xref="A3.T6.32.32.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.32.32.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.32.32.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.32.32.2.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.32.32.2.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.33.33.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.33.33.3.1">
<span class="ltx_p" id="A3.T6.33.33.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.33.33.3.1.1.m1.1"><semantics id="A3.T6.33.33.3.1.1.m1.1a"><mrow id="A3.T6.33.33.3.1.1.m1.1.1" xref="A3.T6.33.33.3.1.1.m1.1.1.cmml"><mi id="A3.T6.33.33.3.1.1.m1.1.1.2" xref="A3.T6.33.33.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.33.33.3.1.1.m1.1.1.1" xref="A3.T6.33.33.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.33.33.3.1.1.m1.1.1.3" xref="A3.T6.33.33.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.33.33.3.1.1.m1.1b"><apply id="A3.T6.33.33.3.1.1.m1.1.1.cmml" xref="A3.T6.33.33.3.1.1.m1.1.1"><eq id="A3.T6.33.33.3.1.1.m1.1.1.1.cmml" xref="A3.T6.33.33.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.33.33.3.1.1.m1.1.1.2.cmml" xref="A3.T6.33.33.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.33.33.3.1.1.m1.1.1.3.cmml" xref="A3.T6.33.33.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.33.33.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.33.33.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.34.34.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.34.34.4.1">
<span class="ltx_p" id="A3.T6.34.34.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.34.34.4.1.1.m1.1"><semantics id="A3.T6.34.34.4.1.1.m1.1a"><mrow id="A3.T6.34.34.4.1.1.m1.1.1" xref="A3.T6.34.34.4.1.1.m1.1.1.cmml"><mi id="A3.T6.34.34.4.1.1.m1.1.1.2" xref="A3.T6.34.34.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.34.34.4.1.1.m1.1.1.1" xref="A3.T6.34.34.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.34.34.4.1.1.m1.1.1.3" xref="A3.T6.34.34.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.34.34.4.1.1.m1.1b"><apply id="A3.T6.34.34.4.1.1.m1.1.1.cmml" xref="A3.T6.34.34.4.1.1.m1.1.1"><eq id="A3.T6.34.34.4.1.1.m1.1.1.1.cmml" xref="A3.T6.34.34.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.34.34.4.1.1.m1.1.1.2.cmml" xref="A3.T6.34.34.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.34.34.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.34.34.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.34.34.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.34.34.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.35.35.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.35.35.5.1">
<span class="ltx_p" id="A3.T6.35.35.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.35.35.5.1.1.m1.1"><semantics id="A3.T6.35.35.5.1.1.m1.1a"><mrow id="A3.T6.35.35.5.1.1.m1.1.1" xref="A3.T6.35.35.5.1.1.m1.1.1.cmml"><mi id="A3.T6.35.35.5.1.1.m1.1.1.2" xref="A3.T6.35.35.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.35.35.5.1.1.m1.1.1.1" xref="A3.T6.35.35.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.35.35.5.1.1.m1.1.1.3" xref="A3.T6.35.35.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.35.35.5.1.1.m1.1b"><apply id="A3.T6.35.35.5.1.1.m1.1.1.cmml" xref="A3.T6.35.35.5.1.1.m1.1.1"><eq id="A3.T6.35.35.5.1.1.m1.1.1.1.cmml" xref="A3.T6.35.35.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.35.35.5.1.1.m1.1.1.2.cmml" xref="A3.T6.35.35.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.35.35.5.1.1.m1.1.1.3.cmml" xref="A3.T6.35.35.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.35.35.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.35.35.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.36.36.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.36.36.6.1">
<span class="ltx_p" id="A3.T6.36.36.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.36.36.6.1.1.m1.1"><semantics id="A3.T6.36.36.6.1.1.m1.1a"><mrow id="A3.T6.36.36.6.1.1.m1.1.1" xref="A3.T6.36.36.6.1.1.m1.1.1.cmml"><mi id="A3.T6.36.36.6.1.1.m1.1.1.2" xref="A3.T6.36.36.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.36.36.6.1.1.m1.1.1.1" xref="A3.T6.36.36.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.36.36.6.1.1.m1.1.1.3" xref="A3.T6.36.36.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.36.36.6.1.1.m1.1b"><apply id="A3.T6.36.36.6.1.1.m1.1.1.cmml" xref="A3.T6.36.36.6.1.1.m1.1.1"><eq id="A3.T6.36.36.6.1.1.m1.1.1.1.cmml" xref="A3.T6.36.36.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.36.36.6.1.1.m1.1.1.2.cmml" xref="A3.T6.36.36.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.36.36.6.1.1.m1.1.1.3.cmml" xref="A3.T6.36.36.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.36.36.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.36.36.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.42.42">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.42.42.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.42.42.7.1">
<span class="ltx_p" id="A3.T6.42.42.7.1.1" style="width:17.1pt;">7</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.42.42.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.42.42.8.1">
<span class="ltx_p" id="A3.T6.42.42.8.1.1" style="width:68.3pt;">Highest marks 7</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.42.42.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.42.42.9.1">
<span class="ltx_p" id="A3.T6.42.42.9.1.1">Same as <span class="ltx_text ltx_font_italic" id="A3.T6.42.42.9.1.1.1">Highest mark 6</span>, but for related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.42.42.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.42.42.10.1">
<span class="ltx_p" id="A3.T6.42.42.10.1.1" style="width:17.1pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.42.42.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.42.42.11.1">
<span class="ltx_p" id="A3.T6.42.42.11.1.1">The references contain no answer, but some absurd information related to the question.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.42.42.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.42.42.12.1">
<span class="ltx_p" id="A3.T6.42.42.12.1.1">Answer claims there is no response in the references and completes with absurd related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.37.37.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.37.37.1.1">
<span class="ltx_p" id="A3.T6.37.37.1.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.37.37.1.1.1.m1.1"><semantics id="A3.T6.37.37.1.1.1.m1.1a"><mrow id="A3.T6.37.37.1.1.1.m1.1.1" xref="A3.T6.37.37.1.1.1.m1.1.1.cmml"><mi id="A3.T6.37.37.1.1.1.m1.1.1.2" xref="A3.T6.37.37.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.37.37.1.1.1.m1.1.1.1" xref="A3.T6.37.37.1.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.37.37.1.1.1.m1.1.1.3" xref="A3.T6.37.37.1.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.37.37.1.1.1.m1.1b"><apply id="A3.T6.37.37.1.1.1.m1.1.1.cmml" xref="A3.T6.37.37.1.1.1.m1.1.1"><eq id="A3.T6.37.37.1.1.1.m1.1.1.1.cmml" xref="A3.T6.37.37.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.37.37.1.1.1.m1.1.1.2.cmml" xref="A3.T6.37.37.1.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.37.37.1.1.1.m1.1.1.3.cmml" xref="A3.T6.37.37.1.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.37.37.1.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.37.37.1.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.38.38.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.38.38.2.1">
<span class="ltx_p" id="A3.T6.38.38.2.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.38.38.2.1.1.m1.1"><semantics id="A3.T6.38.38.2.1.1.m1.1a"><mrow id="A3.T6.38.38.2.1.1.m1.1.1" xref="A3.T6.38.38.2.1.1.m1.1.1.cmml"><mi id="A3.T6.38.38.2.1.1.m1.1.1.2" xref="A3.T6.38.38.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.38.38.2.1.1.m1.1.1.1" xref="A3.T6.38.38.2.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.38.38.2.1.1.m1.1.1.3" xref="A3.T6.38.38.2.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.38.38.2.1.1.m1.1b"><apply id="A3.T6.38.38.2.1.1.m1.1.1.cmml" xref="A3.T6.38.38.2.1.1.m1.1.1"><eq id="A3.T6.38.38.2.1.1.m1.1.1.1.cmml" xref="A3.T6.38.38.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.38.38.2.1.1.m1.1.1.2.cmml" xref="A3.T6.38.38.2.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.38.38.2.1.1.m1.1.1.3.cmml" xref="A3.T6.38.38.2.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.38.38.2.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.38.38.2.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.39.39.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.39.39.3.1">
<span class="ltx_p" id="A3.T6.39.39.3.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.39.39.3.1.1.m1.1"><semantics id="A3.T6.39.39.3.1.1.m1.1a"><mrow id="A3.T6.39.39.3.1.1.m1.1.1" xref="A3.T6.39.39.3.1.1.m1.1.1.cmml"><mi id="A3.T6.39.39.3.1.1.m1.1.1.2" xref="A3.T6.39.39.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.39.39.3.1.1.m1.1.1.1" xref="A3.T6.39.39.3.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.39.39.3.1.1.m1.1.1.3" xref="A3.T6.39.39.3.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.39.39.3.1.1.m1.1b"><apply id="A3.T6.39.39.3.1.1.m1.1.1.cmml" xref="A3.T6.39.39.3.1.1.m1.1.1"><eq id="A3.T6.39.39.3.1.1.m1.1.1.1.cmml" xref="A3.T6.39.39.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.39.39.3.1.1.m1.1.1.2.cmml" xref="A3.T6.39.39.3.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.39.39.3.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.39.39.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.39.39.3.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.39.39.3.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.40.40.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.40.40.4.1">
<span class="ltx_p" id="A3.T6.40.40.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.40.40.4.1.1.m1.1"><semantics id="A3.T6.40.40.4.1.1.m1.1a"><mrow id="A3.T6.40.40.4.1.1.m1.1.1" xref="A3.T6.40.40.4.1.1.m1.1.1.cmml"><mi id="A3.T6.40.40.4.1.1.m1.1.1.2" xref="A3.T6.40.40.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.40.40.4.1.1.m1.1.1.1" xref="A3.T6.40.40.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.40.40.4.1.1.m1.1.1.3" xref="A3.T6.40.40.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.40.40.4.1.1.m1.1b"><apply id="A3.T6.40.40.4.1.1.m1.1.1.cmml" xref="A3.T6.40.40.4.1.1.m1.1.1"><eq id="A3.T6.40.40.4.1.1.m1.1.1.1.cmml" xref="A3.T6.40.40.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.40.40.4.1.1.m1.1.1.2.cmml" xref="A3.T6.40.40.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.40.40.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.40.40.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.40.40.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.40.40.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.41.41.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.41.41.5.1">
<span class="ltx_p" id="A3.T6.41.41.5.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.41.41.5.1.1.m1.1"><semantics id="A3.T6.41.41.5.1.1.m1.1a"><mrow id="A3.T6.41.41.5.1.1.m1.1.1" xref="A3.T6.41.41.5.1.1.m1.1.1.cmml"><mi id="A3.T6.41.41.5.1.1.m1.1.1.2" xref="A3.T6.41.41.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.41.41.5.1.1.m1.1.1.1" xref="A3.T6.41.41.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.41.41.5.1.1.m1.1.1.3" xref="A3.T6.41.41.5.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.41.41.5.1.1.m1.1b"><apply id="A3.T6.41.41.5.1.1.m1.1.1.cmml" xref="A3.T6.41.41.5.1.1.m1.1.1"><eq id="A3.T6.41.41.5.1.1.m1.1.1.1.cmml" xref="A3.T6.41.41.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.41.41.5.1.1.m1.1.1.2.cmml" xref="A3.T6.41.41.5.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.41.41.5.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.41.41.5.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.41.41.5.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.41.41.5.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.42.42.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.42.42.6.1">
<span class="ltx_p" id="A3.T6.42.42.6.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.42.42.6.1.1.m1.1"><semantics id="A3.T6.42.42.6.1.1.m1.1a"><mrow id="A3.T6.42.42.6.1.1.m1.1.1" xref="A3.T6.42.42.6.1.1.m1.1.1.cmml"><mi id="A3.T6.42.42.6.1.1.m1.1.1.2" xref="A3.T6.42.42.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.42.42.6.1.1.m1.1.1.1" xref="A3.T6.42.42.6.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.42.42.6.1.1.m1.1.1.3" xref="A3.T6.42.42.6.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.42.42.6.1.1.m1.1b"><apply id="A3.T6.42.42.6.1.1.m1.1.1.cmml" xref="A3.T6.42.42.6.1.1.m1.1.1"><eq id="A3.T6.42.42.6.1.1.m1.1.1.1.cmml" xref="A3.T6.42.42.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.42.42.6.1.1.m1.1.1.2.cmml" xref="A3.T6.42.42.6.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.42.42.6.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.42.42.6.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.42.42.6.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.42.42.6.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.48.48">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.48.48.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.48.48.7.1">
<span class="ltx_p" id="A3.T6.48.48.7.1.1" style="width:17.1pt;">8</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.48.48.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.48.48.8.1">
<span class="ltx_p" id="A3.T6.48.48.8.1.1" style="width:68.3pt;">Low answer relevancy 1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.48.48.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.48.48.9.1">
<span class="ltx_p" id="A3.T6.48.48.9.1.1">Answer relevancy should be low when the answer contains irrelevant information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.48.48.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.48.48.10.1">
<span class="ltx_p" id="A3.T6.48.48.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i1" title="Item FM1 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM1</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.48.48.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.48.48.11.1">
<span class="ltx_p" id="A3.T6.48.48.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.48.48.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.48.48.12.1">
<span class="ltx_p" id="A3.T6.48.48.12.1.1">Answer contains correct response, but also irrelevant information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.43.43.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.43.43.1.1">
<span class="ltx_p" id="A3.T6.43.43.1.1.1" style="width:31.3pt;"><math alttext="{}&lt;5" class="ltx_Math" display="inline" id="A3.T6.43.43.1.1.1.m1.1"><semantics id="A3.T6.43.43.1.1.1.m1.1a"><mrow id="A3.T6.43.43.1.1.1.m1.1.1" xref="A3.T6.43.43.1.1.1.m1.1.1.cmml"><mi id="A3.T6.43.43.1.1.1.m1.1.1.2" xref="A3.T6.43.43.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.43.43.1.1.1.m1.1.1.1" xref="A3.T6.43.43.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn id="A3.T6.43.43.1.1.1.m1.1.1.3" xref="A3.T6.43.43.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.43.43.1.1.1.m1.1b"><apply id="A3.T6.43.43.1.1.1.m1.1.1.cmml" xref="A3.T6.43.43.1.1.1.m1.1.1"><lt id="A3.T6.43.43.1.1.1.m1.1.1.1.cmml" xref="A3.T6.43.43.1.1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="A3.T6.43.43.1.1.1.m1.1.1.2.cmml" xref="A3.T6.43.43.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.43.43.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.43.43.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.43.43.1.1.1.m1.1c">{}&lt;5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.43.43.1.1.1.m1.1d">&lt; 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.44.44.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.44.44.2.1">
<span class="ltx_p" id="A3.T6.44.44.2.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.44.44.2.1.1.m1.1"><semantics id="A3.T6.44.44.2.1.1.m1.1a"><mrow id="A3.T6.44.44.2.1.1.m1.1.1" xref="A3.T6.44.44.2.1.1.m1.1.1.cmml"><mi id="A3.T6.44.44.2.1.1.m1.1.1.2" xref="A3.T6.44.44.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.44.44.2.1.1.m1.1.1.1" xref="A3.T6.44.44.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.44.44.2.1.1.m1.1.1.3" xref="A3.T6.44.44.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.44.44.2.1.1.m1.1b"><apply id="A3.T6.44.44.2.1.1.m1.1.1.cmml" xref="A3.T6.44.44.2.1.1.m1.1.1"><eq id="A3.T6.44.44.2.1.1.m1.1.1.1.cmml" xref="A3.T6.44.44.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.44.44.2.1.1.m1.1.1.2.cmml" xref="A3.T6.44.44.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.44.44.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.44.44.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.44.44.2.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.44.44.2.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.45.45.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.45.45.3.1">
<span class="ltx_p" id="A3.T6.45.45.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.45.45.3.1.1.m1.1"><semantics id="A3.T6.45.45.3.1.1.m1.1a"><mrow id="A3.T6.45.45.3.1.1.m1.1.1" xref="A3.T6.45.45.3.1.1.m1.1.1.cmml"><mi id="A3.T6.45.45.3.1.1.m1.1.1.2" xref="A3.T6.45.45.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.45.45.3.1.1.m1.1.1.1" xref="A3.T6.45.45.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.45.45.3.1.1.m1.1.1.3" xref="A3.T6.45.45.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.45.45.3.1.1.m1.1b"><apply id="A3.T6.45.45.3.1.1.m1.1.1.cmml" xref="A3.T6.45.45.3.1.1.m1.1.1"><eq id="A3.T6.45.45.3.1.1.m1.1.1.1.cmml" xref="A3.T6.45.45.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.45.45.3.1.1.m1.1.1.2.cmml" xref="A3.T6.45.45.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.45.45.3.1.1.m1.1.1.3.cmml" xref="A3.T6.45.45.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.45.45.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.45.45.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.46.46.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.46.46.4.1">
<span class="ltx_p" id="A3.T6.46.46.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.46.46.4.1.1.m1.1"><semantics id="A3.T6.46.46.4.1.1.m1.1a"><mrow id="A3.T6.46.46.4.1.1.m1.1.1" xref="A3.T6.46.46.4.1.1.m1.1.1.cmml"><mi id="A3.T6.46.46.4.1.1.m1.1.1.2" xref="A3.T6.46.46.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.46.46.4.1.1.m1.1.1.1" xref="A3.T6.46.46.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.46.46.4.1.1.m1.1.1.3" xref="A3.T6.46.46.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.46.46.4.1.1.m1.1b"><apply id="A3.T6.46.46.4.1.1.m1.1.1.cmml" xref="A3.T6.46.46.4.1.1.m1.1.1"><eq id="A3.T6.46.46.4.1.1.m1.1.1.1.cmml" xref="A3.T6.46.46.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.46.46.4.1.1.m1.1.1.2.cmml" xref="A3.T6.46.46.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.46.46.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.46.46.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.46.46.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.46.46.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.47.47.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.47.47.5.1">
<span class="ltx_p" id="A3.T6.47.47.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.47.47.5.1.1.m1.1"><semantics id="A3.T6.47.47.5.1.1.m1.1a"><mrow id="A3.T6.47.47.5.1.1.m1.1.1" xref="A3.T6.47.47.5.1.1.m1.1.1.cmml"><mi id="A3.T6.47.47.5.1.1.m1.1.1.2" xref="A3.T6.47.47.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.47.47.5.1.1.m1.1.1.1" xref="A3.T6.47.47.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.47.47.5.1.1.m1.1.1.3" xref="A3.T6.47.47.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.47.47.5.1.1.m1.1b"><apply id="A3.T6.47.47.5.1.1.m1.1.1.cmml" xref="A3.T6.47.47.5.1.1.m1.1.1"><eq id="A3.T6.47.47.5.1.1.m1.1.1.1.cmml" xref="A3.T6.47.47.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.47.47.5.1.1.m1.1.1.2.cmml" xref="A3.T6.47.47.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.47.47.5.1.1.m1.1.1.3.cmml" xref="A3.T6.47.47.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.47.47.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.47.47.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.48.48.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.48.48.6.1">
<span class="ltx_p" id="A3.T6.48.48.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.48.48.6.1.1.m1.1"><semantics id="A3.T6.48.48.6.1.1.m1.1a"><mrow id="A3.T6.48.48.6.1.1.m1.1.1" xref="A3.T6.48.48.6.1.1.m1.1.1.cmml"><mi id="A3.T6.48.48.6.1.1.m1.1.1.2" xref="A3.T6.48.48.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.48.48.6.1.1.m1.1.1.1" xref="A3.T6.48.48.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.48.48.6.1.1.m1.1.1.3" xref="A3.T6.48.48.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.48.48.6.1.1.m1.1b"><apply id="A3.T6.48.48.6.1.1.m1.1.1.cmml" xref="A3.T6.48.48.6.1.1.m1.1.1"><eq id="A3.T6.48.48.6.1.1.m1.1.1.1.cmml" xref="A3.T6.48.48.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.48.48.6.1.1.m1.1.1.2.cmml" xref="A3.T6.48.48.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.48.48.6.1.1.m1.1.1.3.cmml" xref="A3.T6.48.48.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.48.48.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.48.48.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.54.54">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.54.54.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.54.54.7.1">
<span class="ltx_p" id="A3.T6.54.54.7.1.1" style="width:17.1pt;">9</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.54.54.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.54.54.8.1">
<span class="ltx_p" id="A3.T6.54.54.8.1.1" style="width:68.3pt;">Low answer relevancy 2</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.54.54.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.54.54.9.1">
<span class="ltx_p" id="A3.T6.54.54.9.1.1">Answer relevancy should be minimal when the answer contains no relevant information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.54.54.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.54.54.10.1">
<span class="ltx_p" id="A3.T6.54.54.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i1" title="Item FM1 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM1</span></a> <a class="ltx_ref ltx_centering" href="https://arxiv.org/html/2409.06595v1#S4.I1.i2" title="Item FM2 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM2</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.54.54.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.54.54.11.1">
<span class="ltx_p" id="A3.T6.54.54.11.1.1">References are completely off-topic.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.54.54.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.54.54.12.1">
<span class="ltx_p" id="A3.T6.54.54.12.1.1">Answer contains only irrelevant information, quoting the off-topic references.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.49.49.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.49.49.1.1">
<span class="ltx_p" id="A3.T6.49.49.1.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.49.49.1.1.1.m1.1"><semantics id="A3.T6.49.49.1.1.1.m1.1a"><mrow id="A3.T6.49.49.1.1.1.m1.1.1" xref="A3.T6.49.49.1.1.1.m1.1.1.cmml"><mi id="A3.T6.49.49.1.1.1.m1.1.1.2" xref="A3.T6.49.49.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.49.49.1.1.1.m1.1.1.1" xref="A3.T6.49.49.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.49.49.1.1.1.m1.1.1.3" xref="A3.T6.49.49.1.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.49.49.1.1.1.m1.1b"><apply id="A3.T6.49.49.1.1.1.m1.1.1.cmml" xref="A3.T6.49.49.1.1.1.m1.1.1"><eq id="A3.T6.49.49.1.1.1.m1.1.1.1.cmml" xref="A3.T6.49.49.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.49.49.1.1.1.m1.1.1.2.cmml" xref="A3.T6.49.49.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.49.49.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.49.49.1.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.49.49.1.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.49.49.1.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.50.50.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.50.50.2.1">
<span class="ltx_p" id="A3.T6.50.50.2.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.50.50.2.1.1.m1.1"><semantics id="A3.T6.50.50.2.1.1.m1.1a"><mrow id="A3.T6.50.50.2.1.1.m1.1.1" xref="A3.T6.50.50.2.1.1.m1.1.1.cmml"><mi id="A3.T6.50.50.2.1.1.m1.1.1.2" xref="A3.T6.50.50.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.50.50.2.1.1.m1.1.1.1" xref="A3.T6.50.50.2.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.50.50.2.1.1.m1.1.1.3" xref="A3.T6.50.50.2.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.50.50.2.1.1.m1.1b"><apply id="A3.T6.50.50.2.1.1.m1.1.1.cmml" xref="A3.T6.50.50.2.1.1.m1.1.1"><eq id="A3.T6.50.50.2.1.1.m1.1.1.1.cmml" xref="A3.T6.50.50.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.50.50.2.1.1.m1.1.1.2.cmml" xref="A3.T6.50.50.2.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.50.50.2.1.1.m1.1.1.3.cmml" xref="A3.T6.50.50.2.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.50.50.2.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.50.50.2.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.51.51.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.51.51.3.1">
<span class="ltx_p" id="A3.T6.51.51.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.51.51.3.1.1.m1.1"><semantics id="A3.T6.51.51.3.1.1.m1.1a"><mrow id="A3.T6.51.51.3.1.1.m1.1.1" xref="A3.T6.51.51.3.1.1.m1.1.1.cmml"><mi id="A3.T6.51.51.3.1.1.m1.1.1.2" xref="A3.T6.51.51.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.51.51.3.1.1.m1.1.1.1" xref="A3.T6.51.51.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.51.51.3.1.1.m1.1.1.3" xref="A3.T6.51.51.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.51.51.3.1.1.m1.1b"><apply id="A3.T6.51.51.3.1.1.m1.1.1.cmml" xref="A3.T6.51.51.3.1.1.m1.1.1"><eq id="A3.T6.51.51.3.1.1.m1.1.1.1.cmml" xref="A3.T6.51.51.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.51.51.3.1.1.m1.1.1.2.cmml" xref="A3.T6.51.51.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.51.51.3.1.1.m1.1.1.3.cmml" xref="A3.T6.51.51.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.51.51.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.51.51.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.52.52.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.52.52.4.1">
<span class="ltx_p" id="A3.T6.52.52.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.52.52.4.1.1.m1.1"><semantics id="A3.T6.52.52.4.1.1.m1.1a"><mrow id="A3.T6.52.52.4.1.1.m1.1.1" xref="A3.T6.52.52.4.1.1.m1.1.1.cmml"><mi id="A3.T6.52.52.4.1.1.m1.1.1.2" xref="A3.T6.52.52.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.52.52.4.1.1.m1.1.1.1" xref="A3.T6.52.52.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.52.52.4.1.1.m1.1.1.3" xref="A3.T6.52.52.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.52.52.4.1.1.m1.1b"><apply id="A3.T6.52.52.4.1.1.m1.1.1.cmml" xref="A3.T6.52.52.4.1.1.m1.1.1"><eq id="A3.T6.52.52.4.1.1.m1.1.1.1.cmml" xref="A3.T6.52.52.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.52.52.4.1.1.m1.1.1.2.cmml" xref="A3.T6.52.52.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.52.52.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.52.52.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.52.52.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.52.52.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.53.53.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.53.53.5.1">
<span class="ltx_p" id="A3.T6.53.53.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.53.53.5.1.1.m1.1"><semantics id="A3.T6.53.53.5.1.1.m1.1a"><mrow id="A3.T6.53.53.5.1.1.m1.1.1" xref="A3.T6.53.53.5.1.1.m1.1.1.cmml"><mi id="A3.T6.53.53.5.1.1.m1.1.1.2" xref="A3.T6.53.53.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.53.53.5.1.1.m1.1.1.1" xref="A3.T6.53.53.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.53.53.5.1.1.m1.1.1.3" xref="A3.T6.53.53.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.53.53.5.1.1.m1.1b"><apply id="A3.T6.53.53.5.1.1.m1.1.1.cmml" xref="A3.T6.53.53.5.1.1.m1.1.1"><eq id="A3.T6.53.53.5.1.1.m1.1.1.1.cmml" xref="A3.T6.53.53.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.53.53.5.1.1.m1.1.1.2.cmml" xref="A3.T6.53.53.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.53.53.5.1.1.m1.1.1.3.cmml" xref="A3.T6.53.53.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.53.53.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.53.53.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.54.54.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.54.54.6.1">
<span class="ltx_p" id="A3.T6.54.54.6.1.1" style="width:31.3pt;"><math alttext="{}=0" class="ltx_Math" display="inline" id="A3.T6.54.54.6.1.1.m1.1"><semantics id="A3.T6.54.54.6.1.1.m1.1a"><mrow id="A3.T6.54.54.6.1.1.m1.1.1" xref="A3.T6.54.54.6.1.1.m1.1.1.cmml"><mi id="A3.T6.54.54.6.1.1.m1.1.1.2" xref="A3.T6.54.54.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.54.54.6.1.1.m1.1.1.1" xref="A3.T6.54.54.6.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.54.54.6.1.1.m1.1.1.3" xref="A3.T6.54.54.6.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.54.54.6.1.1.m1.1b"><apply id="A3.T6.54.54.6.1.1.m1.1.1.cmml" xref="A3.T6.54.54.6.1.1.m1.1.1"><eq id="A3.T6.54.54.6.1.1.m1.1.1.1.cmml" xref="A3.T6.54.54.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.54.54.6.1.1.m1.1.1.2.cmml" xref="A3.T6.54.54.6.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.54.54.6.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.54.54.6.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.54.54.6.1.1.m1.1c">{}=0</annotation><annotation encoding="application/x-llamapun" id="A3.T6.54.54.6.1.1.m1.1d">= 0</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.60.60">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.60.60.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.60.60.7.1">
<span class="ltx_p" id="A3.T6.60.60.7.1.1" style="width:17.1pt;">10</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.60.60.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.60.60.8.1">
<span class="ltx_p" id="A3.T6.60.60.8.1.1" style="width:68.3pt;">Low completeness 1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.60.60.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.60.60.9.1">
<span class="ltx_p" id="A3.T6.60.60.9.1.1">Completeness should be low when the answer lacks relevant information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.60.60.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.60.60.10.1">
<span class="ltx_p" id="A3.T6.60.60.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i3" title="Item FM3 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM3</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.60.60.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.60.60.11.1">
<span class="ltx_p" id="A3.T6.60.60.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.60.60.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.60.60.12.1">
<span class="ltx_p" id="A3.T6.60.60.12.1.1">Answer contains most of the relevant information, but some is missing.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.55.55.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.55.55.1.1">
<span class="ltx_p" id="A3.T6.55.55.1.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.55.55.1.1.1.m1.1"><semantics id="A3.T6.55.55.1.1.1.m1.1a"><mrow id="A3.T6.55.55.1.1.1.m1.1.1" xref="A3.T6.55.55.1.1.1.m1.1.1.cmml"><mi id="A3.T6.55.55.1.1.1.m1.1.1.2" xref="A3.T6.55.55.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.55.55.1.1.1.m1.1.1.1" xref="A3.T6.55.55.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.55.55.1.1.1.m1.1.1.3" xref="A3.T6.55.55.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.55.55.1.1.1.m1.1b"><apply id="A3.T6.55.55.1.1.1.m1.1.1.cmml" xref="A3.T6.55.55.1.1.1.m1.1.1"><eq id="A3.T6.55.55.1.1.1.m1.1.1.1.cmml" xref="A3.T6.55.55.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.55.55.1.1.1.m1.1.1.2.cmml" xref="A3.T6.55.55.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.55.55.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.55.55.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.55.55.1.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.55.55.1.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.56.56.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.56.56.2.1">
<span class="ltx_p" id="A3.T6.56.56.2.1.1" style="width:31.3pt;"><math alttext="{}&lt;5" class="ltx_Math" display="inline" id="A3.T6.56.56.2.1.1.m1.1"><semantics id="A3.T6.56.56.2.1.1.m1.1a"><mrow id="A3.T6.56.56.2.1.1.m1.1.1" xref="A3.T6.56.56.2.1.1.m1.1.1.cmml"><mi id="A3.T6.56.56.2.1.1.m1.1.1.2" xref="A3.T6.56.56.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.56.56.2.1.1.m1.1.1.1" xref="A3.T6.56.56.2.1.1.m1.1.1.1.cmml">&lt;</mo><mn id="A3.T6.56.56.2.1.1.m1.1.1.3" xref="A3.T6.56.56.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.56.56.2.1.1.m1.1b"><apply id="A3.T6.56.56.2.1.1.m1.1.1.cmml" xref="A3.T6.56.56.2.1.1.m1.1.1"><lt id="A3.T6.56.56.2.1.1.m1.1.1.1.cmml" xref="A3.T6.56.56.2.1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="A3.T6.56.56.2.1.1.m1.1.1.2.cmml" xref="A3.T6.56.56.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.56.56.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.56.56.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.56.56.2.1.1.m1.1c">{}&lt;5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.56.56.2.1.1.m1.1d">&lt; 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.57.57.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.57.57.3.1">
<span class="ltx_p" id="A3.T6.57.57.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.57.57.3.1.1.m1.1"><semantics id="A3.T6.57.57.3.1.1.m1.1a"><mrow id="A3.T6.57.57.3.1.1.m1.1.1" xref="A3.T6.57.57.3.1.1.m1.1.1.cmml"><mi id="A3.T6.57.57.3.1.1.m1.1.1.2" xref="A3.T6.57.57.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.57.57.3.1.1.m1.1.1.1" xref="A3.T6.57.57.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.57.57.3.1.1.m1.1.1.3" xref="A3.T6.57.57.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.57.57.3.1.1.m1.1b"><apply id="A3.T6.57.57.3.1.1.m1.1.1.cmml" xref="A3.T6.57.57.3.1.1.m1.1.1"><eq id="A3.T6.57.57.3.1.1.m1.1.1.1.cmml" xref="A3.T6.57.57.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.57.57.3.1.1.m1.1.1.2.cmml" xref="A3.T6.57.57.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.57.57.3.1.1.m1.1.1.3.cmml" xref="A3.T6.57.57.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.57.57.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.57.57.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.58.58.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.58.58.4.1">
<span class="ltx_p" id="A3.T6.58.58.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.58.58.4.1.1.m1.1"><semantics id="A3.T6.58.58.4.1.1.m1.1a"><mrow id="A3.T6.58.58.4.1.1.m1.1.1" xref="A3.T6.58.58.4.1.1.m1.1.1.cmml"><mi id="A3.T6.58.58.4.1.1.m1.1.1.2" xref="A3.T6.58.58.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.58.58.4.1.1.m1.1.1.1" xref="A3.T6.58.58.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.58.58.4.1.1.m1.1.1.3" xref="A3.T6.58.58.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.58.58.4.1.1.m1.1b"><apply id="A3.T6.58.58.4.1.1.m1.1.1.cmml" xref="A3.T6.58.58.4.1.1.m1.1.1"><eq id="A3.T6.58.58.4.1.1.m1.1.1.1.cmml" xref="A3.T6.58.58.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.58.58.4.1.1.m1.1.1.2.cmml" xref="A3.T6.58.58.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.58.58.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.58.58.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.58.58.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.58.58.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.59.59.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.59.59.5.1">
<span class="ltx_p" id="A3.T6.59.59.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.59.59.5.1.1.m1.1"><semantics id="A3.T6.59.59.5.1.1.m1.1a"><mrow id="A3.T6.59.59.5.1.1.m1.1.1" xref="A3.T6.59.59.5.1.1.m1.1.1.cmml"><mi id="A3.T6.59.59.5.1.1.m1.1.1.2" xref="A3.T6.59.59.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.59.59.5.1.1.m1.1.1.1" xref="A3.T6.59.59.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.59.59.5.1.1.m1.1.1.3" xref="A3.T6.59.59.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.59.59.5.1.1.m1.1b"><apply id="A3.T6.59.59.5.1.1.m1.1.1.cmml" xref="A3.T6.59.59.5.1.1.m1.1.1"><eq id="A3.T6.59.59.5.1.1.m1.1.1.1.cmml" xref="A3.T6.59.59.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.59.59.5.1.1.m1.1.1.2.cmml" xref="A3.T6.59.59.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.59.59.5.1.1.m1.1.1.3.cmml" xref="A3.T6.59.59.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.59.59.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.59.59.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.60.60.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.60.60.6.1">
<span class="ltx_p" id="A3.T6.60.60.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.60.60.6.1.1.m1.1"><semantics id="A3.T6.60.60.6.1.1.m1.1a"><mrow id="A3.T6.60.60.6.1.1.m1.1.1" xref="A3.T6.60.60.6.1.1.m1.1.1.cmml"><mi id="A3.T6.60.60.6.1.1.m1.1.1.2" xref="A3.T6.60.60.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.60.60.6.1.1.m1.1.1.1" xref="A3.T6.60.60.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.60.60.6.1.1.m1.1.1.3" xref="A3.T6.60.60.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.60.60.6.1.1.m1.1b"><apply id="A3.T6.60.60.6.1.1.m1.1.1.cmml" xref="A3.T6.60.60.6.1.1.m1.1.1"><eq id="A3.T6.60.60.6.1.1.m1.1.1.1.cmml" xref="A3.T6.60.60.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.60.60.6.1.1.m1.1.1.2.cmml" xref="A3.T6.60.60.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.60.60.6.1.1.m1.1.1.3.cmml" xref="A3.T6.60.60.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.60.60.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.60.60.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.66.66">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.66.66.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.66.66.7.1">
<span class="ltx_p" id="A3.T6.66.66.7.1.1" style="width:17.1pt;">11</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.66.66.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.66.66.8.1">
<span class="ltx_p" id="A3.T6.66.66.8.1.1" style="width:68.3pt;">Low completeness 2</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.66.66.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.66.66.9.1">
<span class="ltx_p" id="A3.T6.66.66.9.1.1">Completeness should be minimal when the answer wrongly claims there is no answer.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.66.66.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.66.66.10.1">
<span class="ltx_p" id="A3.T6.66.66.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i3" title="Item FM3 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM3</span></a> <a class="ltx_ref ltx_centering" href="https://arxiv.org/html/2409.06595v1#S4.I1.i4" title="Item FM4 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM4</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.66.66.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.66.66.11.1">
<span class="ltx_p" id="A3.T6.66.66.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.66.66.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.66.66.12.1">
<span class="ltx_p" id="A3.T6.66.66.12.1.1">Answer claims there is no response in the references.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.61.61.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.61.61.1.1">
<span class="ltx_p" id="A3.T6.61.61.1.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.61.61.1.1.1.m1.1"><semantics id="A3.T6.61.61.1.1.1.m1.1a"><mrow id="A3.T6.61.61.1.1.1.m1.1.1" xref="A3.T6.61.61.1.1.1.m1.1.1.cmml"><mi id="A3.T6.61.61.1.1.1.m1.1.1.2" xref="A3.T6.61.61.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.61.61.1.1.1.m1.1.1.1" xref="A3.T6.61.61.1.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.61.61.1.1.1.m1.1.1.3" xref="A3.T6.61.61.1.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.61.61.1.1.1.m1.1b"><apply id="A3.T6.61.61.1.1.1.m1.1.1.cmml" xref="A3.T6.61.61.1.1.1.m1.1.1"><eq id="A3.T6.61.61.1.1.1.m1.1.1.1.cmml" xref="A3.T6.61.61.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.61.61.1.1.1.m1.1.1.2.cmml" xref="A3.T6.61.61.1.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.61.61.1.1.1.m1.1.1.3.cmml" xref="A3.T6.61.61.1.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.61.61.1.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.61.61.1.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.62.62.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.62.62.2.1">
<span class="ltx_p" id="A3.T6.62.62.2.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.62.62.2.1.1.m1.1"><semantics id="A3.T6.62.62.2.1.1.m1.1a"><mrow id="A3.T6.62.62.2.1.1.m1.1.1" xref="A3.T6.62.62.2.1.1.m1.1.1.cmml"><mi id="A3.T6.62.62.2.1.1.m1.1.1.2" xref="A3.T6.62.62.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.62.62.2.1.1.m1.1.1.1" xref="A3.T6.62.62.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.62.62.2.1.1.m1.1.1.3" xref="A3.T6.62.62.2.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.62.62.2.1.1.m1.1b"><apply id="A3.T6.62.62.2.1.1.m1.1.1.cmml" xref="A3.T6.62.62.2.1.1.m1.1.1"><eq id="A3.T6.62.62.2.1.1.m1.1.1.1.cmml" xref="A3.T6.62.62.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.62.62.2.1.1.m1.1.1.2.cmml" xref="A3.T6.62.62.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.62.62.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.62.62.2.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.62.62.2.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.62.62.2.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.63.63.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.63.63.3.1">
<span class="ltx_p" id="A3.T6.63.63.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.63.63.3.1.1.m1.1"><semantics id="A3.T6.63.63.3.1.1.m1.1a"><mrow id="A3.T6.63.63.3.1.1.m1.1.1" xref="A3.T6.63.63.3.1.1.m1.1.1.cmml"><mi id="A3.T6.63.63.3.1.1.m1.1.1.2" xref="A3.T6.63.63.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.63.63.3.1.1.m1.1.1.1" xref="A3.T6.63.63.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.63.63.3.1.1.m1.1.1.3" xref="A3.T6.63.63.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.63.63.3.1.1.m1.1b"><apply id="A3.T6.63.63.3.1.1.m1.1.1.cmml" xref="A3.T6.63.63.3.1.1.m1.1.1"><eq id="A3.T6.63.63.3.1.1.m1.1.1.1.cmml" xref="A3.T6.63.63.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.63.63.3.1.1.m1.1.1.2.cmml" xref="A3.T6.63.63.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.63.63.3.1.1.m1.1.1.3.cmml" xref="A3.T6.63.63.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.63.63.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.63.63.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.64.64.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.64.64.4.1">
<span class="ltx_p" id="A3.T6.64.64.4.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.64.64.4.1.1.m1.1"><semantics id="A3.T6.64.64.4.1.1.m1.1a"><mrow id="A3.T6.64.64.4.1.1.m1.1.1" xref="A3.T6.64.64.4.1.1.m1.1.1.cmml"><mi id="A3.T6.64.64.4.1.1.m1.1.1.2" xref="A3.T6.64.64.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.64.64.4.1.1.m1.1.1.1" xref="A3.T6.64.64.4.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.64.64.4.1.1.m1.1.1.3" xref="A3.T6.64.64.4.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.64.64.4.1.1.m1.1b"><apply id="A3.T6.64.64.4.1.1.m1.1.1.cmml" xref="A3.T6.64.64.4.1.1.m1.1.1"><eq id="A3.T6.64.64.4.1.1.m1.1.1.1.cmml" xref="A3.T6.64.64.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.64.64.4.1.1.m1.1.1.2.cmml" xref="A3.T6.64.64.4.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.64.64.4.1.1.m1.1.1.3.cmml" xref="A3.T6.64.64.4.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.64.64.4.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.64.64.4.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.65.65.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.65.65.5.1">
<span class="ltx_p" id="A3.T6.65.65.5.1.1" style="width:31.3pt;"><math alttext="{}=0" class="ltx_Math" display="inline" id="A3.T6.65.65.5.1.1.m1.1"><semantics id="A3.T6.65.65.5.1.1.m1.1a"><mrow id="A3.T6.65.65.5.1.1.m1.1.1" xref="A3.T6.65.65.5.1.1.m1.1.1.cmml"><mi id="A3.T6.65.65.5.1.1.m1.1.1.2" xref="A3.T6.65.65.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.65.65.5.1.1.m1.1.1.1" xref="A3.T6.65.65.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.65.65.5.1.1.m1.1.1.3" xref="A3.T6.65.65.5.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.65.65.5.1.1.m1.1b"><apply id="A3.T6.65.65.5.1.1.m1.1.1.cmml" xref="A3.T6.65.65.5.1.1.m1.1.1"><eq id="A3.T6.65.65.5.1.1.m1.1.1.1.cmml" xref="A3.T6.65.65.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.65.65.5.1.1.m1.1.1.2.cmml" xref="A3.T6.65.65.5.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.65.65.5.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.65.65.5.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.65.65.5.1.1.m1.1c">{}=0</annotation><annotation encoding="application/x-llamapun" id="A3.T6.65.65.5.1.1.m1.1d">= 0</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.66.66.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.66.66.6.1">
<span class="ltx_p" id="A3.T6.66.66.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.66.66.6.1.1.m1.1"><semantics id="A3.T6.66.66.6.1.1.m1.1a"><mrow id="A3.T6.66.66.6.1.1.m1.1.1" xref="A3.T6.66.66.6.1.1.m1.1.1.cmml"><mi id="A3.T6.66.66.6.1.1.m1.1.1.2" xref="A3.T6.66.66.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.66.66.6.1.1.m1.1.1.1" xref="A3.T6.66.66.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.66.66.6.1.1.m1.1.1.3" xref="A3.T6.66.66.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.66.66.6.1.1.m1.1b"><apply id="A3.T6.66.66.6.1.1.m1.1.1.cmml" xref="A3.T6.66.66.6.1.1.m1.1.1"><eq id="A3.T6.66.66.6.1.1.m1.1.1.1.cmml" xref="A3.T6.66.66.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.66.66.6.1.1.m1.1.1.2.cmml" xref="A3.T6.66.66.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.66.66.6.1.1.m1.1.1.3.cmml" xref="A3.T6.66.66.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.66.66.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.66.66.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.72.72">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.72.72.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.72.72.7.1">
<span class="ltx_p" id="A3.T6.72.72.7.1.1" style="width:17.1pt;">12</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.72.72.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.72.72.8.1">
<span class="ltx_p" id="A3.T6.72.72.8.1.1" style="width:68.3pt;">Low completeness 3</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.72.72.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.72.72.9.1">
<span class="ltx_p" id="A3.T6.72.72.9.1.1">Same as above, even if the answer provides related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.72.72.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.72.72.10.1">
<span class="ltx_p" id="A3.T6.72.72.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i3" title="Item FM3 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM3</span></a> <a class="ltx_ref ltx_centering" href="https://arxiv.org/html/2409.06595v1#S4.I1.i4" title="Item FM4 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM4</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.72.72.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.72.72.11.1">
<span class="ltx_p" id="A3.T6.72.72.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.72.72.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.72.72.12.1">
<span class="ltx_p" id="A3.T6.72.72.12.1.1">Answer claims there is no response in the references and completes with related information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.67.67.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.67.67.1.1">
<span class="ltx_p" id="A3.T6.67.67.1.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.67.67.1.1.1.m1.1"><semantics id="A3.T6.67.67.1.1.1.m1.1a"><mrow id="A3.T6.67.67.1.1.1.m1.1.1" xref="A3.T6.67.67.1.1.1.m1.1.1.cmml"><mi id="A3.T6.67.67.1.1.1.m1.1.1.2" xref="A3.T6.67.67.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.67.67.1.1.1.m1.1.1.1" xref="A3.T6.67.67.1.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.67.67.1.1.1.m1.1.1.3" xref="A3.T6.67.67.1.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.67.67.1.1.1.m1.1b"><apply id="A3.T6.67.67.1.1.1.m1.1.1.cmml" xref="A3.T6.67.67.1.1.1.m1.1.1"><eq id="A3.T6.67.67.1.1.1.m1.1.1.1.cmml" xref="A3.T6.67.67.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.67.67.1.1.1.m1.1.1.2.cmml" xref="A3.T6.67.67.1.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.67.67.1.1.1.m1.1.1.3.cmml" xref="A3.T6.67.67.1.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.67.67.1.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.67.67.1.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.68.68.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.68.68.2.1">
<span class="ltx_p" id="A3.T6.68.68.2.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.68.68.2.1.1.m1.1"><semantics id="A3.T6.68.68.2.1.1.m1.1a"><mrow id="A3.T6.68.68.2.1.1.m1.1.1" xref="A3.T6.68.68.2.1.1.m1.1.1.cmml"><mi id="A3.T6.68.68.2.1.1.m1.1.1.2" xref="A3.T6.68.68.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.68.68.2.1.1.m1.1.1.1" xref="A3.T6.68.68.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.68.68.2.1.1.m1.1.1.3" xref="A3.T6.68.68.2.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.68.68.2.1.1.m1.1b"><apply id="A3.T6.68.68.2.1.1.m1.1.1.cmml" xref="A3.T6.68.68.2.1.1.m1.1.1"><eq id="A3.T6.68.68.2.1.1.m1.1.1.1.cmml" xref="A3.T6.68.68.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.68.68.2.1.1.m1.1.1.2.cmml" xref="A3.T6.68.68.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.68.68.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.68.68.2.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.68.68.2.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.68.68.2.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.69.69.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.69.69.3.1">
<span class="ltx_p" id="A3.T6.69.69.3.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.69.69.3.1.1.m1.1"><semantics id="A3.T6.69.69.3.1.1.m1.1a"><mrow id="A3.T6.69.69.3.1.1.m1.1.1" xref="A3.T6.69.69.3.1.1.m1.1.1.cmml"><mi id="A3.T6.69.69.3.1.1.m1.1.1.2" xref="A3.T6.69.69.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.69.69.3.1.1.m1.1.1.1" xref="A3.T6.69.69.3.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.69.69.3.1.1.m1.1.1.3" xref="A3.T6.69.69.3.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.69.69.3.1.1.m1.1b"><apply id="A3.T6.69.69.3.1.1.m1.1.1.cmml" xref="A3.T6.69.69.3.1.1.m1.1.1"><eq id="A3.T6.69.69.3.1.1.m1.1.1.1.cmml" xref="A3.T6.69.69.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.69.69.3.1.1.m1.1.1.2.cmml" xref="A3.T6.69.69.3.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.69.69.3.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.69.69.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.69.69.3.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.69.69.3.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.70.70.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.70.70.4.1">
<span class="ltx_p" id="A3.T6.70.70.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.70.70.4.1.1.m1.1"><semantics id="A3.T6.70.70.4.1.1.m1.1a"><mrow id="A3.T6.70.70.4.1.1.m1.1.1" xref="A3.T6.70.70.4.1.1.m1.1.1.cmml"><mi id="A3.T6.70.70.4.1.1.m1.1.1.2" xref="A3.T6.70.70.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.70.70.4.1.1.m1.1.1.1" xref="A3.T6.70.70.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.70.70.4.1.1.m1.1.1.3" xref="A3.T6.70.70.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.70.70.4.1.1.m1.1b"><apply id="A3.T6.70.70.4.1.1.m1.1.1.cmml" xref="A3.T6.70.70.4.1.1.m1.1.1"><eq id="A3.T6.70.70.4.1.1.m1.1.1.1.cmml" xref="A3.T6.70.70.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.70.70.4.1.1.m1.1.1.2.cmml" xref="A3.T6.70.70.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.70.70.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.70.70.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.70.70.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.70.70.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.71.71.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.71.71.5.1">
<span class="ltx_p" id="A3.T6.71.71.5.1.1" style="width:31.3pt;"><math alttext="{}=0" class="ltx_Math" display="inline" id="A3.T6.71.71.5.1.1.m1.1"><semantics id="A3.T6.71.71.5.1.1.m1.1a"><mrow id="A3.T6.71.71.5.1.1.m1.1.1" xref="A3.T6.71.71.5.1.1.m1.1.1.cmml"><mi id="A3.T6.71.71.5.1.1.m1.1.1.2" xref="A3.T6.71.71.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.71.71.5.1.1.m1.1.1.1" xref="A3.T6.71.71.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.71.71.5.1.1.m1.1.1.3" xref="A3.T6.71.71.5.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.71.71.5.1.1.m1.1b"><apply id="A3.T6.71.71.5.1.1.m1.1.1.cmml" xref="A3.T6.71.71.5.1.1.m1.1.1"><eq id="A3.T6.71.71.5.1.1.m1.1.1.1.cmml" xref="A3.T6.71.71.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.71.71.5.1.1.m1.1.1.2.cmml" xref="A3.T6.71.71.5.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.71.71.5.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.71.71.5.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.71.71.5.1.1.m1.1c">{}=0</annotation><annotation encoding="application/x-llamapun" id="A3.T6.71.71.5.1.1.m1.1d">= 0</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.72.72.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.72.72.6.1">
<span class="ltx_p" id="A3.T6.72.72.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.72.72.6.1.1.m1.1"><semantics id="A3.T6.72.72.6.1.1.m1.1a"><mrow id="A3.T6.72.72.6.1.1.m1.1.1" xref="A3.T6.72.72.6.1.1.m1.1.1.cmml"><mi id="A3.T6.72.72.6.1.1.m1.1.1.2" xref="A3.T6.72.72.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.72.72.6.1.1.m1.1.1.1" xref="A3.T6.72.72.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.72.72.6.1.1.m1.1.1.3" xref="A3.T6.72.72.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.72.72.6.1.1.m1.1b"><apply id="A3.T6.72.72.6.1.1.m1.1.1.cmml" xref="A3.T6.72.72.6.1.1.m1.1.1"><eq id="A3.T6.72.72.6.1.1.m1.1.1.1.cmml" xref="A3.T6.72.72.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.72.72.6.1.1.m1.1.1.2.cmml" xref="A3.T6.72.72.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.72.72.6.1.1.m1.1.1.3.cmml" xref="A3.T6.72.72.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.72.72.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.72.72.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.78.78">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.78.78.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.78.78.7.1">
<span class="ltx_p" id="A3.T6.78.78.7.1.1" style="width:17.1pt;">13</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.78.78.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.78.78.8.1">
<span class="ltx_p" id="A3.T6.78.78.8.1.1" style="width:68.3pt;">Low usefulness 1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.78.78.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.78.78.9.1">
<span class="ltx_p" id="A3.T6.78.78.9.1.1">Usefulness should be low when an answer provides unrelated information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.78.78.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.78.78.10.1">
<span class="ltx_p" id="A3.T6.78.78.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i5" title="Item FM5 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM5</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.78.78.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.78.78.11.1">
<span class="ltx_p" id="A3.T6.78.78.11.1.1">References are completely off-topic.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.78.78.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.78.78.12.1">
<span class="ltx_p" id="A3.T6.78.78.12.1.1">Answer claims there is no response in the references and completes with off-topic information.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.73.73.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.73.73.1.1">
<span class="ltx_p" id="A3.T6.73.73.1.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.73.73.1.1.1.m1.1"><semantics id="A3.T6.73.73.1.1.1.m1.1a"><mrow id="A3.T6.73.73.1.1.1.m1.1.1" xref="A3.T6.73.73.1.1.1.m1.1.1.cmml"><mi id="A3.T6.73.73.1.1.1.m1.1.1.2" xref="A3.T6.73.73.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.73.73.1.1.1.m1.1.1.1" xref="A3.T6.73.73.1.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.73.73.1.1.1.m1.1.1.3" xref="A3.T6.73.73.1.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.73.73.1.1.1.m1.1b"><apply id="A3.T6.73.73.1.1.1.m1.1.1.cmml" xref="A3.T6.73.73.1.1.1.m1.1.1"><eq id="A3.T6.73.73.1.1.1.m1.1.1.1.cmml" xref="A3.T6.73.73.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.73.73.1.1.1.m1.1.1.2.cmml" xref="A3.T6.73.73.1.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.73.73.1.1.1.m1.1.1.3.cmml" xref="A3.T6.73.73.1.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.73.73.1.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.73.73.1.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.74.74.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.74.74.2.1">
<span class="ltx_p" id="A3.T6.74.74.2.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.74.74.2.1.1.m1.1"><semantics id="A3.T6.74.74.2.1.1.m1.1a"><mrow id="A3.T6.74.74.2.1.1.m1.1.1" xref="A3.T6.74.74.2.1.1.m1.1.1.cmml"><mi id="A3.T6.74.74.2.1.1.m1.1.1.2" xref="A3.T6.74.74.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.74.74.2.1.1.m1.1.1.1" xref="A3.T6.74.74.2.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.74.74.2.1.1.m1.1.1.3" xref="A3.T6.74.74.2.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.74.74.2.1.1.m1.1b"><apply id="A3.T6.74.74.2.1.1.m1.1.1.cmml" xref="A3.T6.74.74.2.1.1.m1.1.1"><eq id="A3.T6.74.74.2.1.1.m1.1.1.1.cmml" xref="A3.T6.74.74.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.74.74.2.1.1.m1.1.1.2.cmml" xref="A3.T6.74.74.2.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.74.74.2.1.1.m1.1.1.3.cmml" xref="A3.T6.74.74.2.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.74.74.2.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.74.74.2.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.75.75.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.75.75.3.1">
<span class="ltx_p" id="A3.T6.75.75.3.1.1" style="width:31.3pt;"><math alttext="{}=0" class="ltx_Math" display="inline" id="A3.T6.75.75.3.1.1.m1.1"><semantics id="A3.T6.75.75.3.1.1.m1.1a"><mrow id="A3.T6.75.75.3.1.1.m1.1.1" xref="A3.T6.75.75.3.1.1.m1.1.1.cmml"><mi id="A3.T6.75.75.3.1.1.m1.1.1.2" xref="A3.T6.75.75.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.75.75.3.1.1.m1.1.1.1" xref="A3.T6.75.75.3.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.75.75.3.1.1.m1.1.1.3" xref="A3.T6.75.75.3.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.75.75.3.1.1.m1.1b"><apply id="A3.T6.75.75.3.1.1.m1.1.1.cmml" xref="A3.T6.75.75.3.1.1.m1.1.1"><eq id="A3.T6.75.75.3.1.1.m1.1.1.1.cmml" xref="A3.T6.75.75.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.75.75.3.1.1.m1.1.1.2.cmml" xref="A3.T6.75.75.3.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.75.75.3.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.75.75.3.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.75.75.3.1.1.m1.1c">{}=0</annotation><annotation encoding="application/x-llamapun" id="A3.T6.75.75.3.1.1.m1.1d">= 0</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.76.76.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.76.76.4.1">
<span class="ltx_p" id="A3.T6.76.76.4.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.76.76.4.1.1.m1.1"><semantics id="A3.T6.76.76.4.1.1.m1.1a"><mrow id="A3.T6.76.76.4.1.1.m1.1.1" xref="A3.T6.76.76.4.1.1.m1.1.1.cmml"><mi id="A3.T6.76.76.4.1.1.m1.1.1.2" xref="A3.T6.76.76.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.76.76.4.1.1.m1.1.1.1" xref="A3.T6.76.76.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.76.76.4.1.1.m1.1.1.3" xref="A3.T6.76.76.4.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.76.76.4.1.1.m1.1b"><apply id="A3.T6.76.76.4.1.1.m1.1.1.cmml" xref="A3.T6.76.76.4.1.1.m1.1.1"><eq id="A3.T6.76.76.4.1.1.m1.1.1.1.cmml" xref="A3.T6.76.76.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.76.76.4.1.1.m1.1.1.2.cmml" xref="A3.T6.76.76.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.76.76.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.76.76.4.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.76.76.4.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.76.76.4.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.77.77.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.77.77.5.1">
<span class="ltx_p" id="A3.T6.77.77.5.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.77.77.5.1.1.m1.1"><semantics id="A3.T6.77.77.5.1.1.m1.1a"><mrow id="A3.T6.77.77.5.1.1.m1.1.1" xref="A3.T6.77.77.5.1.1.m1.1.1.cmml"><mi id="A3.T6.77.77.5.1.1.m1.1.1.2" xref="A3.T6.77.77.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.77.77.5.1.1.m1.1.1.1" xref="A3.T6.77.77.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.77.77.5.1.1.m1.1.1.3" xref="A3.T6.77.77.5.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.77.77.5.1.1.m1.1b"><apply id="A3.T6.77.77.5.1.1.m1.1.1.cmml" xref="A3.T6.77.77.5.1.1.m1.1.1"><eq id="A3.T6.77.77.5.1.1.m1.1.1.1.cmml" xref="A3.T6.77.77.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.77.77.5.1.1.m1.1.1.2.cmml" xref="A3.T6.77.77.5.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.77.77.5.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.77.77.5.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.77.77.5.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.77.77.5.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.78.78.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.78.78.6.1">
<span class="ltx_p" id="A3.T6.78.78.6.1.1" style="width:31.3pt;"><math alttext="{}=1" class="ltx_Math" display="inline" id="A3.T6.78.78.6.1.1.m1.1"><semantics id="A3.T6.78.78.6.1.1.m1.1a"><mrow id="A3.T6.78.78.6.1.1.m1.1.1" xref="A3.T6.78.78.6.1.1.m1.1.1.cmml"><mi id="A3.T6.78.78.6.1.1.m1.1.1.2" xref="A3.T6.78.78.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.78.78.6.1.1.m1.1.1.1" xref="A3.T6.78.78.6.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.78.78.6.1.1.m1.1.1.3" xref="A3.T6.78.78.6.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.78.78.6.1.1.m1.1b"><apply id="A3.T6.78.78.6.1.1.m1.1.1.cmml" xref="A3.T6.78.78.6.1.1.m1.1.1"><eq id="A3.T6.78.78.6.1.1.m1.1.1.1.cmml" xref="A3.T6.78.78.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.78.78.6.1.1.m1.1.1.2.cmml" xref="A3.T6.78.78.6.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.78.78.6.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.78.78.6.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.78.78.6.1.1.m1.1c">{}=1</annotation><annotation encoding="application/x-llamapun" id="A3.T6.78.78.6.1.1.m1.1d">= 1</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.84.84">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.84.84.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.84.84.7.1">
<span class="ltx_p" id="A3.T6.84.84.7.1.1" style="width:17.1pt;">14</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.84.84.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.84.84.8.1">
<span class="ltx_p" id="A3.T6.84.84.8.1.1" style="width:68.3pt;">Low faithfulness 1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.84.84.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.84.84.9.1">
<span class="ltx_p" id="A3.T6.84.84.9.1.1">Faithfulness should be low when the answer contains an incorrect citation.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.84.84.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.84.84.10.1">
<span class="ltx_p" id="A3.T6.84.84.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i6" title="Item FM6 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM6</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.84.84.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.84.84.11.1">
<span class="ltx_p" id="A3.T6.84.84.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.84.84.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.84.84.12.1">
<span class="ltx_p" id="A3.T6.84.84.12.1.1">Answer contains correct response, but contains a mistake in the citations.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.79.79.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.79.79.1.1">
<span class="ltx_p" id="A3.T6.79.79.1.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.79.79.1.1.1.m1.1"><semantics id="A3.T6.79.79.1.1.1.m1.1a"><mrow id="A3.T6.79.79.1.1.1.m1.1.1" xref="A3.T6.79.79.1.1.1.m1.1.1.cmml"><mi id="A3.T6.79.79.1.1.1.m1.1.1.2" xref="A3.T6.79.79.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.79.79.1.1.1.m1.1.1.1" xref="A3.T6.79.79.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.79.79.1.1.1.m1.1.1.3" xref="A3.T6.79.79.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.79.79.1.1.1.m1.1b"><apply id="A3.T6.79.79.1.1.1.m1.1.1.cmml" xref="A3.T6.79.79.1.1.1.m1.1.1"><eq id="A3.T6.79.79.1.1.1.m1.1.1.1.cmml" xref="A3.T6.79.79.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.79.79.1.1.1.m1.1.1.2.cmml" xref="A3.T6.79.79.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.79.79.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.79.79.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.79.79.1.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.79.79.1.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.80.80.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.80.80.2.1">
<span class="ltx_p" id="A3.T6.80.80.2.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.80.80.2.1.1.m1.1"><semantics id="A3.T6.80.80.2.1.1.m1.1a"><mrow id="A3.T6.80.80.2.1.1.m1.1.1" xref="A3.T6.80.80.2.1.1.m1.1.1.cmml"><mi id="A3.T6.80.80.2.1.1.m1.1.1.2" xref="A3.T6.80.80.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.80.80.2.1.1.m1.1.1.1" xref="A3.T6.80.80.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.80.80.2.1.1.m1.1.1.3" xref="A3.T6.80.80.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.80.80.2.1.1.m1.1b"><apply id="A3.T6.80.80.2.1.1.m1.1.1.cmml" xref="A3.T6.80.80.2.1.1.m1.1.1"><eq id="A3.T6.80.80.2.1.1.m1.1.1.1.cmml" xref="A3.T6.80.80.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.80.80.2.1.1.m1.1.1.2.cmml" xref="A3.T6.80.80.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.80.80.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.80.80.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.80.80.2.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.80.80.2.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.81.81.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.81.81.3.1">
<span class="ltx_p" id="A3.T6.81.81.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.81.81.3.1.1.m1.1"><semantics id="A3.T6.81.81.3.1.1.m1.1a"><mrow id="A3.T6.81.81.3.1.1.m1.1.1" xref="A3.T6.81.81.3.1.1.m1.1.1.cmml"><mi id="A3.T6.81.81.3.1.1.m1.1.1.2" xref="A3.T6.81.81.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.81.81.3.1.1.m1.1.1.1" xref="A3.T6.81.81.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.81.81.3.1.1.m1.1.1.3" xref="A3.T6.81.81.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.81.81.3.1.1.m1.1b"><apply id="A3.T6.81.81.3.1.1.m1.1.1.cmml" xref="A3.T6.81.81.3.1.1.m1.1.1"><eq id="A3.T6.81.81.3.1.1.m1.1.1.1.cmml" xref="A3.T6.81.81.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.81.81.3.1.1.m1.1.1.2.cmml" xref="A3.T6.81.81.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.81.81.3.1.1.m1.1.1.3.cmml" xref="A3.T6.81.81.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.81.81.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.81.81.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.82.82.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.82.82.4.1">
<span class="ltx_p" id="A3.T6.82.82.4.1.1" style="width:31.3pt;"><math alttext="{}=0" class="ltx_Math" display="inline" id="A3.T6.82.82.4.1.1.m1.1"><semantics id="A3.T6.82.82.4.1.1.m1.1a"><mrow id="A3.T6.82.82.4.1.1.m1.1.1" xref="A3.T6.82.82.4.1.1.m1.1.1.cmml"><mi id="A3.T6.82.82.4.1.1.m1.1.1.2" xref="A3.T6.82.82.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.82.82.4.1.1.m1.1.1.1" xref="A3.T6.82.82.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.82.82.4.1.1.m1.1.1.3" xref="A3.T6.82.82.4.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.82.82.4.1.1.m1.1b"><apply id="A3.T6.82.82.4.1.1.m1.1.1.cmml" xref="A3.T6.82.82.4.1.1.m1.1.1"><eq id="A3.T6.82.82.4.1.1.m1.1.1.1.cmml" xref="A3.T6.82.82.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.82.82.4.1.1.m1.1.1.2.cmml" xref="A3.T6.82.82.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.82.82.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.82.82.4.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.82.82.4.1.1.m1.1c">{}=0</annotation><annotation encoding="application/x-llamapun" id="A3.T6.82.82.4.1.1.m1.1d">= 0</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.83.83.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.83.83.5.1">
<span class="ltx_p" id="A3.T6.83.83.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.83.83.5.1.1.m1.1"><semantics id="A3.T6.83.83.5.1.1.m1.1a"><mrow id="A3.T6.83.83.5.1.1.m1.1.1" xref="A3.T6.83.83.5.1.1.m1.1.1.cmml"><mi id="A3.T6.83.83.5.1.1.m1.1.1.2" xref="A3.T6.83.83.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.83.83.5.1.1.m1.1.1.1" xref="A3.T6.83.83.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.83.83.5.1.1.m1.1.1.3" xref="A3.T6.83.83.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.83.83.5.1.1.m1.1b"><apply id="A3.T6.83.83.5.1.1.m1.1.1.cmml" xref="A3.T6.83.83.5.1.1.m1.1.1"><eq id="A3.T6.83.83.5.1.1.m1.1.1.1.cmml" xref="A3.T6.83.83.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.83.83.5.1.1.m1.1.1.2.cmml" xref="A3.T6.83.83.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.83.83.5.1.1.m1.1.1.3.cmml" xref="A3.T6.83.83.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.83.83.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.83.83.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.84.84.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.84.84.6.1">
<span class="ltx_p" id="A3.T6.84.84.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.84.84.6.1.1.m1.1"><semantics id="A3.T6.84.84.6.1.1.m1.1a"><mrow id="A3.T6.84.84.6.1.1.m1.1.1" xref="A3.T6.84.84.6.1.1.m1.1.1.cmml"><mi id="A3.T6.84.84.6.1.1.m1.1.1.2" xref="A3.T6.84.84.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.84.84.6.1.1.m1.1.1.1" xref="A3.T6.84.84.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.84.84.6.1.1.m1.1.1.3" xref="A3.T6.84.84.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.84.84.6.1.1.m1.1b"><apply id="A3.T6.84.84.6.1.1.m1.1.1.cmml" xref="A3.T6.84.84.6.1.1.m1.1.1"><eq id="A3.T6.84.84.6.1.1.m1.1.1.1.cmml" xref="A3.T6.84.84.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.84.84.6.1.1.m1.1.1.2.cmml" xref="A3.T6.84.84.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.84.84.6.1.1.m1.1.1.3.cmml" xref="A3.T6.84.84.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.84.84.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.84.84.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.90.90">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.90.90.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.90.90.7.1">
<span class="ltx_p" id="A3.T6.90.90.7.1.1" style="width:17.1pt;">15</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.90.90.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.90.90.8.1">
<span class="ltx_p" id="A3.T6.90.90.8.1.1" style="width:68.3pt;">Low faithfulness 2</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.90.90.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.90.90.9.1">
<span class="ltx_p" id="A3.T6.90.90.9.1.1">Faithfulness should be low when the answer misses a citation.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.90.90.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.90.90.10.1">
<span class="ltx_p" id="A3.T6.90.90.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i7" title="Item FM7 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM7</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.90.90.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.90.90.11.1">
<span class="ltx_p" id="A3.T6.90.90.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A3.T6.90.90.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.90.90.12.1">
<span class="ltx_p" id="A3.T6.90.90.12.1.1">Answer contains correct response, but forgets one of the citations.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.85.85.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.85.85.1.1">
<span class="ltx_p" id="A3.T6.85.85.1.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.85.85.1.1.1.m1.1"><semantics id="A3.T6.85.85.1.1.1.m1.1a"><mrow id="A3.T6.85.85.1.1.1.m1.1.1" xref="A3.T6.85.85.1.1.1.m1.1.1.cmml"><mi id="A3.T6.85.85.1.1.1.m1.1.1.2" xref="A3.T6.85.85.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.85.85.1.1.1.m1.1.1.1" xref="A3.T6.85.85.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.85.85.1.1.1.m1.1.1.3" xref="A3.T6.85.85.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.85.85.1.1.1.m1.1b"><apply id="A3.T6.85.85.1.1.1.m1.1.1.cmml" xref="A3.T6.85.85.1.1.1.m1.1.1"><eq id="A3.T6.85.85.1.1.1.m1.1.1.1.cmml" xref="A3.T6.85.85.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.85.85.1.1.1.m1.1.1.2.cmml" xref="A3.T6.85.85.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.85.85.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.85.85.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.85.85.1.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.85.85.1.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.86.86.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.86.86.2.1">
<span class="ltx_p" id="A3.T6.86.86.2.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.86.86.2.1.1.m1.1"><semantics id="A3.T6.86.86.2.1.1.m1.1a"><mrow id="A3.T6.86.86.2.1.1.m1.1.1" xref="A3.T6.86.86.2.1.1.m1.1.1.cmml"><mi id="A3.T6.86.86.2.1.1.m1.1.1.2" xref="A3.T6.86.86.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.86.86.2.1.1.m1.1.1.1" xref="A3.T6.86.86.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.86.86.2.1.1.m1.1.1.3" xref="A3.T6.86.86.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.86.86.2.1.1.m1.1b"><apply id="A3.T6.86.86.2.1.1.m1.1.1.cmml" xref="A3.T6.86.86.2.1.1.m1.1.1"><eq id="A3.T6.86.86.2.1.1.m1.1.1.1.cmml" xref="A3.T6.86.86.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.86.86.2.1.1.m1.1.1.2.cmml" xref="A3.T6.86.86.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.86.86.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.86.86.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.86.86.2.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.86.86.2.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.87.87.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.87.87.3.1">
<span class="ltx_p" id="A3.T6.87.87.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.87.87.3.1.1.m1.1"><semantics id="A3.T6.87.87.3.1.1.m1.1a"><mrow id="A3.T6.87.87.3.1.1.m1.1.1" xref="A3.T6.87.87.3.1.1.m1.1.1.cmml"><mi id="A3.T6.87.87.3.1.1.m1.1.1.2" xref="A3.T6.87.87.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.87.87.3.1.1.m1.1.1.1" xref="A3.T6.87.87.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.87.87.3.1.1.m1.1.1.3" xref="A3.T6.87.87.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.87.87.3.1.1.m1.1b"><apply id="A3.T6.87.87.3.1.1.m1.1.1.cmml" xref="A3.T6.87.87.3.1.1.m1.1.1"><eq id="A3.T6.87.87.3.1.1.m1.1.1.1.cmml" xref="A3.T6.87.87.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.87.87.3.1.1.m1.1.1.2.cmml" xref="A3.T6.87.87.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.87.87.3.1.1.m1.1.1.3.cmml" xref="A3.T6.87.87.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.87.87.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.87.87.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.88.88.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.88.88.4.1">
<span class="ltx_p" id="A3.T6.88.88.4.1.1" style="width:31.3pt;"><math alttext="{}=0" class="ltx_Math" display="inline" id="A3.T6.88.88.4.1.1.m1.1"><semantics id="A3.T6.88.88.4.1.1.m1.1a"><mrow id="A3.T6.88.88.4.1.1.m1.1.1" xref="A3.T6.88.88.4.1.1.m1.1.1.cmml"><mi id="A3.T6.88.88.4.1.1.m1.1.1.2" xref="A3.T6.88.88.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.88.88.4.1.1.m1.1.1.1" xref="A3.T6.88.88.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.88.88.4.1.1.m1.1.1.3" xref="A3.T6.88.88.4.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.88.88.4.1.1.m1.1b"><apply id="A3.T6.88.88.4.1.1.m1.1.1.cmml" xref="A3.T6.88.88.4.1.1.m1.1.1"><eq id="A3.T6.88.88.4.1.1.m1.1.1.1.cmml" xref="A3.T6.88.88.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.88.88.4.1.1.m1.1.1.2.cmml" xref="A3.T6.88.88.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.88.88.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.88.88.4.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.88.88.4.1.1.m1.1c">{}=0</annotation><annotation encoding="application/x-llamapun" id="A3.T6.88.88.4.1.1.m1.1d">= 0</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.89.89.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.89.89.5.1">
<span class="ltx_p" id="A3.T6.89.89.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.89.89.5.1.1.m1.1"><semantics id="A3.T6.89.89.5.1.1.m1.1a"><mrow id="A3.T6.89.89.5.1.1.m1.1.1" xref="A3.T6.89.89.5.1.1.m1.1.1.cmml"><mi id="A3.T6.89.89.5.1.1.m1.1.1.2" xref="A3.T6.89.89.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.89.89.5.1.1.m1.1.1.1" xref="A3.T6.89.89.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.89.89.5.1.1.m1.1.1.3" xref="A3.T6.89.89.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.89.89.5.1.1.m1.1b"><apply id="A3.T6.89.89.5.1.1.m1.1.1.cmml" xref="A3.T6.89.89.5.1.1.m1.1.1"><eq id="A3.T6.89.89.5.1.1.m1.1.1.1.cmml" xref="A3.T6.89.89.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.89.89.5.1.1.m1.1.1.2.cmml" xref="A3.T6.89.89.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.89.89.5.1.1.m1.1.1.3.cmml" xref="A3.T6.89.89.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.89.89.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.89.89.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T6.90.90.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.90.90.6.1">
<span class="ltx_p" id="A3.T6.90.90.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.90.90.6.1.1.m1.1"><semantics id="A3.T6.90.90.6.1.1.m1.1a"><mrow id="A3.T6.90.90.6.1.1.m1.1.1" xref="A3.T6.90.90.6.1.1.m1.1.1.cmml"><mi id="A3.T6.90.90.6.1.1.m1.1.1.2" xref="A3.T6.90.90.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.90.90.6.1.1.m1.1.1.1" xref="A3.T6.90.90.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.90.90.6.1.1.m1.1.1.3" xref="A3.T6.90.90.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.90.90.6.1.1.m1.1b"><apply id="A3.T6.90.90.6.1.1.m1.1.1.cmml" xref="A3.T6.90.90.6.1.1.m1.1.1"><eq id="A3.T6.90.90.6.1.1.m1.1.1.1.cmml" xref="A3.T6.90.90.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.90.90.6.1.1.m1.1.1.2.cmml" xref="A3.T6.90.90.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.90.90.6.1.1.m1.1.1.3.cmml" xref="A3.T6.90.90.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.90.90.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.90.90.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.96.96">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.96.96.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.96.7.1">
<span class="ltx_p" id="A3.T6.96.96.7.1.1" style="width:17.1pt;">16</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.96.96.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.96.8.1">
<span class="ltx_p" id="A3.T6.96.96.8.1.1" style="width:68.3pt;">Low faithfulness 3</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A3.T6.96.96.9" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.96.9.1">
<span class="ltx_p" id="A3.T6.96.96.9.1.1">Faithfulness should be low when the response distorts the content of the references.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.96.96.10" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.96.10.1">
<span class="ltx_p" id="A3.T6.96.96.10.1.1" style="width:17.1pt;"><a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.I1.i7" title="Item FM7 ‣ 4.1 Grounded QA failure modes ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">FM7</span></a></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A3.T6.96.96.11" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.96.11.1">
<span class="ltx_p" id="A3.T6.96.96.11.1.1">References contain a precise response.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A3.T6.96.96.12" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.96.12.1">
<span class="ltx_p" id="A3.T6.96.96.12.1.1">Answer contains correct response, but distorts the content of the references.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.91.91.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.91.91.1.1">
<span class="ltx_p" id="A3.T6.91.91.1.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.91.91.1.1.1.m1.1"><semantics id="A3.T6.91.91.1.1.1.m1.1a"><mrow id="A3.T6.91.91.1.1.1.m1.1.1" xref="A3.T6.91.91.1.1.1.m1.1.1.cmml"><mi id="A3.T6.91.91.1.1.1.m1.1.1.2" xref="A3.T6.91.91.1.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.91.91.1.1.1.m1.1.1.1" xref="A3.T6.91.91.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.91.91.1.1.1.m1.1.1.3" xref="A3.T6.91.91.1.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.91.91.1.1.1.m1.1b"><apply id="A3.T6.91.91.1.1.1.m1.1.1.cmml" xref="A3.T6.91.91.1.1.1.m1.1.1"><eq id="A3.T6.91.91.1.1.1.m1.1.1.1.cmml" xref="A3.T6.91.91.1.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.91.91.1.1.1.m1.1.1.2.cmml" xref="A3.T6.91.91.1.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.91.91.1.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.91.91.1.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.91.91.1.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.91.91.1.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.92.92.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.92.92.2.1">
<span class="ltx_p" id="A3.T6.92.92.2.1.1" style="width:31.3pt;"><math alttext="{}=5" class="ltx_Math" display="inline" id="A3.T6.92.92.2.1.1.m1.1"><semantics id="A3.T6.92.92.2.1.1.m1.1a"><mrow id="A3.T6.92.92.2.1.1.m1.1.1" xref="A3.T6.92.92.2.1.1.m1.1.1.cmml"><mi id="A3.T6.92.92.2.1.1.m1.1.1.2" xref="A3.T6.92.92.2.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.92.92.2.1.1.m1.1.1.1" xref="A3.T6.92.92.2.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.92.92.2.1.1.m1.1.1.3" xref="A3.T6.92.92.2.1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.92.92.2.1.1.m1.1b"><apply id="A3.T6.92.92.2.1.1.m1.1.1.cmml" xref="A3.T6.92.92.2.1.1.m1.1.1"><eq id="A3.T6.92.92.2.1.1.m1.1.1.1.cmml" xref="A3.T6.92.92.2.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.92.92.2.1.1.m1.1.1.2.cmml" xref="A3.T6.92.92.2.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.92.92.2.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.92.92.2.1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.92.92.2.1.1.m1.1c">{}=5</annotation><annotation encoding="application/x-llamapun" id="A3.T6.92.92.2.1.1.m1.1d">= 5</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.93.93.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.93.93.3.1">
<span class="ltx_p" id="A3.T6.93.93.3.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.93.93.3.1.1.m1.1"><semantics id="A3.T6.93.93.3.1.1.m1.1a"><mrow id="A3.T6.93.93.3.1.1.m1.1.1" xref="A3.T6.93.93.3.1.1.m1.1.1.cmml"><mi id="A3.T6.93.93.3.1.1.m1.1.1.2" xref="A3.T6.93.93.3.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.93.93.3.1.1.m1.1.1.1" xref="A3.T6.93.93.3.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.93.93.3.1.1.m1.1.1.3" xref="A3.T6.93.93.3.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.93.93.3.1.1.m1.1b"><apply id="A3.T6.93.93.3.1.1.m1.1.1.cmml" xref="A3.T6.93.93.3.1.1.m1.1.1"><eq id="A3.T6.93.93.3.1.1.m1.1.1.1.cmml" xref="A3.T6.93.93.3.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.93.93.3.1.1.m1.1.1.2.cmml" xref="A3.T6.93.93.3.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.93.93.3.1.1.m1.1.1.3.cmml" xref="A3.T6.93.93.3.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.93.93.3.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.93.93.3.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.94.94.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.94.94.4.1">
<span class="ltx_p" id="A3.T6.94.94.4.1.1" style="width:31.3pt;"><math alttext="{}=0" class="ltx_Math" display="inline" id="A3.T6.94.94.4.1.1.m1.1"><semantics id="A3.T6.94.94.4.1.1.m1.1a"><mrow id="A3.T6.94.94.4.1.1.m1.1.1" xref="A3.T6.94.94.4.1.1.m1.1.1.cmml"><mi id="A3.T6.94.94.4.1.1.m1.1.1.2" xref="A3.T6.94.94.4.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.94.94.4.1.1.m1.1.1.1" xref="A3.T6.94.94.4.1.1.m1.1.1.1.cmml">=</mo><mn id="A3.T6.94.94.4.1.1.m1.1.1.3" xref="A3.T6.94.94.4.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.94.94.4.1.1.m1.1b"><apply id="A3.T6.94.94.4.1.1.m1.1.1.cmml" xref="A3.T6.94.94.4.1.1.m1.1.1"><eq id="A3.T6.94.94.4.1.1.m1.1.1.1.cmml" xref="A3.T6.94.94.4.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.94.94.4.1.1.m1.1.1.2.cmml" xref="A3.T6.94.94.4.1.1.m1.1.1.2">absent</csymbol><cn id="A3.T6.94.94.4.1.1.m1.1.1.3.cmml" type="integer" xref="A3.T6.94.94.4.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.94.94.4.1.1.m1.1c">{}=0</annotation><annotation encoding="application/x-llamapun" id="A3.T6.94.94.4.1.1.m1.1d">= 0</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.95.95.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.95.95.5.1">
<span class="ltx_p" id="A3.T6.95.95.5.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.95.95.5.1.1.m1.1"><semantics id="A3.T6.95.95.5.1.1.m1.1a"><mrow id="A3.T6.95.95.5.1.1.m1.1.1" xref="A3.T6.95.95.5.1.1.m1.1.1.cmml"><mi id="A3.T6.95.95.5.1.1.m1.1.1.2" xref="A3.T6.95.95.5.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.95.95.5.1.1.m1.1.1.1" xref="A3.T6.95.95.5.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.95.95.5.1.1.m1.1.1.3" xref="A3.T6.95.95.5.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.95.95.5.1.1.m1.1b"><apply id="A3.T6.95.95.5.1.1.m1.1.1.cmml" xref="A3.T6.95.95.5.1.1.m1.1.1"><eq id="A3.T6.95.95.5.1.1.m1.1.1.1.cmml" xref="A3.T6.95.95.5.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.95.95.5.1.1.m1.1.1.2.cmml" xref="A3.T6.95.95.5.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.95.95.5.1.1.m1.1.1.3.cmml" xref="A3.T6.95.95.5.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.95.95.5.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.95.95.5.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A3.T6.96.96.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span class="ltx_inline-block ltx_align_top" id="A3.T6.96.96.6.1">
<span class="ltx_p" id="A3.T6.96.96.6.1.1" style="width:31.3pt;"><math alttext="{}=\operatorname{None}" class="ltx_Math" display="inline" id="A3.T6.96.96.6.1.1.m1.1"><semantics id="A3.T6.96.96.6.1.1.m1.1a"><mrow id="A3.T6.96.96.6.1.1.m1.1.1" xref="A3.T6.96.96.6.1.1.m1.1.1.cmml"><mi id="A3.T6.96.96.6.1.1.m1.1.1.2" xref="A3.T6.96.96.6.1.1.m1.1.1.2.cmml"></mi><mo id="A3.T6.96.96.6.1.1.m1.1.1.1" xref="A3.T6.96.96.6.1.1.m1.1.1.1.cmml">=</mo><mi id="A3.T6.96.96.6.1.1.m1.1.1.3" xref="A3.T6.96.96.6.1.1.m1.1.1.3.cmml">None</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T6.96.96.6.1.1.m1.1b"><apply id="A3.T6.96.96.6.1.1.m1.1.1.cmml" xref="A3.T6.96.96.6.1.1.m1.1.1"><eq id="A3.T6.96.96.6.1.1.m1.1.1.1.cmml" xref="A3.T6.96.96.6.1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="A3.T6.96.96.6.1.1.m1.1.1.2.cmml" xref="A3.T6.96.96.6.1.1.m1.1.1.2">absent</csymbol><ci id="A3.T6.96.96.6.1.1.m1.1.1.3.cmml" xref="A3.T6.96.96.6.1.1.m1.1.1.3">None</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.96.96.6.1.1.m1.1c">{}=\operatorname{None}</annotation><annotation encoding="application/x-llamapun" id="A3.T6.96.96.6.1.1.m1.1d">= roman_None</annotation></semantics></math></span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Detailed list of unit test types: their goals, which failure modes they cover, the characteristics of the references and answer, as well as the expected notes. The first seven tests cover no failure modes but check that correct answers get the highest marks possible, in various situations.</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Detailed unit test results</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">Detailed performances of models on GroUSE are available on Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.F13" title="Figure 13 ‣ Impact of training dataset imbalance. ‣ Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">13</span></a> for closed models, and Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.F14" title="Figure 14 ‣ Impact of training dataset imbalance. ‣ Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">14</span></a> for open-source models. In these Figures, each square represents the result of one test.</p>
</div>
<div class="ltx_para" id="A4.p2">
<p class="ltx_p" id="A4.p2.1">These results were obtained through the OpenAI<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/openai-api/" title="">https://openai.com/index/openai-api/</a></span></span></span> and VertexAI<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/vertex-ai/docs/reference" title="">https://cloud.google.com/vertex-ai/docs/reference</a></span></span></span> API for the GPT and Gemini models respectively. For Mixtral and Llama-3 models, the Fireworks AI<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://fireworks.ai/" title="">https://fireworks.ai/</a></span></span></span> API was used. Prometheus 2 7b was deployed using TGI<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/text-generation-inference/" title="">https://huggingface.co/docs/text-generation-inference/</a></span></span></span>, and the inferences for Prometheus 2 8x7b were made using a model quantized with llama.cpp<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ggerganov/llama.cpp" title="">https://github.com/ggerganov/llama.cpp</a></span></span></span> (Q4_K_M quantization), and deployed with the same library. For all models, greedy decoding was used when available, else the smallest temperature allowed.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Dataset constitution</h2>
<section class="ltx_paragraph" id="A5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Fine-tuning prompt format.</h4>
<div class="ltx_para" id="A5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A5.SS0.SSS0.Px1.p1.1">Although Table <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A3.T5" title="Table 5 ‣ Ablation. ‣ Appendix C Prompt templates used for evaluating a grounded answer ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">5</span></a> indicates that the best results are achieved without a justification, we opted to build the dataset of GPT-4 traces with one. This decision is supported by two main reasons: first, <cite class="ltx_cite ltx_citemacro_citet">Mukherjee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib20" title="">2023</a>)</cite> show that a smaller model benefit more from GPT-4’s traces if they include explanations of its reasoning. Second, the justification enhances the interpretability of the model’s responses.</p>
</div>
</section>
<section class="ltx_paragraph" id="A5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Models used for inference.</h4>
<div class="ltx_para" id="A5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A5.SS0.SSS0.Px2.p1.1">Given the 1200 grounded QA statements, we used the following list of models to generate the predictions :</p>
<ol class="ltx_enumerate" id="A5.I1">
<li class="ltx_item" id="A5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A5.I1.i1.p1">
<p class="ltx_p" id="A5.I1.i1.p1.1">412 answers were generated using a Llama 7b <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib26" title="">2023</a>)</cite> finetuned on a Grounded QA answering task.</p>
</div>
</li>
<li class="ltx_item" id="A5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A5.I1.i2.p1">
<p class="ltx_p" id="A5.I1.i2.p1.1">333 answers were generated using a Bloom 1b1 <cite class="ltx_cite ltx_citemacro_cite">Workshop et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib29" title="">2023</a>)</cite> finetuned on a Grounded QA answering task.</p>
</div>
</li>
<li class="ltx_item" id="A5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A5.I1.i3.p1">
<p class="ltx_p" id="A5.I1.i3.p1.1">319 answers were generated using a Llama 13b <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib26" title="">2023</a>)</cite> finetuned on a Grounded QA answering task.</p>
</div>
</li>
<li class="ltx_item" id="A5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A5.I1.i4.p1">
<p class="ltx_p" id="A5.I1.i4.p1.1">136 answers were generated using a OpenHermes 2.5 Mistral-7B<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B" title="">https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B</a></span></span></span>.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Training and inference hyperparameters</h2>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.2">The finetuning of the language model was conducted using the Meta-Llama-3-8B base model, employing an 8-bit quantization scheme to optimize memory efficiency. The model was trained to accommodate a sequence length of 7104 tokens, with sample packing enabled to maximize the utilization of input data. We utilized the LoRA (Low-Rank Adaptation) <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib8" title="">2022</a>)</cite> technique using an adapter with parameters set to <math alttext="r=32" class="ltx_Math" display="inline" id="A6.p1.1.m1.1"><semantics id="A6.p1.1.m1.1a"><mrow id="A6.p1.1.m1.1.1" xref="A6.p1.1.m1.1.1.cmml"><mi id="A6.p1.1.m1.1.1.2" xref="A6.p1.1.m1.1.1.2.cmml">r</mi><mo id="A6.p1.1.m1.1.1.1" xref="A6.p1.1.m1.1.1.1.cmml">=</mo><mn id="A6.p1.1.m1.1.1.3" xref="A6.p1.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p1.1.m1.1b"><apply id="A6.p1.1.m1.1.1.cmml" xref="A6.p1.1.m1.1.1"><eq id="A6.p1.1.m1.1.1.1.cmml" xref="A6.p1.1.m1.1.1.1"></eq><ci id="A6.p1.1.m1.1.1.2.cmml" xref="A6.p1.1.m1.1.1.2">𝑟</ci><cn id="A6.p1.1.m1.1.1.3.cmml" type="integer" xref="A6.p1.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.1.m1.1c">r=32</annotation><annotation encoding="application/x-llamapun" id="A6.p1.1.m1.1d">italic_r = 32</annotation></semantics></math>, <math alttext="\alpha=16" class="ltx_Math" display="inline" id="A6.p1.2.m2.1"><semantics id="A6.p1.2.m2.1a"><mrow id="A6.p1.2.m2.1.1" xref="A6.p1.2.m2.1.1.cmml"><mi id="A6.p1.2.m2.1.1.2" xref="A6.p1.2.m2.1.1.2.cmml">α</mi><mo id="A6.p1.2.m2.1.1.1" xref="A6.p1.2.m2.1.1.1.cmml">=</mo><mn id="A6.p1.2.m2.1.1.3" xref="A6.p1.2.m2.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p1.2.m2.1b"><apply id="A6.p1.2.m2.1.1.cmml" xref="A6.p1.2.m2.1.1"><eq id="A6.p1.2.m2.1.1.1.cmml" xref="A6.p1.2.m2.1.1.1"></eq><ci id="A6.p1.2.m2.1.1.2.cmml" xref="A6.p1.2.m2.1.1.2">𝛼</ci><cn id="A6.p1.2.m2.1.1.3.cmml" type="integer" xref="A6.p1.2.m2.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.2.m2.1c">\alpha=16</annotation><annotation encoding="application/x-llamapun" id="A6.p1.2.m2.1d">italic_α = 16</annotation></semantics></math>, and a dropout rate of 0.05.</p>
</div>
<div class="ltx_para" id="A6.p2">
<p class="ltx_p" id="A6.p2.3">Training was performed with a batch size of 64 over the course of three epochs, which took 2 hours on one A100 PCIe with 80GB of VRAM. The optimization process employed the AdamW <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#bib.bib15" title="">2019</a>)</cite> algorithm with an 8-bit implementation. A cosine learning rate scheduler was used, with a learning rate of <math alttext="2.10^{-4}" class="ltx_Math" display="inline" id="A6.p2.1.m1.1"><semantics id="A6.p2.1.m1.1a"><msup id="A6.p2.1.m1.1.1" xref="A6.p2.1.m1.1.1.cmml"><mn id="A6.p2.1.m1.1.1.2" xref="A6.p2.1.m1.1.1.2.cmml">2.10</mn><mrow id="A6.p2.1.m1.1.1.3" xref="A6.p2.1.m1.1.1.3.cmml"><mo id="A6.p2.1.m1.1.1.3a" xref="A6.p2.1.m1.1.1.3.cmml">−</mo><mn id="A6.p2.1.m1.1.1.3.2" xref="A6.p2.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A6.p2.1.m1.1b"><apply id="A6.p2.1.m1.1.1.cmml" xref="A6.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A6.p2.1.m1.1.1.1.cmml" xref="A6.p2.1.m1.1.1">superscript</csymbol><cn id="A6.p2.1.m1.1.1.2.cmml" type="float" xref="A6.p2.1.m1.1.1.2">2.10</cn><apply id="A6.p2.1.m1.1.1.3.cmml" xref="A6.p2.1.m1.1.1.3"><minus id="A6.p2.1.m1.1.1.3.1.cmml" xref="A6.p2.1.m1.1.1.3"></minus><cn id="A6.p2.1.m1.1.1.3.2.cmml" type="integer" xref="A6.p2.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.1.m1.1c">2.10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A6.p2.1.m1.1d">2.10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> and 10 warmup steps. Two other trainings were conducted with learning rates <math alttext="2.10^{-3}" class="ltx_Math" display="inline" id="A6.p2.2.m2.1"><semantics id="A6.p2.2.m2.1a"><msup id="A6.p2.2.m2.1.1" xref="A6.p2.2.m2.1.1.cmml"><mn id="A6.p2.2.m2.1.1.2" xref="A6.p2.2.m2.1.1.2.cmml">2.10</mn><mrow id="A6.p2.2.m2.1.1.3" xref="A6.p2.2.m2.1.1.3.cmml"><mo id="A6.p2.2.m2.1.1.3a" xref="A6.p2.2.m2.1.1.3.cmml">−</mo><mn id="A6.p2.2.m2.1.1.3.2" xref="A6.p2.2.m2.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A6.p2.2.m2.1b"><apply id="A6.p2.2.m2.1.1.cmml" xref="A6.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A6.p2.2.m2.1.1.1.cmml" xref="A6.p2.2.m2.1.1">superscript</csymbol><cn id="A6.p2.2.m2.1.1.2.cmml" type="float" xref="A6.p2.2.m2.1.1.2">2.10</cn><apply id="A6.p2.2.m2.1.1.3.cmml" xref="A6.p2.2.m2.1.1.3"><minus id="A6.p2.2.m2.1.1.3.1.cmml" xref="A6.p2.2.m2.1.1.3"></minus><cn id="A6.p2.2.m2.1.1.3.2.cmml" type="integer" xref="A6.p2.2.m2.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.2.m2.1c">2.10^{-3}</annotation><annotation encoding="application/x-llamapun" id="A6.p2.2.m2.1d">2.10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="2.10^{-5}" class="ltx_Math" display="inline" id="A6.p2.3.m3.1"><semantics id="A6.p2.3.m3.1a"><msup id="A6.p2.3.m3.1.1" xref="A6.p2.3.m3.1.1.cmml"><mn id="A6.p2.3.m3.1.1.2" xref="A6.p2.3.m3.1.1.2.cmml">2.10</mn><mrow id="A6.p2.3.m3.1.1.3" xref="A6.p2.3.m3.1.1.3.cmml"><mo id="A6.p2.3.m3.1.1.3a" xref="A6.p2.3.m3.1.1.3.cmml">−</mo><mn id="A6.p2.3.m3.1.1.3.2" xref="A6.p2.3.m3.1.1.3.2.cmml">5</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A6.p2.3.m3.1b"><apply id="A6.p2.3.m3.1.1.cmml" xref="A6.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A6.p2.3.m3.1.1.1.cmml" xref="A6.p2.3.m3.1.1">superscript</csymbol><cn id="A6.p2.3.m3.1.1.2.cmml" type="float" xref="A6.p2.3.m3.1.1.2">2.10</cn><apply id="A6.p2.3.m3.1.1.3.cmml" xref="A6.p2.3.m3.1.1.3"><minus id="A6.p2.3.m3.1.1.3.1.cmml" xref="A6.p2.3.m3.1.1.3"></minus><cn id="A6.p2.3.m3.1.1.3.2.cmml" type="integer" xref="A6.p2.3.m3.1.1.3.2">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.3.m3.1c">2.10^{-5}</annotation><annotation encoding="application/x-llamapun" id="A6.p2.3.m3.1d">2.10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>, but the results on GroUSE and alignment measures were less promising.</p>
</div>
<div class="ltx_para" id="A6.p3">
<p class="ltx_p" id="A6.p3.1">The inferences of the trained model were then conducted using greedy decoding.</p>
</div>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Finetuning results</h2>
<div class="ltx_para" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.F12" title="Figure 12 ‣ Impact of training dataset imbalance. ‣ Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">12</span></a> shows a detailed comparison of the results between the Llama-3 8b before and after finetuning.</p>
</div>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Ablation: balancing the training dataset to reduce judgement biases</h2>
<section class="ltx_paragraph" id="A8.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Dataset balance.</h4>
<div class="ltx_para" id="A8.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A8.SS0.SSS0.Px1.p1.1">To ensure the dataset encompassed a wide range of answer qualities, we utilized a diverse set of models to generate answers to the grounded QA statements. However, upon evaluating these answers, we observed certain GPT-4 biases in the distribution of marks: notably, a scarcity of score 2 for <span class="ltx_text ltx_font_bold" id="A8.SS0.SSS0.Px1.p1.1.1">Answer Relevancy</span>, and an overabundance of scores 1 and 5 for <span class="ltx_text ltx_font_bold" id="A8.SS0.SSS0.Px1.p1.1.2">Completeness</span>, as illustrated in the first row of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.F11" title="Figure 11 ‣ Impact of training dataset imbalance. ‣ Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">11</span></a>. To avoid propagating these biases in the finetuned model, we kept on predicting answers until the dataset seemed balanced enough, trying to select models with intermediate performances to produce answers of average quality and fill the gaps. The final balanced dataset was built choosing the 1400 answers which best harmonized the metrics among 4k evaluated grounded QA answers, resulting in the distribution shown in the second row of Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.F11" title="Figure 11 ‣ Impact of training dataset imbalance. ‣ Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A8.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Impact of training dataset imbalance.</h4>
<div class="ltx_para" id="A8.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p1.1">To assess the impact of dataset debiasing, we trained a model on the balanced dataset: this model will hereafter be referred to as the <span class="ltx_text ltx_font_italic" id="A8.SS0.SSS0.Px2.p1.1.1">balanced model</span>, as opposed to the model trained on the naive dataset, named the <span class="ltx_text ltx_font_italic" id="A8.SS0.SSS0.Px2.p1.1.2">unbalanced model</span>.</p>
</div>
<div class="ltx_para" id="A8.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p2.4">The evaluations of the balanced model closely mirror those of the unbalanced model. The grades of both models on the test set have an exact match of <math alttext="58\%" class="ltx_Math" display="inline" id="A8.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="A8.SS0.SSS0.Px2.p2.1.m1.1a"><mrow id="A8.SS0.SSS0.Px2.p2.1.m1.1.1" xref="A8.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mn id="A8.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="A8.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">58</mn><mo id="A8.SS0.SSS0.Px2.p2.1.m1.1.1.1" xref="A8.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A8.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="A8.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="latexml" id="A8.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.1.m1.1.1.1">percent</csymbol><cn id="A8.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" type="integer" xref="A8.SS0.SSS0.Px2.p2.1.m1.1.1.2">58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS0.SSS0.Px2.p2.1.m1.1c">58\%</annotation><annotation encoding="application/x-llamapun" id="A8.SS0.SSS0.Px2.p2.1.m1.1d">58 %</annotation></semantics></math> for <span class="ltx_text ltx_font_bold" id="A8.SS0.SSS0.Px2.p2.4.1">Answer relevancy</span> and <math alttext="63\%" class="ltx_Math" display="inline" id="A8.SS0.SSS0.Px2.p2.2.m2.1"><semantics id="A8.SS0.SSS0.Px2.p2.2.m2.1a"><mrow id="A8.SS0.SSS0.Px2.p2.2.m2.1.1" xref="A8.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mn id="A8.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="A8.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">63</mn><mo id="A8.SS0.SSS0.Px2.p2.2.m2.1.1.1" xref="A8.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A8.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="A8.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="latexml" id="A8.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.2.m2.1.1.1">percent</csymbol><cn id="A8.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" type="integer" xref="A8.SS0.SSS0.Px2.p2.2.m2.1.1.2">63</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS0.SSS0.Px2.p2.2.m2.1c">63\%</annotation><annotation encoding="application/x-llamapun" id="A8.SS0.SSS0.Px2.p2.2.m2.1d">63 %</annotation></semantics></math> for <span class="ltx_text ltx_font_bold" id="A8.SS0.SSS0.Px2.p2.4.2">Completeness</span>. Additionally, the Spearman correlation between the models for these metrics are <math alttext="76\%" class="ltx_Math" display="inline" id="A8.SS0.SSS0.Px2.p2.3.m3.1"><semantics id="A8.SS0.SSS0.Px2.p2.3.m3.1a"><mrow id="A8.SS0.SSS0.Px2.p2.3.m3.1.1" xref="A8.SS0.SSS0.Px2.p2.3.m3.1.1.cmml"><mn id="A8.SS0.SSS0.Px2.p2.3.m3.1.1.2" xref="A8.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml">76</mn><mo id="A8.SS0.SSS0.Px2.p2.3.m3.1.1.1" xref="A8.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A8.SS0.SSS0.Px2.p2.3.m3.1b"><apply id="A8.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="latexml" id="A8.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.3.m3.1.1.1">percent</csymbol><cn id="A8.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml" type="integer" xref="A8.SS0.SSS0.Px2.p2.3.m3.1.1.2">76</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS0.SSS0.Px2.p2.3.m3.1c">76\%</annotation><annotation encoding="application/x-llamapun" id="A8.SS0.SSS0.Px2.p2.3.m3.1d">76 %</annotation></semantics></math> and <math alttext="82\%" class="ltx_Math" display="inline" id="A8.SS0.SSS0.Px2.p2.4.m4.1"><semantics id="A8.SS0.SSS0.Px2.p2.4.m4.1a"><mrow id="A8.SS0.SSS0.Px2.p2.4.m4.1.1" xref="A8.SS0.SSS0.Px2.p2.4.m4.1.1.cmml"><mn id="A8.SS0.SSS0.Px2.p2.4.m4.1.1.2" xref="A8.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml">82</mn><mo id="A8.SS0.SSS0.Px2.p2.4.m4.1.1.1" xref="A8.SS0.SSS0.Px2.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A8.SS0.SSS0.Px2.p2.4.m4.1b"><apply id="A8.SS0.SSS0.Px2.p2.4.m4.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.4.m4.1.1"><csymbol cd="latexml" id="A8.SS0.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p2.4.m4.1.1.1">percent</csymbol><cn id="A8.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml" type="integer" xref="A8.SS0.SSS0.Px2.p2.4.m4.1.1.2">82</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS0.SSS0.Px2.p2.4.m4.1c">82\%</annotation><annotation encoding="application/x-llamapun" id="A8.SS0.SSS0.Px2.p2.4.m4.1d">82 %</annotation></semantics></math>, respectively. The results on GroUSE and measured alignments are also close, with the unbalanced model showing a slightly higher correlation with GPT-4, while the balanced model performed marginally better on unit tests. Qualitative analysis of the balanced model’s predicted marks reveals a persistent lack of intermediate scores. Overall, the debiasing process did not yield the anticipated improvements.</p>
</div>
<figure class="ltx_figure" id="A8.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="824" id="A8.F11.g1" src="x11.png" width="831"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Comparison of the first and last dataset obtained during the iterative process of debiasing.</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F12"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="514" id="A8.F12.g1" src="x12.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Comparison of unit tests results before and after finetuning of the Llama 3 8b model. Each matrix represents the performance of one model on a specific metric. Orange squares represent instances where the model’s output did not adhere to the expected format, preventing score retrieval. Hatched squares denote LLM calls that the pipeline would skip if previous calls had returned the expected value (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F4" title="Figure 4 ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a>). 
<br class="ltx_break"/>Note that in this situation the four metrics were evaluated in a single prompt by the models, which explains the difference of results between the non finetuned Llama-3 8b depicted here and the Llama-3 8b results depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#A8.F14" title="Figure 14 ‣ Impact of training dataset imbalance. ‣ Appendix H Ablation: balancing the training dataset to reduce judgement biases ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">14</span></a>.</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F13"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="994" id="A8.F13.g1" src="x13.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Detailed unit tests results for closed-source models. Each matrix represents the performance of one model on a specific metric. Orange squares represent instances where the model’s output did not adhere to the expected format, preventing score retrieval. Hatched squares denote LLM calls that the pipeline would skip if previous calls had returned the expected value (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F4" title="Figure 4 ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a>).</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F14"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="1145" id="A8.F14.g1" src="x14.png" width="789"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Detailed unit tests results for open-source models. Each matrix represents the performance of one model on a specific metric. Orange squares represent instances where the model’s output did not adhere to the expected format, preventing score retrieval. Hatched squares denote LLM calls that the pipeline would skip if previous calls had returned the expected value (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.06595v1#S4.F4" title="Figure 4 ‣ 4.4 Enhancing existing frameworks ‣ 4 Rethinking Grounded QA Evaluation ‣ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a>).</figcaption>
</figure>
<figure class="ltx_table" id="A8.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A8.T7.1">
<tr class="ltx_tr" id="A8.T7.1.1">
<td class="ltx_td ltx_border_tt" id="A8.T7.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="6" id="A8.T7.1.1.2"><span class="ltx_text ltx_font_bold" id="A8.T7.1.1.2.1">Agreement rate of metrics</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="A8.T7.1.1.3" rowspan="2"><span class="ltx_text" id="A8.T7.1.1.3.1"><span class="ltx_text" id="A8.T7.1.1.3.1.1"></span> <span class="ltx_text" id="A8.T7.1.1.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.1.3.1.2.1">
<span class="ltx_tr" id="A8.T7.1.1.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.1.3.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A8.T7.1.1.3.1.2.1.1.1.1">Total</span></span></span>
<span class="ltx_tr" id="A8.T7.1.1.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.1.3.1.2.1.2.1">test pass</span></span>
<span class="ltx_tr" id="A8.T7.1.1.3.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.1.3.1.2.1.3.1">rate</span></span>
</span></span> <span class="ltx_text" id="A8.T7.1.1.3.1.3"></span></span></td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.2">
<td class="ltx_td" id="A8.T7.1.2.1"></td>
<td class="ltx_td ltx_align_center" id="A8.T7.1.2.2">
<span class="ltx_text" id="A8.T7.1.2.2.1"></span> <span class="ltx_text" id="A8.T7.1.2.2.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.2.2.2.1">
<span class="ltx_tr" id="A8.T7.1.2.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.2.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.2.2.1.1.1.1">Answer relevancy</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.2.2.3"></span></td>
<td class="ltx_td ltx_align_center" id="A8.T7.1.2.3">
<span class="ltx_text" id="A8.T7.1.2.3.1"></span> <span class="ltx_text" id="A8.T7.1.2.3.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.2.3.2.1">
<span class="ltx_tr" id="A8.T7.1.2.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.3.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.3.2.1.1.1.1">Completeness</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.2.3.3"></span></td>
<td class="ltx_td ltx_align_center" id="A8.T7.1.2.4">
<span class="ltx_text" id="A8.T7.1.2.4.1"></span> <span class="ltx_text" id="A8.T7.1.2.4.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.2.4.2.1">
<span class="ltx_tr" id="A8.T7.1.2.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.4.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.4.2.1.1.1.1">Usefulness</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.2.4.3"></span></td>
<td class="ltx_td ltx_align_center" id="A8.T7.1.2.5">
<span class="ltx_text" id="A8.T7.1.2.5.1"></span> <span class="ltx_text" id="A8.T7.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.2.5.2.1">
<span class="ltx_tr" id="A8.T7.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.5.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.5.2.1.1.1.1">Faithfulness</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.2.5.3"></span></td>
<td class="ltx_td ltx_align_center" id="A8.T7.1.2.6">
<span class="ltx_text" id="A8.T7.1.2.6.1"></span> <span class="ltx_text" id="A8.T7.1.2.6.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.2.6.2.1">
<span class="ltx_tr" id="A8.T7.1.2.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.6.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.6.2.1.1.1.1">Positive</span></span></span>
<span class="ltx_tr" id="A8.T7.1.2.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.6.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.6.2.1.2.1.1">acceptance</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.2.6.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A8.T7.1.2.7">
<span class="ltx_text" id="A8.T7.1.2.7.1"></span> <span class="ltx_text" id="A8.T7.1.2.7.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.2.7.2.1">
<span class="ltx_tr" id="A8.T7.1.2.7.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.7.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.7.2.1.1.1.1">Negative</span></span></span>
<span class="ltx_tr" id="A8.T7.1.2.7.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.2.7.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.2.7.2.1.2.1.1">rejection</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.2.7.3"></span></td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A8.T7.1.3.1">
<span class="ltx_text" id="A8.T7.1.3.1.1"></span> <span class="ltx_text" id="A8.T7.1.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.3.1.2.1">
<span class="ltx_tr" id="A8.T7.1.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.3.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A8.T7.1.3.1.2.1.1.1.1">Finetuned Llama 3 8b</span></span></span>
<span class="ltx_tr" id="A8.T7.1.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.3.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.3.1.2.1.2.1.1">(Unbalanced dataset)</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.3.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.3.2"><span class="ltx_text ltx_font_bold" id="A8.T7.1.3.2.1">88.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.3.3">81.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.3.4">81.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.3.5">52.78</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.3.6">91.67</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A8.T7.1.3.7"><span class="ltx_text ltx_font_bold" id="A8.T7.1.3.7.1">91.67</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A8.T7.1.3.8">81.37</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A8.T7.1.4.1">
<span class="ltx_text" id="A8.T7.1.4.1.1"></span> <span class="ltx_text" id="A8.T7.1.4.1.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T7.1.4.1.2.1">
<span class="ltx_tr" id="A8.T7.1.4.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.4.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A8.T7.1.4.1.2.1.1.1.1">Finetuned Llama 3 8b</span></span></span>
<span class="ltx_tr" id="A8.T7.1.4.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T7.1.4.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T7.1.4.1.2.1.2.1.1">(Balanced dataset)</span></span></span>
</span></span><span class="ltx_text" id="A8.T7.1.4.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.1.4.2">87.50</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.1.4.3"><span class="ltx_text ltx_font_bold" id="A8.T7.1.4.3.1">83.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.1.4.4"><span class="ltx_text ltx_font_bold" id="A8.T7.1.4.4.1">81.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.1.4.5"><span class="ltx_text ltx_font_bold" id="A8.T7.1.4.5.1">61.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.1.4.6">90.97</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A8.T7.1.4.7"><span class="ltx_text ltx_font_bold" id="A8.T7.1.4.7.1">92.36</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="A8.T7.1.4.8"><span class="ltx_text ltx_font_bold" id="A8.T7.1.4.8.1">82.99</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Percentage of tests passed for balanced and unbalanced model. The highest score in each column is highlighted in bold.</figcaption>
</figure>
<figure class="ltx_table" id="A8.T8">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A8.T8.1">
<tr class="ltx_tr" id="A8.T8.1.1">
<td class="ltx_td ltx_border_tt" id="A8.T8.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="A8.T8.1.1.2"><span class="ltx_text ltx_font_bold" id="A8.T8.1.1.2.1">Spearman correlation</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A8.T8.1.1.3"><span class="ltx_text ltx_font_bold" id="A8.T8.1.1.3.1">F1-score</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.2">
<td class="ltx_td" id="A8.T8.1.2.1"></td>
<td class="ltx_td ltx_align_center" id="A8.T8.1.2.2">
<span class="ltx_text" id="A8.T8.1.2.2.1"></span> <span class="ltx_text" id="A8.T8.1.2.2.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T8.1.2.2.2.1">
<span class="ltx_tr" id="A8.T8.1.2.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.2.2.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.2.2.1.1.1.1">Answer relevancy</span></span></span>
</span></span><span class="ltx_text" id="A8.T8.1.2.2.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A8.T8.1.2.3"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.3.1">Completeness</span></td>
<td class="ltx_td ltx_align_center" id="A8.T8.1.2.4">
<span class="ltx_text" id="A8.T8.1.2.4.1"></span> <span class="ltx_text" id="A8.T8.1.2.4.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T8.1.2.4.2.1">
<span class="ltx_tr" id="A8.T8.1.2.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.2.4.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.4.2.1.1.1.1">Usefulness</span></span></span>
</span></span><span class="ltx_text" id="A8.T8.1.2.4.3"></span></td>
<td class="ltx_td ltx_align_center" id="A8.T8.1.2.5">
<span class="ltx_text" id="A8.T8.1.2.5.1"></span> <span class="ltx_text" id="A8.T8.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T8.1.2.5.2.1">
<span class="ltx_tr" id="A8.T8.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.2.5.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.5.2.1.1.1.1">Faithfulness</span></span></span>
</span></span><span class="ltx_text" id="A8.T8.1.2.5.3"></span></td>
<td class="ltx_td ltx_align_center" id="A8.T8.1.2.6">
<span class="ltx_text" id="A8.T8.1.2.6.1"></span> <span class="ltx_text" id="A8.T8.1.2.6.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T8.1.2.6.2.1">
<span class="ltx_tr" id="A8.T8.1.2.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.2.6.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.6.2.1.1.1.1">Positive</span></span></span>
<span class="ltx_tr" id="A8.T8.1.2.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.2.6.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.6.2.1.2.1.1">acceptance</span></span></span>
</span></span><span class="ltx_text" id="A8.T8.1.2.6.3"></span></td>
<td class="ltx_td ltx_align_center" id="A8.T8.1.2.7">
<span class="ltx_text" id="A8.T8.1.2.7.1"></span> <span class="ltx_text" id="A8.T8.1.2.7.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T8.1.2.7.2.1">
<span class="ltx_tr" id="A8.T8.1.2.7.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.2.7.2.1.1.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.7.2.1.1.1.1">Negative</span></span></span>
<span class="ltx_tr" id="A8.T8.1.2.7.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.2.7.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.2.7.2.1.2.1.1">rejection</span></span></span>
</span></span><span class="ltx_text" id="A8.T8.1.2.7.3"></span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A8.T8.1.3.1">
<span class="ltx_text" id="A8.T8.1.3.1.1"></span> <span class="ltx_text" id="A8.T8.1.3.1.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T8.1.3.1.2.1">
<span class="ltx_tr" id="A8.T8.1.3.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.3.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A8.T8.1.3.1.2.1.1.1.1">Finetuned Llama-3 8b</span></span></span>
<span class="ltx_tr" id="A8.T8.1.3.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.3.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.3.1.2.1.2.1.1">(Unbalanced dataset)</span></span></span>
</span></span><span class="ltx_text" id="A8.T8.1.3.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.3.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.3.2.1">0.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.3.3">0.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.3.4">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.3.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.3.5.1">0.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.3.6">0.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.3.7">0.73</td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A8.T8.1.4.1">
<span class="ltx_text" id="A8.T8.1.4.1.1"></span> <span class="ltx_text" id="A8.T8.1.4.1.2">
<span class="ltx_tabular ltx_align_middle" id="A8.T8.1.4.1.2.1">
<span class="ltx_tr" id="A8.T8.1.4.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.4.1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A8.T8.1.4.1.2.1.1.1.1">Finetuned Llama-3 8b</span></span></span>
<span class="ltx_tr" id="A8.T8.1.4.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A8.T8.1.4.1.2.1.2.1"><span class="ltx_text ltx_font_italic" id="A8.T8.1.4.1.2.1.2.1.1">(Balanced dataset)</span></span></span>
</span></span><span class="ltx_text" id="A8.T8.1.4.1.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.1.4.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.4.2.1">0.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.1.4.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.4.3.1">0.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.1.4.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.4.4.1">0.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.1.4.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.4.5.1">0.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.1.4.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.4.6.1">0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.1.4.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="A8.T8.1.4.7.1">0.74</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Alignment with the ground truth (GPT-4) evaluations on the test set.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 10 15:24:44 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
