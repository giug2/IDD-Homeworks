<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.16340] Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.16340">

<!--Generated on Sun Oct  6 00:59:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nikolas Koutsoubis
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Machine Learning, Moffitt Cancer Center, Tampa, FL
</span>
<span class="ltx_contact ltx_role_affiliation">Electrical Engineering Department, University of South Florida, FL
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Asim Waqas
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Cancer Epidemiology, Moffitt Cancer Center, Tampa, FL
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yasin Yilmaz
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Electrical Engineering Department, University of South Florida, FL
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ravi P. Ramachandran
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Electrical &amp; Computer Engineering Department, Rowan University, NJ
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Matthew Schabath
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Cancer Epidemiology, Moffitt Cancer Center, Tampa, FL
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ghulam Rasool
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Machine Learning, Moffitt Cancer Center, Tampa, FL
</span>
<span class="ltx_contact ltx_role_affiliation">Electrical Engineering Department, University of South Florida, FL
</span></span></span>
</div>

<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Abstract</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Artificial Intelligence (AI) has demonstrated significant potential in automating various medical imaging tasks, which could soon become routine in clinical practice for disease diagnosis, prognosis, treatment planning, and post-treatment surveillance. However, the privacy concerns surrounding patient data present a major barrier to the widespread adoption of AI in medical imaging, as large, diverse training datasets are essential for developing accurate, generalizable, and robust Artificial intelligence models. Federated Learning (FL) offers a solution that enables organizations to train AI models collaboratively without sharing sensitive data. federated learning exchanges model training information, such as gradients, between the participating sites. Despite its promise, federated learning is still in its developmental stages and faces several challenges. Notably, sensitive information can still be inferred from the gradients shared during model training. Quantifying AI models’ uncertainty is vital due to potential data distribution shifts post-deployment, which can affect model performance. Uncertainty quantification (UQ) in FL is particularly challenging due to data heterogeneity across participating sites. This review provides a comprehensive examination of FL, privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL methodologies and propose future research directions to enhance data privacy and trustworthiness in medical imaging applications.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Keywords</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">Federated Learning, Medical Imaging, Privacy Preservation, Uncertainty Estimation</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The recent wave of artificial intelligence (AI) enabled by deep neural networks and the availability of large datasets and computational resources is transforming our society, and medical imaging is no exception. AI models trained on radiological data, such as mammograms, CT scans, and MRIs, are poised to become invaluable tools in both clinical and research settings <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">1</span></a></sup>, <sup class="ltx_sup"><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2</span></a></sup>, <sup class="ltx_sup"><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">3</span></a></sup></cite>. Nevertheless, a significant challenge remains — curating large, annotated, domain-specific datasets, which is hindered by privacy regulations and other factors. In contrast to conventional AI model development methods, which require pooling data at a single location, federated learning (FL) enables decentralized model development without data sharing <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">4</span></a></sup>, <sup class="ltx_sup"><a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">5</span></a></sup></cite>. FL allows large-scale model training by sharing gradient updates between sites rather than the training data. This permits multiple sites to act as clients and train a global model on the server, which is later shared with every site.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL can potentially solve many challenges related to data sharing for AI model training in medical imaging <cite class="ltx_cite ltx_citemacro_cite"><sup id="S1.p2.1.1.1" class="ltx_sup"><a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">6</span></a></sup></cite>. However, FL has its own unique challenges. First, data heterogeneity across different sites often violates the independent and identically distributed (IID) assumption, leading to challenges such as poor model convergence, biased outcomes, and reduced generalization. These non-IID issues can stem from variations in imaging protocols, patient demographics, and disease prevalence across sites. Second, some studies have shown that private data can be extracted from the gradient updates communicated between FL sites <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">7</span></a></sup></cite>. Methods such as differential privacy (DP) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">8</span></a></sup></cite> and homomorphic encryption (HE) <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">9</span></a></sup></cite> have been proposed to improve communications security; however, there may be an inherent trade-off between privacy preservation and model performance <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">10</span></a></sup></cite>. The third challenge is uncertainty quantification (UQ), which is the process of quantifying the AI’s confidence in its predictions <cite class="ltx_cite ltx_citemacro_cite"><sup id="S1.p2.1.2.1" class="ltx_sup"><a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">11</span></a></sup></cite>. This is important for the trustworthiness and reliability of AI for deployment in clinical settings <cite class="ltx_cite ltx_citemacro_cite"><sup id="S1.p2.1.3.1" class="ltx_sup"><a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">11</span></a></sup></cite>. Virtually all AI models based on deep neural networks require output calibration for accurate UQ <cite class="ltx_cite ltx_citemacro_cite"><sup id="S1.p2.1.4.1" class="ltx_sup"><a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">12</span></a></sup></cite>. The likelihood of non-IID data and the possibility of class imbalance in datasets at client sites require modifications to traditional UQ methods to work for FL models <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">13</span></a></sup></cite>. FL, with strong privacy preservation and UQ, has the potential to revolutionize medical imaging by developing generalizable, robust, and trustworthy AI models using large-scale multi-institutional datasets.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">This work reviews state-of-the-art FL, privacy-preserving FL (PPFL), and UQ methods in FL and outlines how these advancements will enable transformation in medical imaging. We present an overview of FL, PPFL, UQ, and a summary of the topics covered in this review in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The primary contributions of this work include:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">A review of the current state-of-the-art (last 5 years) FL methods for learning from distributed data, simultaneously dealing with non-IID datasets, privacy-preservation requirements, and the challenges of UQ.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Exploration of two real-world use cases of FL in medical imaging and what can be learned from the success stories. We also present current challenges in FL, PPFL, and UQ related to medical imaging and potential opportunities for future research.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The paper is organized as follows: Sections <a href="#S2" title="2 Federated Learning (FL) ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, <a href="#S3" title="3 Privacy-Preserving FL (PPFL) ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, and <a href="#S4" title="4 Uncertainty Quantification (UQ) in FL ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> review FL, PPFL, and UQ in FL, respectively. Section <a href="#S5" title="5 FL in the Medical Imaging World ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> covers the real-world applications of FL in medical imaging and summarizes the current challenges and opportunities. A GitHub repository with links to papers reviewed in this work is provided here: <a target="_blank" href="https://github.com/Niko-k98/Awesome-list-Federated-Learning-Review/tree/main" title="" class="ltx_ref ltx_href" style="color:#0000FF;">Awesome List</a>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.16340/assets/radai-figs/Fig1-2.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of federated learning (FL), PPFL, and UQ is presented. Combining FL with strong privacy-preservation and Uncertainty quantification methods can help the medical imaging community develop large-scale multi-institutional AI models that are truly generalizable, robust, and trustworthy.]</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2409.16340/assets/radai-figs/Fig2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="222" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of FL algorithm types is presented. (A) In centralized federated learning, sites train a local model and pass the learned information to a central server to generate the global model, the global model is then passed to the local sites for further training. (B) Decentralized FL removes the need for a central server allowing for direct communication between sites. (C) Personalized FL leverages a central server while making a specific model for each site. Having a personalized model at each site is ideal in FL deployments with high data heterogeneity.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Federated Learning (FL)</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FL was originally proposed to train AI models on edge devices without exposing private data <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">14</span></a></sup></cite>. This led to a paradigm shift in how machine learning (ML) models could be trained on sensitive and private data in distributed settings. The original FL algorithm, FedAvg, trains local models on client data and sends gradient information to a central server to create a global model that, in theory, can outperform all local models <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">14</span></a></sup></cite>. In this section, we focus on FL algorithms and present state-of-the-art advancements. A summary of the topics covered in this section is shown in Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>FL Algorithms - Characterization and Types</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">FL can be categorized as centralized or decentralized, depending on whether a central server is utilized to aggregate updates and build the global model. Centralized FL is the more common approach, where a server orchestrates the learning process by collecting and combining client updates. In contrast, decentralized FL allows clients to communicate directly, which can be advantageous when a central server is impractical or undesirable due to privacy or connectivity constraints. Recently, personalized FL (PFL) has gained significant attention as a refinement of traditional centralized FL <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">15</span></a></sup></cite>. PFL addresses the inherent data heterogeneity among clients, such as variations in data distributions (non-IID data), computational resources, and specific local requirements. Instead of creating a single global model, PFL focuses on developing models tailored to individual clients while still leveraging shared knowledge across FL sites. PFL models are generally trained within a centralized FL framework. Given their unique approach to personalization and adaptation in heterogeneous environments, the PFL algorithms reviewed in this paper are presented in a separate section. Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:table:fl_algorithms</span> summarizes all FL algorithms reviewed in this work.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Centralized FL</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Centralized FL requires a dedicated central server for parameter aggregation and building the federated model. It is the most common form of FL implemented for various ML tasks. These algorithms offer technical advancements for (1) learning from the distributed, heterogeneous, and non-IID data using various methods, including knowledge distillation, (2) optimizing the learning for the global and local models to avoid catastrophic forgetting of the local model, and (3) stabilizing training across federated runs, locally as well as globally, to ensure convergence of model training. In the following, we provide a chronological list of centralized FL algorithms.</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">FedProx</span>: FedProx is a generalization of the original FedAvg algorithm <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">16</span></a></sup></cite>. The two distinguishing features of the FedProX include (1) allowing partial updates to be sent to the server instead of dropping them from a federated round and (2) adding a proximal term to prevent any client from contributing too much to the global model, thereby increasing model stability.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">FedBN</span>: FedBN leverages batch normalization (batch-norm) to reduce the effect of non-IID data <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">17</span></a></sup></cite>. FedBN follows a similar architecture to FedAvg, involving the transmission of local updates and their aggregation on a central server, but it treats the batch-norm parameters as site-specific and excludes them from the averaging process.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">FedGeN</span>: Knowledge distillation is an emerging approach in FL that addresses data heterogeneity by extracting and sharing knowledge from an ensemble of client models <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">18</span></a></sup></cite>. FedGeN employs a data-free method for knowledge distillation in FL and has demonstrated better accuracy and faster convergence in heterogeneous data settings, particularly in medical imaging tasks like multi-organ segmentation <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">18</span></a></sup></cite>.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">FOLA</span>: Local catastrophic forgetting is a significant challenge in FL, where local models lose specific knowledge of their data when updated with global model weights, similar to issues in continual learning <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">19</span></a></sup></cite>. To address this, the Federated Online Laplace Approximation (FOLA) algorithm combines Bayesian principles with an online approximation approach to estimate probabilistic parameters for both global and local models, reducing aggregation errors and mitigating local forgetting <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">20</span></a></sup></cite>.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Train-Convexify-Train</span>: Heterogeneous, specifically, non-convex data, where the relationship between variables does not form a convex shape in the feature space, could lead to local models with different optima, making it difficult for the global model to converge <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">21</span></a></sup></cite>. Train-Convexify-Train procedure tackles this by first using FedAvg to learn features and then refining the model, resulting in up to 37% accuracy improvement on heterogeneous data.</p>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.1" class="ltx_p"><span id="S2.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">FCCL</span>: Federated Cross-Correlation and Continual Learning (FCCL) addresses local forgetting by using unlabeled public data to construct a cross-correlation matrix on model logit outputs, promoting generalizable representations across non-IID data <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">22</span></a></sup></cite>. FCCL balances knowledge retention by employing knowledge distillation, where the global model helps retain inter-domain information, and the local model preserves intra-domain information, reducing the risk of catastrophic forgetting during local updates.</p>
</div>
</li>
<li id="S2.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i7.p1" class="ltx_para">
<p id="S2.I1.i7.p1.1" class="ltx_p"><span id="S2.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">FedFA</span>: FedFA was proposed to address the data heterogeneity challenge using feature anchors to align features and calibrate classifiers across clients simultaneously <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">23</span></a></sup></cite>. This enables local models to be updated in a shared feature space with consistent classifiers during local training. The FedFA algorithm encompasses a server-side component where both class feature anchors and the global model undergo aggregation.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Decentralized FL</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Decentralized FL implementations do not utilize a central server to coordinate learning <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">24</span></a></sup>, <sup class="ltx_sup"><a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">25</span></a></sup>, <sup class="ltx_sup"><a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">26</span></a></sup></cite>. Depending on the application, decentralized FL may provide enhanced privacy and security, increase robustness and fault tolerance by eliminating single points of failure. Decentralized FL improves scalability by distributing workloads across the network, making them superior to centralized FL. In the following, we present some recent decentralized FL algorithms.</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Swarm Learning</span>: It integrates edge computing with blockchain-based peer-to-peer networking, eliminating the need for a central server to coordinate learning <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">24</span></a></sup></cite>. This approach leverages decentralized hardware and distributed ML with blockchain to securely manage member onboarding, leader election, and model parameter merging. Sharing model parameters through a swarm network enables independent model training on private data at individual sites. Security and confidentiality are ensured through the blockchain’s restricted execution to pre-authorized clients and dynamic onboarding of new participants.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">ProxyFL</span>: ProxyFL enhances communication efficiency by using proxy models for information exchange, allowing clients to maintain private models that are never shared <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">25</span></a></sup></cite>. This approach supports model heterogeneity, enabling each client to have a unique model architecture while ensuring privacy through DP techniques. ProxyFL outperformed existing methods with reduced communication overhead and stronger privacy protections <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">25</span></a></sup></cite>.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Fog-FL</span>: Fog-FL enhances computing efficiency and reliability by utilizing a decentralized fog computing infrastructure that operates between the data source and the cloud, bringing compute, storage, and networking services closer to the network edge where data is generated <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">26</span></a></sup></cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Personalized FL (PFL) - Dealing With Client Data Heterogeneity</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">PFL focuses on developing tailored models for clients to address the challenges posed by data heterogeneity across sites while still exploiting learning from the clients in the FL network <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">15</span></a></sup></cite>.</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p"><span id="S2.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">FedAP</span>: FedAP identifies similarities between clients by analyzing the batch-norm layer statistics from a pre-trained model and uses these similarities to guide the aggregation process <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">15</span></a></sup></cite>. Each client retains its batch-norm layers to preserve personalized features, while the server aggregates model parameters based on client similarities to create unique models for each site. FedAP has demonstrated over 10% improvement in accuracy and faster convergence compared to state-of-the-art FL algorithms across diverse healthcare datasets <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">15</span></a></sup></cite>.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p"><span id="S2.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">pFedBayes</span>: Personalized FL via Bayesian inference (pFedBayes) integrates Bayesian variational inference and weight uncertainty to mitigate model overfitting and improve personalization by minimizing construction error on private data and its Kullback–Leibler divergence with the global distribution from the server <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">27</span></a></sup></cite>. This method allows each client to refine its local model by balancing the accuracy on its private data with alignment to the global distribution.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p"><span id="S2.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">FedPop</span>: FedPop addresses the challenges of FL, including their struggle with personalization in cross-silo and cross-device settings, especially for new clients or those with limited data and a lack of UQ <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">28</span></a></sup></cite>. FedPop integrates population modeling with fixed common parameters and random effects to explain data heterogeneity and introduces federated stochastic optimization algorithms based on Markov chain Monte Carlo. This results in increased robustness to client drift, better inference for new clients, and enables UQ with minimal computational overhead.</p>
</div>
</li>
<li id="S2.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i4.p1" class="ltx_para">
<p id="S2.I3.i4.p1.1" class="ltx_p"><span id="S2.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">Self-Aware PFL</span>: A key challenge in PFL is balancing the improvement of local models with global model tuning, especially when personal and global objectives differ. Inspired by Bayesian hierarchical models, self-aware PFL introduces a self-aware method that allows clients to automatically balance local and global training based on inter-client and intra-client UQ <cite class="ltx_cite ltx_citemacro_cite"><sup id="S2.I3.i4.p1.1.2.1" class="ltx_sup"><a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">29</span></a></sup></cite>. The method employs uncertainty-driven local training and aggregation, replacing conventional fine-tuning techniques.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Privacy-Preserving FL (PPFL)</h2>

<figure id="S3.F3" class="ltx_figure"><img src="/html/2409.16340/assets/radai-figs/Fig3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="229" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A summary of privacy-preserving FL (PPFL) methods is presented. (A) Differential Privacy (DP) works by adding artificial noise into other gradient information before it is communicated, this hinders the ability of an attacker to extract useful information. (B) Homomorphic Encryption (HE) allows for mathematical operations to be performed on encrypted cyphertexts, and then once decrypted the results are as if the math was performed on plaintext. HE is useful in situations where the central server can’t be trusted. (C) Various other methods of PPFL include hybrid approaches of DP and HE, knowledge transfer, loss differential strategies, and decentralized trust.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Ensuring secure processing of protected and identifiable information is paramount in the medical field, where federal regulations strictly prohibit sharing patient data to prevent privacy breaches. FL addresses this by keeping data localized at each site, but privacy risks still exist as gradient updates exchanged between clients and the server can inadvertently reveal information about training data, leading to privacy leaks <cite class="ltx_cite ltx_citemacro_cite"><sup id="S3.p1.1.1.1" class="ltx_sup"><a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">1</span></a></sup></cite>. In this section, we present several topics related to PPFL as depicted in Figure <a href="#S3.F3" title="Figure 3 ‣ 3 Privacy-Preserving FL (PPFL) ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Table <a href="#S6.T3" title="Table 3 ‣ 6 Conclusion ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Differential Privacy (DP)</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.3" class="ltx_p">DP is one of the most popular methods for PPFL and works by introducing noise into the gradients to prevent private information leakage <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">8</span></a></sup></cite>. DP provides mathematical guarantees of privacy preservation; however, these may come at the cost of model accuracy and convergence <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">10</span></a></sup></cite>. Noising before Aggregation FL (nbAFL) proposed by Wei <em id="S3.SS1.p1.3.1" class="ltx_emph ltx_font_italic">et al.</em> ensures DP by adding artificial noise to the model parameters on the client side before aggregation, reducing the risk of privacy breaches <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">30</span></a></sup></cite>. To optimize the trade-off between privacy and model performance, nbAFL employs a <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">K</annotation></semantics></math>-random scheduling technique, where <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">K</annotation></semantics></math> clients are randomly selected for each aggregation round, making it harder for attackers to extract useful information from the updates. The optimal value of <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">K</annotation></semantics></math> must be carefully determined to balance the level of privacy and the model’s convergence, a concept known as privacy budget allocation.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Homomorphic Encryption (HE) and Somewhat HE (SHE)</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">HE is a form of encryption that enables mathematical operations to be performed directly on encrypted data, producing encrypted results that, when decrypted, correspond to the results as if the operations were performed on the original plaintext data <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">31</span></a></sup>, <sup class="ltx_sup"><a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">32</span></a></sup></cite>. This allows data to be securely encrypted and shared with a third party for processing without the third party ever gaining access to the underlying plaintext data. SHE is a sub-type of HE that allows for a limited number of arithmetic operations and is generally more efficient <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">33</span></a></sup></cite>. An FL method based on SHE, Somewhat Homomorphically Encrypted FL (SHEFL), was used to train models for brain tumor segmentation from MRIs and predict biomarkers from histopathology slides in colorectal cancer <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">34</span></a></sup></cite>. The models trained with SHEFL are on par with regular FL while providing privacy guarantees, showing that encryption does not always negatively impact model accuracy <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">34</span></a></sup></cite>. These methods only encrypt the vulnerable areas of the FL with a less than <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">5</mn><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">5\%</annotation></semantics></math> increase in training time/ compute.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Other PPFL Methods</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In addition to DP and HE, many other methods have been proposed in conjunction with the aforementioned methods to preserve privacy in FL, as follows:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.2" class="ltx_p"><span id="S3.I1.i1.p1.2.1" class="ltx_text ltx_font_bold">Hybrid Approach</span>: Truex <span id="S3.I1.i1.p1.2.2" class="ltx_text ltx_font_italic">et al.</span> combined DP with Secure Multiparty Computation (SMC) to balance the trade-off between data privacy and model accuracy <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">35</span></a></sup></cite>. Their method mitigates the noise growth that typically increases with the number of parties in DP-based FL systems while maintaining a pre-defined level of trust. A tunable trust parameter, <math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><mi id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">t</annotation></semantics></math>, specifies the minimum number of honest, non-colluding parties required for the system to function securely. As <math id="S3.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.I1.i1.p1.2.m2.1a"><mi id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><ci id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">t</annotation></semantics></math> decreases, indicating less trust, more noise is added by each honest party to guard against potential colluders.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">PrivateKT</span>: PrivateKT leverages DP to implement private knowledge transfer using a small subset of public data selected based on their information content <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">36</span></a></sup></cite>. PrivateKT involves three steps: (i) <span id="S3.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">knowledge extraction</span>, where clients use private data to make predictions on selected public data; (ii) <span id="S3.I1.i2.p1.1.3" class="ltx_text ltx_font_italic">knowledge exchange</span>, where DP is applied to these predictions before sending them to the central server; and (iii) <span id="S3.I1.i2.p1.1.4" class="ltx_text ltx_font_italic">knowledge aggregation</span>, where the server aggregates these predictions into a knowledge buffer. PrivateKT also uses importance sampling to focus on data with higher uncertainty, enhancing knowledge quality and a knowledge buffer to store past aggregated predictions. PrivateKT reduced the performance gap with centralized learning by up to 84% under a strict privacy budget.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Multi-RoundSecAgg</span>: Traditional secure aggregation methods in FL focus on preserving privacy in a single training round <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">37</span></a></sup></cite>. However, this can lead to significant privacy leaks over multiple rounds due to partial user selection. Multi-RoundSecAgg addresses this issue by introducing a secure aggregation framework with multi-round privacy guarantees, employing a structured user selection strategy that ensures long-term privacy while maintaining fairness and participation balance <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">37</span></a></sup></cite>.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Loss Differential Strategy for Parameter Replacement (LDS-FL)</span>: LDS-FL implements PPFL by maintaining the performance of a private model through selective parameter replacement among multiple participants <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">38</span></a></sup></cite>. LDS-FL introduces a public participant that shares parameters, enabling private participants to construct loss differential models that resist privacy attacks without exposing their data. The authors demonstrated that LDS-FL provides robust privacy guarantees against membership inference attacks, reducing attack accuracy by over 10% while only slightly impacting model accuracy, making it a strong alternative to DP and HE <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">38</span></a></sup></cite>.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p"><span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">DeTrust-FL</span>: DeTrust-FL offers a decentralized solution to enhance privacy by securely aggregating model updates without relying on a centralized trusted authority <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">39</span></a></sup></cite>. It addresses vulnerabilities to inference attacks, such as dis-aggregation, through a decentralized functional encryption scheme where clients collaboratively generate decryption key fragments using a transparent participation matrix. Additionally, DeTrust-FL employs batch partitioning to prevent attacks and encrypts model updates with round labels to thwart replay attacks, achieving state-of-the-art communication efficiency while reducing dependency on centralized trust entities.</p>
</div>
</li>
</ul>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2409.16340/assets/radai-figs/Fig4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="496" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>A summary of UQ methods in FL is presented. (A) Model ensembling is where various models are trained and the final result is the average of their predictions. (B) Conformal Prediction (CP) is a method of UQ that provides a set of possible predictions, where the more uncertain the model is the more possible predictions it will provide. (C) Model calibration is a post-processing UQ method that serves to correct the issue of overconfidence in model prediction particularly when the model makes an incorrect prediction. This allows for more trustworthy confidence measures in the model’s predictions. (D) Bayesian FL is another method of UQ that tracks the variance of the model during training and at inference time. The variance will go up as the model becomes more uncertain providing a measure of model uncertainty.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Uncertainty Quantification (UQ) in FL</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">UQ aims to evaluate an AI model’s confidence in its predictions, which is vital for fostering trust, reliability, and user acceptance <cite class="ltx_cite ltx_citemacro_cite"><sup id="S4.p1.1.1.1" class="ltx_sup"><a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">11</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">40</span></a></sup></cite>. UQ can play a critical role in monitoring the AI model’s performance post-deployment and serving as an early warning system for potential performance degradation, enabling timely human intervention. Additionally, UQ can inform decisions on whether to apply personalized or global models, assists in detecting out-of-distribution samples, and supports active learning during model training. However, UQ in FL encounters unique challenges due to the non-IID nature of data across participating sites, which often exhibit differing data distributions, class imbalances, and other site-specific issues. This section will delve into various UQ methods specifically designed to address these complexities. Figure <a href="#S3.F4" title="Figure 4 ‣ 3.3 Other PPFL Methods ‣ 3 Privacy-Preserving FL (PPFL) ‣ Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:table:Uncertainty-estimation</span> provide a summary of the UQ methods discussed in this section.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>UQ using Model Ensembling</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Model ensembling is a widely used UQ method in FL that leverages the distributed nature of FL by treating multiple clients as an ensemble of models <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">13</span></a></sup></cite>. Three key ensembling approaches in FL include the ensemble of local models, an ensemble of global models, and the ensemble based on multiple coordinators <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">13</span></a></sup></cite>. The ensemble of local models prioritizes privacy and simplicity by treating each client’s model as an independent ensemble member, though it diverges from FL’s collaborative nature. The ensemble of global models preserves collaboration but increases computational and communication overhead due to repeated model training with different random seeds. The ensemble based on multiple coordinators improves scalability by distributing clients into subgroups with their coordinators, but this approach introduces coordination complexity and risks learning fragmentation.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Fed-ensemble extends ensembling methods by using random permutations to update a group of <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">K</annotation></semantics></math> models, with predictions made through model averaging <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">41</span></a></sup></cite>. Fed-ensemble incurs no additional computational overhead and can be seamlessly integrated into existing FL algorithms. Empirical results show that Fed-ensemble outperforms other FL algorithms across diverse datasets, especially in heterogeneous settings common in FL applications. Each method offers distinct trade-offs, and hybrid or adaptive ensembling strategies might help balance efficiency with collaborative benefits, depending on the specific needs of the FL application.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>UQ using Conformal Prediction (CP)</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">CP is a statistical framework for providing a reliable confidence measure for predictions made by ML models <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">42</span></a></sup></cite>. CP works by defining a nonconformity measure, which assesses how different a new example is from previously seen data and generates prediction regions that are likely to contain the true label or value. CP is particularly valuable in FL; however, the data heterogeneity inherent in FL clients violates the assumption of exchangeability, which is fundamental to traditional CP methods. To address this, Lu <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> introduced the concept of partial exchangeability and developed the Federated CP (FCP) framework, which retains rigorous theoretical guarantees and demonstrates strong empirical performance across computer vision and medical imaging datasets, making it a practical solution for UQ in heterogeneous FL environments <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">43</span></a></sup></cite>. Plassier <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> proposed a new FCP method using quantile regression, incorporating privacy constraints through DP. This approach adequately addresses label shifts between sites using importance weighting and provides theoretical guarantees for valid prediction coverage and privacy <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">44</span></a></sup></cite>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>UQ using Bayesian FL</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In Bayesian FL, each client learns a posterior probability distribution function (PDF) over its parameters <cite class="ltx_cite ltx_citemacro_cite"><sup id="S4.SS3.p1.1.1.1" class="ltx_sup"><a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">45</span></a>, <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">46</span></a></sup></cite>. The learned PDF is communicated by the clients to the server to aggregate the local PDFs and learn a global PDF that can serve all the clients. The posterior PDF can be used for UQ in the model’s output. Various approximation methods for the approximation of the posterior PDF, like MC-dropout and Stochastic Weight Averaging Gaussians (SWAG), have also been proposed <cite class="ltx_cite ltx_citemacro_cite"><sup id="S4.SS3.p1.1.2.1" class="ltx_sup"><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">13</span></a></sup></cite>.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>UQ and Model Output Calibration</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">UQ methods aim to assess and communicate how confident a model is in its predictions, which is crucial for reliable deployment and decision-making. While UQ provides a direct way to quantify uncertainty in model outputs, model calibration corrects the model’s tendency to be overconfident, particularly due to the Softmax function, thus aligning predicted probabilities with actual performance <cite class="ltx_cite ltx_citemacro_cite"><sup id="S4.SS4.p1.1.1.1" class="ltx_sup"><a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">11</span></a></sup></cite>. By calibrating the Softmax output, a more accurate assessment of the model’s confidence is achieved. Classifier Calibration with Virtual Representations (CCVR) calibrates a global model to improve performance on non-i.i.d data in heterogeneous settings <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">47</span></a></sup></cite>. The authors found a greater bias in representations learned in the deeper layers of a model trained with FL. They show that the classifier contains the greatest bias and that post-calibration can greatly improve classification performance. Specifically, the classifiers learned on different clients show the lowest feature similarity. The classifiers tend to get biased toward the classes over-represented in the local client data, leading to poor performance in under-represented classes. This classifier bias is a key reason behind performance degradation on non-IID federated data. Regularizing the classifier during federated training brings minor improvements <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">47</span></a></sup></cite>. However, post-training calibration of the classifier significantly improves classification accuracy across various FL algorithms and datasets <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">47</span></a></sup></cite>. A recently proposed method, Federated Calibration (FedCal), performs local and global calibration of models <cite class="ltx_cite ltx_citemacro_cite"><sup id="S4.SS4.p1.1.2.1" class="ltx_sup"><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">48</span></a></sup></cite>. It uses client-specific parameters for local calibration to effectively correct output misalignment without sacrificing prediction accuracy. These values are then aggregated via weight averaging to generate a global scalar value, minimizing the global calibration error <cite class="ltx_cite ltx_citemacro_cite"><sup id="S4.SS4.p1.1.3.1" class="ltx_sup"><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">48</span></a></sup></cite>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>FL in the Medical Imaging World</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">With the growing research in FL, PPFL, and UQ, real-world applications focusing on medical imaging have begun to demonstrate FL’s potential. This section presents FL implementation tools, real-world clinical case studies, and the future outlook of FL in medical imaging with challenges and opportunities.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Planning Medical Imaging FL Project</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Implementing an FL project for medical imaging involves several key steps to ensure the project’s success and compliance with privacy standards set by the participating institution and federal regulations. The project’s success could be measured by validating a model that performs better than all local models, trained by sites locally using their own data.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The process of implementing an FL project begins by defining the specific medical imaging problem, such as the classification of disease, pixel-level segmentation of organs of interest, or the identification of malignant masses in radiological scans. The next step involves selecting the participating institutions, such as hospitals or imaging labs, and determining which site will act as the central server. The selection of sites is based on their ability to collect and pre-process the data needed for training, train the model, and share updates with the server site over the internet. After identifying the collaborators, an appropriate FL software framework, such as NVIDIA FLARE, is selected and customized to meet the project’s specific needs. This customization may include implementing privacy-preserving techniques, UQ algorithms, and configuring site-specific software for data loading and resultant storage. The ML model architecture, inputs, and outputs are also determined at this stage before deploying the FL software framework at both the server and client sites.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Before model training begins, each site must prepare its data according to standardized preprocessing and labeling steps that have been agreed upon beforehand. The federated training process commences once the environment is fully set up, with both central server and client configurations in place. During this phase, each client trains the model locally and sends updates to the central server, which aggregates these updates and redistributes the updated model for further training. This iterative process continues until the model converges. If implemented, UQ is used to guide the training process.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">After training, the model is evaluated both locally at each site and globally across all sites to assess its performance. Upon achieving satisfactory results, the model is deployed for clinical use or further research, with ongoing monitoring to ensure its continued effectiveness. The UQ data can guide the model selection process for deployment, allow users to monitor the system’s performance, and invoke a manual review of the model output if necessary. The entire process is thoroughly documented, and reports are prepared to share findings with the research community. Finally, the model is maintained and periodically updated with new data or improved algorithms, ensuring its relevance and accuracy over time, while collaboration between participating sites continues to drive ongoing learning and improvement.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>FL Implementation Tools</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">To streamline FL model training, validation, and deployment process, several open-source frameworks or software development kits (SDKs) have been developed. NVIDIA Federated Learning Application Runtime Environment (FLARE) is a well-known open-source SDK <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">49</span></a></sup></cite>. NVIDIA-FLARE supports various FL algorithms, workflows, and privacy-preserving techniques, including DP and HE. OpenFL is an open-source Python library that operates using a static network topology where clients connect to a central aggregating server via encrypted channels <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">50</span></a></sup></cite>. The workflow is dictated by a federation plan that all sites agree upon before the start. Originally designed with medical imaging in mind, OpenFL can be adapted for other types. Fed-BioMed is another open-source framework tailored for biomedical applications of FL. It offers tools and libraries to manage distributed training, handle heterogeneous data, and ensure privacy and security in a biomedical research context <cite class="ltx_cite ltx_citemacro_cite"><sup id="S5.SS2.p1.1.1.1" class="ltx_sup"><a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">51</span></a></sup></cite>. Argonne Privacy-Preserving Framework (APPFL) is an open-source Python package that provides tools to implement, test, and validate various aspects of PPFL experiments in simulation settings <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">52</span></a></sup></cite>.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Medical Imaging FL Studies</h3>

<div id="S5.SS3.p1" class="ltx_para">
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Federated Tumor Segmentation (FeTS)</span>: FeTS-1.0 was the first real-world, large-scale FL effort for medical imaging, which aimed to identify the optimal weight aggregation approach for training a consensus model across multiple geographically distinct institutions while retaining data locally <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">53</span></a></sup>, <sup class="ltx_sup"><a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">54</span></a></sup></cite>. Presented in the form of a challenge, FeTS evaluated the generalizability of a federated model trained on brain tumor segmentation to unseen, institution-specific data, showcasing the potential of FL in real-world medical settings. Building on this, the FeTS-2.0 challenge focused on out-of-sample generalizability for Glioblastoma detection, creating the largest Glioblastoma dataset to date and demonstrating significant improvements in tumor segmentation accuracy.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p"><span id="S5.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">FL for Predicting COVID-19 Outcomes</span>: Dayan <span id="S5.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> used FL to train a model on Covid-19 data from 20 different institutes across the globe without sharing data <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">55</span></a></sup></cite>. The EXAM model was created to predict the future oxygen needs of Covid-19 patients from the federated setup. The model achieved an average AUC of more than 0.92 in predicting outcomes. The federated model provided a 16% improvement in AUC and 38% improvement in generalizability over models trained at individual institutions. The study incorporated data from 4 continents and was validated on three independent sites to ensure the robust performance of the federated model. The study also explores DP in their FL setup, showing that enhanced privacy can be provided while maintaining performance. It was one of the largest real-world applications of FL and showcased the potential FL has to enable large-scale medical AI model training.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Challenges and Opportunities</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">We have presented an overview of FL, PPFL, and UQ from a technological and algorithmic perspective. We also presented an overview of how the FL project can be implemented and two case studies that used FL to solve real-world medical imaging tasks. While significant progress has been made in recent years, FL is still in its infancy. Multiple challenges must be addressed for FL to become a standard ML model development paradigm for medical imaging AI. These challenges present potential opportunities for researchers to further explore and improve the state of FL for medical imaging.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<ol id="S5.I2" class="ltx_enumerate">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p id="S5.I2.i1.p1.1" class="ltx_p"><span id="S5.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Administrative Challenges</span>: Before an FL project can be implemented, engaging stakeholders from all participating institutions is essential. These stakeholders typically include researchers, the medical imaging team, information technology and cybersecurity experts, contract and agreement management teams, and hospital administrators. Engaging these groups ensures that all aspects of the project, from technical implementation to legal and ethical considerations, are addressed. Ethical approvals from relevant Institutional Review Boards (IRBs) or ethics committees must be secured to ensure compliance with regulatory standards, particularly concerning patient data privacy and security. In addition to ethical approvals, formal agreements about “weight sharing” between institutions must be established. These agreements should outline whether model weights will be shared in “plain” or “encrypted” formats, addressing concerns related to data security and compliance with privacy laws such as HIPAA or GDPR. These agreements also need to specify the responsibilities of each institution, including data governance, data transmission protocols, and contingency plans in case of data breaches. Addressing these issues comprehensively before the FL project begins is crucial for ensuring smooth collaboration and maintaining trust among the involved parties.</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p id="S5.I2.i2.p1.1" class="ltx_p"><span id="S5.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Requirement for Annotated Datasets</span>: It is important to recognize that FL does not eliminate the need for annotated data. Each participating site must still invest significant resources in creating and annotating datasets for training local models. The FL community needs to build upon and extend ongoing work in self-supervised learning, active learning, continual learning, and transfer learning to federated environments. An exciting area of research involves using generative AI models to create diverse, medically relevant datasets. However, despite the aesthetically appealing nature of AI-generated images, there is currently limited convincing evidence of their clinical relevance. This highlights the need for further research to validate the utility of AI-generated images in training federated models.</p>
</div>
</li>
<li id="S5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I2.i3.p1" class="ltx_para">
<p id="S5.I2.i3.p1.1" class="ltx_p"><span id="S5.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Privacy-Performance Trade-offs</span>: Another significant challenge in FL is the inherent trade-off between privacy and model performance <cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">30</span></a></sup></cite>. Further research is needed to efficiently allocate the privacy budget to enhance privacy without compromising the model’s effectiveness. Exploring alternative types of noise and methods for adding noise presents a potential pathway for improving the effectiveness of DP. Additionally, there is a need to further adapt encryption methods, including HE and SHE, to FL environments to minimize the performance gap between federated models with and without encryption. Simultaneously, communication efficiency between the server and clients remains a crucial factor to consider when evaluating the overall effectiveness of FL algorithms.</p>
</div>
</li>
<li id="S5.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I2.i4.p1" class="ltx_para">
<p id="S5.I2.i4.p1.1" class="ltx_p"><span id="S5.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">Pesonalization vs. Generalization in PFL</span>: PFL offers the advantage of tailoring models to the specific needs of individual clients, which can lead to improved performance on local data. However, it also presents challenges, as personalized models may risk overfitting and compromise the generalization abilities typically expected from FL models. Incorporating uncertainty information about model weights calculated during federated runs could provide PFL models with the insights needed to optimize learning and enhance generalization. Consequently, UQ-guided PFL has the potential to produce more generalizable, personalized models that effectively capture federated knowledge while performing well on local data. Moreover, CP-based UQ methods, though still in their early stages of development, hold promise for further improving the generalizability and personalization of PFL models.</p>
</div>
</li>
<li id="S5.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S5.I2.i5.p1" class="ltx_para">
<p id="S5.I2.i5.p1.1" class="ltx_p"><span id="S5.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">Computational Requirements for UQ in FL</span>: Computational efficiency remains an unresolved challenge in the area of UQ for federated models, particularly with ensembling and Bayesian approaches. Model ensembling involves training multiple models with different initialization seeds, which can be computationally expensive and time-consuming. Similarly, Bayesian FL requires training local models with additional parameters to represent PDFs defined over the model weights, further increasing the computational burden. Developing UQ methods that are computationally efficient and scalable in the FL environment would be highly beneficial, enabling more practical and widespread adoption of UQ in FL.</p>
</div>
</li>
<li id="S5.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="S5.I2.i6.p1" class="ltx_para">
<p id="S5.I2.i6.p1.1" class="ltx_p"><span id="S5.I2.i6.p1.1.1" class="ltx_text ltx_font_bold">Post-Deployment Performance Monitoring</span>: After model deployment, performance monitoring using UQ methods for identifying out-of-distribution and noisy data is a crucial yet relatively unexplored area of research. UQ provides the capability to monitor model performance, enabling the invocation of a human-in-the-loop approach to diagnose and address the causes of model underperformance. This process not only helps resolve immediate issues but also contributes to future model improvement by incorporating the identified data into subsequent training cycles. As previously discussed, there is significant potential for researchers to build upon classical UQ methods and optimize them for the unique challenges of FL.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">FL holds the potential to dramatically improve medical imaging workflows in both research and clinical environments. Various forms of FL such as centralized, decentralized, and personalized federated learning are all being developed to tackle multiple problems in the healthcare domain. FL addresses critical privacy and security concerns while leveraging diverse and extensive datasets to enhance model performance and generalizability by enabling collaborative model training across multiple institutions without directly sharing sensitive patient data. Enhanced privacy preservation in the form of differential privacy, homomorphic encryption, and other hybrid approaches enable even more secure deployments, protecting patient privacy. Active research is also being conducted to embed uncertainty quantification for trustworthy AI models. Continued interdisciplinary efforts and technological advancements in this domain are expected to streamline medical imaging workflows further, support precision medicine initiatives, and ultimately contribute to better healthcare delivery and patient outcomes worldwide.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="S6.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>List of Frequent Abbreviations</figcaption>
<table id="S6.T1.1" class="ltx_tabular">
<tr id="S6.T1.1.1" class="ltx_tr">
<td id="S6.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S6.T1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.1.1.1.1" class="ltx_p" style="width:86.7pt;"><span id="S6.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Abbreviation</span></span>
</span>
</td>
<td id="S6.T1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S6.T1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.1.2.1.1" class="ltx_p" style="width:303.5pt;"><span id="S6.T1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Description</span></span>
</span>
</td>
</tr>
<tr id="S6.T1.1.2" class="ltx_tr">
<td id="S6.T1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S6.T1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.2.1.1.1" class="ltx_p" style="width:86.7pt;">CP</span>
</span>
</td>
<td id="S6.T1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S6.T1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.2.2.1.1" class="ltx_p" style="width:303.5pt;">Conformal Prediction</span>
</span>
</td>
</tr>
<tr id="S6.T1.1.3" class="ltx_tr">
<td id="S6.T1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S6.T1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.3.1.1.1" class="ltx_p" style="width:86.7pt;">DP</span>
</span>
</td>
<td id="S6.T1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S6.T1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.3.2.1.1" class="ltx_p" style="width:303.5pt;">Differential Privacy</span>
</span>
</td>
</tr>
<tr id="S6.T1.1.4" class="ltx_tr">
<td id="S6.T1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S6.T1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.4.1.1.1" class="ltx_p" style="width:86.7pt;">FL</span>
</span>
</td>
<td id="S6.T1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S6.T1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.4.2.1.1" class="ltx_p" style="width:303.5pt;">Federated Learning</span>
</span>
</td>
</tr>
<tr id="S6.T1.1.5" class="ltx_tr">
<td id="S6.T1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S6.T1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.5.1.1.1" class="ltx_p" style="width:86.7pt;">HE</span>
</span>
</td>
<td id="S6.T1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S6.T1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.5.2.1.1" class="ltx_p" style="width:303.5pt;">Homomorphic Encryption</span>
</span>
</td>
</tr>
<tr id="S6.T1.1.6" class="ltx_tr">
<td id="S6.T1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S6.T1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.6.1.1.1" class="ltx_p" style="width:86.7pt;">IID</span>
</span>
</td>
<td id="S6.T1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S6.T1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.6.2.1.1" class="ltx_p" style="width:303.5pt;">Independant and IDentically Distributed</span>
</span>
</td>
</tr>
<tr id="S6.T1.1.7" class="ltx_tr">
<td id="S6.T1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S6.T1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.7.1.1.1" class="ltx_p" style="width:86.7pt;">PFL</span>
</span>
</td>
<td id="S6.T1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S6.T1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.7.2.1.1" class="ltx_p" style="width:303.5pt;">Personalized Federated Learning</span>
</span>
</td>
</tr>
<tr id="S6.T1.1.8" class="ltx_tr">
<td id="S6.T1.1.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="S6.T1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.8.1.1.1" class="ltx_p" style="width:86.7pt;">PPFL</span>
</span>
</td>
<td id="S6.T1.1.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S6.T1.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.8.2.1.1" class="ltx_p" style="width:303.5pt;">Privacy Preserving Federated Learning</span>
</span>
</td>
</tr>
<tr id="S6.T1.1.9" class="ltx_tr">
<td id="S6.T1.1.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r">
<span id="S6.T1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.9.1.1.1" class="ltx_p" style="width:86.7pt;">UQ</span>
</span>
</td>
<td id="S6.T1.1.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r">
<span id="S6.T1.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T1.1.9.2.1.1" class="ltx_p" style="width:303.5pt;">Uncertainty Quantification</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S6.T2" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>List and Characteristics of FL Algorithms.</figcaption>
<table id="S6.T2.3" class="ltx_tabular">
<tr id="S6.T2.3.1" class="ltx_tr">
<td id="S6.T2.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.1.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Algorithm</span></span>
</span>
</td>
<td id="S6.T2.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.1.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Central Server</span></span>
</span>
</td>
<td id="S6.T2.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Local Forgetting</span></span>
</span>
</td>
<td id="S6.T2.3.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.1.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.1.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Summary</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.2" class="ltx_tr">
<td id="S6.T2.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.2.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">FedAvg </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">14</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.2.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.2.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.2.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.2.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T2.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.2.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.2.4.1.1.1" class="ltx_text" style="font-size:80%;">Train local models across various clients and then average the gradient updates at the central server to update the global mode; first proposed method of FL.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.3" class="ltx_tr">
<td id="S6.T2.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.3.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.3.1.1.1.1" class="ltx_text" style="font-size:80%;">FedProx </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">16</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.3.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.3.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.3.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.3.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.3.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.3.4.1.1.1" class="ltx_text" style="font-size:80%;">Excels in heterogeneous settings; generalization of the FedAvg algorithm; allows for partial updates to be sent to the server instead of simply dropping them from a federated round; adds proximal term that prevents any one client from having too much of an impact on the global model.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.4" class="ltx_tr">
<td id="S6.T2.3.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.4.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.4.1.1.1.1" class="ltx_text" style="font-size:80%;">FedBN </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">17</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.4.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.4.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.4.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.4.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.4.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.4.4.1.1.1" class="ltx_text" style="font-size:80%;">Addresses the issue of non-IID data by leveraging batch normalization; follows a similar procedure to Fed-Avg but assumes local models have batch norm layers and excludes their parameters from the averaging step.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.5" class="ltx_tr">
<td id="S6.T2.3.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.5.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.5.1.1.1.1" class="ltx_text" style="font-size:80%;">FedGen </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">18</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.5.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.5.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.5.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.5.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.5.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.5.4.1.1.1" class="ltx_text" style="font-size:80%;">Learns a generator model on the server to ensemble user models’ predictions, creating augmented samples that encapsulate consensual knowledge from user models; generate augmented samples that are shared with users to regularize local model training, leading to better accuracy and faster convergence.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.6" class="ltx_tr">
<td id="S6.T2.3.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.6.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.6.1.1.1.1" class="ltx_text" style="font-size:80%;">FOLA </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">20</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.6.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.6.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.6.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.6.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.6.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.6.4.1.1.1" class="ltx_text" style="font-size:80%;">Bayesian federated learning framework utilizing online Laplace approximation to address local catastrophic forgetting and data heterogeneity; maximizes the posteriors of the server and clients simultaneously to reduce aggregation error and mitigate local forgetting.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.7" class="ltx_tr">
<td id="S6.T2.3.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.7.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.7.1.1.1.1" class="ltx_text" style="font-size:80%;">Swarm Learning </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">24</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.7.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.7.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.7.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.7.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.7.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.7.4.1.1.1" class="ltx_text" style="font-size:80%;">Model parameters are shared via a swarm network, and the model is built independently on private data at the individual sites; only pre-authorized clients are allowed to execute transactions; on-boarding new clients can be done dynamically.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.8" class="ltx_tr">
<td id="S6.T2.3.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.8.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.8.1.1.1.1" class="ltx_text" style="font-size:80%;">TCT </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">21</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.8.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.8.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.8.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.8.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.8.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.8.4.1.1.1" class="ltx_text" style="font-size:80%;">Train-Convexify-Train: Learn features with an off-the-shelf method (i.e., Fedavg) and then optimize a convexified problem obtained using the model’s empirical neural tangent kernel approximation; involves two stages where the first stage learns useful features from the data, and the second stage learns to use these features to generate a well-performing model.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.9" class="ltx_tr">
<td id="S6.T2.3.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.9.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.9.1.1.1.1" class="ltx_text" style="font-size:80%;">FedAP </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">15</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.9.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.9.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.9.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.9.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.9.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.9.4.1.1.1" class="ltx_text" style="font-size:80%;">Learns similarities between clients by calculating distances between batch normalization layer statistics obtained from a pre-trained model; these similarities are used to aggregate client models; each client preserves its batch normalization layers to maintain personalized features; the server aggregates client model parameters weighted by client similarities in a personalized manner to generate a unique final model for each client.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.10" class="ltx_tr">
<td id="S6.T2.3.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.10.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.10.1.1.1.1" class="ltx_text" style="font-size:80%;">pFedBays </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">27</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.10.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.10.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.10.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.10.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.10.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.10.4.1.1.1" class="ltx_text" style="font-size:80%;">Weight uncertainty is introduced in client and server neural networks; to achieve personalization, each client updates its local distribution parameters by balancing its construction error over private data.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.11" class="ltx_tr">
<td id="S6.T2.3.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.11.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.11.1.1.1.1" class="ltx_text" style="font-size:80%;">FCCL </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">22</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.11.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.11.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.11.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.11.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.11.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.11.4.1.1.1" class="ltx_text" style="font-size:80%;">Federated cross-correlational and continual learning uses unlabeled public data to address heterogeneity across models and non-IID data, enhancing model generalizability; constructs a cross-correlation matrix on model outputs to encourage class invariance and diversity; employs knowledge distillation, utilizing both the updated global model and the trained local model to balance inter-domain and intra-domain knowledge to mitigate local forgetting.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.12" class="ltx_tr">
<td id="S6.T2.3.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.12.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.12.1.1.1.1" class="ltx_text" style="font-size:80%;">Self-FL </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">29</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.12.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.12.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.12.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.12.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.12.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.12.4.1.1.1" class="ltx_text" style="font-size:80%;">Self-aware personalized FL method that uses intra-client and inter-client uncertainty estimation to balance the training of its local personal model and global model.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.13" class="ltx_tr">
<td id="S6.T2.3.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.13.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.13.1.1.1.1" class="ltx_text" style="font-size:80%;">Fedpop </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">28</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.13.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.13.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.13.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.13.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.13.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.13.4.1.1.1" class="ltx_text" style="font-size:80%;">Each client has a local model composed of fixed population parameters that are shared across clients, as well as random effects that explain heterogeneity in the local data.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.14" class="ltx_tr">
<td id="S6.T2.3.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.14.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.14.1.1.1.1" class="ltx_text" style="font-size:80%;">FedFA </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">23</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.14.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.14.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.14.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.14.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.14.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.14.4.1.1.1" class="ltx_text" style="font-size:80%;">Feature anchors are used to align features and calibrate classifiers across clients simultaneously; this enables client models to be updated in a shared feature space with consistent classifiers during local training.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.15" class="ltx_tr">
<td id="S6.T2.3.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.15.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.15.1.1.1.1" class="ltx_text" style="font-size:80%;">ProxyFL </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">25</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.15.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.15.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T2.3.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.15.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.15.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T2.3.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.15.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.15.4.1.1.1" class="ltx_text" style="font-size:80%;">Clients maintain two models, a private model that is never shared and a publicly shared proxy model that is designed to preserve patient privacy; proxy models allow for efficient information exchange among clients without needing a centralized server; clients can have different model architectures.</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.3.16" class="ltx_tr">
<td id="S6.T2.3.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.3.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.16.1.1.1" class="ltx_p" style="width:51.2pt;"><span id="S6.T2.3.16.1.1.1.1" class="ltx_text" style="font-size:80%;">FogML </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">26</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T2.3.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.3.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.16.2.1.1" class="ltx_p" style="width:28.5pt;"><span id="S6.T2.3.16.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.3.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.16.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S6.T2.3.16.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T2.3.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T2.3.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.16.4.1.1" class="ltx_p" style="width:332.9pt;"><span id="S6.T2.3.16.4.1.1.1" class="ltx_text" style="font-size:80%;">Fog computing nodes reside on the local area networks of each site; fog nodes can pre-process data and aggregate updates from the locally trained models before transmitting, reducing data traffic over sending raw data.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>List of PPFL Algorithms having Differential Privacy (DP), Homomorphic Encryption (HE).</figcaption>
<table id="S6.T3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.3.1.1" class="ltx_tr">
<th id="S6.T3.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T3.3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.1.1.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Algorithm</span></span>
</span>
</th>
<th id="S6.T3.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T3.3.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.1.1.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">DP</span></span>
</span>
</th>
<th id="S6.T3.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T3.3.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.1.1.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">HE</span></span>
</span>
</th>
<th id="S6.T3.3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T3.3.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.1.1.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.1.1.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Summary</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.3.2.1" class="ltx_tr">
<td id="S6.T3.3.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T3.3.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.2.1.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Hybrid Approach </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">35</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T3.3.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T3.3.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.2.1.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.2.1.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T3.3.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T3.3.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.2.1.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.2.1.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T3.3.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T3.3.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.2.1.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.2.1.4.1.1.1" class="ltx_text" style="font-size:80%;">Combining DP with secure multiparty computation enables this method to reduce the growth of noise injection as the number of parties increases without sacrificing privacy; the trust parameter allows for maintaining a set level of trust.</span></span>
</span>
</td>
</tr>
<tr id="S6.T3.3.3.2" class="ltx_tr">
<td id="S6.T3.3.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.3.2.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">NbAFL </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">30</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T3.3.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.3.2.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.3.2.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T3.3.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.3.2.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.3.2.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T3.3.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.3.2.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.3.2.4.1.1.1" class="ltx_text" style="font-size:80%;">Noising before aggregation FL (NbAFL) Uses K-random scheduling to optimize the privacy and accuracy trade-off by introducing artificial noise into the parameters of each client before aggregation.</span></span>
</span>
</td>
</tr>
<tr id="S6.T3.3.4.3" class="ltx_tr">
<td id="S6.T3.3.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.4.3.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.4.3.1.1.1.1" class="ltx_text" style="font-size:80%;">DeTrust-FL </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">39</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T3.3.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.4.3.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.4.3.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T3.3.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.4.3.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.4.3.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T3.3.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.4.3.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.4.3.4.1.1.1" class="ltx_text" style="font-size:80%;">Provides secure aggregation of model updates in a decentralized trust setting; implements a decentralized functional encryption scheme where clients collaboratively generate decryption key fragments based on an agreed participation matrix.</span></span>
</span>
</td>
</tr>
<tr id="S6.T3.3.5.4" class="ltx_tr">
<td id="S6.T3.3.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.5.4.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.5.4.1.1.1.1" class="ltx_text" style="font-size:80%;">SHEFL </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">34</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T3.3.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.5.4.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.5.4.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T3.3.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.5.4.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.5.4.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T3.3.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.5.4.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.5.4.4.1.1.1" class="ltx_text" style="font-size:80%;">Somewhat homomorphically encrypted FL (SHEFL); only communicating encrypted weights; all model updates are conducted in an encrypted space.</span></span>
</span>
</td>
</tr>
<tr id="S6.T3.3.6.5" class="ltx_tr">
<td id="S6.T3.3.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.6.5.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.6.5.1.1.1.1" class="ltx_text" style="font-size:80%;">PrivateKT </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">36</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T3.3.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.6.5.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.6.5.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T3.3.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.6.5.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.6.5.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T3.3.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.6.5.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.6.5.4.1.1.1" class="ltx_text" style="font-size:80%;">Private knowledge transfer method that uses a small subset of public data to transfer knowledge with local DP guarantee; selects public data points based on informativeness rather than randomly to maximize the knowledge quality.</span></span>
</span>
</td>
</tr>
<tr id="S6.T3.3.7.6" class="ltx_tr">
<td id="S6.T3.3.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.7.6.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.7.6.1.1.1.1" class="ltx_text" style="font-size:80%;">Multi-RoundSecAgg </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">37</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T3.3.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.7.6.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.7.6.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T3.3.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.7.6.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.7.6.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T3.3.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T3.3.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.7.6.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.7.6.4.1.1.1" class="ltx_text" style="font-size:80%;">Provides privacy guarantees over multiple training rounds; develops a structured user section strategy that guarantees the long-term privacy of each use.</span></span>
</span>
</td>
</tr>
<tr id="S6.T3.3.8.7" class="ltx_tr">
<td id="S6.T3.3.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T3.3.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.8.7.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S6.T3.3.8.7.1.1.1.1" class="ltx_text" style="font-size:80%;">LDS-FL </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">38</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T3.3.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T3.3.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.8.7.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.8.7.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T3.3.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T3.3.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.8.7.3.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T3.3.8.7.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T3.3.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T3.3.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.3.8.7.4.1.1" class="ltx_p" style="width:335.7pt;"><span id="S6.T3.3.8.7.4.1.1.1" class="ltx_text" style="font-size:80%;">Maintain the performance of a private model preserved through parameter replacement with multi-user participation to reduce the efficiency of privacy attacks.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S6.T4" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>UQ Methods in FL.</figcaption>
<table id="S6.T4.3" class="ltx_tabular">
<tr id="S6.T4.3.1" class="ltx_tr">
<td id="S6.T4.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Algorithm</span></span>
</span>
</td>
<td id="S6.T4.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CP</span></span>
</span>
</td>
<td id="S6.T4.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dist Pred</span></span>
</span>
</td>
<td id="S6.T4.3.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.1.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Bayes</span></span>
</span>
</td>
<td id="S6.T4.3.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Cal</span></span>
</span>
</td>
<td id="S6.T4.3.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.1.6.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Summary</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.2" class="ltx_tr">
<td id="S6.T4.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">CCVR </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">47</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T4.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.2.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.2.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.2.4.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.2.5.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T4.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S6.T4.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.2.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.2.6.1.1.1" class="ltx_text" style="font-size:80%;">Classifier calibration with Virtual Representation (CCVR) Found a greater bias in representations learned in the deeper layers of a model trained with FL; they show that the classifier contains the greatest bias toward local client data and that classification performance can be greatly improved with post-training classifier calibration</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.3" class="ltx_tr">
<td id="S6.T4.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.3.1.1.1.1" class="ltx_text" style="font-size:80%;">Fed-ensemble </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">41</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T4.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.3.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.3.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.3.4.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.3.5.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.3.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.3.6.1.1.1" class="ltx_text" style="font-size:80%;">Extends ensembling methods to FL; characterizes uncertainty in predictions by using the variance in the predictions as a measure of knowledge uncertainty.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.4" class="ltx_tr">
<td id="S6.T4.3.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.4.1.1.1.1" class="ltx_text" style="font-size:80%;">DP-fedCP </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">44</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T4.3.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.4.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T4.3.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.4.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.4.4.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.4.5.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.4.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.4.6.1.1.1" class="ltx_text" style="font-size:80%;">Differentially Private Federated Average Quantile Estimation (DP-fedCP); the method is designed to construct personalized CP sets in an FL scenario.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.5" class="ltx_tr">
<td id="S6.T4.3.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.5.1.1.1.1" class="ltx_text" style="font-size:80%;">FCP </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">43</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T4.3.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.5.2.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T4.3.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.5.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.5.4.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.5.5.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.5.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.5.6.1.1.1" class="ltx_text" style="font-size:80%;">Federated CP, a framework for extending CP to FL that addresses the non-IID nature of data in FL.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.6" class="ltx_tr">
<td id="S6.T4.3.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.6.1.1.1.1" class="ltx_text" style="font-size:80%;">FedPPD </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">45</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T4.3.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.6.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.6.3.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T4.3.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.6.4.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.6.5.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.6.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.6.6.1.1.1" class="ltx_text" style="font-size:80%;">Framework for FL with uncertainty, where, in every round, each client infers the posterior distribution over its parameters
and the posterior predictive distribution (PPD); PPD is sent to the server.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.7" class="ltx_tr">
<td id="S6.T4.3.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.7.1.1.1.1" class="ltx_text" style="font-size:80%;">FedBNN </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">56</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T4.3.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.7.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.7.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.7.4.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T4.3.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.7.5.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.3.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.7.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.7.6.1.1.1" class="ltx_text" style="font-size:80%;">FL framework based on training a customized local Bayesian model for each client.</span></span>
</span>
</td>
</tr>
<tr id="S6.T4.3.8" class="ltx_tr">
<td id="S6.T4.3.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T4.3.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.1.1.1" class="ltx_p" style="width:45.5pt;"><span id="S6.T4.3.8.1.1.1.1" class="ltx_text" style="font-size:80%;">FedCal </span><cite class="ltx_cite ltx_citemacro_citep"><sup class="ltx_sup"><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">48</span></a></sup></cite></span>
</span>
</td>
<td id="S6.T4.3.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T4.3.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.2.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.8.2.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T4.3.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.3.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.8.3.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T4.3.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.4.1.1" class="ltx_p" style="width:22.8pt;"><span id="S6.T4.3.8.4.1.1.1" class="ltx_text" style="font-size:80%;color:#FF0000;">✗</span></span>
</span>
</td>
<td id="S6.T4.3.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T4.3.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.5.1.1" class="ltx_p" style="width:19.9pt;"><span id="S6.T4.3.8.5.1.1.1" class="ltx_text" style="font-size:80%;color:#0000FF;">✔</span></span>
</span>
</td>
<td id="S6.T4.3.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S6.T4.3.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.8.6.1.1" class="ltx_p" style="width:298.8pt;"><span id="S6.T4.3.8.6.1.1.1" class="ltx_text" style="font-size:80%;">Performs local and global calibration of models. FedCAL uses client-specific
parameters for local calibration to effectively correct output misalignment without sacrificing prediction accuracy. Values are then aggregated via weight averaging to minimize global calibration error</span></span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text" style="font-size:50%;">CP: Conformal Prediction, Dist Pred: Distilled Prediction, Bayes: Bayesian, Cal: Calibration.
<span id="S6.p2.1.1.1" class="ltx_text" style="font-size:160%;"></span></span></p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:80%;">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgements</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p"><span id="S7.p1.1.1" class="ltx_text" style="font-size:80%;">This work was funded by NSF grants 2234468 and 2234836, NIH grant U01CA200464. The content is the responsibility of the authors and does not reflect the official views of the National Science Foundation</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:80%;">Pati et al. 2024</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:80%;">
Pati, S., Kumar, S., Varma, A., and Edwards, B. (2024). Privacy preservation for federated learning in healthcare.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:80%;">Patterns </span><em id="bib.bib1.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">5</em><span id="bib.bib1.10.3" class="ltx_text" style="font-size:80%;">. URL: </span><a target="_blank" href="https://www.sciencedirect.com/journal/patterns/vol/5/issue/7" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://www.sciencedirect.com/journal/patterns/vol/5/issue/7</a><span id="bib.bib1.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:80%;">Wiggins et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:80%;">
Wiggins, W. F., Magudia, K., Schmidt, T. M. S., O’Connor, S. D., Carr, C. D., Kohli, M. D., and Andriole, K. P. (2021). Imaging AI in Practice: A Demonstration of Future Workflow Using Integration Standards.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:80%;">Radiology: Artificial Intelligence </span><em id="bib.bib2.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">3</em><span id="bib.bib2.10.3" class="ltx_text" style="font-size:80%;">, e210152. URL: </span><a target="_blank" href="https://doi.org/10.1148/ryai.2021210152" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.1148/ryai.2021210152</a><span id="bib.bib2.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.12.1" class="ltx_text" style="font-size:80%;">PMID: 34350414.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:80%;">Monti et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:80%;">
Monti, C. B., van Assen, M., Stillman, A. E., Lee, S. J., Hoelzer, P., Fung, G. S. K., Secchi, F., Sardanelli, F., and De Cecco, C. N. (2022). Evaluating the performance of a convolutional neural network algorithm for measuring thoracic aortic diameters in a heterogeneous population.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:80%;">Radiology: Artificial Intelligence </span><em id="bib.bib3.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">4</em><span id="bib.bib3.10.3" class="ltx_text" style="font-size:80%;">, e210196. URL: </span><a target="_blank" href="https://doi.org/10.1148/ryai.210196" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.1148/ryai.210196</a><span id="bib.bib3.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:80%;">Darzidehkalani et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:80%;">
Darzidehkalani, E., Ghasemi-rad, M., and van Ooijen, P. V. (2022). Federated Learning in Medical Imaging: Part II: Methods, Challenges, and Considerations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:80%;">Journal of the American College of Radiology </span><em id="bib.bib4.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">19</em><span id="bib.bib4.10.3" class="ltx_text" style="font-size:80%;">, P755–765. doi:</span><a target="_blank" href="http://dx.doi.org/10.1016/j.jacr.2022.03.016" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1016/j.jacr.2022.03.016</span></a><span id="bib.bib4.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:80%;">Kaissis et al. 2020</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:80%;">
Kaissis, G., Makowski, M., Rückert, D., and Braren, R. (2020). Secure, privacy-preserving and federated machine learning in medical imaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:80%;">Nature Machine Intelligence </span><em id="bib.bib5.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">2</em><span id="bib.bib5.10.3" class="ltx_text" style="font-size:80%;">. doi:</span><a target="_blank" href="http://dx.doi.org/10.1038/s42256-020-0186-1" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1038/s42256-020-0186-1</span></a><span id="bib.bib5.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:80%;">Zhang et al. 2024</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:80%;">
Zhang, F., Kreuter, D., Chen, Y., Dittmer, S., and Tull, S. (2024). Recent methodological advances in federated learning for healthcare.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:80%;">Patterns. URL: </span><a target="_blank" href="https://www.cell.com/patterns/fulltext/S2666-3899(24)00131-4" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://www.cell.com/patterns/fulltext/S2666-3899(24)00131-4</a><span id="bib.bib6.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:80%;">Jere et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:80%;">
Jere, M. S., Farnan, T., and Koushanfar, F. (2021). A Taxonomy of Attacks on Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:80%;">IEEE Security &amp; Privacy </span><em id="bib.bib7.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">19</em><span id="bib.bib7.10.3" class="ltx_text" style="font-size:80%;">, 20–28. doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/MSEC.2020.3039941" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/MSEC.2020.3039941</span></a><span id="bib.bib7.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.4.4.1" class="ltx_text" style="font-size:80%;">Dwork 2006</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.6.1" class="ltx_text" style="font-size:80%;">
Dwork, C. (2006).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:80%;">Differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:80%;">In: 33rd International Colloquium on Automata, Languages and Programming, part II (ICALP 2006). Springer ( 1–12).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.1007/11787006_1" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1007/11787006_1</span></a><span id="bib.bib8.10.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.4.4.1" class="ltx_text" style="font-size:80%;">Gentry 2009</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text" style="font-size:80%;">
Gentry, C.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:80%;">A Fully Homomorphic Encryption Scheme.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:80%;">Ph.D. thesis Stanford University (2009).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://crypto.stanford.edu/craig/craig-thesis.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://crypto.stanford.edu/craig/craig-thesis.pdf</a><span id="bib.bib9.10.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:80%;">Xu et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:80%;">
Xu, L., Jiang, C., Qian, Y., Li, J., Zhao, Y., and Ren, Y. (2021). Privacy-Accuracy Trade-Off in Differentially-Private Distributed Classification: A Game Theoretical Approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Big Data. doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TBDATA.2017.2777968" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TBDATA.2017.2777968</span></a><span id="bib.bib10.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:80%;">Dera et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:80%;">
Dera, D., Bouaynaya, N. C., Rasool, G., Shterenberg, R., and Fathallah-Shaykh, H. M. (2021). PremiUm-CNN: Propagating Uncertainty Towards Robust Convolutional Neural Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Signal Processing </span><em id="bib.bib11.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">69</em><span id="bib.bib11.10.3" class="ltx_text" style="font-size:80%;">, 4669–4684. doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TSP.2021.3096804" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TSP.2021.3096804</span></a><span id="bib.bib11.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:80%;">Ahmed et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:80%;">
Ahmed, S., Dera, D., Hassan, S. U., Bouaynaya, N., and Rasool, G. (2022). Failure detection in deep neural networks for medical imaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:80%;">Frontiers in Medical Technology </span><em id="bib.bib12.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">4</em><span id="bib.bib12.10.3" class="ltx_text" style="font-size:80%;">. URL: </span><a target="_blank" href="https://doi.org/10.3389/fmedt.2022.919046" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.3389/fmedt.2022.919046</a><span id="bib.bib12.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:80%;">Linsner et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:80%;">
Linsner, F., Adilova, L., Däubener, S., Kamp, M., and Fischer, A. (2021).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:80%;">Approaches to Uncertainty Quantification in Federated Deep Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text" style="font-size:80%;">In: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer ( 128–145).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.10.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://doi.org/10.1007/978-3-030-93736-2_12" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.1007/978-3-030-93736-2_12</a><span id="bib.bib13.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:80%;">McMahan et al. 2017</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:80%;">
McMahan, B., Moore, E., Ramage, D., Hampson, S., and Arcas, B. A. y. (2017).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:80%;">Communication-Efficient Learning of Deep Networks from Decentralized Data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.9.1" class="ltx_text" style="font-size:80%;">In: Singh, A., and Zhu, J., eds. Proceedings of the 20th International Conference on Artificial Intelligence and Statistics vol. 54 of </span><em id="bib.bib14.10.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of Machine Learning Research</em><span id="bib.bib14.11.3" class="ltx_text" style="font-size:80%;">. PMLR ( 1273–1282).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.12.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://proceedings.mlr.press/v54/mcmahan17a.html</a><span id="bib.bib14.13.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:80%;">Lu et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:80%;">
Lu, W., Wang, J., Chen, Y., Qin, X., Xu, R., Dimitriadis, D., and Qin, T. (2022). Personalized Federated Learning with Adaptive Batchnorm for Healthcare.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Big Data ( 1–1). doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TBDATA.2022.3177197" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TBDATA.2022.3177197</span></a><span id="bib.bib15.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:80%;">Li et al. 2020</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:80%;">
Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith, V. (2020). Federated Optimization in Heterogeneous Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:80%;">Proceedings of Machine learning and systems </span><em id="bib.bib16.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">2</em><span id="bib.bib16.10.3" class="ltx_text" style="font-size:80%;">, 429–450. URL: </span><a target="_blank" href="https://proceedings.mlsys.org/paper_files/paper/2020/file/1f5fe83998a09396ebe6477d9475ba0c-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://proceedings.mlsys.org/paper_files/paper/2020/file/1f5fe83998a09396ebe6477d9475ba0c-Paper.pdf</a><span id="bib.bib16.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:80%;">Li et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:80%;">
Li, X., Jiang, M., Zhang, X., Kamp, M., and Dou, Q. (2021).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:80%;">FedBN: Federated Learning on Non-IID Features via Local Batch Normalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.9.1" class="ltx_text" style="font-size:80%;">In: International Conference on Learning Representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.10.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://openreview.net/pdf?id=6YEQUn0QICG" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://openreview.net/pdf?id=6YEQUn0QICG</a><span id="bib.bib17.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:80%;">Zhu et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:80%;">
Zhu, Z., Hong, J., and Zhou, J. (2021). Data-Free Knowledge Distillation for Heterogeneous Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:80%;">Proceedings of machine learning research </span><em id="bib.bib18.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">139</em><span id="bib.bib18.10.3" class="ltx_text" style="font-size:80%;">, 12878–12889. URL: </span><a target="_blank" href="https://proceedings.mlr.press/v139/zhu21b.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://proceedings.mlr.press/v139/zhu21b.html</a><span id="bib.bib18.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:80%;">Khan et al. 2024</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:80%;">
Khan, H., Bouaynaya, N. C., and Rasool, G. (2024). Brain-inspired continual learning: Robust feature distillation and re-consolidation for class incremental learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:80%;">IEEE Access. URL: </span><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10443885" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://ieeexplore.ieee.org/abstract/document/10443885</a><span id="bib.bib19.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:80%;">Liu et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:80%;">
Liu, L., Jiang, X., Zheng, F., Chen, H., Qi, G.-J., Huang, H., and Shao, L. (2021). A Bayesian Federated Learning Framework with Online Laplace Approximation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:80%;">IEEE transactions on pattern analysis and machine intelligence </span><em id="bib.bib20.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">PP</em><span id="bib.bib20.10.3" class="ltx_text" style="font-size:80%;">. URL: </span><a target="_blank" href="https://doi.org/10.1109/TPAMI.2023.3322743" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.1109/TPAMI.2023.3322743</a><span id="bib.bib20.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:80%;">Yu et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:80%;">
Yu, Y., Wei, A., Karimireddy, S. P., Ma, Y., and Jordan, M. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:80%;">TCT: Convexifying Federated Learning using Bootstrapped Neural Tangent Kernels.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:80%;">In: Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., eds. Advances in Neural Information Processing Systems vol. 35. ( 30882–30897).
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:80%;">Huang et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:80%;">
Huang, W., Ye, M., and Du, B. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:80%;">Learn from others and be yourself in heterogeneous federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text" style="font-size:80%;">In: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). ( 10133–10143).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.10.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/CVPR52688.2022.00990" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/CVPR52688.2022.00990</span></a><span id="bib.bib22.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:80%;">Zhou et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:80%;">
Zhou, T., Zhang, J., and Tsang, D. H. (2023). FedFA: Federated Learning with Feature Anchors to Align Features and Classifiers for Heterogeneous Data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Mobile Computing ( 1–12). doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TMC.2023.3325366" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TMC.2023.3325366</span></a><span id="bib.bib23.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:80%;">Warnat-Herresthal et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:80%;">
Warnat-Herresthal, S., Schultze, H., Shastry, K., Manamohan, S., Mukherjee, S., Garg, V., Sarveswara, R., Händler, K., Pickkers, P., Aziz, N. A., Breteler, M., Giamarellos-Bourboulis, E., Kox, M., Becker, M., Cheran, S., Woodacre, M., Goh, E., Schultze, J., and Grundmann, H. (2021). Swarm learning for decentralized and confidential clinical machine learning.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:80%;">Kalra et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:80%;">
Kalra, S., Wen, J., Cresswell, J. C., Volkovs, M., and Tizhoosh, H. R. (2023). Decentralized Federated Learning through Proxy Model Sharing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:80%;">Nature Communications </span><em id="bib.bib25.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">14</em><span id="bib.bib25.10.3" class="ltx_text" style="font-size:80%;">, 2899. doi:</span><a target="_blank" href="http://dx.doi.org/10.1038/s41467-023-38569-4" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1038/s41467-023-38569-4</span></a><span id="bib.bib25.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:80%;">Butt et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:80%;">
Butt, M., Tariq, N., Ashraf, M., Alsagri, H. S., Moqurrab, S. A., Alhakbani, H. A. A., and Alduraywish, Y. A. (2023). A fog-based privacy-preserving federated learning system for smart healthcare applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:80%;">Electronics </span><em id="bib.bib26.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">12</em><span id="bib.bib26.10.3" class="ltx_text" style="font-size:80%;">. URL: </span><a target="_blank" href="https://www.mdpi.com/2079-9292/12/19/4074" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://www.mdpi.com/2079-9292/12/19/4074</a><span id="bib.bib26.11.4" class="ltx_text" style="font-size:80%;">. doi:</span><a target="_blank" href="http://dx.doi.org/10.3390/electronics12194074" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.3390/electronics12194074</span></a><span id="bib.bib26.12.5" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:80%;">Zhang et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:80%;">
Zhang, X., Li, Y., Li, W., Guo, K., and Shao, Y. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text" style="font-size:80%;">Personalized federated learning via variational Bayesian inference.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:80%;">In: Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and Sabato, S., eds. Proceedings of the 39th International Conference on Machine Learning vol. 162 of </span><em id="bib.bib27.10.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of Machine Learning Research</em><span id="bib.bib27.11.3" class="ltx_text" style="font-size:80%;">. PMLR ( 26293–26310).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.12.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://proceedings.mlr.press/v162/zhang22o.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://proceedings.mlr.press/v162/zhang22o.html</a><span id="bib.bib27.13.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:80%;">Kotelevskii et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:80%;">
Kotelevskii, N., Vono, M., Durmus, A., and Moulines, E. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:80%;">FedPop: A Bayesian Approach for Personalised Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text" style="font-size:80%;">In: Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., eds. Advances in Neural Information Processing Systems vol. 35. Curran Associates, Inc. ( 8687–8701).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.10.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/395409679270591fd2a70abc694cf5a1-Paper-Conference.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://proceedings.neurips.cc/paper_files/paper/2022/file/395409679270591fd2a70abc694cf5a1-Paper-Conference.pdf</a><span id="bib.bib28.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:80%;">Chen et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:80%;">
Chen, H., Ding, J., Tramel, E. W., Wu, S., Sahu, A. K., Avestimehr, S., and Zhang, T. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:80%;">Self-aware personalized federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text" style="font-size:80%;">In: Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., eds. Advances in Neural Information Processing Systems vol. 35. Curran Associates, Inc. ( 20675–20688).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.10.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8265d7bb2db42e86637001db2c46619f-Paper-Conference.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://proceedings.neurips.cc/paper_files/paper/2022/file/8265d7bb2db42e86637001db2c46619f-Paper-Conference.pdf</a><span id="bib.bib29.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:80%;">Wei et al. 2020</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:80%;">
Wei, K., Li, J., Ding, M., Ma, C., Yang, H. H., Farokhi, F., Jin, S., Quek, T. Q. S., and Vincent Poor, H. (2020). Federated learning with differential privacy: Algorithms and performance analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Information Forensics and Security </span><em id="bib.bib30.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">15</em><span id="bib.bib30.10.3" class="ltx_text" style="font-size:80%;">, 3454–3469. doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TIFS.2020.2988575" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TIFS.2020.2988575</span></a><span id="bib.bib30.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:80%;">Dhiman et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:80%;">
Dhiman, S., Nayak, S., Mahato, G. K., Ram, A., and Chakraborty, S. K. (2023).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:80%;">Homomorphic encryption based federated learning for financial data security.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:80%;">In: IEEE International Conference on Innovations in Computer Science and Engineering (I3CS).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.10.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/I3CS58314.2023.10127502" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/I3CS58314.2023.10127502</span></a><span id="bib.bib31.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:80%;">Stripelis et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:80%;">
Stripelis, D., Saleem, H., Ghai, T., Dhinagar, N. J., Gupta, U., Anastasiou, C., Steeg, G. V., Ravi, S., Naveed, M., Thompson, P. M., and Ambite, J. (2021).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:80%;">Secure neuroimaging analysis using federated learning with homomorphic encryption.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.9.1" class="ltx_text" style="font-size:80%;">In: SPIE Medical Imaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.10.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.1117/12.2606256" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1117/12.2606256</span></a><span id="bib.bib32.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:80%;">Acar et al. 2018</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:80%;">
Acar, A., Aksu, H., Uluagac, A. S., and Conti, M. (2018). A Survey on Homomorphic Encryption Schemes: Theory and Implementation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.8.1" class="ltx_text" style="font-size:80%;">ACM Comput. Surv. </span><em id="bib.bib33.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">51</em><span id="bib.bib33.10.3" class="ltx_text" style="font-size:80%;">. doi:</span><a target="_blank" href="http://dx.doi.org/10.1145/3214303" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1145/3214303</span></a><span id="bib.bib33.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:80%;">Truhn et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:80%;">
Truhn, D., Arasteh, S. T., Saldanha, O. L., Müller-Franzes, G., Khader, F., Quirke, P., West, N. P., Gray, R., Hutchins, G. G., James, J. A., Loughrey, M. B., Salto-Tellez, M., Brenner, H., Brobeil, A., Yuan, T., Chang-Claude, J., Hoffmeister, M., Foersch, S., Han, T., Keil, S., Schulze-Hagen, M., Isfort, P., Bruners, P., Kaissis, G., Kuhl, C., Nebelung, S., and Kather, J. N. (2023). Encrypted federated learning for secure decentralized collaboration in cancer image analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.8.1" class="ltx_text" style="font-size:80%;">Medical Image Analysis ( 103059). doi:</span><a target="_blank" href="http://dx.doi.org/https://doi.org/10.1016/j.media.2023.103059" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">https://doi.org/10.1016/j.media.2023.103059</span></a><span id="bib.bib34.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:80%;">Truex et al. 2019</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:80%;">
Truex, S., Baracaldo, N., Anwar, A., Steinke, T., Ludwig, H., Zhang, R., and Zhou, Y. (2019).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:80%;">A Hybrid Approach to Privacy-Preserving Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text" style="font-size:80%;">AISec’19 New York, NY, USA: Association for Computing Machinery.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.10.1" class="ltx_text" style="font-size:80%;">ISBN 9781450368339 ( 1–11).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.11.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.1145/3338501.3357370" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1145/3338501.3357370</span></a><span id="bib.bib35.12.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:80%;">Qi et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:80%;">
Qi, T., Wu, F., Wu, C., He, L., Huang, Y., and Xie, X. (2023). Differentially Private Knowledge Transfer for Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:80%;">Nature Communications </span><em id="bib.bib36.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">14</em><span id="bib.bib36.10.3" class="ltx_text" style="font-size:80%;">, 3785. doi:</span><a target="_blank" href="http://dx.doi.org/10.1038/s41467-023-38794-x" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1038/s41467-023-38794-x</span></a><span id="bib.bib36.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:80%;">So et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:80%;">
So, J., Ali, R. E., Güler, B., Jiao, J., and Avestimehr, A. S. (2023).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:80%;">Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.9.1" class="ltx_text" style="font-size:80%;">AAAI’23/IAAI’23/EAAI’23 AAAI Press.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.10.1" class="ltx_text" style="font-size:80%;">ISBN 978-1-57735-880-0.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.11.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.1609/aaai.v37i8.26177" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1609/aaai.v37i8.26177</span></a><span id="bib.bib37.12.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:80%;">Wang et al. 2024</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:80%;">
Wang, T., Yang, Q., Zhu, K., Wang, J., Su, C., and Sato, K. (2024). Lds-fl: Loss differential strategy based federated learning for privacy preserving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Information Forensics and Security </span><em id="bib.bib38.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">19</em><span id="bib.bib38.10.3" class="ltx_text" style="font-size:80%;">, 1015–1030. doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TIFS.2023.3322328" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TIFS.2023.3322328</span></a><span id="bib.bib38.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:80%;">Xu et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:80%;">
Xu, R., Baracaldo, N., Zhou, Y., Anwar, A., Kadhe, S., and Ludwig, H. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text" style="font-size:80%;">DeTrust-FL: Privacy-Preserving Federated Learning in Decentralized Trust Setting.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:80%;">In: 2022 IEEE 15th International Conference on Cloud Computing (CLOUD). IEEE ( 417–426).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.10.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://doi.org/10.1109/CLOUD55607.2022.00065" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.1109/CLOUD55607.2022.00065</a><span id="bib.bib39.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:80%;">Dera et al. 2024</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:80%;">
Dera, D., Ahmed, S., Bouaynaya, N., and Rasool, G. (2024). TRustworthy Uncertainty Propagation for Sequential Time-Series Analysis in RNNs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Knowledge &amp; Data Engineering </span><em id="bib.bib40.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">36</em><span id="bib.bib40.10.3" class="ltx_text" style="font-size:80%;">, 882–896. doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TKDE.2023.3288628" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TKDE.2023.3288628</span></a><span id="bib.bib40.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text" style="font-size:80%;">Shi et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:80%;">
Shi, N., Lai, F., Kontar, R. A., and Chowdhury, M. (2023). Fed-ensemble: Ensemble models in federated learning for improved generalization and uncertainty quantification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text" style="font-size:80%;">IEEE Transactions on Automation Science and Engineering ( 1–0). doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/TASE.2023.3269639" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/TASE.2023.3269639</span></a><span id="bib.bib41.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:80%;">Gammerman et al. 1998</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text" style="font-size:80%;">
Gammerman, A., Vovk, V., and Vapnik, V. (1998).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text" style="font-size:80%;">Learning by transduction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text" style="font-size:80%;">In: Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence. UAI’98 San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.10.1" class="ltx_text" style="font-size:80%;">ISBN 155860555X ( 148–155).
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:80%;">Lu et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:80%;">
Lu, C., Yu, Y., Karimireddy, S. P., Jordan, M. I., and Raskar, R. (2023).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text" style="font-size:80%;">Federated conformal predictors for distributed uncertainty quantification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.9.1" class="ltx_text" style="font-size:80%;">In: Proceedings of the 40th International Conference on Machine Learning. ICML’23 JMLR.org.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:80%;">Plassier et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:80%;">
Plassier, V., Makni, M., Rubashevskii, A., Moulines, E., and Panov, M. (2023).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:80%;">Conformal prediction for federated uncertainty quantification under label shift.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.9.1" class="ltx_text" style="font-size:80%;">In: Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J., eds. Proceedings of the 40th International Conference on Machine Learning vol. 202 of </span><em id="bib.bib44.10.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of Machine Learning Research</em><span id="bib.bib44.11.3" class="ltx_text" style="font-size:80%;">. PMLR ( 27907–27947).
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:80%;">Bhatt et al. 2024</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:80%;">
Bhatt, S., Gupta, A., and Rai, P. (2024).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text" style="font-size:80%;">Federated Learning with Uncertainty via Distilled Predictive Distributions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text" style="font-size:80%;">In: Yanıkoğlu, B., and Buntine, W., eds. Proceedings of the 15th Asian Conference on Machine Learning vol. 222 of </span><em id="bib.bib45.10.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of Machine Learning Research</em><span id="bib.bib45.11.3" class="ltx_text" style="font-size:80%;">. PMLR ( 153–168).
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:80%;">Al-Shedivat et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:80%;">
Al-Shedivat, M., Gillenwater, J., Xing, E., and Rostamizadeh, A. (2021).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text" style="font-size:80%;">Federated Learning via Posterior Inference: A New Perspective and Practical Algorithms.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.9.1" class="ltx_text" style="font-size:80%;">In: International Conference on Learning Representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.10.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://openreview.net/forum?id=GFsU8a0sGB" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://openreview.net/forum?id=GFsU8a0sGB</a><span id="bib.bib46.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:80%;">Luo et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:80%;">
Luo, M., Chen, F., Hu, D., Zhang, Y., Liang, J., and Feng, J. (2021). No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text" style="font-size:80%;">Advances in Neural Information Processing Systems </span><em id="bib.bib47.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">34</em><span id="bib.bib47.10.3" class="ltx_text" style="font-size:80%;">, 5972–5984. URL: </span><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/2f2b265625d76a6704b08093c652fd79-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://proceedings.neurips.cc/paper_files/paper/2021/file/2f2b265625d76a6704b08093c652fd79-Paper.pdf</a><span id="bib.bib47.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:80%;">Peng et al. 2024</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:80%;">
Peng, H., Yu, H., Tang, X., and Li, X. (2024).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text" style="font-size:80%;">FedCal: Achieving Local and Global Calibration in Federated Learning via Aggregated Parameterized Scaler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.9.1" class="ltx_text" style="font-size:80%;">In: Salakhutdinov, R., Kolter, Z., Heller, K., Weller, A., Oliver, N., Scarlett, J., and Berkenkamp, F., eds. Forty-first International Conference on Machine Learning vol. 235 of </span><em id="bib.bib48.10.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of Machine Learning Research</em><span id="bib.bib48.11.3" class="ltx_text" style="font-size:80%;">. PMLR.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.12.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://openreview.net/forum?id=XecUTmB9yD" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://openreview.net/forum?id=XecUTmB9yD</a><span id="bib.bib48.13.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:80%;">Roth et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text" style="font-size:80%;">
Roth, H., Cheng, Y., Wen, Y., Yang, I., Xu, Z., Hsieh, Y.-T., Kersten, K., Harouni, A., Zhao, C., Lu, K., Zhang, Z., Li, W., Myronenko, A., Yang, D., Yang, S., Rieke, N., Quraini, A., Chen, C., Xu, D., and Feng, A. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text" style="font-size:80%;">NVIDIA FLARE: Federated Learning from Simulation to Real-World.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.9.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.48550/arXiv.2210.13291" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.48550/arXiv.2210.13291</span></a><span id="bib.bib49.10.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.4.4.1" class="ltx_text" style="font-size:80%;">Patrick Foley and Micah J Sheller and Brandon Edwards and Sarthak Pati and Walter Riviera and Mansi Sharma and Prakash Narayana Moorthy and Shih-han Wang and Jason Martin and Parsa Mirhaji and Prashant Shah and Spyridon Bakas 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.6.1" class="ltx_text" style="font-size:80%;">
Patrick Foley and Micah J Sheller and Brandon Edwards and Sarthak Pati and Walter Riviera and Mansi Sharma and Prakash Narayana Moorthy and Shih-han Wang and Jason Martin and Parsa Mirhaji and Prashant Shah and Spyridon Bakas (2022). OpenFL: the open federated learning library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text" style="font-size:80%;">Physics in Medicine &amp; Biology </span><em id="bib.bib50.8.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">67</em><span id="bib.bib50.9.3" class="ltx_text" style="font-size:80%;">, 214001. doi:</span><a target="_blank" href="http://dx.doi.org/10.1088/1361-6560/ac97d9" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1088/1361-6560/ac97d9</span></a><span id="bib.bib50.10.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:80%;">Cremonesi et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.7.1" class="ltx_text" style="font-size:80%;">
Cremonesi, F., Vesin, M., Cansiz, S., Bouillard, Y., Balelli, I., Innocenti, L., Silva, S., Ayed, S.-S., Taiello, R., Kameni, L., Vidal, R., Orlhac, F., Nioche, C., Lapel, N., Houis, B., Modzelewski, R., Humbert, O., Önen, M., and Lorenzi, M. (2023).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.8.1" class="ltx_text" style="font-size:80%;">Fed-BioMed: Open, Transparent and Trusted Federated Learning for Real-world Healthcare Applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.9.1" class="ltx_text" style="font-size:80%;">URL: </span><a target="_blank" href="https://arxiv.org/abs/2304.12012" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://arxiv.org/abs/2304.12012</a><span id="bib.bib51.10.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:80%;">Ryu et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text" style="font-size:80%;">
Ryu, M., Kim, Y., Kim, K., and Madduri, R. K. (2022).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.8.1" class="ltx_text" style="font-size:80%;">APPFL: Open-Source Software Framework for Privacy-Preserving Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text" style="font-size:80%;">In: 2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW). Los Alamitos, CA, USA: IEEE Computer Society ( 1074–1083).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.10.1" class="ltx_text" style="font-size:80%;">doi:</span><a target="_blank" href="http://dx.doi.org/10.1109/IPDPSW55747.2022.00175" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1109/IPDPSW55747.2022.00175</span></a><span id="bib.bib52.11.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.5.5.1" class="ltx_text" style="font-size:80%;">Pati et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.7.1" class="ltx_text" style="font-size:80%;">
Pati, S., Baid, U., Zenk, M., Edwards, B., Sheller, M., Reina, G. A., Foley, P., Gruzdev, A., Martin, J., Albarqouni, S. et al. (2021). The Federated Tumor Segmentation (FeTS) Challenge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.8.1" class="ltx_text" style="font-size:80%;">arXiv preprint arXiv:2105.05874. URL: </span><a target="_blank" href="https://doi.org/10.48550/arXiv.2105.05874" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.48550/arXiv.2105.05874</a><span id="bib.bib53.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.5.5.1" class="ltx_text" style="font-size:80%;">Pati et al. 2022</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.7.1" class="ltx_text" style="font-size:80%;">
Pati, S., Baid, U., Edwards, B., Sheller, M., Wang, S.-H., Reina, G. A., Foley, P., Gruzdev, A., Karkada, D., Davatzikos, C. et al. (2022). Federated learning enables big data for rare cancer boundary detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.8.1" class="ltx_text" style="font-size:80%;">Nature communications </span><em id="bib.bib54.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">13</em><span id="bib.bib54.10.3" class="ltx_text" style="font-size:80%;">, 7346. URL: </span><a target="_blank" href="https://doi.org/10.1038/s41467-022-33407-5" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.1038/s41467-022-33407-5</a><span id="bib.bib54.11.4" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.5.5.1" class="ltx_text" style="font-size:80%;">Dayan et al. 2021</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.7.1" class="ltx_text" style="font-size:80%;">
Dayan, I., Roth, H. R., Zhong, A., Harouni, A., Gentili, A., Abidin, A. Z., Liu, A., Costa, A. B., Wood, B. J., Tsai, C.-S. et al. (2021). Federated learning for predicting clinical outcomes in patients with covid-19.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.8.1" class="ltx_text" style="font-size:80%;">Nature Medicine </span><em id="bib.bib55.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">27</em><span id="bib.bib55.10.3" class="ltx_text" style="font-size:80%;">, 1735–1743. URL: </span><a target="_blank" href="https://www.nature.com/articles/s41591-021-01506-3" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://www.nature.com/articles/s41591-021-01506-3</a><span id="bib.bib55.11.4" class="ltx_text" style="font-size:80%;">. doi:</span><a target="_blank" href="http://dx.doi.org/10.1038/s41591-021-01506-3" title="" class="ltx_ref ltx_href" style="font-size:80%;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">10.1038/s41591-021-01506-3</span></a><span id="bib.bib55.12.5" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text" style="font-size:80%;">Makhija et al. 2023</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.7.1" class="ltx_text" style="font-size:80%;">
Makhija, D., Ghosh, J., and Ho, N. (2023). Privacy preserving bayesian federated learning in heterogeneous settings.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.8.1" class="ltx_text" style="font-size:80%;">arXiv preprint arXiv:2306.07959. URL: </span><a target="_blank" href="https://doi.org/10.48550/arXiv.2306.07959" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.48550/arXiv.2306.07959</a><span id="bib.bib56.9.2" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.16338" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.16340" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.16340">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.16340" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.16341" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 00:59:59 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
