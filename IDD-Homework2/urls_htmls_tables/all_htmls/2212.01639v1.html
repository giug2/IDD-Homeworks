<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.01639] Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests</title><meta property="og:description" content="Different types of mental rotation tests have been used extensively in psychology to understand human visual reasoning and perception. Understanding what an object or visual scene would look like from another viewpoint…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.01639">

<!--Generated on Fri Mar  1 12:26:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Christopher Beckham<sup id="id7.7.id1" class="ltx_sup"><span id="id7.7.id1.1" class="ltx_text ltx_font_italic">a,b,c</span></sup>, Martin Weiss<sup id="id8.8.id2" class="ltx_sup"><span id="id8.8.id2.1" class="ltx_text ltx_font_italic">a,c</span></sup>, Florian Golemo<sup id="id9.9.id3" class="ltx_sup"><span id="id9.9.id3.1" class="ltx_text ltx_font_italic">a,b</span></sup>, Sina Honari<sup id="id10.10.id4" class="ltx_sup"><span id="id10.10.id4.1" class="ltx_text ltx_font_italic">e</span></sup>, 
<br class="ltx_break">Derek Nowrouzezahrai<sup id="id11.11.id5" class="ltx_sup"><span id="id11.11.id5.1" class="ltx_text ltx_font_italic">a,d</span></sup> and Christopher Pal<sup id="id12.12.id6" class="ltx_sup"><span id="id12.12.id6.1" class="ltx_text ltx_font_italic">a,b,c,†</span></sup>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">Different types of <em id="id13.id1.1" class="ltx_emph ltx_font_italic">mental rotation tests</em> have been used extensively in psychology to understand human visual reasoning and perception. Understanding what an object or visual scene would look like from another viewpoint is a challenging problem that is made even harder if it must be performed from a single image. We explore a controlled setting whereby questions are posed about the properties of a scene if that scene was observed from another viewpoint. To do this we have created a new version of the CLEVR dataset that we call <em id="id13.id1.2" class="ltx_emph ltx_font_italic">CLEVR Mental Rotation Tests</em> (CLEVR-MRT). Using CLEVR-MRT we examine standard methods, show how they fall short, then explore novel neural architectures that involve inferring volumetric representations of a scene. These volumes can be manipulated via camera-conditioned transformations to answer the question. We examine the efficacy of different model variants through rigorous ablations and demonstrate the efficacy of volumetric representations.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span><sup id="footnotex1.1" class="ltx_sup"><span id="footnotex1.1.1" class="ltx_text ltx_font_italic">a</span></sup>Mila - Quebec Artificial Intelligence Institute, <sup id="footnotex1.2" class="ltx_sup"><span id="footnotex1.2.1" class="ltx_text ltx_font_italic">b</span></sup>ServiceNow Research, <sup id="footnotex1.3" class="ltx_sup"><span id="footnotex1.3.1" class="ltx_text ltx_font_italic">c</span></sup>Polytechnique Montreal, <sup id="footnotex1.4" class="ltx_sup"><span id="footnotex1.4.1" class="ltx_text ltx_font_italic">d</span></sup>McGill University, <sup id="footnotex1.5" class="ltx_sup"><span id="footnotex1.5.1" class="ltx_text ltx_font_italic">e</span></sup>EPFL, <sup id="footnotex1.6" class="ltx_sup"><span id="footnotex1.6.1" class="ltx_text ltx_font_italic">†</span></sup>Canada CIFAR AI Chair</span></span></span>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Psychologists have employed <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">mental rotation</em> tests for decades <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> as a powerful tool for devising how the human mind interprets and (internally) manipulates three dimensional representations of the world. Instead of using these tests to probe the human capacity for mental 3D manipulation, we are interested here in understanding the ability of modern deep neural architectures to perform mental rotation tasks, and building architectures better suited to 3D inference and understanding. This kind of capability finds application across a variety of visual reasoning and navigation tasks. <span id="footnotex2" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Dataset and code will be available at <a target="_blank" href="https://github.com/christopher-beckham/clevr-mrt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/christopher-beckham/clevr-mrt</a></span></span></span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recent applications of concepts from 3D graphics to deep learning have led to promising results. We are similarly interested in leveraging models of 3D image formation from the graphics and vision communities to augment neural network architectures with inductive biases that improve their ability to reason about the real world. Here we measure the effectiveness of adding such biases, confirming their ability to improve the performance of neural models on mental rotation tasks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Concepts from <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">inverse graphics</span> can be used to guide the construction of neural architectures designed to perform tasks related to the reverse of the traditional image synthesis processes: namely, taking 2D image input and inferring 3D information about the scene. For instance, 3D reconstruction in computer vision <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> can be realized with neural-based approaches that output voxel <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, mesh <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, or point cloud <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> representations of the underlying 3D scene geometry. Such inverse graphics methods range from fully-differentiable graphics pipelines <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> to implicit neural-based approaches with learnable modules designed to mimic the structure of certain components of the forward graphics pipeline <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. While inverse rendering is potentially an interesting and useful goal in itself, many computer vision systems could benefit from neural architectures that demonstrate good performance for more targeted mental rotation tasks.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In our work we are interested in exploring neural “mental rotation” by adapting a well known standard benchmark for visual question-and-answering (VQA) through answering questions with respect to another viewpoint. We use the the Compositional Language and Elementary Visual Reasoning (CLEVR) Diagnostic Dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> as the starting point for our work.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">While we focus on this well known benchmark, many analogous questions of practical interest exist. For example, given the camera viewpoint of a blind person crossing the street, can we infer if each of the drivers of the cars at an intersection can see this person? As humans, we are endowed with the ability to reason about scenes and imagine them from different viewpoints, even if we have only seen them from one perspective. As noted by others, it therefore seems intuitive that we should encourage the same capabilities in deep neural networks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. In order to answer such questions effectively, some sort of representation encoding 3D information seems necessary to permit inferences to be drawn due to a change in the orientation and position of the viewpoint camera. However, humans clearly do not have access to error signals obtained through re-rendering scenes, but are able to perform such tasks. To explore these problems in a controlled setting, we adapt the original CLEVR setup in which a VQA model is trained to answer different types of questions about a scene consisting of various types and colours of objects. While images from the original dataset are generated through the rendering of randomly generated 3D scenes, the three-dimensional structure of the scene is never fully exploited because the viewpoint camera never changes. We call our problem formulation and data set <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em>, as it is a new <em id="S1.p5.1.2" class="ltx_emph ltx_font_italic">Mental Rotation Test</em> version of the CLEVR problem setup.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In CLEVR-MRT alternative views of a scene are rendered and used as the input to a perception pipeline that must then answer a question that is posed with respect to another (the original CLEVR) viewpoint. This gives rise to a more difficult task where the VQA model must learn how to map from its current viewpoint to the viewpoint that is required to answer the question. In Figure <a href="#S1.F1.sf1" title="In Figure 1 ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>, we motivate our dataset by depicting a real world street corner and a ‘CLEVR-like’ illustration of the scene, where questions concerning the relative positions of objects after a mental rotation could be of practical interest (e.g. intelligent intersections, cars, robots, or navigation assistants for the blind), and in Figure <a href="#S1.F1.sf2" title="In Figure 1 ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> an actual scene from <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em>.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2212.01639/assets/figures/fig1/real-world.jpg" id="S1.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="186" height="105" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2212.01639/assets/figures/fig1/normal-view.png" id="S1.F1.sf1.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="186" height="105" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2212.01639/assets/figures/fig1/rotated-view.png" id="S1.F1.sf1.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="186" height="105" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">(Left) A view of a street corner. (Middle) a CLEVR-like representation of the scene with abstractions of buildings, cars and pedestrians. (Right) The same virtual scene from another viewpoint, where questions concerning the relative positions of objects after a mental rotation could be of significant practical interest.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.01639/assets/figures/clevr_kiwi/example/ck_allcams.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="375" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.10.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F1.sf2.11.2" class="ltx_text" style="font-size:90%;">A full example of a CLEVR-MRT scene, showing 16 randomly sampled views of the scene (out of 20 in total). The canonical view is not shown here, but a sample of questions pertaining to the canonical view are:
<span id="S1.F1.sf2.11.2.1" class="ltx_text ltx_font_bold">Q</span>: Are there the same number of large gray objects that are left of the gray thing and big matte cylinders? <span id="S1.F1.sf2.11.2.2" class="ltx_text ltx_font_bold">(True)</span>;
<span id="S1.F1.sf2.11.2.3" class="ltx_text ltx_font_bold">Q</span>: Is the number of large brown things that are behind the red thing less than the number of purple objects? <span id="S1.F1.sf2.11.2.4" class="ltx_text ltx_font_bold">(True)</span>;
<span id="S1.F1.sf2.11.2.5" class="ltx_text ltx_font_bold">Q</span>: Are there more blue blocks to the left of the large gray thing than blue matte spheres? <span id="S1.F1.sf2.11.2.6" class="ltx_text ltx_font_bold">(False)</span>;
<span id="S1.F1.sf2.11.2.7" class="ltx_text ltx_font_bold">Q</span>: Are there an equal number of big brown things that are in front of the large brown rubber ball and big metal things that are behind the purple sphere? <span id="S1.F1.sf2.11.2.8" class="ltx_text ltx_font_bold">(False)</span>
</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">(a) A real-world example where the ability to perform mental rotations can be of practical utility. (b) Images from a randomly selected scene from the <em id="S1.F1.4.2.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em> dataset.</span></figcaption>
</figure>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Using our new mental rotation task definition and our CLEVR-MRT dataset, we examine a number of new inverse-graphics inspired neural architectures. We examine models that use the FILM (Feature-wise Linear Modulation) technique <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> for VQA, which delivers competitive performance using contemporary state-of-the-art convolutional networks. We observe that such methods fall short for this more challenging MRT VQA setting. This motivates us to create new architectures that involve inferring a latent <em id="S1.p7.1.1" class="ltx_emph ltx_font_italic">feature volume</em> that we subject to rigid 3D transformations (rotations and translations), in a manner that has been examined in 3D generative modelling techniques such as spatial transformers <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> as well as HoloGAN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. This can either be done through the adaptation of a pre-trained 2D encoder network, i.e. an ImageNet-based feature extractor as in Section <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a>, or through training our encoder proposed here, which is obtained through the use of contrastive learning as in Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a>. In the case of the latter model, we leverage the InfoNCE loss <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> to minimise the distance between different views of the <em id="S1.p7.1.2" class="ltx_emph ltx_font_italic">same</em> scene in a learned metric space, and conversely the opposite for views of <em id="S1.p7.1.3" class="ltx_emph ltx_font_italic">different</em> scenes altogether. However, rather than simply using a stochastic (2D) data augmentation policy to create positive pairs for the contrastive loss (e.g. random crops, resizes, and pixel perturbations), we leverage the fact that we have access to many views of each scene <em id="S1.p7.1.4" class="ltx_emph ltx_font_italic">at training time</em> and that this can be seen as a data augmentation policy operating in 3D. This in turn can be leveraged to learn an encoder that can map 2D views to a 3D latent space without assuming any extra guidance such as camera extrinsics.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Note that the specific formulation of the VQA task differs slightly from the analogy we have proposed, due to technical and pragmatic reasons: rather than having the viewpoint camera be unknown and the canonical camera being giiven or inferred from a ‘landmark’, we instead have the opposite but slightly less intuitive interpretation, which is that the viewpoint camera is known and the canonical viewpoint is unknown. This is just a minor difference however. As we will see later, due to the many views available per scene and the fact that this task is supervised with respect to question/answer pairs, the problem can still be addressed.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Related work</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Several extensions of the CLEVR dataset exist, though they mainly focus on extensions to the language processing elements of the problem setup, exploring themes such as: systematic generalisation <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, adding dialogue <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, and robust captioning of changes between scenes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. In terms of visual-based extensions, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> proposed a temporal version of CLEVR which looks at VQA in the context of causal and counterfactual reasoning. Concurrent to our work, a version of CLEVR has recently been proposed <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> in the context of reinforcement learning, where an agent is trained to perform viewpoint <em id="S1.SS1.p1.1.1" class="ltx_emph ltx_font_italic">selection</em> on a scene to be able to answer the question, with each scene consisting of a large occluder object in the center to accentuate occlusions. However, the main difference is that our dataset decouples the camera viewpoint from the viewpoint from which the question must be answered. Furthermore, their dataset has relatively limited question and scene variability (for instance, focusing on only two types of questions and the same occluding object in the center). We also do not assume the VQA model is an agent that is able actively change its viewpoint to better answer the question – instead, our model must learn to ‘imagine’ what the same scene should look like from another perspective, conditioned only on a single view. The most closely related work to ours explores the incorporation of 3D information into a FILM-based pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, though this is done by conditioning on multiple views of the same scene at inference time either through pooling the features of those views or through a scene representation network <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Their main motivating factor for their work is to address the issue of occlusions which cannot be easily resolved under a single view setting. In contrast we examine mental rotation-based reasoning where the input is a single image and a 3D latent volume has to be inferred from it. Lastly, their proposed dataset has limited variability compared to ours, with only four equally spaced camera rotations (every <math id="S1.SS1.p1.1.m1.1" class="ltx_Math" alttext="90^{\circ}" display="inline"><semantics id="S1.SS1.p1.1.m1.1a"><msup id="S1.SS1.p1.1.m1.1.1" xref="S1.SS1.p1.1.m1.1.1.cmml"><mn id="S1.SS1.p1.1.m1.1.1.2" xref="S1.SS1.p1.1.m1.1.1.2.cmml">90</mn><mo id="S1.SS1.p1.1.m1.1.1.3" xref="S1.SS1.p1.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S1.SS1.p1.1.m1.1b"><apply id="S1.SS1.p1.1.m1.1.1.cmml" xref="S1.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S1.SS1.p1.1.m1.1.1.1.cmml" xref="S1.SS1.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S1.SS1.p1.1.m1.1.1.2.cmml" xref="S1.SS1.p1.1.m1.1.1.2">90</cn><compose id="S1.SS1.p1.1.m1.1.1.3.cmml" xref="S1.SS1.p1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.p1.1.m1.1c">90^{\circ}</annotation></semantics></math>) at a fixed elevation.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Our work is very closely related to single view reconstruction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> because at inference time the VQA model is only being conditioned on a single view, and so the network must infer as much as possible about the scene in order to answer the question. While single view reconstruction constitutes a very difficult learning scenario, the requirement that only a single view be needed makes it a very interesting and pragmatic line of research for problem domains where data collection is difficult. Single view reconstruction has a wide variety of applications ranging from 3D facial reconstruction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, to pose estimation for anatomical structures in medical imagery <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, to image super-resolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and the reconstruction of 3D objects in general <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Since single views make it impossible to resolve issues relating to occlusion, prior information must be integrated into the learning algorithm to infer any missing details. Classically this is done through hand-crafted and highly engineered solutions. In the case of deep neural networks however one way this can be achieved is through transfer learning, where a network that is pre-trained on one task is repurposed for another. It is usually assumed that the new task contains relatively fewer examples, labels, or lower quality data than the former, hence the need to ‘transfer’ knowledge to the latter. For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> considers the task of performing 3D reconstruction of an indoor scene from a single 2D image. Their architectures leverages a Mask R-CNN backbone <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> that was originally trained on MS-COCO (<math id="S1.SS1.p2.1.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="S1.SS1.p2.1.m1.1a"><mo id="S1.SS1.p2.1.m1.1.1" xref="S1.SS1.p2.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S1.SS1.p2.1.m1.1b"><geq id="S1.SS1.p2.1.m1.1.1.cmml" xref="S1.SS1.p2.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.p2.1.m1.1c">\geq</annotation></semantics></math> 300K images and rich labels), which is subsequently repurposed for their indoor scene dataset. Since MS-COCO constitutes an ample number of real world occlusions, it is assumed that knowledge about how to resolve them (baked into the pre-trained R-CNN network) can be repurposed for a smaller but more specialised dataset, in this case indoor scenes. Similarly in our work, we consider two types of pre-trained network for our VQA pipeline: an ImageNet classifier, and our own which leverages contrastive learning.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, they also explore the way in which visual question answering techniques could be used to enhance the quality of 3D scene representations based on traditional computer graphics CAD models. In their work these questions really serve as a form of auxiliary task, aiding their primary goal of creating these CAD based scene representations. In contrast, in our work we focus on learning completely neural representations in which the final goal is always that of answering a question regarding the scene, encoded in natural language. Recent work on Neural Radiance Fields <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> has shown great promise for representing pixel level details of 3D scenes, allowing scenes to be rendered from novel viewpoints using fully neural representations. In contrast, our work, focuses exclusively on visual question answering as the final goal and represents a setting where a pixel level model of the scene from an alternative viewpoint is not needed. For problems like high level navigation, e.g. directing a robot or a person to location containing an object at a particular location), our method operating at a completely semantic level of abstraction, allows models of lower complexity to be used because our models do not need to reconstruct new viewpoints.</p>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p id="S1.SS1.p4.1" class="ltx_p">The use of rigid transforms to infer latent 3D volumes was loosely inspired by HoloGAN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Here, they use a GAN to map a randomly sampled noise vector to a 3D latent volume (a voxel representation) before subsequently rendering using a neural renderer. Several works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> condition on images and camera poses to learn voxels that represent the input, with options to re-render from different camera poses. These methods, however, assume a dataset consisting of just a single scene as well as camera poses that are known. Conversely, CLEVR consists of tens of thousands of scenes, which makes any re-rendering task significantly more difficult due to the need for the renderer to generalise to all scenes. Rather than considering an approach that does both encoding and decoding (re-rendering), we only consider encoding, which is more computationally efficient. 3D latent volumes can be seen as highly compressed and feature-rich representations of their original images however, and can in principle be used to re-render a scene <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.</p>
</div>
<div id="S1.SS1.p5" class="ltx_para">
<p id="S1.SS1.p5.1" class="ltx_p">Other ways of encoding 3D data can be used such as point clouds <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, meshes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, surfels <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, latent codes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, or as an implicit neural representation such as in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Out of these modalities, representing data as 3D volumes is convenient because they can be used in conjunction with 3D convolutions without modification.</p>
</div>
<div id="S1.SS1.p6" class="ltx_para">
<p id="S1.SS1.p6.1" class="ltx_p">In terms of VQA, other models have been proposed, e.g., MAC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> proposes a memory and attention-based reasoning architecture for more interpretable VQA. While this could in principle be modified to leverage 3D volumes, FILM serves as a simpler architectural choice for analysis. More sophisticated architectural choices can also involve strongly-supervised feature extractors (e.g. Mask R-CNN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> or bounding box predictors <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>) or neuro-symbolic reasoning pipelines <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, but here we opt for a simple FILM-based architecture where the feature extractor is ‘simple’ (one whose training does not involve ‘rich’ labels like segmentation masks or bounding boxes, such as a pre-trained ImageNet classifier).</p>
</div>
<div id="S1.SS1.p7" class="ltx_para">
<p id="S1.SS1.p7.1" class="ltx_p">As for learning encoders, there has been a lot of interest in leveraging self-supervised learning as a way to learn encoders that are just as competitive as their ‘supervised’ counterparts. In the case of contrastive learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> – one particular instance of self-supervised learning – we do not assume labels for individual images but assume it is possible to define labels with respect to pairs of images. In particular, these labels can either be positive or negative, denoting some semantic relationship between the pair (e.g. does this pair of images belong the same category or not?). The main objective is to learn a latent space in which pairs of inputs that should be positive are close together in that latent space, and conversely the opposite for negative pairs. Once trained, the encoder can be treated as a feature extractor to be used for future downstream tasks. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> the authors propose that such a framework can be used to maximise the mutual information across different <em id="S1.SS1.p7.1.1" class="ltx_emph ltx_font_italic">views</em> of an input, for instance different camera views within a scene, or different modalities corresponding to the same input (e.g. olfactory, visual). In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> the authors demonstrated that when positive pairs comprise stochastic 2D data augmentation operations on the same image then a resulting classifier trained on that encoder can obtain performance on par with that of its purely supervised counterpart for many benchmark image datasets including ImageNet. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, competitive results were achieved with respect to object segmentation and detection. One particular bottleneck that is common with these techniques is that of memory, since a large batch size is usually needed in order to contrast each positive pair with a significantly larger number of negative pairs, though this has been mitigated with more recent methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S1.SS1.p8" class="ltx_para">
<p id="S1.SS1.p8.1" class="ltx_p">In terms of combining such techniques with 3D, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> explored contrastive learning of scenes, though the multi-view aspect in this setting was applied to different sensory views rather than camera views. Lastly, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> explored the use of contrastive learning on 2.5D video (i.e. RGB + depth) to predict novel views, with the goal of learning 3D object detectors in a semi-supervised manner.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Proposed dataset</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">The CLEVR dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> is a VQA dataset consisting of a range of synthetic 3D shapes laid out on a canvas. The dataset consists of a range of questions designed to test various aspects of visual reasoning such as counting (e.g. ‘how many red cubes are in this scene?’), spatial relationships (e.g. ‘what colour is the cylinder to the left of the big brown cube?’) and comparisons (e.g. ‘are there an equal number of blue objects as red ones?’). In recent years however, proposed techniques have performed extraordinarily well on the dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, which has inspired us to explore VQA in more difficult contexts.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p">The original CLEVR dataset provided one image for each scene. <em id="S1.SS2.p2.1.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em> contains 20 images generated for each scene holding a constant altitude and sampling over azimuthal angle. To ensure that the model would not have any clues as to how the view had been rotated, we replaced the asymmetrical "photo backdrop" canvas of the CLEVR dataset with a large plane and centered overhead lighting. To focus on questions with viewpoint dependent answers, we filtered the set of questions to only include those containing spatial relationships (e.g. ‘is X to the right of Y’). From the original 90 question templates, only 44 contained spatial relationships. In total, the training + validation split consists of 45,600 scenes, each containing roughly 10 questions for a total of 455,549 questions. 5% of these scenes were set aside for validation. For the test set, 10,000 scenes were generated with roughly 5 questions each, for a total of 49,670 questions. A schematic of the problem is illustrated in Figure <a href="#S1.F2" title="Figure 2 ‣ 1.2 Proposed dataset ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, and in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b) we show a concrete example of one of these scenes.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.01639/assets/x1.png" id="S1.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="252" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">Dataset schematic.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2212.01639/assets/figures/clevr-2plot-frame1.png" id="S1.F2.sf2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="140" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2212.01639/assets/figures/clevr-2plot-frame2.png" id="S1.F2.sf2.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="140" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">Two example views from one scene, with the camera position and vector plotted in 3D.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><a href="#S1.F2.sf1" title="In Figure 2 ‣ 1.2 Proposed dataset ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2(a)</span></a><span id="S1.F2.4.2" class="ltx_text" style="font-size:90%;">: Schematic of the <em id="S1.F2.4.2.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em>dataset. An image corresponding to the viewpoint camera is given as a query, but the corresponding question to answer is posed with respect to the question viewpoint. Given this image as well as the camera coordinates corresponding to the question viewpoint, the goal is to answer the question. <a href="#S1.F2.sf2" title="In Figure 2 ‣ 1.2 Proposed dataset ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(b)</span></a>: Two example views from a single scene. In each example the corresponding camera position (vector) is shown. All other dots in the point cloud denote possible camera positions. To see a full gif animation of different camera views for this particular scene, please see <a target="_blank" href="https://raw.githubusercontent.com/christopher-beckham/clevr-mrt-dataset-gen/kiwi_v3/out.gif" title="" class="ltx_ref ltx_href">here</a>.</span></figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We begin here by describing simple and strong baseline methods as well as upper bound estimates used to evaluate the performance of different techniques on this dataset. We then present our new approach to learning 3D features and two different ways to address this task.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>FILM baselines</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.6" class="ltx_p">The architecture we use is based on FILM <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, in which a pre-trained ResNet-101 classifier on ImageNet extracts features from the input images which are then fed to a succession of FILM-modulated residual blocks using the hidden state output from the GRU. As a sanity check – to ensure our models are adequately parameterised – the simplest baseline to run is one where each scene in the dataset contains only one view: the <em id="S2.SS1.p1.6.1" class="ltx_emph ltx_font_italic">canonical view</em>. In this setting, we would expect the highest validation performance since the canonical viewpoint is precisely the viewpoint that all questions are posed with respect to. The second and third baselines to run are ones where we use the <em id="S2.SS1.p1.6.2" class="ltx_emph ltx_font_italic">full dataset</em>, with and without conditioning on the viewpoint camera via FILM, respectively. This is illustrated in Figure <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, where we can see the viewpoint camera also being embedded before being concatenated to the question embedding and passed through the subsequent FILM blocks. If we let <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">S</annotation></semantics></math> denote a scene consisting of all of its camera views (images) <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\mathbf{X}</annotation></semantics></math>, the camera <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{c}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\mathbf{c}</annotation></semantics></math>, the question <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{q}" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">𝐪</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝐪</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">\mathbf{q}</annotation></semantics></math>, and its corresponding answer <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{y}" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">𝐲</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝐲</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\mathbf{y}</annotation></semantics></math>, we can describe the pipeline shown in Figure <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> as the following, with <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">\phi</annotation></semantics></math> denoting the learnable parameters:</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex1.m1.4" class="ltx_Math" alttext="\displaystyle S=(\mathbf{X},\mathbf{q},\mathbf{c},\mathbf{y})" display="inline"><semantics id="S2.Ex1.m1.4a"><mrow id="S2.Ex1.m1.4.5" xref="S2.Ex1.m1.4.5.cmml"><mi id="S2.Ex1.m1.4.5.2" xref="S2.Ex1.m1.4.5.2.cmml">S</mi><mo id="S2.Ex1.m1.4.5.1" xref="S2.Ex1.m1.4.5.1.cmml">=</mo><mrow id="S2.Ex1.m1.4.5.3.2" xref="S2.Ex1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.4.5.3.2.1" xref="S2.Ex1.m1.4.5.3.1.cmml">(</mo><mi id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml">𝐗</mi><mo id="S2.Ex1.m1.4.5.3.2.2" xref="S2.Ex1.m1.4.5.3.1.cmml">,</mo><mi id="S2.Ex1.m1.2.2" xref="S2.Ex1.m1.2.2.cmml">𝐪</mi><mo id="S2.Ex1.m1.4.5.3.2.3" xref="S2.Ex1.m1.4.5.3.1.cmml">,</mo><mi id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml">𝐜</mi><mo id="S2.Ex1.m1.4.5.3.2.4" xref="S2.Ex1.m1.4.5.3.1.cmml">,</mo><mi id="S2.Ex1.m1.4.4" xref="S2.Ex1.m1.4.4.cmml">𝐲</mi><mo stretchy="false" id="S2.Ex1.m1.4.5.3.2.5" xref="S2.Ex1.m1.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.4b"><apply id="S2.Ex1.m1.4.5.cmml" xref="S2.Ex1.m1.4.5"><eq id="S2.Ex1.m1.4.5.1.cmml" xref="S2.Ex1.m1.4.5.1"></eq><ci id="S2.Ex1.m1.4.5.2.cmml" xref="S2.Ex1.m1.4.5.2">𝑆</ci><vector id="S2.Ex1.m1.4.5.3.1.cmml" xref="S2.Ex1.m1.4.5.3.2"><ci id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1">𝐗</ci><ci id="S2.Ex1.m1.2.2.cmml" xref="S2.Ex1.m1.2.2">𝐪</ci><ci id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3">𝐜</ci><ci id="S2.Ex1.m1.4.4.cmml" xref="S2.Ex1.m1.4.4">𝐲</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.4c">\displaystyle S=(\mathbf{X},\mathbf{q},\mathbf{c},\mathbf{y})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex1.m2.1" class="ltx_Math" alttext="\displaystyle\sim\mathcal{D}\text{ (sample a scene)}" display="inline"><semantics id="S2.Ex1.m2.1a"><mrow id="S2.Ex1.m2.1.1" xref="S2.Ex1.m2.1.1.cmml"><mi id="S2.Ex1.m2.1.1.2" xref="S2.Ex1.m2.1.1.2.cmml"></mi><mo id="S2.Ex1.m2.1.1.1" xref="S2.Ex1.m2.1.1.1.cmml">∼</mo><mrow id="S2.Ex1.m2.1.1.3" xref="S2.Ex1.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex1.m2.1.1.3.2" xref="S2.Ex1.m2.1.1.3.2.cmml">𝒟</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m2.1.1.3.1" xref="S2.Ex1.m2.1.1.3.1.cmml">​</mo><mtext id="S2.Ex1.m2.1.1.3.3" xref="S2.Ex1.m2.1.1.3.3a.cmml"> (sample a scene)</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m2.1b"><apply id="S2.Ex1.m2.1.1.cmml" xref="S2.Ex1.m2.1.1"><csymbol cd="latexml" id="S2.Ex1.m2.1.1.1.cmml" xref="S2.Ex1.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S2.Ex1.m2.1.1.2.cmml" xref="S2.Ex1.m2.1.1.2">absent</csymbol><apply id="S2.Ex1.m2.1.1.3.cmml" xref="S2.Ex1.m2.1.1.3"><times id="S2.Ex1.m2.1.1.3.1.cmml" xref="S2.Ex1.m2.1.1.3.1"></times><ci id="S2.Ex1.m2.1.1.3.2.cmml" xref="S2.Ex1.m2.1.1.3.2">𝒟</ci><ci id="S2.Ex1.m2.1.1.3.3a.cmml" xref="S2.Ex1.m2.1.1.3.3"><mtext id="S2.Ex1.m2.1.1.3.3.cmml" xref="S2.Ex1.m2.1.1.3.3"> (sample a scene)</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m2.1c">\displaystyle\sim\mathcal{D}\text{ (sample a scene)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex2.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{x}" display="inline"><semantics id="S2.Ex2.m1.1a"><mi id="S2.Ex2.m1.1.1" xref="S2.Ex2.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.1b"><ci id="S2.Ex2.m1.1.1.cmml" xref="S2.Ex2.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.1c">\displaystyle\mathbf{x}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex2.m2.1" class="ltx_Math" alttext="\displaystyle\sim\mathbf{X}\text{ (sample a random view)}" display="inline"><semantics id="S2.Ex2.m2.1a"><mrow id="S2.Ex2.m2.1.1" xref="S2.Ex2.m2.1.1.cmml"><mi id="S2.Ex2.m2.1.1.2" xref="S2.Ex2.m2.1.1.2.cmml"></mi><mo id="S2.Ex2.m2.1.1.1" xref="S2.Ex2.m2.1.1.1.cmml">∼</mo><mrow id="S2.Ex2.m2.1.1.3" xref="S2.Ex2.m2.1.1.3.cmml"><mi id="S2.Ex2.m2.1.1.3.2" xref="S2.Ex2.m2.1.1.3.2.cmml">𝐗</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m2.1.1.3.1" xref="S2.Ex2.m2.1.1.3.1.cmml">​</mo><mtext id="S2.Ex2.m2.1.1.3.3" xref="S2.Ex2.m2.1.1.3.3a.cmml"> (sample a random view)</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m2.1b"><apply id="S2.Ex2.m2.1.1.cmml" xref="S2.Ex2.m2.1.1"><csymbol cd="latexml" id="S2.Ex2.m2.1.1.1.cmml" xref="S2.Ex2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S2.Ex2.m2.1.1.2.cmml" xref="S2.Ex2.m2.1.1.2">absent</csymbol><apply id="S2.Ex2.m2.1.1.3.cmml" xref="S2.Ex2.m2.1.1.3"><times id="S2.Ex2.m2.1.1.3.1.cmml" xref="S2.Ex2.m2.1.1.3.1"></times><ci id="S2.Ex2.m2.1.1.3.2.cmml" xref="S2.Ex2.m2.1.1.3.2">𝐗</ci><ci id="S2.Ex2.m2.1.1.3.3a.cmml" xref="S2.Ex2.m2.1.1.3.3"><mtext id="S2.Ex2.m2.1.1.3.3.cmml" xref="S2.Ex2.m2.1.1.3.3"> (sample a random view)</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m2.1c">\displaystyle\sim\mathbf{X}\text{ (sample a random view)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex3.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{h}" display="inline"><semantics id="S2.Ex3.m1.1a"><mi id="S2.Ex3.m1.1.1" xref="S2.Ex3.m1.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.Ex3.m1.1b"><ci id="S2.Ex3.m1.1.1.cmml" xref="S2.Ex3.m1.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex3.m1.1c">\displaystyle\mathbf{h}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex3.m2.1" class="ltx_Math" alttext="\displaystyle:=\text{encode}(\mathbf{x})" display="inline"><semantics id="S2.Ex3.m2.1a"><mrow id="S2.Ex3.m2.1.2" xref="S2.Ex3.m2.1.2.cmml"><mi id="S2.Ex3.m2.1.2.2" xref="S2.Ex3.m2.1.2.2.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex3.m2.1.2.1" xref="S2.Ex3.m2.1.2.1.cmml">:=</mo><mrow id="S2.Ex3.m2.1.2.3" xref="S2.Ex3.m2.1.2.3.cmml"><mtext id="S2.Ex3.m2.1.2.3.2" xref="S2.Ex3.m2.1.2.3.2a.cmml">encode</mtext><mo lspace="0em" rspace="0em" id="S2.Ex3.m2.1.2.3.1" xref="S2.Ex3.m2.1.2.3.1.cmml">​</mo><mrow id="S2.Ex3.m2.1.2.3.3.2" xref="S2.Ex3.m2.1.2.3.cmml"><mo stretchy="false" id="S2.Ex3.m2.1.2.3.3.2.1" xref="S2.Ex3.m2.1.2.3.cmml">(</mo><mi id="S2.Ex3.m2.1.1" xref="S2.Ex3.m2.1.1.cmml">𝐱</mi><mo stretchy="false" id="S2.Ex3.m2.1.2.3.3.2.2" xref="S2.Ex3.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex3.m2.1b"><apply id="S2.Ex3.m2.1.2.cmml" xref="S2.Ex3.m2.1.2"><csymbol cd="latexml" id="S2.Ex3.m2.1.2.1.cmml" xref="S2.Ex3.m2.1.2.1">assign</csymbol><csymbol cd="latexml" id="S2.Ex3.m2.1.2.2.cmml" xref="S2.Ex3.m2.1.2.2">absent</csymbol><apply id="S2.Ex3.m2.1.2.3.cmml" xref="S2.Ex3.m2.1.2.3"><times id="S2.Ex3.m2.1.2.3.1.cmml" xref="S2.Ex3.m2.1.2.3.1"></times><ci id="S2.Ex3.m2.1.2.3.2a.cmml" xref="S2.Ex3.m2.1.2.3.2"><mtext id="S2.Ex3.m2.1.2.3.2.cmml" xref="S2.Ex3.m2.1.2.3.2">encode</mtext></ci><ci id="S2.Ex3.m2.1.1.cmml" xref="S2.Ex3.m2.1.1">𝐱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex3.m2.1c">\displaystyle:=\text{encode}(\mathbf{x})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex4.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{e}_{\text{cam}}" display="inline"><semantics id="S2.Ex4.m1.1a"><msub id="S2.Ex4.m1.1.1" xref="S2.Ex4.m1.1.1.cmml"><mi id="S2.Ex4.m1.1.1.2" xref="S2.Ex4.m1.1.1.2.cmml">𝐞</mi><mtext id="S2.Ex4.m1.1.1.3" xref="S2.Ex4.m1.1.1.3a.cmml">cam</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.Ex4.m1.1b"><apply id="S2.Ex4.m1.1.1.cmml" xref="S2.Ex4.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex4.m1.1.1.1.cmml" xref="S2.Ex4.m1.1.1">subscript</csymbol><ci id="S2.Ex4.m1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.2">𝐞</ci><ci id="S2.Ex4.m1.1.1.3a.cmml" xref="S2.Ex4.m1.1.1.3"><mtext mathsize="70%" id="S2.Ex4.m1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.3">cam</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m1.1c">\displaystyle\mathbf{e}_{\text{cam}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex4.m2.1" class="ltx_Math" alttext="\displaystyle:=\text{embed}_{\phi}^{\text{(film)}}(\mathbf{c})" display="inline"><semantics id="S2.Ex4.m2.1a"><mrow id="S2.Ex4.m2.1.2" xref="S2.Ex4.m2.1.2.cmml"><mi id="S2.Ex4.m2.1.2.2" xref="S2.Ex4.m2.1.2.2.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex4.m2.1.2.1" xref="S2.Ex4.m2.1.2.1.cmml">:=</mo><mrow id="S2.Ex4.m2.1.2.3" xref="S2.Ex4.m2.1.2.3.cmml"><msubsup id="S2.Ex4.m2.1.2.3.2" xref="S2.Ex4.m2.1.2.3.2.cmml"><mtext id="S2.Ex4.m2.1.2.3.2.2.2" xref="S2.Ex4.m2.1.2.3.2.2.2a.cmml">embed</mtext><mi id="S2.Ex4.m2.1.2.3.2.2.3" xref="S2.Ex4.m2.1.2.3.2.2.3.cmml">ϕ</mi><mtext id="S2.Ex4.m2.1.2.3.2.3" xref="S2.Ex4.m2.1.2.3.2.3a.cmml">(film)</mtext></msubsup><mo lspace="0em" rspace="0em" id="S2.Ex4.m2.1.2.3.1" xref="S2.Ex4.m2.1.2.3.1.cmml">​</mo><mrow id="S2.Ex4.m2.1.2.3.3.2" xref="S2.Ex4.m2.1.2.3.cmml"><mo stretchy="false" id="S2.Ex4.m2.1.2.3.3.2.1" xref="S2.Ex4.m2.1.2.3.cmml">(</mo><mi id="S2.Ex4.m2.1.1" xref="S2.Ex4.m2.1.1.cmml">𝐜</mi><mo stretchy="false" id="S2.Ex4.m2.1.2.3.3.2.2" xref="S2.Ex4.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex4.m2.1b"><apply id="S2.Ex4.m2.1.2.cmml" xref="S2.Ex4.m2.1.2"><csymbol cd="latexml" id="S2.Ex4.m2.1.2.1.cmml" xref="S2.Ex4.m2.1.2.1">assign</csymbol><csymbol cd="latexml" id="S2.Ex4.m2.1.2.2.cmml" xref="S2.Ex4.m2.1.2.2">absent</csymbol><apply id="S2.Ex4.m2.1.2.3.cmml" xref="S2.Ex4.m2.1.2.3"><times id="S2.Ex4.m2.1.2.3.1.cmml" xref="S2.Ex4.m2.1.2.3.1"></times><apply id="S2.Ex4.m2.1.2.3.2.cmml" xref="S2.Ex4.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.Ex4.m2.1.2.3.2.1.cmml" xref="S2.Ex4.m2.1.2.3.2">superscript</csymbol><apply id="S2.Ex4.m2.1.2.3.2.2.cmml" xref="S2.Ex4.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.Ex4.m2.1.2.3.2.2.1.cmml" xref="S2.Ex4.m2.1.2.3.2">subscript</csymbol><ci id="S2.Ex4.m2.1.2.3.2.2.2a.cmml" xref="S2.Ex4.m2.1.2.3.2.2.2"><mtext id="S2.Ex4.m2.1.2.3.2.2.2.cmml" xref="S2.Ex4.m2.1.2.3.2.2.2">embed</mtext></ci><ci id="S2.Ex4.m2.1.2.3.2.2.3.cmml" xref="S2.Ex4.m2.1.2.3.2.2.3">italic-ϕ</ci></apply><ci id="S2.Ex4.m2.1.2.3.2.3a.cmml" xref="S2.Ex4.m2.1.2.3.2.3"><mtext mathsize="70%" id="S2.Ex4.m2.1.2.3.2.3.cmml" xref="S2.Ex4.m2.1.2.3.2.3">(film)</mtext></ci></apply><ci id="S2.Ex4.m2.1.1.cmml" xref="S2.Ex4.m2.1.1">𝐜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m2.1c">\displaystyle:=\text{embed}_{\phi}^{\text{(film)}}(\mathbf{c})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex5.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{e}_{\text{gru}}" display="inline"><semantics id="S2.Ex5.m1.1a"><msub id="S2.Ex5.m1.1.1" xref="S2.Ex5.m1.1.1.cmml"><mi id="S2.Ex5.m1.1.1.2" xref="S2.Ex5.m1.1.1.2.cmml">𝐞</mi><mtext id="S2.Ex5.m1.1.1.3" xref="S2.Ex5.m1.1.1.3a.cmml">gru</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.Ex5.m1.1b"><apply id="S2.Ex5.m1.1.1.cmml" xref="S2.Ex5.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex5.m1.1.1.1.cmml" xref="S2.Ex5.m1.1.1">subscript</csymbol><ci id="S2.Ex5.m1.1.1.2.cmml" xref="S2.Ex5.m1.1.1.2">𝐞</ci><ci id="S2.Ex5.m1.1.1.3a.cmml" xref="S2.Ex5.m1.1.1.3"><mtext mathsize="70%" id="S2.Ex5.m1.1.1.3.cmml" xref="S2.Ex5.m1.1.1.3">gru</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex5.m1.1c">\displaystyle\mathbf{e}_{\text{gru}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex5.m2.1" class="ltx_Math" alttext="\displaystyle:=\text{GRU}_{\phi}(\mathbf{q})" display="inline"><semantics id="S2.Ex5.m2.1a"><mrow id="S2.Ex5.m2.1.2" xref="S2.Ex5.m2.1.2.cmml"><mi id="S2.Ex5.m2.1.2.2" xref="S2.Ex5.m2.1.2.2.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex5.m2.1.2.1" xref="S2.Ex5.m2.1.2.1.cmml">:=</mo><mrow id="S2.Ex5.m2.1.2.3" xref="S2.Ex5.m2.1.2.3.cmml"><msub id="S2.Ex5.m2.1.2.3.2" xref="S2.Ex5.m2.1.2.3.2.cmml"><mtext id="S2.Ex5.m2.1.2.3.2.2" xref="S2.Ex5.m2.1.2.3.2.2a.cmml">GRU</mtext><mi id="S2.Ex5.m2.1.2.3.2.3" xref="S2.Ex5.m2.1.2.3.2.3.cmml">ϕ</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex5.m2.1.2.3.1" xref="S2.Ex5.m2.1.2.3.1.cmml">​</mo><mrow id="S2.Ex5.m2.1.2.3.3.2" xref="S2.Ex5.m2.1.2.3.cmml"><mo stretchy="false" id="S2.Ex5.m2.1.2.3.3.2.1" xref="S2.Ex5.m2.1.2.3.cmml">(</mo><mi id="S2.Ex5.m2.1.1" xref="S2.Ex5.m2.1.1.cmml">𝐪</mi><mo stretchy="false" id="S2.Ex5.m2.1.2.3.3.2.2" xref="S2.Ex5.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex5.m2.1b"><apply id="S2.Ex5.m2.1.2.cmml" xref="S2.Ex5.m2.1.2"><csymbol cd="latexml" id="S2.Ex5.m2.1.2.1.cmml" xref="S2.Ex5.m2.1.2.1">assign</csymbol><csymbol cd="latexml" id="S2.Ex5.m2.1.2.2.cmml" xref="S2.Ex5.m2.1.2.2">absent</csymbol><apply id="S2.Ex5.m2.1.2.3.cmml" xref="S2.Ex5.m2.1.2.3"><times id="S2.Ex5.m2.1.2.3.1.cmml" xref="S2.Ex5.m2.1.2.3.1"></times><apply id="S2.Ex5.m2.1.2.3.2.cmml" xref="S2.Ex5.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.Ex5.m2.1.2.3.2.1.cmml" xref="S2.Ex5.m2.1.2.3.2">subscript</csymbol><ci id="S2.Ex5.m2.1.2.3.2.2a.cmml" xref="S2.Ex5.m2.1.2.3.2.2"><mtext id="S2.Ex5.m2.1.2.3.2.2.cmml" xref="S2.Ex5.m2.1.2.3.2.2">GRU</mtext></ci><ci id="S2.Ex5.m2.1.2.3.2.3.cmml" xref="S2.Ex5.m2.1.2.3.2.3">italic-ϕ</ci></apply><ci id="S2.Ex5.m2.1.1.cmml" xref="S2.Ex5.m2.1.1">𝐪</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex5.m2.1c">\displaystyle:=\text{GRU}_{\phi}(\mathbf{q})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex6.m1.1" class="ltx_Math" alttext="\displaystyle\tilde{\mathbf{y}}" display="inline"><semantics id="S2.Ex6.m1.1a"><mover accent="true" id="S2.Ex6.m1.1.1" xref="S2.Ex6.m1.1.1.cmml"><mi id="S2.Ex6.m1.1.1.2" xref="S2.Ex6.m1.1.1.2.cmml">𝐲</mi><mo id="S2.Ex6.m1.1.1.1" xref="S2.Ex6.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S2.Ex6.m1.1b"><apply id="S2.Ex6.m1.1.1.cmml" xref="S2.Ex6.m1.1.1"><ci id="S2.Ex6.m1.1.1.1.cmml" xref="S2.Ex6.m1.1.1.1">~</ci><ci id="S2.Ex6.m1.1.1.2.cmml" xref="S2.Ex6.m1.1.1.2">𝐲</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex6.m1.1c">\displaystyle\tilde{\mathbf{y}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex6.m2.2" class="ltx_Math" alttext="\displaystyle:=\text{FILM}_{\phi}(\mathbf{h},[\mathbf{e}_{\text{gru}},\mathbf{e}_{\text{cam}}])" display="inline"><semantics id="S2.Ex6.m2.2a"><mrow id="S2.Ex6.m2.2.2" xref="S2.Ex6.m2.2.2.cmml"><mi id="S2.Ex6.m2.2.2.3" xref="S2.Ex6.m2.2.2.3.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex6.m2.2.2.2" xref="S2.Ex6.m2.2.2.2.cmml">:=</mo><mrow id="S2.Ex6.m2.2.2.1" xref="S2.Ex6.m2.2.2.1.cmml"><msub id="S2.Ex6.m2.2.2.1.3" xref="S2.Ex6.m2.2.2.1.3.cmml"><mtext id="S2.Ex6.m2.2.2.1.3.2" xref="S2.Ex6.m2.2.2.1.3.2a.cmml">FILM</mtext><mi id="S2.Ex6.m2.2.2.1.3.3" xref="S2.Ex6.m2.2.2.1.3.3.cmml">ϕ</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex6.m2.2.2.1.2" xref="S2.Ex6.m2.2.2.1.2.cmml">​</mo><mrow id="S2.Ex6.m2.2.2.1.1.1" xref="S2.Ex6.m2.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.Ex6.m2.2.2.1.1.1.2" xref="S2.Ex6.m2.2.2.1.1.2.cmml">(</mo><mi id="S2.Ex6.m2.1.1" xref="S2.Ex6.m2.1.1.cmml">𝐡</mi><mo id="S2.Ex6.m2.2.2.1.1.1.3" xref="S2.Ex6.m2.2.2.1.1.2.cmml">,</mo><mrow id="S2.Ex6.m2.2.2.1.1.1.1.2" xref="S2.Ex6.m2.2.2.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.Ex6.m2.2.2.1.1.1.1.2.3" xref="S2.Ex6.m2.2.2.1.1.1.1.3.cmml">[</mo><msub id="S2.Ex6.m2.2.2.1.1.1.1.1.1" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1.cmml"><mi id="S2.Ex6.m2.2.2.1.1.1.1.1.1.2" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1.2.cmml">𝐞</mi><mtext id="S2.Ex6.m2.2.2.1.1.1.1.1.1.3" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1.3a.cmml">gru</mtext></msub><mo id="S2.Ex6.m2.2.2.1.1.1.1.2.4" xref="S2.Ex6.m2.2.2.1.1.1.1.3.cmml">,</mo><msub id="S2.Ex6.m2.2.2.1.1.1.1.2.2" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2.cmml"><mi id="S2.Ex6.m2.2.2.1.1.1.1.2.2.2" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2.2.cmml">𝐞</mi><mtext id="S2.Ex6.m2.2.2.1.1.1.1.2.2.3" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2.3a.cmml">cam</mtext></msub><mo stretchy="false" id="S2.Ex6.m2.2.2.1.1.1.1.2.5" xref="S2.Ex6.m2.2.2.1.1.1.1.3.cmml">]</mo></mrow><mo stretchy="false" id="S2.Ex6.m2.2.2.1.1.1.4" xref="S2.Ex6.m2.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex6.m2.2b"><apply id="S2.Ex6.m2.2.2.cmml" xref="S2.Ex6.m2.2.2"><csymbol cd="latexml" id="S2.Ex6.m2.2.2.2.cmml" xref="S2.Ex6.m2.2.2.2">assign</csymbol><csymbol cd="latexml" id="S2.Ex6.m2.2.2.3.cmml" xref="S2.Ex6.m2.2.2.3">absent</csymbol><apply id="S2.Ex6.m2.2.2.1.cmml" xref="S2.Ex6.m2.2.2.1"><times id="S2.Ex6.m2.2.2.1.2.cmml" xref="S2.Ex6.m2.2.2.1.2"></times><apply id="S2.Ex6.m2.2.2.1.3.cmml" xref="S2.Ex6.m2.2.2.1.3"><csymbol cd="ambiguous" id="S2.Ex6.m2.2.2.1.3.1.cmml" xref="S2.Ex6.m2.2.2.1.3">subscript</csymbol><ci id="S2.Ex6.m2.2.2.1.3.2a.cmml" xref="S2.Ex6.m2.2.2.1.3.2"><mtext id="S2.Ex6.m2.2.2.1.3.2.cmml" xref="S2.Ex6.m2.2.2.1.3.2">FILM</mtext></ci><ci id="S2.Ex6.m2.2.2.1.3.3.cmml" xref="S2.Ex6.m2.2.2.1.3.3">italic-ϕ</ci></apply><interval closure="open" id="S2.Ex6.m2.2.2.1.1.2.cmml" xref="S2.Ex6.m2.2.2.1.1.1"><ci id="S2.Ex6.m2.1.1.cmml" xref="S2.Ex6.m2.1.1">𝐡</ci><interval closure="closed" id="S2.Ex6.m2.2.2.1.1.1.1.3.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.2"><apply id="S2.Ex6.m2.2.2.1.1.1.1.1.1.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex6.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex6.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1.2">𝐞</ci><ci id="S2.Ex6.m2.2.2.1.1.1.1.1.1.3a.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S2.Ex6.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.1.1.3">gru</mtext></ci></apply><apply id="S2.Ex6.m2.2.2.1.1.1.1.2.2.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.Ex6.m2.2.2.1.1.1.1.2.2.1.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2">subscript</csymbol><ci id="S2.Ex6.m2.2.2.1.1.1.1.2.2.2.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2.2">𝐞</ci><ci id="S2.Ex6.m2.2.2.1.1.1.1.2.2.3a.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2.3"><mtext mathsize="70%" id="S2.Ex6.m2.2.2.1.1.1.1.2.2.3.cmml" xref="S2.Ex6.m2.2.2.1.1.1.1.2.2.3">cam</mtext></ci></apply></interval></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex6.m2.2c">\displaystyle:=\text{FILM}_{\phi}(\mathbf{h},[\mathbf{e}_{\text{gru}},\mathbf{e}_{\text{cam}}])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\displaystyle\ell" display="inline"><semantics id="S2.E1.m1.1a"><mi mathvariant="normal" id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">ℓ</mi><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ℓ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\displaystyle\ell</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1.m2.3" class="ltx_Math" alttext="\displaystyle:=\ell_{\text{cls}}(\mathbf{y},\tilde{\mathbf{y}})," display="inline"><semantics id="S2.E1.m2.3a"><mrow id="S2.E1.m2.3.3.1" xref="S2.E1.m2.3.3.1.1.cmml"><mrow id="S2.E1.m2.3.3.1.1" xref="S2.E1.m2.3.3.1.1.cmml"><mi id="S2.E1.m2.3.3.1.1.2" xref="S2.E1.m2.3.3.1.1.2.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.E1.m2.3.3.1.1.1" xref="S2.E1.m2.3.3.1.1.1.cmml">:=</mo><mrow id="S2.E1.m2.3.3.1.1.3" xref="S2.E1.m2.3.3.1.1.3.cmml"><msub id="S2.E1.m2.3.3.1.1.3.2" xref="S2.E1.m2.3.3.1.1.3.2.cmml"><mi mathvariant="normal" id="S2.E1.m2.3.3.1.1.3.2.2" xref="S2.E1.m2.3.3.1.1.3.2.2.cmml">ℓ</mi><mtext id="S2.E1.m2.3.3.1.1.3.2.3" xref="S2.E1.m2.3.3.1.1.3.2.3a.cmml">cls</mtext></msub><mo lspace="0em" rspace="0em" id="S2.E1.m2.3.3.1.1.3.1" xref="S2.E1.m2.3.3.1.1.3.1.cmml">​</mo><mrow id="S2.E1.m2.3.3.1.1.3.3.2" xref="S2.E1.m2.3.3.1.1.3.3.1.cmml"><mo stretchy="false" id="S2.E1.m2.3.3.1.1.3.3.2.1" xref="S2.E1.m2.3.3.1.1.3.3.1.cmml">(</mo><mi id="S2.E1.m2.1.1" xref="S2.E1.m2.1.1.cmml">𝐲</mi><mo id="S2.E1.m2.3.3.1.1.3.3.2.2" xref="S2.E1.m2.3.3.1.1.3.3.1.cmml">,</mo><mover accent="true" id="S2.E1.m2.2.2" xref="S2.E1.m2.2.2.cmml"><mi id="S2.E1.m2.2.2.2" xref="S2.E1.m2.2.2.2.cmml">𝐲</mi><mo id="S2.E1.m2.2.2.1" xref="S2.E1.m2.2.2.1.cmml">~</mo></mover><mo stretchy="false" id="S2.E1.m2.3.3.1.1.3.3.2.3" xref="S2.E1.m2.3.3.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E1.m2.3.3.1.2" xref="S2.E1.m2.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m2.3b"><apply id="S2.E1.m2.3.3.1.1.cmml" xref="S2.E1.m2.3.3.1"><csymbol cd="latexml" id="S2.E1.m2.3.3.1.1.1.cmml" xref="S2.E1.m2.3.3.1.1.1">assign</csymbol><csymbol cd="latexml" id="S2.E1.m2.3.3.1.1.2.cmml" xref="S2.E1.m2.3.3.1.1.2">absent</csymbol><apply id="S2.E1.m2.3.3.1.1.3.cmml" xref="S2.E1.m2.3.3.1.1.3"><times id="S2.E1.m2.3.3.1.1.3.1.cmml" xref="S2.E1.m2.3.3.1.1.3.1"></times><apply id="S2.E1.m2.3.3.1.1.3.2.cmml" xref="S2.E1.m2.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m2.3.3.1.1.3.2.1.cmml" xref="S2.E1.m2.3.3.1.1.3.2">subscript</csymbol><ci id="S2.E1.m2.3.3.1.1.3.2.2.cmml" xref="S2.E1.m2.3.3.1.1.3.2.2">ℓ</ci><ci id="S2.E1.m2.3.3.1.1.3.2.3a.cmml" xref="S2.E1.m2.3.3.1.1.3.2.3"><mtext mathsize="70%" id="S2.E1.m2.3.3.1.1.3.2.3.cmml" xref="S2.E1.m2.3.3.1.1.3.2.3">cls</mtext></ci></apply><interval closure="open" id="S2.E1.m2.3.3.1.1.3.3.1.cmml" xref="S2.E1.m2.3.3.1.1.3.3.2"><ci id="S2.E1.m2.1.1.cmml" xref="S2.E1.m2.1.1">𝐲</ci><apply id="S2.E1.m2.2.2.cmml" xref="S2.E1.m2.2.2"><ci id="S2.E1.m2.2.2.1.cmml" xref="S2.E1.m2.2.2.1">~</ci><ci id="S2.E1.m2.2.2.2.cmml" xref="S2.E1.m2.2.2.2">𝐲</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m2.3c">\displaystyle:=\ell_{\text{cls}}(\mathbf{y},\tilde{\mathbf{y}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p2.1" class="ltx_p">where the encoder (pre-trained ResNet) is frozen and therefore has no learnable parameters. Here, <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="\ell_{\text{cls}}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><msub id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">ℓ</mi><mtext id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3a.cmml">cls</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">ℓ</ci><ci id="S2.SS1.p2.1.m1.1.1.3a.cmml" xref="S2.SS1.p2.1.m1.1.1.3"><mtext mathsize="70%" id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">cls</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\ell_{\text{cls}}</annotation></semantics></math> is the multinomial classification loss over the predicted answer token.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2212.01639/assets/x2.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="146" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.4.2.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S2.F3.2.1" class="ltx_text" style="font-size:90%;">The pipeline of our FILM baselines <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. An input view (which is randomly sampled from a scene) is fed through a pre-trained encoder (a ResNet-101 pretrained on ImageNet) to produce a high-dimensional stack of feature maps <math id="S2.F3.2.1.m1.1" class="ltx_Math" alttext="\mathbf{h}" display="inline"><semantics id="S2.F3.2.1.m1.1b"><mi id="S2.F3.2.1.m1.1.1" xref="S2.F3.2.1.m1.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.F3.2.1.m1.1c"><ci id="S2.F3.2.1.m1.1.1.cmml" xref="S2.F3.2.1.m1.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.2.1.m1.1d">\mathbf{h}</annotation></semantics></math> of dimension (1024, 14, 14). The question embedding is fed through a GRU which outputs an embedding vector of the sentence. The viewpoint camera is also run through its own embedding module before being concatenated to the question embedding, and its arrows are presented as dashes to show that it is optional, depending on the precise baseline that is run. The resulting feature maps from the encoder are fed through FILM-modulated residual blocks using the final question/camera embedding vector. (Please see the supplementary materials section for more details.)</span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Learning 3D Feature Representations from Single View Images</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">So far we have been operating in 2D, based on the pre-trained ResNet-101 ImageNet encoder which outputs a high-dimensional stack of feature maps (a 3D tensor). To work in 3D, we would either need to somehow transform the existing encoding into a 4D tensor (a stack of 3D feature <em id="S2.SS2.p1.1.1" class="ltx_emph ltx_font_italic">cubes</em>) or use a completely different encoder altogether which can output a 3D volume directly. Assuming we already had such a volume, we can manipulate the volume in 3D space directly by having it undergo any rigid transformation that is necessary for the question to be answered. In Section <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a> we illustrate a simple technique which simply takes the existing ImageNet encoder’s features and runs it through a learnable ‘post-processing’ block to yield a 3D volume, and in Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a> we propose a self-supervised contrastive approach to learn such an encoder from scratch without the use of camera extrinsics.</p>
</div>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Projecting 2D Features into 3D Features</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.2" class="ltx_p">To exploit the power of pre-trained representations, we start with a pre-trained ResNet encoder and transform its stack of feature maps through an additional set of 2D convolution blocks using the ‘post-processor’ shown in Figure <a href="#S2.F4" title="Figure 4 ‣ 2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, right before reshaping the 3D tensor into 4D. In other words, we learn a module which maps from a stack of feature maps <math id="S2.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{h}" display="inline"><semantics id="S2.SS2.SSS1.p1.1.m1.1a"><mi id="S2.SS2.SSS1.p1.1.m1.1.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.1.m1.1b"><ci id="S2.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.1.m1.1c">\mathbf{h}</annotation></semantics></math> to a stack of feature cubes, i.e. the encoding step in Equation <a href="#S2.Ex1" title="2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a> is replaced with <math id="S2.SS2.SSS1.p1.2.m2.2" class="ltx_Math" alttext="\mathbf{h}:=\text{postproc}_{\phi}(\text{encode}(\mathbf{x}))" display="inline"><semantics id="S2.SS2.SSS1.p1.2.m2.2a"><mrow id="S2.SS2.SSS1.p1.2.m2.2.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.cmml"><mi id="S2.SS2.SSS1.p1.2.m2.2.2.3" xref="S2.SS2.SSS1.p1.2.m2.2.2.3.cmml">𝐡</mi><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS1.p1.2.m2.2.2.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.2.cmml">:=</mo><mrow id="S2.SS2.SSS1.p1.2.m2.2.2.1" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.cmml"><msub id="S2.SS2.SSS1.p1.2.m2.2.2.1.3" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3.cmml"><mtext id="S2.SS2.SSS1.p1.2.m2.2.2.1.3.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3.2a.cmml">postproc</mtext><mi id="S2.SS2.SSS1.p1.2.m2.2.2.1.3.3" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3.3.cmml">ϕ</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.SSS1.p1.2.m2.2.2.1.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.2.cmml">​</mo><mrow id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml"><mtext id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.2a.cmml">encode</mtext><mo lspace="0em" rspace="0em" id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.1" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.1.cmml">​</mo><mrow id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.3.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.3.2.1" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml">(</mo><mi id="S2.SS2.SSS1.p1.2.m2.1.1" xref="S2.SS2.SSS1.p1.2.m2.1.1.cmml">𝐱</mi><mo stretchy="false" id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.3.2.2" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.3" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.2.m2.2b"><apply id="S2.SS2.SSS1.p1.2.m2.2.2.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2"><csymbol cd="latexml" id="S2.SS2.SSS1.p1.2.m2.2.2.2.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.2">assign</csymbol><ci id="S2.SS2.SSS1.p1.2.m2.2.2.3.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.3">𝐡</ci><apply id="S2.SS2.SSS1.p1.2.m2.2.2.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1"><times id="S2.SS2.SSS1.p1.2.m2.2.2.1.2.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.2"></times><apply id="S2.SS2.SSS1.p1.2.m2.2.2.1.3.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.2.m2.2.2.1.3.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3">subscript</csymbol><ci id="S2.SS2.SSS1.p1.2.m2.2.2.1.3.2a.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3.2"><mtext id="S2.SS2.SSS1.p1.2.m2.2.2.1.3.2.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3.2">postproc</mtext></ci><ci id="S2.SS2.SSS1.p1.2.m2.2.2.1.3.3.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.3.3">italic-ϕ</ci></apply><apply id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1"><times id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.1"></times><ci id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.2a.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.2"><mtext id="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.2.cmml" xref="S2.SS2.SSS1.p1.2.m2.2.2.1.1.1.1.2">encode</mtext></ci><ci id="S2.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.2.m2.2c">\mathbf{h}:=\text{postproc}_{\phi}(\text{encode}(\mathbf{x}))</annotation></semantics></math>. Since the post-processor is a <em id="S2.SS2.SSS1.p1.2.1" class="ltx_emph ltx_font_italic">learnable</em> module through which the FILM part of the pipeline is able to backpropagate through, it can be seen as learning how to <em id="S2.SS2.SSS1.p1.2.2" class="ltx_emph ltx_font_italic">lift</em> said 2D representation into 3D. Through back-propagation it learns to perform well when manipulated with camera-conditioned FILM operations either as is or, more interestingly, when also subjected to rigid 3D transformations as we will see shortly in Section <a href="#S2.SS2.SSS2" title="2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.2</span></a>.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2212.01639/assets/x3.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="66" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F4.9.4.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S2.F4.6.3" class="ltx_text" style="font-size:90%;">The pre-trained ResNet encoder outputs a stack of feature maps <math id="S2.F4.4.1.m1.1" class="ltx_Math" alttext="\mathbf{h}" display="inline"><semantics id="S2.F4.4.1.m1.1b"><mi id="S2.F4.4.1.m1.1.1" xref="S2.F4.4.1.m1.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.F4.4.1.m1.1c"><ci id="S2.F4.4.1.m1.1.1.cmml" xref="S2.F4.4.1.m1.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.4.1.m1.1d">\mathbf{h}</annotation></semantics></math> of dimensions (1024, 14, 14), as in Fig. <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, but now a post-processing module <math id="S2.F4.5.2.m2.1" class="ltx_Math" alttext="\text{postproc}_{\psi}(\mathbf{h})" display="inline"><semantics id="S2.F4.5.2.m2.1b"><mrow id="S2.F4.5.2.m2.1.2" xref="S2.F4.5.2.m2.1.2.cmml"><msub id="S2.F4.5.2.m2.1.2.2" xref="S2.F4.5.2.m2.1.2.2.cmml"><mtext id="S2.F4.5.2.m2.1.2.2.2" xref="S2.F4.5.2.m2.1.2.2.2a.cmml">postproc</mtext><mi id="S2.F4.5.2.m2.1.2.2.3" xref="S2.F4.5.2.m2.1.2.2.3.cmml">ψ</mi></msub><mo lspace="0em" rspace="0em" id="S2.F4.5.2.m2.1.2.1" xref="S2.F4.5.2.m2.1.2.1.cmml">​</mo><mrow id="S2.F4.5.2.m2.1.2.3.2" xref="S2.F4.5.2.m2.1.2.cmml"><mo stretchy="false" id="S2.F4.5.2.m2.1.2.3.2.1" xref="S2.F4.5.2.m2.1.2.cmml">(</mo><mi id="S2.F4.5.2.m2.1.1" xref="S2.F4.5.2.m2.1.1.cmml">𝐡</mi><mo stretchy="false" id="S2.F4.5.2.m2.1.2.3.2.2" xref="S2.F4.5.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.F4.5.2.m2.1c"><apply id="S2.F4.5.2.m2.1.2.cmml" xref="S2.F4.5.2.m2.1.2"><times id="S2.F4.5.2.m2.1.2.1.cmml" xref="S2.F4.5.2.m2.1.2.1"></times><apply id="S2.F4.5.2.m2.1.2.2.cmml" xref="S2.F4.5.2.m2.1.2.2"><csymbol cd="ambiguous" id="S2.F4.5.2.m2.1.2.2.1.cmml" xref="S2.F4.5.2.m2.1.2.2">subscript</csymbol><ci id="S2.F4.5.2.m2.1.2.2.2a.cmml" xref="S2.F4.5.2.m2.1.2.2.2"><mtext id="S2.F4.5.2.m2.1.2.2.2.cmml" xref="S2.F4.5.2.m2.1.2.2.2">postproc</mtext></ci><ci id="S2.F4.5.2.m2.1.2.2.3.cmml" xref="S2.F4.5.2.m2.1.2.2.3">𝜓</ci></apply><ci id="S2.F4.5.2.m2.1.1.cmml" xref="S2.F4.5.2.m2.1.1">𝐡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.5.2.m2.1d">\text{postproc}_{\psi}(\mathbf{h})</annotation></semantics></math>, e.g. a set of 2D convolutions, processes the feature stack and reshapes it into a 4D tensor <math id="S2.F4.6.3.m3.1" class="ltx_Math" alttext="\mathbf{h}^{\prime}" display="inline"><semantics id="S2.F4.6.3.m3.1b"><msup id="S2.F4.6.3.m3.1.1" xref="S2.F4.6.3.m3.1.1.cmml"><mi id="S2.F4.6.3.m3.1.1.2" xref="S2.F4.6.3.m3.1.1.2.cmml">𝐡</mi><mo id="S2.F4.6.3.m3.1.1.3" xref="S2.F4.6.3.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.F4.6.3.m3.1c"><apply id="S2.F4.6.3.m3.1.1.cmml" xref="S2.F4.6.3.m3.1.1"><csymbol cd="ambiguous" id="S2.F4.6.3.m3.1.1.1.cmml" xref="S2.F4.6.3.m3.1.1">superscript</csymbol><ci id="S2.F4.6.3.m3.1.1.2.cmml" xref="S2.F4.6.3.m3.1.1.2">𝐡</ci><ci id="S2.F4.6.3.m3.1.1.3.cmml" xref="S2.F4.6.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.6.3.m3.1d">\mathbf{h}^{\prime}</annotation></semantics></math> of dimensions (64, 16, 14, 14) , i.e., a stack of feature <em id="S2.F4.6.3.1" class="ltx_emph ltx_font_italic">cubes</em>. This entire block (inside the grey border) is the new ‘encoder’, with the forward pass remaining the same as described in Equation <a href="#S2.Ex1" title="2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.</span></figcaption>
</figure>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>3D Camera Controllable FILM</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.4" class="ltx_p">In lieu of conditioning the camera with FILM (as seen in Figure <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> with <math id="S2.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\text{embed}_{\phi}^{\text{(film)}}" display="inline"><semantics id="S2.SS2.SSS2.p1.1.m1.1a"><msubsup id="S2.SS2.SSS2.p1.1.m1.1.1" xref="S2.SS2.SSS2.p1.1.m1.1.1.cmml"><mtext id="S2.SS2.SSS2.p1.1.m1.1.1.2.2" xref="S2.SS2.SSS2.p1.1.m1.1.1.2.2a.cmml">embed</mtext><mi id="S2.SS2.SSS2.p1.1.m1.1.1.2.3" xref="S2.SS2.SSS2.p1.1.m1.1.1.2.3.cmml">ϕ</mi><mtext id="S2.SS2.SSS2.p1.1.m1.1.1.3" xref="S2.SS2.SSS2.p1.1.m1.1.1.3a.cmml">(film)</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.1.m1.1b"><apply id="S2.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1">superscript</csymbol><apply id="S2.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.1.m1.1.1.2.1.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS2.p1.1.m1.1.1.2.2a.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1.2.2"><mtext id="S2.SS2.SSS2.p1.1.m1.1.1.2.2.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1.2.2">embed</mtext></ci><ci id="S2.SS2.SSS2.p1.1.m1.1.1.2.3.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1.2.3">italic-ϕ</ci></apply><ci id="S2.SS2.SSS2.p1.1.m1.1.1.3a.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S2.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS2.p1.1.m1.1.1.3">(film)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.1.m1.1c">\text{embed}_{\phi}^{\text{(film)}}</annotation></semantics></math>), we can also condition on it to output translation and rotation parameters <math id="S2.SS2.SSS2.p1.2.m2.6" class="ltx_Math" alttext="(\tilde{\bm{\theta}}_{x},\tilde{\bm{\theta}}_{y},\tilde{\bm{\theta}}_{z},\tilde{\mathbf{t}}_{x},\tilde{\mathbf{t}}_{y},\tilde{\mathbf{t}}_{z})" display="inline"><semantics id="S2.SS2.SSS2.p1.2.m2.6a"><mrow id="S2.SS2.SSS2.p1.2.m2.6.6.6" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml"><mo stretchy="false" id="S2.SS2.SSS2.p1.2.m2.6.6.6.7" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml">(</mo><msub id="S2.SS2.SSS2.p1.2.m2.1.1.1.1" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.cmml"><mover accent="true" id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.cmml"><mi id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.2" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.2.cmml">𝜽</mi><mo id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.1" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.3" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.3.cmml">x</mi></msub><mo id="S2.SS2.SSS2.p1.2.m2.6.6.6.8" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p1.2.m2.2.2.2.2" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.cmml"><mover accent="true" id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.cmml"><mi id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.2" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.2.cmml">𝜽</mi><mo id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.1" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.3" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.3.cmml">y</mi></msub><mo id="S2.SS2.SSS2.p1.2.m2.6.6.6.9" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p1.2.m2.3.3.3.3" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.cmml"><mover accent="true" id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.cmml"><mi id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.2" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.2.cmml">𝜽</mi><mo id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.1" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.3" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.3.cmml">z</mi></msub><mo id="S2.SS2.SSS2.p1.2.m2.6.6.6.10" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p1.2.m2.4.4.4.4" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.cmml"><mover accent="true" id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.cmml"><mi id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.2" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.2.cmml">𝐭</mi><mo id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.1" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.3" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.3.cmml">x</mi></msub><mo id="S2.SS2.SSS2.p1.2.m2.6.6.6.11" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p1.2.m2.5.5.5.5" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.cmml"><mover accent="true" id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.cmml"><mi id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.2" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.2.cmml">𝐭</mi><mo id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.1" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.3" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.3.cmml">y</mi></msub><mo id="S2.SS2.SSS2.p1.2.m2.6.6.6.12" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p1.2.m2.6.6.6.6" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.cmml"><mover accent="true" id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.cmml"><mi id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.2" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.2.cmml">𝐭</mi><mo id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.1" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.1.cmml">~</mo></mover><mi id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.3" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.3.cmml">z</mi></msub><mo stretchy="false" id="S2.SS2.SSS2.p1.2.m2.6.6.6.13" xref="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.2.m2.6b"><vector id="S2.SS2.SSS2.p1.2.m2.6.6.7.cmml" xref="S2.SS2.SSS2.p1.2.m2.6.6.6"><apply id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1">subscript</csymbol><apply id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2"><ci id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.1">~</ci><ci id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.2.2">𝜽</ci></apply><ci id="S2.SS2.SSS2.p1.2.m2.1.1.1.1.3.cmml" xref="S2.SS2.SSS2.p1.2.m2.1.1.1.1.3">𝑥</ci></apply><apply id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2">subscript</csymbol><apply id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2"><ci id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.1">~</ci><ci id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.2.2">𝜽</ci></apply><ci id="S2.SS2.SSS2.p1.2.m2.2.2.2.2.3.cmml" xref="S2.SS2.SSS2.p1.2.m2.2.2.2.2.3">𝑦</ci></apply><apply id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.cmml" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3">subscript</csymbol><apply id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2"><ci id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.1">~</ci><ci id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.2.2">𝜽</ci></apply><ci id="S2.SS2.SSS2.p1.2.m2.3.3.3.3.3.cmml" xref="S2.SS2.SSS2.p1.2.m2.3.3.3.3.3">𝑧</ci></apply><apply id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.cmml" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4">subscript</csymbol><apply id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2"><ci id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.1">~</ci><ci id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.2.2">𝐭</ci></apply><ci id="S2.SS2.SSS2.p1.2.m2.4.4.4.4.3.cmml" xref="S2.SS2.SSS2.p1.2.m2.4.4.4.4.3">𝑥</ci></apply><apply id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.cmml" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5">subscript</csymbol><apply id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2"><ci id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.1">~</ci><ci id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.2.2">𝐭</ci></apply><ci id="S2.SS2.SSS2.p1.2.m2.5.5.5.5.3.cmml" xref="S2.SS2.SSS2.p1.2.m2.5.5.5.5.3">𝑦</ci></apply><apply id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.cmml" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6">subscript</csymbol><apply id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2"><ci id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.1.cmml" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.1">~</ci><ci id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.2.cmml" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.2.2">𝐭</ci></apply><ci id="S2.SS2.SSS2.p1.2.m2.6.6.6.6.3.cmml" xref="S2.SS2.SSS2.p1.2.m2.6.6.6.6.3">𝑧</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.2.m2.6c">(\tilde{\bm{\theta}}_{x},\tilde{\bm{\theta}}_{y},\tilde{\bm{\theta}}_{z},\tilde{\mathbf{t}}_{x},\tilde{\mathbf{t}}_{y},\tilde{\mathbf{t}}_{z})</annotation></semantics></math> which are then used to construct a 3D rotation and translation matrix <math id="S2.SS2.SSS2.p1.3.m3.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S2.SS2.SSS2.p1.3.m3.1a"><mi mathvariant="normal" id="S2.SS2.SSS2.p1.3.m3.1.1" xref="S2.SS2.SSS2.p1.3.m3.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.3.m3.1b"><ci id="S2.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS2.p1.3.m3.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.3.m3.1c">\Theta</annotation></semantics></math> that <math id="S2.SS2.SSS2.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{h}" display="inline"><semantics id="S2.SS2.SSS2.p1.4.m4.1a"><mi id="S2.SS2.SSS2.p1.4.m4.1.1" xref="S2.SS2.SSS2.p1.4.m4.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.4.m4.1b"><ci id="S2.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS2.p1.4.m4.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.4.m4.1c">\mathbf{h}</annotation></semantics></math> is subjected to (which is now a volume). Therefore, we can write out the 3D FILM pipeline as:</p>
<table id="S5.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.Ex7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex7.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{h}" display="inline"><semantics id="S2.Ex7.m1.1a"><mi id="S2.Ex7.m1.1.1" xref="S2.Ex7.m1.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.Ex7.m1.1b"><ci id="S2.Ex7.m1.1.1.cmml" xref="S2.Ex7.m1.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex7.m1.1c">\displaystyle\mathbf{h}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex7.m2.2" class="ltx_Math" alttext="\displaystyle:=\text{postproc}_{\phi}(\text{encoder}(\mathbf{x}))" display="inline"><semantics id="S2.Ex7.m2.2a"><mrow id="S2.Ex7.m2.2.2" xref="S2.Ex7.m2.2.2.cmml"><mi id="S2.Ex7.m2.2.2.3" xref="S2.Ex7.m2.2.2.3.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex7.m2.2.2.2" xref="S2.Ex7.m2.2.2.2.cmml">:=</mo><mrow id="S2.Ex7.m2.2.2.1" xref="S2.Ex7.m2.2.2.1.cmml"><msub id="S2.Ex7.m2.2.2.1.3" xref="S2.Ex7.m2.2.2.1.3.cmml"><mtext id="S2.Ex7.m2.2.2.1.3.2" xref="S2.Ex7.m2.2.2.1.3.2a.cmml">postproc</mtext><mi id="S2.Ex7.m2.2.2.1.3.3" xref="S2.Ex7.m2.2.2.1.3.3.cmml">ϕ</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex7.m2.2.2.1.2" xref="S2.Ex7.m2.2.2.1.2.cmml">​</mo><mrow id="S2.Ex7.m2.2.2.1.1.1" xref="S2.Ex7.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex7.m2.2.2.1.1.1.2" xref="S2.Ex7.m2.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.Ex7.m2.2.2.1.1.1.1" xref="S2.Ex7.m2.2.2.1.1.1.1.cmml"><mtext id="S2.Ex7.m2.2.2.1.1.1.1.2" xref="S2.Ex7.m2.2.2.1.1.1.1.2a.cmml">encoder</mtext><mo lspace="0em" rspace="0em" id="S2.Ex7.m2.2.2.1.1.1.1.1" xref="S2.Ex7.m2.2.2.1.1.1.1.1.cmml">​</mo><mrow id="S2.Ex7.m2.2.2.1.1.1.1.3.2" xref="S2.Ex7.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex7.m2.2.2.1.1.1.1.3.2.1" xref="S2.Ex7.m2.2.2.1.1.1.1.cmml">(</mo><mi id="S2.Ex7.m2.1.1" xref="S2.Ex7.m2.1.1.cmml">𝐱</mi><mo stretchy="false" id="S2.Ex7.m2.2.2.1.1.1.1.3.2.2" xref="S2.Ex7.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex7.m2.2.2.1.1.1.3" xref="S2.Ex7.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex7.m2.2b"><apply id="S2.Ex7.m2.2.2.cmml" xref="S2.Ex7.m2.2.2"><csymbol cd="latexml" id="S2.Ex7.m2.2.2.2.cmml" xref="S2.Ex7.m2.2.2.2">assign</csymbol><csymbol cd="latexml" id="S2.Ex7.m2.2.2.3.cmml" xref="S2.Ex7.m2.2.2.3">absent</csymbol><apply id="S2.Ex7.m2.2.2.1.cmml" xref="S2.Ex7.m2.2.2.1"><times id="S2.Ex7.m2.2.2.1.2.cmml" xref="S2.Ex7.m2.2.2.1.2"></times><apply id="S2.Ex7.m2.2.2.1.3.cmml" xref="S2.Ex7.m2.2.2.1.3"><csymbol cd="ambiguous" id="S2.Ex7.m2.2.2.1.3.1.cmml" xref="S2.Ex7.m2.2.2.1.3">subscript</csymbol><ci id="S2.Ex7.m2.2.2.1.3.2a.cmml" xref="S2.Ex7.m2.2.2.1.3.2"><mtext id="S2.Ex7.m2.2.2.1.3.2.cmml" xref="S2.Ex7.m2.2.2.1.3.2">postproc</mtext></ci><ci id="S2.Ex7.m2.2.2.1.3.3.cmml" xref="S2.Ex7.m2.2.2.1.3.3">italic-ϕ</ci></apply><apply id="S2.Ex7.m2.2.2.1.1.1.1.cmml" xref="S2.Ex7.m2.2.2.1.1.1"><times id="S2.Ex7.m2.2.2.1.1.1.1.1.cmml" xref="S2.Ex7.m2.2.2.1.1.1.1.1"></times><ci id="S2.Ex7.m2.2.2.1.1.1.1.2a.cmml" xref="S2.Ex7.m2.2.2.1.1.1.1.2"><mtext id="S2.Ex7.m2.2.2.1.1.1.1.2.cmml" xref="S2.Ex7.m2.2.2.1.1.1.1.2">encoder</mtext></ci><ci id="S2.Ex7.m2.1.1.cmml" xref="S2.Ex7.m2.1.1">𝐱</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex7.m2.2c">\displaystyle:=\text{postproc}_{\phi}(\text{encoder}(\mathbf{x}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex8.m1.6" class="ltx_Math" alttext="\displaystyle(\tilde{\bm{\theta}}_{x},\tilde{\bm{\theta}}_{y},\tilde{\bm{\theta}}_{z},\tilde{\mathbf{t}}_{x},\tilde{\mathbf{t}}_{y},\tilde{\mathbf{t}}_{z})" display="inline"><semantics id="S2.Ex8.m1.6a"><mrow id="S2.Ex8.m1.6.6.6" xref="S2.Ex8.m1.6.6.7.cmml"><mo stretchy="false" id="S2.Ex8.m1.6.6.6.7" xref="S2.Ex8.m1.6.6.7.cmml">(</mo><msub id="S2.Ex8.m1.1.1.1.1" xref="S2.Ex8.m1.1.1.1.1.cmml"><mover accent="true" id="S2.Ex8.m1.1.1.1.1.2" xref="S2.Ex8.m1.1.1.1.1.2.cmml"><mi id="S2.Ex8.m1.1.1.1.1.2.2" xref="S2.Ex8.m1.1.1.1.1.2.2.cmml">𝜽</mi><mo id="S2.Ex8.m1.1.1.1.1.2.1" xref="S2.Ex8.m1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S2.Ex8.m1.1.1.1.1.3" xref="S2.Ex8.m1.1.1.1.1.3.cmml">x</mi></msub><mo id="S2.Ex8.m1.6.6.6.8" xref="S2.Ex8.m1.6.6.7.cmml">,</mo><msub id="S2.Ex8.m1.2.2.2.2" xref="S2.Ex8.m1.2.2.2.2.cmml"><mover accent="true" id="S2.Ex8.m1.2.2.2.2.2" xref="S2.Ex8.m1.2.2.2.2.2.cmml"><mi id="S2.Ex8.m1.2.2.2.2.2.2" xref="S2.Ex8.m1.2.2.2.2.2.2.cmml">𝜽</mi><mo id="S2.Ex8.m1.2.2.2.2.2.1" xref="S2.Ex8.m1.2.2.2.2.2.1.cmml">~</mo></mover><mi id="S2.Ex8.m1.2.2.2.2.3" xref="S2.Ex8.m1.2.2.2.2.3.cmml">y</mi></msub><mo id="S2.Ex8.m1.6.6.6.9" xref="S2.Ex8.m1.6.6.7.cmml">,</mo><msub id="S2.Ex8.m1.3.3.3.3" xref="S2.Ex8.m1.3.3.3.3.cmml"><mover accent="true" id="S2.Ex8.m1.3.3.3.3.2" xref="S2.Ex8.m1.3.3.3.3.2.cmml"><mi id="S2.Ex8.m1.3.3.3.3.2.2" xref="S2.Ex8.m1.3.3.3.3.2.2.cmml">𝜽</mi><mo id="S2.Ex8.m1.3.3.3.3.2.1" xref="S2.Ex8.m1.3.3.3.3.2.1.cmml">~</mo></mover><mi id="S2.Ex8.m1.3.3.3.3.3" xref="S2.Ex8.m1.3.3.3.3.3.cmml">z</mi></msub><mo id="S2.Ex8.m1.6.6.6.10" xref="S2.Ex8.m1.6.6.7.cmml">,</mo><msub id="S2.Ex8.m1.4.4.4.4" xref="S2.Ex8.m1.4.4.4.4.cmml"><mover accent="true" id="S2.Ex8.m1.4.4.4.4.2" xref="S2.Ex8.m1.4.4.4.4.2.cmml"><mi id="S2.Ex8.m1.4.4.4.4.2.2" xref="S2.Ex8.m1.4.4.4.4.2.2.cmml">𝐭</mi><mo id="S2.Ex8.m1.4.4.4.4.2.1" xref="S2.Ex8.m1.4.4.4.4.2.1.cmml">~</mo></mover><mi id="S2.Ex8.m1.4.4.4.4.3" xref="S2.Ex8.m1.4.4.4.4.3.cmml">x</mi></msub><mo id="S2.Ex8.m1.6.6.6.11" xref="S2.Ex8.m1.6.6.7.cmml">,</mo><msub id="S2.Ex8.m1.5.5.5.5" xref="S2.Ex8.m1.5.5.5.5.cmml"><mover accent="true" id="S2.Ex8.m1.5.5.5.5.2" xref="S2.Ex8.m1.5.5.5.5.2.cmml"><mi id="S2.Ex8.m1.5.5.5.5.2.2" xref="S2.Ex8.m1.5.5.5.5.2.2.cmml">𝐭</mi><mo id="S2.Ex8.m1.5.5.5.5.2.1" xref="S2.Ex8.m1.5.5.5.5.2.1.cmml">~</mo></mover><mi id="S2.Ex8.m1.5.5.5.5.3" xref="S2.Ex8.m1.5.5.5.5.3.cmml">y</mi></msub><mo id="S2.Ex8.m1.6.6.6.12" xref="S2.Ex8.m1.6.6.7.cmml">,</mo><msub id="S2.Ex8.m1.6.6.6.6" xref="S2.Ex8.m1.6.6.6.6.cmml"><mover accent="true" id="S2.Ex8.m1.6.6.6.6.2" xref="S2.Ex8.m1.6.6.6.6.2.cmml"><mi id="S2.Ex8.m1.6.6.6.6.2.2" xref="S2.Ex8.m1.6.6.6.6.2.2.cmml">𝐭</mi><mo id="S2.Ex8.m1.6.6.6.6.2.1" xref="S2.Ex8.m1.6.6.6.6.2.1.cmml">~</mo></mover><mi id="S2.Ex8.m1.6.6.6.6.3" xref="S2.Ex8.m1.6.6.6.6.3.cmml">z</mi></msub><mo stretchy="false" id="S2.Ex8.m1.6.6.6.13" xref="S2.Ex8.m1.6.6.7.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex8.m1.6b"><vector id="S2.Ex8.m1.6.6.7.cmml" xref="S2.Ex8.m1.6.6.6"><apply id="S2.Ex8.m1.1.1.1.1.cmml" xref="S2.Ex8.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex8.m1.1.1.1.1.1.cmml" xref="S2.Ex8.m1.1.1.1.1">subscript</csymbol><apply id="S2.Ex8.m1.1.1.1.1.2.cmml" xref="S2.Ex8.m1.1.1.1.1.2"><ci id="S2.Ex8.m1.1.1.1.1.2.1.cmml" xref="S2.Ex8.m1.1.1.1.1.2.1">~</ci><ci id="S2.Ex8.m1.1.1.1.1.2.2.cmml" xref="S2.Ex8.m1.1.1.1.1.2.2">𝜽</ci></apply><ci id="S2.Ex8.m1.1.1.1.1.3.cmml" xref="S2.Ex8.m1.1.1.1.1.3">𝑥</ci></apply><apply id="S2.Ex8.m1.2.2.2.2.cmml" xref="S2.Ex8.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.Ex8.m1.2.2.2.2.1.cmml" xref="S2.Ex8.m1.2.2.2.2">subscript</csymbol><apply id="S2.Ex8.m1.2.2.2.2.2.cmml" xref="S2.Ex8.m1.2.2.2.2.2"><ci id="S2.Ex8.m1.2.2.2.2.2.1.cmml" xref="S2.Ex8.m1.2.2.2.2.2.1">~</ci><ci id="S2.Ex8.m1.2.2.2.2.2.2.cmml" xref="S2.Ex8.m1.2.2.2.2.2.2">𝜽</ci></apply><ci id="S2.Ex8.m1.2.2.2.2.3.cmml" xref="S2.Ex8.m1.2.2.2.2.3">𝑦</ci></apply><apply id="S2.Ex8.m1.3.3.3.3.cmml" xref="S2.Ex8.m1.3.3.3.3"><csymbol cd="ambiguous" id="S2.Ex8.m1.3.3.3.3.1.cmml" xref="S2.Ex8.m1.3.3.3.3">subscript</csymbol><apply id="S2.Ex8.m1.3.3.3.3.2.cmml" xref="S2.Ex8.m1.3.3.3.3.2"><ci id="S2.Ex8.m1.3.3.3.3.2.1.cmml" xref="S2.Ex8.m1.3.3.3.3.2.1">~</ci><ci id="S2.Ex8.m1.3.3.3.3.2.2.cmml" xref="S2.Ex8.m1.3.3.3.3.2.2">𝜽</ci></apply><ci id="S2.Ex8.m1.3.3.3.3.3.cmml" xref="S2.Ex8.m1.3.3.3.3.3">𝑧</ci></apply><apply id="S2.Ex8.m1.4.4.4.4.cmml" xref="S2.Ex8.m1.4.4.4.4"><csymbol cd="ambiguous" id="S2.Ex8.m1.4.4.4.4.1.cmml" xref="S2.Ex8.m1.4.4.4.4">subscript</csymbol><apply id="S2.Ex8.m1.4.4.4.4.2.cmml" xref="S2.Ex8.m1.4.4.4.4.2"><ci id="S2.Ex8.m1.4.4.4.4.2.1.cmml" xref="S2.Ex8.m1.4.4.4.4.2.1">~</ci><ci id="S2.Ex8.m1.4.4.4.4.2.2.cmml" xref="S2.Ex8.m1.4.4.4.4.2.2">𝐭</ci></apply><ci id="S2.Ex8.m1.4.4.4.4.3.cmml" xref="S2.Ex8.m1.4.4.4.4.3">𝑥</ci></apply><apply id="S2.Ex8.m1.5.5.5.5.cmml" xref="S2.Ex8.m1.5.5.5.5"><csymbol cd="ambiguous" id="S2.Ex8.m1.5.5.5.5.1.cmml" xref="S2.Ex8.m1.5.5.5.5">subscript</csymbol><apply id="S2.Ex8.m1.5.5.5.5.2.cmml" xref="S2.Ex8.m1.5.5.5.5.2"><ci id="S2.Ex8.m1.5.5.5.5.2.1.cmml" xref="S2.Ex8.m1.5.5.5.5.2.1">~</ci><ci id="S2.Ex8.m1.5.5.5.5.2.2.cmml" xref="S2.Ex8.m1.5.5.5.5.2.2">𝐭</ci></apply><ci id="S2.Ex8.m1.5.5.5.5.3.cmml" xref="S2.Ex8.m1.5.5.5.5.3">𝑦</ci></apply><apply id="S2.Ex8.m1.6.6.6.6.cmml" xref="S2.Ex8.m1.6.6.6.6"><csymbol cd="ambiguous" id="S2.Ex8.m1.6.6.6.6.1.cmml" xref="S2.Ex8.m1.6.6.6.6">subscript</csymbol><apply id="S2.Ex8.m1.6.6.6.6.2.cmml" xref="S2.Ex8.m1.6.6.6.6.2"><ci id="S2.Ex8.m1.6.6.6.6.2.1.cmml" xref="S2.Ex8.m1.6.6.6.6.2.1">~</ci><ci id="S2.Ex8.m1.6.6.6.6.2.2.cmml" xref="S2.Ex8.m1.6.6.6.6.2.2">𝐭</ci></apply><ci id="S2.Ex8.m1.6.6.6.6.3.cmml" xref="S2.Ex8.m1.6.6.6.6.3">𝑧</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex8.m1.6c">\displaystyle(\tilde{\bm{\theta}}_{x},\tilde{\bm{\theta}}_{y},\tilde{\bm{\theta}}_{z},\tilde{\mathbf{t}}_{x},\tilde{\mathbf{t}}_{y},\tilde{\mathbf{t}}_{z})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex8.m2.1" class="ltx_Math" alttext="\displaystyle:=\text{embed}_{\phi}^{\text{(rot)}}(\mathbf{c})" display="inline"><semantics id="S2.Ex8.m2.1a"><mrow id="S2.Ex8.m2.1.2" xref="S2.Ex8.m2.1.2.cmml"><mi id="S2.Ex8.m2.1.2.2" xref="S2.Ex8.m2.1.2.2.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex8.m2.1.2.1" xref="S2.Ex8.m2.1.2.1.cmml">:=</mo><mrow id="S2.Ex8.m2.1.2.3" xref="S2.Ex8.m2.1.2.3.cmml"><msubsup id="S2.Ex8.m2.1.2.3.2" xref="S2.Ex8.m2.1.2.3.2.cmml"><mtext id="S2.Ex8.m2.1.2.3.2.2.2" xref="S2.Ex8.m2.1.2.3.2.2.2a.cmml">embed</mtext><mi id="S2.Ex8.m2.1.2.3.2.2.3" xref="S2.Ex8.m2.1.2.3.2.2.3.cmml">ϕ</mi><mtext id="S2.Ex8.m2.1.2.3.2.3" xref="S2.Ex8.m2.1.2.3.2.3a.cmml">(rot)</mtext></msubsup><mo lspace="0em" rspace="0em" id="S2.Ex8.m2.1.2.3.1" xref="S2.Ex8.m2.1.2.3.1.cmml">​</mo><mrow id="S2.Ex8.m2.1.2.3.3.2" xref="S2.Ex8.m2.1.2.3.cmml"><mo stretchy="false" id="S2.Ex8.m2.1.2.3.3.2.1" xref="S2.Ex8.m2.1.2.3.cmml">(</mo><mi id="S2.Ex8.m2.1.1" xref="S2.Ex8.m2.1.1.cmml">𝐜</mi><mo stretchy="false" id="S2.Ex8.m2.1.2.3.3.2.2" xref="S2.Ex8.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex8.m2.1b"><apply id="S2.Ex8.m2.1.2.cmml" xref="S2.Ex8.m2.1.2"><csymbol cd="latexml" id="S2.Ex8.m2.1.2.1.cmml" xref="S2.Ex8.m2.1.2.1">assign</csymbol><csymbol cd="latexml" id="S2.Ex8.m2.1.2.2.cmml" xref="S2.Ex8.m2.1.2.2">absent</csymbol><apply id="S2.Ex8.m2.1.2.3.cmml" xref="S2.Ex8.m2.1.2.3"><times id="S2.Ex8.m2.1.2.3.1.cmml" xref="S2.Ex8.m2.1.2.3.1"></times><apply id="S2.Ex8.m2.1.2.3.2.cmml" xref="S2.Ex8.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.Ex8.m2.1.2.3.2.1.cmml" xref="S2.Ex8.m2.1.2.3.2">superscript</csymbol><apply id="S2.Ex8.m2.1.2.3.2.2.cmml" xref="S2.Ex8.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.Ex8.m2.1.2.3.2.2.1.cmml" xref="S2.Ex8.m2.1.2.3.2">subscript</csymbol><ci id="S2.Ex8.m2.1.2.3.2.2.2a.cmml" xref="S2.Ex8.m2.1.2.3.2.2.2"><mtext id="S2.Ex8.m2.1.2.3.2.2.2.cmml" xref="S2.Ex8.m2.1.2.3.2.2.2">embed</mtext></ci><ci id="S2.Ex8.m2.1.2.3.2.2.3.cmml" xref="S2.Ex8.m2.1.2.3.2.2.3">italic-ϕ</ci></apply><ci id="S2.Ex8.m2.1.2.3.2.3a.cmml" xref="S2.Ex8.m2.1.2.3.2.3"><mtext mathsize="70%" id="S2.Ex8.m2.1.2.3.2.3.cmml" xref="S2.Ex8.m2.1.2.3.2.3">(rot)</mtext></ci></apply><ci id="S2.Ex8.m2.1.1.cmml" xref="S2.Ex8.m2.1.1">𝐜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex8.m2.1c">\displaystyle:=\text{embed}_{\phi}^{\text{(rot)}}(\mathbf{c})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex9.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{h}_{\text{rot}}" display="inline"><semantics id="S2.Ex9.m1.1a"><msub id="S2.Ex9.m1.1.1" xref="S2.Ex9.m1.1.1.cmml"><mi id="S2.Ex9.m1.1.1.2" xref="S2.Ex9.m1.1.1.2.cmml">𝐡</mi><mtext id="S2.Ex9.m1.1.1.3" xref="S2.Ex9.m1.1.1.3a.cmml">rot</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.Ex9.m1.1b"><apply id="S2.Ex9.m1.1.1.cmml" xref="S2.Ex9.m1.1.1"><csymbol cd="ambiguous" id="S2.Ex9.m1.1.1.1.cmml" xref="S2.Ex9.m1.1.1">subscript</csymbol><ci id="S2.Ex9.m1.1.1.2.cmml" xref="S2.Ex9.m1.1.1.2">𝐡</ci><ci id="S2.Ex9.m1.1.1.3a.cmml" xref="S2.Ex9.m1.1.1.3"><mtext mathsize="70%" id="S2.Ex9.m1.1.1.3.cmml" xref="S2.Ex9.m1.1.1.3">rot</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex9.m1.1c">\displaystyle\mathbf{h}_{\text{rot}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex9.m2.2" class="ltx_Math" alttext="\displaystyle:=\text{transform}(\mathbf{h};P(\tilde{\bm{\theta}}_{x},\tilde{\bm{\theta}}_{y},\tilde{\bm{\theta}}_{z},\tilde{\mathbf{t}}_{x},\tilde{\mathbf{t}}_{y},\tilde{\mathbf{t}}_{z}))" display="inline"><semantics id="S2.Ex9.m2.2a"><mrow id="S2.Ex9.m2.2.2" xref="S2.Ex9.m2.2.2.cmml"><mi id="S2.Ex9.m2.2.2.3" xref="S2.Ex9.m2.2.2.3.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex9.m2.2.2.2" xref="S2.Ex9.m2.2.2.2.cmml">:=</mo><mrow id="S2.Ex9.m2.2.2.1" xref="S2.Ex9.m2.2.2.1.cmml"><mtext id="S2.Ex9.m2.2.2.1.3" xref="S2.Ex9.m2.2.2.1.3a.cmml">transform</mtext><mo lspace="0em" rspace="0em" id="S2.Ex9.m2.2.2.1.2" xref="S2.Ex9.m2.2.2.1.2.cmml">​</mo><mrow id="S2.Ex9.m2.2.2.1.1.1" xref="S2.Ex9.m2.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.Ex9.m2.2.2.1.1.1.2" xref="S2.Ex9.m2.2.2.1.1.2.cmml">(</mo><mi id="S2.Ex9.m2.1.1" xref="S2.Ex9.m2.1.1.cmml">𝐡</mi><mo id="S2.Ex9.m2.2.2.1.1.1.3" xref="S2.Ex9.m2.2.2.1.1.2.cmml">;</mo><mrow id="S2.Ex9.m2.2.2.1.1.1.1" xref="S2.Ex9.m2.2.2.1.1.1.1.cmml"><mi id="S2.Ex9.m2.2.2.1.1.1.1.8" xref="S2.Ex9.m2.2.2.1.1.1.1.8.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.Ex9.m2.2.2.1.1.1.1.7" xref="S2.Ex9.m2.2.2.1.1.1.1.7.cmml">​</mo><mrow id="S2.Ex9.m2.2.2.1.1.1.1.6.6" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml"><mo stretchy="false" id="S2.Ex9.m2.2.2.1.1.1.1.6.6.7" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml">(</mo><msub id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.2.cmml">𝜽</mi><mo id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.1" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mi id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.3" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S2.Ex9.m2.2.2.1.1.1.1.6.6.8" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml">,</mo><msub id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.cmml"><mover accent="true" id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.cmml"><mi id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.2.cmml">𝜽</mi><mo id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.1" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.1.cmml">~</mo></mover><mi id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.3" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.3.cmml">y</mi></msub><mo id="S2.Ex9.m2.2.2.1.1.1.1.6.6.9" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml">,</mo><msub id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.cmml"><mover accent="true" id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.cmml"><mi id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.2.cmml">𝜽</mi><mo id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.1" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.1.cmml">~</mo></mover><mi id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.3" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.3.cmml">z</mi></msub><mo id="S2.Ex9.m2.2.2.1.1.1.1.6.6.10" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml">,</mo><msub id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.cmml"><mover accent="true" id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.cmml"><mi id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.2.cmml">𝐭</mi><mo id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.1" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.1.cmml">~</mo></mover><mi id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.3" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.3.cmml">x</mi></msub><mo id="S2.Ex9.m2.2.2.1.1.1.1.6.6.11" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml">,</mo><msub id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.cmml"><mover accent="true" id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.cmml"><mi id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.2.cmml">𝐭</mi><mo id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.1" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.1.cmml">~</mo></mover><mi id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.3" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.3.cmml">y</mi></msub><mo id="S2.Ex9.m2.2.2.1.1.1.1.6.6.12" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml">,</mo><msub id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.cmml"><mover accent="true" id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.cmml"><mi id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.2" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.2.cmml">𝐭</mi><mo id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.1" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.1.cmml">~</mo></mover><mi id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.3" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.3.cmml">z</mi></msub><mo stretchy="false" id="S2.Ex9.m2.2.2.1.1.1.1.6.6.13" xref="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex9.m2.2.2.1.1.1.4" xref="S2.Ex9.m2.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex9.m2.2b"><apply id="S2.Ex9.m2.2.2.cmml" xref="S2.Ex9.m2.2.2"><csymbol cd="latexml" id="S2.Ex9.m2.2.2.2.cmml" xref="S2.Ex9.m2.2.2.2">assign</csymbol><csymbol cd="latexml" id="S2.Ex9.m2.2.2.3.cmml" xref="S2.Ex9.m2.2.2.3">absent</csymbol><apply id="S2.Ex9.m2.2.2.1.cmml" xref="S2.Ex9.m2.2.2.1"><times id="S2.Ex9.m2.2.2.1.2.cmml" xref="S2.Ex9.m2.2.2.1.2"></times><ci id="S2.Ex9.m2.2.2.1.3a.cmml" xref="S2.Ex9.m2.2.2.1.3"><mtext id="S2.Ex9.m2.2.2.1.3.cmml" xref="S2.Ex9.m2.2.2.1.3">transform</mtext></ci><list id="S2.Ex9.m2.2.2.1.1.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1"><ci id="S2.Ex9.m2.1.1.cmml" xref="S2.Ex9.m2.1.1">𝐡</ci><apply id="S2.Ex9.m2.2.2.1.1.1.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1"><times id="S2.Ex9.m2.2.2.1.1.1.1.7.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.7"></times><ci id="S2.Ex9.m2.2.2.1.1.1.1.8.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.8">𝑃</ci><vector id="S2.Ex9.m2.2.2.1.1.1.1.6.7.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6"><apply id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2"><ci id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.1">~</ci><ci id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.2.2">𝜽</ci></apply><ci id="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.1.1.1.3">𝑥</ci></apply><apply id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2">subscript</csymbol><apply id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2"><ci id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.1">~</ci><ci id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.2.2">𝜽</ci></apply><ci id="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.3.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.2.2.2.3">𝑦</ci></apply><apply id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3">subscript</csymbol><apply id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2"><ci id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.1">~</ci><ci id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.2.2">𝜽</ci></apply><ci id="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.3.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.3.3.3.3">𝑧</ci></apply><apply id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4"><csymbol cd="ambiguous" id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4">subscript</csymbol><apply id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2"><ci id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.1">~</ci><ci id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.2.2">𝐭</ci></apply><ci id="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.3.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.4.4.4.3">𝑥</ci></apply><apply id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5"><csymbol cd="ambiguous" id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5">subscript</csymbol><apply id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2"><ci id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.1">~</ci><ci id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.2.2">𝐭</ci></apply><ci id="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.3.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.5.5.5.3">𝑦</ci></apply><apply id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6"><csymbol cd="ambiguous" id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6">subscript</csymbol><apply id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2"><ci id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.1.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.1">~</ci><ci id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.2.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.2.2">𝐭</ci></apply><ci id="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.3.cmml" xref="S2.Ex9.m2.2.2.1.1.1.1.6.6.6.3">𝑧</ci></apply></vector></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex9.m2.2c">\displaystyle:=\text{transform}(\mathbf{h};P(\tilde{\bm{\theta}}_{x},\tilde{\bm{\theta}}_{y},\tilde{\bm{\theta}}_{z},\tilde{\mathbf{t}}_{x},\tilde{\mathbf{t}}_{y},\tilde{\mathbf{t}}_{z}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex10"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex10.m1.1" class="ltx_Math" alttext="\displaystyle\tilde{\mathbf{y}}" display="inline"><semantics id="S2.Ex10.m1.1a"><mover accent="true" id="S2.Ex10.m1.1.1" xref="S2.Ex10.m1.1.1.cmml"><mi id="S2.Ex10.m1.1.1.2" xref="S2.Ex10.m1.1.1.2.cmml">𝐲</mi><mo id="S2.Ex10.m1.1.1.1" xref="S2.Ex10.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S2.Ex10.m1.1b"><apply id="S2.Ex10.m1.1.1.cmml" xref="S2.Ex10.m1.1.1"><ci id="S2.Ex10.m1.1.1.1.cmml" xref="S2.Ex10.m1.1.1.1">~</ci><ci id="S2.Ex10.m1.1.1.2.cmml" xref="S2.Ex10.m1.1.1.2">𝐲</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex10.m1.1c">\displaystyle\tilde{\mathbf{y}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex10.m2.3" class="ltx_Math" alttext="\displaystyle:=\text{FILM}_{\phi}(\mathbf{h}_{\text{rot}},[\text{GRU}_{\phi}(\mathbf{q})])" display="inline"><semantics id="S2.Ex10.m2.3a"><mrow id="S2.Ex10.m2.3.3" xref="S2.Ex10.m2.3.3.cmml"><mi id="S2.Ex10.m2.3.3.4" xref="S2.Ex10.m2.3.3.4.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.Ex10.m2.3.3.3" xref="S2.Ex10.m2.3.3.3.cmml">:=</mo><mrow id="S2.Ex10.m2.3.3.2" xref="S2.Ex10.m2.3.3.2.cmml"><msub id="S2.Ex10.m2.3.3.2.4" xref="S2.Ex10.m2.3.3.2.4.cmml"><mtext id="S2.Ex10.m2.3.3.2.4.2" xref="S2.Ex10.m2.3.3.2.4.2a.cmml">FILM</mtext><mi id="S2.Ex10.m2.3.3.2.4.3" xref="S2.Ex10.m2.3.3.2.4.3.cmml">ϕ</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex10.m2.3.3.2.3" xref="S2.Ex10.m2.3.3.2.3.cmml">​</mo><mrow id="S2.Ex10.m2.3.3.2.2.2" xref="S2.Ex10.m2.3.3.2.2.3.cmml"><mo stretchy="false" id="S2.Ex10.m2.3.3.2.2.2.3" xref="S2.Ex10.m2.3.3.2.2.3.cmml">(</mo><msub id="S2.Ex10.m2.2.2.1.1.1.1" xref="S2.Ex10.m2.2.2.1.1.1.1.cmml"><mi id="S2.Ex10.m2.2.2.1.1.1.1.2" xref="S2.Ex10.m2.2.2.1.1.1.1.2.cmml">𝐡</mi><mtext id="S2.Ex10.m2.2.2.1.1.1.1.3" xref="S2.Ex10.m2.2.2.1.1.1.1.3a.cmml">rot</mtext></msub><mo id="S2.Ex10.m2.3.3.2.2.2.4" xref="S2.Ex10.m2.3.3.2.2.3.cmml">,</mo><mrow id="S2.Ex10.m2.3.3.2.2.2.2.1" xref="S2.Ex10.m2.3.3.2.2.2.2.2.cmml"><mo stretchy="false" id="S2.Ex10.m2.3.3.2.2.2.2.1.2" xref="S2.Ex10.m2.3.3.2.2.2.2.2.1.cmml">[</mo><mrow id="S2.Ex10.m2.3.3.2.2.2.2.1.1" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.cmml"><msub id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.cmml"><mtext id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.2" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.2a.cmml">GRU</mtext><mi id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.3" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.3.cmml">ϕ</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex10.m2.3.3.2.2.2.2.1.1.1" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.1.cmml">​</mo><mrow id="S2.Ex10.m2.3.3.2.2.2.2.1.1.3.2" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S2.Ex10.m2.3.3.2.2.2.2.1.1.3.2.1" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.cmml">(</mo><mi id="S2.Ex10.m2.1.1" xref="S2.Ex10.m2.1.1.cmml">𝐪</mi><mo stretchy="false" id="S2.Ex10.m2.3.3.2.2.2.2.1.1.3.2.2" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex10.m2.3.3.2.2.2.2.1.3" xref="S2.Ex10.m2.3.3.2.2.2.2.2.1.cmml">]</mo></mrow><mo stretchy="false" id="S2.Ex10.m2.3.3.2.2.2.5" xref="S2.Ex10.m2.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex10.m2.3b"><apply id="S2.Ex10.m2.3.3.cmml" xref="S2.Ex10.m2.3.3"><csymbol cd="latexml" id="S2.Ex10.m2.3.3.3.cmml" xref="S2.Ex10.m2.3.3.3">assign</csymbol><csymbol cd="latexml" id="S2.Ex10.m2.3.3.4.cmml" xref="S2.Ex10.m2.3.3.4">absent</csymbol><apply id="S2.Ex10.m2.3.3.2.cmml" xref="S2.Ex10.m2.3.3.2"><times id="S2.Ex10.m2.3.3.2.3.cmml" xref="S2.Ex10.m2.3.3.2.3"></times><apply id="S2.Ex10.m2.3.3.2.4.cmml" xref="S2.Ex10.m2.3.3.2.4"><csymbol cd="ambiguous" id="S2.Ex10.m2.3.3.2.4.1.cmml" xref="S2.Ex10.m2.3.3.2.4">subscript</csymbol><ci id="S2.Ex10.m2.3.3.2.4.2a.cmml" xref="S2.Ex10.m2.3.3.2.4.2"><mtext id="S2.Ex10.m2.3.3.2.4.2.cmml" xref="S2.Ex10.m2.3.3.2.4.2">FILM</mtext></ci><ci id="S2.Ex10.m2.3.3.2.4.3.cmml" xref="S2.Ex10.m2.3.3.2.4.3">italic-ϕ</ci></apply><interval closure="open" id="S2.Ex10.m2.3.3.2.2.3.cmml" xref="S2.Ex10.m2.3.3.2.2.2"><apply id="S2.Ex10.m2.2.2.1.1.1.1.cmml" xref="S2.Ex10.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex10.m2.2.2.1.1.1.1.1.cmml" xref="S2.Ex10.m2.2.2.1.1.1.1">subscript</csymbol><ci id="S2.Ex10.m2.2.2.1.1.1.1.2.cmml" xref="S2.Ex10.m2.2.2.1.1.1.1.2">𝐡</ci><ci id="S2.Ex10.m2.2.2.1.1.1.1.3a.cmml" xref="S2.Ex10.m2.2.2.1.1.1.1.3"><mtext mathsize="70%" id="S2.Ex10.m2.2.2.1.1.1.1.3.cmml" xref="S2.Ex10.m2.2.2.1.1.1.1.3">rot</mtext></ci></apply><apply id="S2.Ex10.m2.3.3.2.2.2.2.2.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1"><csymbol cd="latexml" id="S2.Ex10.m2.3.3.2.2.2.2.2.1.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.2">delimited-[]</csymbol><apply id="S2.Ex10.m2.3.3.2.2.2.2.1.1.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1"><times id="S2.Ex10.m2.3.3.2.2.2.2.1.1.1.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.1"></times><apply id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.1.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2">subscript</csymbol><ci id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.2a.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.2"><mtext id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.2.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.2">GRU</mtext></ci><ci id="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.3.cmml" xref="S2.Ex10.m2.3.3.2.2.2.2.1.1.2.3">italic-ϕ</ci></apply><ci id="S2.Ex10.m2.1.1.cmml" xref="S2.Ex10.m2.1.1">𝐪</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex10.m2.3c">\displaystyle:=\text{FILM}_{\phi}(\mathbf{h}_{\text{rot}},[\text{GRU}_{\phi}(\mathbf{q})])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E2.m1.1" class="ltx_Math" alttext="\displaystyle\ell_{\text{cls}}" display="inline"><semantics id="S2.E2.m1.1a"><msub id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mi mathvariant="normal" id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml">ℓ</mi><mtext id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3a.cmml">cls</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2">ℓ</ci><ci id="S2.E2.m1.1.1.3a.cmml" xref="S2.E2.m1.1.1.3"><mtext mathsize="70%" id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3">cls</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\displaystyle\ell_{\text{cls}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E2.m2.3" class="ltx_Math" alttext="\displaystyle:=\ell(\mathbf{y},\tilde{\mathbf{y}})," display="inline"><semantics id="S2.E2.m2.3a"><mrow id="S2.E2.m2.3.3.1" xref="S2.E2.m2.3.3.1.1.cmml"><mrow id="S2.E2.m2.3.3.1.1" xref="S2.E2.m2.3.3.1.1.cmml"><mi id="S2.E2.m2.3.3.1.1.2" xref="S2.E2.m2.3.3.1.1.2.cmml"></mi><mo lspace="0.278em" rspace="0.278em" id="S2.E2.m2.3.3.1.1.1" xref="S2.E2.m2.3.3.1.1.1.cmml">:=</mo><mrow id="S2.E2.m2.3.3.1.1.3" xref="S2.E2.m2.3.3.1.1.3.cmml"><mi mathvariant="normal" id="S2.E2.m2.3.3.1.1.3.2" xref="S2.E2.m2.3.3.1.1.3.2.cmml">ℓ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m2.3.3.1.1.3.1" xref="S2.E2.m2.3.3.1.1.3.1.cmml">​</mo><mrow id="S2.E2.m2.3.3.1.1.3.3.2" xref="S2.E2.m2.3.3.1.1.3.3.1.cmml"><mo stretchy="false" id="S2.E2.m2.3.3.1.1.3.3.2.1" xref="S2.E2.m2.3.3.1.1.3.3.1.cmml">(</mo><mi id="S2.E2.m2.1.1" xref="S2.E2.m2.1.1.cmml">𝐲</mi><mo id="S2.E2.m2.3.3.1.1.3.3.2.2" xref="S2.E2.m2.3.3.1.1.3.3.1.cmml">,</mo><mover accent="true" id="S2.E2.m2.2.2" xref="S2.E2.m2.2.2.cmml"><mi id="S2.E2.m2.2.2.2" xref="S2.E2.m2.2.2.2.cmml">𝐲</mi><mo id="S2.E2.m2.2.2.1" xref="S2.E2.m2.2.2.1.cmml">~</mo></mover><mo stretchy="false" id="S2.E2.m2.3.3.1.1.3.3.2.3" xref="S2.E2.m2.3.3.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E2.m2.3.3.1.2" xref="S2.E2.m2.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m2.3b"><apply id="S2.E2.m2.3.3.1.1.cmml" xref="S2.E2.m2.3.3.1"><csymbol cd="latexml" id="S2.E2.m2.3.3.1.1.1.cmml" xref="S2.E2.m2.3.3.1.1.1">assign</csymbol><csymbol cd="latexml" id="S2.E2.m2.3.3.1.1.2.cmml" xref="S2.E2.m2.3.3.1.1.2">absent</csymbol><apply id="S2.E2.m2.3.3.1.1.3.cmml" xref="S2.E2.m2.3.3.1.1.3"><times id="S2.E2.m2.3.3.1.1.3.1.cmml" xref="S2.E2.m2.3.3.1.1.3.1"></times><ci id="S2.E2.m2.3.3.1.1.3.2.cmml" xref="S2.E2.m2.3.3.1.1.3.2">ℓ</ci><interval closure="open" id="S2.E2.m2.3.3.1.1.3.3.1.cmml" xref="S2.E2.m2.3.3.1.1.3.3.2"><ci id="S2.E2.m2.1.1.cmml" xref="S2.E2.m2.1.1">𝐲</ci><apply id="S2.E2.m2.2.2.cmml" xref="S2.E2.m2.2.2"><ci id="S2.E2.m2.2.2.1.cmml" xref="S2.E2.m2.2.2.1">~</ci><ci id="S2.E2.m2.2.2.2.cmml" xref="S2.E2.m2.2.2.2">𝐲</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m2.3c">\displaystyle:=\ell(\mathbf{y},\tilde{\mathbf{y}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS2.p1.5" class="ltx_p">where <math id="S2.SS2.SSS2.p1.5.m1.1" class="ltx_Math" alttext="P(\cdot)" display="inline"><semantics id="S2.SS2.SSS2.p1.5.m1.1a"><mrow id="S2.SS2.SSS2.p1.5.m1.1.2" xref="S2.SS2.SSS2.p1.5.m1.1.2.cmml"><mi id="S2.SS2.SSS2.p1.5.m1.1.2.2" xref="S2.SS2.SSS2.p1.5.m1.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS2.p1.5.m1.1.2.1" xref="S2.SS2.SSS2.p1.5.m1.1.2.1.cmml">​</mo><mrow id="S2.SS2.SSS2.p1.5.m1.1.2.3.2" xref="S2.SS2.SSS2.p1.5.m1.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS2.p1.5.m1.1.2.3.2.1" xref="S2.SS2.SSS2.p1.5.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS2.SSS2.p1.5.m1.1.1" xref="S2.SS2.SSS2.p1.5.m1.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.SS2.SSS2.p1.5.m1.1.2.3.2.2" xref="S2.SS2.SSS2.p1.5.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p1.5.m1.1b"><apply id="S2.SS2.SSS2.p1.5.m1.1.2.cmml" xref="S2.SS2.SSS2.p1.5.m1.1.2"><times id="S2.SS2.SSS2.p1.5.m1.1.2.1.cmml" xref="S2.SS2.SSS2.p1.5.m1.1.2.1"></times><ci id="S2.SS2.SSS2.p1.5.m1.1.2.2.cmml" xref="S2.SS2.SSS2.p1.5.m1.1.2.2">𝑃</ci><ci id="S2.SS2.SSS2.p1.5.m1.1.1.cmml" xref="S2.SS2.SSS2.p1.5.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p1.5.m1.1c">P(\cdot)</annotation></semantics></math> is a function that produces a rigid transform matrix from its arguments, which are Euler angles. This is illustrated in Figure <a href="#S2.F5" title="Figure 5 ‣ 2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="/html/2212.01639/assets/x4.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="140" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F5.8.4.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S2.F5.6.3" class="ltx_text" style="font-size:90%;">The 3D version of the FILM pipeline proposed in Section <a href="#S2.SS2" title="2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>. The encoder can be either the 2D-to-3D formulation in Section <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a> (with the ResNet-101 inside it frozen but the postprocessor block learnable, i.e. Figure <a href="#S2.F4" title="Figure 4 ‣ 2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) or the contrastive encoder in Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a> (which directly maps to 3D volumes and is also frozen). A camera encoder <math id="S2.F5.4.1.m1.1" class="ltx_Math" alttext="\text{embed}_{\psi}^{\text{(rot)}}(\mathbf{c})" display="inline"><semantics id="S2.F5.4.1.m1.1b"><mrow id="S2.F5.4.1.m1.1.2" xref="S2.F5.4.1.m1.1.2.cmml"><msubsup id="S2.F5.4.1.m1.1.2.2" xref="S2.F5.4.1.m1.1.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S2.F5.4.1.m1.1.2.2.2.2" xref="S2.F5.4.1.m1.1.2.2.2.2a.cmml">embed</mtext><mi id="S2.F5.4.1.m1.1.2.2.2.3" xref="S2.F5.4.1.m1.1.2.2.2.3.cmml">ψ</mi><mtext class="ltx_mathvariant_bold" id="S2.F5.4.1.m1.1.2.2.3" xref="S2.F5.4.1.m1.1.2.2.3a.cmml">(rot)</mtext></msubsup><mo lspace="0em" rspace="0em" id="S2.F5.4.1.m1.1.2.1" xref="S2.F5.4.1.m1.1.2.1.cmml">​</mo><mrow id="S2.F5.4.1.m1.1.2.3.2" xref="S2.F5.4.1.m1.1.2.cmml"><mo stretchy="false" id="S2.F5.4.1.m1.1.2.3.2.1" xref="S2.F5.4.1.m1.1.2.cmml">(</mo><mi id="S2.F5.4.1.m1.1.1" xref="S2.F5.4.1.m1.1.1.cmml">𝐜</mi><mo stretchy="false" id="S2.F5.4.1.m1.1.2.3.2.2" xref="S2.F5.4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.F5.4.1.m1.1c"><apply id="S2.F5.4.1.m1.1.2.cmml" xref="S2.F5.4.1.m1.1.2"><times id="S2.F5.4.1.m1.1.2.1.cmml" xref="S2.F5.4.1.m1.1.2.1"></times><apply id="S2.F5.4.1.m1.1.2.2.cmml" xref="S2.F5.4.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.F5.4.1.m1.1.2.2.1.cmml" xref="S2.F5.4.1.m1.1.2.2">superscript</csymbol><apply id="S2.F5.4.1.m1.1.2.2.2.cmml" xref="S2.F5.4.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.F5.4.1.m1.1.2.2.2.1.cmml" xref="S2.F5.4.1.m1.1.2.2">subscript</csymbol><ci id="S2.F5.4.1.m1.1.2.2.2.2a.cmml" xref="S2.F5.4.1.m1.1.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S2.F5.4.1.m1.1.2.2.2.2.cmml" xref="S2.F5.4.1.m1.1.2.2.2.2">embed</mtext></ci><ci id="S2.F5.4.1.m1.1.2.2.2.3.cmml" xref="S2.F5.4.1.m1.1.2.2.2.3">𝜓</ci></apply><ci id="S2.F5.4.1.m1.1.2.2.3a.cmml" xref="S2.F5.4.1.m1.1.2.2.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S2.F5.4.1.m1.1.2.2.3.cmml" xref="S2.F5.4.1.m1.1.2.2.3">(rot)</mtext></ci></apply><ci id="S2.F5.4.1.m1.1.1.cmml" xref="S2.F5.4.1.m1.1.1">𝐜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F5.4.1.m1.1d">\text{embed}_{\psi}^{\text{(rot)}}(\mathbf{c})</annotation></semantics></math> is trained to map the camera coordinates of the scene to a transformation matrix which is used to transform the resulting 4D volume via an explicit rotation and translation, and/or it can be embedded and concatenated with the GRU embedding via <math id="S2.F5.5.2.m2.1" class="ltx_Math" alttext="\text{embed}_{\phi}^{\text{(film)}}" display="inline"><semantics id="S2.F5.5.2.m2.1b"><msubsup id="S2.F5.5.2.m2.1.1" xref="S2.F5.5.2.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S2.F5.5.2.m2.1.1.2.2" xref="S2.F5.5.2.m2.1.1.2.2a.cmml">embed</mtext><mi id="S2.F5.5.2.m2.1.1.2.3" xref="S2.F5.5.2.m2.1.1.2.3.cmml">ϕ</mi><mtext class="ltx_mathvariant_bold" id="S2.F5.5.2.m2.1.1.3" xref="S2.F5.5.2.m2.1.1.3a.cmml">(film)</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S2.F5.5.2.m2.1c"><apply id="S2.F5.5.2.m2.1.1.cmml" xref="S2.F5.5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.F5.5.2.m2.1.1.1.cmml" xref="S2.F5.5.2.m2.1.1">superscript</csymbol><apply id="S2.F5.5.2.m2.1.1.2.cmml" xref="S2.F5.5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.F5.5.2.m2.1.1.2.1.cmml" xref="S2.F5.5.2.m2.1.1">subscript</csymbol><ci id="S2.F5.5.2.m2.1.1.2.2a.cmml" xref="S2.F5.5.2.m2.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S2.F5.5.2.m2.1.1.2.2.cmml" xref="S2.F5.5.2.m2.1.1.2.2">embed</mtext></ci><ci id="S2.F5.5.2.m2.1.1.2.3.cmml" xref="S2.F5.5.2.m2.1.1.2.3">italic-ϕ</ci></apply><ci id="S2.F5.5.2.m2.1.1.3a.cmml" xref="S2.F5.5.2.m2.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S2.F5.5.2.m2.1.1.3.cmml" xref="S2.F5.5.2.m2.1.1.3">(film)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F5.5.2.m2.1d">\text{embed}_{\phi}^{\text{(film)}}</annotation></semantics></math> (the dotted lines for both indicate that either/or are optional). This volume is then fed to FILM-modulated ResBlocks, which utilise 3D convolutions since <math id="S2.F5.6.3.m3.1" class="ltx_Math" alttext="\mathbf{h}" display="inline"><semantics id="S2.F5.6.3.m3.1b"><mi id="S2.F5.6.3.m3.1.1" xref="S2.F5.6.3.m3.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.F5.6.3.m3.1c"><ci id="S2.F5.6.3.m3.1.1.cmml" xref="S2.F5.6.3.m3.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F5.6.3.m3.1d">\mathbf{h}</annotation></semantics></math> is now a volume instead of feature maps.</span></figcaption>
</figure>
<div id="S2.SS2.SSS2.p2" class="ltx_para">
<p id="S2.SS2.SSS2.p2.4" class="ltx_p">Note that there are now two ways in which the viewpoint camera can modulate the VQA pipeline: either through FILM via <math id="S2.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\text{embed}_{\phi}^{\text{(film)}}" display="inline"><semantics id="S2.SS2.SSS2.p2.1.m1.1a"><msubsup id="S2.SS2.SSS2.p2.1.m1.1.1" xref="S2.SS2.SSS2.p2.1.m1.1.1.cmml"><mtext id="S2.SS2.SSS2.p2.1.m1.1.1.2.2" xref="S2.SS2.SSS2.p2.1.m1.1.1.2.2a.cmml">embed</mtext><mi id="S2.SS2.SSS2.p2.1.m1.1.1.2.3" xref="S2.SS2.SSS2.p2.1.m1.1.1.2.3.cmml">ϕ</mi><mtext id="S2.SS2.SSS2.p2.1.m1.1.1.3" xref="S2.SS2.SSS2.p2.1.m1.1.1.3a.cmml">(film)</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.1.m1.1b"><apply id="S2.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1">superscript</csymbol><apply id="S2.SS2.SSS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.1.m1.1.1.2.1.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS2.p2.1.m1.1.1.2.2a.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1.2.2"><mtext id="S2.SS2.SSS2.p2.1.m1.1.1.2.2.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1.2.2">embed</mtext></ci><ci id="S2.SS2.SSS2.p2.1.m1.1.1.2.3.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1.2.3">italic-ϕ</ci></apply><ci id="S2.SS2.SSS2.p2.1.m1.1.1.3a.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1.3"><mtext mathsize="70%" id="S2.SS2.SSS2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.SSS2.p2.1.m1.1.1.3">(film)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.1.m1.1c">\text{embed}_{\phi}^{\text{(film)}}</annotation></semantics></math> or by directly parameterising a rigid transformation with <math id="S2.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="\text{embed}_{\phi}^{\text{(rot)}}" display="inline"><semantics id="S2.SS2.SSS2.p2.2.m2.1a"><msubsup id="S2.SS2.SSS2.p2.2.m2.1.1" xref="S2.SS2.SSS2.p2.2.m2.1.1.cmml"><mtext id="S2.SS2.SSS2.p2.2.m2.1.1.2.2" xref="S2.SS2.SSS2.p2.2.m2.1.1.2.2a.cmml">embed</mtext><mi id="S2.SS2.SSS2.p2.2.m2.1.1.2.3" xref="S2.SS2.SSS2.p2.2.m2.1.1.2.3.cmml">ϕ</mi><mtext id="S2.SS2.SSS2.p2.2.m2.1.1.3" xref="S2.SS2.SSS2.p2.2.m2.1.1.3a.cmml">(rot)</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.2.m2.1b"><apply id="S2.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.2.m2.1.1.1.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1">superscript</csymbol><apply id="S2.SS2.SSS2.p2.2.m2.1.1.2.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.2.m2.1.1.2.1.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.SSS2.p2.2.m2.1.1.2.2a.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1.2.2"><mtext id="S2.SS2.SSS2.p2.2.m2.1.1.2.2.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1.2.2">embed</mtext></ci><ci id="S2.SS2.SSS2.p2.2.m2.1.1.2.3.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1.2.3">italic-ϕ</ci></apply><ci id="S2.SS2.SSS2.p2.2.m2.1.1.3a.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1.3"><mtext mathsize="70%" id="S2.SS2.SSS2.p2.2.m2.1.1.3.cmml" xref="S2.SS2.SSS2.p2.2.m2.1.1.3">(rot)</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.2.m2.1c">\text{embed}_{\phi}^{\text{(rot)}}</annotation></semantics></math>. While both mechanisms are shown in Figure <a href="#S2.F5" title="Figure 5 ‣ 2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, for brevity’s sake we have only shown in the latter in Equation <a href="#S2.Ex7" title="2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.2</span></a>. Also note that we cannot directly use the raw camera parameters <math id="S2.SS2.SSS2.p2.3.m3.6" class="ltx_Math" alttext="\mathbf{c}=(\bm{\theta}_{x},\bm{\theta}_{y},\bm{\theta}_{z},\mathbf{t}_{x},\mathbf{t}_{y},\mathbf{t}_{z})" display="inline"><semantics id="S2.SS2.SSS2.p2.3.m3.6a"><mrow id="S2.SS2.SSS2.p2.3.m3.6.6" xref="S2.SS2.SSS2.p2.3.m3.6.6.cmml"><mi id="S2.SS2.SSS2.p2.3.m3.6.6.8" xref="S2.SS2.SSS2.p2.3.m3.6.6.8.cmml">𝐜</mi><mo id="S2.SS2.SSS2.p2.3.m3.6.6.7" xref="S2.SS2.SSS2.p2.3.m3.6.6.7.cmml">=</mo><mrow id="S2.SS2.SSS2.p2.3.m3.6.6.6.6" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml"><mo stretchy="false" id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.7" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml">(</mo><msub id="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1" xref="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.2" xref="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.2.cmml">𝜽</mi><mi id="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.3" xref="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.8" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2" xref="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.cmml"><mi id="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.2" xref="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.2.cmml">𝜽</mi><mi id="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.3" xref="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.3.cmml">y</mi></msub><mo id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.9" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3" xref="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.cmml"><mi id="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.2" xref="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.2.cmml">𝜽</mi><mi id="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.3" xref="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.3.cmml">z</mi></msub><mo id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.10" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4" xref="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.cmml"><mi id="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.2" xref="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.2.cmml">𝐭</mi><mi id="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.3" xref="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.3.cmml">x</mi></msub><mo id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.11" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5" xref="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.cmml"><mi id="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.2" xref="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.2.cmml">𝐭</mi><mi id="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.3" xref="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.3.cmml">y</mi></msub><mo id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.12" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml">,</mo><msub id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.cmml"><mi id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.2" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.2.cmml">𝐭</mi><mi id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.3" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.3.cmml">z</mi></msub><mo stretchy="false" id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.13" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.3.m3.6b"><apply id="S2.SS2.SSS2.p2.3.m3.6.6.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6"><eq id="S2.SS2.SSS2.p2.3.m3.6.6.7.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6.7"></eq><ci id="S2.SS2.SSS2.p2.3.m3.6.6.8.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6.8">𝐜</ci><vector id="S2.SS2.SSS2.p2.3.m3.6.6.6.7.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6"><apply id="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.cmml" xref="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.2">𝜽</ci><ci id="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS2.p2.3.m3.1.1.1.1.1.3">𝑥</ci></apply><apply id="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.cmml" xref="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.1.cmml" xref="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2">subscript</csymbol><ci id="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.2">𝜽</ci><ci id="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.3.cmml" xref="S2.SS2.SSS2.p2.3.m3.2.2.2.2.2.3">𝑦</ci></apply><apply id="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.cmml" xref="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.1.cmml" xref="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3">subscript</csymbol><ci id="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.2.cmml" xref="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.2">𝜽</ci><ci id="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.3.cmml" xref="S2.SS2.SSS2.p2.3.m3.3.3.3.3.3.3">𝑧</ci></apply><apply id="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.cmml" xref="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.1.cmml" xref="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4">subscript</csymbol><ci id="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.2.cmml" xref="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.2">𝐭</ci><ci id="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.3.cmml" xref="S2.SS2.SSS2.p2.3.m3.4.4.4.4.4.3">𝑥</ci></apply><apply id="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.cmml" xref="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.1.cmml" xref="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5">subscript</csymbol><ci id="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.2.cmml" xref="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.2">𝐭</ci><ci id="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.3.cmml" xref="S2.SS2.SSS2.p2.3.m3.5.5.5.5.5.3">𝑦</ci></apply><apply id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6"><csymbol cd="ambiguous" id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.1.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6">subscript</csymbol><ci id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.2.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.2">𝐭</ci><ci id="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.3.cmml" xref="S2.SS2.SSS2.p2.3.m3.6.6.6.6.6.3">𝑧</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.3.m3.6c">\mathbf{c}=(\bm{\theta}_{x},\bm{\theta}_{y},\bm{\theta}_{z},\mathbf{t}_{x},\mathbf{t}_{y},\mathbf{t}_{z})</annotation></semantics></math> to construct the rigid transform <math id="S2.SS2.SSS2.p2.4.m4.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S2.SS2.SSS2.p2.4.m4.1a"><mi mathvariant="normal" id="S2.SS2.SSS2.p2.4.m4.1.1" xref="S2.SS2.SSS2.p2.4.m4.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.4.m4.1b"><ci id="S2.SS2.SSS2.p2.4.m4.1.1.cmml" xref="S2.SS2.SSS2.p2.4.m4.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.4.m4.1c">\Theta</annotation></semantics></math> because these are relative to world coordinates, not the canonical camera (whose coordinates are unknown).</p>
</div>
<div id="S2.SS2.SSS2.p3" class="ltx_para">
<p id="S2.SS2.SSS2.p3.1" class="ltx_p">In the following next section (Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a>), we will show that we can replace the pre-trained ImageNet encoder and the learned postprocessor (Figure <a href="#S2.F4" title="Figure 4 ‣ 2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) with a contrastive encoder trained from scratch.</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>Learning 3D Contrastive Encoders</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.2" class="ltx_p">In Section <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a> the encoder proposed was an adaptation of a pre-trained ImageNet classifier backbone to output latent volumes. Here we propose the training of an encoder from scratch in an self-supervised manner, via the use of contrastive learning as demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Conceptually, we would like to learn a metric space where the distance between two views from the <em id="S2.SS2.SSS3.p1.2.1" class="ltx_emph ltx_font_italic">same</em> scene are minimised, and views from two <em id="S2.SS2.SSS3.p1.2.2" class="ltx_emph ltx_font_italic">different</em> scenes are maximised. In practice, the architecture we use is one which directly maps images to latent volumes via a sequence of 2D convolutions followed by 3D convolutions (the <math id="S2.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{h}" display="inline"><semantics id="S2.SS2.SSS3.p1.1.m1.1a"><mi id="S2.SS2.SSS3.p1.1.m1.1.1" xref="S2.SS2.SSS3.p1.1.m1.1.1.cmml">𝐡</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p1.1.m1.1b"><ci id="S2.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS3.p1.1.m1.1.1">𝐡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p1.1.m1.1c">\mathbf{h}</annotation></semantics></math> encoder), followed by the <math id="S2.SS2.SSS3.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{z}" display="inline"><semantics id="S2.SS2.SSS3.p1.2.m2.1a"><mi id="S2.SS2.SSS3.p1.2.m2.1.1" xref="S2.SS2.SSS3.p1.2.m2.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p1.2.m2.1b"><ci id="S2.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS3.p1.2.m2.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p1.2.m2.1c">\mathbf{z}</annotation></semantics></math> encoder which reduces those volumes down to latent codes which is what the contrastive loss operates on. This is shown in Figure <a href="#S2.F6" title="Figure 6 ‣ 2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The key idea to note here is that the training of this encoder does not require any information about the cameras in the scene, nor labels describing objects in the scene (unlike with the ImageNet classifier that was repurposed as an encoder). While we obviously do use camera information for the VQA task itself (for instance the camera embedding modules in Figures <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S2.F5" title="Figure 5 ‣ 2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), we stress that being able to pre-train an encoder as a separate step to the VQA task under limited label supervision is potentially very beneficial in real-world applications where obtaining labels for the VQA task is costly.</p>
</div>
<figure id="S2.F6" class="ltx_figure"><img src="/html/2212.01639/assets/x5.png" id="S2.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="125" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F6.12.6.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S2.F6.10.5" class="ltx_text" style="font-size:90%;">The contrastive-based encoder, inspired from <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. We sample two sets of minibatches <math id="S2.F6.6.1.m1.1" class="ltx_Math" alttext="\mathbf{X}^{(1)}" display="inline"><semantics id="S2.F6.6.1.m1.1b"><msup id="S2.F6.6.1.m1.1.2" xref="S2.F6.6.1.m1.1.2.cmml"><mi id="S2.F6.6.1.m1.1.2.2" xref="S2.F6.6.1.m1.1.2.2.cmml">𝐗</mi><mrow id="S2.F6.6.1.m1.1.1.1.3" xref="S2.F6.6.1.m1.1.2.cmml"><mo stretchy="false" id="S2.F6.6.1.m1.1.1.1.3.1" xref="S2.F6.6.1.m1.1.2.cmml">(</mo><mn id="S2.F6.6.1.m1.1.1.1.1" xref="S2.F6.6.1.m1.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.F6.6.1.m1.1.1.1.3.2" xref="S2.F6.6.1.m1.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.F6.6.1.m1.1c"><apply id="S2.F6.6.1.m1.1.2.cmml" xref="S2.F6.6.1.m1.1.2"><csymbol cd="ambiguous" id="S2.F6.6.1.m1.1.2.1.cmml" xref="S2.F6.6.1.m1.1.2">superscript</csymbol><ci id="S2.F6.6.1.m1.1.2.2.cmml" xref="S2.F6.6.1.m1.1.2.2">𝐗</ci><cn type="integer" id="S2.F6.6.1.m1.1.1.1.1.cmml" xref="S2.F6.6.1.m1.1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F6.6.1.m1.1d">\mathbf{X}^{(1)}</annotation></semantics></math> and <math id="S2.F6.7.2.m2.1" class="ltx_Math" alttext="\mathbf{X}^{(2)}" display="inline"><semantics id="S2.F6.7.2.m2.1b"><msup id="S2.F6.7.2.m2.1.2" xref="S2.F6.7.2.m2.1.2.cmml"><mi id="S2.F6.7.2.m2.1.2.2" xref="S2.F6.7.2.m2.1.2.2.cmml">𝐗</mi><mrow id="S2.F6.7.2.m2.1.1.1.3" xref="S2.F6.7.2.m2.1.2.cmml"><mo stretchy="false" id="S2.F6.7.2.m2.1.1.1.3.1" xref="S2.F6.7.2.m2.1.2.cmml">(</mo><mn id="S2.F6.7.2.m2.1.1.1.1" xref="S2.F6.7.2.m2.1.1.1.1.cmml">2</mn><mo stretchy="false" id="S2.F6.7.2.m2.1.1.1.3.2" xref="S2.F6.7.2.m2.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.F6.7.2.m2.1c"><apply id="S2.F6.7.2.m2.1.2.cmml" xref="S2.F6.7.2.m2.1.2"><csymbol cd="ambiguous" id="S2.F6.7.2.m2.1.2.1.cmml" xref="S2.F6.7.2.m2.1.2">superscript</csymbol><ci id="S2.F6.7.2.m2.1.2.2.cmml" xref="S2.F6.7.2.m2.1.2.2">𝐗</ci><cn type="integer" id="S2.F6.7.2.m2.1.1.1.1.cmml" xref="S2.F6.7.2.m2.1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F6.7.2.m2.1d">\mathbf{X}^{(2)}</annotation></semantics></math>, where the <math id="S2.F6.8.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.F6.8.3.m3.1b"><mi id="S2.F6.8.3.m3.1.1" xref="S2.F6.8.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.F6.8.3.m3.1c"><ci id="S2.F6.8.3.m3.1.1.cmml" xref="S2.F6.8.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F6.8.3.m3.1d">i</annotation></semantics></math>’th instance in each set comprises a positive pair (different views of the same scene). The <math id="S2.F6.9.4.m4.1" class="ltx_Math" alttext="\mathbf{H}" display="inline"><semantics id="S2.F6.9.4.m4.1b"><mi id="S2.F6.9.4.m4.1.1" xref="S2.F6.9.4.m4.1.1.cmml">𝐇</mi><annotation-xml encoding="MathML-Content" id="S2.F6.9.4.m4.1c"><ci id="S2.F6.9.4.m4.1.1.cmml" xref="S2.F6.9.4.m4.1.1">𝐇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F6.9.4.m4.1d">\mathbf{H}</annotation></semantics></math> encoder generates a 3D volume for each view, and an additional <math id="S2.F6.10.5.m5.1" class="ltx_Math" alttext="\mathbf{Z}" display="inline"><semantics id="S2.F6.10.5.m5.1b"><mi id="S2.F6.10.5.m5.1.1" xref="S2.F6.10.5.m5.1.1.cmml">𝐙</mi><annotation-xml encoding="MathML-Content" id="S2.F6.10.5.m5.1c"><ci id="S2.F6.10.5.m5.1.1.cmml" xref="S2.F6.10.5.m5.1.1">𝐙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F6.10.5.m5.1d">\mathbf{Z}</annotation></semantics></math> encoder convolves this down to a summarisation vector over which the contrastive loss is applied.</span></figcaption>
</figure>
<div id="S2.SS2.SSS3.p2" class="ltx_para">
<p id="S2.SS2.SSS3.p2.6" class="ltx_p">Let us denote <math id="S2.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{X}^{(1)}" display="inline"><semantics id="S2.SS2.SSS3.p2.1.m1.1a"><msup id="S2.SS2.SSS3.p2.1.m1.1.2" xref="S2.SS2.SSS3.p2.1.m1.1.2.cmml"><mi id="S2.SS2.SSS3.p2.1.m1.1.2.2" xref="S2.SS2.SSS3.p2.1.m1.1.2.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p2.1.m1.1.1.1.3" xref="S2.SS2.SSS3.p2.1.m1.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.1.m1.1.1.1.3.1" xref="S2.SS2.SSS3.p2.1.m1.1.2.cmml">(</mo><mn id="S2.SS2.SSS3.p2.1.m1.1.1.1.1" xref="S2.SS2.SSS3.p2.1.m1.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS3.p2.1.m1.1.1.1.3.2" xref="S2.SS2.SSS3.p2.1.m1.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.1.m1.1b"><apply id="S2.SS2.SSS3.p2.1.m1.1.2.cmml" xref="S2.SS2.SSS3.p2.1.m1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.1.m1.1.2.1.cmml" xref="S2.SS2.SSS3.p2.1.m1.1.2">superscript</csymbol><ci id="S2.SS2.SSS3.p2.1.m1.1.2.2.cmml" xref="S2.SS2.SSS3.p2.1.m1.1.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p2.1.m1.1.1.1.1.cmml" xref="S2.SS2.SSS3.p2.1.m1.1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.1.m1.1c">\mathbf{X}^{(1)}</annotation></semantics></math> and <math id="S2.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{X}^{(2)}" display="inline"><semantics id="S2.SS2.SSS3.p2.2.m2.1a"><msup id="S2.SS2.SSS3.p2.2.m2.1.2" xref="S2.SS2.SSS3.p2.2.m2.1.2.cmml"><mi id="S2.SS2.SSS3.p2.2.m2.1.2.2" xref="S2.SS2.SSS3.p2.2.m2.1.2.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p2.2.m2.1.1.1.3" xref="S2.SS2.SSS3.p2.2.m2.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.2.m2.1.1.1.3.1" xref="S2.SS2.SSS3.p2.2.m2.1.2.cmml">(</mo><mn id="S2.SS2.SSS3.p2.2.m2.1.1.1.1" xref="S2.SS2.SSS3.p2.2.m2.1.1.1.1.cmml">2</mn><mo stretchy="false" id="S2.SS2.SSS3.p2.2.m2.1.1.1.3.2" xref="S2.SS2.SSS3.p2.2.m2.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.2.m2.1b"><apply id="S2.SS2.SSS3.p2.2.m2.1.2.cmml" xref="S2.SS2.SSS3.p2.2.m2.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.2.m2.1.2.1.cmml" xref="S2.SS2.SSS3.p2.2.m2.1.2">superscript</csymbol><ci id="S2.SS2.SSS3.p2.2.m2.1.2.2.cmml" xref="S2.SS2.SSS3.p2.2.m2.1.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p2.2.m2.1.1.1.1.cmml" xref="S2.SS2.SSS3.p2.2.m2.1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.2.m2.1c">\mathbf{X}^{(2)}</annotation></semantics></math> to be minibatches of images (views), with subscripts for individual examples in the minibatch (e.g. <math id="S2.SS2.SSS3.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{X}^{(1)}_{j}" display="inline"><semantics id="S2.SS2.SSS3.p2.3.m3.1a"><msubsup id="S2.SS2.SSS3.p2.3.m3.1.2" xref="S2.SS2.SSS3.p2.3.m3.1.2.cmml"><mi id="S2.SS2.SSS3.p2.3.m3.1.2.2.2" xref="S2.SS2.SSS3.p2.3.m3.1.2.2.2.cmml">𝐗</mi><mi id="S2.SS2.SSS3.p2.3.m3.1.2.3" xref="S2.SS2.SSS3.p2.3.m3.1.2.3.cmml">j</mi><mrow id="S2.SS2.SSS3.p2.3.m3.1.1.1.3" xref="S2.SS2.SSS3.p2.3.m3.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.3.m3.1.1.1.3.1" xref="S2.SS2.SSS3.p2.3.m3.1.2.cmml">(</mo><mn id="S2.SS2.SSS3.p2.3.m3.1.1.1.1" xref="S2.SS2.SSS3.p2.3.m3.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS3.p2.3.m3.1.1.1.3.2" xref="S2.SS2.SSS3.p2.3.m3.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.3.m3.1b"><apply id="S2.SS2.SSS3.p2.3.m3.1.2.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.3.m3.1.2.1.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.2">subscript</csymbol><apply id="S2.SS2.SSS3.p2.3.m3.1.2.2.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.3.m3.1.2.2.1.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.2">superscript</csymbol><ci id="S2.SS2.SSS3.p2.3.m3.1.2.2.2.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.2.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p2.3.m3.1.1.1.1.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.1.1.1">1</cn></apply><ci id="S2.SS2.SSS3.p2.3.m3.1.2.3.cmml" xref="S2.SS2.SSS3.p2.3.m3.1.2.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.3.m3.1c">\mathbf{X}^{(1)}_{j}</annotation></semantics></math>). We will assume that <math id="S2.SS2.SSS3.p2.4.m4.4" class="ltx_Math" alttext="(\mathbf{X}^{(1)}_{i},\mathbf{X}^{(2)}_{j})" display="inline"><semantics id="S2.SS2.SSS3.p2.4.m4.4a"><mrow id="S2.SS2.SSS3.p2.4.m4.4.4.2" xref="S2.SS2.SSS3.p2.4.m4.4.4.3.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.4.m4.4.4.2.3" xref="S2.SS2.SSS3.p2.4.m4.4.4.3.cmml">(</mo><msubsup id="S2.SS2.SSS3.p2.4.m4.3.3.1.1" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.cmml"><mi id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.2.2" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.2.2.cmml">𝐗</mi><mi id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.3" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.3.cmml">i</mi><mrow id="S2.SS2.SSS3.p2.4.m4.1.1.1.3" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.4.m4.1.1.1.3.1" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.cmml">(</mo><mn id="S2.SS2.SSS3.p2.4.m4.1.1.1.1" xref="S2.SS2.SSS3.p2.4.m4.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS3.p2.4.m4.1.1.1.3.2" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.cmml">)</mo></mrow></msubsup><mo id="S2.SS2.SSS3.p2.4.m4.4.4.2.4" xref="S2.SS2.SSS3.p2.4.m4.4.4.3.cmml">,</mo><msubsup id="S2.SS2.SSS3.p2.4.m4.4.4.2.2" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.cmml"><mi id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.2.2" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.2.2.cmml">𝐗</mi><mi id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.3" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.3.cmml">j</mi><mrow id="S2.SS2.SSS3.p2.4.m4.2.2.1.3" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.4.m4.2.2.1.3.1" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.cmml">(</mo><mn id="S2.SS2.SSS3.p2.4.m4.2.2.1.1" xref="S2.SS2.SSS3.p2.4.m4.2.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.SS2.SSS3.p2.4.m4.2.2.1.3.2" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.cmml">)</mo></mrow></msubsup><mo stretchy="false" id="S2.SS2.SSS3.p2.4.m4.4.4.2.5" xref="S2.SS2.SSS3.p2.4.m4.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.4.m4.4b"><interval closure="open" id="S2.SS2.SSS3.p2.4.m4.4.4.3.cmml" xref="S2.SS2.SSS3.p2.4.m4.4.4.2"><apply id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1">subscript</csymbol><apply id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.2.cmml" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.2.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1">superscript</csymbol><ci id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.2.2.cmml" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p2.4.m4.1.1.1.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.1.1.1.1">1</cn></apply><ci id="S2.SS2.SSS3.p2.4.m4.3.3.1.1.3.cmml" xref="S2.SS2.SSS3.p2.4.m4.3.3.1.1.3">𝑖</ci></apply><apply id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.cmml" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2">subscript</csymbol><apply id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.2.cmml" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.2.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2">superscript</csymbol><ci id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.2.2.cmml" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p2.4.m4.2.2.1.1.cmml" xref="S2.SS2.SSS3.p2.4.m4.2.2.1.1">2</cn></apply><ci id="S2.SS2.SSS3.p2.4.m4.4.4.2.2.3.cmml" xref="S2.SS2.SSS3.p2.4.m4.4.4.2.2.3">𝑗</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.4.m4.4c">(\mathbf{X}^{(1)}_{i},\mathbf{X}^{(2)}_{j})</annotation></semantics></math> correspond to the same scene if <math id="S2.SS2.SSS3.p2.5.m5.1" class="ltx_Math" alttext="i=j" display="inline"><semantics id="S2.SS2.SSS3.p2.5.m5.1a"><mrow id="S2.SS2.SSS3.p2.5.m5.1.1" xref="S2.SS2.SSS3.p2.5.m5.1.1.cmml"><mi id="S2.SS2.SSS3.p2.5.m5.1.1.2" xref="S2.SS2.SSS3.p2.5.m5.1.1.2.cmml">i</mi><mo id="S2.SS2.SSS3.p2.5.m5.1.1.1" xref="S2.SS2.SSS3.p2.5.m5.1.1.1.cmml">=</mo><mi id="S2.SS2.SSS3.p2.5.m5.1.1.3" xref="S2.SS2.SSS3.p2.5.m5.1.1.3.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.5.m5.1b"><apply id="S2.SS2.SSS3.p2.5.m5.1.1.cmml" xref="S2.SS2.SSS3.p2.5.m5.1.1"><eq id="S2.SS2.SSS3.p2.5.m5.1.1.1.cmml" xref="S2.SS2.SSS3.p2.5.m5.1.1.1"></eq><ci id="S2.SS2.SSS3.p2.5.m5.1.1.2.cmml" xref="S2.SS2.SSS3.p2.5.m5.1.1.2">𝑖</ci><ci id="S2.SS2.SSS3.p2.5.m5.1.1.3.cmml" xref="S2.SS2.SSS3.p2.5.m5.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.5.m5.1c">i=j</annotation></semantics></math>, otherwise they are different. The InfoNCE loss <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> is defined as <math id="S2.SS2.SSS3.p2.6.m6.1" class="ltx_Math" alttext="\frac{1}{n}\sum_{i=1}^{n}\ell_{\text{NCE}}^{(i)}" display="inline"><semantics id="S2.SS2.SSS3.p2.6.m6.1a"><mrow id="S2.SS2.SSS3.p2.6.m6.1.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.cmml"><mfrac id="S2.SS2.SSS3.p2.6.m6.1.2.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.2.cmml"><mn id="S2.SS2.SSS3.p2.6.m6.1.2.2.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.2.2.cmml">1</mn><mi id="S2.SS2.SSS3.p2.6.m6.1.2.2.3" xref="S2.SS2.SSS3.p2.6.m6.1.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p2.6.m6.1.2.1" xref="S2.SS2.SSS3.p2.6.m6.1.2.1.cmml">​</mo><mrow id="S2.SS2.SSS3.p2.6.m6.1.2.3" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.cmml"><msubsup id="S2.SS2.SSS3.p2.6.m6.1.2.3.1" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.cmml"><mo id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.2.cmml">∑</mo><mrow id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.cmml"><mi id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.2.cmml">i</mi><mo id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.1" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.1.cmml">=</mo><mn id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.3" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.3" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.3.cmml">n</mi></msubsup><msubsup id="S2.SS2.SSS3.p2.6.m6.1.2.3.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.cmml"><mi mathvariant="normal" id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.2.cmml">ℓ</mi><mtext id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.3" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.3a.cmml">NCE</mtext><mrow id="S2.SS2.SSS3.p2.6.m6.1.1.1.3" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.6.m6.1.1.1.3.1" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.cmml">(</mo><mi id="S2.SS2.SSS3.p2.6.m6.1.1.1.1" xref="S2.SS2.SSS3.p2.6.m6.1.1.1.1.cmml">i</mi><mo stretchy="false" id="S2.SS2.SSS3.p2.6.m6.1.1.1.3.2" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.cmml">)</mo></mrow></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.6.m6.1b"><apply id="S2.SS2.SSS3.p2.6.m6.1.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2"><times id="S2.SS2.SSS3.p2.6.m6.1.2.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.1"></times><apply id="S2.SS2.SSS3.p2.6.m6.1.2.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.2"><divide id="S2.SS2.SSS3.p2.6.m6.1.2.2.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.2"></divide><cn type="integer" id="S2.SS2.SSS3.p2.6.m6.1.2.2.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.2.2">1</cn><ci id="S2.SS2.SSS3.p2.6.m6.1.2.2.3.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.2.3">𝑛</ci></apply><apply id="S2.SS2.SSS3.p2.6.m6.1.2.3.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3"><apply id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1">superscript</csymbol><apply id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1">subscript</csymbol><sum id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.2"></sum><apply id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3"><eq id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.1"></eq><ci id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.3.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS2.SSS3.p2.6.m6.1.2.3.1.3.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.1.3">𝑛</ci></apply><apply id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2">superscript</csymbol><apply id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2">subscript</csymbol><ci id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.2.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.2">ℓ</ci><ci id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.3a.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.3"><mtext mathsize="70%" id="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.3.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.2.3.2.2.3">NCE</mtext></ci></apply><ci id="S2.SS2.SSS3.p2.6.m6.1.1.1.1.cmml" xref="S2.SS2.SSS3.p2.6.m6.1.1.1.1">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.6.m6.1c">\frac{1}{n}\sum_{i=1}^{n}\ell_{\text{NCE}}^{(i)}</annotation></semantics></math>:</p>
<table id="S5.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3.m1.8" class="ltx_Math" alttext="\displaystyle\centering\ell_{\text{NCE}}^{(i)}:=-\log\frac{\text{exp}(\text{sim}(\mathbf{Z}^{(1)}_{i},\mathbf{Z}^{(2)}_{i})/\tau)}{\sum_{k=1}^{n}\text{exp}(\text{sim}(\mathbf{Z}^{(1)}_{i},\mathbf{Z}^{(2)}_{k})/\tau)},\@add@centering" display="inline"><semantics id="S2.E3.m1.8a"><mrow id="S2.E3.m1.8.8.1" xref="S2.E3.m1.8.8.1.1.cmml"><mrow id="S2.E3.m1.8.8.1.1" xref="S2.E3.m1.8.8.1.1.cmml"><msubsup id="S2.E3.m1.8.8.1.1.2" xref="S2.E3.m1.8.8.1.1.2.cmml"><mi mathvariant="normal" id="S2.E3.m1.8.8.1.1.2.2.2" xref="S2.E3.m1.8.8.1.1.2.2.2.cmml">ℓ</mi><mtext id="S2.E3.m1.8.8.1.1.2.2.3" xref="S2.E3.m1.8.8.1.1.2.2.3a.cmml">NCE</mtext><mrow id="S2.E3.m1.1.1.1.3" xref="S2.E3.m1.8.8.1.1.2.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.3.1" xref="S2.E3.m1.8.8.1.1.2.cmml">(</mo><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">i</mi><mo stretchy="false" id="S2.E3.m1.1.1.1.3.2" xref="S2.E3.m1.8.8.1.1.2.cmml">)</mo></mrow></msubsup><mo lspace="0.278em" rspace="0.278em" id="S2.E3.m1.8.8.1.1.1" xref="S2.E3.m1.8.8.1.1.1.cmml">:=</mo><mrow id="S2.E3.m1.8.8.1.1.3" xref="S2.E3.m1.8.8.1.1.3.cmml"><mo rspace="0.167em" id="S2.E3.m1.8.8.1.1.3a" xref="S2.E3.m1.8.8.1.1.3.cmml">−</mo><mrow id="S2.E3.m1.8.8.1.1.3.2" xref="S2.E3.m1.8.8.1.1.3.2.cmml"><mi id="S2.E3.m1.8.8.1.1.3.2.1" xref="S2.E3.m1.8.8.1.1.3.2.1.cmml">log</mi><mo lspace="0.167em" id="S2.E3.m1.8.8.1.1.3.2a" xref="S2.E3.m1.8.8.1.1.3.2.cmml">⁡</mo><mstyle displaystyle="true" id="S2.E3.m1.7.7" xref="S2.E3.m1.7.7.cmml"><mfrac id="S2.E3.m1.7.7a" xref="S2.E3.m1.7.7.cmml"><mrow id="S2.E3.m1.4.4.3" xref="S2.E3.m1.4.4.3.cmml"><mtext id="S2.E3.m1.4.4.3.5" xref="S2.E3.m1.4.4.3.5a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.3.4" xref="S2.E3.m1.4.4.3.4.cmml">​</mo><mrow id="S2.E3.m1.4.4.3.3.1" xref="S2.E3.m1.4.4.3.3.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.4.4.3.3.1.2" xref="S2.E3.m1.4.4.3.3.1.1.cmml">(</mo><mrow id="S2.E3.m1.4.4.3.3.1.1" xref="S2.E3.m1.4.4.3.3.1.1.cmml"><mrow id="S2.E3.m1.4.4.3.3.1.1.2" xref="S2.E3.m1.4.4.3.3.1.1.2.cmml"><mtext id="S2.E3.m1.4.4.3.3.1.1.2.4" xref="S2.E3.m1.4.4.3.3.1.1.2.4a.cmml">sim</mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.3.3.1.1.2.3" xref="S2.E3.m1.4.4.3.3.1.1.2.3.cmml">​</mo><mrow id="S2.E3.m1.4.4.3.3.1.1.2.2.2" xref="S2.E3.m1.4.4.3.3.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.E3.m1.4.4.3.3.1.1.2.2.2.3" xref="S2.E3.m1.4.4.3.3.1.1.2.2.3.cmml">(</mo><msubsup id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.2.2" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.2.2.cmml">𝐙</mi><mi id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.3.cmml">i</mi><mrow id="S2.E3.m1.2.2.1.1.1.3" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.3.1" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.cmml">(</mo><mn id="S2.E3.m1.2.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.3.2" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S2.E3.m1.4.4.3.3.1.1.2.2.2.4" xref="S2.E3.m1.4.4.3.3.1.1.2.2.3.cmml">,</mo><msubsup id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.cmml"><mi id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.2.2" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.2.2.cmml">𝐙</mi><mi id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.3" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.3.cmml">i</mi><mrow id="S2.E3.m1.3.3.2.2.1.3" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.2.2.1.3.1" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.cmml">(</mo><mn id="S2.E3.m1.3.3.2.2.1.1" xref="S2.E3.m1.3.3.2.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.E3.m1.3.3.2.2.1.3.2" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.cmml">)</mo></mrow></msubsup><mo stretchy="false" id="S2.E3.m1.4.4.3.3.1.1.2.2.2.5" xref="S2.E3.m1.4.4.3.3.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.3.3.1.1.3" xref="S2.E3.m1.4.4.3.3.1.1.3.cmml">/</mo><mi id="S2.E3.m1.4.4.3.3.1.1.4" xref="S2.E3.m1.4.4.3.3.1.1.4.cmml">τ</mi></mrow><mo stretchy="false" id="S2.E3.m1.4.4.3.3.1.3" xref="S2.E3.m1.4.4.3.3.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.E3.m1.7.7.6" xref="S2.E3.m1.7.7.6.cmml"><msubsup id="S2.E3.m1.7.7.6.4" xref="S2.E3.m1.7.7.6.4.cmml"><mo id="S2.E3.m1.7.7.6.4.2.2" xref="S2.E3.m1.7.7.6.4.2.2.cmml">∑</mo><mrow id="S2.E3.m1.7.7.6.4.2.3" xref="S2.E3.m1.7.7.6.4.2.3.cmml"><mi id="S2.E3.m1.7.7.6.4.2.3.2" xref="S2.E3.m1.7.7.6.4.2.3.2.cmml">k</mi><mo id="S2.E3.m1.7.7.6.4.2.3.1" xref="S2.E3.m1.7.7.6.4.2.3.1.cmml">=</mo><mn id="S2.E3.m1.7.7.6.4.2.3.3" xref="S2.E3.m1.7.7.6.4.2.3.3.cmml">1</mn></mrow><mi id="S2.E3.m1.7.7.6.4.3" xref="S2.E3.m1.7.7.6.4.3.cmml">n</mi></msubsup><mrow id="S2.E3.m1.7.7.6.3" xref="S2.E3.m1.7.7.6.3.cmml"><mtext id="S2.E3.m1.7.7.6.3.3" xref="S2.E3.m1.7.7.6.3.3a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.7.7.6.3.2" xref="S2.E3.m1.7.7.6.3.2.cmml">​</mo><mrow id="S2.E3.m1.7.7.6.3.1.1" xref="S2.E3.m1.7.7.6.3.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.7.7.6.3.1.1.2" xref="S2.E3.m1.7.7.6.3.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.7.7.6.3.1.1.1" xref="S2.E3.m1.7.7.6.3.1.1.1.cmml"><mrow id="S2.E3.m1.7.7.6.3.1.1.1.2" xref="S2.E3.m1.7.7.6.3.1.1.1.2.cmml"><mtext id="S2.E3.m1.7.7.6.3.1.1.1.2.4" xref="S2.E3.m1.7.7.6.3.1.1.1.2.4a.cmml">sim</mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.7.7.6.3.1.1.1.2.3" xref="S2.E3.m1.7.7.6.3.1.1.1.2.3.cmml">​</mo><mrow id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.3" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.3.cmml">(</mo><msubsup id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.2.2.cmml">𝐙</mi><mi id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.3" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.3.cmml">i</mi><mrow id="S2.E3.m1.5.5.4.1.1.3" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.5.5.4.1.1.3.1" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.cmml">(</mo><mn id="S2.E3.m1.5.5.4.1.1.1" xref="S2.E3.m1.5.5.4.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.E3.m1.5.5.4.1.1.3.2" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.4" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.3.cmml">,</mo><msubsup id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.cmml"><mi id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.2.2" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.2.2.cmml">𝐙</mi><mi id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.3" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.3.cmml">k</mi><mrow id="S2.E3.m1.6.6.5.2.1.3" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.cmml"><mo stretchy="false" id="S2.E3.m1.6.6.5.2.1.3.1" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.cmml">(</mo><mn id="S2.E3.m1.6.6.5.2.1.1" xref="S2.E3.m1.6.6.5.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.E3.m1.6.6.5.2.1.3.2" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.cmml">)</mo></mrow></msubsup><mo stretchy="false" id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.5" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.7.7.6.3.1.1.1.3" xref="S2.E3.m1.7.7.6.3.1.1.1.3.cmml">/</mo><mi id="S2.E3.m1.7.7.6.3.1.1.1.4" xref="S2.E3.m1.7.7.6.3.1.1.1.4.cmml">τ</mi></mrow><mo stretchy="false" id="S2.E3.m1.7.7.6.3.1.1.3" xref="S2.E3.m1.7.7.6.3.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow></mrow></mrow><mo id="S2.E3.m1.8.8.1.2" xref="S2.E3.m1.8.8.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.8b"><apply id="S2.E3.m1.8.8.1.1.cmml" xref="S2.E3.m1.8.8.1"><csymbol cd="latexml" id="S2.E3.m1.8.8.1.1.1.cmml" xref="S2.E3.m1.8.8.1.1.1">assign</csymbol><apply id="S2.E3.m1.8.8.1.1.2.cmml" xref="S2.E3.m1.8.8.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.8.8.1.1.2.1.cmml" xref="S2.E3.m1.8.8.1.1.2">superscript</csymbol><apply id="S2.E3.m1.8.8.1.1.2.2.cmml" xref="S2.E3.m1.8.8.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.8.8.1.1.2.2.1.cmml" xref="S2.E3.m1.8.8.1.1.2">subscript</csymbol><ci id="S2.E3.m1.8.8.1.1.2.2.2.cmml" xref="S2.E3.m1.8.8.1.1.2.2.2">ℓ</ci><ci id="S2.E3.m1.8.8.1.1.2.2.3a.cmml" xref="S2.E3.m1.8.8.1.1.2.2.3"><mtext mathsize="70%" id="S2.E3.m1.8.8.1.1.2.2.3.cmml" xref="S2.E3.m1.8.8.1.1.2.2.3">NCE</mtext></ci></apply><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">𝑖</ci></apply><apply id="S2.E3.m1.8.8.1.1.3.cmml" xref="S2.E3.m1.8.8.1.1.3"><minus id="S2.E3.m1.8.8.1.1.3.1.cmml" xref="S2.E3.m1.8.8.1.1.3"></minus><apply id="S2.E3.m1.8.8.1.1.3.2.cmml" xref="S2.E3.m1.8.8.1.1.3.2"><log id="S2.E3.m1.8.8.1.1.3.2.1.cmml" xref="S2.E3.m1.8.8.1.1.3.2.1"></log><apply id="S2.E3.m1.7.7.cmml" xref="S2.E3.m1.7.7"><divide id="S2.E3.m1.7.7.7.cmml" xref="S2.E3.m1.7.7"></divide><apply id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3"><times id="S2.E3.m1.4.4.3.4.cmml" xref="S2.E3.m1.4.4.3.4"></times><ci id="S2.E3.m1.4.4.3.5a.cmml" xref="S2.E3.m1.4.4.3.5"><mtext id="S2.E3.m1.4.4.3.5.cmml" xref="S2.E3.m1.4.4.3.5">exp</mtext></ci><apply id="S2.E3.m1.4.4.3.3.1.1.cmml" xref="S2.E3.m1.4.4.3.3.1"><divide id="S2.E3.m1.4.4.3.3.1.1.3.cmml" xref="S2.E3.m1.4.4.3.3.1.1.3"></divide><apply id="S2.E3.m1.4.4.3.3.1.1.2.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2"><times id="S2.E3.m1.4.4.3.3.1.1.2.3.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.3"></times><ci id="S2.E3.m1.4.4.3.3.1.1.2.4a.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.4"><mtext id="S2.E3.m1.4.4.3.3.1.1.2.4.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.4">sim</mtext></ci><interval closure="open" id="S2.E3.m1.4.4.3.3.1.1.2.2.3.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2"><apply id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.2.2">𝐙</ci><cn type="integer" id="S2.E3.m1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1">1</cn></apply><ci id="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.3.3.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.1.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2">subscript</csymbol><apply id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.2.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.2.1.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2">superscript</csymbol><ci id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.2.2.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.2.2">𝐙</ci><cn type="integer" id="S2.E3.m1.3.3.2.2.1.1.cmml" xref="S2.E3.m1.3.3.2.2.1.1">2</cn></apply><ci id="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.3.cmml" xref="S2.E3.m1.4.4.3.3.1.1.2.2.2.2.3">𝑖</ci></apply></interval></apply><ci id="S2.E3.m1.4.4.3.3.1.1.4.cmml" xref="S2.E3.m1.4.4.3.3.1.1.4">𝜏</ci></apply></apply><apply id="S2.E3.m1.7.7.6.cmml" xref="S2.E3.m1.7.7.6"><apply id="S2.E3.m1.7.7.6.4.cmml" xref="S2.E3.m1.7.7.6.4"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.6.4.1.cmml" xref="S2.E3.m1.7.7.6.4">superscript</csymbol><apply id="S2.E3.m1.7.7.6.4.2.cmml" xref="S2.E3.m1.7.7.6.4"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.6.4.2.1.cmml" xref="S2.E3.m1.7.7.6.4">subscript</csymbol><sum id="S2.E3.m1.7.7.6.4.2.2.cmml" xref="S2.E3.m1.7.7.6.4.2.2"></sum><apply id="S2.E3.m1.7.7.6.4.2.3.cmml" xref="S2.E3.m1.7.7.6.4.2.3"><eq id="S2.E3.m1.7.7.6.4.2.3.1.cmml" xref="S2.E3.m1.7.7.6.4.2.3.1"></eq><ci id="S2.E3.m1.7.7.6.4.2.3.2.cmml" xref="S2.E3.m1.7.7.6.4.2.3.2">𝑘</ci><cn type="integer" id="S2.E3.m1.7.7.6.4.2.3.3.cmml" xref="S2.E3.m1.7.7.6.4.2.3.3">1</cn></apply></apply><ci id="S2.E3.m1.7.7.6.4.3.cmml" xref="S2.E3.m1.7.7.6.4.3">𝑛</ci></apply><apply id="S2.E3.m1.7.7.6.3.cmml" xref="S2.E3.m1.7.7.6.3"><times id="S2.E3.m1.7.7.6.3.2.cmml" xref="S2.E3.m1.7.7.6.3.2"></times><ci id="S2.E3.m1.7.7.6.3.3a.cmml" xref="S2.E3.m1.7.7.6.3.3"><mtext id="S2.E3.m1.7.7.6.3.3.cmml" xref="S2.E3.m1.7.7.6.3.3">exp</mtext></ci><apply id="S2.E3.m1.7.7.6.3.1.1.1.cmml" xref="S2.E3.m1.7.7.6.3.1.1"><divide id="S2.E3.m1.7.7.6.3.1.1.1.3.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.3"></divide><apply id="S2.E3.m1.7.7.6.3.1.1.1.2.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2"><times id="S2.E3.m1.7.7.6.3.1.1.1.2.3.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.3"></times><ci id="S2.E3.m1.7.7.6.3.1.1.1.2.4a.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.4"><mtext id="S2.E3.m1.7.7.6.3.1.1.1.2.4.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.4">sim</mtext></ci><interval closure="open" id="S2.E3.m1.7.7.6.3.1.1.1.2.2.3.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2"><apply id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.2.2">𝐙</ci><cn type="integer" id="S2.E3.m1.5.5.4.1.1.1.cmml" xref="S2.E3.m1.5.5.4.1.1.1">1</cn></apply><ci id="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.1.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2">subscript</csymbol><apply id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.2.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.2.1.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2">superscript</csymbol><ci id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.2.2.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.2.2">𝐙</ci><cn type="integer" id="S2.E3.m1.6.6.5.2.1.1.cmml" xref="S2.E3.m1.6.6.5.2.1.1">2</cn></apply><ci id="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.3.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.2.2.2.2.3">𝑘</ci></apply></interval></apply><ci id="S2.E3.m1.7.7.6.3.1.1.1.4.cmml" xref="S2.E3.m1.7.7.6.3.1.1.1.4">𝜏</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.8c">\displaystyle\centering\ell_{\text{NCE}}^{(i)}:=-\log\frac{\text{exp}(\text{sim}(\mathbf{Z}^{(1)}_{i},\mathbf{Z}^{(2)}_{i})/\tau)}{\sum_{k=1}^{n}\text{exp}(\text{sim}(\mathbf{Z}^{(1)}_{i},\mathbf{Z}^{(2)}_{k})/\tau)},\@add@centering</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS3.p2.11" class="ltx_p">where <math id="S2.SS2.SSS3.p2.7.m1.2" class="ltx_Math" alttext="\mathbf{H}=\text{enc}_{\mathbf{h}}(T(\mathbf{X}))" display="inline"><semantics id="S2.SS2.SSS3.p2.7.m1.2a"><mrow id="S2.SS2.SSS3.p2.7.m1.2.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.cmml"><mi id="S2.SS2.SSS3.p2.7.m1.2.2.3" xref="S2.SS2.SSS3.p2.7.m1.2.2.3.cmml">𝐇</mi><mo id="S2.SS2.SSS3.p2.7.m1.2.2.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.2.cmml">=</mo><mrow id="S2.SS2.SSS3.p2.7.m1.2.2.1" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.cmml"><msub id="S2.SS2.SSS3.p2.7.m1.2.2.1.3" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3.cmml"><mtext id="S2.SS2.SSS3.p2.7.m1.2.2.1.3.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3.2a.cmml">enc</mtext><mi id="S2.SS2.SSS3.p2.7.m1.2.2.1.3.3" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3.3.cmml">𝐡</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p2.7.m1.2.2.1.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.2.cmml">​</mo><mrow id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml"><mi id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.1" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.1.cmml">​</mo><mrow id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.3.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.3.2.1" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S2.SS2.SSS3.p2.7.m1.1.1" xref="S2.SS2.SSS3.p2.7.m1.1.1.cmml">𝐗</mi><mo stretchy="false" id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.3.2.2" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.3" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.7.m1.2b"><apply id="S2.SS2.SSS3.p2.7.m1.2.2.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2"><eq id="S2.SS2.SSS3.p2.7.m1.2.2.2.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.2"></eq><ci id="S2.SS2.SSS3.p2.7.m1.2.2.3.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.3">𝐇</ci><apply id="S2.SS2.SSS3.p2.7.m1.2.2.1.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1"><times id="S2.SS2.SSS3.p2.7.m1.2.2.1.2.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.2"></times><apply id="S2.SS2.SSS3.p2.7.m1.2.2.1.3.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.7.m1.2.2.1.3.1.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3">subscript</csymbol><ci id="S2.SS2.SSS3.p2.7.m1.2.2.1.3.2a.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3.2"><mtext id="S2.SS2.SSS3.p2.7.m1.2.2.1.3.2.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3.2">enc</mtext></ci><ci id="S2.SS2.SSS3.p2.7.m1.2.2.1.3.3.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.3.3">𝐡</ci></apply><apply id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1"><times id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.1.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.1"></times><ci id="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.2.cmml" xref="S2.SS2.SSS3.p2.7.m1.2.2.1.1.1.1.2">𝑇</ci><ci id="S2.SS2.SSS3.p2.7.m1.1.1.cmml" xref="S2.SS2.SSS3.p2.7.m1.1.1">𝐗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.7.m1.2c">\mathbf{H}=\text{enc}_{\mathbf{h}}(T(\mathbf{X}))</annotation></semantics></math>, <math id="S2.SS2.SSS3.p2.8.m2.1" class="ltx_Math" alttext="\mathbf{Z}=\text{enc}_{\mathbf{z}}(\mathbf{H})" display="inline"><semantics id="S2.SS2.SSS3.p2.8.m2.1a"><mrow id="S2.SS2.SSS3.p2.8.m2.1.2" xref="S2.SS2.SSS3.p2.8.m2.1.2.cmml"><mi id="S2.SS2.SSS3.p2.8.m2.1.2.2" xref="S2.SS2.SSS3.p2.8.m2.1.2.2.cmml">𝐙</mi><mo id="S2.SS2.SSS3.p2.8.m2.1.2.1" xref="S2.SS2.SSS3.p2.8.m2.1.2.1.cmml">=</mo><mrow id="S2.SS2.SSS3.p2.8.m2.1.2.3" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.cmml"><msub id="S2.SS2.SSS3.p2.8.m2.1.2.3.2" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2.cmml"><mtext id="S2.SS2.SSS3.p2.8.m2.1.2.3.2.2" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2.2a.cmml">enc</mtext><mi id="S2.SS2.SSS3.p2.8.m2.1.2.3.2.3" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2.3.cmml">𝐳</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p2.8.m2.1.2.3.1" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.1.cmml">​</mo><mrow id="S2.SS2.SSS3.p2.8.m2.1.2.3.3.2" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.8.m2.1.2.3.3.2.1" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.cmml">(</mo><mi id="S2.SS2.SSS3.p2.8.m2.1.1" xref="S2.SS2.SSS3.p2.8.m2.1.1.cmml">𝐇</mi><mo stretchy="false" id="S2.SS2.SSS3.p2.8.m2.1.2.3.3.2.2" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.8.m2.1b"><apply id="S2.SS2.SSS3.p2.8.m2.1.2.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2"><eq id="S2.SS2.SSS3.p2.8.m2.1.2.1.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.1"></eq><ci id="S2.SS2.SSS3.p2.8.m2.1.2.2.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.2">𝐙</ci><apply id="S2.SS2.SSS3.p2.8.m2.1.2.3.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.3"><times id="S2.SS2.SSS3.p2.8.m2.1.2.3.1.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.1"></times><apply id="S2.SS2.SSS3.p2.8.m2.1.2.3.2.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p2.8.m2.1.2.3.2.1.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2">subscript</csymbol><ci id="S2.SS2.SSS3.p2.8.m2.1.2.3.2.2a.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2.2"><mtext id="S2.SS2.SSS3.p2.8.m2.1.2.3.2.2.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2.2">enc</mtext></ci><ci id="S2.SS2.SSS3.p2.8.m2.1.2.3.2.3.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.2.3.2.3">𝐳</ci></apply><ci id="S2.SS2.SSS3.p2.8.m2.1.1.cmml" xref="S2.SS2.SSS3.p2.8.m2.1.1">𝐇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.8.m2.1c">\mathbf{Z}=\text{enc}_{\mathbf{z}}(\mathbf{H})</annotation></semantics></math>, and <math id="S2.SS2.SSS3.p2.9.m3.1" class="ltx_Math" alttext="T(\cdot)" display="inline"><semantics id="S2.SS2.SSS3.p2.9.m3.1a"><mrow id="S2.SS2.SSS3.p2.9.m3.1.2" xref="S2.SS2.SSS3.p2.9.m3.1.2.cmml"><mi id="S2.SS2.SSS3.p2.9.m3.1.2.2" xref="S2.SS2.SSS3.p2.9.m3.1.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p2.9.m3.1.2.1" xref="S2.SS2.SSS3.p2.9.m3.1.2.1.cmml">​</mo><mrow id="S2.SS2.SSS3.p2.9.m3.1.2.3.2" xref="S2.SS2.SSS3.p2.9.m3.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p2.9.m3.1.2.3.2.1" xref="S2.SS2.SSS3.p2.9.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p2.9.m3.1.1" xref="S2.SS2.SSS3.p2.9.m3.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.SS2.SSS3.p2.9.m3.1.2.3.2.2" xref="S2.SS2.SSS3.p2.9.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.9.m3.1b"><apply id="S2.SS2.SSS3.p2.9.m3.1.2.cmml" xref="S2.SS2.SSS3.p2.9.m3.1.2"><times id="S2.SS2.SSS3.p2.9.m3.1.2.1.cmml" xref="S2.SS2.SSS3.p2.9.m3.1.2.1"></times><ci id="S2.SS2.SSS3.p2.9.m3.1.2.2.cmml" xref="S2.SS2.SSS3.p2.9.m3.1.2.2">𝑇</ci><ci id="S2.SS2.SSS3.p2.9.m3.1.1.cmml" xref="S2.SS2.SSS3.p2.9.m3.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.9.m3.1c">T(\cdot)</annotation></semantics></math> is some stochastic data augmentation operator (e.g. random crops, flips, colour perturbations) which operates on each example independently in the batch. This loss also contains a temperature term <math id="S2.SS2.SSS3.p2.10.m4.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S2.SS2.SSS3.p2.10.m4.1a"><mi id="S2.SS2.SSS3.p2.10.m4.1.1" xref="S2.SS2.SSS3.p2.10.m4.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.10.m4.1b"><ci id="S2.SS2.SSS3.p2.10.m4.1.1.cmml" xref="S2.SS2.SSS3.p2.10.m4.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.10.m4.1c">\tau</annotation></semantics></math>, which is a hyperparameter to optimise (in practice, we found <math id="S2.SS2.SSS3.p2.11.m5.1" class="ltx_Math" alttext="\tau=0.1" display="inline"><semantics id="S2.SS2.SSS3.p2.11.m5.1a"><mrow id="S2.SS2.SSS3.p2.11.m5.1.1" xref="S2.SS2.SSS3.p2.11.m5.1.1.cmml"><mi id="S2.SS2.SSS3.p2.11.m5.1.1.2" xref="S2.SS2.SSS3.p2.11.m5.1.1.2.cmml">τ</mi><mo id="S2.SS2.SSS3.p2.11.m5.1.1.1" xref="S2.SS2.SSS3.p2.11.m5.1.1.1.cmml">=</mo><mn id="S2.SS2.SSS3.p2.11.m5.1.1.3" xref="S2.SS2.SSS3.p2.11.m5.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p2.11.m5.1b"><apply id="S2.SS2.SSS3.p2.11.m5.1.1.cmml" xref="S2.SS2.SSS3.p2.11.m5.1.1"><eq id="S2.SS2.SSS3.p2.11.m5.1.1.1.cmml" xref="S2.SS2.SSS3.p2.11.m5.1.1.1"></eq><ci id="S2.SS2.SSS3.p2.11.m5.1.1.2.cmml" xref="S2.SS2.SSS3.p2.11.m5.1.1.2">𝜏</ci><cn type="float" id="S2.SS2.SSS3.p2.11.m5.1.1.3.cmml" xref="S2.SS2.SSS3.p2.11.m5.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p2.11.m5.1c">\tau=0.1</annotation></semantics></math> to produce the lowest softmax loss). Since a large number of negative examples is needed to learn good features, we train this encoder on an 8-GPU setup with a combined batch size of 2048.</p>
</div>
<div id="S2.SS2.SSS3.p3" class="ltx_para">
<p id="S2.SS2.SSS3.p3.7" class="ltx_p">Note that for the datasets considered in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> (for instance ImageNet and CIFAR-10), positive pairs are generally stochastic 2D data augmentations of the <em id="S2.SS2.SSS3.p3.7.1" class="ltx_emph ltx_font_italic">same</em> image, i.e. (<math id="S2.SS2.SSS3.p3.1.m1.2" class="ltx_math_unparsed" alttext="T(\mathbf{X}),T(\mathbf{X}))" display="inline"><semantics id="S2.SS2.SSS3.p3.1.m1.2a"><mrow id="S2.SS2.SSS3.p3.1.m1.2b"><mi id="S2.SS2.SSS3.p3.1.m1.2.3">T</mi><mrow id="S2.SS2.SSS3.p3.1.m1.2.4"><mo stretchy="false" id="S2.SS2.SSS3.p3.1.m1.2.4.1">(</mo><mi id="S2.SS2.SSS3.p3.1.m1.1.1">𝐗</mi><mo stretchy="false" id="S2.SS2.SSS3.p3.1.m1.2.4.2">)</mo></mrow><mo id="S2.SS2.SSS3.p3.1.m1.2.5">,</mo><mi id="S2.SS2.SSS3.p3.1.m1.2.6">T</mi><mrow id="S2.SS2.SSS3.p3.1.m1.2.7"><mo stretchy="false" id="S2.SS2.SSS3.p3.1.m1.2.7.1">(</mo><mi id="S2.SS2.SSS3.p3.1.m1.2.2">𝐗</mi><mo stretchy="false" id="S2.SS2.SSS3.p3.1.m1.2.7.2">)</mo></mrow><mo stretchy="false" id="S2.SS2.SSS3.p3.1.m1.2.8">)</mo></mrow><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p3.1.m1.2c">T(\mathbf{X}),T(\mathbf{X}))</annotation></semantics></math> comprises a positive pair and <math id="S2.SS2.SSS3.p3.2.m2.1" class="ltx_Math" alttext="T(\cdot)" display="inline"><semantics id="S2.SS2.SSS3.p3.2.m2.1a"><mrow id="S2.SS2.SSS3.p3.2.m2.1.2" xref="S2.SS2.SSS3.p3.2.m2.1.2.cmml"><mi id="S2.SS2.SSS3.p3.2.m2.1.2.2" xref="S2.SS2.SSS3.p3.2.m2.1.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p3.2.m2.1.2.1" xref="S2.SS2.SSS3.p3.2.m2.1.2.1.cmml">​</mo><mrow id="S2.SS2.SSS3.p3.2.m2.1.2.3.2" xref="S2.SS2.SSS3.p3.2.m2.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.2.m2.1.2.3.2.1" xref="S2.SS2.SSS3.p3.2.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p3.2.m2.1.1" xref="S2.SS2.SSS3.p3.2.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.SS2.SSS3.p3.2.m2.1.2.3.2.2" xref="S2.SS2.SSS3.p3.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p3.2.m2.1b"><apply id="S2.SS2.SSS3.p3.2.m2.1.2.cmml" xref="S2.SS2.SSS3.p3.2.m2.1.2"><times id="S2.SS2.SSS3.p3.2.m2.1.2.1.cmml" xref="S2.SS2.SSS3.p3.2.m2.1.2.1"></times><ci id="S2.SS2.SSS3.p3.2.m2.1.2.2.cmml" xref="S2.SS2.SSS3.p3.2.m2.1.2.2">𝑇</ci><ci id="S2.SS2.SSS3.p3.2.m2.1.1.cmml" xref="S2.SS2.SSS3.p3.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p3.2.m2.1c">T(\cdot)</annotation></semantics></math> is stochastic. In our case, since our dataset consists of scenes which in turn consist of many views, we can easily construct a positive pair by sampling two different views from the same scene. This can be thought of as a form of ‘3D’ data augmentation where instead of relatively primitive operations like crops and colour perturbations we are moving a camera around a scene and re-rendering it. We can also choose to perform both 2D and 3D data augmentation to ensure maximise diversity of positive pairs. To make things clear later, we define the positive pair <math id="S2.SS2.SSS3.p3.3.m3.4" class="ltx_Math" alttext="(T(\mathbf{X}^{(1)}),T(\mathbf{X}^{(2)}))" display="inline"><semantics id="S2.SS2.SSS3.p3.3.m3.4a"><mrow id="S2.SS2.SSS3.p3.3.m3.4.4.2" xref="S2.SS2.SSS3.p3.3.m3.4.4.3.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.4.4.2.3" xref="S2.SS2.SSS3.p3.3.m3.4.4.3.cmml">(</mo><mrow id="S2.SS2.SSS3.p3.3.m3.3.3.1.1" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.cmml"><mi id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.3" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.2" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.2.cmml">​</mo><mrow id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.2" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml">(</mo><msup id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml"><mi id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.2" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.3.m3.1.1.1.3" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.1.1.1.3.1" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml">(</mo><mn id="S2.SS2.SSS3.p3.3.m3.1.1.1.1" xref="S2.SS2.SSS3.p3.3.m3.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.1.1.1.3.2" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.3" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.SSS3.p3.3.m3.4.4.2.4" xref="S2.SS2.SSS3.p3.3.m3.4.4.3.cmml">,</mo><mrow id="S2.SS2.SSS3.p3.3.m3.4.4.2.2" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.cmml"><mi id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.3" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.2" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.2.cmml">​</mo><mrow id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.2" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml">(</mo><msup id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml"><mi id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.2" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.3.m3.2.2.1.3" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.2.2.1.3.1" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml">(</mo><mn id="S2.SS2.SSS3.p3.3.m3.2.2.1.1" xref="S2.SS2.SSS3.p3.3.m3.2.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.2.2.1.3.2" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.3" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.SS2.SSS3.p3.3.m3.4.4.2.5" xref="S2.SS2.SSS3.p3.3.m3.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p3.3.m3.4b"><interval closure="open" id="S2.SS2.SSS3.p3.3.m3.4.4.3.cmml" xref="S2.SS2.SSS3.p3.3.m3.4.4.2"><apply id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.cmml" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1"><times id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.2.cmml" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.2"></times><ci id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.3.cmml" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.3">𝑇</ci><apply id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.cmml" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1">superscript</csymbol><ci id="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS3.p3.3.m3.3.3.1.1.1.1.1.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.3.m3.1.1.1.1.cmml" xref="S2.SS2.SSS3.p3.3.m3.1.1.1.1">1</cn></apply></apply><apply id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.cmml" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2"><times id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.2.cmml" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.2"></times><ci id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.3.cmml" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.3">𝑇</ci><apply id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.cmml" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1">superscript</csymbol><ci id="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.2.cmml" xref="S2.SS2.SSS3.p3.3.m3.4.4.2.2.1.1.1.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.3.m3.2.2.1.1.cmml" xref="S2.SS2.SSS3.p3.3.m3.2.2.1.1">2</cn></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p3.3.m3.4c">(T(\mathbf{X}^{(1)}),T(\mathbf{X}^{(2)}))</annotation></semantics></math> as ‘2D only’ data augmentation if <math id="S2.SS2.SSS3.p3.4.m4.2" class="ltx_Math" alttext="\mathbf{X}^{(1)}=\mathbf{X}^{(2)}" display="inline"><semantics id="S2.SS2.SSS3.p3.4.m4.2a"><mrow id="S2.SS2.SSS3.p3.4.m4.2.3" xref="S2.SS2.SSS3.p3.4.m4.2.3.cmml"><msup id="S2.SS2.SSS3.p3.4.m4.2.3.2" xref="S2.SS2.SSS3.p3.4.m4.2.3.2.cmml"><mi id="S2.SS2.SSS3.p3.4.m4.2.3.2.2" xref="S2.SS2.SSS3.p3.4.m4.2.3.2.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.4.m4.1.1.1.3" xref="S2.SS2.SSS3.p3.4.m4.2.3.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.4.m4.1.1.1.3.1" xref="S2.SS2.SSS3.p3.4.m4.2.3.2.cmml">(</mo><mn id="S2.SS2.SSS3.p3.4.m4.1.1.1.1" xref="S2.SS2.SSS3.p3.4.m4.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.4.m4.1.1.1.3.2" xref="S2.SS2.SSS3.p3.4.m4.2.3.2.cmml">)</mo></mrow></msup><mo id="S2.SS2.SSS3.p3.4.m4.2.3.1" xref="S2.SS2.SSS3.p3.4.m4.2.3.1.cmml">=</mo><msup id="S2.SS2.SSS3.p3.4.m4.2.3.3" xref="S2.SS2.SSS3.p3.4.m4.2.3.3.cmml"><mi id="S2.SS2.SSS3.p3.4.m4.2.3.3.2" xref="S2.SS2.SSS3.p3.4.m4.2.3.3.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.4.m4.2.2.1.3" xref="S2.SS2.SSS3.p3.4.m4.2.3.3.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.4.m4.2.2.1.3.1" xref="S2.SS2.SSS3.p3.4.m4.2.3.3.cmml">(</mo><mn id="S2.SS2.SSS3.p3.4.m4.2.2.1.1" xref="S2.SS2.SSS3.p3.4.m4.2.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.4.m4.2.2.1.3.2" xref="S2.SS2.SSS3.p3.4.m4.2.3.3.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p3.4.m4.2b"><apply id="S2.SS2.SSS3.p3.4.m4.2.3.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3"><eq id="S2.SS2.SSS3.p3.4.m4.2.3.1.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3.1"></eq><apply id="S2.SS2.SSS3.p3.4.m4.2.3.2.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.4.m4.2.3.2.1.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3.2">superscript</csymbol><ci id="S2.SS2.SSS3.p3.4.m4.2.3.2.2.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.4.m4.1.1.1.1.cmml" xref="S2.SS2.SSS3.p3.4.m4.1.1.1.1">1</cn></apply><apply id="S2.SS2.SSS3.p3.4.m4.2.3.3.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.4.m4.2.3.3.1.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3.3">superscript</csymbol><ci id="S2.SS2.SSS3.p3.4.m4.2.3.3.2.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.3.3.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.4.m4.2.2.1.1.cmml" xref="S2.SS2.SSS3.p3.4.m4.2.2.1.1">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p3.4.m4.2c">\mathbf{X}^{(1)}=\mathbf{X}^{(2)}</annotation></semantics></math>. If <math id="S2.SS2.SSS3.p3.5.m5.2" class="ltx_Math" alttext="\mathbf{X}^{(1)}\neq\mathbf{X}^{(2)}" display="inline"><semantics id="S2.SS2.SSS3.p3.5.m5.2a"><mrow id="S2.SS2.SSS3.p3.5.m5.2.3" xref="S2.SS2.SSS3.p3.5.m5.2.3.cmml"><msup id="S2.SS2.SSS3.p3.5.m5.2.3.2" xref="S2.SS2.SSS3.p3.5.m5.2.3.2.cmml"><mi id="S2.SS2.SSS3.p3.5.m5.2.3.2.2" xref="S2.SS2.SSS3.p3.5.m5.2.3.2.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.5.m5.1.1.1.3" xref="S2.SS2.SSS3.p3.5.m5.2.3.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.5.m5.1.1.1.3.1" xref="S2.SS2.SSS3.p3.5.m5.2.3.2.cmml">(</mo><mn id="S2.SS2.SSS3.p3.5.m5.1.1.1.1" xref="S2.SS2.SSS3.p3.5.m5.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.5.m5.1.1.1.3.2" xref="S2.SS2.SSS3.p3.5.m5.2.3.2.cmml">)</mo></mrow></msup><mo id="S2.SS2.SSS3.p3.5.m5.2.3.1" xref="S2.SS2.SSS3.p3.5.m5.2.3.1.cmml">≠</mo><msup id="S2.SS2.SSS3.p3.5.m5.2.3.3" xref="S2.SS2.SSS3.p3.5.m5.2.3.3.cmml"><mi id="S2.SS2.SSS3.p3.5.m5.2.3.3.2" xref="S2.SS2.SSS3.p3.5.m5.2.3.3.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.5.m5.2.2.1.3" xref="S2.SS2.SSS3.p3.5.m5.2.3.3.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.5.m5.2.2.1.3.1" xref="S2.SS2.SSS3.p3.5.m5.2.3.3.cmml">(</mo><mn id="S2.SS2.SSS3.p3.5.m5.2.2.1.1" xref="S2.SS2.SSS3.p3.5.m5.2.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.5.m5.2.2.1.3.2" xref="S2.SS2.SSS3.p3.5.m5.2.3.3.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p3.5.m5.2b"><apply id="S2.SS2.SSS3.p3.5.m5.2.3.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3"><neq id="S2.SS2.SSS3.p3.5.m5.2.3.1.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3.1"></neq><apply id="S2.SS2.SSS3.p3.5.m5.2.3.2.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.5.m5.2.3.2.1.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3.2">superscript</csymbol><ci id="S2.SS2.SSS3.p3.5.m5.2.3.2.2.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.5.m5.1.1.1.1.cmml" xref="S2.SS2.SSS3.p3.5.m5.1.1.1.1">1</cn></apply><apply id="S2.SS2.SSS3.p3.5.m5.2.3.3.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.5.m5.2.3.3.1.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3.3">superscript</csymbol><ci id="S2.SS2.SSS3.p3.5.m5.2.3.3.2.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.3.3.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.5.m5.2.2.1.1.cmml" xref="S2.SS2.SSS3.p3.5.m5.2.2.1.1">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p3.5.m5.2c">\mathbf{X}^{(1)}\neq\mathbf{X}^{(2)}</annotation></semantics></math> then this is ‘2D + 3D’ data augmentation, and if <math id="S2.SS2.SSS3.p3.6.m6.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS2.SSS3.p3.6.m6.1a"><mi id="S2.SS2.SSS3.p3.6.m6.1.1" xref="S2.SS2.SSS3.p3.6.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p3.6.m6.1b"><ci id="S2.SS2.SSS3.p3.6.m6.1.1.cmml" xref="S2.SS2.SSS3.p3.6.m6.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p3.6.m6.1c">T</annotation></semantics></math> is simply the identity function then this corresponds to ‘3D only’ data augmentation, which is the pair <math id="S2.SS2.SSS3.p3.7.m7.4" class="ltx_Math" alttext="(\mathbf{X}^{(1)},\mathbf{X}^{(2)})" display="inline"><semantics id="S2.SS2.SSS3.p3.7.m7.4a"><mrow id="S2.SS2.SSS3.p3.7.m7.4.4.2" xref="S2.SS2.SSS3.p3.7.m7.4.4.3.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.7.m7.4.4.2.3" xref="S2.SS2.SSS3.p3.7.m7.4.4.3.cmml">(</mo><msup id="S2.SS2.SSS3.p3.7.m7.3.3.1.1" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1.cmml"><mi id="S2.SS2.SSS3.p3.7.m7.3.3.1.1.2" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.7.m7.1.1.1.3" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.7.m7.1.1.1.3.1" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1.cmml">(</mo><mn id="S2.SS2.SSS3.p3.7.m7.1.1.1.1" xref="S2.SS2.SSS3.p3.7.m7.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.7.m7.1.1.1.3.2" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1.cmml">)</mo></mrow></msup><mo id="S2.SS2.SSS3.p3.7.m7.4.4.2.4" xref="S2.SS2.SSS3.p3.7.m7.4.4.3.cmml">,</mo><msup id="S2.SS2.SSS3.p3.7.m7.4.4.2.2" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2.cmml"><mi id="S2.SS2.SSS3.p3.7.m7.4.4.2.2.2" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2.2.cmml">𝐗</mi><mrow id="S2.SS2.SSS3.p3.7.m7.2.2.1.3" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2.cmml"><mo stretchy="false" id="S2.SS2.SSS3.p3.7.m7.2.2.1.3.1" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2.cmml">(</mo><mn id="S2.SS2.SSS3.p3.7.m7.2.2.1.1" xref="S2.SS2.SSS3.p3.7.m7.2.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.SS2.SSS3.p3.7.m7.2.2.1.3.2" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.SS2.SSS3.p3.7.m7.4.4.2.5" xref="S2.SS2.SSS3.p3.7.m7.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS3.p3.7.m7.4b"><interval closure="open" id="S2.SS2.SSS3.p3.7.m7.4.4.3.cmml" xref="S2.SS2.SSS3.p3.7.m7.4.4.2"><apply id="S2.SS2.SSS3.p3.7.m7.3.3.1.1.cmml" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.7.m7.3.3.1.1.1.cmml" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1">superscript</csymbol><ci id="S2.SS2.SSS3.p3.7.m7.3.3.1.1.2.cmml" xref="S2.SS2.SSS3.p3.7.m7.3.3.1.1.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.7.m7.1.1.1.1.cmml" xref="S2.SS2.SSS3.p3.7.m7.1.1.1.1">1</cn></apply><apply id="S2.SS2.SSS3.p3.7.m7.4.4.2.2.cmml" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS3.p3.7.m7.4.4.2.2.1.cmml" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2">superscript</csymbol><ci id="S2.SS2.SSS3.p3.7.m7.4.4.2.2.2.cmml" xref="S2.SS2.SSS3.p3.7.m7.4.4.2.2.2">𝐗</ci><cn type="integer" id="S2.SS2.SSS3.p3.7.m7.2.2.1.1.cmml" xref="S2.SS2.SSS3.p3.7.m7.2.2.1.1">2</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS3.p3.7.m7.4c">(\mathbf{X}^{(1)},\mathbf{X}^{(2)})</annotation></semantics></math>. This is shown in Figure <a href="#S2.F7" title="Figure 7 ‣ 2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="S2.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.01639/assets/x6.png" id="S2.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="116" height="116" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.F7.sf1.3.2" class="ltx_text" style="font-size:90%;">2D data augmentation</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.01639/assets/x7.png" id="S2.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="116" height="116" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.F7.sf2.3.2" class="ltx_text" style="font-size:90%;">3D data augmentation</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.01639/assets/x8.png" id="S2.F7.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="116" height="116" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F7.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S2.F7.sf3.3.2" class="ltx_text" style="font-size:90%;">2D+3D data augmentation</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F7.14.7.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><a href="#S2.F7.sf1" title="In Figure 7 ‣ 2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">7(a)</span></a><span id="S2.F7.12.6" class="ltx_text" style="font-size:90%;">: 2D data augmentation. If the top left image of the positive pair is <math id="S2.F7.7.1.m1.1" class="ltx_Math" alttext="\mathbf{X}^{(1)}" display="inline"><semantics id="S2.F7.7.1.m1.1b"><msup id="S2.F7.7.1.m1.1.2" xref="S2.F7.7.1.m1.1.2.cmml"><mi id="S2.F7.7.1.m1.1.2.2" xref="S2.F7.7.1.m1.1.2.2.cmml">𝐗</mi><mrow id="S2.F7.7.1.m1.1.1.1.3" xref="S2.F7.7.1.m1.1.2.cmml"><mo stretchy="false" id="S2.F7.7.1.m1.1.1.1.3.1" xref="S2.F7.7.1.m1.1.2.cmml">(</mo><mn id="S2.F7.7.1.m1.1.1.1.1" xref="S2.F7.7.1.m1.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.F7.7.1.m1.1.1.1.3.2" xref="S2.F7.7.1.m1.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.F7.7.1.m1.1c"><apply id="S2.F7.7.1.m1.1.2.cmml" xref="S2.F7.7.1.m1.1.2"><csymbol cd="ambiguous" id="S2.F7.7.1.m1.1.2.1.cmml" xref="S2.F7.7.1.m1.1.2">superscript</csymbol><ci id="S2.F7.7.1.m1.1.2.2.cmml" xref="S2.F7.7.1.m1.1.2.2">𝐗</ci><cn type="integer" id="S2.F7.7.1.m1.1.1.1.1.cmml" xref="S2.F7.7.1.m1.1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F7.7.1.m1.1d">\mathbf{X}^{(1)}</annotation></semantics></math>, then a positive pair is defined by <math id="S2.F7.8.2.m2.4" class="ltx_Math" alttext="(T(\mathbf{X}^{(1)}),T(\mathbf{X}^{(1)}))" display="inline"><semantics id="S2.F7.8.2.m2.4b"><mrow id="S2.F7.8.2.m2.4.4.2" xref="S2.F7.8.2.m2.4.4.3.cmml"><mo stretchy="false" id="S2.F7.8.2.m2.4.4.2.3" xref="S2.F7.8.2.m2.4.4.3.cmml">(</mo><mrow id="S2.F7.8.2.m2.3.3.1.1" xref="S2.F7.8.2.m2.3.3.1.1.cmml"><mi id="S2.F7.8.2.m2.3.3.1.1.3" xref="S2.F7.8.2.m2.3.3.1.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.F7.8.2.m2.3.3.1.1.2" xref="S2.F7.8.2.m2.3.3.1.1.2.cmml">​</mo><mrow id="S2.F7.8.2.m2.3.3.1.1.1.1" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.F7.8.2.m2.3.3.1.1.1.1.2" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml">(</mo><msup id="S2.F7.8.2.m2.3.3.1.1.1.1.1" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml"><mi id="S2.F7.8.2.m2.3.3.1.1.1.1.1.2" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.2.cmml">𝐗</mi><mrow id="S2.F7.8.2.m2.1.1.1.3" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.F7.8.2.m2.1.1.1.3.1" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml">(</mo><mn id="S2.F7.8.2.m2.1.1.1.1" xref="S2.F7.8.2.m2.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.F7.8.2.m2.1.1.1.3.2" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.F7.8.2.m2.3.3.1.1.1.1.3" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.F7.8.2.m2.4.4.2.4" xref="S2.F7.8.2.m2.4.4.3.cmml">,</mo><mrow id="S2.F7.8.2.m2.4.4.2.2" xref="S2.F7.8.2.m2.4.4.2.2.cmml"><mi id="S2.F7.8.2.m2.4.4.2.2.3" xref="S2.F7.8.2.m2.4.4.2.2.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.F7.8.2.m2.4.4.2.2.2" xref="S2.F7.8.2.m2.4.4.2.2.2.cmml">​</mo><mrow id="S2.F7.8.2.m2.4.4.2.2.1.1" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.F7.8.2.m2.4.4.2.2.1.1.2" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml">(</mo><msup id="S2.F7.8.2.m2.4.4.2.2.1.1.1" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml"><mi id="S2.F7.8.2.m2.4.4.2.2.1.1.1.2" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.2.cmml">𝐗</mi><mrow id="S2.F7.8.2.m2.2.2.1.3" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.F7.8.2.m2.2.2.1.3.1" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml">(</mo><mn id="S2.F7.8.2.m2.2.2.1.1" xref="S2.F7.8.2.m2.2.2.1.1.cmml">1</mn><mo stretchy="false" id="S2.F7.8.2.m2.2.2.1.3.2" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.F7.8.2.m2.4.4.2.2.1.1.3" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.F7.8.2.m2.4.4.2.5" xref="S2.F7.8.2.m2.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.F7.8.2.m2.4c"><interval closure="open" id="S2.F7.8.2.m2.4.4.3.cmml" xref="S2.F7.8.2.m2.4.4.2"><apply id="S2.F7.8.2.m2.3.3.1.1.cmml" xref="S2.F7.8.2.m2.3.3.1.1"><times id="S2.F7.8.2.m2.3.3.1.1.2.cmml" xref="S2.F7.8.2.m2.3.3.1.1.2"></times><ci id="S2.F7.8.2.m2.3.3.1.1.3.cmml" xref="S2.F7.8.2.m2.3.3.1.1.3">𝑇</ci><apply id="S2.F7.8.2.m2.3.3.1.1.1.1.1.cmml" xref="S2.F7.8.2.m2.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.F7.8.2.m2.3.3.1.1.1.1.1.1.cmml" xref="S2.F7.8.2.m2.3.3.1.1.1.1">superscript</csymbol><ci id="S2.F7.8.2.m2.3.3.1.1.1.1.1.2.cmml" xref="S2.F7.8.2.m2.3.3.1.1.1.1.1.2">𝐗</ci><cn type="integer" id="S2.F7.8.2.m2.1.1.1.1.cmml" xref="S2.F7.8.2.m2.1.1.1.1">1</cn></apply></apply><apply id="S2.F7.8.2.m2.4.4.2.2.cmml" xref="S2.F7.8.2.m2.4.4.2.2"><times id="S2.F7.8.2.m2.4.4.2.2.2.cmml" xref="S2.F7.8.2.m2.4.4.2.2.2"></times><ci id="S2.F7.8.2.m2.4.4.2.2.3.cmml" xref="S2.F7.8.2.m2.4.4.2.2.3">𝑇</ci><apply id="S2.F7.8.2.m2.4.4.2.2.1.1.1.cmml" xref="S2.F7.8.2.m2.4.4.2.2.1.1"><csymbol cd="ambiguous" id="S2.F7.8.2.m2.4.4.2.2.1.1.1.1.cmml" xref="S2.F7.8.2.m2.4.4.2.2.1.1">superscript</csymbol><ci id="S2.F7.8.2.m2.4.4.2.2.1.1.1.2.cmml" xref="S2.F7.8.2.m2.4.4.2.2.1.1.1.2">𝐗</ci><cn type="integer" id="S2.F7.8.2.m2.2.2.1.1.cmml" xref="S2.F7.8.2.m2.2.2.1.1">1</cn></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.F7.8.2.m2.4d">(T(\mathbf{X}^{(1)}),T(\mathbf{X}^{(1)}))</annotation></semantics></math>. In this illustration, <math id="S2.F7.9.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.F7.9.3.m3.1b"><mi id="S2.F7.9.3.m3.1.1" xref="S2.F7.9.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.F7.9.3.m3.1c"><ci id="S2.F7.9.3.m3.1.1.cmml" xref="S2.F7.9.3.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F7.9.3.m3.1d">T</annotation></semantics></math> is a stochastic function that produces random crops of an image with some pre-determined probability. <a href="#S2.F7.sf2" title="In Figure 7 ‣ 2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(b)</span></a>: 3D data augmentation. We leverage the fact that we have multiple views per scene which can be used to comprise a positive pair, and this can be denoted as simply <math id="S2.F7.10.4.m4.4" class="ltx_Math" alttext="(\mathbf{X}^{(1)},\mathbf{X}^{(2)})" display="inline"><semantics id="S2.F7.10.4.m4.4b"><mrow id="S2.F7.10.4.m4.4.4.2" xref="S2.F7.10.4.m4.4.4.3.cmml"><mo stretchy="false" id="S2.F7.10.4.m4.4.4.2.3" xref="S2.F7.10.4.m4.4.4.3.cmml">(</mo><msup id="S2.F7.10.4.m4.3.3.1.1" xref="S2.F7.10.4.m4.3.3.1.1.cmml"><mi id="S2.F7.10.4.m4.3.3.1.1.2" xref="S2.F7.10.4.m4.3.3.1.1.2.cmml">𝐗</mi><mrow id="S2.F7.10.4.m4.1.1.1.3" xref="S2.F7.10.4.m4.3.3.1.1.cmml"><mo stretchy="false" id="S2.F7.10.4.m4.1.1.1.3.1" xref="S2.F7.10.4.m4.3.3.1.1.cmml">(</mo><mn id="S2.F7.10.4.m4.1.1.1.1" xref="S2.F7.10.4.m4.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.F7.10.4.m4.1.1.1.3.2" xref="S2.F7.10.4.m4.3.3.1.1.cmml">)</mo></mrow></msup><mo id="S2.F7.10.4.m4.4.4.2.4" xref="S2.F7.10.4.m4.4.4.3.cmml">,</mo><msup id="S2.F7.10.4.m4.4.4.2.2" xref="S2.F7.10.4.m4.4.4.2.2.cmml"><mi id="S2.F7.10.4.m4.4.4.2.2.2" xref="S2.F7.10.4.m4.4.4.2.2.2.cmml">𝐗</mi><mrow id="S2.F7.10.4.m4.2.2.1.3" xref="S2.F7.10.4.m4.4.4.2.2.cmml"><mo stretchy="false" id="S2.F7.10.4.m4.2.2.1.3.1" xref="S2.F7.10.4.m4.4.4.2.2.cmml">(</mo><mn id="S2.F7.10.4.m4.2.2.1.1" xref="S2.F7.10.4.m4.2.2.1.1.cmml">2</mn><mo stretchy="false" id="S2.F7.10.4.m4.2.2.1.3.2" xref="S2.F7.10.4.m4.4.4.2.2.cmml">)</mo></mrow></msup><mo stretchy="false" id="S2.F7.10.4.m4.4.4.2.5" xref="S2.F7.10.4.m4.4.4.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.F7.10.4.m4.4c"><interval closure="open" id="S2.F7.10.4.m4.4.4.3.cmml" xref="S2.F7.10.4.m4.4.4.2"><apply id="S2.F7.10.4.m4.3.3.1.1.cmml" xref="S2.F7.10.4.m4.3.3.1.1"><csymbol cd="ambiguous" id="S2.F7.10.4.m4.3.3.1.1.1.cmml" xref="S2.F7.10.4.m4.3.3.1.1">superscript</csymbol><ci id="S2.F7.10.4.m4.3.3.1.1.2.cmml" xref="S2.F7.10.4.m4.3.3.1.1.2">𝐗</ci><cn type="integer" id="S2.F7.10.4.m4.1.1.1.1.cmml" xref="S2.F7.10.4.m4.1.1.1.1">1</cn></apply><apply id="S2.F7.10.4.m4.4.4.2.2.cmml" xref="S2.F7.10.4.m4.4.4.2.2"><csymbol cd="ambiguous" id="S2.F7.10.4.m4.4.4.2.2.1.cmml" xref="S2.F7.10.4.m4.4.4.2.2">superscript</csymbol><ci id="S2.F7.10.4.m4.4.4.2.2.2.cmml" xref="S2.F7.10.4.m4.4.4.2.2.2">𝐗</ci><cn type="integer" id="S2.F7.10.4.m4.2.2.1.1.cmml" xref="S2.F7.10.4.m4.2.2.1.1">2</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.F7.10.4.m4.4d">(\mathbf{X}^{(1)},\mathbf{X}^{(2)})</annotation></semantics></math>, where <math id="S2.F7.11.5.m5.1" class="ltx_Math" alttext="\textbf{X}^{(2)}" display="inline"><semantics id="S2.F7.11.5.m5.1b"><msup id="S2.F7.11.5.m5.1.2" xref="S2.F7.11.5.m5.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S2.F7.11.5.m5.1.2.2" xref="S2.F7.11.5.m5.1.2.2a.cmml">X</mtext><mrow id="S2.F7.11.5.m5.1.1.1.3" xref="S2.F7.11.5.m5.1.2.cmml"><mo stretchy="false" id="S2.F7.11.5.m5.1.1.1.3.1" xref="S2.F7.11.5.m5.1.2.cmml">(</mo><mn id="S2.F7.11.5.m5.1.1.1.1" xref="S2.F7.11.5.m5.1.1.1.1.cmml">2</mn><mo stretchy="false" id="S2.F7.11.5.m5.1.1.1.3.2" xref="S2.F7.11.5.m5.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.F7.11.5.m5.1c"><apply id="S2.F7.11.5.m5.1.2.cmml" xref="S2.F7.11.5.m5.1.2"><csymbol cd="ambiguous" id="S2.F7.11.5.m5.1.2.1.cmml" xref="S2.F7.11.5.m5.1.2">superscript</csymbol><ci id="S2.F7.11.5.m5.1.2.2a.cmml" xref="S2.F7.11.5.m5.1.2.2"><mtext class="ltx_mathvariant_bold" id="S2.F7.11.5.m5.1.2.2.cmml" xref="S2.F7.11.5.m5.1.2.2">X</mtext></ci><cn type="integer" id="S2.F7.11.5.m5.1.1.1.1.cmml" xref="S2.F7.11.5.m5.1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F7.11.5.m5.1d">\textbf{X}^{(2)}</annotation></semantics></math> comes from the same scene as <math id="S2.F7.12.6.m6.1" class="ltx_Math" alttext="\textbf{X}^{(1)}" display="inline"><semantics id="S2.F7.12.6.m6.1b"><msup id="S2.F7.12.6.m6.1.2" xref="S2.F7.12.6.m6.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S2.F7.12.6.m6.1.2.2" xref="S2.F7.12.6.m6.1.2.2a.cmml">X</mtext><mrow id="S2.F7.12.6.m6.1.1.1.3" xref="S2.F7.12.6.m6.1.2.cmml"><mo stretchy="false" id="S2.F7.12.6.m6.1.1.1.3.1" xref="S2.F7.12.6.m6.1.2.cmml">(</mo><mn id="S2.F7.12.6.m6.1.1.1.1" xref="S2.F7.12.6.m6.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.F7.12.6.m6.1.1.1.3.2" xref="S2.F7.12.6.m6.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.F7.12.6.m6.1c"><apply id="S2.F7.12.6.m6.1.2.cmml" xref="S2.F7.12.6.m6.1.2"><csymbol cd="ambiguous" id="S2.F7.12.6.m6.1.2.1.cmml" xref="S2.F7.12.6.m6.1.2">superscript</csymbol><ci id="S2.F7.12.6.m6.1.2.2a.cmml" xref="S2.F7.12.6.m6.1.2.2"><mtext class="ltx_mathvariant_bold" id="S2.F7.12.6.m6.1.2.2.cmml" xref="S2.F7.12.6.m6.1.2.2">X</mtext></ci><cn type="integer" id="S2.F7.12.6.m6.1.1.1.1.cmml" xref="S2.F7.12.6.m6.1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F7.12.6.m6.1d">\textbf{X}^{(1)}</annotation></semantics></math>. <a href="#S2.F7.sf3" title="In Figure 7 ‣ 2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(c)</span></a>: Furthermore, both 2D and 3D data augmentation can be employed simultaneously, and this is required in order to pre-train an encoder that works well for VQA, as shown in Table <a href="#S3.T2" title="Table 2 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results and Analysis</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">The pre-trained ImageNet backbone we use is the one that is pre-packaged with the PyTorch <span id="S3.p1.2.1" class="ltx_text ltx_font_typewriter">torchvision</span> module, which is a ResNet-101 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. For the 3D contrastive encoder (Figure <a href="#S2.F6" title="Figure 6 ‣ 2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>), the backbone is simply a sequence of strided 2D Conv-BN-ReLU blocks, the result of which is subsequently reshaped into a 3D volume (a 4D tensor) and post-processed with 3D convolution blocks which output the final 3D latent volume. For the pre-training of this, the contrastive loss operates on the flat vector representation of the latent volume, which is simply computed with average pooling over the spatial axes. For the FILM pipeline, we use a sequence of ResNet blocks with ReLU nonlinearities and batch normalisation, as well as CoordConv feature maps <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Each experiment was trained for a maximum of 60 epochs with the ADAM optimiser <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, with a default learning rate of <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="3\times 10^{-4}" display="inline"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mn id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">×</mo><msup id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml"><mn id="S3.p1.1.m1.1.1.3.2" xref="S3.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S3.p1.1.m1.1.1.3.3" xref="S3.p1.1.m1.1.1.3.3.cmml"><mo id="S3.p1.1.m1.1.1.3.3a" xref="S3.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S3.p1.1.m1.1.1.3.3.2" xref="S3.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><times id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">3</cn><apply id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.3.1.cmml" xref="S3.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S3.p1.1.m1.1.1.3.2.cmml" xref="S3.p1.1.m1.1.1.3.2">10</cn><apply id="S3.p1.1.m1.1.1.3.3.cmml" xref="S3.p1.1.m1.1.1.3.3"><minus id="S3.p1.1.m1.1.1.3.3.1.cmml" xref="S3.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S3.p1.1.m1.1.1.3.3.2.cmml" xref="S3.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">3\times 10^{-4}</annotation></semantics></math> and first and second moment coefficients <math id="S3.p1.2.m2.4" class="ltx_Math" alttext="\{\beta_{1},\beta_{2}\}=\{0.9,0.999\}" display="inline"><semantics id="S3.p1.2.m2.4a"><mrow id="S3.p1.2.m2.4.4" xref="S3.p1.2.m2.4.4.cmml"><mrow id="S3.p1.2.m2.4.4.2.2" xref="S3.p1.2.m2.4.4.2.3.cmml"><mo stretchy="false" id="S3.p1.2.m2.4.4.2.2.3" xref="S3.p1.2.m2.4.4.2.3.cmml">{</mo><msub id="S3.p1.2.m2.3.3.1.1.1" xref="S3.p1.2.m2.3.3.1.1.1.cmml"><mi id="S3.p1.2.m2.3.3.1.1.1.2" xref="S3.p1.2.m2.3.3.1.1.1.2.cmml">β</mi><mn id="S3.p1.2.m2.3.3.1.1.1.3" xref="S3.p1.2.m2.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S3.p1.2.m2.4.4.2.2.4" xref="S3.p1.2.m2.4.4.2.3.cmml">,</mo><msub id="S3.p1.2.m2.4.4.2.2.2" xref="S3.p1.2.m2.4.4.2.2.2.cmml"><mi id="S3.p1.2.m2.4.4.2.2.2.2" xref="S3.p1.2.m2.4.4.2.2.2.2.cmml">β</mi><mn id="S3.p1.2.m2.4.4.2.2.2.3" xref="S3.p1.2.m2.4.4.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S3.p1.2.m2.4.4.2.2.5" xref="S3.p1.2.m2.4.4.2.3.cmml">}</mo></mrow><mo id="S3.p1.2.m2.4.4.3" xref="S3.p1.2.m2.4.4.3.cmml">=</mo><mrow id="S3.p1.2.m2.4.4.4.2" xref="S3.p1.2.m2.4.4.4.1.cmml"><mo stretchy="false" id="S3.p1.2.m2.4.4.4.2.1" xref="S3.p1.2.m2.4.4.4.1.cmml">{</mo><mn id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">0.9</mn><mo id="S3.p1.2.m2.4.4.4.2.2" xref="S3.p1.2.m2.4.4.4.1.cmml">,</mo><mn id="S3.p1.2.m2.2.2" xref="S3.p1.2.m2.2.2.cmml">0.999</mn><mo stretchy="false" id="S3.p1.2.m2.4.4.4.2.3" xref="S3.p1.2.m2.4.4.4.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.4b"><apply id="S3.p1.2.m2.4.4.cmml" xref="S3.p1.2.m2.4.4"><eq id="S3.p1.2.m2.4.4.3.cmml" xref="S3.p1.2.m2.4.4.3"></eq><set id="S3.p1.2.m2.4.4.2.3.cmml" xref="S3.p1.2.m2.4.4.2.2"><apply id="S3.p1.2.m2.3.3.1.1.1.cmml" xref="S3.p1.2.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.3.3.1.1.1.1.cmml" xref="S3.p1.2.m2.3.3.1.1.1">subscript</csymbol><ci id="S3.p1.2.m2.3.3.1.1.1.2.cmml" xref="S3.p1.2.m2.3.3.1.1.1.2">𝛽</ci><cn type="integer" id="S3.p1.2.m2.3.3.1.1.1.3.cmml" xref="S3.p1.2.m2.3.3.1.1.1.3">1</cn></apply><apply id="S3.p1.2.m2.4.4.2.2.2.cmml" xref="S3.p1.2.m2.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.p1.2.m2.4.4.2.2.2.1.cmml" xref="S3.p1.2.m2.4.4.2.2.2">subscript</csymbol><ci id="S3.p1.2.m2.4.4.2.2.2.2.cmml" xref="S3.p1.2.m2.4.4.2.2.2.2">𝛽</ci><cn type="integer" id="S3.p1.2.m2.4.4.2.2.2.3.cmml" xref="S3.p1.2.m2.4.4.2.2.2.3">2</cn></apply></set><set id="S3.p1.2.m2.4.4.4.1.cmml" xref="S3.p1.2.m2.4.4.4.2"><cn type="float" id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">0.9</cn><cn type="float" id="S3.p1.2.m2.2.2.cmml" xref="S3.p1.2.m2.2.2">0.999</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.4c">\{\beta_{1},\beta_{2}\}=\{0.9,0.999\}</annotation></semantics></math>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.3" class="ltx_p">For each experiment, we perform a sweep over many hyperparameters of the FILM architecture (detailed in Table <a href="#S5.T4" title="Table 4 ‣ 5.1 Hyperparameters ‣ 5 Supplementary material ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) to find the experiment which performs the best, according to validation set accuracy. We then select the best-performing experiment and run repeats of it with varying seeds (3-6, depending on the variance exhibited by those experiments), for a total of <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="N=6" display="inline"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">N</mi><mo id="S3.p2.1.m1.1.1.1" xref="S3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><eq id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"></eq><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">𝑁</ci><cn type="integer" id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">N=6</annotation></semantics></math> runs. The validation set accuracy reported is the mean over these <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p2.2.m2.1a"><mi id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">N</annotation></semantics></math> runs, and similarly for the test set. It is worth noting that for our postprocessor experiments (Section <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a>), some runs appeared to hit undesirable local minima, exhibiting much lower validation accuracies. We conjecture is due to a ‘domain mismatch’ between our dataset and ImageNet, and this conjecture appears to be supported by the fact that these outliers do not exist when we use our pre-trained contrastive encoder (Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a>). To deal with these outliers, we instead compute the mean/stdev over only the top three runs out of the <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="N=6" display="inline"><semantics id="S3.p2.3.m3.1a"><mrow id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml"><mi id="S3.p2.3.m3.1.1.2" xref="S3.p2.3.m3.1.1.2.cmml">N</mi><mo id="S3.p2.3.m3.1.1.1" xref="S3.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.p2.3.m3.1.1.3" xref="S3.p2.3.m3.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><apply id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1"><eq id="S3.p2.3.m3.1.1.1.cmml" xref="S3.p2.3.m3.1.1.1"></eq><ci id="S3.p2.3.m3.1.1.2.cmml" xref="S3.p2.3.m3.1.1.2">𝑁</ci><cn type="integer" id="S3.p2.3.m3.1.1.3.cmml" xref="S3.p2.3.m3.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">N=6</annotation></semantics></math> we originally trained.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.29.2.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.2.1" class="ltx_text" style="font-size:90%;">Table of results for experiments run using a pre-trained ResNet-101 encoder. The <em id="S3.T1.2.1.1" class="ltx_emph ltx_font_italic">Upper bound</em> model is a baseline model where <em id="S3.T1.2.1.2" class="ltx_emph ltx_font_italic">only</em> canonical views are given as input, and is expected to have the highest performance since it does not have to answer questions from another random viewpoint as input. For the columns shown: <span id="S3.T1.2.1.3" class="ltx_text ltx_font_bold">3D?</span> refers to whether we are using 2D latents or 3D latents (the difference between Figs <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S2.F5" title="Figure 5 ‣ 2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>); <span id="S3.T1.2.1.4" class="ltx_text ltx_font_bold">camera (embed)</span> refers to embedding the camera coordinates and concatenating it with the question embedding; <span id="S3.T1.2.1.5" class="ltx_text ltx_font_bold">camera (rotation)</span> refers to using the camera to map to a rigid transform of the volume (shown in Figure <a href="#S2.F5" title="Figure 5 ‣ 2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). The result denoted with <math id="S3.T1.2.1.m1.1" class="ltx_Math" alttext="\bm{\dagger}" display="inline"><semantics id="S3.T1.2.1.m1.1b"><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S3.T1.2.1.m1.1.1" xref="S3.T1.2.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.1.m1.1c"><ci id="S3.T1.2.1.m1.1.1.cmml" xref="S3.T1.2.1.m1.1.1">bold-†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.1.m1.1d">\bm{\dagger}</annotation></semantics></math> (in small text) indicates the same experiment but with the postprocessor frozen after random weight initialisation. See Appendix Section <a href="#S5.SS2" title="5.2 MAC baselines ‣ 5 Supplementary material ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a> for more on MAC baseline. Accuracies shown are percentages. For all <em id="S3.T1.2.1.6" class="ltx_emph ltx_font_italic">3D FILM, projection</em> results, the mean/stdev is computed over the top 3 performing models (out of 6).</span></figcaption>
<table id="S3.T1.21" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.21.20.1" class="ltx_tr">
<td id="S3.T1.21.20.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T1.21.20.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.20.1.1.1.1" class="ltx_p" style="width:113.8pt;">Method</span>
</span>
</td>
<td id="S3.T1.21.20.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:14.2pt;">
<span id="S3.T1.21.20.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.20.1.2.1.1" class="ltx_p">3D?</span>
</span>
</td>
<td id="S3.T1.21.20.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:42.7pt;">
<span id="S3.T1.21.20.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.20.1.3.1.1" class="ltx_p">camera (embed)</span>
</span>
</td>
<td id="S3.T1.21.20.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:42.7pt;">
<span id="S3.T1.21.20.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.20.1.4.1.1" class="ltx_p">camera (rotation)</span>
</span>
</td>
<td id="S3.T1.21.20.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:65.4pt;">
<span id="S3.T1.21.20.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.20.1.5.1.1" class="ltx_p">valid acc. (%)</span>
</span>
</td>
<td id="S3.T1.21.20.1.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:65.4pt;">
<span id="S3.T1.21.20.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.20.1.6.1.1" class="ltx_p">test acc. (%)</span>
</span>
</td>
</tr>
<tr id="S3.T1.4.2" class="ltx_tr">
<td id="S3.T1.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.2.3.1.1" class="ltx_p" style="width:113.8pt;">Majority class</span>
</span>
</td>
<td id="S3.T1.4.2.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S3.T1.4.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.2.4.1.1" class="ltx_p">–</span>
</span>
</td>
<td id="S3.T1.4.2.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.4.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.2.5.1.1" class="ltx_p">–</span>
</span>
</td>
<td id="S3.T1.4.2.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.4.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.2.6.1.1" class="ltx_p">–</span>
</span>
</td>
<td id="S3.T1.3.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.1.1.1.1" class="ltx_p">24.72 <math id="S3.T1.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.3.1.1.1.1.m1.1a"><mo id="S3.T1.3.1.1.1.1.m1.1.1" xref="S3.T1.3.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.3.1.1.1.1.m1.1.1.cmml" xref="S3.T1.3.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.00</span>
</span>
</td>
<td id="S3.T1.4.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.2.2.1.1" class="ltx_p">24.75 <math id="S3.T1.4.2.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.4.2.2.1.1.m1.1a"><mo id="S3.T1.4.2.2.1.1.m1.1.1" xref="S3.T1.4.2.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.2.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.4.2.2.1.1.m1.1.1.cmml" xref="S3.T1.4.2.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.2.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.00</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.3" class="ltx_tr">
<td id="S3.T1.5.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.3.2.1.1" class="ltx_p" style="width:113.8pt;">GRU-only</span>
</span>
</td>
<td id="S3.T1.5.3.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="S3.T1.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.3.3.1.1" class="ltx_p">–</span>
</span>
</td>
<td id="S3.T1.5.3.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.5.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.3.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.5.3.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.5.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.3.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.5.3.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.3.1.1.1" class="ltx_p">49.38 <math id="S3.T1.5.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.5.3.1.1.1.m1.1a"><mo id="S3.T1.5.3.1.1.1.m1.1.1" xref="S3.T1.5.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.5.3.1.1.1.m1.1.1.cmml" xref="S3.T1.5.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.3.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.40</span>
</span>
</td>
<td id="S3.T1.5.3.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.5.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.3.6.1.1" class="ltx_p">–</span>
</span>
</td>
</tr>
<tr id="S3.T1.7.5" class="ltx_tr">
<td id="S3.T1.7.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.7.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.7.5.3.1.1" class="ltx_p" style="width:113.8pt;">Upper bound (<em id="S3.T1.7.5.3.1.1.1" class="ltx_emph ltx_align_left ltx_font_italic">canon. views only</em>)</span>
</span>
</td>
<td id="S3.T1.7.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="S3.T1.7.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.7.5.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.7.5.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.7.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.7.5.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.7.5.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.7.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.7.5.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.6.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.6.4.1.1.1" class="ltx_p">94.19 <math id="S3.T1.6.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.6.4.1.1.1.m1.1a"><mo id="S3.T1.6.4.1.1.1.m1.1.1" xref="S3.T1.6.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.6.4.1.1.1.m1.1.1.cmml" xref="S3.T1.6.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.4.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.39</span>
</span>
</td>
<td id="S3.T1.7.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.7.5.2.1.1" class="ltx_p">94.24 <math id="S3.T1.7.5.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.7.5.2.1.1.m1.1a"><mo id="S3.T1.7.5.2.1.1.m1.1.1" xref="S3.T1.7.5.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.5.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.7.5.2.1.1.m1.1.1.cmml" xref="S3.T1.7.5.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.5.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.40</span>
</span>
</td>
</tr>
<tr id="S3.T1.8.6" class="ltx_tr">
<td id="S3.T1.8.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.8.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.8.6.2.1.1" class="ltx_p" style="width:113.8pt;">MAC <cite class="ltx_cite ltx_align_left ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite></span>
</span>
</td>
<td id="S3.T1.8.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S3.T1.8.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.8.6.3.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.8.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.8.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.8.6.4.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.8.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.8.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.8.6.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.8.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.8.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.8.6.1.1.1" class="ltx_p">70.96 <math id="S3.T1.8.6.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.8.6.1.1.1.m1.1a"><mo id="S3.T1.8.6.1.1.1.m1.1.1" xref="S3.T1.8.6.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.8.6.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.8.6.1.1.1.m1.1.1.cmml" xref="S3.T1.8.6.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.6.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.97</span>
</span>
</td>
<td id="S3.T1.8.6.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.8.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.8.6.6.1.1" class="ltx_p">–</span>
</span>
</td>
</tr>
<tr id="S3.T1.10.8" class="ltx_tr">
<td id="S3.T1.10.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.10.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.10.8.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.10.8.3.1.1.1" class="ltx_text">2D FILM (Sec <a href="#S2.SS1" title="2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, Fig <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>)</span></span>
</span>
</td>
<td id="S3.T1.10.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S3.T1.10.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.10.8.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.10.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.10.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.10.8.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.10.8.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.10.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.10.8.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.9.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.9.7.1.1.1" class="ltx_p">70.63 <math id="S3.T1.9.7.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.9.7.1.1.1.m1.1a"><mo id="S3.T1.9.7.1.1.1.m1.1.1" xref="S3.T1.9.7.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.9.7.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.9.7.1.1.1.m1.1.1.cmml" xref="S3.T1.9.7.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.7.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.19</span>
</span>
</td>
<td id="S3.T1.10.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.10.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.10.8.2.1.1" class="ltx_p">69.60 <math id="S3.T1.10.8.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.10.8.2.1.1.m1.1a"><mo id="S3.T1.10.8.2.1.1.m1.1.1" xref="S3.T1.10.8.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.10.8.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.10.8.2.1.1.m1.1.1.cmml" xref="S3.T1.10.8.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.8.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.09</span>
</span>
</td>
</tr>
<tr id="S3.T1.12.10" class="ltx_tr">
<td id="S3.T1.12.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.12.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.12.10.3.1.1" class="ltx_p" style="width:113.8pt;"></span>
</span>
</td>
<td id="S3.T1.12.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="S3.T1.12.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.12.10.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.12.10.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.12.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.12.10.5.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.12.10.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.12.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.12.10.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.11.9.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.11.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.11.9.1.1.1" class="ltx_p">83.95 <math id="S3.T1.11.9.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.11.9.1.1.1.m1.1a"><mo id="S3.T1.11.9.1.1.1.m1.1.1" xref="S3.T1.11.9.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.11.9.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.11.9.1.1.1.m1.1.1.cmml" xref="S3.T1.11.9.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.9.1.1.1.m1.1c">\pm</annotation></semantics></math> 1.21</span>
</span>
</td>
<td id="S3.T1.12.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.12.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.12.10.2.1.1" class="ltx_p">83.68 <math id="S3.T1.12.10.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.12.10.2.1.1.m1.1a"><mo id="S3.T1.12.10.2.1.1.m1.1.1" xref="S3.T1.12.10.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.12.10.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.12.10.2.1.1.m1.1.1.cmml" xref="S3.T1.12.10.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.10.2.1.1.m1.1c">\pm</annotation></semantics></math> 1.21</span>
</span>
</td>
</tr>
<tr id="S3.T1.13.11" class="ltx_tr">
<td id="S3.T1.13.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.13.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.13.11.2.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.13.11.2.1.1.1" class="ltx_text">
<span id="S3.T1.13.11.2.1.1.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:116.7pt;">
<span id="S3.T1.13.11.2.1.1.1.1.1" class="ltx_p">3D FILM, projection (Sec <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a>, Fig <a href="#S2.F5" title="Figure 5 ‣ 2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>)</span>
</span></span></span>
</span>
</td>
<td id="S3.T1.13.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S3.T1.13.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.13.11.3.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.13.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.13.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.13.11.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.13.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T1.13.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.13.11.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.13.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.13.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.13.11.1.1.1" class="ltx_p">68.19 <math id="S3.T1.13.11.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.13.11.1.1.1.m1.1a"><mo id="S3.T1.13.11.1.1.1.m1.1.1" xref="S3.T1.13.11.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.13.11.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.13.11.1.1.1.m1.1.1.cmml" xref="S3.T1.13.11.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.11.1.1.1.m1.1c">\pm</annotation></semantics></math> 1.87</span>
</span>
</td>
<td id="S3.T1.13.11.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:65.4pt;">
<span id="S3.T1.13.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.13.11.6.1.1" class="ltx_p">–</span>
</span>
</td>
</tr>
<tr id="S3.T1.15.13" class="ltx_tr">
<td id="S3.T1.15.13.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.15.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.15.13.3.1.1" class="ltx_p" style="width:113.8pt;"></span>
</span>
</td>
<td id="S3.T1.15.13.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="S3.T1.15.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.15.13.4.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.15.13.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.15.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.15.13.5.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.15.13.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.15.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.15.13.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.14.12.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.14.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.14.12.1.1.1" class="ltx_p">88.82 <math id="S3.T1.14.12.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.14.12.1.1.1.m1.1a"><mo id="S3.T1.14.12.1.1.1.m1.1.1" xref="S3.T1.14.12.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.14.12.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.14.12.1.1.1.m1.1.1.cmml" xref="S3.T1.14.12.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.12.1.1.1.m1.1c">\pm</annotation></semantics></math> 3.04</span>
</span>
</td>
<td id="S3.T1.15.13.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.15.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.15.13.2.1.1" class="ltx_p">86.36 <math id="S3.T1.15.13.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.15.13.2.1.1.m1.1a"><mo id="S3.T1.15.13.2.1.1.m1.1.1" xref="S3.T1.15.13.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.15.13.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.15.13.2.1.1.m1.1.1.cmml" xref="S3.T1.15.13.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.13.2.1.1.m1.1c">\pm</annotation></semantics></math> 3.46</span>
</span>
</td>
</tr>
<tr id="S3.T1.19.17" class="ltx_tr">
<td id="S3.T1.19.17.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.19.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.19.17.5.1.1" class="ltx_p" style="width:113.8pt;"></span>
</span>
</td>
<td id="S3.T1.19.17.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="S3.T1.19.17.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.19.17.6.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.19.17.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.19.17.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.19.17.7.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T1.19.17.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S3.T1.19.17.8.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.19.17.8.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.18.16.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.18.16.3.3" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.18.16.3.3.3" class="ltx_block ltx_parbox ltx_align_middle" style="width:59.8pt;">
<span id="S3.T1.16.14.1.1.1.1" class="ltx_p"><span id="S3.T1.16.14.1.1.1.1.1" class="ltx_text ltx_font_bold">92.80 <math id="S3.T1.16.14.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.16.14.1.1.1.1.1.m1.1a"><mo id="S3.T1.16.14.1.1.1.1.1.m1.1.1" xref="S3.T1.16.14.1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.16.14.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.16.14.1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.16.14.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.14.1.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.30</span></span>
<span id="S3.T1.18.16.3.3.3.3" class="ltx_p ltx_align_right"><span id="S3.T1.18.16.3.3.3.3.2" class="ltx_text" style="font-size:70%;">(<math id="S3.T1.17.15.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S3.T1.17.15.2.2.2.2.1.m1.1a"><mo id="S3.T1.17.15.2.2.2.2.1.m1.1.1" xref="S3.T1.17.15.2.2.2.2.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.17.15.2.2.2.2.1.m1.1b"><ci id="S3.T1.17.15.2.2.2.2.1.m1.1.1.cmml" xref="S3.T1.17.15.2.2.2.2.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.15.2.2.2.2.1.m1.1c">\dagger</annotation></semantics></math> 68.98 <math id="S3.T1.18.16.3.3.3.3.2.m2.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.18.16.3.3.3.3.2.m2.1a"><mo id="S3.T1.18.16.3.3.3.3.2.m2.1.1" xref="S3.T1.18.16.3.3.3.3.2.m2.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.18.16.3.3.3.3.2.m2.1b"><csymbol cd="latexml" id="S3.T1.18.16.3.3.3.3.2.m2.1.1.cmml" xref="S3.T1.18.16.3.3.3.3.2.m2.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.16.3.3.3.3.2.m2.1c">\pm</annotation></semantics></math> 1.43)</span></span>
</span>
</span>
</td>
<td id="S3.T1.19.17.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:65.4pt;">
<span id="S3.T1.19.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.19.17.4.1.1" class="ltx_p"><span id="S3.T1.19.17.4.1.1.1" class="ltx_text ltx_font_bold">90.86 <math id="S3.T1.19.17.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.19.17.4.1.1.1.m1.1a"><mo id="S3.T1.19.17.4.1.1.1.m1.1.1" xref="S3.T1.19.17.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.19.17.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.19.17.4.1.1.1.m1.1.1.cmml" xref="S3.T1.19.17.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.19.17.4.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.87</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.21.19" class="ltx_tr">
<td id="S3.T1.21.19.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S3.T1.21.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.19.3.1.1" class="ltx_p" style="width:113.8pt;"></span>
</span>
</td>
<td id="S3.T1.21.19.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:14.2pt;">
<span id="S3.T1.21.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.19.4.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.21.19.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:42.7pt;">
<span id="S3.T1.21.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.19.5.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.21.19.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:42.7pt;">
<span id="S3.T1.21.19.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.19.6.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T1.20.18.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:65.4pt;">
<span id="S3.T1.20.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.20.18.1.1.1" class="ltx_p">89.83 <math id="S3.T1.20.18.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.20.18.1.1.1.m1.1a"><mo id="S3.T1.20.18.1.1.1.m1.1.1" xref="S3.T1.20.18.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.20.18.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.20.18.1.1.1.m1.1.1.cmml" xref="S3.T1.20.18.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.20.18.1.1.1.m1.1c">\pm</annotation></semantics></math> 1.36</span>
</span>
</td>
<td id="S3.T1.21.19.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:65.4pt;">
<span id="S3.T1.21.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.21.19.2.1.1" class="ltx_p">89.68 <math id="S3.T1.21.19.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T1.21.19.2.1.1.m1.1a"><mo id="S3.T1.21.19.2.1.1.m1.1.1" xref="S3.T1.21.19.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T1.21.19.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T1.21.19.2.1.1.m1.1.1.cmml" xref="S3.T1.21.19.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.21.19.2.1.1.m1.1c">\pm</annotation></semantics></math> 1.34</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.32.7.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.12.6" class="ltx_text" style="font-size:90%;">Table of results for experiments run with the contrastive encoder described in Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a>. For the columns shown: <span id="S3.T2.12.6.1" class="ltx_text ltx_font_bold">Data aug</span> refers to what data augmentation scheme was used (see Figure <a href="#S2.F7" title="Figure 7 ‣ 2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>): <em id="S3.T2.12.6.2" class="ltx_emph ltx_font_italic">2D</em> = +ve pair is <math id="S3.T2.7.1.m1.2" class="ltx_Math" alttext="T(\mathbf{X}^{(1)})" display="inline"><semantics id="S3.T2.7.1.m1.2b"><mrow id="S3.T2.7.1.m1.2.2" xref="S3.T2.7.1.m1.2.2.cmml"><mi id="S3.T2.7.1.m1.2.2.3" xref="S3.T2.7.1.m1.2.2.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.T2.7.1.m1.2.2.2" xref="S3.T2.7.1.m1.2.2.2.cmml">​</mo><mrow id="S3.T2.7.1.m1.2.2.1.1" xref="S3.T2.7.1.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.T2.7.1.m1.2.2.1.1.2" xref="S3.T2.7.1.m1.2.2.1.1.1.cmml">(</mo><msup id="S3.T2.7.1.m1.2.2.1.1.1" xref="S3.T2.7.1.m1.2.2.1.1.1.cmml"><mi id="S3.T2.7.1.m1.2.2.1.1.1.2" xref="S3.T2.7.1.m1.2.2.1.1.1.2.cmml">𝐗</mi><mrow id="S3.T2.7.1.m1.1.1.1.3" xref="S3.T2.7.1.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.T2.7.1.m1.1.1.1.3.1" xref="S3.T2.7.1.m1.2.2.1.1.1.cmml">(</mo><mn id="S3.T2.7.1.m1.1.1.1.1" xref="S3.T2.7.1.m1.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S3.T2.7.1.m1.1.1.1.3.2" xref="S3.T2.7.1.m1.2.2.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S3.T2.7.1.m1.2.2.1.1.3" xref="S3.T2.7.1.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.7.1.m1.2c"><apply id="S3.T2.7.1.m1.2.2.cmml" xref="S3.T2.7.1.m1.2.2"><times id="S3.T2.7.1.m1.2.2.2.cmml" xref="S3.T2.7.1.m1.2.2.2"></times><ci id="S3.T2.7.1.m1.2.2.3.cmml" xref="S3.T2.7.1.m1.2.2.3">𝑇</ci><apply id="S3.T2.7.1.m1.2.2.1.1.1.cmml" xref="S3.T2.7.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.T2.7.1.m1.2.2.1.1.1.1.cmml" xref="S3.T2.7.1.m1.2.2.1.1">superscript</csymbol><ci id="S3.T2.7.1.m1.2.2.1.1.1.2.cmml" xref="S3.T2.7.1.m1.2.2.1.1.1.2">𝐗</ci><cn type="integer" id="S3.T2.7.1.m1.1.1.1.1.cmml" xref="S3.T2.7.1.m1.1.1.1.1">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.1.m1.2d">T(\mathbf{X}^{(1)})</annotation></semantics></math> and <math id="S3.T2.8.2.m2.2" class="ltx_Math" alttext="T(\mathbf{X}^{(1)})" display="inline"><semantics id="S3.T2.8.2.m2.2b"><mrow id="S3.T2.8.2.m2.2.2" xref="S3.T2.8.2.m2.2.2.cmml"><mi id="S3.T2.8.2.m2.2.2.3" xref="S3.T2.8.2.m2.2.2.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.T2.8.2.m2.2.2.2" xref="S3.T2.8.2.m2.2.2.2.cmml">​</mo><mrow id="S3.T2.8.2.m2.2.2.1.1" xref="S3.T2.8.2.m2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.T2.8.2.m2.2.2.1.1.2" xref="S3.T2.8.2.m2.2.2.1.1.1.cmml">(</mo><msup id="S3.T2.8.2.m2.2.2.1.1.1" xref="S3.T2.8.2.m2.2.2.1.1.1.cmml"><mi id="S3.T2.8.2.m2.2.2.1.1.1.2" xref="S3.T2.8.2.m2.2.2.1.1.1.2.cmml">𝐗</mi><mrow id="S3.T2.8.2.m2.1.1.1.3" xref="S3.T2.8.2.m2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.T2.8.2.m2.1.1.1.3.1" xref="S3.T2.8.2.m2.2.2.1.1.1.cmml">(</mo><mn id="S3.T2.8.2.m2.1.1.1.1" xref="S3.T2.8.2.m2.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S3.T2.8.2.m2.1.1.1.3.2" xref="S3.T2.8.2.m2.2.2.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S3.T2.8.2.m2.2.2.1.1.3" xref="S3.T2.8.2.m2.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.8.2.m2.2c"><apply id="S3.T2.8.2.m2.2.2.cmml" xref="S3.T2.8.2.m2.2.2"><times id="S3.T2.8.2.m2.2.2.2.cmml" xref="S3.T2.8.2.m2.2.2.2"></times><ci id="S3.T2.8.2.m2.2.2.3.cmml" xref="S3.T2.8.2.m2.2.2.3">𝑇</ci><apply id="S3.T2.8.2.m2.2.2.1.1.1.cmml" xref="S3.T2.8.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.T2.8.2.m2.2.2.1.1.1.1.cmml" xref="S3.T2.8.2.m2.2.2.1.1">superscript</csymbol><ci id="S3.T2.8.2.m2.2.2.1.1.1.2.cmml" xref="S3.T2.8.2.m2.2.2.1.1.1.2">𝐗</ci><cn type="integer" id="S3.T2.8.2.m2.1.1.1.1.cmml" xref="S3.T2.8.2.m2.1.1.1.1">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.2.m2.2d">T(\mathbf{X}^{(1)})</annotation></semantics></math>, <em id="S3.T2.12.6.3" class="ltx_emph ltx_font_italic">3D</em> = +ve pair is <math id="S3.T2.9.3.m3.1" class="ltx_Math" alttext="\mathbf{X}^{(1)}" display="inline"><semantics id="S3.T2.9.3.m3.1b"><msup id="S3.T2.9.3.m3.1.2" xref="S3.T2.9.3.m3.1.2.cmml"><mi id="S3.T2.9.3.m3.1.2.2" xref="S3.T2.9.3.m3.1.2.2.cmml">𝐗</mi><mrow id="S3.T2.9.3.m3.1.1.1.3" xref="S3.T2.9.3.m3.1.2.cmml"><mo stretchy="false" id="S3.T2.9.3.m3.1.1.1.3.1" xref="S3.T2.9.3.m3.1.2.cmml">(</mo><mn id="S3.T2.9.3.m3.1.1.1.1" xref="S3.T2.9.3.m3.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S3.T2.9.3.m3.1.1.1.3.2" xref="S3.T2.9.3.m3.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T2.9.3.m3.1c"><apply id="S3.T2.9.3.m3.1.2.cmml" xref="S3.T2.9.3.m3.1.2"><csymbol cd="ambiguous" id="S3.T2.9.3.m3.1.2.1.cmml" xref="S3.T2.9.3.m3.1.2">superscript</csymbol><ci id="S3.T2.9.3.m3.1.2.2.cmml" xref="S3.T2.9.3.m3.1.2.2">𝐗</ci><cn type="integer" id="S3.T2.9.3.m3.1.1.1.1.cmml" xref="S3.T2.9.3.m3.1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.3.m3.1d">\mathbf{X}^{(1)}</annotation></semantics></math> and <math id="S3.T2.10.4.m4.1" class="ltx_Math" alttext="\mathbf{X}^{(2)}" display="inline"><semantics id="S3.T2.10.4.m4.1b"><msup id="S3.T2.10.4.m4.1.2" xref="S3.T2.10.4.m4.1.2.cmml"><mi id="S3.T2.10.4.m4.1.2.2" xref="S3.T2.10.4.m4.1.2.2.cmml">𝐗</mi><mrow id="S3.T2.10.4.m4.1.1.1.3" xref="S3.T2.10.4.m4.1.2.cmml"><mo stretchy="false" id="S3.T2.10.4.m4.1.1.1.3.1" xref="S3.T2.10.4.m4.1.2.cmml">(</mo><mn id="S3.T2.10.4.m4.1.1.1.1" xref="S3.T2.10.4.m4.1.1.1.1.cmml">2</mn><mo stretchy="false" id="S3.T2.10.4.m4.1.1.1.3.2" xref="S3.T2.10.4.m4.1.2.cmml">)</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T2.10.4.m4.1c"><apply id="S3.T2.10.4.m4.1.2.cmml" xref="S3.T2.10.4.m4.1.2"><csymbol cd="ambiguous" id="S3.T2.10.4.m4.1.2.1.cmml" xref="S3.T2.10.4.m4.1.2">superscript</csymbol><ci id="S3.T2.10.4.m4.1.2.2.cmml" xref="S3.T2.10.4.m4.1.2.2">𝐗</ci><cn type="integer" id="S3.T2.10.4.m4.1.1.1.1.cmml" xref="S3.T2.10.4.m4.1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.4.m4.1d">\mathbf{X}^{(2)}</annotation></semantics></math>, <em id="S3.T2.12.6.4" class="ltx_emph ltx_font_italic">2D+3D</em> = +ve pair is <math id="S3.T2.11.5.m5.2" class="ltx_Math" alttext="T(\mathbf{X}^{(1)})" display="inline"><semantics id="S3.T2.11.5.m5.2b"><mrow id="S3.T2.11.5.m5.2.2" xref="S3.T2.11.5.m5.2.2.cmml"><mi id="S3.T2.11.5.m5.2.2.3" xref="S3.T2.11.5.m5.2.2.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.T2.11.5.m5.2.2.2" xref="S3.T2.11.5.m5.2.2.2.cmml">​</mo><mrow id="S3.T2.11.5.m5.2.2.1.1" xref="S3.T2.11.5.m5.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.T2.11.5.m5.2.2.1.1.2" xref="S3.T2.11.5.m5.2.2.1.1.1.cmml">(</mo><msup id="S3.T2.11.5.m5.2.2.1.1.1" xref="S3.T2.11.5.m5.2.2.1.1.1.cmml"><mi id="S3.T2.11.5.m5.2.2.1.1.1.2" xref="S3.T2.11.5.m5.2.2.1.1.1.2.cmml">𝐗</mi><mrow id="S3.T2.11.5.m5.1.1.1.3" xref="S3.T2.11.5.m5.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.T2.11.5.m5.1.1.1.3.1" xref="S3.T2.11.5.m5.2.2.1.1.1.cmml">(</mo><mn id="S3.T2.11.5.m5.1.1.1.1" xref="S3.T2.11.5.m5.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S3.T2.11.5.m5.1.1.1.3.2" xref="S3.T2.11.5.m5.2.2.1.1.1.cmml">)</mo></mrow></msup><mo stretchy="false" id="S3.T2.11.5.m5.2.2.1.1.3" xref="S3.T2.11.5.m5.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.11.5.m5.2c"><apply id="S3.T2.11.5.m5.2.2.cmml" xref="S3.T2.11.5.m5.2.2"><times id="S3.T2.11.5.m5.2.2.2.cmml" xref="S3.T2.11.5.m5.2.2.2"></times><ci id="S3.T2.11.5.m5.2.2.3.cmml" xref="S3.T2.11.5.m5.2.2.3">𝑇</ci><apply id="S3.T2.11.5.m5.2.2.1.1.1.cmml" xref="S3.T2.11.5.m5.2.2.1.1"><csymbol cd="ambiguous" id="S3.T2.11.5.m5.2.2.1.1.1.1.cmml" xref="S3.T2.11.5.m5.2.2.1.1">superscript</csymbol><ci id="S3.T2.11.5.m5.2.2.1.1.1.2.cmml" xref="S3.T2.11.5.m5.2.2.1.1.1.2">𝐗</ci><cn type="integer" id="S3.T2.11.5.m5.1.1.1.1.cmml" xref="S3.T2.11.5.m5.1.1.1.1">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.5.m5.2d">T(\mathbf{X}^{(1)})</annotation></semantics></math> and <math id="S3.T2.12.6.m6.1" class="ltx_math_unparsed" alttext="T(\mathbf{X}^{(2)}" display="inline"><semantics id="S3.T2.12.6.m6.1b"><mrow id="S3.T2.12.6.m6.1c"><mi id="S3.T2.12.6.m6.1.2">T</mi><mrow id="S3.T2.12.6.m6.1.3"><mo stretchy="false" id="S3.T2.12.6.m6.1.3.1">(</mo><msup id="S3.T2.12.6.m6.1.3.2"><mi id="S3.T2.12.6.m6.1.3.2.2">𝐗</mi><mrow id="S3.T2.12.6.m6.1.1.1.3"><mo stretchy="false" id="S3.T2.12.6.m6.1.1.1.3.1">(</mo><mn id="S3.T2.12.6.m6.1.1.1.1">2</mn><mo stretchy="false" id="S3.T2.12.6.m6.1.1.1.3.2">)</mo></mrow></msup></mrow></mrow><annotation encoding="application/x-tex" id="S3.T2.12.6.m6.1d">T(\mathbf{X}^{(2)}</annotation></semantics></math>); <span id="S3.T2.12.6.5" class="ltx_text ltx_font_bold">NCE accuracy</span> is how well the contrastive encoder is able to distinguish between pairs of views that belong to the same/different scene; the remaining columns denote the FILM task, as described in Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</span></figcaption>
<table id="S3.T2.25" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.25.14.1" class="ltx_tr">
<th id="S3.T2.25.14.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" colspan="3">Contrastive pre-training stage</th>
<th id="S3.T2.25.14.1.2" class="ltx_td ltx_align_center ltx_align_middle ltx_th ltx_th_column ltx_border_tt" colspan="4">FILM stage</th>
</tr>
<tr id="S3.T2.13.1" class="ltx_tr">
<th id="S3.T2.13.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S3.T2.13.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.1.2.1.1" class="ltx_p" style="width:42.7pt;">Data aug</span>
</span>
</th>
<th id="S3.T2.13.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t" style="width:8.5pt;">
<span id="S3.T2.13.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.1.1.1.1" class="ltx_p"><math id="S3.T2.13.1.1.1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.T2.13.1.1.1.1.m1.1a"><mi id="S3.T2.13.1.1.1.1.m1.1.1" xref="S3.T2.13.1.1.1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.13.1.1.1.1.m1.1b"><ci id="S3.T2.13.1.1.1.1.m1.1.1.cmml" xref="S3.T2.13.1.1.1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.1.1.1.1.m1.1c">\tau</annotation></semantics></math></span>
</span>
</th>
<th id="S3.T2.13.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t" style="width:56.9pt;">
<span id="S3.T2.13.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.1.3.1.1" class="ltx_p">NCE accuracy (valid)</span>
</span>
</th>
<th id="S3.T2.13.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t" style="width:39.8pt;">
<span id="S3.T2.13.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.1.4.1.1" class="ltx_p">camera (embed)</span>
</span>
</th>
<th id="S3.T2.13.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t" style="width:39.8pt;">
<span id="S3.T2.13.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.1.5.1.1" class="ltx_p">camera (rotation)</span>
</span>
</th>
<th id="S3.T2.13.1.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t" style="width:62.6pt;">
<span id="S3.T2.13.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.1.6.1.1" class="ltx_p">valid acc. (%)</span>
</span>
</th>
<th id="S3.T2.13.1.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t" style="width:62.6pt;">
<span id="S3.T2.13.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.1.7.1.1" class="ltx_p">test acc. (%)</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.15.3" class="ltx_tr">
<td id="S3.T2.15.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.15.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.3.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.15.3.3.1.1.1" class="ltx_text">2D</span></span>
</span>
</td>
<td id="S3.T2.15.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:8.5pt;">
<span id="S3.T2.15.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.3.4.1.1" class="ltx_p">0.1</span>
</span>
</td>
<td id="S3.T2.15.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:56.9pt;">
<span id="S3.T2.15.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.3.5.1.1" class="ltx_p">9.13</span>
</span>
</td>
<td id="S3.T2.15.3.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:39.8pt;">
<span id="S3.T2.15.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.3.6.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T2.15.3.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:39.8pt;">
<span id="S3.T2.15.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.3.7.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T2.14.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:62.6pt;">
<span id="S3.T2.14.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.14.2.1.1.1" class="ltx_p">59.78 <math id="S3.T2.14.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.14.2.1.1.1.m1.1a"><mo id="S3.T2.14.2.1.1.1.m1.1.1" xref="S3.T2.14.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.14.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.14.2.1.1.1.m1.1.1.cmml" xref="S3.T2.14.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.2.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.23</span>
</span>
</td>
<td id="S3.T2.15.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:62.6pt;">
<span id="S3.T2.15.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.3.2.1.1" class="ltx_p">59.14 <math id="S3.T2.15.3.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.15.3.2.1.1.m1.1a"><mo id="S3.T2.15.3.2.1.1.m1.1.1" xref="S3.T2.15.3.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.15.3.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.15.3.2.1.1.m1.1.1.cmml" xref="S3.T2.15.3.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.3.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.43</span>
</span>
</td>
</tr>
<tr id="S3.T2.17.5" class="ltx_tr">
<td id="S3.T2.17.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T2.17.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.17.5.3.1.1" class="ltx_p" style="width:42.7pt;"></span>
</span>
</td>
<td id="S3.T2.17.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:8.5pt;"></td>
<td id="S3.T2.17.5.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:56.9pt;"></td>
<td id="S3.T2.17.5.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T2.17.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.17.5.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T2.17.5.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T2.17.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.17.5.7.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T2.16.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T2.16.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.16.4.1.1.1" class="ltx_p">59.29 <math id="S3.T2.16.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.16.4.1.1.1.m1.1a"><mo id="S3.T2.16.4.1.1.1.m1.1.1" xref="S3.T2.16.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.16.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.16.4.1.1.1.m1.1.1.cmml" xref="S3.T2.16.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.4.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.44</span>
</span>
</td>
<td id="S3.T2.17.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T2.17.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.17.5.2.1.1" class="ltx_p">58.57 <math id="S3.T2.17.5.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.17.5.2.1.1.m1.1a"><mo id="S3.T2.17.5.2.1.1.m1.1.1" xref="S3.T2.17.5.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.17.5.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.17.5.2.1.1.m1.1.1.cmml" xref="S3.T2.17.5.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.17.5.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.53</span>
</span>
</td>
</tr>
<tr id="S3.T2.19.7" class="ltx_tr">
<td id="S3.T2.19.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.19.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.19.7.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.19.7.3.1.1.1" class="ltx_text">3D</span></span>
</span>
</td>
<td id="S3.T2.19.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:8.5pt;">
<span id="S3.T2.19.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.19.7.4.1.1" class="ltx_p">0.1</span>
</span>
</td>
<td id="S3.T2.19.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:56.9pt;">
<span id="S3.T2.19.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.19.7.5.1.1" class="ltx_p">99.72</span>
</span>
</td>
<td id="S3.T2.19.7.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T2.19.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.19.7.6.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T2.19.7.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T2.19.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.19.7.7.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T2.18.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T2.18.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.18.6.1.1.1" class="ltx_p">57.42 <math id="S3.T2.18.6.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.18.6.1.1.1.m1.1a"><mo id="S3.T2.18.6.1.1.1.m1.1.1" xref="S3.T2.18.6.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.18.6.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.18.6.1.1.1.m1.1.1.cmml" xref="S3.T2.18.6.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.18.6.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.26</span>
</span>
</td>
<td id="S3.T2.19.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T2.19.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.19.7.2.1.1" class="ltx_p">56.74 <math id="S3.T2.19.7.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.19.7.2.1.1.m1.1a"><mo id="S3.T2.19.7.2.1.1.m1.1.1" xref="S3.T2.19.7.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.19.7.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.19.7.2.1.1.m1.1.1.cmml" xref="S3.T2.19.7.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.19.7.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.31</span>
</span>
</td>
</tr>
<tr id="S3.T2.21.9" class="ltx_tr">
<td id="S3.T2.21.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T2.21.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.21.9.3.1.1" class="ltx_p" style="width:42.7pt;"></span>
</span>
</td>
<td id="S3.T2.21.9.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:8.5pt;"></td>
<td id="S3.T2.21.9.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:56.9pt;"></td>
<td id="S3.T2.21.9.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T2.21.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.21.9.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T2.21.9.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T2.21.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.21.9.7.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T2.20.8.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T2.20.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.20.8.1.1.1" class="ltx_p">57.63 <math id="S3.T2.20.8.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.20.8.1.1.1.m1.1a"><mo id="S3.T2.20.8.1.1.1.m1.1.1" xref="S3.T2.20.8.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.20.8.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.20.8.1.1.1.m1.1.1.cmml" xref="S3.T2.20.8.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.20.8.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.21</span>
</span>
</td>
<td id="S3.T2.21.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T2.21.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.21.9.2.1.1" class="ltx_p">57.10 <math id="S3.T2.21.9.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.21.9.2.1.1.m1.1a"><mo id="S3.T2.21.9.2.1.1.m1.1.1" xref="S3.T2.21.9.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.21.9.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.21.9.2.1.1.m1.1.1.cmml" xref="S3.T2.21.9.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.21.9.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.33</span>
</span>
</td>
</tr>
<tr id="S3.T2.23.11" class="ltx_tr">
<td id="S3.T2.23.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.23.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.23.11.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.23.11.3.1.1.1" class="ltx_text">2D + 3D</span></span>
</span>
</td>
<td id="S3.T2.23.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:8.5pt;">
<span id="S3.T2.23.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.23.11.4.1.1" class="ltx_p">0.1</span>
</span>
</td>
<td id="S3.T2.23.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:56.9pt;">
<span id="S3.T2.23.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.23.11.5.1.1" class="ltx_p">98.14</span>
</span>
</td>
<td id="S3.T2.23.11.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T2.23.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.23.11.6.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T2.23.11.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T2.23.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.23.11.7.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T2.22.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T2.22.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.22.10.1.1.1" class="ltx_p">65.15 <math id="S3.T2.22.10.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.22.10.1.1.1.m1.1a"><mo id="S3.T2.22.10.1.1.1.m1.1.1" xref="S3.T2.22.10.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.22.10.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.22.10.1.1.1.m1.1.1.cmml" xref="S3.T2.22.10.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.22.10.1.1.1.m1.1c">\pm</annotation></semantics></math> 4.63</span>
</span>
</td>
<td id="S3.T2.23.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T2.23.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.23.11.2.1.1" class="ltx_p">63.70 <math id="S3.T2.23.11.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.23.11.2.1.1.m1.1a"><mo id="S3.T2.23.11.2.1.1.m1.1.1" xref="S3.T2.23.11.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.23.11.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.23.11.2.1.1.m1.1.1.cmml" xref="S3.T2.23.11.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.23.11.2.1.1.m1.1c">\pm</annotation></semantics></math> 3.74</span>
</span>
</td>
</tr>
<tr id="S3.T2.25.13" class="ltx_tr">
<td id="S3.T2.25.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S3.T2.25.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.25.13.3.1.1" class="ltx_p" style="width:42.7pt;"></span>
</span>
</td>
<td id="S3.T2.25.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:8.5pt;"></td>
<td id="S3.T2.25.13.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:56.9pt;"></td>
<td id="S3.T2.25.13.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:39.8pt;">
<span id="S3.T2.25.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.25.13.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T2.25.13.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:39.8pt;">
<span id="S3.T2.25.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.25.13.7.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T2.24.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:62.6pt;">
<span id="S3.T2.24.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.24.12.1.1.1" class="ltx_p"><span id="S3.T2.24.12.1.1.1.1" class="ltx_text ltx_font_bold">87.49 <math id="S3.T2.24.12.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.24.12.1.1.1.1.m1.1a"><mo id="S3.T2.24.12.1.1.1.1.m1.1.1" xref="S3.T2.24.12.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.24.12.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.24.12.1.1.1.1.m1.1.1.cmml" xref="S3.T2.24.12.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.24.12.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.78</span></span>
</span>
</td>
<td id="S3.T2.25.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:62.6pt;">
<span id="S3.T2.25.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.25.13.2.1.1" class="ltx_p"><span id="S3.T2.25.13.2.1.1.1" class="ltx_text ltx_font_bold">86.01 <math id="S3.T2.25.13.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.25.13.2.1.1.1.m1.1a"><mo id="S3.T2.25.13.2.1.1.1.m1.1.1" xref="S3.T2.25.13.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.25.13.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.25.13.2.1.1.1.m1.1.1.cmml" xref="S3.T2.25.13.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.25.13.2.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.69</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.7" class="ltx_p">Our results for the FILM baselines (Section <a href="#S2.SS1" title="2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>) and using 2D-to-3D projections (Section <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a>) are shown in Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. What we find surprising is that the 2D baseline without camera conditioning (top-most row of <em id="S3.p3.7.1" class="ltx_emph ltx_font_italic">2D FILM</em>) is able to achieve a decent accuracy of roughly 70%. On closer inspection the misclassifications do not appear to be related to how far away the viewpoint camera is from the canonical, with misclassified points being distributed more or less evenly around the scene. Given that the question-only baseline (‘GRU-only’) is able to achieve an accuracy significantly greater than that of the majority class baseline (<math id="S3.p3.1.m1.1" class="ltx_Math" alttext="\approx 25\%" display="inline"><semantics id="S3.p3.1.m1.1a"><mrow id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mi id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml"></mi><mo id="S3.p3.1.m1.1.1.1" xref="S3.p3.1.m1.1.1.1.cmml">≈</mo><mrow id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml"><mn id="S3.p3.1.m1.1.1.3.2" xref="S3.p3.1.m1.1.1.3.2.cmml">25</mn><mo id="S3.p3.1.m1.1.1.3.1" xref="S3.p3.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><approx id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">absent</csymbol><apply id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3"><csymbol cd="latexml" id="S3.p3.1.m1.1.1.3.1.cmml" xref="S3.p3.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S3.p3.1.m1.1.1.3.2.cmml" xref="S3.p3.1.m1.1.1.3.2">25</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">\approx 25\%</annotation></semantics></math> versus <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="\approx 50\%" display="inline"><semantics id="S3.p3.2.m2.1a"><mrow id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml"><mi id="S3.p3.2.m2.1.1.2" xref="S3.p3.2.m2.1.1.2.cmml"></mi><mo id="S3.p3.2.m2.1.1.1" xref="S3.p3.2.m2.1.1.1.cmml">≈</mo><mrow id="S3.p3.2.m2.1.1.3" xref="S3.p3.2.m2.1.1.3.cmml"><mn id="S3.p3.2.m2.1.1.3.2" xref="S3.p3.2.m2.1.1.3.2.cmml">50</mn><mo id="S3.p3.2.m2.1.1.3.1" xref="S3.p3.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><apply id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1"><approx id="S3.p3.2.m2.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1"></approx><csymbol cd="latexml" id="S3.p3.2.m2.1.1.2.cmml" xref="S3.p3.2.m2.1.1.2">absent</csymbol><apply id="S3.p3.2.m2.1.1.3.cmml" xref="S3.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S3.p3.2.m2.1.1.3.1.cmml" xref="S3.p3.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S3.p3.2.m2.1.1.3.2.cmml" xref="S3.p3.2.m2.1.1.3.2">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">\approx 50\%</annotation></semantics></math>), it seems like it is likely exploiting statistical regularities between the actual question itself and the scene. If we add camera conditioning via FILM (bottom-most row of <em id="S3.p3.7.2" class="ltx_emph ltx_font_italic">2D FILM</em>) then we achieve a much greater test accuracy of <math id="S3.p3.3.m3.1" class="ltx_Math" alttext="83.68\pm 1.21" display="inline"><semantics id="S3.p3.3.m3.1a"><mrow id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml"><mn id="S3.p3.3.m3.1.1.2" xref="S3.p3.3.m3.1.1.2.cmml">83.68</mn><mo id="S3.p3.3.m3.1.1.1" xref="S3.p3.3.m3.1.1.1.cmml">±</mo><mn id="S3.p3.3.m3.1.1.3" xref="S3.p3.3.m3.1.1.3.cmml">1.21</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><apply id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1"><csymbol cd="latexml" id="S3.p3.3.m3.1.1.1.cmml" xref="S3.p3.3.m3.1.1.1">plus-or-minus</csymbol><cn type="float" id="S3.p3.3.m3.1.1.2.cmml" xref="S3.p3.3.m3.1.1.2">83.68</cn><cn type="float" id="S3.p3.3.m3.1.1.3.cmml" xref="S3.p3.3.m3.1.1.3">1.21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">83.68\pm 1.21</annotation></semantics></math>. Furthermore, as shown in the <em id="S3.p3.7.3" class="ltx_emph ltx_font_italic">3D FILM</em> part of Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our results demonstrate the efficacy of using rigid transforms with 3D volumes, achieving the highest accuracy of <math id="S3.p3.4.m4.1" class="ltx_Math" alttext="90.86\pm 0.87" display="inline"><semantics id="S3.p3.4.m4.1a"><mrow id="S3.p3.4.m4.1.1" xref="S3.p3.4.m4.1.1.cmml"><mn id="S3.p3.4.m4.1.1.2" xref="S3.p3.4.m4.1.1.2.cmml">90.86</mn><mo id="S3.p3.4.m4.1.1.1" xref="S3.p3.4.m4.1.1.1.cmml">±</mo><mn id="S3.p3.4.m4.1.1.3" xref="S3.p3.4.m4.1.1.3.cmml">0.87</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.1b"><apply id="S3.p3.4.m4.1.1.cmml" xref="S3.p3.4.m4.1.1"><csymbol cd="latexml" id="S3.p3.4.m4.1.1.1.cmml" xref="S3.p3.4.m4.1.1.1">plus-or-minus</csymbol><cn type="float" id="S3.p3.4.m4.1.1.2.cmml" xref="S3.p3.4.m4.1.1.2">90.86</cn><cn type="float" id="S3.p3.4.m4.1.1.3.cmml" xref="S3.p3.4.m4.1.1.3">0.87</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m4.1c">90.86\pm 0.87</annotation></semantics></math> on the test set (highlighted in bold). If we take the same experiment and freeze the postprocessor (denoted by the small <math id="S3.p3.5.m5.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S3.p3.5.m5.1a"><mo id="S3.p3.5.m5.1.1" xref="S3.p3.5.m5.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.1b"><ci id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.5.m5.1c">\dagger</annotation></semantics></math> symbol), then we achieve a much lower accuracy of 69 %. This is to be expected, considering that any camera information that is forward-propagated will contribute gradients back to the postprocessing parameters in the backward propagation, effectively giving the postprocessor supervision in the form of camera extrinsics. Finally, the last row of the <em id="S3.p3.7.4" class="ltx_emph ltx_font_italic">3D FILM</em> shows that if one uses the camera for both rigid transforms <em id="S3.p3.7.5" class="ltx_emph ltx_font_italic">and</em> embedding, the mean test accuracy is roughly the same as the rigid-transform-only variant (90.86 <math id="S3.p3.6.m6.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.p3.6.m6.1a"><mo id="S3.p3.6.m6.1.1" xref="S3.p3.6.m6.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.p3.6.m6.1b"><csymbol cd="latexml" id="S3.p3.6.m6.1.1.cmml" xref="S3.p3.6.m6.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.6.m6.1c">\pm</annotation></semantics></math> 0.87 vs 89.68 <math id="S3.p3.7.m7.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.p3.7.m7.1a"><mo id="S3.p3.7.m7.1.1" xref="S3.p3.7.m7.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.p3.7.m7.1b"><csymbol cd="latexml" id="S3.p3.7.m7.1.1.cmml" xref="S3.p3.7.m7.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.7.m7.1c">\pm</annotation></semantics></math> 1.34). This appears to suggest that simply performing rigid rotations of the volume is sufficient by itself for good performance.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.13.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S3.T3.14.2" class="ltx_text" style="font-size:90%;">Select experiments from Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> but trained on CLEVR-MRT-v2 (Figure <a href="#S3.F8" title="Figure 8 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>) where small objects exist and camera elevation is allowed to vary. For all experiments shown in this table, the mean/stdev is computed over the top three runs (out of six in total).</span></figcaption>
<table id="S3.T3.11" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T3.11.12.1" class="ltx_tr">
<td id="S3.T3.11.12.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T3.11.12.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.12.1.1.1.1" class="ltx_p" style="width:122.3pt;">Method</span>
</span>
</td>
<td id="S3.T3.11.12.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:14.2pt;">
<span id="S3.T3.11.12.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.12.1.2.1.1" class="ltx_p">3D?</span>
</span>
</td>
<td id="S3.T3.11.12.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:39.8pt;">
<span id="S3.T3.11.12.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.12.1.3.1.1" class="ltx_p">camera (embed)</span>
</span>
</td>
<td id="S3.T3.11.12.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:39.8pt;">
<span id="S3.T3.11.12.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.12.1.4.1.1" class="ltx_p">camera (rotation)</span>
</span>
</td>
<td id="S3.T3.11.12.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:62.6pt;">
<span id="S3.T3.11.12.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.12.1.5.1.1" class="ltx_p">valid acc. (%)</span>
</span>
</td>
<td id="S3.T3.11.12.1.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:62.6pt;">
<span id="S3.T3.11.12.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.12.1.6.1.1" class="ltx_p">test acc. (%)</span>
</span>
</td>
</tr>
<tr id="S3.T3.2.2" class="ltx_tr">
<td id="S3.T3.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T3.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.2.2.3.1.1" class="ltx_p" style="width:122.3pt;">Upper bound (<em id="S3.T3.2.2.3.1.1.1" class="ltx_emph ltx_align_left ltx_font_italic">canon. views only</em>)</span>
</span>
</td>
<td id="S3.T3.2.2.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S3.T3.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.2.2.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.2.2.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T3.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.2.2.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.2.2.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T3.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.2.2.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.1.1" class="ltx_p">90.00 <math id="S3.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.1.1.1.1.1.m1.1a"><mo id="S3.T3.1.1.1.1.1.m1.1.1" xref="S3.T3.1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.1.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.23</span>
</span>
</td>
<td id="S3.T3.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T3.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.2.2.2.1.1" class="ltx_p">89.37 <math id="S3.T3.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.2.2.2.1.1.m1.1a"><mo id="S3.T3.2.2.2.1.1.m1.1.1" xref="S3.T3.2.2.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.2.2.2.1.1.m1.1.1.cmml" xref="S3.T3.2.2.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.1.1.m1.1c">\pm</annotation></semantics></math> 0.19</span>
</span>
</td>
</tr>
<tr id="S3.T3.3.3" class="ltx_tr">
<td id="S3.T3.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.2.1.1" class="ltx_p" style="width:122.3pt;"><span id="S3.T3.3.3.2.1.1.1" class="ltx_text">2D FILM (Sec <a href="#S2.SS1" title="2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, Fig <a href="#S2.F3" title="Figure 3 ‣ 2.1 FILM baselines ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>)</span></span>
</span>
</td>
<td id="S3.T3.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S3.T3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.3.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.3.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T3.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.3.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T3.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.3.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.1.1.1" class="ltx_p">67.26 <math id="S3.T3.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.3.3.1.1.1.m1.1a"><mo id="S3.T3.3.3.1.1.1.m1.1.1" xref="S3.T3.3.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.3.3.1.1.1.m1.1.1.cmml" xref="S3.T3.3.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.78</span>
</span>
</td>
<td id="S3.T3.3.3.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T3.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.6.1.1" class="ltx_p">–</span>
</span>
</td>
</tr>
<tr id="S3.T3.5.5" class="ltx_tr">
<td id="S3.T3.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T3.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.3.1.1" class="ltx_p" style="width:122.3pt;"></span>
</span>
</td>
<td id="S3.T3.5.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="S3.T3.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.4.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.5.5.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T3.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.5.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.5.5.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T3.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T3.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.4.4.1.1.1" class="ltx_p">79.69 <math id="S3.T3.4.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.4.4.1.1.1.m1.1a"><mo id="S3.T3.4.4.1.1.1.m1.1.1" xref="S3.T3.4.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.4.4.1.1.1.m1.1.1.cmml" xref="S3.T3.4.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.1.1.1.m1.1c">\pm</annotation></semantics></math> 2.05</span>
</span>
</td>
<td id="S3.T3.5.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T3.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.2.1.1" class="ltx_p">79.14 <math id="S3.T3.5.5.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.5.5.2.1.1.m1.1a"><mo id="S3.T3.5.5.2.1.1.m1.1.1" xref="S3.T3.5.5.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.5.5.2.1.1.m1.1.1.cmml" xref="S3.T3.5.5.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.2.1.1.m1.1c">\pm</annotation></semantics></math> 2.35</span>
</span>
</td>
</tr>
<tr id="S3.T3.7.7" class="ltx_tr">
<td id="S3.T3.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T3.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.3.1.1" class="ltx_p" style="width:122.3pt;"><span id="S3.T3.7.7.3.1.1.1" class="ltx_text">
<span id="S3.T3.7.7.3.1.1.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:116.7pt;">
<span id="S3.T3.7.7.3.1.1.1.1.1" class="ltx_p">3D FILM, projection (Sec <a href="#S2.SS2.SSS1" title="2.2.1 Projecting 2D Features into 3D Features ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.1</span></a>, Fig <a href="#S2.F5" title="Figure 5 ‣ 2.2.2 3D Camera Controllable FILM ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>)</span>
</span></span></span>
</span>
</td>
<td id="S3.T3.7.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="S3.T3.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.4.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.7.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T3.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.5.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.7.7.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.8pt;">
<span id="S3.T3.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.6.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T3.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.6.6.1.1.1" class="ltx_p">65.49 <math id="S3.T3.6.6.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.6.6.1.1.1.m1.1a"><mo id="S3.T3.6.6.1.1.1.m1.1.1" xref="S3.T3.6.6.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.6.6.1.1.1.m1.1.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.1.1.1.m1.1c">\pm</annotation></semantics></math> 1.46</span>
</span>
</td>
<td id="S3.T3.7.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:62.6pt;">
<span id="S3.T3.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.2.1.1" class="ltx_p">65.10 <math id="S3.T3.7.7.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.7.7.2.1.1.m1.1a"><mo id="S3.T3.7.7.2.1.1.m1.1.1" xref="S3.T3.7.7.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.7.7.2.1.1.m1.1.1.cmml" xref="S3.T3.7.7.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.2.1.1.m1.1c">\pm</annotation></semantics></math> 1.67</span>
</span>
</td>
</tr>
<tr id="S3.T3.9.9" class="ltx_tr">
<td id="S3.T3.9.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T3.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.3.1.1" class="ltx_p" style="width:122.3pt;"></span>
</span>
</td>
<td id="S3.T3.9.9.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="S3.T3.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.4.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.9.9.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T3.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.5.1.1" class="ltx_p">✗</span>
</span>
</td>
<td id="S3.T3.9.9.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.8pt;">
<span id="S3.T3.9.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.6.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T3.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.8.8.1.1.1" class="ltx_p">86.92 <math id="S3.T3.8.8.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.8.8.1.1.1.m1.1a"><mo id="S3.T3.8.8.1.1.1.m1.1.1" xref="S3.T3.8.8.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.8.8.1.1.1.m1.1.1.cmml" xref="S3.T3.8.8.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.1.1.1.m1.1c">\pm</annotation></semantics></math> 2.00</span>
</span>
</td>
<td id="S3.T3.9.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:62.6pt;">
<span id="S3.T3.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.2.1.1" class="ltx_p">86.89 <math id="S3.T3.9.9.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.9.9.2.1.1.m1.1a"><mo id="S3.T3.9.9.2.1.1.m1.1.1" xref="S3.T3.9.9.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.2.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.9.9.2.1.1.m1.1.1.cmml" xref="S3.T3.9.9.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.2.1.1.m1.1c">\pm</annotation></semantics></math> 2.04</span>
</span>
</td>
</tr>
<tr id="S3.T3.11.11" class="ltx_tr">
<td id="S3.T3.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S3.T3.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.3.1.1" class="ltx_p" style="width:122.3pt;"></span>
</span>
</td>
<td id="S3.T3.11.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:14.2pt;">
<span id="S3.T3.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.4.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.11.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:39.8pt;">
<span id="S3.T3.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.5.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.11.11.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:39.8pt;">
<span id="S3.T3.11.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.6.1.1" class="ltx_p">✓</span>
</span>
</td>
<td id="S3.T3.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:62.6pt;">
<span id="S3.T3.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.10.10.1.1.1" class="ltx_p"><span id="S3.T3.10.10.1.1.1.1" class="ltx_text ltx_font_bold">89.98 <math id="S3.T3.10.10.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.10.10.1.1.1.1.m1.1a"><mo id="S3.T3.10.10.1.1.1.1.m1.1.1" xref="S3.T3.10.10.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.10.10.1.1.1.1.m1.1.1.cmml" xref="S3.T3.10.10.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.59</span></span>
</span>
</td>
<td id="S3.T3.11.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:62.6pt;">
<span id="S3.T3.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.2.1.1" class="ltx_p"><span id="S3.T3.11.11.2.1.1.1" class="ltx_text ltx_font_bold">89.91 <math id="S3.T3.11.11.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.11.11.2.1.1.1.m1.1a"><mo id="S3.T3.11.11.2.1.1.1.m1.1.1" xref="S3.T3.11.11.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.11.11.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.11.11.2.1.1.1.m1.1.1.cmml" xref="S3.T3.11.11.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.11.2.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.73</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">In Table <a href="#S3.T2" title="Table 2 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we present 3D FILM results but using the contrastive pre-trained encoder described in Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a>. Specifically, we perform an ablation on the type of data augmentation used during the contrastive pre-training stage (described at the end of Section <a href="#S2.SS2.SSS3" title="2.2.3 Learning 3D Contrastive Encoders ‣ 2.2 Learning 3D Feature Representations from Single View Images ‣ 2 Methods ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.3</span></a>) and find that 3D data augmentation is essential for the encoder to distinguish whether a pair of views come from the same scene or not, as shown in the ‘NCE accuracy’ column (9.13% for 2D versus 99.72 % for 3D). However, both 2D and 3D data augmentation is necessary in order for the FILM task to yield the best results, as seen in the last row. This is consistent with the observation that very strong data augmentation is required to ensure that contrastive techniques do not learn trivial features that perform poorly on downstream tasks. Similar to Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, utilising the viewpoint camera for rigid transforms produces the best results, with 86.01 <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.p4.1.m1.1a"><mo id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><csymbol cd="latexml" id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">\pm</annotation></semantics></math> 0.69 % test accuracy. While the best result of Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> is slightly higher, we re-iterate that some of those runs hit undesirable local minima, which we did not experience with this contrastive formulation. Furthermore, as noted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, contrastive encoders have to be significantly overparameterised compared to their supervised counterparts in order to achieve roughly the same classification error, so further architecture tuning may be required.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.2" class="ltx_p">Our results show that our best performing formulation (either 2D-to-3D or contrastive) performs on average only 8% less than the canonical baseline’s 94%, which can be seen as a rough upper bound on generalisation performance. While we obtained promising results, it may not leave a lot of room to improve on top of our methods, and we identified some ways in which the dataset could be made more difficult. One of them is removing the viewpoint camera coordinates and instead placing a sprite in the scene showing where the canonical camera is. This means that the model has an additional inference task it has to perform, which is inferring the 3D position of the canonical viewpoint from a 2D marker. Another idea is to allow some variation in the elevation of the viewpoint camera. While this can accentuate the effects of occlusion (if the camera is allowed to go lower than its default elevation), it also provides for a more grounded dataset since occlusions are commonplace in real-world datasets. We examine the latter here, generating a version of CLEVR-MRT where the camera elevation is allowed to vary, and with both small and large objects present in the scene (small objects were not present in the original CLEVR-MRT dataset). The default elevation in the original dataset was <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="30^{\circ}" display="inline"><semantics id="S3.p5.1.m1.1a"><msup id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mn id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">30</mn><mo id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1">superscript</csymbol><cn type="integer" id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1.2">30</cn><compose id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">30^{\circ}</annotation></semantics></math>, whereas now it is randomly sampled from <math id="S3.p5.2.m2.2" class="ltx_Math" alttext="\text{Uniform}(20,30)" display="inline"><semantics id="S3.p5.2.m2.2a"><mrow id="S3.p5.2.m2.2.3" xref="S3.p5.2.m2.2.3.cmml"><mtext id="S3.p5.2.m2.2.3.2" xref="S3.p5.2.m2.2.3.2a.cmml">Uniform</mtext><mo lspace="0em" rspace="0em" id="S3.p5.2.m2.2.3.1" xref="S3.p5.2.m2.2.3.1.cmml">​</mo><mrow id="S3.p5.2.m2.2.3.3.2" xref="S3.p5.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.p5.2.m2.2.3.3.2.1" xref="S3.p5.2.m2.2.3.3.1.cmml">(</mo><mn id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">20</mn><mo id="S3.p5.2.m2.2.3.3.2.2" xref="S3.p5.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.p5.2.m2.2.2" xref="S3.p5.2.m2.2.2.cmml">30</mn><mo stretchy="false" id="S3.p5.2.m2.2.3.3.2.3" xref="S3.p5.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.2b"><apply id="S3.p5.2.m2.2.3.cmml" xref="S3.p5.2.m2.2.3"><times id="S3.p5.2.m2.2.3.1.cmml" xref="S3.p5.2.m2.2.3.1"></times><ci id="S3.p5.2.m2.2.3.2a.cmml" xref="S3.p5.2.m2.2.3.2"><mtext id="S3.p5.2.m2.2.3.2.cmml" xref="S3.p5.2.m2.2.3.2">Uniform</mtext></ci><interval closure="open" id="S3.p5.2.m2.2.3.3.1.cmml" xref="S3.p5.2.m2.2.3.3.2"><cn type="integer" id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">20</cn><cn type="integer" id="S3.p5.2.m2.2.2.cmml" xref="S3.p5.2.m2.2.2">30</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.2c">\text{Uniform}(20,30)</annotation></semantics></math>. An example scene of this new dataset, CLEVR-MRT-v2, is shown in Figure <a href="#S3.F8" title="Figure 8 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure id="S3.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/cc.jpg" id="S3.F8.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/cam13.jpg" id="S3.F8.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/cam16.jpg" id="S3.F8.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/cam2.jpg" id="S3.F8.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/cam4.jpg" id="S3.F8.g5" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene2/cc.jpg" id="S3.F8.g6" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene2/cam17.jpg" id="S3.F8.g7" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene2/cam16.jpg" id="S3.F8.g8" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene2/cam18.jpg" id="S3.F8.g9" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene2/cam19.jpg" id="S3.F8.g10" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene3/cc.jpg" id="S3.F8.g11" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene3/cam8.jpg" id="S3.F8.g12" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene3/cam11.jpg" id="S3.F8.g13" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene3/cam13.jpg" id="S3.F8.g14" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_mrt_v2/scene3/cam16.jpg" id="S3.F8.g15" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="114" height="86" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.3.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><em id="S3.F8.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CLEVR-MRT</em><span id="S3.F8.5.3" class="ltx_text" style="font-size:90%;"> v2 dataset. For each scene (corresponding to a row), the left-most image is the canonical view. The rest are randomly sampled views, of varying azimuth and elevation, the latter of which is now allowed to vary, unlike the original CLEVR-MRT dataset. Because of this, occlusions here are more prevalent compared to the original dataset shown in Figure <a href="#S1.F1.sf2" title="In Figure 1 ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>.</span></figcaption>
</figure>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">See Table <a href="#S3.T3" title="Table 3 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for these results. We also demonstrate here that 3D FILM performs the best, though compared to Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> it appears that camera conditioning via FILM is also required for a few extra percentage points (bottom-most row of <em id="S3.p6.1.1" class="ltx_emph ltx_font_italic">3D FILM</em>). Like Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, it appears that our best result is on par with the upper bound, indicating that more difficult versions of the dataset are required. As we mentioned earlier, one addition would be to allow the camera to be present in the scene as a model or a sprite, with the goal of inferring the coordinates of the camera to answer the question without the viewpoint camera being provided as it is now. This would also have the benefit of making the dataset more realistic with respect to the illustrative examples given in the introduction. We leave this to future work however.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Limitations and Future Work</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We have examined a <em id="S3.SS1.p1.1.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em>  setup where one is given an image as well as coordinates of the question viewpoint. Other tasks involving mental rotations might require the question viewpoint to be inferred by the neural network. For instance, if we wish to infer what another agent sees, we might wish to infer the position and orientation of their face or camera. One might reformulate our setup to include some sort of marker or object representing the desired camera position and orientation, and task the model with inferring that position and orientation. In Figure <a href="#S3.F9.sf1" title="In Figure 9 ‣ 3.1 Limitations and Future Work ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(a)</span></a> we visualize this scenario where the desired camera position and viewpoint is illustrated in the scene as a purple cone. In this scenario instead of the VQA pipeline being given camera coordinates, they must inferrred from the appearance of the code, in addition to performing the mental rotation required to answer the question. While we leave such a task to future research we plan to release our formulation of CLEVR-MRT as a dataset in our code repository to encourage future work on more challenging mental rotation based tasks.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Another interesting and related task is that of using natural language to guide robot navigation, and another version of CLEVR for this task has been proposed and examined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> within a reinforcement learning setup. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, each scene contains a large occluding object in the center of the scene and the agent must try to navigate around it in order to answer the question. However, in the dataset of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> it appears that the occluding object is always a large object in the center of the scene, which limits the variability of the scenes. Conversely, our dataset has significantly more occlusion variability when the camera’s elevation is such that it is very close to the ground (see Figure <a href="#S3.F8" title="Figure 8 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>). Therefore, ideas from both these datasets could be combined to construct a more difficult CLEVR-like dataset specifically targeted towards navigation tasks.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Our work also has applications in indoor navigation for humans, using natural language to assist themn. Consider a user trying to navigate to a particular location in an unknown building while receiving instructions from a neural network acting as a navigation system. In such an indoor scenario, occlusion is extremely commonplace: potted plants, desks, chairs, walls, and doors. Smaller objects such as desks and chairs may not necessarily occupy a static position, and may change location. Unfamiliar room locations may be hard to find. As we discussed in Section <a href="#S1.SS1" title="1.1 Related work ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.1</span></a>, for these kinds of tasks it is not strictly necessary to perform a pixel-level 3D reconstruction of the scene, but rather powerful neural representations that can be modulated through natural language. With an understanding of what a user would see at different locations, a system could better provide navigation assistance.</p>
</div>
<figure id="S3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.01639/assets/figures/clevr-mrt-v3-poc.png" id="S3.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F9.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.01639/assets/figures/clevr-mrt-nav-poc.png" id="S3.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F9.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F9.4.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><a href="#S3.F9.sf1" title="In Figure 9 ‣ 3.1 Limitations and Future Work ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">9(a)</span></a><span id="S3.F9.5.2" class="ltx_text" style="font-size:90%;">: Visualization of a more difficult formulation of <em id="S3.F9.5.2.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em> where the camera is now visible as floating purple cone. Instead of being given its coordinates a-priori to condition on the rotation of the latent volume, its coordinates will also have to be inferred from the image. <a href="#S3.F9.sf2" title="In Figure 9 ‣ 3.1 Limitations and Future Work ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a>: An example use-case for systems capable of performing CLEVR-MRT tasks. A system that is able to answer questions in natural language about what would be seen from another viewpoint, could be leveraged to provide navigation instructions using natural language to an agent seeking a destination or object. In this scenario the agent wishes to navigate to the shiny cyan cube. A system could provide instructions of the form: <span id="S3.F9.5.2.2" class="ltx_text ltx_font_bold ltx_font_italic">‘To find the shiny cyan cube go straight past the blue sphere on your left and the grey sphere on your right until you are in front of the red cube. You should see the cyan cube to your left as you approach the red cube.’</span> Multiple rounds of interaction may be needed, but a key capability here is the ability of the system to understand what would be seen from a particular viewpoint.</span></figcaption>
</figure>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">In Figure <a href="#S3.F9.sf2" title="In Figure 9 ‣ 3.1 Limitations and Future Work ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9(b)</span></a> we also provide a concrete example of how learning to perform the CLEVR-MRT tasks is related to the types of language guided navigation applications discussed above. By understanding what would be seen by an agent at a particular location and viewing position, a system could better formulate natural language instructions for how to reach a desired destination. Our current system is limited in that we have not implemented a mechanism to transform the answers to questions about alternative viewpoints into sequences of navigation instructions, but we feel that integrating CLEVR-MRT approaches into these navigation scenarios would be an interesting direction for future research.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">In terms of limitations related to our contrastive learning results, we note that the particular algorithm we used, SimCLR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, requires a large batch size so that many negative examples can be contrasted against per minibatch. Such a large batch size can be prohibitively expensive in practice and require GPUs with large amounts of memory. Other recent work that alleviates this includes MoCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and SimSiam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, the latter of which does not require any negative examples whatsoever.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Lastly, another limitation of our work concerns the interpretability of the learned latent feature volumes. Although we argue that certain tasks such as VQA do not necessarily require an explicit 3D reconstruction of the scene (see Section <a href="#S1.SS1" title="1.1 Related work ‣ 1 Introduction ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.1</span></a>), it may be beneficial from an interpretability or explainability point of view to consider an additional neural rendering step which takes the latent volume as input and re-renders the scene, possibly in another viewpoint. This can certainly be useful as a diagnostic tool to probe learned neural representations.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We address the problem of answering a question from a single image, posed in a reference frame that is different to the one of the viewer. We illustrate the difficulties here in a controlled setting, proposing a new CLEVR dataset and exploring a 3D FILM-based architecture that operates directly on latent feature volumes (using camera conditioning via FILM or via direct rigid transforms on the volume). We propose two techniques to train volumetric encoders: with 2D-to-3D projection of pre-trained ImageNet features, or using a self-supervised contrastive approach. In the latter case, we showed that the use of combined 2D+3D data augmentation was crucial to learning a volumetric encoder, as well as performing almost just as well as pre-trained ImageNet features. Because pre-training such a self-supervised encoder does not require supervision in the form of camera extrinsics or dataset-specific labels, it is more economically feasible for datasets where rich labels are not available. Through rigorous ablations, we demonstrated that performing 3D FILM was the most effective for <em id="S4.p1.1.1" class="ltx_emph ltx_font_italic">CLEVR-MRT</em>, especially when the latent volume can be subjected to rigid transformations in order to answer the question. While the efficacy of our method has been demonstrated empirically, we identified several avenues in which <em id="S4.p1.1.2" class="ltx_emph ltx_font_italic">CLEVR-MRT</em> can be made more realistic and challenging. Some examples of this include: an additional task of inferring the camera from the scene before performing the mental rotation; robot navigation tasks with a large variety of occluding objects; and language-guided indoor navigation. Lastly, while the use of an artificially-created dataset like CLEVR makes it easy to probe and test various properties of our algorithms, real-world VQA datasets involving mental rotations are required for a more practical validation of our proposed methods.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Broader Impacts</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Endowing intelligent embodied systems with the ability to answer questions regarding properties of a 3D visual scene with respect to the perspective of another agent could make such systems safer. In the case of an autonomous vehicles, better control decisions could eventually be made. If such systems are adversarial in nature, negative outcomes could arise to the adversaries of such systems.</p>
</div>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The authors are grateful to the Natural Sciences and Engineering Research Council (NSERC) of Canada, and PROMPT Quebec for their support of this work. The first author also thanks the Mathematics of Information Technology and Complex Systems (MITACS) organization as well as the Institute for Data Valorization (IVADO) for their support. We also thank the Canadian Institute for Advanced Research (CIFAR) for their support under the Artificial Intelligence Research Chairs program. The primary author is grateful to David Vasquez and Catherine Martin for facilitating a research internship at ServiceNow Research.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bachman et al. [2019]</span>
<span class="ltx_bibblock">
Philip Bachman, R Devon Hjelm, and William Buchwalter.

</span>
<span class="ltx_bibblock">Learning representations by maximizing mutual information across
views.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pp. 15535–15545, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al. [2019]</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Harm de Vries, Timothy J O’Donnell, Shikhar Murty, Philippe
Beaudoin, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock">CLOSURE: assessing systematic generalization of CLEVR models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Visually Grounded Interaction and Language (ViGIL)
workshop, NeurIPS 2019</em>, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Behjati et al. [2023]</span>
<span class="ltx_bibblock">
Parichehr Behjati, Pau Rodriguez, Carles Fernández, Isabelle Hupont, Armin
Mehri, and Jordi Gonzàlez.

</span>
<span class="ltx_bibblock">Single image super-resolution based on directional variance attention
network.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 133:108997, 2023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2020]</span>
<span class="ltx_bibblock">
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">A simple framework for contrastive learning of visual
representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp. 1597–1607. PMLR, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen &amp; He [2021]</span>
<span class="ltx_bibblock">
Xinlei Chen and Kaiming He.

</span>
<span class="ltx_bibblock">Exploring simple siamese representation learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  15750–15758, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dou et al. [2018]</span>
<span class="ltx_bibblock">
Pengfei Dou, Yuhang Wu, Shishir K Shah, and Ioannis A Kakadiaris.

</span>
<span class="ltx_bibblock">Monocular 3D facial shape reconstruction from a single 2D image
with coupled-dictionary learning and sparse coding.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 81:515–527, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eslami et al. [2018]</span>
<span class="ltx_bibblock">
SM Ali Eslami, Danilo Jimenez Rezende, Frederic Besse, Fabio Viola, Ari S
Morcos, Marta Garnelo, Avraham Ruderman, Andrei A Rusu, Ivo Danihelka, Karol
Gregor, et al.

</span>
<span class="ltx_bibblock">Neural scene representation and rendering.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Science</em>, 360(6394):1204–1210, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fahim et al. [2021]</span>
<span class="ltx_bibblock">
George Fahim, Khalid Amin, and Sameh Zarif.

</span>
<span class="ltx_bibblock">Single-view 3D reconstruction: A survey of deep learning methods.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Graphics</em>, 94:164–190, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Furukawa &amp; Hernández [2015]</span>
<span class="ltx_bibblock">
Yasutaka Furukawa and Carlos Hernández.

</span>
<span class="ltx_bibblock">Multi-view stereo: A tutorial.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Computer Graphics
and Vision</em>, 9(1-2):1–148, 2015.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harley et al. [2020]</span>
<span class="ltx_bibblock">
Adam W Harley, Shrinidhi K Lakshmikanth, Fangyu Li, Xian Zhou, Hsiao-Yu Fish
Tung, and Katerina Fragkiadaki.

</span>
<span class="ltx_bibblock">Learning from unlabelled videos using contrastive predictive neural
3D mapping.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2016]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition</em>, pp.  770–778, 2016.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2018]</span>
<span class="ltx_bibblock">
Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.

</span>
<span class="ltx_bibblock">Mask R-CNN.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 42(2):386–397, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2020]</span>
<span class="ltx_bibblock">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.

</span>
<span class="ltx_bibblock">Momentum contrast for unsupervised visual representation learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  9729–9738, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2023]</span>
<span class="ltx_bibblock">
Zewei He, Du Chen, Yanpeng Cao, Jiangxin Yang, Yanlong Cao, Xin Li, Siliang
Tang, Yueting Zhuang, and Zhe-ming Lu.

</span>
<span class="ltx_bibblock">Single image super-resolution based on progressive fusion of
orientation-aware features.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 133:109038, 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hudson &amp; Manning [2018]</span>
<span class="ltx_bibblock">
Drew A Hudson and Christopher D Manning.

</span>
<span class="ltx_bibblock">Compositional attention networks for machine reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>,
2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaderberg et al. [2015]</span>
<span class="ltx_bibblock">
Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al.

</span>
<span class="ltx_bibblock">Spatial transformer networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pp. 2017–2025, 2015.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jo et al. [2015]</span>
<span class="ltx_bibblock">
Jaeik Jo, Heeseung Choi, Ig-Jae Kim, and Jaihie Kim.

</span>
<span class="ltx_bibblock">Single-view-based 3D facial reconstruction method robust against
pose variations.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 48(1):73–85, 2015.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. [2017]</span>
<span class="ltx_bibblock">
Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei,
C Lawrence Zitnick, and Ross Girshick.

</span>
<span class="ltx_bibblock">CLEVR: A diagnostic dataset for compositional language and
elementary visual reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em>, pp.  2901–2910, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamath et al. [2021]</span>
<span class="ltx_bibblock">
Aishwarya Kamath, Mannat Singh, Yann LeCun, Gabriel Synnaeve, Ishan Misra, and
Nicolas Carion.

</span>
<span class="ltx_bibblock">MDETR-modulated detection for end-to-end multi-modal understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pp.  1780–1790, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al. [2016]</span>
<span class="ltx_bibblock">
Xin Kang, Wai-Pan Yau, and Russell H Taylor.

</span>
<span class="ltx_bibblock">Simultaneous pose estimation and patient-specific model
reconstruction from single image using maximum penalized likelihood
estimation (MPLE).

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 57:61–69, 2016.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kato et al. [2018]</span>
<span class="ltx_bibblock">
Hiroharu Kato, Yoshitaka Ushiku, and Tatsuya Harada.

</span>
<span class="ltx_bibblock">Neural 3D mesh renderer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em>, pp.  3907–3916, 2018.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma &amp; Ba [2015]</span>
<span class="ltx_bibblock">
Diederik P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">ADAM: A method for stochastic optimization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">ICLR (Poster)</em>, 2015.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kottur et al. [2019]</span>
<span class="ltx_bibblock">
Satwik Kottur, José MF Moura, Devi Parikh, Dhruv Batra, and Marcus
Rohrbach.

</span>
<span class="ltx_bibblock">CLEVR-Dialog: A diagnostic dataset for multi-round reasoning in
visual dialog.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT (1)</em>, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2018]</span>
<span class="ltx_bibblock">
Rosanne Liu, Joel Lehman, Piero Molino, Felipe Petroski Such, Eric Frank, Alex
Sergeev, and Jason Yosinski.

</span>
<span class="ltx_bibblock">An intriguing failing of convolutional neural networks and the
CoordConv solution.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 31, 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lombardi et al. [2019]</span>
<span class="ltx_bibblock">
Stephen Lombardi, Tomas Simon, Jason Saragih, Gabriel Schwartz, Andreas
Lehrmann, and Yaser Sheikh.

</span>
<span class="ltx_bibblock">Neural volumes: Learning dynamic renderable volumes from images.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (TOG)</em>, 38(4):65, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mildenhall et al. [2021]</span>
<span class="ltx_bibblock">
Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi
Ramamoorthi, and Ren Ng.

</span>
<span class="ltx_bibblock">NERF: Representing scenes as neural radiance fields for view
synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 65(1):99–106,
2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen-Phuoc et al. [2019]</span>
<span class="ltx_bibblock">
Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, and Yong-Liang
Yang.

</span>
<span class="ltx_bibblock">HoloGAN: Unsupervised learning of 3D representations from natural
images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pp.  7588–7597, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nie et al. [2020]</span>
<span class="ltx_bibblock">
Yinyu Nie, Shihui Guo, Jian Chang, Xiaoguang Han, Jiahui Huang, Shi-Min Hu, and
Jian Jun Zhang.

</span>
<span class="ltx_bibblock">Shallow2Deep: Indoor scene modeling by single image understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 103:107271, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord et al. [2018]</span>
<span class="ltx_bibblock">
Aaron van den Oord, Yazhe Li, and Oriol Vinyals.

</span>
<span class="ltx_bibblock">Representation learning with contrastive predictive coding.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1807.03748</em>, 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. [2019]</span>
<span class="ltx_bibblock">
Dong Huk Park, Trevor Darrell, and Anna Rohrbach.

</span>
<span class="ltx_bibblock">Robust change captioning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on
Computer Vision</em>, pp.  4624–4633, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perez et al. [2018]</span>
<span class="ltx_bibblock">
Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron
Courville.

</span>
<span class="ltx_bibblock">FILM: Visual reasoning with a general conditioning layer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 32, 2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pontes et al. [2018]</span>
<span class="ltx_bibblock">
Jhony K Pontes, Chen Kong, Sridha Sridharan, Simon Lucey, Anders Eriksson, and
Clinton Fookes.

</span>
<span class="ltx_bibblock">Image2mesh: A learning framework for single image 3D
reconstruction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Asian Conference on Computer Vision</em>, pp.  365–381.
Springer, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et al. [2017]</span>
<span class="ltx_bibblock">
Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas.

</span>
<span class="ltx_bibblock">Pointnet: Deep learning on point sets for 3D classification and
segmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em>, pp.  652–660, 2017.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al. [2019]</span>
<span class="ltx_bibblock">
Yue Qiu, Yutaka Satoh, Ryota Suzuki, and Hirokatsu Kataoka.

</span>
<span class="ltx_bibblock">Incorporating 3D information into visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">2019 International Conference on 3D Vision (3DV)</em>, pp. 756–765. IEEE, 2019.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al. [2020]</span>
<span class="ltx_bibblock">
Yue Qiu, Yutaka Satoh, Ryota Suzuki, Kenji Iwata, and Hirokatsu Kataoka.

</span>
<span class="ltx_bibblock">Multi-view visual question answering with active viewpoint selection.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, 20(8):2281, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajeswar et al. [2020]</span>
<span class="ltx_bibblock">
Sai Rajeswar, Fahim Mannan, Florian Golemo, Jérôme Parent-Lévesque,
David Vazquez, Derek Nowrouzezahrai, and Aaron Courville.

</span>
<span class="ltx_bibblock">Pix2shape: Towards unsupervised learning of 3D scenes from images
using a view-based representation.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, pp.  1–16, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shepard &amp; Metzler [1971]</span>
<span class="ltx_bibblock">
Roger N Shepard and Jacqueline Metzler.

</span>
<span class="ltx_bibblock">Mental rotation of three-dimensional objects.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Science</em>, 171(3972):701–703, 1971.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sitzmann et al. [2019]</span>
<span class="ltx_bibblock">
Vincent Sitzmann, Justus Thies, Felix Heide, Matthias Nießner, Gordon
Wetzstein, and Michael Zollhofer.

</span>
<span class="ltx_bibblock">Deepvoxels: Learning persistent 3D feature embeddings.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  2437–2446, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thies et al. [2019]</span>
<span class="ltx_bibblock">
Justus Thies, Michael Zollhöfer, and Matthias Nießner.

</span>
<span class="ltx_bibblock">Deferred neural rendering: Image synthesis using neural textures.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (TOG)</em>, 38(4):1–12, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. [2020]</span>
<span class="ltx_bibblock">
Yonglong Tian, Dilip Krishnan, and Phillip Isola.

</span>
<span class="ltx_bibblock">Contrastive multiview coding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>, pp.  776–794.
Springer, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2018]</span>
<span class="ltx_bibblock">
Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, and Yu-Gang Jiang.

</span>
<span class="ltx_bibblock">Pixel2Mesh: Generating 3D mesh models from single RGB images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>, 2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2016]</span>
<span class="ltx_bibblock">
Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum.

</span>
<span class="ltx_bibblock">Learning a probabilistic latent space of object shapes via 3D
generative-adversarial modeling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pp. 82–90, 2016.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. [2016]</span>
<span class="ltx_bibblock">
Xinchen Yan, Jimei Yang, Ersin Yumer, Yijie Guo, and Honglak Lee.

</span>
<span class="ltx_bibblock">Perspective transformer nets: Learning single-view 3D object
reconstruction without 3D supervision.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 29, 2016.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2022]</span>
<span class="ltx_bibblock">
Yang Yang, Junwei Han, Dingwen Zhang, and Qi Tian.

</span>
<span class="ltx_bibblock">Exploring rich intermediate representations for reconstructing 3D
shapes from 2D images.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 122:108295, 2022.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. [2018]</span>
<span class="ltx_bibblock">
Shunyu Yao, Tzu Ming Hsu, Jun-Yan Zhu, Jiajun Wu, Antonio Torralba, Bill
Freeman, and Josh Tenenbaum.

</span>
<span class="ltx_bibblock">3D-aware scene manipulation via inverse graphics.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 31, 2018.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et al. [2018]</span>
<span class="ltx_bibblock">
Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, and
Joshua B. Tenenbaum.

</span>
<span class="ltx_bibblock">Neural-symbolic VQA: Disentangling reasoning from vision and
language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pp. 1039–1050, 2018.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et al. [2019]</span>
<span class="ltx_bibblock">
Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba,
and Joshua B Tenenbaum.

</span>
<span class="ltx_bibblock">CLEVRER: collision events for video representation and reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>,
2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Supplementary material</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Hyperparameters</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Table <a href="#S5.T4" title="Table 4 ‣ 5.1 Hyperparameters ‣ 5 Supplementary material ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> lists hyperparameters of the FILM module, which can be found in <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">architectures/clevr/probe.py</span>. <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>While an effort was made for this information to be accurate, the source code should always be the definitive reference.</span></span></span></p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S5.T4.3.2" class="ltx_text" style="font-size:90%;">Names and descriptions of hyperparameters used for the experiments. Please see Appendix Figure <a href="#S5.F10" title="Figure 10 ‣ 5.1 Hyperparameters ‣ 5 Supplementary material ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> for more details.</span></figcaption>
<table id="S5.T4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.4.1.1" class="ltx_tr">
<th id="S5.T4.4.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt" style="width:130.1pt;">
<span id="S5.T4.4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.1.1.1.1.1" class="ltx_p">Hyperparameter</span>
</span>
</th>
<th id="S5.T4.4.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_tt" style="width:260.2pt;">
<span id="S5.T4.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.1.1.2.1.1" class="ltx_p">Description</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.4.2.1" class="ltx_tr">
<td id="S5.T4.4.2.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.2.1.1.1.1" class="ltx_p"><span id="S5.T4.4.2.1.1.1.1.1" class="ltx_text ltx_font_typewriter">rnn_dim</span></span>
</span>
</td>
<td id="S5.T4.4.2.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.2.1.2.1.1" class="ltx_p">Output GRU embedding dimension</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.3.2" class="ltx_tr">
<td id="S5.T4.4.3.2.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.3.2.1.1.1" class="ltx_p"><span id="S5.T4.4.3.2.1.1.1.1" class="ltx_text ltx_font_typewriter">rnn_num_layers</span></span>
</span>
</td>
<td id="S5.T4.4.3.2.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.3.2.2.1.1" class="ltx_p">Number of hidden layers in the GRU</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.4.3" class="ltx_tr">
<td id="S5.T4.4.4.3.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.4.3.1.1.1" class="ltx_p"><span id="S5.T4.4.4.3.1.1.1.1" class="ltx_text ltx_font_typewriter">n_resblocks</span></span>
</span>
</td>
<td id="S5.T4.4.4.3.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.4.3.2.1.1" class="ltx_p">How many FILMed ResBlocks do we use?</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.5.4" class="ltx_tr">
<td id="S5.T4.4.5.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.5.4.1.1.1" class="ltx_p"><span id="S5.T4.4.5.4.1.1.1.1" class="ltx_text ltx_font_typewriter">with_coords</span></span>
</span>
</td>
<td id="S5.T4.4.5.4.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.5.4.2.1.1" class="ltx_p">Do we append CoordConv <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> feature maps in each ResBlock?</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.6.5" class="ltx_tr">
<td id="S5.T4.4.6.5.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.6.5.1.1.1" class="ltx_p"><span id="S5.T4.4.6.5.1.1.1.1" class="ltx_text ltx_font_typewriter">nf_</span></span>
</span>
</td>
<td id="S5.T4.4.6.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.6.5.2.1.1" class="ltx_p">Number of output feature maps in each ResBlock</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.7.6" class="ltx_tr">
<td id="S5.T4.4.7.6.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.7.6.1.1.1" class="ltx_p"><span id="S5.T4.4.7.6.1.1.1.1" class="ltx_text ltx_font_typewriter">with_camera</span></span>
</span>
</td>
<td id="S5.T4.4.7.6.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.7.6.2.1.1" class="ltx_p">Do we concatenate the camera embedding with the GRU embedding? (This should be set to true when using camera-conditioned FILM.)</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.8.7" class="ltx_tr">
<td id="S5.T4.4.8.7.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.8.7.1.1.1" class="ltx_p"><span id="S5.T4.4.8.7.1.1.1.1" class="ltx_text ltx_font_typewriter">ncf</span></span>
</span>
</td>
<td id="S5.T4.4.8.7.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.8.7.2.1.1" class="ltx_p">Dimension of the camera embedding. If set to none, we will simply use the original six coordinates rather than a projection MLP.</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.9.8" class="ltx_tr">
<td id="S5.T4.4.9.8.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.9.8.1.1.1" class="ltx_p"><span id="S5.T4.4.9.8.1.1.1.1" class="ltx_text ltx_font_typewriter">weight_decay</span></span>
</span>
</td>
<td id="S5.T4.4.9.8.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.9.8.2.1.1" class="ltx_p">Weight decay term for ADAM optimiser.</span>
</span>
</td>
</tr>
<tr id="S5.T4.4.10.9" class="ltx_tr">
<td id="S5.T4.4.10.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:130.1pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.10.9.1.1.1" class="ltx_p"><span id="S5.T4.4.10.9.1.1.1.1" class="ltx_text ltx_font_typewriter">imagenet_scaling</span></span>
</span>
</td>
<td id="S5.T4.4.10.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:260.2pt;padding-bottom:4.0pt;">
<span id="S5.T4.4.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T4.4.10.9.2.1.1" class="ltx_p">(For pretrained ImageNet encoder only) Use ImageNet mean/variance to scale the inputs instead of the default [-1, 1] scaling?</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.2" class="ltx_p">Each experiment was trained for a maximum of 60 epochs with the ADAM optimiser <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, with a default learning rate of <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="3\times 10^{-4}" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mn id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.p2.1.m1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.cmml">×</mo><msup id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml"><mn id="S5.SS1.p2.1.m1.1.1.3.2" xref="S5.SS1.p2.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.SS1.p2.1.m1.1.1.3.3" xref="S5.SS1.p2.1.m1.1.1.3.3.cmml"><mo id="S5.SS1.p2.1.m1.1.1.3.3a" xref="S5.SS1.p2.1.m1.1.1.3.3.cmml">−</mo><mn id="S5.SS1.p2.1.m1.1.1.3.3.2" xref="S5.SS1.p2.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><times id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">3</cn><apply id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.3.1.cmml" xref="S5.SS1.p2.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.SS1.p2.1.m1.1.1.3.2.cmml" xref="S5.SS1.p2.1.m1.1.1.3.2">10</cn><apply id="S5.SS1.p2.1.m1.1.1.3.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3.3"><minus id="S5.SS1.p2.1.m1.1.1.3.3.1.cmml" xref="S5.SS1.p2.1.m1.1.1.3.3"></minus><cn type="integer" id="S5.SS1.p2.1.m1.1.1.3.3.2.cmml" xref="S5.SS1.p2.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">3\times 10^{-4}</annotation></semantics></math> and first and second moment coefficients <math id="S5.SS1.p2.2.m2.4" class="ltx_Math" alttext="\{\beta_{1},\beta_{2}\}=\{0.9,0.999\}" display="inline"><semantics id="S5.SS1.p2.2.m2.4a"><mrow id="S5.SS1.p2.2.m2.4.4" xref="S5.SS1.p2.2.m2.4.4.cmml"><mrow id="S5.SS1.p2.2.m2.4.4.2.2" xref="S5.SS1.p2.2.m2.4.4.2.3.cmml"><mo stretchy="false" id="S5.SS1.p2.2.m2.4.4.2.2.3" xref="S5.SS1.p2.2.m2.4.4.2.3.cmml">{</mo><msub id="S5.SS1.p2.2.m2.3.3.1.1.1" xref="S5.SS1.p2.2.m2.3.3.1.1.1.cmml"><mi id="S5.SS1.p2.2.m2.3.3.1.1.1.2" xref="S5.SS1.p2.2.m2.3.3.1.1.1.2.cmml">β</mi><mn id="S5.SS1.p2.2.m2.3.3.1.1.1.3" xref="S5.SS1.p2.2.m2.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S5.SS1.p2.2.m2.4.4.2.2.4" xref="S5.SS1.p2.2.m2.4.4.2.3.cmml">,</mo><msub id="S5.SS1.p2.2.m2.4.4.2.2.2" xref="S5.SS1.p2.2.m2.4.4.2.2.2.cmml"><mi id="S5.SS1.p2.2.m2.4.4.2.2.2.2" xref="S5.SS1.p2.2.m2.4.4.2.2.2.2.cmml">β</mi><mn id="S5.SS1.p2.2.m2.4.4.2.2.2.3" xref="S5.SS1.p2.2.m2.4.4.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S5.SS1.p2.2.m2.4.4.2.2.5" xref="S5.SS1.p2.2.m2.4.4.2.3.cmml">}</mo></mrow><mo id="S5.SS1.p2.2.m2.4.4.3" xref="S5.SS1.p2.2.m2.4.4.3.cmml">=</mo><mrow id="S5.SS1.p2.2.m2.4.4.4.2" xref="S5.SS1.p2.2.m2.4.4.4.1.cmml"><mo stretchy="false" id="S5.SS1.p2.2.m2.4.4.4.2.1" xref="S5.SS1.p2.2.m2.4.4.4.1.cmml">{</mo><mn id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">0.9</mn><mo id="S5.SS1.p2.2.m2.4.4.4.2.2" xref="S5.SS1.p2.2.m2.4.4.4.1.cmml">,</mo><mn id="S5.SS1.p2.2.m2.2.2" xref="S5.SS1.p2.2.m2.2.2.cmml">0.999</mn><mo stretchy="false" id="S5.SS1.p2.2.m2.4.4.4.2.3" xref="S5.SS1.p2.2.m2.4.4.4.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.4b"><apply id="S5.SS1.p2.2.m2.4.4.cmml" xref="S5.SS1.p2.2.m2.4.4"><eq id="S5.SS1.p2.2.m2.4.4.3.cmml" xref="S5.SS1.p2.2.m2.4.4.3"></eq><set id="S5.SS1.p2.2.m2.4.4.2.3.cmml" xref="S5.SS1.p2.2.m2.4.4.2.2"><apply id="S5.SS1.p2.2.m2.3.3.1.1.1.cmml" xref="S5.SS1.p2.2.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.3.3.1.1.1.1.cmml" xref="S5.SS1.p2.2.m2.3.3.1.1.1">subscript</csymbol><ci id="S5.SS1.p2.2.m2.3.3.1.1.1.2.cmml" xref="S5.SS1.p2.2.m2.3.3.1.1.1.2">𝛽</ci><cn type="integer" id="S5.SS1.p2.2.m2.3.3.1.1.1.3.cmml" xref="S5.SS1.p2.2.m2.3.3.1.1.1.3">1</cn></apply><apply id="S5.SS1.p2.2.m2.4.4.2.2.2.cmml" xref="S5.SS1.p2.2.m2.4.4.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.4.4.2.2.2.1.cmml" xref="S5.SS1.p2.2.m2.4.4.2.2.2">subscript</csymbol><ci id="S5.SS1.p2.2.m2.4.4.2.2.2.2.cmml" xref="S5.SS1.p2.2.m2.4.4.2.2.2.2">𝛽</ci><cn type="integer" id="S5.SS1.p2.2.m2.4.4.2.2.2.3.cmml" xref="S5.SS1.p2.2.m2.4.4.2.2.2.3">2</cn></apply></set><set id="S5.SS1.p2.2.m2.4.4.4.1.cmml" xref="S5.SS1.p2.2.m2.4.4.4.2"><cn type="float" id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">0.9</cn><cn type="float" id="S5.SS1.p2.2.m2.2.2.cmml" xref="S5.SS1.p2.2.m2.2.2">0.999</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.4c">\{\beta_{1},\beta_{2}\}=\{0.9,0.999\}</annotation></semantics></math>. Figure <a href="#S5.F10" title="Figure 10 ‣ 5.1 Hyperparameters ‣ 5 Supplementary material ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> illustrates an example range of hyperparameters explored per experiment (where each experiment refers to one of the results performed in Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Note that this is <em id="S5.SS1.p2.2.1" class="ltx_emph ltx_font_italic">not</em> an exhaustive range of values explored – rather, the values seen per experiment in the Figure <a href="#S5.F10" title="Figure 10 ‣ 5.1 Hyperparameters ‣ 5 Supplementary material ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> correspond to the batch of runs in which at least one of the runs inside the batch gave the highest validation score(s). (Other batches of HP/value combinations were also run but may not have yielded the best validation accuracies, and therefore are not shown in the figure.) Whichever experiment was found to have the highest validation score was re-trained multiple times (under different seeds) and evaluated on the test set.</p>
</div>
<figure id="S5.F10" class="ltx_figure">
<figure id="S5.F10.tab1" class="ltx_float ltx_lstlisting">
<div id="S5.F10.tab1.1" class="ltx_listing ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,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" download="hps.txt">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">2</span><span id="lstnumberx1.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">d</span><span id="lstnumberx1.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx1.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">film</span><span id="lstnumberx1.5" class="ltx_text ltx_font_typewriter" style="font-size:50%;">,</span><span id="lstnumberx1.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx1.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">no</span><span id="lstnumberx1.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx1.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">camera</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">------------------</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx4.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx4.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_dim</span><span id="lstnumberx4.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{128,</span><span id="lstnumberx4.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">512,</span><span id="lstnumberx4.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">256,</span><span id="lstnumberx4.11" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1024},</span><span id="lstnumberx4.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_resblocks</span><span id="lstnumberx4.16" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.17" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.18" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{4},</span><span id="lstnumberx4.19" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.20" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">encoder</span><span id="lstnumberx4.22" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.23" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.24" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx4.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">gru</span><span id="lstnumberx4.26" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’},</span><span id="lstnumberx4.27" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.28" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_coords</span><span id="lstnumberx4.30" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.31" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.32" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx4.33" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx4.34" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx4.35" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.36" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.37" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_num_layers</span><span id="lstnumberx4.38" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.39" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.40" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1,</span><span id="lstnumberx4.41" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.42" class="ltx_text ltx_font_typewriter" style="font-size:50%;">2},</span><span id="lstnumberx4.43" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.44" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.45" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_in</span><span id="lstnumberx4.46" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.47" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.48" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1024},</span><span id="lstnumberx4.49" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.50" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.51" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">nf</span><span id="lstnumberx4.52" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.53" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.54" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx4.55" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">None</span><span id="lstnumberx4.56" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx4.57" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.58" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.59" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">coord_shape</span><span id="lstnumberx4.60" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.61" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.62" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{(14,</span><span id="lstnumberx4.63" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.64" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14)},</span><span id="lstnumberx4.65" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.66" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.67" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_camera</span><span id="lstnumberx4.68" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.69" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.70" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx4.71" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx4.72" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx4.73" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.74" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx4.75" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">ncf</span><span id="lstnumberx4.76" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx4.77" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx4.78" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx4.79" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">None</span><span id="lstnumberx4.80" class="ltx_text ltx_font_typewriter" style="font-size:50%;">}}</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx5.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx5.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">weight_decay</span><span id="lstnumberx5.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx5.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx5.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1</span><span id="lstnumberx5.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx5.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-05,</span><span id="lstnumberx5.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx5.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">0.0001}}</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span id="lstnumberx7.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">2</span><span id="lstnumberx7.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">d</span><span id="lstnumberx7.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx7.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">film</span><span id="lstnumberx7.5" class="ltx_text ltx_font_typewriter" style="font-size:50%;">,</span><span id="lstnumberx7.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx7.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">camera</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">---------------</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx10.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx10.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_dim</span><span id="lstnumberx10.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1024,</span><span id="lstnumberx10.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">512},</span><span id="lstnumberx10.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_resblocks</span><span id="lstnumberx10.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{4},</span><span id="lstnumberx10.15" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.16" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">encoder</span><span id="lstnumberx10.18" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.19" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.20" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx10.21" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">gru</span><span id="lstnumberx10.22" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’},</span><span id="lstnumberx10.23" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.24" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_coords</span><span id="lstnumberx10.26" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.27" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.28" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx10.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx10.30" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx10.31" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.32" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.33" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_num_layers</span><span id="lstnumberx10.34" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.35" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.36" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1,</span><span id="lstnumberx10.37" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.38" class="ltx_text ltx_font_typewriter" style="font-size:50%;">2},</span><span id="lstnumberx10.39" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.40" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.41" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_in</span><span id="lstnumberx10.42" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.43" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.44" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1024},</span><span id="lstnumberx10.45" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.46" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.47" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">nf</span><span id="lstnumberx10.48" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.49" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.50" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{64,</span><span id="lstnumberx10.51" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.52" class="ltx_text ltx_font_typewriter" style="font-size:50%;">128},</span><span id="lstnumberx10.53" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.54" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.55" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">coord_shape</span><span id="lstnumberx10.56" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.57" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.58" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{(14,</span><span id="lstnumberx10.59" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.60" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14)},</span><span id="lstnumberx10.61" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.62" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.63" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_camera</span><span id="lstnumberx10.64" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.65" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.66" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx10.67" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx10.68" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx10.69" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.70" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx10.71" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">ncf</span><span id="lstnumberx10.72" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx10.73" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx10.74" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{64}}</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx11.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx11.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">weight_decay</span><span id="lstnumberx11.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx11.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx11.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{0,</span><span id="lstnumberx11.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx11.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">0.0001,</span><span id="lstnumberx11.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx11.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1</span><span id="lstnumberx11.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx11.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-05}}</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span id="lstnumberx12.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx12.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx12.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">imagenet_scaling</span><span id="lstnumberx12.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx12.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx12.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx12.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx12.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">}}</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx13.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx13.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">batch_size</span><span id="lstnumberx13.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx13.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx13.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{16}}</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
</div>
<div id="lstnumberx15" class="ltx_listingline">
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">3</span><span id="lstnumberx16.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">d</span><span id="lstnumberx16.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx16.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">film</span><span id="lstnumberx16.5" class="ltx_text ltx_font_typewriter" style="font-size:50%;">,</span><span id="lstnumberx16.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx16.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">no</span><span id="lstnumberx16.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx16.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">camera</span><span id="lstnumberx16.10" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx16.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">embed</span><span id="lstnumberx16.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">/</span><span id="lstnumberx16.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rotation</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">---------------------------------</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx19.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx19.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_dim</span><span id="lstnumberx19.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{512,</span><span id="lstnumberx19.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1024},</span><span id="lstnumberx19.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_num_layers</span><span id="lstnumberx19.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1},</span><span id="lstnumberx19.15" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.16" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_resblocks</span><span id="lstnumberx19.18" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.19" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.20" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{4},</span><span id="lstnumberx19.21" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.22" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">encoder</span><span id="lstnumberx19.24" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.25" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.26" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx19.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">gru</span><span id="lstnumberx19.28" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’},</span><span id="lstnumberx19.29" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.30" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.31" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_coords</span><span id="lstnumberx19.32" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.33" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.34" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx19.35" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx19.36" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx19.37" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.38" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.39" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">coord_shape</span><span id="lstnumberx19.40" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.41" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.42" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{(16,</span><span id="lstnumberx19.43" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.44" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14,</span><span id="lstnumberx19.45" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.46" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14)},</span><span id="lstnumberx19.47" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.48" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.49" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_camera</span><span id="lstnumberx19.50" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.51" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.52" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx19.53" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx19.54" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx19.55" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.56" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.57" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">ncf</span><span id="lstnumberx19.58" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.59" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.60" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx19.61" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">None</span><span id="lstnumberx19.62" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx19.63" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.64" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.65" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">flatten_3d</span><span id="lstnumberx19.66" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.67" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.68" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx19.69" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx19.70" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx19.71" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.72" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.73" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">is_3d</span><span id="lstnumberx19.74" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.75" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.76" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx19.77" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx19.78" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx19.79" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.80" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.81" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_in</span><span id="lstnumberx19.82" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.83" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.84" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{128},</span><span id="lstnumberx19.85" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.86" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx19.87" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">nf</span><span id="lstnumberx19.88" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx19.89" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.90" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{64,</span><span id="lstnumberx19.91" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx19.92" class="ltx_text ltx_font_typewriter" style="font-size:50%;">128}}</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span id="lstnumberx20.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx20.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx20.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">weight_decay</span><span id="lstnumberx20.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx20.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx20.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{0,</span><span id="lstnumberx20.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx20.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1</span><span id="lstnumberx20.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx20.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-05}}</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx21.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx21.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">imagenet_scaling</span><span id="lstnumberx21.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx21.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx21.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx21.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx21.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">}}</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span id="lstnumberx23.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">3</span><span id="lstnumberx23.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">d</span><span id="lstnumberx23.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx23.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">film</span><span id="lstnumberx23.5" class="ltx_text ltx_font_typewriter" style="font-size:50%;">,</span><span id="lstnumberx23.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx23.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">camera</span><span id="lstnumberx23.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx23.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rotation</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
<span id="lstnumberx24.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">------------------------</span>
</div>
<div id="lstnumberx25" class="ltx_listingline">
</div>
<div id="lstnumberx26" class="ltx_listingline">
<span id="lstnumberx26.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx26.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx26.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_dim</span><span id="lstnumberx26.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{512,</span><span id="lstnumberx26.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1024},</span><span id="lstnumberx26.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_num_layers</span><span id="lstnumberx26.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1,</span><span id="lstnumberx26.15" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.16" class="ltx_text ltx_font_typewriter" style="font-size:50%;">2},</span><span id="lstnumberx26.17" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.18" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_resblocks</span><span id="lstnumberx26.20" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.21" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.22" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{4},</span><span id="lstnumberx26.23" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.24" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">encoder</span><span id="lstnumberx26.26" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.27" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.28" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx26.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">gru</span><span id="lstnumberx26.30" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’},</span><span id="lstnumberx26.31" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.32" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.33" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_coords</span><span id="lstnumberx26.34" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.35" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.36" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx26.37" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx26.38" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx26.39" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.40" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.41" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">coord_shape</span><span id="lstnumberx26.42" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.43" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.44" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{(16,</span><span id="lstnumberx26.45" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.46" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14,</span><span id="lstnumberx26.47" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.48" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14)},</span><span id="lstnumberx26.49" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.50" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.51" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_camera</span><span id="lstnumberx26.52" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.53" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.54" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx26.55" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx26.56" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx26.57" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.58" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.59" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">ncf</span><span id="lstnumberx26.60" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.61" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.62" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx26.63" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">None</span><span id="lstnumberx26.64" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx26.65" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.66" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.67" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">flatten_3d</span><span id="lstnumberx26.68" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.69" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.70" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx26.71" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx26.72" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx26.73" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.74" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.75" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">is_3d</span><span id="lstnumberx26.76" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.77" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.78" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx26.79" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx26.80" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx26.81" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.82" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.83" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_in</span><span id="lstnumberx26.84" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.85" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.86" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{128},</span><span id="lstnumberx26.87" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.88" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx26.89" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">nf</span><span id="lstnumberx26.90" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx26.91" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.92" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{64,</span><span id="lstnumberx26.93" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx26.94" class="ltx_text ltx_font_typewriter" style="font-size:50%;">128}}</span>
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span id="lstnumberx27.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx27.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx27.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">weight_decay</span><span id="lstnumberx27.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx27.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx27.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{0,</span><span id="lstnumberx27.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx27.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">0.0001,</span><span id="lstnumberx27.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx27.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1</span><span id="lstnumberx27.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx27.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-05}}</span>
</div>
<div id="lstnumberx28" class="ltx_listingline">
<span id="lstnumberx28.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx28.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx28.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">imagenet_scaling</span><span id="lstnumberx28.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx28.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx28.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx28.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx28.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">}}</span>
</div>
<div id="lstnumberx29" class="ltx_listingline">
</div>
<div id="lstnumberx30" class="ltx_listingline">
<span id="lstnumberx30.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">3</span><span id="lstnumberx30.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">d</span><span id="lstnumberx30.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx30.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">film</span><span id="lstnumberx30.5" class="ltx_text ltx_font_typewriter" style="font-size:50%;">,</span><span id="lstnumberx30.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx30.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">camera</span><span id="lstnumberx30.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx30.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">embed</span>
</div>
<div id="lstnumberx31" class="ltx_listingline">
<span id="lstnumberx31.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">---------------------</span>
</div>
<div id="lstnumberx32" class="ltx_listingline">
</div>
<div id="lstnumberx33" class="ltx_listingline">
<span id="lstnumberx33.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx33.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx33.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_dim</span><span id="lstnumberx33.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{512,</span><span id="lstnumberx33.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1024},</span><span id="lstnumberx33.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_num_layers</span><span id="lstnumberx33.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1,</span><span id="lstnumberx33.15" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.16" class="ltx_text ltx_font_typewriter" style="font-size:50%;">2},</span><span id="lstnumberx33.17" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.18" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_resblocks</span><span id="lstnumberx33.20" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.21" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.22" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{4},</span><span id="lstnumberx33.23" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.24" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">encoder</span><span id="lstnumberx33.26" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.27" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.28" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx33.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">gru</span><span id="lstnumberx33.30" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’},</span><span id="lstnumberx33.31" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.32" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.33" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_coords</span><span id="lstnumberx33.34" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.35" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.36" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx33.37" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx33.38" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx33.39" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.40" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.41" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">coord_shape</span><span id="lstnumberx33.42" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.43" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.44" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{(16,</span><span id="lstnumberx33.45" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.46" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14,</span><span id="lstnumberx33.47" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.48" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14)},</span><span id="lstnumberx33.49" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.50" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.51" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_camera</span><span id="lstnumberx33.52" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.53" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.54" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx33.55" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx33.56" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx33.57" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.58" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.59" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">ncf</span><span id="lstnumberx33.60" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.61" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.62" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx33.63" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">None</span><span id="lstnumberx33.64" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx33.65" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.66" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.67" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">flatten_3d</span><span id="lstnumberx33.68" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.69" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.70" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx33.71" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx33.72" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx33.73" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.74" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.75" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">is_3d</span><span id="lstnumberx33.76" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.77" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.78" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx33.79" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx33.80" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx33.81" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.82" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.83" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_in</span><span id="lstnumberx33.84" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.85" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.86" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{128},</span><span id="lstnumberx33.87" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.88" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx33.89" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">nf</span><span id="lstnumberx33.90" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx33.91" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.92" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{64,</span><span id="lstnumberx33.93" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx33.94" class="ltx_text ltx_font_typewriter" style="font-size:50%;">128}}</span>
</div>
<div id="lstnumberx34" class="ltx_listingline">
<span id="lstnumberx34.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx34.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx34.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">weight_decay</span><span id="lstnumberx34.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx34.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx34.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1</span><span id="lstnumberx34.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx34.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-05,</span><span id="lstnumberx34.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx34.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">0,</span><span id="lstnumberx34.11" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx34.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1</span><span id="lstnumberx34.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx34.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-06}}</span>
</div>
<div id="lstnumberx35" class="ltx_listingline">
<span id="lstnumberx35.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx35.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx35.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">imagenet_scaling</span><span id="lstnumberx35.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx35.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx35.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx35.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx35.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">}}</span>
</div>
<div id="lstnumberx36" class="ltx_listingline">
</div>
<div id="lstnumberx37" class="ltx_listingline">
</div>
<div id="lstnumberx38" class="ltx_listingline">
<span id="lstnumberx38.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">3</span><span id="lstnumberx38.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">d</span><span id="lstnumberx38.3" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx38.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">film</span><span id="lstnumberx38.5" class="ltx_text ltx_font_typewriter" style="font-size:50%;">,</span><span id="lstnumberx38.6" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx38.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">both</span><span id="lstnumberx38.8" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx38.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">camera</span><span id="lstnumberx38.10" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx38.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">embed</span><span id="lstnumberx38.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">/</span><span id="lstnumberx38.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rotation</span>
</div>
<div id="lstnumberx39" class="ltx_listingline">
<span id="lstnumberx39.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-----------------------------------</span>
</div>
<div id="lstnumberx40" class="ltx_listingline">
</div>
<div id="lstnumberx41" class="ltx_listingline">
<span id="lstnumberx41.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx41.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx41.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_dim</span><span id="lstnumberx41.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{512,</span><span id="lstnumberx41.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1024},</span><span id="lstnumberx41.9" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">rnn_num_layers</span><span id="lstnumberx41.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.13" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{1},</span><span id="lstnumberx41.15" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.16" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_resblocks</span><span id="lstnumberx41.18" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.19" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.20" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{4},</span><span id="lstnumberx41.21" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.22" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">encoder</span><span id="lstnumberx41.24" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.25" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.26" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx41.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">gru</span><span id="lstnumberx41.28" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’},</span><span id="lstnumberx41.29" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.30" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.31" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_coords</span><span id="lstnumberx41.32" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.33" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.34" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx41.35" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx41.36" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx41.37" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.38" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.39" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">coord_shape</span><span id="lstnumberx41.40" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.41" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.42" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{(16,</span><span id="lstnumberx41.43" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.44" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14,</span><span id="lstnumberx41.45" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.46" class="ltx_text ltx_font_typewriter" style="font-size:50%;">14)},</span><span id="lstnumberx41.47" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.48" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.49" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">with_camera</span><span id="lstnumberx41.50" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.51" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.52" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx41.53" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx41.54" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx41.55" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.56" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.57" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">ncf</span><span id="lstnumberx41.58" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.59" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.60" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{64},</span><span id="lstnumberx41.61" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.62" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.63" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">flatten_3d</span><span id="lstnumberx41.64" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.65" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.66" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx41.67" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">False</span><span id="lstnumberx41.68" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx41.69" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.70" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.71" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">is_3d</span><span id="lstnumberx41.72" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.73" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.74" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx41.75" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx41.76" class="ltx_text ltx_font_typewriter" style="font-size:50%;">},</span><span id="lstnumberx41.77" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.78" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.79" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">n_in</span><span id="lstnumberx41.80" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.81" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.82" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{128},</span><span id="lstnumberx41.83" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.84" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’</span><span id="lstnumberx41.85" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">nf</span><span id="lstnumberx41.86" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx41.87" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.88" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{64,</span><span id="lstnumberx41.89" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx41.90" class="ltx_text ltx_font_typewriter" style="font-size:50%;">128}}</span>
</div>
<div id="lstnumberx42" class="ltx_listingline">
<span id="lstnumberx42.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx42.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx42.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">weight_decay</span><span id="lstnumberx42.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx42.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx42.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{0,</span><span id="lstnumberx42.7" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx42.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1</span><span id="lstnumberx42.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx42.10" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-05,</span><span id="lstnumberx42.11" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx42.12" class="ltx_text ltx_font_typewriter" style="font-size:50%;">1</span><span id="lstnumberx42.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">e</span><span id="lstnumberx42.14" class="ltx_text ltx_font_typewriter" style="font-size:50%;">-06}}</span>
</div>
<div id="lstnumberx43" class="ltx_listingline">
<span id="lstnumberx43.1" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;">  </span><span id="lstnumberx43.2" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{’</span><span id="lstnumberx43.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">imagenet_scaling</span><span id="lstnumberx43.4" class="ltx_text ltx_font_typewriter" style="font-size:50%;">’:</span><span id="lstnumberx43.5" class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:50%;"> </span><span id="lstnumberx43.6" class="ltx_text ltx_font_typewriter" style="font-size:50%;">{</span><span id="lstnumberx43.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:50%;">True</span><span id="lstnumberx43.8" class="ltx_text ltx_font_typewriter" style="font-size:50%;">}}</span>
</div>
</div>
</figure>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S5.F10.3.2" class="ltx_text" style="font-size:90%;">The range of hyperparameters explored per experiment in Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (the upper bound canonical baseline and contrastive experiments are not shown here).</span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>MAC baselines</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Code for our MAC baseline was adapted from here<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/rosinality/mac-network-pytorch.git" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/rosinality/mac-network-pytorch.git</a></span></span></span>. In short, a bidirectional LSTM was used here with 12 time steps used for the MAC reasoning step. In order to leverage camera information, we simply concatenated the camera’s embedding to the summary question embedding (not to the contextual word embeddings). For the best performing experiment, self-attention was disabled.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Due to significant time constraints, hyperparameter tuning for this baseline was minimal. However, we can see in Table <a href="#S3.T1" title="Table 1 ‣ 3 Results and Analysis ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> that it obtains similar validation accuracy to the 2D FILM + camera conditioning baseline, and in principle can probably also be adapted to perform 3D reasoning.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Example images from dataset</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">See Figure <a href="#S5.F11" title="Figure 11 ‣ 5.3 Example images from dataset ‣ 5 Supplementary material ‣ Visual Question Answering From Another Perspective: CLEVR Mental Rotation Tests" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<figure id="S5.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_098/CLEVR_train-clevr-kiwi-spatial_s000098_cam14.jpg" id="S5.F11.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_098/CLEVR_train-clevr-kiwi-spatial_s000098_cam15.jpg" id="S5.F11.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_098/CLEVR_train-clevr-kiwi-spatial_s000098_cc.jpg" id="S5.F11.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_098/CLEVR_train-clevr-kiwi-spatial_s000098_cam16.jpg" id="S5.F11.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_098/CLEVR_train-clevr-kiwi-spatial_s000098_cam17.jpg" id="S5.F11.g5" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_900/CLEVR_train-clevr-kiwi-spatial_s000900_cam14.jpg" id="S5.F11.g6" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_900/CLEVR_train-clevr-kiwi-spatial_s000900_cam15.jpg" id="S5.F11.g7" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_900/CLEVR_train-clevr-kiwi-spatial_s000900_cc.jpg" id="S5.F11.g8" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_900/CLEVR_train-clevr-kiwi-spatial_s000900_cam16.jpg" id="S5.F11.g9" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_many"><img src="/html/2212.01639/assets/figures/clevr_kiwi/examples_900/CLEVR_train-clevr-kiwi-spatial_s000900_cam17.jpg" id="S5.F11.g10" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="108" height="81" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S5.F11.3.2" class="ltx_text" style="font-size:90%;">Random views of an example scene in CLEVR-MRT. The center image is the ‘canonical’ view.</span></figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2212.01638" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2212.01639" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2212.01639">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.01639" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2212.01640" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 12:26:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
