<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.12906] Fog enabled distributed training architecture for federated learning</title><meta property="og:description" content="The amount of data being produced at every epoch of second is increasing every moment. Various sensors, cameras and smart gadgets produce continuous data throughout its installation. Processing and analyzing raw data a…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fog enabled distributed training architecture for federated learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Fog enabled distributed training architecture for federated learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.12906">

<!--Generated on Tue Mar  5 16:25:30 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document">Fog enabled distributed training architecture for federated learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aditya Kumar
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Satish Narayana Srirama
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:satish.srirama@uohyd.ac.in">satish.srirama@uohyd.ac.in</a>
</span>
<span class="ltx_contact ltx_role_address">Cloud &amp; Smart Lab, SCIS
<br class="ltx_break">University of Hyderabad
<br class="ltx_break">Telangana, India
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The amount of data being produced at every epoch of second is increasing every moment. Various sensors, cameras and smart gadgets produce continuous data throughout its installation. Processing and analyzing raw data at a cloud server faces several challenges such as bandwidth, congestion, latency, privacy and security. Fog computing brings computational resources closer to IoT that addresses some of these issues. These IoT devices have low computational capability, which is insufficient to train machine learning. Mining hidden patterns and inferential rules from continuously growing data is crucial for various applications. Due to growing privacy concerns, privacy preserving machine learning is another aspect that needs to be inculcated. In this paper, we have proposed a fog enabled distributed training architecture for machine learning tasks using resources constrained devices. The proposed architecture trains machine learning model on rapidly changing data using online learning. The network is inlined with privacy preserving federated learning training. Further, the learning capability of architecture is tested on a real world IIoT use case. We trained a neural network model for human position detection in IIoT setup on rapidly changing data.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Internet of Things , Decentralized Learning , Fog Computing

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With advances in digital technology, Internet of Things (IoT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> devices are prevailing everywhere. Multiple sensors, cameras, mobiles, and smart gadgets are installed to provide support in decision making. As technology progresses, the reliance on such devices is increasing day by day. Deployment of various IoT devices has increased exponentially nowadays. The devices include simple sensors to very sophisticated industrial tools that exchange data/information through the internet. In the past few years, the number of IoT devices has increased rapidly. Currently, there are more than 10 billion IoT devices available worldwide, which is expected to be around 17 billion in 2025 and 26 billion by 2030 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Every standalone device produces data which is shared with other devices for further processing. The IoT devices placed at the edge layer are generally resource constrained. However, devices such as cameras or sensors generate continuous data by sensing the environment. These devices have very crucial information to mine that can be used to achieve a business goal. As the number of devices increases, the velocity and volume of data increases significantly over time. Processing and analysis of continuously generated data from resource constrained remote devices is a challenging task. Training a machine learning(ML)model on such large distributed data can be used to solve real world computational problems.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In the conventional machine learning paradigm, the training is done at the central server/cloud. The data is generated at the edge device, which is sent to the cloud. The cloud stores all data and performs training. The cloud-IoT architecture consumes large bandwidth while transferring raw data to the cloud that also creates network congestion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. The high latency is an issue in the cloud-IoT model that limits it for continuous learning. Additionally, data privacy concern is another major challenge in the data collection at the server. Fog computing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> brings computational resources closer to the edge nodes that can efficiently process the raw data. Various data generating devices closely communicate with the nearest fog node for local computation. A fog node has enough computational capacity to process periodically collected data. The fog node can manoeuvre the associated IoT devices and directly communicates to the central server for further knowledge discovery. The distributed machine learning can be used to learn the hidden patterns from raw data efficiently. Federated learning trains a machine learning model from distributed data without sharing raw data to the server.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Distributed machine learning is a multi-node training paradigm where a participating node trains its model and collaborates with each other or the server for optimization. Federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> training proposed by McMahan et al. is a decentralized machine learning technique that can train an artificial neural network (ANN) without sending and storing raw data at the server. The algorithm trains a global model in collaboration with various devices without sharing data. Every participating device trains a model locally on their local data. The central curator coordinates with all the devices to create a global model. The locally trained model parameters such as weights and biases of ANN are shared with the central server rather than raw data. The server further aggregates model parameters from participating devices and creates a global model. This iterative process continues till the convergence of the model. In the entire training, the raw data is never shared with anyone that makes the system overall privacy preserving. Federated learning is applied to various tasks such as smart city, autonomous driving cars, industrial automation, etc. The data generating IoT devices are resources constrained that cannot train a machine learning model on the edge. Whereas, a fog computing paradigm brings computational efficiency near to IoT devices that can directly participate in federated learning. A fog enabled cloud-IoT model has the potential to quickly process continuous data.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we have proposed an IoT-fog-cloud architecture to train a neural network on continuously generated distributed data. The paper tries to combine fog computing and federated learning for model creation. This addresses online training of continuously generating data using resource constrained devices. The proposed architecture is shown in Fig <a href="#S3.F2" title="Figure 2 ‣ 3.1 Architecture ‣ 3 Decentralized federated learning ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The IoT devices at the edge layer generate continuous data and share it with the fog node. The fog node is capable of online training that trains models in collaboration with the central cloud. The central server applies federated learning with the fog layer. The fog nodes capture periodic data from their associated IoT devices. It performs local model training and communicates with the cloud for global model optimization. The raw data generated at IoT devices are only shared with the local/nearest fog node. The fog layer is equipped with finite computational and storage resources that can process the raw data. The continuous data gets accumulated at fog layer/backup storage, whereas the training is done on a periodic/recent dataset only. Once the data is used for single shot training, it is not used for further training. The data does not leave the premises of fog architecture that makes the system more privacy sensitive. However, the stored data can be used for future references or it can be sent to the server if required by the application in performing long-term big data analytics. We have simulated the proposed architecture to train a neural network for safe position detection in real world Industrial Internet of Things (IIoT) setup using docker. The contributions of the paper are summarized in the following:</p>
</div>
<div id="S1.p5" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Proposed a fog enabled distributed training architecture for machine learning tasks. A hybrid of Fog computing and Federated learning paradigm is used for the model training.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Online continuous training is done with rapidly changing/growing datasets. The training includes only recent periodic data for modelling. The system assures privacy by restricting the raw data to the fog level. In addition, by not sharing raw data directly to the server, the system optimizes network bandwidth and congestion.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We simulated the proposed architecture with Docker container. To test the learning capability of the model, we used radar data to train safe position classification in Human Robot (HR) workspace.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Rest of the paper is organized as follows. Section <a href="#S2" title="2 Related Work ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> discusses existing related articles. The proposed architecture and decentralized machine learning are discussed in <a href="#S3" title="3 Decentralized federated learning ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Experimental setup and numerical results are shown in section <a href="#S4" title="4 Evaluation and results ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Section <a href="#S5" title="5 Conclusions and future work ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> concludes the paper with scope for future work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Data processing and machine learning need huge computational and storage resources to execute a specific task. Multiple IoT devices have generated and continue to generate voluminous data. One of the efficient ways to achieve such a task is to rent a cloud computing facility. With virtually infinite resources, the cloud executes complex model training on big data. The cloud-IoT faces various challenges such as Bandwidth, Latency, Uninterrupted, Resources-constraint and security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. The IoT devices are resource constraint which are connected through a wireless network to the cloud. These shortcomings obstruct smooth execution of the various tasks, specifically the real time processing. Fog computing proposes an alternative to the cloud that brings resources closer to IoT devices. It ensures low latency, network congestion, efficiency, agility and security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. This enabled efficient data processing at the fog layer and opens door to various applications such as smart cars, traffic control, smart buildings, real time security surveillance, smart grid, and many more. The fog layer has sufficiently enough resources to store and process raw data. This gives an advantage over a cloud to processing and decision making locally.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Bonomi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> have discussed about the role of fog computing in IoT and its applications. Fog computing provides localization that acted as a milestone in delay sensitive and real time applications. Data analytics on real time data have various applications based on context. Some of them, such as detection or controlling, need quick response typically in milliseconds or sub seconds, whereas other applications like report generation, global data mining tasks are long term tasks. Fog computing and cloud computing can performs interplay operations to achieve big data solutions. Fog responds to the real time processing task, which can be geographically distributed, and cloud computing proceed with big data analysis or knowledge consolidation. Due to proximity, fog computing is beneficial for delay sensitive applications, but it may lose importance when it gets congested. The number of jobs received at a particular fog node at a specific time may be higher, which cannot be processed quickly due to limited resources. Al-khafajiy et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> have proposed a fog load balancing algorithm to request offloading that can potentially improve network efficiency and minimize latency of the services. The fog nodes communicate with each other to share their load optimally, which improves the quality of services of the network. Similarly, Srirama et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, have studied utilizing fog nodes efficiently with distributed execution frameworks such as Akka, based on Actor programming model. In this context, it is also worth mentioning that scheduling of applications/tasks in cloud and fog has been studied extensively in the last few years, which is summarized in the related work of Hazra et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The Cloud-fog computing paradigm is more efficient, scalable and privacy preserving for machine learning model training. So edge centric computing framework is needed to solve various real time operations. Munusamy et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> have designed a blockchain-enabled edge centric framework to analyze the real time data in Maritime transportation systems. The framework ensures security and privacy of the network and exhibits low latency and power consumption. Distributed machine learning training offers parallel data processing over the edge of the network. Kamath et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> propose a decentralized stochastic gradient descent method to learn linear regression on the edge of the network. The work utilizes distributed environment to train regression model using SGD. The method process data at device level and avoids sending it to the cloud. Federated learning is another decentralized ML technique that trains models using very large set of low resourced participating devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The proposed federated method collaborates with various participating devices to create a global ML model on decentralized data. Federated learning is done on low constraint devices that need efficient training strategies for uplink and down ink communication. Konečný et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, talks about efficient communication between cloud and devices. The authors have suggested sketched and structured updates for server communication that reduce the amount of data sent to the server.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The fog-cloud architecture is well suited for distributed machine learning training. Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> have used cloud-fog architecture for secure and privacy preserving distributed deep learning training. The local training is given at the fog layer then it coordinates with the cloud server for aggregation. Additionally, it uses encrypted parameters and authentication of valid fog node to ensure legit updates. The central node works like a master node for information consolidation. It synchronizes the training from various devices. Due to stragglers or mobility of devices such as vehicles, drone the synchronous update creates difficulty in training. Lu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> proposes asynchronous federated training for mobile edge computing. The training is done similar to federated learning, but global model aggregation is done asynchronously. To ensure the privacy and security of the shared model, it adds adds noise to the parameters before sending it to the server. Luo et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> have proposed a hierarchical federated edge learning framework to train low latency and energy-efficient federated learning. The framework introduces a middle layer that partially offloads cloud computational work. The proposed 3-layered framework aggregates model parameters at both fog layer and cloud layer while training is done at the remote device. Fog enabled federated learning can facilitate distributed learning for delay-sensitive applications. Saha et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> proposed fog assisted federated learning architecture for delay-sensitive applications. The federated learning is done between edge and fog layer, then the central node heuristically steps in for global model aggregation. This training is done on geographically distributed network that optimizes communication latency by 92% and energy consumption by 85%. Most of the research assumes that data generating IoT devices contain enough computational resources to train ML models. Additionally, these IoT devices participate in distributed training with the complete dataset. Our proposed architecture is a three layered network for machine learning training. The edge layer generates raw data only, and the cloud layer consolidates the global model. Whereas, the fog layer participates in decentralized machine learning training with the central server. The federated training is done on continuously changing dataset generated by the edge layer.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Decentralized federated learning</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.13" class="ltx_p">Decentralized federated learning aggregates locally trained models on the central server. A global model is created by combining multiple independently trained models. The conventional machine learning approaches collect possible data <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">D</annotation></semantics></math> to the server; then it learns a machine learning model <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">M</annotation></semantics></math> using a sophisticated algorithm. In contrast, federated learning trains its model without collecting all possible data to the central server. It is a collaborative learning paradigm where <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p1.3.m3.1a"><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">k</annotation></semantics></math> number of participating devices trains a local model on their data <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p1.4.m4.1a"><msub id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml"><mi id="S3.p1.4.m4.1.1.2" xref="S3.p1.4.m4.1.1.2.cmml">D</mi><mi id="S3.p1.4.m4.1.1.3" xref="S3.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><apply id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p1.4.m4.1.1.1.cmml" xref="S3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.p1.4.m4.1.1.2.cmml" xref="S3.p1.4.m4.1.1.2">𝐷</ci><ci id="S3.p1.4.m4.1.1.3.cmml" xref="S3.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">D_{i}</annotation></semantics></math>. Each participating device i contains their personal data <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p1.5.m5.1a"><msub id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml"><mi id="S3.p1.5.m5.1.1.2" xref="S3.p1.5.m5.1.1.2.cmml">D</mi><mi id="S3.p1.5.m5.1.1.3" xref="S3.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><apply id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p1.5.m5.1.1.1.cmml" xref="S3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.p1.5.m5.1.1.2.cmml" xref="S3.p1.5.m5.1.1.2">𝐷</ci><ci id="S3.p1.5.m5.1.1.3.cmml" xref="S3.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">D_{i}</annotation></semantics></math>. The total data set is <math id="S3.p1.6.m6.1" class="ltx_Math" alttext="D=\sum\limits_{i=1}^{k}D_{i}" display="inline"><semantics id="S3.p1.6.m6.1a"><mrow id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml"><mi id="S3.p1.6.m6.1.1.2" xref="S3.p1.6.m6.1.1.2.cmml">D</mi><mo rspace="0.111em" id="S3.p1.6.m6.1.1.1" xref="S3.p1.6.m6.1.1.1.cmml">=</mo><mrow id="S3.p1.6.m6.1.1.3" xref="S3.p1.6.m6.1.1.3.cmml"><munderover id="S3.p1.6.m6.1.1.3.1" xref="S3.p1.6.m6.1.1.3.1.cmml"><mo movablelimits="false" id="S3.p1.6.m6.1.1.3.1.2.2" xref="S3.p1.6.m6.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.p1.6.m6.1.1.3.1.2.3" xref="S3.p1.6.m6.1.1.3.1.2.3.cmml"><mi id="S3.p1.6.m6.1.1.3.1.2.3.2" xref="S3.p1.6.m6.1.1.3.1.2.3.2.cmml">i</mi><mo id="S3.p1.6.m6.1.1.3.1.2.3.1" xref="S3.p1.6.m6.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.p1.6.m6.1.1.3.1.2.3.3" xref="S3.p1.6.m6.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.p1.6.m6.1.1.3.1.3" xref="S3.p1.6.m6.1.1.3.1.3.cmml">k</mi></munderover><msub id="S3.p1.6.m6.1.1.3.2" xref="S3.p1.6.m6.1.1.3.2.cmml"><mi id="S3.p1.6.m6.1.1.3.2.2" xref="S3.p1.6.m6.1.1.3.2.2.cmml">D</mi><mi id="S3.p1.6.m6.1.1.3.2.3" xref="S3.p1.6.m6.1.1.3.2.3.cmml">i</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><apply id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1"><eq id="S3.p1.6.m6.1.1.1.cmml" xref="S3.p1.6.m6.1.1.1"></eq><ci id="S3.p1.6.m6.1.1.2.cmml" xref="S3.p1.6.m6.1.1.2">𝐷</ci><apply id="S3.p1.6.m6.1.1.3.cmml" xref="S3.p1.6.m6.1.1.3"><apply id="S3.p1.6.m6.1.1.3.1.cmml" xref="S3.p1.6.m6.1.1.3.1"><csymbol cd="ambiguous" id="S3.p1.6.m6.1.1.3.1.1.cmml" xref="S3.p1.6.m6.1.1.3.1">superscript</csymbol><apply id="S3.p1.6.m6.1.1.3.1.2.cmml" xref="S3.p1.6.m6.1.1.3.1"><csymbol cd="ambiguous" id="S3.p1.6.m6.1.1.3.1.2.1.cmml" xref="S3.p1.6.m6.1.1.3.1">subscript</csymbol><sum id="S3.p1.6.m6.1.1.3.1.2.2.cmml" xref="S3.p1.6.m6.1.1.3.1.2.2"></sum><apply id="S3.p1.6.m6.1.1.3.1.2.3.cmml" xref="S3.p1.6.m6.1.1.3.1.2.3"><eq id="S3.p1.6.m6.1.1.3.1.2.3.1.cmml" xref="S3.p1.6.m6.1.1.3.1.2.3.1"></eq><ci id="S3.p1.6.m6.1.1.3.1.2.3.2.cmml" xref="S3.p1.6.m6.1.1.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.p1.6.m6.1.1.3.1.2.3.3.cmml" xref="S3.p1.6.m6.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.p1.6.m6.1.1.3.1.3.cmml" xref="S3.p1.6.m6.1.1.3.1.3">𝑘</ci></apply><apply id="S3.p1.6.m6.1.1.3.2.cmml" xref="S3.p1.6.m6.1.1.3.2"><csymbol cd="ambiguous" id="S3.p1.6.m6.1.1.3.2.1.cmml" xref="S3.p1.6.m6.1.1.3.2">subscript</csymbol><ci id="S3.p1.6.m6.1.1.3.2.2.cmml" xref="S3.p1.6.m6.1.1.3.2.2">𝐷</ci><ci id="S3.p1.6.m6.1.1.3.2.3.cmml" xref="S3.p1.6.m6.1.1.3.2.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">D=\sum\limits_{i=1}^{k}D_{i}</annotation></semantics></math>. Here, <math id="S3.p1.7.m7.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p1.7.m7.1a"><msub id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml"><mi id="S3.p1.7.m7.1.1.2" xref="S3.p1.7.m7.1.1.2.cmml">D</mi><mi id="S3.p1.7.m7.1.1.3" xref="S3.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><apply id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.p1.7.m7.1.1.1.cmml" xref="S3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.p1.7.m7.1.1.2.cmml" xref="S3.p1.7.m7.1.1.2">𝐷</ci><ci id="S3.p1.7.m7.1.1.3.cmml" xref="S3.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">D_{i}</annotation></semantics></math> is a collection of input data samples <math id="S3.p1.8.m8.2" class="ltx_Math" alttext="(x_{j},y_{j})_{j=1}^{n}" display="inline"><semantics id="S3.p1.8.m8.2a"><msubsup id="S3.p1.8.m8.2.2" xref="S3.p1.8.m8.2.2.cmml"><mrow id="S3.p1.8.m8.2.2.2.2.2" xref="S3.p1.8.m8.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.p1.8.m8.2.2.2.2.2.3" xref="S3.p1.8.m8.2.2.2.2.3.cmml">(</mo><msub id="S3.p1.8.m8.1.1.1.1.1.1" xref="S3.p1.8.m8.1.1.1.1.1.1.cmml"><mi id="S3.p1.8.m8.1.1.1.1.1.1.2" xref="S3.p1.8.m8.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.p1.8.m8.1.1.1.1.1.1.3" xref="S3.p1.8.m8.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.p1.8.m8.2.2.2.2.2.4" xref="S3.p1.8.m8.2.2.2.2.3.cmml">,</mo><msub id="S3.p1.8.m8.2.2.2.2.2.2" xref="S3.p1.8.m8.2.2.2.2.2.2.cmml"><mi id="S3.p1.8.m8.2.2.2.2.2.2.2" xref="S3.p1.8.m8.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.p1.8.m8.2.2.2.2.2.2.3" xref="S3.p1.8.m8.2.2.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.p1.8.m8.2.2.2.2.2.5" xref="S3.p1.8.m8.2.2.2.2.3.cmml">)</mo></mrow><mrow id="S3.p1.8.m8.2.2.2.4" xref="S3.p1.8.m8.2.2.2.4.cmml"><mi id="S3.p1.8.m8.2.2.2.4.2" xref="S3.p1.8.m8.2.2.2.4.2.cmml">j</mi><mo id="S3.p1.8.m8.2.2.2.4.1" xref="S3.p1.8.m8.2.2.2.4.1.cmml">=</mo><mn id="S3.p1.8.m8.2.2.2.4.3" xref="S3.p1.8.m8.2.2.2.4.3.cmml">1</mn></mrow><mi id="S3.p1.8.m8.2.2.4" xref="S3.p1.8.m8.2.2.4.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.2b"><apply id="S3.p1.8.m8.2.2.cmml" xref="S3.p1.8.m8.2.2"><csymbol cd="ambiguous" id="S3.p1.8.m8.2.2.3.cmml" xref="S3.p1.8.m8.2.2">superscript</csymbol><apply id="S3.p1.8.m8.2.2.2.cmml" xref="S3.p1.8.m8.2.2"><csymbol cd="ambiguous" id="S3.p1.8.m8.2.2.2.3.cmml" xref="S3.p1.8.m8.2.2">subscript</csymbol><interval closure="open" id="S3.p1.8.m8.2.2.2.2.3.cmml" xref="S3.p1.8.m8.2.2.2.2.2"><apply id="S3.p1.8.m8.1.1.1.1.1.1.cmml" xref="S3.p1.8.m8.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.8.m8.1.1.1.1.1.1.1.cmml" xref="S3.p1.8.m8.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.8.m8.1.1.1.1.1.1.2.cmml" xref="S3.p1.8.m8.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.p1.8.m8.1.1.1.1.1.1.3.cmml" xref="S3.p1.8.m8.1.1.1.1.1.1.3">𝑗</ci></apply><apply id="S3.p1.8.m8.2.2.2.2.2.2.cmml" xref="S3.p1.8.m8.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p1.8.m8.2.2.2.2.2.2.1.cmml" xref="S3.p1.8.m8.2.2.2.2.2.2">subscript</csymbol><ci id="S3.p1.8.m8.2.2.2.2.2.2.2.cmml" xref="S3.p1.8.m8.2.2.2.2.2.2.2">𝑦</ci><ci id="S3.p1.8.m8.2.2.2.2.2.2.3.cmml" xref="S3.p1.8.m8.2.2.2.2.2.2.3">𝑗</ci></apply></interval><apply id="S3.p1.8.m8.2.2.2.4.cmml" xref="S3.p1.8.m8.2.2.2.4"><eq id="S3.p1.8.m8.2.2.2.4.1.cmml" xref="S3.p1.8.m8.2.2.2.4.1"></eq><ci id="S3.p1.8.m8.2.2.2.4.2.cmml" xref="S3.p1.8.m8.2.2.2.4.2">𝑗</ci><cn type="integer" id="S3.p1.8.m8.2.2.2.4.3.cmml" xref="S3.p1.8.m8.2.2.2.4.3">1</cn></apply></apply><ci id="S3.p1.8.m8.2.2.4.cmml" xref="S3.p1.8.m8.2.2.4">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.2c">(x_{j},y_{j})_{j=1}^{n}</annotation></semantics></math> for supervised learning. Where <math id="S3.p1.9.m9.1" class="ltx_Math" alttext="x_{j}\in\mathbb{R}^{d}" display="inline"><semantics id="S3.p1.9.m9.1a"><mrow id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml"><msub id="S3.p1.9.m9.1.1.2" xref="S3.p1.9.m9.1.1.2.cmml"><mi id="S3.p1.9.m9.1.1.2.2" xref="S3.p1.9.m9.1.1.2.2.cmml">x</mi><mi id="S3.p1.9.m9.1.1.2.3" xref="S3.p1.9.m9.1.1.2.3.cmml">j</mi></msub><mo id="S3.p1.9.m9.1.1.1" xref="S3.p1.9.m9.1.1.1.cmml">∈</mo><msup id="S3.p1.9.m9.1.1.3" xref="S3.p1.9.m9.1.1.3.cmml"><mi id="S3.p1.9.m9.1.1.3.2" xref="S3.p1.9.m9.1.1.3.2.cmml">ℝ</mi><mi id="S3.p1.9.m9.1.1.3.3" xref="S3.p1.9.m9.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><apply id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1"><in id="S3.p1.9.m9.1.1.1.cmml" xref="S3.p1.9.m9.1.1.1"></in><apply id="S3.p1.9.m9.1.1.2.cmml" xref="S3.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.2.1.cmml" xref="S3.p1.9.m9.1.1.2">subscript</csymbol><ci id="S3.p1.9.m9.1.1.2.2.cmml" xref="S3.p1.9.m9.1.1.2.2">𝑥</ci><ci id="S3.p1.9.m9.1.1.2.3.cmml" xref="S3.p1.9.m9.1.1.2.3">𝑗</ci></apply><apply id="S3.p1.9.m9.1.1.3.cmml" xref="S3.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.3.1.cmml" xref="S3.p1.9.m9.1.1.3">superscript</csymbol><ci id="S3.p1.9.m9.1.1.3.2.cmml" xref="S3.p1.9.m9.1.1.3.2">ℝ</ci><ci id="S3.p1.9.m9.1.1.3.3.cmml" xref="S3.p1.9.m9.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">x_{j}\in\mathbb{R}^{d}</annotation></semantics></math> is a <math id="S3.p1.10.m10.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.p1.10.m10.1a"><mi id="S3.p1.10.m10.1.1" xref="S3.p1.10.m10.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.1b"><ci id="S3.p1.10.m10.1.1.cmml" xref="S3.p1.10.m10.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.1c">d</annotation></semantics></math> dimensional input data and <math id="S3.p1.11.m11.1" class="ltx_Math" alttext="y_{j}\in\mathbb{R}" display="inline"><semantics id="S3.p1.11.m11.1a"><mrow id="S3.p1.11.m11.1.1" xref="S3.p1.11.m11.1.1.cmml"><msub id="S3.p1.11.m11.1.1.2" xref="S3.p1.11.m11.1.1.2.cmml"><mi id="S3.p1.11.m11.1.1.2.2" xref="S3.p1.11.m11.1.1.2.2.cmml">y</mi><mi id="S3.p1.11.m11.1.1.2.3" xref="S3.p1.11.m11.1.1.2.3.cmml">j</mi></msub><mo id="S3.p1.11.m11.1.1.1" xref="S3.p1.11.m11.1.1.1.cmml">∈</mo><mi id="S3.p1.11.m11.1.1.3" xref="S3.p1.11.m11.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.11.m11.1b"><apply id="S3.p1.11.m11.1.1.cmml" xref="S3.p1.11.m11.1.1"><in id="S3.p1.11.m11.1.1.1.cmml" xref="S3.p1.11.m11.1.1.1"></in><apply id="S3.p1.11.m11.1.1.2.cmml" xref="S3.p1.11.m11.1.1.2"><csymbol cd="ambiguous" id="S3.p1.11.m11.1.1.2.1.cmml" xref="S3.p1.11.m11.1.1.2">subscript</csymbol><ci id="S3.p1.11.m11.1.1.2.2.cmml" xref="S3.p1.11.m11.1.1.2.2">𝑦</ci><ci id="S3.p1.11.m11.1.1.2.3.cmml" xref="S3.p1.11.m11.1.1.2.3">𝑗</ci></apply><ci id="S3.p1.11.m11.1.1.3.cmml" xref="S3.p1.11.m11.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.11.m11.1c">y_{j}\in\mathbb{R}</annotation></semantics></math> is the associated label for input <math id="S3.p1.12.m12.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S3.p1.12.m12.1a"><msub id="S3.p1.12.m12.1.1" xref="S3.p1.12.m12.1.1.cmml"><mi id="S3.p1.12.m12.1.1.2" xref="S3.p1.12.m12.1.1.2.cmml">x</mi><mi id="S3.p1.12.m12.1.1.3" xref="S3.p1.12.m12.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.12.m12.1b"><apply id="S3.p1.12.m12.1.1.cmml" xref="S3.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S3.p1.12.m12.1.1.1.cmml" xref="S3.p1.12.m12.1.1">subscript</csymbol><ci id="S3.p1.12.m12.1.1.2.cmml" xref="S3.p1.12.m12.1.1.2">𝑥</ci><ci id="S3.p1.12.m12.1.1.3.cmml" xref="S3.p1.12.m12.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.12.m12.1c">x_{j}</annotation></semantics></math>. The device data <math id="S3.p1.13.m13.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p1.13.m13.1a"><msub id="S3.p1.13.m13.1.1" xref="S3.p1.13.m13.1.1.cmml"><mi id="S3.p1.13.m13.1.1.2" xref="S3.p1.13.m13.1.1.2.cmml">D</mi><mi id="S3.p1.13.m13.1.1.3" xref="S3.p1.13.m13.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.13.m13.1b"><apply id="S3.p1.13.m13.1.1.cmml" xref="S3.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.p1.13.m13.1.1.1.cmml" xref="S3.p1.13.m13.1.1">subscript</csymbol><ci id="S3.p1.13.m13.1.1.2.cmml" xref="S3.p1.13.m13.1.1.2">𝐷</ci><ci id="S3.p1.13.m13.1.1.3.cmml" xref="S3.p1.13.m13.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.13.m13.1c">D_{i}</annotation></semantics></math> are remotely generated or centrally distributed.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2402.12906/assets/fig/learning.jpg" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="442" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;"> Decentralized federated learning training paradigm </span></figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.12" class="ltx_p">For every participating device, it is a machine learning task where it trains local model parameters using its data <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p2.1.m1.1a"><msub id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">D</mi><mi id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">𝐷</ci><ci id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">D_{i}</annotation></semantics></math>. It takes input data <math id="S3.p2.2.m2.2" class="ltx_Math" alttext="(x_{j},y_{j})_{j=1}^{n}" display="inline"><semantics id="S3.p2.2.m2.2a"><msubsup id="S3.p2.2.m2.2.2" xref="S3.p2.2.m2.2.2.cmml"><mrow id="S3.p2.2.m2.2.2.2.2.2" xref="S3.p2.2.m2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.p2.2.m2.2.2.2.2.2.3" xref="S3.p2.2.m2.2.2.2.2.3.cmml">(</mo><msub id="S3.p2.2.m2.1.1.1.1.1.1" xref="S3.p2.2.m2.1.1.1.1.1.1.cmml"><mi id="S3.p2.2.m2.1.1.1.1.1.1.2" xref="S3.p2.2.m2.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.p2.2.m2.1.1.1.1.1.1.3" xref="S3.p2.2.m2.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.p2.2.m2.2.2.2.2.2.4" xref="S3.p2.2.m2.2.2.2.2.3.cmml">,</mo><msub id="S3.p2.2.m2.2.2.2.2.2.2" xref="S3.p2.2.m2.2.2.2.2.2.2.cmml"><mi id="S3.p2.2.m2.2.2.2.2.2.2.2" xref="S3.p2.2.m2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.p2.2.m2.2.2.2.2.2.2.3" xref="S3.p2.2.m2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.p2.2.m2.2.2.2.2.2.5" xref="S3.p2.2.m2.2.2.2.2.3.cmml">)</mo></mrow><mrow id="S3.p2.2.m2.2.2.2.4" xref="S3.p2.2.m2.2.2.2.4.cmml"><mi id="S3.p2.2.m2.2.2.2.4.2" xref="S3.p2.2.m2.2.2.2.4.2.cmml">j</mi><mo id="S3.p2.2.m2.2.2.2.4.1" xref="S3.p2.2.m2.2.2.2.4.1.cmml">=</mo><mn id="S3.p2.2.m2.2.2.2.4.3" xref="S3.p2.2.m2.2.2.2.4.3.cmml">1</mn></mrow><mi id="S3.p2.2.m2.2.2.4" xref="S3.p2.2.m2.2.2.4.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.2b"><apply id="S3.p2.2.m2.2.2.cmml" xref="S3.p2.2.m2.2.2"><csymbol cd="ambiguous" id="S3.p2.2.m2.2.2.3.cmml" xref="S3.p2.2.m2.2.2">superscript</csymbol><apply id="S3.p2.2.m2.2.2.2.cmml" xref="S3.p2.2.m2.2.2"><csymbol cd="ambiguous" id="S3.p2.2.m2.2.2.2.3.cmml" xref="S3.p2.2.m2.2.2">subscript</csymbol><interval closure="open" id="S3.p2.2.m2.2.2.2.2.3.cmml" xref="S3.p2.2.m2.2.2.2.2.2"><apply id="S3.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.p2.2.m2.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.p2.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.p2.2.m2.1.1.1.1.1.1.3">𝑗</ci></apply><apply id="S3.p2.2.m2.2.2.2.2.2.2.cmml" xref="S3.p2.2.m2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p2.2.m2.2.2.2.2.2.2.1.cmml" xref="S3.p2.2.m2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.p2.2.m2.2.2.2.2.2.2.2.cmml" xref="S3.p2.2.m2.2.2.2.2.2.2.2">𝑦</ci><ci id="S3.p2.2.m2.2.2.2.2.2.2.3.cmml" xref="S3.p2.2.m2.2.2.2.2.2.2.3">𝑗</ci></apply></interval><apply id="S3.p2.2.m2.2.2.2.4.cmml" xref="S3.p2.2.m2.2.2.2.4"><eq id="S3.p2.2.m2.2.2.2.4.1.cmml" xref="S3.p2.2.m2.2.2.2.4.1"></eq><ci id="S3.p2.2.m2.2.2.2.4.2.cmml" xref="S3.p2.2.m2.2.2.2.4.2">𝑗</ci><cn type="integer" id="S3.p2.2.m2.2.2.2.4.3.cmml" xref="S3.p2.2.m2.2.2.2.4.3">1</cn></apply></apply><ci id="S3.p2.2.m2.2.2.4.cmml" xref="S3.p2.2.m2.2.2.4">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.2c">(x_{j},y_{j})_{j=1}^{n}</annotation></semantics></math> to compute local parameters i.e. weights and biases. The loss function of every devices <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.p2.3.m3.1a"><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">i</annotation></semantics></math> for dataset <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p2.4.m4.1a"><msub id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mi id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml">D</mi><mi id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2">𝐷</ci><ci id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">D_{i}</annotation></semantics></math> is <math id="S3.p2.5.m5.5" class="ltx_Math" alttext="F_{i}(w)=\frac{1}{|D_{i}|}\sum\limits_{j=1}^{n}f(h(w,x_{j}),y_{j})" display="inline"><semantics id="S3.p2.5.m5.5a"><mrow id="S3.p2.5.m5.5.5" xref="S3.p2.5.m5.5.5.cmml"><mrow id="S3.p2.5.m5.5.5.4" xref="S3.p2.5.m5.5.5.4.cmml"><msub id="S3.p2.5.m5.5.5.4.2" xref="S3.p2.5.m5.5.5.4.2.cmml"><mi id="S3.p2.5.m5.5.5.4.2.2" xref="S3.p2.5.m5.5.5.4.2.2.cmml">F</mi><mi id="S3.p2.5.m5.5.5.4.2.3" xref="S3.p2.5.m5.5.5.4.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.p2.5.m5.5.5.4.1" xref="S3.p2.5.m5.5.5.4.1.cmml">​</mo><mrow id="S3.p2.5.m5.5.5.4.3.2" xref="S3.p2.5.m5.5.5.4.cmml"><mo stretchy="false" id="S3.p2.5.m5.5.5.4.3.2.1" xref="S3.p2.5.m5.5.5.4.cmml">(</mo><mi id="S3.p2.5.m5.2.2" xref="S3.p2.5.m5.2.2.cmml">w</mi><mo stretchy="false" id="S3.p2.5.m5.5.5.4.3.2.2" xref="S3.p2.5.m5.5.5.4.cmml">)</mo></mrow></mrow><mo id="S3.p2.5.m5.5.5.3" xref="S3.p2.5.m5.5.5.3.cmml">=</mo><mrow id="S3.p2.5.m5.5.5.2" xref="S3.p2.5.m5.5.5.2.cmml"><mfrac id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><mn id="S3.p2.5.m5.1.1.3" xref="S3.p2.5.m5.1.1.3.cmml">1</mn><mrow id="S3.p2.5.m5.1.1.1.1" xref="S3.p2.5.m5.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.5.m5.1.1.1.1.2" xref="S3.p2.5.m5.1.1.1.2.1.cmml">|</mo><msub id="S3.p2.5.m5.1.1.1.1.1" xref="S3.p2.5.m5.1.1.1.1.1.cmml"><mi id="S3.p2.5.m5.1.1.1.1.1.2" xref="S3.p2.5.m5.1.1.1.1.1.2.cmml">D</mi><mi id="S3.p2.5.m5.1.1.1.1.1.3" xref="S3.p2.5.m5.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.p2.5.m5.1.1.1.1.3" xref="S3.p2.5.m5.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.p2.5.m5.5.5.2.3" xref="S3.p2.5.m5.5.5.2.3.cmml">​</mo><mrow id="S3.p2.5.m5.5.5.2.2" xref="S3.p2.5.m5.5.5.2.2.cmml"><munderover id="S3.p2.5.m5.5.5.2.2.3" xref="S3.p2.5.m5.5.5.2.2.3.cmml"><mo movablelimits="false" id="S3.p2.5.m5.5.5.2.2.3.2.2" xref="S3.p2.5.m5.5.5.2.2.3.2.2.cmml">∑</mo><mrow id="S3.p2.5.m5.5.5.2.2.3.2.3" xref="S3.p2.5.m5.5.5.2.2.3.2.3.cmml"><mi id="S3.p2.5.m5.5.5.2.2.3.2.3.2" xref="S3.p2.5.m5.5.5.2.2.3.2.3.2.cmml">j</mi><mo id="S3.p2.5.m5.5.5.2.2.3.2.3.1" xref="S3.p2.5.m5.5.5.2.2.3.2.3.1.cmml">=</mo><mn id="S3.p2.5.m5.5.5.2.2.3.2.3.3" xref="S3.p2.5.m5.5.5.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.p2.5.m5.5.5.2.2.3.3" xref="S3.p2.5.m5.5.5.2.2.3.3.cmml">n</mi></munderover><mrow id="S3.p2.5.m5.5.5.2.2.2" xref="S3.p2.5.m5.5.5.2.2.2.cmml"><mi id="S3.p2.5.m5.5.5.2.2.2.4" xref="S3.p2.5.m5.5.5.2.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.p2.5.m5.5.5.2.2.2.3" xref="S3.p2.5.m5.5.5.2.2.2.3.cmml">​</mo><mrow id="S3.p2.5.m5.5.5.2.2.2.2.2" xref="S3.p2.5.m5.5.5.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.p2.5.m5.5.5.2.2.2.2.2.3" xref="S3.p2.5.m5.5.5.2.2.2.2.3.cmml">(</mo><mrow id="S3.p2.5.m5.4.4.1.1.1.1.1.1" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.cmml"><mi id="S3.p2.5.m5.4.4.1.1.1.1.1.1.3" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.p2.5.m5.4.4.1.1.1.1.1.1.2" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.2" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.p2.5.m5.3.3" xref="S3.p2.5.m5.3.3.cmml">w</mi><mo id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.3" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.2" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.3" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.4" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.p2.5.m5.5.5.2.2.2.2.2.4" xref="S3.p2.5.m5.5.5.2.2.2.2.3.cmml">,</mo><msub id="S3.p2.5.m5.5.5.2.2.2.2.2.2" xref="S3.p2.5.m5.5.5.2.2.2.2.2.2.cmml"><mi id="S3.p2.5.m5.5.5.2.2.2.2.2.2.2" xref="S3.p2.5.m5.5.5.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.p2.5.m5.5.5.2.2.2.2.2.2.3" xref="S3.p2.5.m5.5.5.2.2.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.p2.5.m5.5.5.2.2.2.2.2.5" xref="S3.p2.5.m5.5.5.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.5b"><apply id="S3.p2.5.m5.5.5.cmml" xref="S3.p2.5.m5.5.5"><eq id="S3.p2.5.m5.5.5.3.cmml" xref="S3.p2.5.m5.5.5.3"></eq><apply id="S3.p2.5.m5.5.5.4.cmml" xref="S3.p2.5.m5.5.5.4"><times id="S3.p2.5.m5.5.5.4.1.cmml" xref="S3.p2.5.m5.5.5.4.1"></times><apply id="S3.p2.5.m5.5.5.4.2.cmml" xref="S3.p2.5.m5.5.5.4.2"><csymbol cd="ambiguous" id="S3.p2.5.m5.5.5.4.2.1.cmml" xref="S3.p2.5.m5.5.5.4.2">subscript</csymbol><ci id="S3.p2.5.m5.5.5.4.2.2.cmml" xref="S3.p2.5.m5.5.5.4.2.2">𝐹</ci><ci id="S3.p2.5.m5.5.5.4.2.3.cmml" xref="S3.p2.5.m5.5.5.4.2.3">𝑖</ci></apply><ci id="S3.p2.5.m5.2.2.cmml" xref="S3.p2.5.m5.2.2">𝑤</ci></apply><apply id="S3.p2.5.m5.5.5.2.cmml" xref="S3.p2.5.m5.5.5.2"><times id="S3.p2.5.m5.5.5.2.3.cmml" xref="S3.p2.5.m5.5.5.2.3"></times><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><divide id="S3.p2.5.m5.1.1.2.cmml" xref="S3.p2.5.m5.1.1"></divide><cn type="integer" id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3">1</cn><apply id="S3.p2.5.m5.1.1.1.2.cmml" xref="S3.p2.5.m5.1.1.1.1"><abs id="S3.p2.5.m5.1.1.1.2.1.cmml" xref="S3.p2.5.m5.1.1.1.1.2"></abs><apply id="S3.p2.5.m5.1.1.1.1.1.cmml" xref="S3.p2.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.5.m5.1.1.1.1.1.2.cmml" xref="S3.p2.5.m5.1.1.1.1.1.2">𝐷</ci><ci id="S3.p2.5.m5.1.1.1.1.1.3.cmml" xref="S3.p2.5.m5.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="S3.p2.5.m5.5.5.2.2.cmml" xref="S3.p2.5.m5.5.5.2.2"><apply id="S3.p2.5.m5.5.5.2.2.3.cmml" xref="S3.p2.5.m5.5.5.2.2.3"><csymbol cd="ambiguous" id="S3.p2.5.m5.5.5.2.2.3.1.cmml" xref="S3.p2.5.m5.5.5.2.2.3">superscript</csymbol><apply id="S3.p2.5.m5.5.5.2.2.3.2.cmml" xref="S3.p2.5.m5.5.5.2.2.3"><csymbol cd="ambiguous" id="S3.p2.5.m5.5.5.2.2.3.2.1.cmml" xref="S3.p2.5.m5.5.5.2.2.3">subscript</csymbol><sum id="S3.p2.5.m5.5.5.2.2.3.2.2.cmml" xref="S3.p2.5.m5.5.5.2.2.3.2.2"></sum><apply id="S3.p2.5.m5.5.5.2.2.3.2.3.cmml" xref="S3.p2.5.m5.5.5.2.2.3.2.3"><eq id="S3.p2.5.m5.5.5.2.2.3.2.3.1.cmml" xref="S3.p2.5.m5.5.5.2.2.3.2.3.1"></eq><ci id="S3.p2.5.m5.5.5.2.2.3.2.3.2.cmml" xref="S3.p2.5.m5.5.5.2.2.3.2.3.2">𝑗</ci><cn type="integer" id="S3.p2.5.m5.5.5.2.2.3.2.3.3.cmml" xref="S3.p2.5.m5.5.5.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.p2.5.m5.5.5.2.2.3.3.cmml" xref="S3.p2.5.m5.5.5.2.2.3.3">𝑛</ci></apply><apply id="S3.p2.5.m5.5.5.2.2.2.cmml" xref="S3.p2.5.m5.5.5.2.2.2"><times id="S3.p2.5.m5.5.5.2.2.2.3.cmml" xref="S3.p2.5.m5.5.5.2.2.2.3"></times><ci id="S3.p2.5.m5.5.5.2.2.2.4.cmml" xref="S3.p2.5.m5.5.5.2.2.2.4">𝑓</ci><interval closure="open" id="S3.p2.5.m5.5.5.2.2.2.2.3.cmml" xref="S3.p2.5.m5.5.5.2.2.2.2.2"><apply id="S3.p2.5.m5.4.4.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1"><times id="S3.p2.5.m5.4.4.1.1.1.1.1.1.2.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.2"></times><ci id="S3.p2.5.m5.4.4.1.1.1.1.1.1.3.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.3">ℎ</ci><interval closure="open" id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1"><ci id="S3.p2.5.m5.3.3.cmml" xref="S3.p2.5.m5.3.3">𝑤</ci><apply id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.5.m5.4.4.1.1.1.1.1.1.1.1.1.3">𝑗</ci></apply></interval></apply><apply id="S3.p2.5.m5.5.5.2.2.2.2.2.2.cmml" xref="S3.p2.5.m5.5.5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p2.5.m5.5.5.2.2.2.2.2.2.1.cmml" xref="S3.p2.5.m5.5.5.2.2.2.2.2.2">subscript</csymbol><ci id="S3.p2.5.m5.5.5.2.2.2.2.2.2.2.cmml" xref="S3.p2.5.m5.5.5.2.2.2.2.2.2.2">𝑦</ci><ci id="S3.p2.5.m5.5.5.2.2.2.2.2.2.3.cmml" xref="S3.p2.5.m5.5.5.2.2.2.2.2.2.3">𝑗</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.5c">F_{i}(w)=\frac{1}{|D_{i}|}\sum\limits_{j=1}^{n}f(h(w,x_{j}),y_{j})</annotation></semantics></math>. Where <math id="S3.p2.6.m6.3" class="ltx_Math" alttext="f(h(w,x_{j}),y_{j})" display="inline"><semantics id="S3.p2.6.m6.3a"><mrow id="S3.p2.6.m6.3.3" xref="S3.p2.6.m6.3.3.cmml"><mi id="S3.p2.6.m6.3.3.4" xref="S3.p2.6.m6.3.3.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.p2.6.m6.3.3.3" xref="S3.p2.6.m6.3.3.3.cmml">​</mo><mrow id="S3.p2.6.m6.3.3.2.2" xref="S3.p2.6.m6.3.3.2.3.cmml"><mo stretchy="false" id="S3.p2.6.m6.3.3.2.2.3" xref="S3.p2.6.m6.3.3.2.3.cmml">(</mo><mrow id="S3.p2.6.m6.2.2.1.1.1" xref="S3.p2.6.m6.2.2.1.1.1.cmml"><mi id="S3.p2.6.m6.2.2.1.1.1.3" xref="S3.p2.6.m6.2.2.1.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.p2.6.m6.2.2.1.1.1.2" xref="S3.p2.6.m6.2.2.1.1.1.2.cmml">​</mo><mrow id="S3.p2.6.m6.2.2.1.1.1.1.1" xref="S3.p2.6.m6.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.6.m6.2.2.1.1.1.1.1.2" xref="S3.p2.6.m6.2.2.1.1.1.1.2.cmml">(</mo><mi id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml">w</mi><mo id="S3.p2.6.m6.2.2.1.1.1.1.1.3" xref="S3.p2.6.m6.2.2.1.1.1.1.2.cmml">,</mo><msub id="S3.p2.6.m6.2.2.1.1.1.1.1.1" xref="S3.p2.6.m6.2.2.1.1.1.1.1.1.cmml"><mi id="S3.p2.6.m6.2.2.1.1.1.1.1.1.2" xref="S3.p2.6.m6.2.2.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.p2.6.m6.2.2.1.1.1.1.1.1.3" xref="S3.p2.6.m6.2.2.1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.p2.6.m6.2.2.1.1.1.1.1.4" xref="S3.p2.6.m6.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.p2.6.m6.3.3.2.2.4" xref="S3.p2.6.m6.3.3.2.3.cmml">,</mo><msub id="S3.p2.6.m6.3.3.2.2.2" xref="S3.p2.6.m6.3.3.2.2.2.cmml"><mi id="S3.p2.6.m6.3.3.2.2.2.2" xref="S3.p2.6.m6.3.3.2.2.2.2.cmml">y</mi><mi id="S3.p2.6.m6.3.3.2.2.2.3" xref="S3.p2.6.m6.3.3.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.p2.6.m6.3.3.2.2.5" xref="S3.p2.6.m6.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.3b"><apply id="S3.p2.6.m6.3.3.cmml" xref="S3.p2.6.m6.3.3"><times id="S3.p2.6.m6.3.3.3.cmml" xref="S3.p2.6.m6.3.3.3"></times><ci id="S3.p2.6.m6.3.3.4.cmml" xref="S3.p2.6.m6.3.3.4">𝑓</ci><interval closure="open" id="S3.p2.6.m6.3.3.2.3.cmml" xref="S3.p2.6.m6.3.3.2.2"><apply id="S3.p2.6.m6.2.2.1.1.1.cmml" xref="S3.p2.6.m6.2.2.1.1.1"><times id="S3.p2.6.m6.2.2.1.1.1.2.cmml" xref="S3.p2.6.m6.2.2.1.1.1.2"></times><ci id="S3.p2.6.m6.2.2.1.1.1.3.cmml" xref="S3.p2.6.m6.2.2.1.1.1.3">ℎ</ci><interval closure="open" id="S3.p2.6.m6.2.2.1.1.1.1.2.cmml" xref="S3.p2.6.m6.2.2.1.1.1.1.1"><ci id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1">𝑤</ci><apply id="S3.p2.6.m6.2.2.1.1.1.1.1.1.cmml" xref="S3.p2.6.m6.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.6.m6.2.2.1.1.1.1.1.1.1.cmml" xref="S3.p2.6.m6.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.6.m6.2.2.1.1.1.1.1.1.2.cmml" xref="S3.p2.6.m6.2.2.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.p2.6.m6.2.2.1.1.1.1.1.1.3.cmml" xref="S3.p2.6.m6.2.2.1.1.1.1.1.1.3">𝑗</ci></apply></interval></apply><apply id="S3.p2.6.m6.3.3.2.2.2.cmml" xref="S3.p2.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p2.6.m6.3.3.2.2.2.1.cmml" xref="S3.p2.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S3.p2.6.m6.3.3.2.2.2.2.cmml" xref="S3.p2.6.m6.3.3.2.2.2.2">𝑦</ci><ci id="S3.p2.6.m6.3.3.2.2.2.3.cmml" xref="S3.p2.6.m6.3.3.2.2.2.3">𝑗</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.3c">f(h(w,x_{j}),y_{j})</annotation></semantics></math> is the loss for <math id="S3.p2.7.m7.1" class="ltx_Math" alttext="j^{th}" display="inline"><semantics id="S3.p2.7.m7.1a"><msup id="S3.p2.7.m7.1.1" xref="S3.p2.7.m7.1.1.cmml"><mi id="S3.p2.7.m7.1.1.2" xref="S3.p2.7.m7.1.1.2.cmml">j</mi><mrow id="S3.p2.7.m7.1.1.3" xref="S3.p2.7.m7.1.1.3.cmml"><mi id="S3.p2.7.m7.1.1.3.2" xref="S3.p2.7.m7.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.p2.7.m7.1.1.3.1" xref="S3.p2.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.p2.7.m7.1.1.3.3" xref="S3.p2.7.m7.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.p2.7.m7.1b"><apply id="S3.p2.7.m7.1.1.cmml" xref="S3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.p2.7.m7.1.1.1.cmml" xref="S3.p2.7.m7.1.1">superscript</csymbol><ci id="S3.p2.7.m7.1.1.2.cmml" xref="S3.p2.7.m7.1.1.2">𝑗</ci><apply id="S3.p2.7.m7.1.1.3.cmml" xref="S3.p2.7.m7.1.1.3"><times id="S3.p2.7.m7.1.1.3.1.cmml" xref="S3.p2.7.m7.1.1.3.1"></times><ci id="S3.p2.7.m7.1.1.3.2.cmml" xref="S3.p2.7.m7.1.1.3.2">𝑡</ci><ci id="S3.p2.7.m7.1.1.3.3.cmml" xref="S3.p2.7.m7.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.7.m7.1c">j^{th}</annotation></semantics></math> sample from <math id="S3.p2.8.m8.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S3.p2.8.m8.1a"><msub id="S3.p2.8.m8.1.1" xref="S3.p2.8.m8.1.1.cmml"><mi id="S3.p2.8.m8.1.1.2" xref="S3.p2.8.m8.1.1.2.cmml">D</mi><mi id="S3.p2.8.m8.1.1.3" xref="S3.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.8.m8.1b"><apply id="S3.p2.8.m8.1.1.cmml" xref="S3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p2.8.m8.1.1.1.cmml" xref="S3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.p2.8.m8.1.1.2.cmml" xref="S3.p2.8.m8.1.1.2">𝐷</ci><ci id="S3.p2.8.m8.1.1.3.cmml" xref="S3.p2.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.8.m8.1c">D_{i}</annotation></semantics></math>. The participating devices optimize the loss using an optimizer to find optimal parameters. In the subsequent step, the locally trained parameters (weights and biases) are shared with the central server for global model creation. The central curator receives all <math id="S3.p2.9.m9.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p2.9.m9.1a"><mi id="S3.p2.9.m9.1.1" xref="S3.p2.9.m9.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p2.9.m9.1b"><ci id="S3.p2.9.m9.1.1.cmml" xref="S3.p2.9.m9.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.9.m9.1c">k</annotation></semantics></math> locally trained models parameters and performs aggregation operations on them. The weights and biases (<math id="S3.p2.10.m10.2" class="ltx_Math" alttext="W,b" display="inline"><semantics id="S3.p2.10.m10.2a"><mrow id="S3.p2.10.m10.2.3.2" xref="S3.p2.10.m10.2.3.1.cmml"><mi id="S3.p2.10.m10.1.1" xref="S3.p2.10.m10.1.1.cmml">W</mi><mo id="S3.p2.10.m10.2.3.2.1" xref="S3.p2.10.m10.2.3.1.cmml">,</mo><mi id="S3.p2.10.m10.2.2" xref="S3.p2.10.m10.2.2.cmml">b</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.10.m10.2b"><list id="S3.p2.10.m10.2.3.1.cmml" xref="S3.p2.10.m10.2.3.2"><ci id="S3.p2.10.m10.1.1.cmml" xref="S3.p2.10.m10.1.1">𝑊</ci><ci id="S3.p2.10.m10.2.2.cmml" xref="S3.p2.10.m10.2.2">𝑏</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.10.m10.2c">W,b</annotation></semantics></math>) of respective layers of every model are aggregated. Thus, the aggregated model contains representation from all models, which is further fine-tuned in the next iteration. The global model training paradigm is done in collaboration with central serve as shown in Fig <a href="#S3.F1" title="Figure 1 ‣ 3 Decentralized federated learning ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The aggregated/updated global parameters (<math id="S3.p2.11.m11.2" class="ltx_Math" alttext="W,b" display="inline"><semantics id="S3.p2.11.m11.2a"><mrow id="S3.p2.11.m11.2.3.2" xref="S3.p2.11.m11.2.3.1.cmml"><mi id="S3.p2.11.m11.1.1" xref="S3.p2.11.m11.1.1.cmml">W</mi><mo id="S3.p2.11.m11.2.3.2.1" xref="S3.p2.11.m11.2.3.1.cmml">,</mo><mi id="S3.p2.11.m11.2.2" xref="S3.p2.11.m11.2.2.cmml">b</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.11.m11.2b"><list id="S3.p2.11.m11.2.3.1.cmml" xref="S3.p2.11.m11.2.3.2"><ci id="S3.p2.11.m11.1.1.cmml" xref="S3.p2.11.m11.1.1">𝑊</ci><ci id="S3.p2.11.m11.2.2.cmml" xref="S3.p2.11.m11.2.2">𝑏</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.11.m11.2c">W,b</annotation></semantics></math>) are pushed back to local devices for the next round of training. It is an iterative process that optimizes global parameters using local model updates. The global loss function for the system is <math id="S3.p2.12.m12.4" class="ltx_Math" alttext="F(w)=\frac{1}{|D|}\sum\limits_{i=1}^{k}|D_{i}|\times F_{i}(w)" display="inline"><semantics id="S3.p2.12.m12.4a"><mrow id="S3.p2.12.m12.4.4" xref="S3.p2.12.m12.4.4.cmml"><mrow id="S3.p2.12.m12.4.4.3" xref="S3.p2.12.m12.4.4.3.cmml"><mi id="S3.p2.12.m12.4.4.3.2" xref="S3.p2.12.m12.4.4.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.p2.12.m12.4.4.3.1" xref="S3.p2.12.m12.4.4.3.1.cmml">​</mo><mrow id="S3.p2.12.m12.4.4.3.3.2" xref="S3.p2.12.m12.4.4.3.cmml"><mo stretchy="false" id="S3.p2.12.m12.4.4.3.3.2.1" xref="S3.p2.12.m12.4.4.3.cmml">(</mo><mi id="S3.p2.12.m12.2.2" xref="S3.p2.12.m12.2.2.cmml">w</mi><mo stretchy="false" id="S3.p2.12.m12.4.4.3.3.2.2" xref="S3.p2.12.m12.4.4.3.cmml">)</mo></mrow></mrow><mo id="S3.p2.12.m12.4.4.2" xref="S3.p2.12.m12.4.4.2.cmml">=</mo><mrow id="S3.p2.12.m12.4.4.1" xref="S3.p2.12.m12.4.4.1.cmml"><mfrac id="S3.p2.12.m12.1.1" xref="S3.p2.12.m12.1.1.cmml"><mn id="S3.p2.12.m12.1.1.3" xref="S3.p2.12.m12.1.1.3.cmml">1</mn><mrow id="S3.p2.12.m12.1.1.1.3" xref="S3.p2.12.m12.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.12.m12.1.1.1.3.1" xref="S3.p2.12.m12.1.1.1.2.1.cmml">|</mo><mi id="S3.p2.12.m12.1.1.1.1" xref="S3.p2.12.m12.1.1.1.1.cmml">D</mi><mo stretchy="false" id="S3.p2.12.m12.1.1.1.3.2" xref="S3.p2.12.m12.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.p2.12.m12.4.4.1.2" xref="S3.p2.12.m12.4.4.1.2.cmml">​</mo><mrow id="S3.p2.12.m12.4.4.1.1" xref="S3.p2.12.m12.4.4.1.1.cmml"><munderover id="S3.p2.12.m12.4.4.1.1.2" xref="S3.p2.12.m12.4.4.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.p2.12.m12.4.4.1.1.2.2.2" xref="S3.p2.12.m12.4.4.1.1.2.2.2.cmml">∑</mo><mrow id="S3.p2.12.m12.4.4.1.1.2.2.3" xref="S3.p2.12.m12.4.4.1.1.2.2.3.cmml"><mi id="S3.p2.12.m12.4.4.1.1.2.2.3.2" xref="S3.p2.12.m12.4.4.1.1.2.2.3.2.cmml">i</mi><mo id="S3.p2.12.m12.4.4.1.1.2.2.3.1" xref="S3.p2.12.m12.4.4.1.1.2.2.3.1.cmml">=</mo><mn id="S3.p2.12.m12.4.4.1.1.2.2.3.3" xref="S3.p2.12.m12.4.4.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.p2.12.m12.4.4.1.1.2.3" xref="S3.p2.12.m12.4.4.1.1.2.3.cmml">k</mi></munderover><mrow id="S3.p2.12.m12.4.4.1.1.1" xref="S3.p2.12.m12.4.4.1.1.1.cmml"><mrow id="S3.p2.12.m12.4.4.1.1.1.1" xref="S3.p2.12.m12.4.4.1.1.1.1.cmml"><mrow id="S3.p2.12.m12.4.4.1.1.1.1.1.1" xref="S3.p2.12.m12.4.4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.12.m12.4.4.1.1.1.1.1.1.2" xref="S3.p2.12.m12.4.4.1.1.1.1.1.2.1.cmml">|</mo><msub id="S3.p2.12.m12.4.4.1.1.1.1.1.1.1" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.cmml"><mi id="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.2" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.2.cmml">D</mi><mi id="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.3" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo rspace="0.055em" stretchy="false" id="S3.p2.12.m12.4.4.1.1.1.1.1.1.3" xref="S3.p2.12.m12.4.4.1.1.1.1.1.2.1.cmml">|</mo></mrow><mo rspace="0.222em" id="S3.p2.12.m12.4.4.1.1.1.1.2" xref="S3.p2.12.m12.4.4.1.1.1.1.2.cmml">×</mo><msub id="S3.p2.12.m12.4.4.1.1.1.1.3" xref="S3.p2.12.m12.4.4.1.1.1.1.3.cmml"><mi id="S3.p2.12.m12.4.4.1.1.1.1.3.2" xref="S3.p2.12.m12.4.4.1.1.1.1.3.2.cmml">F</mi><mi id="S3.p2.12.m12.4.4.1.1.1.1.3.3" xref="S3.p2.12.m12.4.4.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.p2.12.m12.4.4.1.1.1.2" xref="S3.p2.12.m12.4.4.1.1.1.2.cmml">​</mo><mrow id="S3.p2.12.m12.4.4.1.1.1.3.2" xref="S3.p2.12.m12.4.4.1.1.1.cmml"><mo stretchy="false" id="S3.p2.12.m12.4.4.1.1.1.3.2.1" xref="S3.p2.12.m12.4.4.1.1.1.cmml">(</mo><mi id="S3.p2.12.m12.3.3" xref="S3.p2.12.m12.3.3.cmml">w</mi><mo stretchy="false" id="S3.p2.12.m12.4.4.1.1.1.3.2.2" xref="S3.p2.12.m12.4.4.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.12.m12.4b"><apply id="S3.p2.12.m12.4.4.cmml" xref="S3.p2.12.m12.4.4"><eq id="S3.p2.12.m12.4.4.2.cmml" xref="S3.p2.12.m12.4.4.2"></eq><apply id="S3.p2.12.m12.4.4.3.cmml" xref="S3.p2.12.m12.4.4.3"><times id="S3.p2.12.m12.4.4.3.1.cmml" xref="S3.p2.12.m12.4.4.3.1"></times><ci id="S3.p2.12.m12.4.4.3.2.cmml" xref="S3.p2.12.m12.4.4.3.2">𝐹</ci><ci id="S3.p2.12.m12.2.2.cmml" xref="S3.p2.12.m12.2.2">𝑤</ci></apply><apply id="S3.p2.12.m12.4.4.1.cmml" xref="S3.p2.12.m12.4.4.1"><times id="S3.p2.12.m12.4.4.1.2.cmml" xref="S3.p2.12.m12.4.4.1.2"></times><apply id="S3.p2.12.m12.1.1.cmml" xref="S3.p2.12.m12.1.1"><divide id="S3.p2.12.m12.1.1.2.cmml" xref="S3.p2.12.m12.1.1"></divide><cn type="integer" id="S3.p2.12.m12.1.1.3.cmml" xref="S3.p2.12.m12.1.1.3">1</cn><apply id="S3.p2.12.m12.1.1.1.2.cmml" xref="S3.p2.12.m12.1.1.1.3"><abs id="S3.p2.12.m12.1.1.1.2.1.cmml" xref="S3.p2.12.m12.1.1.1.3.1"></abs><ci id="S3.p2.12.m12.1.1.1.1.cmml" xref="S3.p2.12.m12.1.1.1.1">𝐷</ci></apply></apply><apply id="S3.p2.12.m12.4.4.1.1.cmml" xref="S3.p2.12.m12.4.4.1.1"><apply id="S3.p2.12.m12.4.4.1.1.2.cmml" xref="S3.p2.12.m12.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.p2.12.m12.4.4.1.1.2.1.cmml" xref="S3.p2.12.m12.4.4.1.1.2">superscript</csymbol><apply id="S3.p2.12.m12.4.4.1.1.2.2.cmml" xref="S3.p2.12.m12.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.p2.12.m12.4.4.1.1.2.2.1.cmml" xref="S3.p2.12.m12.4.4.1.1.2">subscript</csymbol><sum id="S3.p2.12.m12.4.4.1.1.2.2.2.cmml" xref="S3.p2.12.m12.4.4.1.1.2.2.2"></sum><apply id="S3.p2.12.m12.4.4.1.1.2.2.3.cmml" xref="S3.p2.12.m12.4.4.1.1.2.2.3"><eq id="S3.p2.12.m12.4.4.1.1.2.2.3.1.cmml" xref="S3.p2.12.m12.4.4.1.1.2.2.3.1"></eq><ci id="S3.p2.12.m12.4.4.1.1.2.2.3.2.cmml" xref="S3.p2.12.m12.4.4.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.p2.12.m12.4.4.1.1.2.2.3.3.cmml" xref="S3.p2.12.m12.4.4.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.p2.12.m12.4.4.1.1.2.3.cmml" xref="S3.p2.12.m12.4.4.1.1.2.3">𝑘</ci></apply><apply id="S3.p2.12.m12.4.4.1.1.1.cmml" xref="S3.p2.12.m12.4.4.1.1.1"><times id="S3.p2.12.m12.4.4.1.1.1.2.cmml" xref="S3.p2.12.m12.4.4.1.1.1.2"></times><apply id="S3.p2.12.m12.4.4.1.1.1.1.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1"><times id="S3.p2.12.m12.4.4.1.1.1.1.2.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.2"></times><apply id="S3.p2.12.m12.4.4.1.1.1.1.1.2.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1"><abs id="S3.p2.12.m12.4.4.1.1.1.1.1.2.1.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.2"></abs><apply id="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.2">𝐷</ci><ci id="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.3.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.p2.12.m12.4.4.1.1.1.1.3.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.p2.12.m12.4.4.1.1.1.1.3.1.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.3">subscript</csymbol><ci id="S3.p2.12.m12.4.4.1.1.1.1.3.2.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.3.2">𝐹</ci><ci id="S3.p2.12.m12.4.4.1.1.1.1.3.3.cmml" xref="S3.p2.12.m12.4.4.1.1.1.1.3.3">𝑖</ci></apply></apply><ci id="S3.p2.12.m12.3.3.cmml" xref="S3.p2.12.m12.3.3">𝑤</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.12.m12.4c">F(w)=\frac{1}{|D|}\sum\limits_{i=1}^{k}|D_{i}|\times F_{i}(w)</annotation></semantics></math>. The goal of federated learning is to learn a global model by combining all local models. This training cycle continues until convergence without accessing raw data as shown in Fig <a href="#S3.F1" title="Figure 1 ‣ 3 Decentralized federated learning ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Architecture</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Sending raw data to the server consumes large bandwidth and creates network congestion. So it is not recommended for systems such as real time, delay-sensitive. Further, it also has privacy concerns. Another way is to compute the model on edge devices in collaboration with the cloud that suffers from high latency. However, the IoT devices have low computational resources that can not train machine learning model. To address this, we propose a fog enabled cloud-IoT online training architecture to simulate a machine learning model from continuously generated data by various IoT devices efficiently. The IoT nodes generate continuous data and share it with the fog node. A fog node has sufficient computational resources to train a machine learning model. It also has storage capability to store historical data generated from IoT devices. The cloud server facilitates global model creation by aggregating all participating devices leanings. The proposed architecture is shown in Fig <a href="#S3.F2" title="Figure 2 ‣ 3.1 Architecture ‣ 3 Decentralized federated learning ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2402.12906/assets/fig/BDA_architecture.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="400" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;"> Distributed learning architecture </span></figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The Edge layer contains a large number of resources constrained IoT devices such as cameras, watches, GPS, bulbs, sensors, radars, etc. These devices continuously generate raw data by sensing the surroundings but are limited in storage and computations. The edge layer directly connects with the fog layer and share their data to the associated fog node. With enough computational power, a fog node trains a machine learning model in collaboration with the central server. Although, a fog node stores historic data of associated devices but the training is done on recently captured periodic data frames. This simulates online training of continuously changing datasets. The Fog-Cloud layers participate in federated learning for machine learning. Once local models are trained on the fog layer, it is shared with the cloud layer. The cloud layer aggregates the local models and creates a global model. The federated learning with fog-cloud architecture is continued till the convergence of the global model. The proposed architecture is used for machine learning model training on rapidly growing data on resource constrained devices. The fog layer is responsible for data collection and federated learning training with a cloud node. While federated training fog layer only shares learning parameters to the cloud for aggregations. The raw data is stored at the fog layer, which is not shared with the central server. The proposed architecture simulates a distributed machine learning using computations of resource constrained devices.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Online training and Data privacy</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">With the variety of digital devices, data proliferation is another challenge in machine learning training. As discussed earlier, sending this data to the server would not be an efficient way to mine it. Additionally, collecting, storing all the data, and then applying machine learning training needs huge computational resources. The data’s velocity increases as the number of devices employed increases. Consequently, it increases volume of the data with a variety of data that lead to big data problems. To address this to some extent, a continuous learning approach is applied while training a model. Rather than applying training on the complete dataset, online training is done on a subset of data. The subset can be periodic data generated from a device over a fixed time interval. Once the device learns the representation from current data, it shares representations with the central curator for global modelling. The curator aggregates all the representations and creates a central model for all devices. In the next round, every device generates a new set of datasets. Subsequently, in this round, the global model is further fine-tuned with the next dataset. This is important because IoT devices are low resources devices that are incapable of machine learning training on a very large dataset. The devices continue to generate the raw data and train the model. This can simulate a global model by exploiting low constrained devices computations.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">However, the IoT devices such as sensors, CCTV cameras, radars do not have enough computation resources to run on-device machine learning. This work addresses this issue by deploying a fog node near IoT devices. All data generating devices are connected to the associated fog node to share raw data. With sufficient computational and storage capabilities, a fog node stores periodic data and performs online machine learning training. The rapid growth of data accumulates a large amount on a fog node. Due to the computational limitation of a fog node, online training is done on recently captured data leaving historic data aside. At the same time, the entire data is kept at the fog layer on backup storage, which can be reproduced in future if required. Then fog node participates in the federated learning process in collaboration with the central cloud server.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">IoT devices contain private data, location information, sensitive data, bank details, chat and personally identifiable data. Data privacy and security is another major challenge in cloud-IoT computation. Nowadays, there are increasing concerns for personal data sharing. The users are not comfortable in sharing personal data such as photos or chat to the cloud. The raw data contains crucial patterns that can be useful for various applications such as recommender systems, security analyses, smart homes, safety predictions, etc. Additionally, machine learning task has to follow strict data protection rules such as General Data Protection Regulation (GDPR). To address the privacy concerns, we have used a decentralized machine learning approach for model training. In the proposed work, the data is stored at the fog layer and not shared with the cloud. Fog node participates in machine learning training that only shares model parameters, not raw data. This makes the system overall privacy preserving.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation and results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section describes evaluations and experimental results of the proposed framework for machine learning model. The model training is done for radar data in IIoT setup. We simulate the proposed architecture using Docker containers. Then, training of a global model for safe distance detection is done for human position in HR workspace. To show the efficiency of the proposed work, We have trained the ANN model in distributed environments and achieved expected results.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Docker based fog federation framework </h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We have used docker containers to simulate the distributed machine learning. The docker engine facilitates multiple containers to run various programs independently. A container provides a run time environment for program execution. Additionally, docker creates a network of multiple containers that can communicate to others. With sufficient computational resources, we employed multiple docker containers as a fog node. Every container runs a machine learning model independently with their local data. We have used gRPC library for requests and service calls between fog and central node. The federated learning is done between cloud and fog nodes using docker containers with gRPC calls. The IoT devices generate continuous data and share it with the fog node. Fog node stores historical data at backup devices and trains the model on recent data. To simulate the continuous data generation and online training, we used a fixed set of data samples for local training. Every container has its personal data, and machine learning is done on fixed periodic sequential training samples.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">We have simulated the proposed architecture to train ANN based machine learning model for human operator position detection in a human-robot workspace. The dataset is recorded from multiple Frequency-Modulated Continuous Wave (FMCW) radars. The fog nodes compile one minute of data from every device and complete one round of federating learning. We trained the model on 60 frames assuming every radar is generating 1 frame/sec. The next round of training is done on the next sequence of datasets. For this experiment, we have taken 5 fog nodes for decentralized machine learning training. The fog node trains fully connected ANN using tensorlow framework. The ANN model contains a single hidden layer with 64 neurons. The input and output layers have 512 and 8 neurons, respectively, based on data dimension and output labels.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.2" class="ltx_p">We have trained a shallow neural network with one hidden layer. The model is a fully connected dense network with 64 units in the hidden layer. Input layer has 512 input neurons which is fully connected to the only hidden layer (dimension 512<math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mo id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><times id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\times</annotation></semantics></math>64 + 64 bias) followed by a ReLu layer. The output layer has 8 neurons which is densely connected to the hidden layer (dimension 64 <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mo id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><times id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\times</annotation></semantics></math> 8 + 8 bias). The final output label is predicted based on softmax activation function at the output layer. The local training on every device is done for 5 epochs to simulate low computational resources. The network is trained by backpropogation algorithm using categorical crossentropy loss function. Further, the ’adam’ optimizer is used with learning 0.001 as an optimizer to optimize the training error. The loss value of the global model is calculated on test data. Also, we have traced the accuracy performance of the global model on both personal and unknown test datasets. The fog node participates in federated learning in collaboration with a central node with its local data, where device local data is recently generated one minute data. The simulation is done to show computational intelligence of proposed work on continuously changing data.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>FMCW radar dataset for federated learning</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The proposed architecture is validated on a real world IIoT use case. The data is generated from FMCW radars in a human-robot workspace. FMCW radars are effective IIoT device in industrial setup for environment sensing, distance measurement, etc. These radars are placed in a shared workspace of human robot to capture human position in the environment. Detection of human position in an industrial setup is crucial for worker’s safety. These radars contain data to measure the distance and position of the human operator near it. The data distribution of devices is non independent and identically Distributed(non-IID), i.e. every device has its locally generated dataset. However, each participating devices have all classes samples. We used mentioned dataset to train a machine learning model to classify human safe distance. The dataset is published by Stefano Savazzi, which can be downloaded from IEEE Dataport <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. The radars output signals are preprocessed and converted into 512-point. The detailed methodology and collection of data are given in this paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.3.2" class="ltx_text" style="font-size:90%;">FMCW radars dataset</span></figcaption>
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.4.1.1" class="ltx_tr">
<th id="S4.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.1" class="ltx_text ltx_font_bold">Distance(m)</span></th>
<th id="S4.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.2.1" class="ltx_text ltx_font_bold">Class</span></th>
<th id="S4.T1.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.3.1" class="ltx_text ltx_font_bold">Critical/Safe</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.2.1" class="ltx_tr">
<td id="S4.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">&lt;0.5</td>
<td id="S4.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1</td>
<td id="S4.T1.4.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Critical</td>
</tr>
<tr id="S4.T1.4.3.2" class="ltx_tr">
<td id="S4.T1.4.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">0.5 &lt;= d &lt;1.0</td>
<td id="S4.T1.4.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2</td>
<td id="S4.T1.4.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Critical</td>
</tr>
<tr id="S4.T1.4.4.3" class="ltx_tr">
<td id="S4.T1.4.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">1.0 &lt;= d &lt;1.5</td>
<td id="S4.T1.4.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3</td>
<td id="S4.T1.4.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Critical</td>
</tr>
<tr id="S4.T1.4.5.4" class="ltx_tr">
<td id="S4.T1.4.5.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">1.5 &lt;= d &lt;2.0</td>
<td id="S4.T1.4.5.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4</td>
<td id="S4.T1.4.5.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Safe</td>
</tr>
<tr id="S4.T1.4.6.5" class="ltx_tr">
<td id="S4.T1.4.6.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">2.0 &lt;= d &lt;2.5</td>
<td id="S4.T1.4.6.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">5</td>
<td id="S4.T1.4.6.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Safe</td>
</tr>
<tr id="S4.T1.4.7.6" class="ltx_tr">
<td id="S4.T1.4.7.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">2.5 &lt;= d &lt;3.0</td>
<td id="S4.T1.4.7.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6</td>
<td id="S4.T1.4.7.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Safe</td>
</tr>
<tr id="S4.T1.4.8.7" class="ltx_tr">
<td id="S4.T1.4.8.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">3.0 &lt;= d &lt;3.5</td>
<td id="S4.T1.4.8.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7</td>
<td id="S4.T1.4.8.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Safe</td>
</tr>
<tr id="S4.T1.4.9.8" class="ltx_tr">
<td id="S4.T1.4.9.8.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">&gt;=3.5</td>
<td id="S4.T1.4.9.8.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">0</td>
<td id="S4.T1.4.9.8.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Safe</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The input sample contains 512 points with 8 labels. The labels are characterized by different distances of human operator and radar. The dataset contains a total of 32,000 samples of FFT range measurements 521 points. The dataset is already divided into training and testing samples of 16,000 <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mo id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><times id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\times</annotation></semantics></math> 512 shape. Additionally, the data sample is also randomly distributed over various devices for federated learning simulation in the database. We have implemented the given data distribution over 5 devices for federated learning to learn ANN model for safe/unsafe position detection. The training is done for C=8 classification of the potential situation in human robot workspace. The label is an integer from 0 to 7, where Class 0 represents human distance &gt;3.5m which is also marked as safe. Class 1 is represented as critical since the distance is &lt;0.5m. Other labels are marked based on different distance measures between humans and radars. Table <a href="#S4.T1" title="Table 1 ‣ 4.2 FMCW radar dataset for federated learning ‣ 4 Evaluation and results ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> contains labels for various classes.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results and Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We trained an ANN model for human position classification in the shared HR workspace. The online training is done with 60 frames at a time with 5 fog nodes. From 16,000 training samples, every fog node receives 3200 independent samples. The local model training is done with the current 60 samples for 5 epochs only. Then central server performs aggregation of all learnt model parameters. This completes one round of federated learning. In the next round, we use next 60 samples for training by skipping previous data points. We executed such 53 rounds that exhaust entire local dataset training. At every round, we assess the model performance in terms of loss and accuracy. The global model is evaluated on the test dataset. The training loss and accuracy of the model on test data are shown in Fig <a href="#S4.F3" title="Figure 3 ‣ 4.3 Results and Analysis ‣ 4 Evaluation and results ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2402.12906/assets/fig/loss.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F3.sf1.3.2" class="ltx_text" style="font-size:90%;"> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2402.12906/assets/fig/accuracy.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F3.sf2.3.2" class="ltx_text" style="font-size:90%;"> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Global model performance on test data: Loss value (a) and Accuracy (b) at every training round</span></figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">As training increases over the number of rounds, model improves its accuracy significantly. The model optimizes loss value and stabilizes the training after 30 rounds. The proposed online training performed exceptionally well as the test accuracy reached 99%. The local model is trained on multiple fog nodes parallelly. The global model is combined learning of all local models. Fig <a href="#S4.F4" title="Figure 4 ‣ 4.3 Results and Analysis ‣ 4 Evaluation and results ‣ Fog enabled distributed training architecture for federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows accuracy of the global model on various local data resides in fog devices. The accuracy of test data is averaged by cancelling the drift on various local training data.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2402.12906/assets/fig/accuracy_local.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;"> Model performance on all devices </span></figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Training a machine learning model with a neural network is prone to overfitting, specifically in online training mode. Comparatively, a large model with huge parameters can memorize the data labels that tend to perform poorly on test data. In our experiment, the amount of data passed at a particular instance is relatively small (60 frames/iteration). The ANN model quickly learnt the sample with very high accuracy (&gt;90%) in fewer epochs. However, it failed to perform similar results on global test data. This is because of possible model overfitting on relatively small data. The federated learning consolidates such a few models to combined learnt information. The combined output model is better generalized and reduces possible overfitting. With the varying number of participating devices, federated learning prevents overfitting intrinsically. However, other generalization techniques such as dropout, normalization, regularization, etc may be applied at the architectural level. This type of learning paradigm can help in creating a better generalized model that can be scope for future work.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions and future work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This work focuses on machine learning model training on decentralized data. We have proposed fog enabled distributed training architecture to train ML model on rapidly changing data. The architecture suitably uses decentralized algorithms such as federated learning for model creation. The edge layer is responsible for data generation. The cloud layer coordinates with computational nodes on the fog layer for machine learning. Whereas, the fog layer participates in distributed machine learning training with the central server. We have tested the proposed architecture on real world IIoT use case. The simulation result of position detection model trained on changing dataset is significant. We will further investigate the distributed architecture for communication and energy efficient training. Moreover, we only share trainable parameters to the server, not raw data. However, trainable parameters are vulnerable to attack. The robust privacy sensitive training could be another scope of work.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We acknowledge financial support to UoH-IoE by MHRD, India (F11/9/2019-U3(A)).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Gubbi, R. Buyya, S. Marusic, M. Palaniswami,
<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0167739X13000241" title="" class="ltx_ref ltx_href">Internet
of Things (IoT): A vision, architectural elements, and future directions</a>,
Future Generation Computer Systems 29 (7) (2013) 1645–1660.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/https://doi.org/10.1016/j.future.2013.01.010" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:https://doi.org/10.1016/j.future.2013.01.010</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0167739X13000241" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S0167739X13000241</a>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Holst,
<a target="_blank" href="https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/" title="" class="ltx_ref ltx_href">IoT
connected devices worldwide 2019-2030</a> (Aug 2021).

<br class="ltx_break">URL <a target="_blank" href="https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
C. Chang, S. N. Srirama, R. Buyya, Internet of Things (IoT) and New Computing
Paradigms (2018).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1812.00591" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:1812.00591</span></a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
F. Bonomi, R. Milito, J. Zhu, S. Addepalli,
<a target="_blank" href="https://doi.org/10.1145/2342509.2342513" title="" class="ltx_ref ltx_href">Fog Computing and Its Role in
the Internet of Things</a>, in: Proceedings of the First Edition of the MCC
Workshop on Mobile Cloud Computing, MCC ’12, Association for Computing
Machinery, New York, NY, USA, 2012, p. 13–16.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1145/2342509.2342513" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1145/2342509.2342513</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://doi.org/10.1145/2342509.2342513" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2342509.2342513</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. Buyya, S. N. Srirama, Fog and edge computing: principles and paradigms,
John Wiley &amp; Sons, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, B. A. y. Arcas,
<a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_href">Communication-Efficient
Learning of Deep Networks from Decentralized Data</a>, in: A. Singh, J. Zhu
(Eds.), Proceedings of the 20th International Conference on Artificial
Intelligence and Statistics, Vol. 54 of Proceedings of Machine Learning
Research, PMLR, 2017, pp. 1273–1282.

<br class="ltx_break">URL <a target="_blank" href="https://proceedings.mlr.press/v54/mcmahan17a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v54/mcmahan17a.html</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
O. Consortium, OpenFog Reference Architecture for Fog Computing, Technical
Report (February, 2017).

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Al-Khafajiy, T. Baker, A. Waraich, O. Alfandi, A. Hussien, Enabling high
performance fog computing through fog-2-fog coordination model, in: 2019
IEEE/ACS 16th International Conference on Computer Systems and Applications
(AICCSA), 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/AICCSA47632.2019.9035353" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/AICCSA47632.2019.9035353</span></a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. N. Srirama, F. M. S. Dick, M. Adhikari, Akka framework based on the actor
model for executing distributed fog computing applications, Future Generation
Computer Systems 117 (2021) 439–452.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Hazra, M. Adhikari, T. Amgoth, S. N. Srirama, Joint computation offloading
and scheduling optimization of iot applications in fog networks, IEEE
Transactions on Network Science and Engineering 7 (4) (2020) 3266–3278.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A. Munusamy, M. Adhikari, M. A. Khan, V. G. Menon, S. N. Srirama, L. T. Alex,
M. R. Khosravi, Edge-Centric Secure Service Provisioning in IoT-Enabled
Maritime Transportation Systems, IEEE Transactions on Intelligent
Transportation Systems (2021) 1–10<a target="_blank" href="http://dx.doi.org/10.1109/TITS.2021.3102957" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TITS.2021.3102957</span></a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
G. Kamath, P. Agnihotri, M. Valero, K. Sarker, W.-Z. Song, Pushing Analytics
to the Edge, in: 2016 IEEE Global Communications Conference (GLOBECOM),
2016, pp. 1–6.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/GLOCOM.2016.7842181" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/GLOCOM.2016.7842181</span></a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Konečný, H. B. McMahan, D. Ramage, P. Richtárik,
<a target="_blank" href="http://arxiv.org/abs/1610.02527" title="" class="ltx_ref ltx_href">Federated Optimization: Distributed
Machine Learning for On-Device Intelligence</a>, CoRR abs/1610.02527.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1610.02527" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:1610.02527</span></a>.

<br class="ltx_break">URL <a target="_blank" href="http://arxiv.org/abs/1610.02527" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1610.02527</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J. Konečný, H. B. McMahan, F. X. Yu, P. Richtarik, A. T. Suresh, D. Bacon,
<a target="_blank" href="https://arxiv.org/abs/1610.05492" title="" class="ltx_ref ltx_href">Federated Learning: Strategies for
Improving Communication Efficiency</a>, in: NIPS Workshop on Private
Multi-Party Machine Learning, 2016.

<br class="ltx_break">URL <a target="_blank" href="https://arxiv.org/abs/1610.05492" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1610.05492</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Li, H. Li, G. Xu, T. Xiang, X. Huang, R. Lu, Toward Secure and
Privacy-Preserving Distributed Deep Learning in Fog-Cloud Computing, IEEE
Internet of Things Journal 7 (12) (2020) 11460–11472.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/JIOT.2020.3012480" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2020.3012480</span></a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, Y. Dai, S. Maharjan, Y. Zhang, Differentially Private
Asynchronous Federated Learning for Mobile Edge Computing in Urban
Informatics, IEEE Transactions on Industrial Informatics 16 (3) (2020)
2134–2143.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/TII.2019.2942179" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TII.2019.2942179</span></a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
S. Luo, X. Chen, Q. Wu, Z. Zhou, S. Yu, HFEL: Joint Edge Association and
Resource Allocation for Cost-Efficient Hierarchical Federated Edge Learning,
IEEE Transactions on Wireless Communications 19 (10) (2020) 6535–6548.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/TWC.2020.3003744" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/TWC.2020.3003744</span></a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
R. Saha, S. Misra, P. K. Deb, FogFL: Fog-Assisted Federated Learning for
Resource-Constrained IoT Devices, IEEE Internet of Things Journal 8 (10)
(2021) 8456–8463.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/JIOT.2020.3046509" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2020.3046509</span></a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
S. Savazzi, <a target="_blank" href="https://dx.doi.org/10.21227/8yqc-1j15" title="" class="ltx_ref ltx_href">Federated learning:
example dataset (fmcw 122ghz radars)</a> (2019).

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.21227/8yqc-1j15" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.21227/8yqc-1j15</span></a>.

<br class="ltx_break">URL <a target="_blank" href="https://dx.doi.org/10.21227/8yqc-1j15" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dx.doi.org/10.21227/8yqc-1j15</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. Savazzi, M. Nicoli, V. Rampa, Federated Learning With Cooperating Devices:
A Consensus Approach for Massive IoT Networks, IEEE Internet of Things
Journal 7 (5) (2020) 4641–4654.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://dx.doi.org/10.1109/JIOT.2020.2964162" title="" class="ltx_ref ltx_href"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/JIOT.2020.2964162</span></a>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.12905" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.12906" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2402.12906">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.12906" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.12907" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 16:25:30 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
