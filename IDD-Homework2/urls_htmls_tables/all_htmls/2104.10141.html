<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2104.10141] An Overview of Federated Learning at the Edge and Distributed Ledger Technologies for Robotic and Autonomous Systems</title><meta property="og:description" content="Autonomous systems are becoming inherently ubiquitous with the advancements of computing and communication solutions enabling low-latency offloading and real-time collaboration of distributed devices. Decentralized tec…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="An Overview of Federated Learning at the Edge and Distributed Ledger Technologies for Robotic and Autonomous Systems">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="An Overview of Federated Learning at the Edge and Distributed Ledger Technologies for Robotic and Autonomous Systems">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2104.10141">

<!--Generated on Sat Mar  2 06:10:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Robotics Cloud Robotics Fog Robotics Federated Learning Federated Reinforcement Learning Federated Edge Learning Distributed Learning Distributed Ledger Technologies ">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\WarningFilter</span>
<p id="p1.2" class="ltx_p">remresetThe remreset package











<span id="p1.2.1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
<a target="_blank" href="https://tiers.utu.fi" title="" class="ltx_ref ltx_href">Turku Intelligent Embedded and Robotic Systems Lab, University of Turku, Turku, Finland</a> 
<br class="ltx_break"><span id="p1.2.1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>{xianjia.yu, jopequ, jukhei, tovewe}@utu.fi</span></span></span> 
<br class="ltx_break">
<a href="%****%20main.tex%20Line%2075%20****https://tiers.utu.fi" title="" class="ltx_ref ltx_url ltx_font_typewriter">%****␣main.tex␣Line␣75␣****https://tiers.utu.fi</a>
</span></span></span></p>
</div>
<h1 class="ltx_title ltx_title_document">An Overview of Federated Learning at the Edge and Distributed Ledger Technologies for Robotic and Autonomous Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yu Xianjia
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jorge Peña Queralta
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jukka Heikkonen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break">Tomi Westerlund
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Autonomous systems are becoming inherently ubiquitous with the advancements of computing and communication solutions enabling low-latency offloading and real-time collaboration of distributed devices. Decentralized technologies with blockchain and distributed ledger technologies (DLTs) are playing a key role.
At the same time, advances in deep learning (DL) have significantly raised the degree of autonomy and level of intelligence of robotic and autonomous systems. While these technological revolutions were taking place, raising concerns in terms of data security and end-user privacy has become an inescapable research consideration. Federated learning (FL) is a promising solution to privacy-preserving DL at the edge, with an inherently distributed nature by learning on isolated data islands and communicating only model updates. However, FL by itself does not provide the levels of security and robustness required by today’s standards in distributed autonomous systems. This survey covers applications of FL to autonomous robots, analyzes the role of DLT and FL for these systems, and introduces the key background concepts and considerations in current research.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>
Robotics Cloud Robotics Fog Robotics Federated Learning Federated Reinforcement Learning Federated Edge Learning Distributed Learning Distributed Ledger Technologies 
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With a staggering increase in the number of connected devices being deployed worldwide within the Internet of Things (IoT), the amount of data that is generated and transmitted has grown at exponential rates. The inefficiency of processing all this data in a centralized manner at the cloud has brought forward new computing and networking paradigms in recent years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Computing at the edge, closed to where the data sources are, has evident benefits in terms of latency and bandwidth savings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Another key advantage is the inherent benefits to data privacy, as raw data does not travel too far <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. At the same time, the data is being fed to increasingly complex artificial intelligence (AI) models, with deep learning (DL) in particular becoming pervasive across multiple fields and application domains. Recent years have also brought an increasing awareness to the risks and drawbacks of sharing personal data over the internet. The solution to distributed computing at the edge while preserving privacy of data and leveraging DL solutions is federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Federated learning (FL) enables distributed training of complex models over isolated data islands from remote nodes (data sources). The local training results (updates to local models) are then aggregated, e.g. in a cloud server, and a global generalized model is shared back to the nodes. All this with zero raw data transmission <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">From the perspective of robotic and autonomous systems, which are becoming increasingly ubiquitous, cloud solutions have enabled higher degrees of intelligence by eliminating constraints of onboard computational and storage resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Cloud robotics and AI robotics are now an essential part of state-of-the-art robotic systems. Furthermore, as mobile connectivity evolves, 5G and beyond networks are set to further bring the integration of AI, robotics and distributed networking solutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Applications of AI in robotics include, e.g., the deployment of DL for natural language processing (NLP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, or in navigation and mapping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. In control, Reinforcement learning (RL) has been successfully applied in complex games <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and its relevance for dexterous manipulation extensively demonstrated <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Deep reinforcement learning (DRL) is particularly relevant to autonomous robots <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated learning provides a framework for more efficient learning in distributed autonomous systems and multi-robot systems, enabling collaborative learning across heterogeneous cloud and edge nodes and a wide range of robotic and autonomous systems. Even though cloud robotics can promote scalability, collaborative knowledge sharing, and development operation of robotics and autonomous systems, challenges remain in, e.g., security or reliable connectivity.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Multiple reviews and survey papers in the literature have been devoted to studying design approaches, implementation details and application possibilities of FL. Compared to current works focused on security and privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, personalized FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, or communication at the edge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, the present work aims to provide a comprehensive view of how FL can be leveraged to raise the level of autonomy and degree of intelligence of robotic systems. We look at different application opportunities at the edge and within autonomous mobile robots. We provide an overview of the most important concepts, and pay particular attention to synergies between FL and distributed ledger technologies (DLTs), among which blockchain technology has gained significant attention. A conceptual illustration of FL applications and approaches to connectivity is shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ An Overview of Federated Learning at the Edge and Distributed Ledger Technologies for Robotic and Autonomous Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2104.10141/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="615" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Conceptual illustration showing potential application areas and connectivity topologies in federated learning systems.</figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The rest of this survey is organized as follows. In Section II, we introduce key concepts and background to FL frameworks and related research areas. Section III explores the synergies with blockchain and other DLTs. Then, Section IV shifts the focus towards FL at the edge, and its significance and relevance to robotic and autonomous systems. Section V overviews application domains, and the work is concluded in Section VI.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The adoption and development of FL frameworks have been directly or indirectly influenced by other technological and paradigm trends in robotics and autonomous systems. Since the invention of FL, there are a number of works on optimization of FL itself. Different research directions include increasing the adaptiveness, enhancing the privacy-preserving properties, or building towards more efficient collaboration for distributed robot learning, among others. In this section, we briefly introduce the different identifiable research directions from the literature, and the concepts that underpin the popularity of FL in robotics and autonomous systems.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Cloud Robotics and Automation</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Cloud robotics is a field of robotics that capitalizes on cloud technologies.
The cloud infrastructure can provide robots and autonomous systems with extensive resources and potential benefits including big data, cloud computing, collective robot learning, and human learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Under cloud infrastructures, robotic systems have access to more collaborative approaches to autonomy, faster processing of deep learning models, and more powerful computational capabilities in general. A collection of robots in different areas or states can cooperate in a variety of tasks such as disaster management identifying several critical challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and manufacturing environment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. There are a number of examples and implementations of cloud robotics platforms such as AWS RobotMaker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> from Amazon, Dex-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> from UC Berkeley Automation Lab, and Google cloud robotics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Distributed Deep Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">With the increasing amount of data and complexity of DL models, the process of training models becomes inherently costly, computation-intensive, and time-consuming. Distributed DL was proposed to utilize the multiple processors to accelerate DL training process by parallel the computation and the data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. There is a significant amount of work in the literature dedicated to distributed DL in the pursuit of closer collaboration between cloud and edge computing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. This balance between the two paradigms is set to become increasingly pervasive with a well-established IoT era. Immediate concerns that raise with the deployment of distributed DL across cloud and edge is the security of data and privacy of users. In consequence, multiple research directions have emerged to make distributed learning processes more scalable, secure and privacy-preserving through <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Additionally, other research efforts are directed towards utilizing distributed DL for processing and learning from sensitive data such as health data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, video surveillance data  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> and medical data from multiple private or public institutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Privacy and Security in Deep Learning and Federated Learning</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">With the wider adoption of DL over the past decade, issues regarding data security and privacy of data sources became increasingly studied. Some of the main types of security-related issues in DL appear with evasion attacks during model inference and poisoning attack during model training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Adversarial attacks to the algorithms, and model reconstruction attacks are other examples. Multiple solutions have been proposed to deal with these and other attack vectors, including differential privacy, homomorphic encryption, data anonymization, pseudonymization, algorithm encryption, or hardware security implementations, among others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Despite the efforts, new attack vectors have appeared such as re-identification attacks (identification of individual data sources despite data anonymization techniques based on other information in the datasets), dataset reconstruction attacks, or tracing attacks (also referred to as membership inference, though which the inclusion of a specific individual in a dataset is inferred). While FL itself offers privacy-preserving attributes, the security robustness depends largely on the implementation and deployment methodologies. A recent survey on the topic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> presents a comprehensive study on the current security and privacy concerning aspects with the conclusion that fewer privacy-specific threats than security-specific ones exist. Among these are, e.g., communication bottlenecks, poisoning, and backdoor attacks, especially inference-based ones.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Federated and Distributed Reinforcement Learning</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Multi-agent RL is regarded as essential to realize general intelligence and cooperative environment learning. The main objective of a multi-agent RL is to obtain the localized policies and maximize the global reward for knowledge sharing on the premise of increased system complexity and computation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. In multi-robot systems, distributed RL can be leveraged to expose different robots to different environments, or to learn more robust policies in the presence of disturbances <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">While the literature in distributed RL is extensive, most works rely on sharing raw experiences or training in a centralized manner. Federated RL (FRL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> has been proposed as an efficient solution for achieving high-quality policy transfer with the protection of both data and model privacy. FRL can be applied, e.g., to understand user behavior and adapt to it <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, FRL was proposed to allow multiple RL agents to learn optimal control policies for a series of IoT devices with slightly different dynamics. In another direction, FRL is regarded as an efficient method for resource allocation among networked devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Recent Trends in Federated Learning</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">Federated learning has arguably raised the possibilities for collaborative learning across multiple independent agents. In this section, we give an overview of works that have focused towards improving specific aspects of FL.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">With a focus on scalability, a high-level designed FL system based on TensorFlow has been developed that draws significant conclusions on existing challenges and future research directions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. From the perspective of system security, a systematic study of Byzantine-robust federated learning in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> shows different approaches to secure FL systems and make them more robust against local model poisoning attacks. A similar approach in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, instead considers a solution to detect the malicious model updates in every round of training process before aggregating the locals models in the centralized cloud server. Owing to a wide range of approaches relying on a the centralized cloud server for aggregation of local model updates, FL frameworks may fail if a malicious aggregation server takes over the central FL node. To cope with this problem, dispersed FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> has been proposed, where a global model is yielded in either a centralized or distributed manner through the aggregation of sub-global models, which are iteratively computed based on different groups similar to traditional FL approaches.</p>
</div>
<div id="S2.SS5.p3" class="ltx_para">
<p id="S2.SS5.p3.1" class="ltx_p">Machine learning itself can also play a role in improving the performance of FL systems. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, deep reinforcement learning is used to select the optimized edge nodes and the learned model parameters are integrated into a blockchain-based FL scheme for enhanced security and reliability. Furthermore, combining with other privacy-preserving machine learning methods such as differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> and modern cryptography techniques such as homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, FL can achieve high level privacy-preserving and secure capabilities.</p>
</div>
<div id="S2.SS5.p4" class="ltx_para">
<p id="S2.SS5.p4.1" class="ltx_p">It is also worth meaning at this point that FL solutions are specialized in aggregating local models to a global model for knowledge sharing. Nonetheless, in terms of the characterization of heterogeneous data collected across large-scale deployments of edge devices, it is often essential to the application to make the models discriminative in each device. In this direction, personalized FL was proposed to tackle the aforementioned problem by further performing a series of learning steps locally after receiving the global model from the cloud server, based mostly on locally available data for which the model needs to be tailored <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated Learning at the Edge</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Federated learning has emerged within the wider edge computing paradigm. Deploying FL at the edge has gained significant attention from the research community owing to the availability of rapidly increasing amounts of data and computational resources at the edge. Research directions include the deployment FL in resource constrained embedded systems, communication-efficient FL, energy-efficient FL and privacy-preserving federated edge learning with the aim to improve the learning performance in networks where the general assumption is that resources are inherently at the edge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. For instance, an early work explored how to capitalize on FL to optimize the caching scheme in edge computing process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Task Allocation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">A general problem in distributed systems is task allocation. Learning more efficient task allocation at the edge can produce more effective strategies for worker selection and load distribution. Doing so through a distributed FL framework is a natural fit to such systems. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, a matching-theoretic approach was proposed for task assignments schemes in federated edge learning framework to solve the task assignment problem between the workers and multiple task publishers with efficient performance. In another work, an asynchronous task allocation method was introduced to realize equal task allocation within the FL system itself, i.e., minimizing the maximum difference between the number of model updates done by every worker in a FL edge network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Communication and Energy Efficiency</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Multiple studies in the literature focus on mitigating the bottleneck that communication latency can become in FL systems. Some of the proposed solutions involve the aggregation over the air of multiple updates from an analog perspective, rather than relying on conventional orthogonal network access <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. In a similar direction, and to mitigate the communication overhead, authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> introduced an asynchronous communication model for digital twin edge networks. In their work, FL is formulated as an optimization problem that aims at reducing the communication cost by decomposing it and using DNN for communication resource allocation. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, compression techniques were utilized to realize a more communication-efficient FL solution.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Regarding to energy efficiency of FL, authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> tackled the problem of improving the energy efficiency of FL by developing a convergence-guaranteed algorithm with flexible communication compression. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, two transmission protocols based on the non orthogonal multiple access and time division multiple access were considered to jointly optimizing the transmission power and rate at edge devices in a federated edge learning system. Other authors showed that learning an optimal resource-management policy substantial energy can be reduced in a FL system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Client Selection</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Client selection is a process to choose model updates from certain clients to be aggregated, especially when computational resources are constrained and complex aggregation processes are not possible. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, a framework named FedCS (Federated Client Selection) was introduced to dynamically select and maximize the number of clients (training agents) in heterogeneous edge networks. The dynamic approach was based on an online estimation of actively available resources. The results show that such approach can provide significant better training performance with heterogeneity of resources across clients, with overall significantly shorter training times than traditional FL methods. In another work, an optimization algorithm is designed to jointly optimize the data sampling and user selection strategies, which is shown to approach to the stationary optimal solution efficiently <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Privacy-Preserving and Secure Mechanisms</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">While FL is flexible in nature and inherently deals with issues related to data ownership and governance, it does guarantee privacy and security by itself. Integration of other techniques and approaches to data security and user privacy needs to be considered to achieve a robust FL framework. For instance, an asynchronous FL system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> with the incorporation of local differential privacy for enhanced privacy of local modes updates has been proposed in the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.
To tackle the problem of active poisoning attacks, which FL is vulnerable to, authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> generated a model for different poisoning attacks based on generative adversarial networks (GANs). Utilizing GANs, which is a well established approach in DL research, opens the door to more robust FL systems.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Synergies between Federated Learning and Distributed Ledger Technologies</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Distributed ledger technologies have multiple applications in multi-robot systems and distributed autonomous systems. Blockchain technology, in particular, has been applied to robot swarms able to deal with byzantine agents <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, for sharing computational and communication resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, but also for privacy-critical applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. The distributed consensus algorithms in DLTs, the auditability of operations and the built-in encryption, among others, aid in designing more secure and privacy-preserving systems at the edge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. Blockchain technology and subsequent DLT solutions can be thus leveraged as the basis for trust and credibility in a distributed system.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Traditional FL approaches rely on a centralized cloud server for model aggregation, therefore assuming such central node has full trust from the rest of the system. In practice, the reliance on the cloud server and the transmission to the local clients can be threatened by various types malicious attacks. Additionally, the scalability of the system is inherently limited by the existence of the single processing node. Even if it is replicated in the cloud, there is still a strong reliance on trusted cloud servers. Therefore, being able to deploy trustable FL frameworks in a distributed and decentralized manner can take FL to new application domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">The literature on applications of DLTs and FL for robotic systems is sparse. At present, studies on applications of blockchain-enhanced FL mainly focus on autonomous vehicles and the Internet of Vehicles (IoVs). The core objective of these is studies is to build a trustworthy vehicular network without any centralized training process or trusted third party. In this direction,
blockchain-supported FL has been proposed to build a trustworthy vehicular network. with performance metrics including accuracy, energy consumption, and lifetime rate, along with throughput and latency evaluated by simulation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. It is worth mentioning as well that a hierarchical blockchain based FL has also proved to be efficient in building towards large-scale vehicular networks and shown potential resilience against certain malicious attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. In another work, an autonomous blockchain enabled FL has been proposed to add further privacy-preserving properties and efficient local on-vehicle machine learning model aggregation in a decentralized manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. The authors indicate some key challenges of the proposed framework in the autonomous vehicles field including sophisticated mobility models, mobility-aware and efficient verification, or privacy leakage risk analysis.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">Other examples of blockchain-enhanced FL include drones in 6G networks and control in railway systems. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, with the objective of replacing the manual fraction and braking operations with automatic operations in a heavy haul railway system, blockchain-based FL was utilized to obtain a novel ML model for intelligent control under the circumstance of the imbalanced fraction and braking data. One approach to build the foundations for the upcoming 6G era, a blockchain-based empowered FL with the applications of mobile miners at drones has been proposed for a disaster response system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. In this work, the authors mainly focused on the definition of frameworks and analysis of blockchain latency and energy consumption.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Applications of FL In Robotic and Autonomous System</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Networked robotic and autonomous systems are becoming ubiquitous. These agents are in turn increasingly heterogeneous in terms of their computational capabilities but also the type of data they produce. With the wider availability of unprecedented amounts of data, deep learning has been broadly employed across autonomous robots of all types. Cloud robotics unlocks for robotic and autonomous systems access to potentially unlimited computational, memory or storage resources, partially avoiding the limitations of onboard resources. Cloud robotics also offers the use of the internet for massive parallel computing and resource sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. At the same time, autonomous robotic solutions have been adopted across a growing number of industries and application domains. These include data-sensitive scenarios such as hospitals, military bases or hotels. On account of features ranging from privacy preservation, decentralized reliability, minimal communication and focus on on-board computation, it is arguable that federated learning has potential to be a secure and efficient robot learning framework in and it will be further adopted across different types of autonomous systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">From a system-level perspective, different nomenclatures are used to define the paradigm of shared computation across and between cloud and edge. In this area, fog robotics has been introduced as the paradigm of deploying robot deep learning across shared computational, storage, and networking resources between cloud and edge in a federated way. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>, the authors evaluated the performance of the designed fog robotics system through a surface decluttering application with object recognition approaches. They trained the deep models in the cloud server based on the non-private images, adapted and deployed the model based on the real world images on the edge side to reduce the round-trip communication cost. In another application of fog robotics, blockchain-based FL has been proposed for autonomous vehicles which enables a communication network where on-vehicle machine learning model are verified and exchanged in a distributed and privacy-aware fashion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. The authors evaluate the performance of generation delay, block propagation, and upload-download delay, showing promising applications of such frameworks.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Federated learning has potential within multiple specific autonomy problems and robotic subsystems. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, cooperative SLAM based on visual-Lidar have been proposed by deploying a federated deep learning algorithm for feature extraction and dynamic map fusion without transferring original images among the robots. In the area of dynamic map fusion, authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> developed a novel fusion scheme among the networked vehicles supported by FL. Superior performance and robustness were then demonstrated in the Car Learning to Act (CARLA) simulation platform. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>, trajectories forecasting (spatio-temporal predictions) has been performed in a multi-robot system through different FL variants: traditional FL approach where a cloud server aggregates the local models and serverless version. In the paper, the authors found that in a trajectories forecasting task, the results of the above methods are not notably different and they provided the first federated learning dataset obtained from multi-robot behaviors. FL has also proven to be an efficient and novel framework in heterogeneous sensor data fusion for imitation learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>. In terms of situational awareness, continuous learning has been demonstrated to be feasible through FL as a framework across computationally limited edge devices while enabling the post-deployment of learned models in inference-only mode <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, FRL was applied to learn an optimal control policy among multiple IoT autonomous devices of the same type.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, the authors introduced a FL-based online reinforcement transfer learning process for real-time perception, with a demonstration through a collision avoidance system simulated in Airsim. From a more general autonomous navigation perspective, planning modules in cloud robotic systems can utilize federated reinforcement learning as a learning architecture for fusing prior knowledge and quickly adapting to new environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">In the area of human-robot collaborative learning, a novel cognitive architecture based on FL was introduced for multi-agent learning from demonstration (LfD) with multiple humans incorporated in the self robot learning loop <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. In a subsequent study, the authors integrated the short- and long-term analysis of human behavior within their cognitive robot learning architecture to show that it can adaptively enhance large-scale multi-agent LfD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">FL offers advantageous solutions to collaborative learning in decentralized multi-robot systems and distributed autonomous systems. FL will play a key role in networked ubiquitous robots and autonomous intelligent systems at the edge. The vast and rapidly growing amount of research in the area is revealing the efficiency and applicability of FL in various solutions.The key advantages of FL solutions include the optimization of networking resources, resilience through decentralization, and inherent privacy-preserving properties by processing data directly at the edge.
We have also reviewed DLT-empowered FL, with DLTs in general having drawn significant attention in the robotics domain in recent years. DLT solutions, and blockchain technology in particular, can be the backbone of decentralized local model aggregation in a more privacy-preserving, secure, and distributed manner. Some of the most prominent results are being shown in the era of the internet of vehicles, set to become increasingly important with the wider adoption of 5G and beyond mobile connectivity solutions.
In summary, FL has multiple application possibilities in autonomous systems, either from a system-level perspective or within specific subsystems in, e.g., autonomous robots. Key research directions that need further exploration include optimization of communication, energy-efficiency at the edge, personalized FL, and further privacy and security enhancements. Research efforts are currently capitalizing on multidisciplinary approaches including modern encryption, novel connectivity topologies or new learning paradigms.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Weisong Shi, Jie Cao, Quan Zhang, Youhuizi Li, and Lanyu Xu.

</span>
<span class="ltx_bibblock">Edge computing: Vision and challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">IEEE internet of things journal</span>, 3(5):637–646, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Jorge Peña Queralta, Tuan Nguyen Gia, Hannu Tenhunen, and Tomi
Westerlund.

</span>
<span class="ltx_bibblock">Edge-ai in lora-based health monitoring: Fall detection system with
fog computing and lstm recurrent neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">2019 42nd international conference on telecommunications and
signal processing (TSP)</span>, pages 601–604. IEEE, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Aly Metwaly, Jorge Peña Queralta, Victor Kathan Sarker, Tuan Nguyen Gia,
Omar Nasir, and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Edge computing with embedded ai: Thermal image analysis for occupancy
estimation in intelligent buildings.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proceedings of the INTelligent Embedded Systems Architectures
and Applications Workshop 2019</span>, pages 1–6, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</span>,
10(2):1–19, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Yi Liu, Xingliang Yuan, Zehui Xiong, Jiawen Kang, Xiaofei Wang, and Dusit
Niyato.

</span>
<span class="ltx_bibblock">Federated learning for 6g communications: Challenges, methods, and
future directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">China Communications</span>, 17(9):105–118, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Ben Kehoe, Sachin Patil, Pieter Abbeel, and Ken Goldberg.

</span>
<span class="ltx_bibblock">A survey of research on cloud robotics and automation.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on automation science and engineering</span>,
12(2):398–409, 2015.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Robert Bogue.

</span>
<span class="ltx_bibblock">Cloud robotics: a review of technologies, developments and
applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Industrial Robot: An International Journal</span>, 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Cynthia Matuszek.

</span>
<span class="ltx_bibblock">Grounded language learning: Where robotics and nlp meet (invited
talk).

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the International Joint Conference on
Artificial Intelligence</span>, 2018.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Javier Ruiz-del Solar, Patricio Loncomilla, and Naiomi Soto.

</span>
<span class="ltx_bibblock">A survey on deep learning methods for robot vision.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1803.10862</span>, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Haoran Li, Qichao Zhang, and Dongbin Zhao.

</span>
<span class="ltx_bibblock">Deep reinforcement learning-based automatic exploration for
navigation in unknown environment.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">IEEE transactions on neural networks and learning systems</span>,
31(6):2064–2076, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Kun Shao, Zhentao Tang, Yuanheng Zhu, Nannan Li, and Dongbin Zhao.

</span>
<span class="ltx_bibblock">A survey of deep reinforcement learning in video games.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.10944</span>, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Aravind Rajeswaran, Vikash Kumar, Abhishek Gupta, Giulia Vezzani, John
Schulman, Emanuel Todorov, and Sergey Levine.

</span>
<span class="ltx_bibblock">Learning complex dexterous manipulation with deep reinforcement
learning and demonstrations.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1709.10087</span>, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina Precup,
and David Meger.

</span>
<span class="ltx_bibblock">Deep reinforcement learning that matters.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</span>, volume 32, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Viraaji Mothukuri, Reza M Parizi, Seyedamin Pouriyeh, Yan Huang, Ali
Dehghantanha, and Gautam Srivastava.

</span>
<span class="ltx_bibblock">A survey on security and privacy of federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Future Generation Computer Systems</span>, 115:619–640, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant.

</span>
<span class="ltx_bibblock">Survey of personalization techniques for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">2020 Fourth World Conference on Smart Trends in Systems,
Security and Sustainability (WorldS4)</span>, pages 794–797. IEEE, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Wei Yang Bryan Lim, Nguyen Cong Luong, Dinh Thai Hoang, Yutao Jiao, Ying-Chang
Liang, Qiang Yang, Dusit Niyato, and Chunyan Miao.

</span>
<span class="ltx_bibblock">Federated learning in mobile edge networks: A comprehensive survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</span>, 22(3):2031–2063,
2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Wuhui Chen, Yuichi Yaguchi, Keitaro Naruse, Yutaka Watanobe, Keita Nakamura,
and Jun Ogawa.

</span>
<span class="ltx_bibblock">A study of robotic cooperation in cloud robotics: Architecture and
challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 6:36662–36682, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Hehua Yan, Qingsong Hua, Yingying Wang, Wenguo Wei, and Muhammad Imran.

</span>
<span class="ltx_bibblock">Cloud robotics in smart manufacturing environments: Challenges and
countermeasures.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Computers &amp;amp; Electrical Engineering</span>, 63:56–65, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
AWS.

</span>
<span class="ltx_bibblock">Aws robomaker.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aws.amazon.com/robomaker/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aws.amazon.com/robomaker/</a>.

</span>
<span class="ltx_bibblock">[Online] - Last access: 2021-04-09.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
AUTOLAB: UC Berkeley Automation Lab.

</span>
<span class="ltx_bibblock">Dex-net.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://berkeleyautomation.github.io/dex-net/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://berkeleyautomation.github.io/dex-net/</a>.

</span>
<span class="ltx_bibblock">[Online] - Last access: 2021-04-09.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">Google cloud robotics.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://googlecloudrobotics.github.io/core/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://googlecloudrobotics.github.io/core/</a>.

</span>
<span class="ltx_bibblock">[Online] - Last access: 2021-04-09.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Eric P Xing, Qirong Ho, Wei Dai, Jin Kyu Kim, Jinliang Wei, Seunghak Lee, Xun
Zheng, Pengtao Xie, Abhimanu Kumar, and Yaoliang Yu.

</span>
<span class="ltx_bibblock">Petuum: A new platform for distributed machine learning on big data.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Big Data</span>, 1(2):49–67, 2015.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Zhenheng Tang, Shaohuai Shi, Xiaowen Chu, Wei Wang, and Bo Li.

</span>
<span class="ltx_bibblock">Communication-efficient distributed deep learning: A comprehensive
survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.06307</span>, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Mahmoud Assran, Nicolas Loizou, Nicolas Ballas, and Mike Rabbat.

</span>
<span class="ltx_bibblock">Stochastic gradient push for distributed deep learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
344–353. PMLR, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Huaming Wu, Ziru Zhang, Chang Guan, Katinka Wolter, and Minxian Xu.

</span>
<span class="ltx_bibblock">Collaborate edge and cloud computing with distributed deep learning
for smart city internet of things.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 7(9):8099–8110, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Haotian Jiang, James Starkman, Yu-Ju Lee, Huan Chen, Xiaoye Qian, and Ming-Chun
Huang.

</span>
<span class="ltx_bibblock">Distributed deep learning optimized system over the cloud and smart
phone devices.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Mobile Computing</span>, 20(1):147–161, 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Yitao Chen, Kaiqi Zhao, Baoxin Li, and Ming Zhao.

</span>
<span class="ltx_bibblock">Exploring the use of synthetic gradients for distributed deep
learning across cloud and edge resources.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.2.2" class="ltx_text ltx_font_italic">2nd <math id="bib.bib27.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib27.1.1.m1.1a"><mo stretchy="false" id="bib.bib27.1.1.m1.1.1" xref="bib.bib27.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib27.1.1.m1.1b"><ci id="bib.bib27.1.1.m1.1.1.cmml" xref="bib.bib27.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib27.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib27.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib27.2.2.m2.1a"><mo stretchy="false" id="bib.bib27.2.2.m2.1.1" xref="bib.bib27.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib27.2.2.m2.1b"><ci id="bib.bib27.2.2.m2.1.1.cmml" xref="bib.bib27.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib27.2.2.m2.1c">\}</annotation></semantics></math> Workshop on Hot Topics in Edge Computing
(HotEdge 19)</span>, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Shaohuai Shi, Xianhao Zhou, Shutao Song, Xingyao Wang, Zilin Zhu, Xue Huang,
Xinan Jiang, Feihu Zhou, Zhenyu Guo, Liqiang Xie, et al.

</span>
<span class="ltx_bibblock">Towards scalable distributed training of deep learning on public
cloud clusters.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine Learning and Systems</span>, 3, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Yiran Li, Hongwei Li, Guowen Xu, Tao Xiang, Xiaoming Huang, and Rongxing Lu.

</span>
<span class="ltx_bibblock">Toward secure and privacy-preserving distributed deep learning in
fog-cloud computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 7(12):11460–11472, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Davit Buniatyan.

</span>
<span class="ltx_bibblock">Hyper: Distributed cloud processing for large-scale deep learning
tasks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">2019 Computer Science and Information Technologies (CSIT)</span>,
pages 27–32. IEEE, 2019.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Jia Duan, Jiantao Zhou, and Yuanman Li.

</span>
<span class="ltx_bibblock">Privacy-preserving distributed deep learning based on secret sharing.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Information Sciences</span>, 527:108–127, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Yitian Zhang, Hojjat Salehinejad, Joseph Barfett, Errol Colak, and Shahrokh
Valaee.

</span>
<span class="ltx_bibblock">Privacy preserving deep learning with distributed encoders.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">2019 IEEE Global Conference on Signal and Information
Processing (GlobalSIP)</span>, pages 1–5. IEEE, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Praneeth Vepakomma, Otkrist Gupta, Abhimanyu Dubey, and Ramesh Raskar.

</span>
<span class="ltx_bibblock">Reducing leakage in distributed deep learning for sensitive health
data.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.00564</span>, 2019.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Jianguo Chen, Kenli Li, Qingying Deng, Keqin Li, and S Yu Philip.

</span>
<span class="ltx_bibblock">Distributed deep learning model for intelligent video surveillance
systems with edge computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 2019.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Niranjan Balachandar, Ken Chang, Jayashree Kalpathy-Cramer, and Daniel L Rubin.

</span>
<span class="ltx_bibblock">Accounting for data variability in multi-institutional distributed
deep learning for medical imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Journal of the American Medical Informatics Association</span>,
27(5):700–708, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Ho Bae, Jaehee Jang, Dahuin Jung, Hyemi Jang, Heonseok Ha, and Sungroh Yoon.

</span>
<span class="ltx_bibblock">Security and privacy issues in deep learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1807.11655</span>, 2018.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Georgios A Kaissis, Marcus R Makowski, Daniel Rückert, and Rickmer F
Braren.

</span>
<span class="ltx_bibblock">Secure, privacy-preserving and federated machine learning in medical
imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, 2(6):305–311, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Wenshuai Zhao, Jorge Peña Queralta, and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Sim-to-real transfer in deep reinforcement learning for robotics: a
survey.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">2020 IEEE Symposium Series on Computational Intelligence
(SSCI)</span>, pages 737–744. IEEE, 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Wenshuai Zhao, Jorge Peña Queralta, Li Qingqing, and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Towards closing the sim-to-real gap in collaborative multi-robot deep
reinforcement learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">2020 5th International Conference on Robotics and Automation
Engineering (ICRAE)</span>, pages 7–12. IEEE, 2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Wenshuai Zhao, Jorge Peña Queralta, Li Qingqing, and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Ubiquitous distributed deep reinforcement learning at the edge:
Analyzing byzantine agents in discrete action spaces.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Procedia Computer Science</span>, 177:324–329, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Hankz Hankui Zhuo, Wenfeng Feng, Qian Xu, Qiang Yang, and Yufeng Lin.

</span>
<span class="ltx_bibblock">Federated reinforcement learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1901.08277</span>, 1, 2019.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Chetan Nadiger, Anil Kumar, and Sherine Abdelhak.

</span>
<span class="ltx_bibblock">Federated reinforcement learning for fast personalization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">2019 IEEE Second International Conference on Artificial
Intelligence and Knowledge Engineering (AIKE)</span>, pages 123–127. IEEE, 2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Lihua Ruan, Sourav Mondal, Imali Dias, and Elaine Wong.

</span>
<span class="ltx_bibblock">Low-latency federated reinforcement learning-based resource
allocation in converged access networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Optical Fiber Communication Conference</span>, pages W2A–28.
Optical Society of America, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Huy T Nguyen, Nguyen Cong Luong, Jun Zhao, Chau Yuen, and Dusit Niyato.

</span>
<span class="ltx_bibblock">Resource allocation in mobility-aware federated learning networks: a
deep reinforcement learning approach.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">2020 IEEE 6th World Forum on Internet of Things (WF-IoT)</span>,
pages 1–6. IEEE, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečnỳ, Stefano
Mazzocchi, H Brendan McMahan, et al.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1902.01046</span>, 2019.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Gong.

</span>
<span class="ltx_bibblock">Local model poisoning attacks to byzantine-robust federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.4.4" class="ltx_text ltx_font_italic">29th <math id="bib.bib46.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib46.1.1.m1.1a"><mo stretchy="false" id="bib.bib46.1.1.m1.1.1" xref="bib.bib46.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib46.1.1.m1.1b"><ci id="bib.bib46.1.1.m1.1.1.cmml" xref="bib.bib46.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib46.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib46.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib46.2.2.m2.1a"><mo stretchy="false" id="bib.bib46.2.2.m2.1.1" xref="bib.bib46.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib46.2.2.m2.1b"><ci id="bib.bib46.2.2.m2.1.1.cmml" xref="bib.bib46.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib46.2.2.m2.1c">\}</annotation></semantics></math> Security Symposium (<math id="bib.bib46.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib46.3.3.m3.1a"><mo stretchy="false" id="bib.bib46.3.3.m3.1.1" xref="bib.bib46.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib46.3.3.m3.1b"><ci id="bib.bib46.3.3.m3.1.1.cmml" xref="bib.bib46.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib46.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib46.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib46.4.4.m4.1a"><mo stretchy="false" id="bib.bib46.4.4.m4.1.1" xref="bib.bib46.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib46.4.4.m4.1b"><ci id="bib.bib46.4.4.m4.1.1.cmml" xref="bib.bib46.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib46.4.4.m4.1c">\}</annotation></semantics></math>
Security 20)</span>, pages 1605–1622, 2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Suyi Li, Yong Cheng, Wei Wang, Yang Liu, and Tianjian Chen.

</span>
<span class="ltx_bibblock">Learning to detect malicious clients for robust federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.00211</span>, 2020.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Latif U Khan, Walid Saad, Zhu Han, and Choong Seon Hong.

</span>
<span class="ltx_bibblock">Dispersed federated learning: Vision, taxonomy, and future
directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2008.05189</span>, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan Zhang.

</span>
<span class="ltx_bibblock">Blockchain empowered asynchronous federated learning for secure data
sharing in internet of vehicles.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Vehicular Technology</span>, 69(4):4298–4311,
2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin,
Tony QS Quek, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy: Algorithms and
performance analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Information Forensics and Security</span>,
15:3454–3469, 2020.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Chengliang Zhang, Suyi Li, Junzhe Xia, Wei Wang, Feng Yan, and Yang Liu.

</span>
<span class="ltx_bibblock">Batchcrypt: Efficient homomorphic encryption for cross-silo federated
learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.6.6" class="ltx_text ltx_font_italic">2020 <math id="bib.bib51.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib51.1.1.m1.1a"><mo stretchy="false" id="bib.bib51.1.1.m1.1.1" xref="bib.bib51.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib51.1.1.m1.1b"><ci id="bib.bib51.1.1.m1.1.1.cmml" xref="bib.bib51.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib51.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib51.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib51.2.2.m2.1a"><mo stretchy="false" id="bib.bib51.2.2.m2.1.1" xref="bib.bib51.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib51.2.2.m2.1b"><ci id="bib.bib51.2.2.m2.1.1.cmml" xref="bib.bib51.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib51.2.2.m2.1c">\}</annotation></semantics></math> Annual Technical Conference
(<math id="bib.bib51.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib51.3.3.m3.1a"><mo stretchy="false" id="bib.bib51.3.3.m3.1.1" xref="bib.bib51.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib51.3.3.m3.1b"><ci id="bib.bib51.3.3.m3.1.1.cmml" xref="bib.bib51.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib51.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib51.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib51.4.4.m4.1a"><mo stretchy="false" id="bib.bib51.4.4.m4.1.1" xref="bib.bib51.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib51.4.4.m4.1b"><ci id="bib.bib51.4.4.m4.1.1.cmml" xref="bib.bib51.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib51.4.4.m4.1c">\}</annotation></semantics></math><math id="bib.bib51.5.5.m5.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib51.5.5.m5.1a"><mo stretchy="false" id="bib.bib51.5.5.m5.1.1" xref="bib.bib51.5.5.m5.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib51.5.5.m5.1b"><ci id="bib.bib51.5.5.m5.1.1.cmml" xref="bib.bib51.5.5.m5.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib51.5.5.m5.1c">\{</annotation></semantics></math>ATC<math id="bib.bib51.6.6.m6.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib51.6.6.m6.1a"><mo stretchy="false" id="bib.bib51.6.6.m6.1.1" xref="bib.bib51.6.6.m6.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib51.6.6.m6.1b"><ci id="bib.bib51.6.6.m6.1.1.cmml" xref="bib.bib51.6.6.m6.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib51.6.6.m6.1c">\}</annotation></semantics></math> 20)</span>, pages 493–506, 2020.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi.

</span>
<span class="ltx_bibblock">Adaptive personalized federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.13461</span>, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.

</span>
<span class="ltx_bibblock">Personalized federated learning: A meta-learning approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2002.07948</span>, 2020.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian
Makaya, Ting He, and Kevin Chan.

</span>
<span class="ltx_bibblock">Adaptive federated learning in resource constrained edge computing
systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">IEEE Journal on Selected Areas in Communications</span>,
37(6):1205–1221, 2019.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Zhengxin Yu, Jia Hu, Geyong Min, Haochuan Lu, Zhiwei Zhao, Haozhe Wang, and
Nektarios Georgalas.

</span>
<span class="ltx_bibblock">Federated learning based proactive content caching in edge computing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">2018 IEEE Global Communications Conference (GLOBECOM)</span>, pages
1–6. IEEE, 2018.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Jiawen Kang, Zehui Xiong, Dusit Niyato, Zhiguang Cao, and Amir Leshem.

</span>
<span class="ltx_bibblock">Training task allocation in federated edge learning: A
matching-theoretic approach.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">2020 IEEE 17th Annual Consumer Communications &amp;amp;
Networking Conference (CCNC)</span>, pages 1–6. IEEE, 2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Umair Mohammad and Sameh Sorour.

</span>
<span class="ltx_bibblock">Adaptive task allocation for asynchronous federated mobile edge
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1905.01656</span>, 2019.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Guangxu Zhu, Yong Wang, and Kaibin Huang.

</span>
<span class="ltx_bibblock">Broadband analog aggregation for low-latency federated edge learning
(extended version).

</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.11494</span>, 2018.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan Zhang.

</span>
<span class="ltx_bibblock">Communication-efficient federated learning for digital twin edge
networks in industrial iot.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 2020.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Jed Mills, Jia Hu, and Geyong Min.

</span>
<span class="ltx_bibblock">Communication-efficient federated learning for wireless edge
intelligence in iot.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 7(7):5986–5994, 2019.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Liang Li, Dian Shi, Ronghui Hou, Hui Li, Miao Pan, and Zhu Han.

</span>
<span class="ltx_bibblock">To talk or to work: Flexible communication compression for energy
efficient federated learning over heterogeneous mobile edge devices.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.11804</span>, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Xiaopeng Mo and Jie Xu.

</span>
<span class="ltx_bibblock">Energy-efficient federated edge learning with joint communication and
computation design.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2003.00199</span>, 2020.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Qunsong Zeng, Yuqing Du, Kaibin Huang, and Kin K Leung.

</span>
<span class="ltx_bibblock">Energy-efficient radio resource allocation for federated edge
learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">2020 IEEE International Conference on Communications
Workshops (ICC Workshops)</span>, pages 1–6. IEEE, 2020.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Takayuki Nishio and Ryo Yonetani.

</span>
<span class="ltx_bibblock">Client selection for federated learning with heterogeneous resources
in mobile edge.

</span>
<span class="ltx_bibblock">In <span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">ICC 2019-2019 IEEE International Conference on Communications
(ICC)</span>, pages 1–7. IEEE, 2019.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Chenyuan Feng, Yidong Wang, Zhongyuan Zhao, Tony QS Quek, and Mugen Peng.

</span>
<span class="ltx_bibblock">Joint optimization of data sampling and user selection for federated
learning in the mobile edge computing systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">2020 IEEE International Conference on Communications
Workshops (ICC Workshops)</span>, pages 1–6. IEEE, 2020.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Xiaofeng Lu, Yuying Liao, Pietro Lio, and Pan Hui.

</span>
<span class="ltx_bibblock">Privacy-preserving asynchronous federated learning mechanism for edge
network computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 8:48970–48981, 2020.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Yunlong Lu, Xiaohong Huang, Yueyue Dai, Sabita Maharjan, and Yan Zhang.

</span>
<span class="ltx_bibblock">Differentially private asynchronous federated learning for mobile
edge computing in urban informatics.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 16(3):2134–2143,
2019.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Jiale Zhang, Bing Chen, Xiang Cheng, Huynh Thi Thanh Binh, and Shui Yu.

</span>
<span class="ltx_bibblock">Poisongan: Generative poisoning attacks against federated learning in
edge computing systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Eduardo Castelló Ferrer.

</span>
<span class="ltx_bibblock">The blockchain: a new framework for robotic swarm systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">Proceedings of the future technologies conference</span>, pages
1037–1058. Springer, 2018.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Jorge Peña Queralta and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Blockchain-powered collaboration in heterogeneous swarms of robots.

</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.01711</span>, 2019.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Anum Nawaz, Tuan Nguyen Gia, Jorge Peña Queralta, and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Edge ai and blockchain for privacy-critical and data-sensitive
applications.

</span>
<span class="ltx_bibblock">In <span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">2019 Twelfth International Conference on Mobile Computing and
Ubiquitous Network (ICMU)</span>, pages 1–2. IEEE, 2019.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Anum Nawaz, Jorge Peña Queralta, Jixin Guan, Muhammad Awais, Tuan Nguyen
Gia, Ali Kashif Bashir, Haibin Kan, and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Edge computing to secure iot data ownership and trade with the
ethereum blockchain.

</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">Sensors</span>, 20(14):3965, 2020.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Jorge Peña Queralta and Tomi Westerlund.

</span>
<span class="ltx_bibblock">Blockchain for mobile edge computing: Consensus mechanisms and
scalability.

</span>
<span class="ltx_bibblock"><span id="bib.bib73.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.07578</span>, 2020.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Dinh C Nguyen, Ming Ding, Quoc-Viet Pham, Pubudu N Pathirana, Long Bao Le,
Aruna Seneviratne, Jun Li, Dusit Niyato, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Federated learning meets blockchain in edge computing: Opportunities
and challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.01776</span>, 2021.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Xianglin Bao, Cheng Su, Yan Xiong, Wenchao Huang, and Yifei Hu.

</span>
<span class="ltx_bibblock">Flchain: A blockchain for auditable federated learning with trust and
incentive.

</span>
<span class="ltx_bibblock">In <span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">2019 5th International Conference on Big Data Computing and
Communications (BIGCOM)</span>, pages 151–159. IEEE, 2019.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Umer Majeed and Choong Seon Hong.

</span>
<span class="ltx_bibblock">Flchain: Federated learning via mec-enabled blockchain network.

</span>
<span class="ltx_bibblock">In <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">2019 20th Asia-Pacific Network Operations and Management
Symposium (APNOMS)</span>, pages 1–4. IEEE, 2019.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Safa Otoum, Ismaeel Al Ridhawi, and Hussein T Mouftah.

</span>
<span class="ltx_bibblock">Blockchain-supported federated learning for trustworthy vehicular
networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">GLOBECOM 2020-2020 IEEE Global Communications Conference</span>,
pages 1–6. IEEE, 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Haoye Chai, Supeng Leng, Yijin Chen, and Ke Zhang.

</span>
<span class="ltx_bibblock">A hierarchical blockchain-enabled federated learning algorithm for
knowledge sharing in internet of vehicles.

</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Intelligent Transportation Systems</span>, 2020.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Shiva Raj Pokhrel and Jinho Choi.

</span>
<span class="ltx_bibblock">Federated learning with blockchain for autonomous vehicles: Analysis
and design.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Hua Gaofeng, Li Zhu, Jinsong Wu, Chunzi Shen, Lingyan Zhou, and Qingqing Lin.

</span>
<span class="ltx_bibblock">Blockchain-based federated learning for intelligent control in heavy
haul railway.

</span>
<span class="ltx_bibblock">2020.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Shiva Raj Pokhrel.

</span>
<span class="ltx_bibblock">Federated learning meets blockchain at 6g edge: A drone-assisted
networking for disaster response.

</span>
<span class="ltx_bibblock">In <span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted
Wireless Communications for 5G and Beyond</span>, pages 49–54, 2020.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Ken Goldberg and Ben Kehoe.

</span>
<span class="ltx_bibblock">Cloud robotics and automation: A survey of related work.

</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">EECS Department, University of California, Berkeley, Tech. Rep.
UCB/EECS-2013-5</span>, 2013.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Stefano Savazzi, Monica Nicoli, Mehdi Bennis, Sanaz Kianoush, and Luca
Barbieri.

</span>
<span class="ltx_bibblock">Opportunities of federated learning in connected, cooperative and
automated industrial systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2101.03367</span>, 2021.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Ajay Kumar Tanwani, Nitesh Mor, John Kubiatowicz, Joseph E Gonzalez, and Ken
Goldberg.

</span>
<span class="ltx_bibblock">A fog robotics approach to deep robot learning: Application to object
recognition and grasp planning in surface decluttering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">2019 International Conference on Robotics and Automation
(ICRA)</span>, pages 4559–4566. IEEE, 2019.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Zhaoran Li, Lujia Wang, Lingxin Jiang, and Cheng-Zhong Xu.

</span>
<span class="ltx_bibblock">Fc-slam: Federated learning enhanced distributed visual-lidar slam in
cloud robotic system.

</span>
<span class="ltx_bibblock">In <span id="bib.bib85.1.1" class="ltx_text ltx_font_italic">2019 IEEE International Conference on Robotics and
Biomimetics (ROBIO)</span>, pages 1995–2000. IEEE, 2019.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Zijian Zhang, Shuai Wang, Yuncong Hong, Liangkai Zhou, and Qi Hao.

</span>
<span class="ltx_bibblock">Distributed dynamic map fusion via federated learning for intelligent
networked vehicles.

</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.03786</span>, 2021.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Nathalie Majcherczyk, Nishan Srishankar, and Carlo Pinciroli.

</span>
<span class="ltx_bibblock">Flow-fl: Data-driven federated learning for spatio-temporal
predictions in multi-robot systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib87.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2010.08595</span>, 2020.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Boyi Liu, Lujia Wang, Ming Liu, and Cheng-Zhong Xu.

</span>
<span class="ltx_bibblock">Federated imitation learning: A novel framework for cloud robotic
systems with heterogeneous sensor data.

</span>
<span class="ltx_bibblock"><span id="bib.bib88.1.1" class="ltx_text ltx_font_italic">IEEE Robotics and Automation Letters</span>, 5(2):3509–3516, 2020.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Carl E Busart III.

</span>
<span class="ltx_bibblock"><span id="bib.bib89.1.1" class="ltx_text ltx_font_italic">Federated Learning Architecture to Enable Continuous Learning at
the Tactical Edge for Situational Awareness</span>.

</span>
<span class="ltx_bibblock">PhD thesis, The George Washington University, 2020.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Xinle Liang, Yang Liu, Tianjian Chen, Ming Liu, and Qiang Yang.

</span>
<span class="ltx_bibblock">Federated transfer reinforcement learning for autonomous driving.

</span>
<span class="ltx_bibblock"><span id="bib.bib90.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1910.06001</span>, 2019.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Boyi Liu, Lujia Wang, and Ming Liu.

</span>
<span class="ltx_bibblock">Lifelong federated reinforcement learning: a learning architecture
for navigation in cloud robotic systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib91.1.1" class="ltx_text ltx_font_italic">IEEE Robotics and Automation Letters</span>, 4(4):4555–4562, 2019.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Georgios Th Papadopoulos, Margherita Antona, and Constantine Stephanidis.

</span>
<span class="ltx_bibblock">Towards open and expandable cognitive ai architectures for
large-scale multi-agent human-robot collaborative learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib92.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.08174</span>, 2020.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Georgios Th Papadopoulos, Asterios Leonidis, Margherita Antona, and Constantine
Stephanidis.

</span>
<span class="ltx_bibblock">User profile-driven large-scale multi-agent learning from
demonstration in federated human-robot collaborative environments.

</span>
<span class="ltx_bibblock"><span id="bib.bib93.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.16434</span>, 2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2104.10140" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2104.10141" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2104.10141">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2104.10141" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2104.10142" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 06:10:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
