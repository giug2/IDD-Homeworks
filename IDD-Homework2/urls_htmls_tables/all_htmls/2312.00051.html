<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.00051] MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning</title><meta property="og:description" content="The membership inference attack (MIA) is a popular paradigm for compromising the privacy of a machine learning (ML) model. MIA exploits the natural inclination of ML models to overfit upon the training data. MIAs are tâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.00051">

<!--Generated on Tue Feb 27 16:11:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Membership Inference Attack,  Privacy,  Security.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">

Soumya Banerjee1,
Sandip Roy1,
Sayyed Farid Ahamed1,
Devin Quinn2,
Marc Vucovich2,


Dhruv Nandakumar2,
Kevin Choi2,
Abdul Rahman2,
Edward Bowen2,
Sachin Shetty1
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
1Virginia Modeling, Analysis and Simulation Center, Old Dominion University, Virginia, USA

<br class="ltx_break">{s1banerj, sroy, saham001, sshetty}@odu.edu
</span>
<span class="ltx_contact ltx_role_affiliation">
2Deloitte &amp; Touche LLP

<br class="ltx_break">{devquinn, mvucovich, dnandakumar,kevchoi, abdulrahman, edbowen}@deloitte.com
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The membership inference attack (MIA) is a popular paradigm for compromising the privacy of a machine learning (ML) model. MIA exploits the natural inclination of ML models to overfit upon the training data. MIAs are trained to distinguish between training and testing prediction confidence to infer membership information.
Federated Learning (FL) is a privacy-preserving ML paradigm that enables multiple clients to train a unified model without disclosing their private data.
In this paper, we propose an enhanced Membership Inference Attack with the Batch-wise generated Attack Dataset (MIA-BAD), a modification to the MIA approach.
We investigate that the MIA is more accurate when the attack dataset is generated batch-wise. This quantitatively decreases the attack dataset while qualitatively improving it.
We show how training an ML model through FL, has some distinct advantages and investigate how the threat introduced with the proposed MIA-BAD approach can be mitigated with FL approaches.
Finally, we demonstrate the qualitative effects of the proposed MIA-BAD methodology by conducting extensive experiments with various target datasets, variable numbers of federated clients, and training batch sizes.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Membership Inference Attack, Privacy, Security.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent years, federated learning (FL) has emerged as a popular privacy-preserving machine learning (ML) paradigm, allowing multiple clients to collaboratively develop a unified and consolidated model while protecting their individual training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Unlike typical centralized ML, FL does not need users to send their original data to the centralized server, which might compromise usersâ€™ privacy and security. The basic procedure involves training localized models on individual client data, followed by the exchange of model updates among federated clients, and finally the building of a unified model that is shared by all clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Because collaborative learning doesnâ€™t involve sharing data, FL shows the potential to solve problems with data privacy and user privacy that are common in traditional centralized ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite the fact that FL is designed to secure personal information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, recent research has shown that FL models are vulnerable to attacks that leak critical training dataset information through source inference, model inversion, and reconstruction attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. In this paper, we focus on membership inference attacks (MIAs), which are aimed against the FL model, and attempt to infer whether or not the target sample was included in the modelâ€™s training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. MIAs that are successful may jeopardize the security of federated clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. For example, knowing the target sample may disclose the victimâ€™s condition and treatment history if an FL model is trained on data from different medical institutions<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. An attacker can launch a membership inference attack in a â€œBlack-Boxâ€ environment (Restrictive Knowledge of the model) by developing a binary attack model that, when fed the confidence score vector from the target model, returns the likelihood that the given data sample is part of the training dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<p id="S1.F1.1" class="ltx_p ltx_align_center"><span id="S1.F1.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;">
<img src="/html/2312.00051/assets/x1.png" id="S1.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="207" height="155" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Training procedure of an ML model, centrally vs FL. (a) Centrally or non-federated training of an ML model. (b) Training of an ML model in FL environment consisting of n clients. </figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Given a sample of data, MIA in FL detects its participation in the FL training process. A breach of privacy transpires when an adversary has any knowledge about the use of a certain data element for the purpose of training FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. For example, if the data includes device information, we may deduce if the device is participating in the FL training process, exposing the deviceâ€™s privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, our aim is twofold. Initially, we show how an adversary can more accurately launch MIA attack into FL models for various datasets and then develop new insights for resisting such attacks in FL environments. We demonstrate that the FL paradigm while providing only limited protection to MIA, has a distinct advantage in reducing the potency of the proposed MIA-BAD approach.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The main contributions of this paper are as follows:</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We demonstrate how federated training can reduce the potency of membership inference attacks and how the number of federated clients affects this result.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose a novel modification to the membership inference attacks paradigm, MIA-BAD, showing that the MIA is more accurate when the attack dataset is generated batch-wise.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We demonstrate how the attackerâ€™s advantage of the proposed MIA-BAD can be minimized with FL. Through detailed experiments with different target datasets, and a varying number of clients and batch sizes, we document the the qualitative effects of the proposed MIA-BAD approach.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The paper is organized as follows. In <a href="#S2" title="II Preliminary â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">section</span>Â <span class="ltx_text ltx_ref_tag">II</span></a>, we introduce the relevant theoretical background and present a brief literature survey. <a href="#S3" title="III Threat Model â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">III</span></a> defines the threat model and the attackerâ€™s goals, knowledge, and capabilities. <a href="#S4" title="IV Framework Overview â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>Â <span class="ltx_text ltx_ref_tag">IV</span></a> defines the framework for implementing the membership inference attack. We propose the MAI-BAD approach in <a href="#S5" title="V The MIA-BAD Approach â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">section</span>Â <span class="ltx_text ltx_ref_tag">V</span></a>. The experimental results are provided and analyzed in <a href="#S6" title="VI Performance Evaluation â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">section</span>Â <span class="ltx_text ltx_ref_tag">VI</span></a>. Finally, we conclude our work and discuss future research scope in <a href="#S7" title="VII Conclusion and future Scope â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">section</span>Â <span class="ltx_text ltx_ref_tag">VII</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Preliminary</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.9" class="ltx_p">FL is a decentralized ML training approach that allows multiple clients to collaboratively train a shared machine-learning model without accessing the local data of the clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. A conventional FL system consists of <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">n</annotation></semantics></math> federated clients (<math id="S2.SS1.p1.2.m2.5" class="ltx_Math" alttext="C_{1},C_{2},C_{3},...,C_{n}" display="inline"><semantics id="S2.SS1.p1.2.m2.5a"><mrow id="S2.SS1.p1.2.m2.5.5.4" xref="S2.SS1.p1.2.m2.5.5.5.cmml"><msub id="S2.SS1.p1.2.m2.2.2.1.1" xref="S2.SS1.p1.2.m2.2.2.1.1.cmml"><mi id="S2.SS1.p1.2.m2.2.2.1.1.2" xref="S2.SS1.p1.2.m2.2.2.1.1.2.cmml">C</mi><mn id="S2.SS1.p1.2.m2.2.2.1.1.3" xref="S2.SS1.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.2.m2.5.5.4.5" xref="S2.SS1.p1.2.m2.5.5.5.cmml">,</mo><msub id="S2.SS1.p1.2.m2.3.3.2.2" xref="S2.SS1.p1.2.m2.3.3.2.2.cmml"><mi id="S2.SS1.p1.2.m2.3.3.2.2.2" xref="S2.SS1.p1.2.m2.3.3.2.2.2.cmml">C</mi><mn id="S2.SS1.p1.2.m2.3.3.2.2.3" xref="S2.SS1.p1.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p1.2.m2.5.5.4.6" xref="S2.SS1.p1.2.m2.5.5.5.cmml">,</mo><msub id="S2.SS1.p1.2.m2.4.4.3.3" xref="S2.SS1.p1.2.m2.4.4.3.3.cmml"><mi id="S2.SS1.p1.2.m2.4.4.3.3.2" xref="S2.SS1.p1.2.m2.4.4.3.3.2.cmml">C</mi><mn id="S2.SS1.p1.2.m2.4.4.3.3.3" xref="S2.SS1.p1.2.m2.4.4.3.3.3.cmml">3</mn></msub><mo id="S2.SS1.p1.2.m2.5.5.4.7" xref="S2.SS1.p1.2.m2.5.5.5.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">â€¦</mi><mo id="S2.SS1.p1.2.m2.5.5.4.8" xref="S2.SS1.p1.2.m2.5.5.5.cmml">,</mo><msub id="S2.SS1.p1.2.m2.5.5.4.4" xref="S2.SS1.p1.2.m2.5.5.4.4.cmml"><mi id="S2.SS1.p1.2.m2.5.5.4.4.2" xref="S2.SS1.p1.2.m2.5.5.4.4.2.cmml">C</mi><mi id="S2.SS1.p1.2.m2.5.5.4.4.3" xref="S2.SS1.p1.2.m2.5.5.4.4.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.5b"><list id="S2.SS1.p1.2.m2.5.5.5.cmml" xref="S2.SS1.p1.2.m2.5.5.4"><apply id="S2.SS1.p1.2.m2.2.2.1.1.cmml" xref="S2.SS1.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.2.2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.2.2.1.1.2">ğ¶</ci><cn type="integer" id="S2.SS1.p1.2.m2.2.2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.2.2.1.1.3">1</cn></apply><apply id="S2.SS1.p1.2.m2.3.3.2.2.cmml" xref="S2.SS1.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.3.3.2.2.1.cmml" xref="S2.SS1.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S2.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="S2.SS1.p1.2.m2.3.3.2.2.2">ğ¶</ci><cn type="integer" id="S2.SS1.p1.2.m2.3.3.2.2.3.cmml" xref="S2.SS1.p1.2.m2.3.3.2.2.3">2</cn></apply><apply id="S2.SS1.p1.2.m2.4.4.3.3.cmml" xref="S2.SS1.p1.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.4.4.3.3.1.cmml" xref="S2.SS1.p1.2.m2.4.4.3.3">subscript</csymbol><ci id="S2.SS1.p1.2.m2.4.4.3.3.2.cmml" xref="S2.SS1.p1.2.m2.4.4.3.3.2">ğ¶</ci><cn type="integer" id="S2.SS1.p1.2.m2.4.4.3.3.3.cmml" xref="S2.SS1.p1.2.m2.4.4.3.3.3">3</cn></apply><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">â€¦</ci><apply id="S2.SS1.p1.2.m2.5.5.4.4.cmml" xref="S2.SS1.p1.2.m2.5.5.4.4"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.5.5.4.4.1.cmml" xref="S2.SS1.p1.2.m2.5.5.4.4">subscript</csymbol><ci id="S2.SS1.p1.2.m2.5.5.4.4.2.cmml" xref="S2.SS1.p1.2.m2.5.5.4.4.2">ğ¶</ci><ci id="S2.SS1.p1.2.m2.5.5.4.4.3.cmml" xref="S2.SS1.p1.2.m2.5.5.4.4.3">ğ‘›</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.5c">C_{1},C_{2},C_{3},...,C_{n}</annotation></semantics></math>), in proximity with a central server denoted as <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">S</annotation></semantics></math>. The central server <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">S</annotation></semantics></math> is responsible for coordinating the FL training process and through iterative training generates a converged global FL model <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\mathcal{M}</annotation></semantics></math>.
The training process of the ML model <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">\mathcal{M}</annotation></semantics></math> at the <math id="S2.SS1.p1.7.m7.1" class="ltx_Math" alttext="r^{th}" display="inline"><semantics id="S2.SS1.p1.7.m7.1a"><msup id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml"><mi id="S2.SS1.p1.7.m7.1.1.2" xref="S2.SS1.p1.7.m7.1.1.2.cmml">r</mi><mrow id="S2.SS1.p1.7.m7.1.1.3" xref="S2.SS1.p1.7.m7.1.1.3.cmml"><mi id="S2.SS1.p1.7.m7.1.1.3.2" xref="S2.SS1.p1.7.m7.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.7.m7.1.1.3.1" xref="S2.SS1.p1.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS1.p1.7.m7.1.1.3.3" xref="S2.SS1.p1.7.m7.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><apply id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.1.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">superscript</csymbol><ci id="S2.SS1.p1.7.m7.1.1.2.cmml" xref="S2.SS1.p1.7.m7.1.1.2">ğ‘Ÿ</ci><apply id="S2.SS1.p1.7.m7.1.1.3.cmml" xref="S2.SS1.p1.7.m7.1.1.3"><times id="S2.SS1.p1.7.m7.1.1.3.1.cmml" xref="S2.SS1.p1.7.m7.1.1.3.1"></times><ci id="S2.SS1.p1.7.m7.1.1.3.2.cmml" xref="S2.SS1.p1.7.m7.1.1.3.2">ğ‘¡</ci><ci id="S2.SS1.p1.7.m7.1.1.3.3.cmml" xref="S2.SS1.p1.7.m7.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">r^{th}</annotation></semantics></math> training round (where <math id="S2.SS1.p1.8.m8.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.SS1.p1.8.m8.1a"><mi id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.1b"><ci id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.1c">r</annotation></semantics></math> is an element of set <math id="S2.SS1.p1.9.m9.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">R</annotation></semantics></math>, representing the number of FL training rounds) is comprised of the following four steps:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.6" class="ltx_p">Step 1. The centralized server denoted as <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><mi id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">S</annotation></semantics></math>, distributes the current global FL model, denoted as <math id="S2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{M}^{r}" display="inline"><semantics id="S2.I1.i1.p1.2.m2.1a"><msup id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.2.m2.1.1.2" xref="S2.I1.i1.p1.2.m2.1.1.2.cmml">â„³</mi><mi id="S2.I1.i1.p1.2.m2.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><apply id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">superscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2">â„³</ci><ci id="S2.I1.i1.p1.2.m2.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">\mathcal{M}^{r}</annotation></semantics></math>, to the federated clients participating in the process, denoted as <math id="S2.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S2.I1.i1.p1.3.m3.1a"><msub id="S2.I1.i1.p1.3.m3.1.1" xref="S2.I1.i1.p1.3.m3.1.1.cmml"><mi id="S2.I1.i1.p1.3.m3.1.1.2" xref="S2.I1.i1.p1.3.m3.1.1.2.cmml">C</mi><mi id="S2.I1.i1.p1.3.m3.1.1.3" xref="S2.I1.i1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.3.m3.1b"><apply id="S2.I1.i1.p1.3.m3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.1.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.1.1.2.cmml" xref="S2.I1.i1.p1.3.m3.1.1.2">ğ¶</ci><ci id="S2.I1.i1.p1.3.m3.1.1.3.cmml" xref="S2.I1.i1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.3.m3.1c">C_{i}</annotation></semantics></math> (where <math id="S2.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.I1.i1.p1.4.m4.1a"><mi id="S2.I1.i1.p1.4.m4.1.1" xref="S2.I1.i1.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.4.m4.1b"><ci id="S2.I1.i1.p1.4.m4.1.1.cmml" xref="S2.I1.i1.p1.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.4.m4.1c">i</annotation></semantics></math> ranges from <math id="S2.I1.i1.p1.5.m5.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.I1.i1.p1.5.m5.1a"><mn id="S2.I1.i1.p1.5.m5.1.1" xref="S2.I1.i1.p1.5.m5.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.5.m5.1b"><cn type="integer" id="S2.I1.i1.p1.5.m5.1.1.cmml" xref="S2.I1.i1.p1.5.m5.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.5.m5.1c">1</annotation></semantics></math> to <math id="S2.I1.i1.p1.6.m6.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.I1.i1.p1.6.m6.1a"><mi id="S2.I1.i1.p1.6.m6.1.1" xref="S2.I1.i1.p1.6.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.6.m6.1b"><ci id="S2.I1.i1.p1.6.m6.1.1.cmml" xref="S2.I1.i1.p1.6.m6.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.6.m6.1c">n</annotation></semantics></math>)</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.5" class="ltx_p">Step 2. In parallel, each client <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><msub id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.2" xref="S2.I1.i2.p1.1.m1.1.1.2.cmml">C</mi><mi id="S2.I1.i2.p1.1.m1.1.1.3" xref="S2.I1.i2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><apply id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.1.m1.1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.1.m1.1.1.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2">ğ¶</ci><ci id="S2.I1.i2.p1.1.m1.1.1.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">C_{i}</annotation></semantics></math> independently trains and improves the model <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{M}^{r}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><msup id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i2.p1.2.m2.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.2.cmml">â„³</mi><mi id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">superscript</csymbol><ci id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2">â„³</ci><ci id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">\mathcal{M}^{r}</annotation></semantics></math>, using its own dataset <math id="S2.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S2.I1.i2.p1.3.m3.1a"><msub id="S2.I1.i2.p1.3.m3.1.1" xref="S2.I1.i2.p1.3.m3.1.1.cmml"><mi id="S2.I1.i2.p1.3.m3.1.1.2" xref="S2.I1.i2.p1.3.m3.1.1.2.cmml">D</mi><mi id="S2.I1.i2.p1.3.m3.1.1.3" xref="S2.I1.i2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m3.1b"><apply id="S2.I1.i2.p1.3.m3.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.3.m3.1.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.3.m3.1.1.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1.2">ğ·</ci><ci id="S2.I1.i2.p1.3.m3.1.1.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m3.1c">D_{i}</annotation></semantics></math>. Once the local training process has been concluded, each client <math id="S2.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S2.I1.i2.p1.4.m4.1a"><msub id="S2.I1.i2.p1.4.m4.1.1" xref="S2.I1.i2.p1.4.m4.1.1.cmml"><mi id="S2.I1.i2.p1.4.m4.1.1.2" xref="S2.I1.i2.p1.4.m4.1.1.2.cmml">C</mi><mi id="S2.I1.i2.p1.4.m4.1.1.3" xref="S2.I1.i2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.4.m4.1b"><apply id="S2.I1.i2.p1.4.m4.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.4.m4.1.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.4.m4.1.1.2.cmml" xref="S2.I1.i2.p1.4.m4.1.1.2">ğ¶</ci><ci id="S2.I1.i2.p1.4.m4.1.1.3.cmml" xref="S2.I1.i2.p1.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.4.m4.1c">C_{i}</annotation></semantics></math> transmits the updated model parameters, denoted by <math id="S2.I1.i2.p1.5.m5.1" class="ltx_Math" alttext="U_{i}^{r}" display="inline"><semantics id="S2.I1.i2.p1.5.m5.1a"><msubsup id="S2.I1.i2.p1.5.m5.1.1" xref="S2.I1.i2.p1.5.m5.1.1.cmml"><mi id="S2.I1.i2.p1.5.m5.1.1.2.2" xref="S2.I1.i2.p1.5.m5.1.1.2.2.cmml">U</mi><mi id="S2.I1.i2.p1.5.m5.1.1.2.3" xref="S2.I1.i2.p1.5.m5.1.1.2.3.cmml">i</mi><mi id="S2.I1.i2.p1.5.m5.1.1.3" xref="S2.I1.i2.p1.5.m5.1.1.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.5.m5.1b"><apply id="S2.I1.i2.p1.5.m5.1.1.cmml" xref="S2.I1.i2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.5.m5.1.1.1.cmml" xref="S2.I1.i2.p1.5.m5.1.1">superscript</csymbol><apply id="S2.I1.i2.p1.5.m5.1.1.2.cmml" xref="S2.I1.i2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.5.m5.1.1.2.1.cmml" xref="S2.I1.i2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.5.m5.1.1.2.2.cmml" xref="S2.I1.i2.p1.5.m5.1.1.2.2">ğ‘ˆ</ci><ci id="S2.I1.i2.p1.5.m5.1.1.2.3.cmml" xref="S2.I1.i2.p1.5.m5.1.1.2.3">ğ‘–</ci></apply><ci id="S2.I1.i2.p1.5.m5.1.1.3.cmml" xref="S2.I1.i2.p1.5.m5.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.5.m5.1c">U_{i}^{r}</annotation></semantics></math>, to the central server.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.2" class="ltx_p">Step 3. The central server <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><mi id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><ci id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">S</annotation></semantics></math> accumulates the updated parameters <math id="S2.I1.i3.p1.2.m2.4" class="ltx_Math" alttext="U^{r}=[U_{1}^{r},U_{2}^{r},\cdots,U_{n}^{r}]" display="inline"><semantics id="S2.I1.i3.p1.2.m2.4a"><mrow id="S2.I1.i3.p1.2.m2.4.4" xref="S2.I1.i3.p1.2.m2.4.4.cmml"><msup id="S2.I1.i3.p1.2.m2.4.4.5" xref="S2.I1.i3.p1.2.m2.4.4.5.cmml"><mi id="S2.I1.i3.p1.2.m2.4.4.5.2" xref="S2.I1.i3.p1.2.m2.4.4.5.2.cmml">U</mi><mi id="S2.I1.i3.p1.2.m2.4.4.5.3" xref="S2.I1.i3.p1.2.m2.4.4.5.3.cmml">r</mi></msup><mo id="S2.I1.i3.p1.2.m2.4.4.4" xref="S2.I1.i3.p1.2.m2.4.4.4.cmml">=</mo><mrow id="S2.I1.i3.p1.2.m2.4.4.3.3" xref="S2.I1.i3.p1.2.m2.4.4.3.4.cmml"><mo stretchy="false" id="S2.I1.i3.p1.2.m2.4.4.3.3.4" xref="S2.I1.i3.p1.2.m2.4.4.3.4.cmml">[</mo><msubsup id="S2.I1.i3.p1.2.m2.2.2.1.1.1" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.cmml"><mi id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2.cmml">U</mi><mn id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3.cmml">1</mn><mi id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.cmml">r</mi></msubsup><mo id="S2.I1.i3.p1.2.m2.4.4.3.3.5" xref="S2.I1.i3.p1.2.m2.4.4.3.4.cmml">,</mo><msubsup id="S2.I1.i3.p1.2.m2.3.3.2.2.2" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.cmml"><mi id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2.cmml">U</mi><mn id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3.cmml">2</mn><mi id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.cmml">r</mi></msubsup><mo id="S2.I1.i3.p1.2.m2.4.4.3.3.6" xref="S2.I1.i3.p1.2.m2.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml">â‹¯</mi><mo id="S2.I1.i3.p1.2.m2.4.4.3.3.7" xref="S2.I1.i3.p1.2.m2.4.4.3.4.cmml">,</mo><msubsup id="S2.I1.i3.p1.2.m2.4.4.3.3.3" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3.cmml"><mi id="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.2" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.2.cmml">U</mi><mi id="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.3" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.3.cmml">n</mi><mi id="S2.I1.i3.p1.2.m2.4.4.3.3.3.3" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3.3.cmml">r</mi></msubsup><mo stretchy="false" id="S2.I1.i3.p1.2.m2.4.4.3.3.8" xref="S2.I1.i3.p1.2.m2.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.4b"><apply id="S2.I1.i3.p1.2.m2.4.4.cmml" xref="S2.I1.i3.p1.2.m2.4.4"><eq id="S2.I1.i3.p1.2.m2.4.4.4.cmml" xref="S2.I1.i3.p1.2.m2.4.4.4"></eq><apply id="S2.I1.i3.p1.2.m2.4.4.5.cmml" xref="S2.I1.i3.p1.2.m2.4.4.5"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.4.4.5.1.cmml" xref="S2.I1.i3.p1.2.m2.4.4.5">superscript</csymbol><ci id="S2.I1.i3.p1.2.m2.4.4.5.2.cmml" xref="S2.I1.i3.p1.2.m2.4.4.5.2">ğ‘ˆ</ci><ci id="S2.I1.i3.p1.2.m2.4.4.5.3.cmml" xref="S2.I1.i3.p1.2.m2.4.4.5.3">ğ‘Ÿ</ci></apply><list id="S2.I1.i3.p1.2.m2.4.4.3.4.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3"><apply id="S2.I1.i3.p1.2.m2.2.2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.2.2.1.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1">superscript</csymbol><apply id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.1.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.2.3">1</cn></apply><ci id="S2.I1.i3.p1.2.m2.2.2.1.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.2.2.1.1.1.3">ğ‘Ÿ</ci></apply><apply id="S2.I1.i3.p1.2.m2.3.3.2.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2">superscript</csymbol><apply id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.1.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.2">ğ‘ˆ</ci><cn type="integer" id="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.2.3">2</cn></apply><ci id="S2.I1.i3.p1.2.m2.3.3.2.2.2.3.cmml" xref="S2.I1.i3.p1.2.m2.3.3.2.2.2.3">ğ‘Ÿ</ci></apply><ci id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1">â‹¯</ci><apply id="S2.I1.i3.p1.2.m2.4.4.3.3.3.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.4.4.3.3.3.1.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3">superscript</csymbol><apply id="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.1.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.2.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.2">ğ‘ˆ</ci><ci id="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.3.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3.2.3">ğ‘›</ci></apply><ci id="S2.I1.i3.p1.2.m2.4.4.3.3.3.3.cmml" xref="S2.I1.i3.p1.2.m2.4.4.3.3.3.3">ğ‘Ÿ</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.4c">U^{r}=[U_{1}^{r},U_{2}^{r},\cdots,U_{n}^{r}]</annotation></semantics></math> from each of the clients that are participating in the process.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.4" class="ltx_p">Step 4. The central server <math id="S2.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.I1.i4.p1.1.m1.1a"><mi id="S2.I1.i4.p1.1.m1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.1.m1.1b"><ci id="S2.I1.i4.p1.1.m1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.1.m1.1c">S</annotation></semantics></math> then updates the global model <math id="S2.I1.i4.p1.2.m2.1" class="ltx_Math" alttext="M^{r}" display="inline"><semantics id="S2.I1.i4.p1.2.m2.1a"><msup id="S2.I1.i4.p1.2.m2.1.1" xref="S2.I1.i4.p1.2.m2.1.1.cmml"><mi id="S2.I1.i4.p1.2.m2.1.1.2" xref="S2.I1.i4.p1.2.m2.1.1.2.cmml">M</mi><mi id="S2.I1.i4.p1.2.m2.1.1.3" xref="S2.I1.i4.p1.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.2.m2.1b"><apply id="S2.I1.i4.p1.2.m2.1.1.cmml" xref="S2.I1.i4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i4.p1.2.m2.1.1.1.cmml" xref="S2.I1.i4.p1.2.m2.1.1">superscript</csymbol><ci id="S2.I1.i4.p1.2.m2.1.1.2.cmml" xref="S2.I1.i4.p1.2.m2.1.1.2">ğ‘€</ci><ci id="S2.I1.i4.p1.2.m2.1.1.3.cmml" xref="S2.I1.i4.p1.2.m2.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.2.m2.1c">M^{r}</annotation></semantics></math> by aggregating the collected parameter updates <math id="S2.I1.i4.p1.3.m3.1" class="ltx_Math" alttext="U^{r}" display="inline"><semantics id="S2.I1.i4.p1.3.m3.1a"><msup id="S2.I1.i4.p1.3.m3.1.1" xref="S2.I1.i4.p1.3.m3.1.1.cmml"><mi id="S2.I1.i4.p1.3.m3.1.1.2" xref="S2.I1.i4.p1.3.m3.1.1.2.cmml">U</mi><mi id="S2.I1.i4.p1.3.m3.1.1.3" xref="S2.I1.i4.p1.3.m3.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.3.m3.1b"><apply id="S2.I1.i4.p1.3.m3.1.1.cmml" xref="S2.I1.i4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i4.p1.3.m3.1.1.1.cmml" xref="S2.I1.i4.p1.3.m3.1.1">superscript</csymbol><ci id="S2.I1.i4.p1.3.m3.1.1.2.cmml" xref="S2.I1.i4.p1.3.m3.1.1.2">ğ‘ˆ</ci><ci id="S2.I1.i4.p1.3.m3.1.1.3.cmml" xref="S2.I1.i4.p1.3.m3.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.3.m3.1c">U^{r}</annotation></semantics></math>. During the subsequent training iteration, the recently updated model <math id="S2.I1.i4.p1.4.m4.1" class="ltx_Math" alttext="M^{r+1}" display="inline"><semantics id="S2.I1.i4.p1.4.m4.1a"><msup id="S2.I1.i4.p1.4.m4.1.1" xref="S2.I1.i4.p1.4.m4.1.1.cmml"><mi id="S2.I1.i4.p1.4.m4.1.1.2" xref="S2.I1.i4.p1.4.m4.1.1.2.cmml">M</mi><mrow id="S2.I1.i4.p1.4.m4.1.1.3" xref="S2.I1.i4.p1.4.m4.1.1.3.cmml"><mi id="S2.I1.i4.p1.4.m4.1.1.3.2" xref="S2.I1.i4.p1.4.m4.1.1.3.2.cmml">r</mi><mo id="S2.I1.i4.p1.4.m4.1.1.3.1" xref="S2.I1.i4.p1.4.m4.1.1.3.1.cmml">+</mo><mn id="S2.I1.i4.p1.4.m4.1.1.3.3" xref="S2.I1.i4.p1.4.m4.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.4.m4.1b"><apply id="S2.I1.i4.p1.4.m4.1.1.cmml" xref="S2.I1.i4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.I1.i4.p1.4.m4.1.1.1.cmml" xref="S2.I1.i4.p1.4.m4.1.1">superscript</csymbol><ci id="S2.I1.i4.p1.4.m4.1.1.2.cmml" xref="S2.I1.i4.p1.4.m4.1.1.2">ğ‘€</ci><apply id="S2.I1.i4.p1.4.m4.1.1.3.cmml" xref="S2.I1.i4.p1.4.m4.1.1.3"><plus id="S2.I1.i4.p1.4.m4.1.1.3.1.cmml" xref="S2.I1.i4.p1.4.m4.1.1.3.1"></plus><ci id="S2.I1.i4.p1.4.m4.1.1.3.2.cmml" xref="S2.I1.i4.p1.4.m4.1.1.3.2">ğ‘Ÿ</ci><cn type="integer" id="S2.I1.i4.p1.4.m4.1.1.3.3.cmml" xref="S2.I1.i4.p1.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.4.m4.1c">M^{r+1}</annotation></semantics></math> will be distributed to federated clients.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The training process in FL is executed iteratively by the central server and clients until a termination criterion is met. This criterion can be a maximum number of iterations or a threshold for model accuracy. Subsequently, the central server converges FL model <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\mathcal{M}</annotation></semantics></math>, which is then distributed to each and every client of the system. <a href="#S1.F1" title="In I Introduction â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> contrasts the centralized and federated training of ML models.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">In order to enhance privacy protection, recent advancements in the field of FL have incorporated various privacy protection mechanisms such as differential privacy<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span id="footnote1.1" class="ltx_text ltx_font_bold">Differential privacy</span> guarantees that an individualâ€™s data is modified or perturbed in a controlled manner to provide a privacy guarantee, ensuring that the overall statistical outcomes of computations are stable and independent of whether their specific information is included or altered.</span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and secure aggregation<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span id="footnote2.1" class="ltx_text ltx_font_bold">Secure aggregation</span> ensures that data collected from multiple sources is combined using cryptographic techniques to maintain individual data privacy and confidentiality, enabling collaborative computations without revealing the raw data.</span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
Prior studies have primarily concentrated on two approaches for achieving differential privacy: centralized differential privacy, which relies on a central trusted party <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, and local differential privacy, where each user perturbs their updates randomly before transmitting them to an untrusted aggregator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. While FL has been recognized as a potentially effective approach that prioritizes privacy, a limited number of recent studies have demonstrated the susceptibility of FL to MIAs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Membership Inference Attack</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.2" class="ltx_p">Our work focuses on investigating the potential of membership privacy breaches through MIA and studying the attackâ€™s accuracy. In this section, we provide a brief overview of the background of existing works of MIAs as they pertain to ML models. An attacker intends to ascertain the membership property of a target sample <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">x</annotation></semantics></math>, i.e., whether or not this sample was used to train the target model, by exploiting the prediction behavior of an ML model <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{T}_{m}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><msub id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">ğ’¯</mi><mi id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">ğ’¯</ci><ci id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\mathcal{T}_{m}</annotation></semantics></math> (referred to as the target model). MIA may compromise the privacy of training data used in ML models, thereby introducing additional risks for the producers of such training data.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">The MIA can be expressed in a more formal way as:</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.3" class="ltx_Math" alttext="\mathcal{A}(\mathcal{T}_{m},\Omega,x)\rightarrow\textbf{In}\,/\,\textbf{Out}" display="block"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml"><mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3.1.3" xref="S2.E1.m1.3.3.1.3.cmml">ğ’œ</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.2" xref="S2.E1.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.2" xref="S2.E1.m1.3.3.1.1.2.cmml">(</mo><msub id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">ğ’¯</mi><mi id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.3.cmml">m</mi></msub><mo id="S2.E1.m1.3.3.1.1.1.3" xref="S2.E1.m1.3.3.1.1.2.cmml">,</mo><mi mathvariant="normal" id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">Î©</mi><mo id="S2.E1.m1.3.3.1.1.1.4" xref="S2.E1.m1.3.3.1.1.2.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.5" xref="S2.E1.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E1.m1.3.3.2" xref="S2.E1.m1.3.3.2.cmml">â†’</mo><mrow id="S2.E1.m1.3.3.3" xref="S2.E1.m1.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S2.E1.m1.3.3.3.2" xref="S2.E1.m1.3.3.3.2a.cmml">In</mtext><mo lspace="0.392em" rspace="0.392em" id="S2.E1.m1.3.3.3.1" xref="S2.E1.m1.3.3.3.1.cmml">/</mo><mtext class="ltx_mathvariant_bold" id="S2.E1.m1.3.3.3.3" xref="S2.E1.m1.3.3.3.3a.cmml">Out</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.3b"><apply id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3"><ci id="S2.E1.m1.3.3.2.cmml" xref="S2.E1.m1.3.3.2">â†’</ci><apply id="S2.E1.m1.3.3.1.cmml" xref="S2.E1.m1.3.3.1"><times id="S2.E1.m1.3.3.1.2.cmml" xref="S2.E1.m1.3.3.1.2"></times><ci id="S2.E1.m1.3.3.1.3.cmml" xref="S2.E1.m1.3.3.1.3">ğ’œ</ci><vector id="S2.E1.m1.3.3.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1"><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">ğ’¯</ci><ci id="S2.E1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3">ğ‘š</ci></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">Î©</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">ğ‘¥</ci></vector></apply><apply id="S2.E1.m1.3.3.3.cmml" xref="S2.E1.m1.3.3.3"><divide id="S2.E1.m1.3.3.3.1.cmml" xref="S2.E1.m1.3.3.3.1"></divide><ci id="S2.E1.m1.3.3.3.2a.cmml" xref="S2.E1.m1.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S2.E1.m1.3.3.3.2.cmml" xref="S2.E1.m1.3.3.3.2">In</mtext></ci><ci id="S2.E1.m1.3.3.3.3a.cmml" xref="S2.E1.m1.3.3.3.3"><mtext class="ltx_mathvariant_bold" id="S2.E1.m1.3.3.3.3.cmml" xref="S2.E1.m1.3.3.3.3">Out</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.3c">\mathcal{A}(\mathcal{T}_{m},\Omega,x)\rightarrow\textbf{In}\,/\,\textbf{Out}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.6" class="ltx_p">where the attack is represented by <math id="S2.SS2.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS2.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p4.1.m1.1.1" xref="S2.SS2.p4.1.m1.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.1.m1.1b"><ci id="S2.SS2.p4.1.m1.1.1.cmml" xref="S2.SS2.p4.1.m1.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.1.m1.1c">\mathcal{A}</annotation></semantics></math>, <span id="S2.SS2.p4.6.1" class="ltx_text ltx_font_bold">In</span> means that <math id="S2.SS2.p4.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS2.p4.2.m2.1a"><mi id="S2.SS2.p4.2.m2.1.1" xref="S2.SS2.p4.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.2.m2.1b"><ci id="S2.SS2.p4.2.m2.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.2.m2.1c">x</annotation></semantics></math> is a member, <span id="S2.SS2.p4.6.2" class="ltx_text ltx_font_bold">Out</span> means <math id="S2.SS2.p4.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS2.p4.3.m3.1a"><mi id="S2.SS2.p4.3.m3.1.1" xref="S2.SS2.p4.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.3.m3.1b"><ci id="S2.SS2.p4.3.m3.1.1.cmml" xref="S2.SS2.p4.3.m3.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.3.m3.1c">x</annotation></semantics></math> is not a member of training data <math id="S2.SS2.p4.4.m4.1" class="ltx_Math" alttext="\mathcal{T}_{m}" display="inline"><semantics id="S2.SS2.p4.4.m4.1a"><msub id="S2.SS2.p4.4.m4.1.1" xref="S2.SS2.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p4.4.m4.1.1.2" xref="S2.SS2.p4.4.m4.1.1.2.cmml">ğ’¯</mi><mi id="S2.SS2.p4.4.m4.1.1.3" xref="S2.SS2.p4.4.m4.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.4.m4.1b"><apply id="S2.SS2.p4.4.m4.1.1.cmml" xref="S2.SS2.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p4.4.m4.1.1.1.cmml" xref="S2.SS2.p4.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p4.4.m4.1.1.2.cmml" xref="S2.SS2.p4.4.m4.1.1.2">ğ’¯</ci><ci id="S2.SS2.p4.4.m4.1.1.3.cmml" xref="S2.SS2.p4.4.m4.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.4.m4.1c">\mathcal{T}_{m}</annotation></semantics></math>. <math id="S2.SS2.p4.5.m5.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S2.SS2.p4.5.m5.1a"><mi mathvariant="normal" id="S2.SS2.p4.5.m5.1.1" xref="S2.SS2.p4.5.m5.1.1.cmml">Î©</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.5.m5.1b"><ci id="S2.SS2.p4.5.m5.1.1.cmml" xref="S2.SS2.p4.5.m5.1.1">Î©</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.5.m5.1c">\Omega</annotation></semantics></math> refers to any additional knowledge about the target model and its training data that <math id="S2.SS2.p4.6.m6.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S2.SS2.p4.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p4.6.m6.1.1" xref="S2.SS2.p4.6.m6.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.6.m6.1b"><ci id="S2.SS2.p4.6.m6.1.1.cmml" xref="S2.SS2.p4.6.m6.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.6.m6.1c">\mathcal{A}</annotation></semantics></math> can receive.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p">In 2017, Shokri et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> introduced an MIA algorithm for ML models, that assumes that the adversary has â€œRestrictive Knowledgeâ€ access to the model<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span id="footnote3.1" class="ltx_text ltx_font_bold">Restrictive Knowledge</span> is achieved by an adversary for a black-box access or query access. It implies that the attacker can query the ML model to get a prediction on a given sample, but has no other access to the ML model and its weights.</span></span></span> and similar sample data as a priori knowledge. The experiments showed that the adversary can obtain significant information about the training data by attacking the model. In an FL environment, Truex et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> gave insights that MIA may also result in the exposure of private membership information. Salem et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> showed that the criteria for the execution of an MIA may be relaxed, which allows the attack to be carried out in a wider range of settings.
Xu et al. provided a method for conspiring attackers to purposefully alter training data in order to enhance or decrease the weight of a dimension in the aggregation model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. If the aggregation modelâ€™s weights or parameters reflect a recognizable pattern that generates relevant signals, sensitive data may be exposed.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.1" class="ltx_p"><span id="S2.SS2.p6.1.1" class="ltx_text ltx_font_bold">Synthesis: </span>Recently, there have been a few efforts to deploy various MIA variants in both centralized and federated ML environments. However, the effect of attack accuracy on different batch sizes of training to build the attack model for different numbers of clients in the FL has not been well studied.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Threat Model</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we discuss the basic threat model, where we explain the attackerâ€™s knowledge of the environment, the attackerâ€™s goal, and the capability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Adversaryâ€™s knowledge:</span> We consider the challenging situation in which the adversary can only acquire restricted knowledge about the target model and knowledge about the distribution of the target dataset. The training goals and model architecture are shared by all FL participants. As a result, this level of attacker knowledge is realistic. However, the adversary is unable to get any knowledge on the global training process (centralized or FL), or the distribution of the training data among the clients (if applicable).</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">Attackerâ€™s Goals:</span> For the ML model, the attacker guesses or infers data from the initial training set. Following training, the attacker develops an attack model that infers private data from query-level access to the target model. The attacker does not alter the parameters of the model and does not need any additional information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Attackerâ€™s Capability:</span> The attacker is presumed to be an honest but curious user with query access to the target model, but cannot access its internal weights and gradients. The attacker uses this query access to implement the membership inference attack.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2312.00051/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="166" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>MIAâ€™s shadow model training technique. Shadow models are trained in the same manner as the target model using <math id="S3.F2.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.F2.2.m1.1b"><mi id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><ci id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">k</annotation></semantics></math> shadow-training and shadow-evaluation datasets.</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Framework Overview</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Attack Overview</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Our study is focused on a framework that is predicated on the notion that, given training vs. non-training data, MIA may recognize the difference in an ML modelâ€™s behavior. The inference attacker employs a two-step strategy. To begin, a collection of shadow models with behaviors comparable to the target model is built and trained. Then, the shadow models are utilized to generate an attack dataset for training the attack model. The trained attack model can infer whether a sample belongs to the training set of the target model data.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">When the FL training procedure is completed, a global model is produced. This global model comprises the training outcomes of all participantsâ€™ data that comes from many rounds of aggregation. To the adversary, this federally trained model is indistinguishable from a centrally trained model and thus makes no difference for MIA purposes.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">The attacker trains the shadow models locally, each with behavior comparable to the global model. Having trained on the shadow model outcomes, the attack models may effectively infer the global modelâ€™s â€œinâ€ and â€œoutâ€ dataset.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Shadow Model</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The concept of shadow model training involves using identically distributed data on the as similar as possible model architecture to train models that evaluate data similarly <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. The attacker utilizes knowledge about the target datasetâ€™s distribution to build multiple shadow datasets with similar styles and distributions. The attacker trains shadow models, with a similar architecture to the target model, on these shadow datasets. Once trained, the shadow model is used to produce training data for the attack model. <a href="#S3.F2" title="In III Threat Model â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> summarizes how the shadow models are trained.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<p id="S4.F3.1" class="ltx_p ltx_align_center"><span id="S4.F3.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;"><img src="/html/2312.00051/assets/fig3-2.png" id="S4.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="359" height="217" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Training process of the proposed MIA-BAD approach. The attack model is trained from batch-wise generation of the attack dataset.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Attack Model</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The attack model is a binary classifier that is trained
to predict if a given record is part of the modelâ€™s training set or not. For each record in the shadow modelâ€™s training dataset, the adversary creates a query, retrieves the output, marks the resultant vectors as â€œinâ€ and finally adds them to the attack modelâ€™s training dataset. Similarly, the attacker queries and records output labeled as â€œoutâ€ using a disjoint test dataset of the shadow model. The attacker now possesses a dataset comprising records, as well as the appropriate outputs of the shadow models and the corresponding in/out labels. The objective of the attack model is to infer the labels from the records and corresponding outputs.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">The MIA-BAD Approach</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we investigate the effect of modifications on how the attack model is trained. Normally, as described in <a href="#S4.SS3" title="IV-C Attack Model â€£ IV Framework Overview â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">section</span>Â <span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a>, the attack dataset is built by evaluating on the shadow model to enable tabulation of the sample-wise loss in the attack dataset. This approach produces a dataset equal to the size of all the shadow datasets combined. This gives us more than enough data to train the attack model.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">However, it is a well-known phenomenon that ensembling improves performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. We generally
train ML models in batches because larger batch sizes can provide better model convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. In an MIA, the shadow models as well as the attack models are trained in batches, however, the attack dataset is built sample-wise to retain the size of the attack dataset.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">We propose, building the attack dataset by evaluating batch-wise with shadow models on the corresponding shadow dataset. This will significantly decrease the size of the attack dataset. Nevertheless, we hypothesized that the qualitative improvement through the implied ensembling would compensate for the quantitative loss, <a href="#S6.SS3" title="VI-C Effect of Generating the Attack Dataset Batch-wise â€£ VI Performance Evaluation â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">section</span>Â <span class="ltx_text ltx_ref_tag"><span class="ltx_text">VI-C</span></span></a> backs our hypothesis. <a href="#S4.F3" title="In IV-B Shadow Model â€£ IV Framework Overview â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> demonstrates the MIA-BAD approach for attack model training.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">The Overall Attack Paradigm</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">In this section, we first present the basic steps of the proposed MIA-BAD approach. Next, then provide the algorithm (in pseudo-code format), in <a href="#alg1" title="In V-A The Overall Attack Paradigm â€£ V The MIA-BAD Approach â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>, for implementing the proposed attack.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">Define a master shadow dataset by sampling from a similar distribution as the target dataset.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">Sample <math id="S5.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.I1.i2.p1.1.m1.1a"><mi id="S5.I1.i2.p1.1.m1.1.1" xref="S5.I1.i2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i2.p1.1.m1.1b"><ci id="S5.I1.i2.p1.1.m1.1.1.cmml" xref="S5.I1.i2.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i2.p1.1.m1.1c">k</annotation></semantics></math> overlapping but significantly different shadow dataset from the master shadow dataset. Split each shadow dataset into training and test subsets.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Train the <math id="S5.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.I1.i3.p1.1.m1.1a"><mi id="S5.I1.i3.p1.1.m1.1.1" xref="S5.I1.i3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.m1.1b"><ci id="S5.I1.i3.p1.1.m1.1.1.cmml" xref="S5.I1.i3.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.m1.1c">k</annotation></semantics></math> shadow models on the training subsets of its corresponding shadow dataset.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p id="S5.I1.i4.p1.1" class="ltx_p">For every shadow model, evaluate the entire shadow dataset (train or test, represented by seen and unseen) batch-wise, and record the batch-wise loss with the seen/unseen label to build the attack dataset.</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S5.I1.i5.p1" class="ltx_para">
<p id="S5.I1.i5.p1.1" class="ltx_p">Train a binary classifier on the attack dataset as the attack model.</p>
</div>
</li>
</ol>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Performance of MIA-BAD on CIFAR10 dataset for different batch sizes.</figcaption>
<table id="S5.T1.9.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.9.9.10.1" class="ltx_tr">
<th id="S5.T1.9.9.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Training Mode</th>
<th id="S5.T1.9.9.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Sample wise</th>
<th id="S5.T1.9.9.10.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="6">Batch wise</th>
</tr>
<tr id="S5.T1.6.6.6" class="ltx_tr">
<th id="S5.T1.6.6.6.7" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S5.T1.6.6.6.8" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S5.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S5.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S5.T1.1.1.1.1.m1.1a"><mn id="S5.T1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><cn type="integer" id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">8</annotation></semantics></math></th>
<th id="S5.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S5.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S5.T1.2.2.2.2.m1.1a"><mn id="S5.T1.2.2.2.2.m1.1.1" xref="S5.T1.2.2.2.2.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.2.m1.1b"><cn type="integer" id="S5.T1.2.2.2.2.m1.1.1.cmml" xref="S5.T1.2.2.2.2.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.2.m1.1c">16</annotation></semantics></math></th>
<th id="S5.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S5.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S5.T1.3.3.3.3.m1.1a"><mn id="S5.T1.3.3.3.3.m1.1.1" xref="S5.T1.3.3.3.3.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.3.m1.1b"><cn type="integer" id="S5.T1.3.3.3.3.m1.1.1.cmml" xref="S5.T1.3.3.3.3.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.3.m1.1c">32</annotation></semantics></math></th>
<th id="S5.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S5.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S5.T1.4.4.4.4.m1.1a"><mn id="S5.T1.4.4.4.4.m1.1.1" xref="S5.T1.4.4.4.4.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.4.m1.1b"><cn type="integer" id="S5.T1.4.4.4.4.m1.1.1.cmml" xref="S5.T1.4.4.4.4.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.4.m1.1c">64</annotation></semantics></math></th>
<th id="S5.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S5.T1.5.5.5.5.m1.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S5.T1.5.5.5.5.m1.1a"><mn id="S5.T1.5.5.5.5.m1.1.1" xref="S5.T1.5.5.5.5.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.5.m1.1b"><cn type="integer" id="S5.T1.5.5.5.5.m1.1.1.cmml" xref="S5.T1.5.5.5.5.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.5.m1.1c">128</annotation></semantics></math></th>
<th id="S5.T1.6.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S5.T1.6.6.6.6.m1.1" class="ltx_Math" alttext="258" display="inline"><semantics id="S5.T1.6.6.6.6.m1.1a"><mn id="S5.T1.6.6.6.6.m1.1.1" xref="S5.T1.6.6.6.6.m1.1.1.cmml">258</mn><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.6.6.m1.1b"><cn type="integer" id="S5.T1.6.6.6.6.m1.1.1.cmml" xref="S5.T1.6.6.6.6.m1.1.1">258</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.6.6.m1.1c">258</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.9.9.11.1" class="ltx_tr">
<th id="S5.T1.9.9.11.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Centrally</th>
<th id="S5.T1.9.9.11.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">0.833</th>
<td id="S5.T1.9.9.11.1.3" class="ltx_td ltx_align_center ltx_border_t">0.853</td>
<td id="S5.T1.9.9.11.1.4" class="ltx_td ltx_align_center ltx_border_t">0.869</td>
<td id="S5.T1.9.9.11.1.5" class="ltx_td ltx_align_center ltx_border_t">0.856</td>
<td id="S5.T1.9.9.11.1.6" class="ltx_td ltx_align_center ltx_border_t">0.853</td>
<td id="S5.T1.9.9.11.1.7" class="ltx_td ltx_align_center ltx_border_t">0.869</td>
<td id="S5.T1.9.9.11.1.8" class="ltx_td ltx_align_center ltx_border_t">0.856</td>
</tr>
<tr id="S5.T1.7.7.7" class="ltx_tr">
<th id="S5.T1.7.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<math id="S5.T1.7.7.7.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.T1.7.7.7.1.m1.1a"><mn id="S5.T1.7.7.7.1.m1.1.1" xref="S5.T1.7.7.7.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.7.1.m1.1b"><cn type="integer" id="S5.T1.7.7.7.1.m1.1.1.cmml" xref="S5.T1.7.7.7.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.7.1.m1.1c">2</annotation></semantics></math> clients</th>
<th id="S5.T1.7.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.721</th>
<td id="S5.T1.7.7.7.3" class="ltx_td ltx_align_center">0.751</td>
<td id="S5.T1.7.7.7.4" class="ltx_td ltx_align_center">0.755</td>
<td id="S5.T1.7.7.7.5" class="ltx_td ltx_align_center">0.757</td>
<td id="S5.T1.7.7.7.6" class="ltx_td ltx_align_center">0.753</td>
<td id="S5.T1.7.7.7.7" class="ltx_td ltx_align_center">0.753</td>
<td id="S5.T1.7.7.7.8" class="ltx_td ltx_align_center">0.751</td>
</tr>
<tr id="S5.T1.8.8.8" class="ltx_tr">
<th id="S5.T1.8.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<math id="S5.T1.8.8.8.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.T1.8.8.8.1.m1.1a"><mn id="S5.T1.8.8.8.1.m1.1.1" xref="S5.T1.8.8.8.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.8.1.m1.1b"><cn type="integer" id="S5.T1.8.8.8.1.m1.1.1.cmml" xref="S5.T1.8.8.8.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.8.1.m1.1c">5</annotation></semantics></math> clients</th>
<th id="S5.T1.8.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">0.769</th>
<td id="S5.T1.8.8.8.3" class="ltx_td ltx_align_center">0.769</td>
<td id="S5.T1.8.8.8.4" class="ltx_td ltx_align_center">0.772</td>
<td id="S5.T1.8.8.8.5" class="ltx_td ltx_align_center">0.768</td>
<td id="S5.T1.8.8.8.6" class="ltx_td ltx_align_center">0.771</td>
<td id="S5.T1.8.8.8.7" class="ltx_td ltx_align_center">0.768</td>
<td id="S5.T1.8.8.8.8" class="ltx_td ltx_align_center">0.769</td>
</tr>
<tr id="S5.T1.9.9.9" class="ltx_tr">
<th id="S5.T1.9.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">
<math id="S5.T1.9.9.9.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.T1.9.9.9.1.m1.1a"><mn id="S5.T1.9.9.9.1.m1.1.1" xref="S5.T1.9.9.9.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.T1.9.9.9.1.m1.1b"><cn type="integer" id="S5.T1.9.9.9.1.m1.1.1.cmml" xref="S5.T1.9.9.9.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.9.9.1.m1.1c">10</annotation></semantics></math> clients</th>
<th id="S5.T1.9.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">0.786</th>
<td id="S5.T1.9.9.9.3" class="ltx_td ltx_align_center ltx_border_b">0.765</td>
<td id="S5.T1.9.9.9.4" class="ltx_td ltx_align_center ltx_border_b">0.765</td>
<td id="S5.T1.9.9.9.5" class="ltx_td ltx_align_center ltx_border_b">0.796</td>
<td id="S5.T1.9.9.9.6" class="ltx_td ltx_align_center ltx_border_b">0.753</td>
<td id="S5.T1.9.9.9.7" class="ltx_td ltx_align_center ltx_border_b">0.769</td>
<td id="S5.T1.9.9.9.8" class="ltx_td ltx_align_center ltx_border_b">0.786</td>
</tr>
</tbody>
</table>
</figure>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.7.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Algorithm for MIA-BAD</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.5" class="ltx_p ltx_figure_panel"><span id="alg1.5.1" class="ltx_text ltx_font_bold">Input:</span> Target dataset distribution <math id="alg1.1.m1.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="alg1.1.m1.1a"><mi mathvariant="normal" id="alg1.1.m1.1.1" xref="alg1.1.m1.1.1.cmml">Î©</mi><annotation-xml encoding="MathML-Content" id="alg1.1.m1.1b"><ci id="alg1.1.m1.1.1.cmml" xref="alg1.1.m1.1.1">Î©</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.m1.1c">\Omega</annotation></semantics></math>, Shadow model definition <math id="alg1.2.m2.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="alg1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.2.m2.1.1" xref="alg1.2.m2.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="alg1.2.m2.1b"><ci id="alg1.2.m2.1.1.cmml" xref="alg1.2.m2.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.m2.1c">\mathcal{S}</annotation></semantics></math>, Shadow count <math id="alg1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.3.m3.1a"><mi id="alg1.3.m3.1.1" xref="alg1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.3.m3.1b"><ci id="alg1.3.m3.1.1.cmml" xref="alg1.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.m3.1c">k</annotation></semantics></math>, Batch size <math id="alg1.4.m4.1" class="ltx_Math" alttext="B" display="inline"><semantics id="alg1.4.m4.1a"><mi id="alg1.4.m4.1.1" xref="alg1.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="alg1.4.m4.1b"><ci id="alg1.4.m4.1.1.cmml" xref="alg1.4.m4.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.m4.1c">B</annotation></semantics></math>
<br class="ltx_break"><span id="alg1.5.2" class="ltx_text ltx_font_bold">Output:</span> Attack model <math id="alg1.5.m5.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="alg1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.5.m5.1.1" xref="alg1.5.m5.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="alg1.5.m5.1b"><ci id="alg1.5.m5.1.1.cmml" xref="alg1.5.m5.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.m5.1c">\mathcal{A}</annotation></semantics></math></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.8" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>Â Â Set, <math id="alg1.l1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="alg1.l1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">\mathcal{D}</annotation></semantics></math> = [] Â Â Â Â Â Â Â  <math id="alg1.l1.m2.1" class="ltx_Math" alttext="\vartriangleright" display="inline"><semantics id="alg1.l1.m2.1a"><mi mathvariant="normal" id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml">âŠ³</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><ci id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1">âŠ³</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">\vartriangleright</annotation></semantics></math> <span id="alg1.l1.2" class="ltx_text ltx_font_italic">Attack Dataset.</span>

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>Â Â Initialize, <math id="alg1.l2.m1.1" class="ltx_Math" alttext="\mathcal{A}\leftarrow" display="inline"><semantics id="alg1.l2.m1.1a"><mrow id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">ğ’œ</mi><mo stretchy="false" id="alg1.l2.m1.1.1.1" xref="alg1.l2.m1.1.1.1.cmml">â†</mo><mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><ci id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1">â†</ci><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">ğ’œ</ci><csymbol cd="latexml" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\mathcal{A}\leftarrow</annotation></semantics></math> Binary Classifier.

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>Â Â <span id="alg1.l3.2" class="ltx_text ltx_font_bold">for</span>Â <math id="alg1.l3.m1.1" class="ltx_Math" alttext="i=1" display="inline"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mi id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml">i</mi><mo id="alg1.l3.m1.1.1.1" xref="alg1.l3.m1.1.1.1.cmml">=</mo><mn id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><eq id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1"></eq><ci id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2">ğ‘–</ci><cn type="integer" id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">i=1</annotation></semantics></math> to <math id="alg1.l3.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.l3.m2.1a"><mi id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><ci id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">k</annotation></semantics></math>Â <span id="alg1.l3.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>Â Â Â Â Â Initialize, <math id="alg1.l4.m1.1" class="ltx_Math" alttext="\mathcal{S}_{i}\leftarrow\mathcal{S}" display="inline"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><msub id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l4.m1.1.1.2.2" xref="alg1.l4.m1.1.1.2.2.cmml">ğ’®</mi><mi id="alg1.l4.m1.1.1.2.3" xref="alg1.l4.m1.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l4.m1.1.1.1" xref="alg1.l4.m1.1.1.1.cmml">â†</mo><mi class="ltx_font_mathcaligraphic" id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml">ğ’®</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><ci id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1">â†</ci><apply id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.2.1.cmml" xref="alg1.l4.m1.1.1.2">subscript</csymbol><ci id="alg1.l4.m1.1.1.2.2.cmml" xref="alg1.l4.m1.1.1.2.2">ğ’®</ci><ci id="alg1.l4.m1.1.1.2.3.cmml" xref="alg1.l4.m1.1.1.2.3">ğ‘–</ci></apply><ci id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">ğ’®</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\mathcal{S}_{i}\leftarrow\mathcal{S}</annotation></semantics></math>.

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>Â Â Â Â Â Sample, <math id="alg1.l5.m1.1" class="ltx_Math" alttext="\omega_{i}\leftarrow\Omega" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><msub id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml"><mi id="alg1.l5.m1.1.1.2.2" xref="alg1.l5.m1.1.1.2.2.cmml">Ï‰</mi><mi id="alg1.l5.m1.1.1.2.3" xref="alg1.l5.m1.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml">â†</mo><mi mathvariant="normal" id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml">Î©</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><ci id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1">â†</ci><apply id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.2.1.cmml" xref="alg1.l5.m1.1.1.2">subscript</csymbol><ci id="alg1.l5.m1.1.1.2.2.cmml" xref="alg1.l5.m1.1.1.2.2">ğœ”</ci><ci id="alg1.l5.m1.1.1.2.3.cmml" xref="alg1.l5.m1.1.1.2.3">ğ‘–</ci></apply><ci id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3">Î©</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">\omega_{i}\leftarrow\Omega</annotation></semantics></math>.

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>Â Â Â Â Â Train <math id="alg1.l6.m1.1" class="ltx_Math" alttext="\mathcal{S}_{i}" display="inline"><semantics id="alg1.l6.m1.1a"><msub id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">ğ’®</mi><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">ğ’®</ci><ci id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\mathcal{S}_{i}</annotation></semantics></math> with <math id="alg1.l6.m2.1" class="ltx_Math" alttext="\omega^{train}_{i}" display="inline"><semantics id="alg1.l6.m2.1a"><msubsup id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml"><mi id="alg1.l6.m2.1.1.2.2" xref="alg1.l6.m2.1.1.2.2.cmml">Ï‰</mi><mi id="alg1.l6.m2.1.1.3" xref="alg1.l6.m2.1.1.3.cmml">i</mi><mrow id="alg1.l6.m2.1.1.2.3" xref="alg1.l6.m2.1.1.2.3.cmml"><mi id="alg1.l6.m2.1.1.2.3.2" xref="alg1.l6.m2.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m2.1.1.2.3.1" xref="alg1.l6.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="alg1.l6.m2.1.1.2.3.3" xref="alg1.l6.m2.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m2.1.1.2.3.1a" xref="alg1.l6.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="alg1.l6.m2.1.1.2.3.4" xref="alg1.l6.m2.1.1.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m2.1.1.2.3.1b" xref="alg1.l6.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="alg1.l6.m2.1.1.2.3.5" xref="alg1.l6.m2.1.1.2.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l6.m2.1.1.2.3.1c" xref="alg1.l6.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="alg1.l6.m2.1.1.2.3.6" xref="alg1.l6.m2.1.1.2.3.6.cmml">n</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><apply id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1"><csymbol cd="ambiguous" id="alg1.l6.m2.1.1.1.cmml" xref="alg1.l6.m2.1.1">subscript</csymbol><apply id="alg1.l6.m2.1.1.2.cmml" xref="alg1.l6.m2.1.1"><csymbol cd="ambiguous" id="alg1.l6.m2.1.1.2.1.cmml" xref="alg1.l6.m2.1.1">superscript</csymbol><ci id="alg1.l6.m2.1.1.2.2.cmml" xref="alg1.l6.m2.1.1.2.2">ğœ”</ci><apply id="alg1.l6.m2.1.1.2.3.cmml" xref="alg1.l6.m2.1.1.2.3"><times id="alg1.l6.m2.1.1.2.3.1.cmml" xref="alg1.l6.m2.1.1.2.3.1"></times><ci id="alg1.l6.m2.1.1.2.3.2.cmml" xref="alg1.l6.m2.1.1.2.3.2">ğ‘¡</ci><ci id="alg1.l6.m2.1.1.2.3.3.cmml" xref="alg1.l6.m2.1.1.2.3.3">ğ‘Ÿ</ci><ci id="alg1.l6.m2.1.1.2.3.4.cmml" xref="alg1.l6.m2.1.1.2.3.4">ğ‘</ci><ci id="alg1.l6.m2.1.1.2.3.5.cmml" xref="alg1.l6.m2.1.1.2.3.5">ğ‘–</ci><ci id="alg1.l6.m2.1.1.2.3.6.cmml" xref="alg1.l6.m2.1.1.2.3.6">ğ‘›</ci></apply></apply><ci id="alg1.l6.m2.1.1.3.cmml" xref="alg1.l6.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.1c">\omega^{train}_{i}</annotation></semantics></math>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>Â Â Â Â Â <span id="alg1.l7.2" class="ltx_text ltx_font_bold">for</span>Â batch <math id="alg1.l7.m1.1" class="ltx_Math" alttext="b" display="inline"><semantics id="alg1.l7.m1.1a"><mi id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">b</annotation></semantics></math> <math id="alg1.l7.m2.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="alg1.l7.m2.1a"><mo id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml">âˆˆ</mo><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><in id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">\in</annotation></semantics></math> <math id="alg1.l7.m3.1" class="ltx_Math" alttext="\omega_{i}" display="inline"><semantics id="alg1.l7.m3.1a"><msub id="alg1.l7.m3.1.1" xref="alg1.l7.m3.1.1.cmml"><mi id="alg1.l7.m3.1.1.2" xref="alg1.l7.m3.1.1.2.cmml">Ï‰</mi><mi id="alg1.l7.m3.1.1.3" xref="alg1.l7.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.m3.1b"><apply id="alg1.l7.m3.1.1.cmml" xref="alg1.l7.m3.1.1"><csymbol cd="ambiguous" id="alg1.l7.m3.1.1.1.cmml" xref="alg1.l7.m3.1.1">subscript</csymbol><ci id="alg1.l7.m3.1.1.2.cmml" xref="alg1.l7.m3.1.1.2">ğœ”</ci><ci id="alg1.l7.m3.1.1.3.cmml" xref="alg1.l7.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m3.1c">\omega_{i}</annotation></semantics></math>Â <span id="alg1.l7.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>Â Â Â Â Â Â Â Â Set, size of <math id="alg1.l8.m1.1" class="ltx_Math" alttext="b" display="inline"><semantics id="alg1.l8.m1.1a"><mi id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><ci id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">b</annotation></semantics></math> as <math id="alg1.l8.m2.1" class="ltx_Math" alttext="B" display="inline"><semantics id="alg1.l8.m2.1a"><mi id="alg1.l8.m2.1.1" xref="alg1.l8.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b"><ci id="alg1.l8.m2.1.1.cmml" xref="alg1.l8.m2.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m2.1c">B</annotation></semantics></math>.

</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>Â Â Â Â Â Â Â Â Evaluate <math id="alg1.l9.m1.1" class="ltx_Math" alttext="y\leftarrow\mathrm{S}_{i}(b)" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.2" xref="alg1.l9.m1.1.2.cmml"><mi id="alg1.l9.m1.1.2.2" xref="alg1.l9.m1.1.2.2.cmml">y</mi><mo stretchy="false" id="alg1.l9.m1.1.2.1" xref="alg1.l9.m1.1.2.1.cmml">â†</mo><mrow id="alg1.l9.m1.1.2.3" xref="alg1.l9.m1.1.2.3.cmml"><msub id="alg1.l9.m1.1.2.3.2" xref="alg1.l9.m1.1.2.3.2.cmml"><mi mathvariant="normal" id="alg1.l9.m1.1.2.3.2.2" xref="alg1.l9.m1.1.2.3.2.2.cmml">S</mi><mi id="alg1.l9.m1.1.2.3.2.3" xref="alg1.l9.m1.1.2.3.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="alg1.l9.m1.1.2.3.1" xref="alg1.l9.m1.1.2.3.1.cmml">â€‹</mo><mrow id="alg1.l9.m1.1.2.3.3.2" xref="alg1.l9.m1.1.2.3.cmml"><mo stretchy="false" id="alg1.l9.m1.1.2.3.3.2.1" xref="alg1.l9.m1.1.2.3.cmml">(</mo><mi id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml">b</mi><mo stretchy="false" id="alg1.l9.m1.1.2.3.3.2.2" xref="alg1.l9.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.2.cmml" xref="alg1.l9.m1.1.2"><ci id="alg1.l9.m1.1.2.1.cmml" xref="alg1.l9.m1.1.2.1">â†</ci><ci id="alg1.l9.m1.1.2.2.cmml" xref="alg1.l9.m1.1.2.2">ğ‘¦</ci><apply id="alg1.l9.m1.1.2.3.cmml" xref="alg1.l9.m1.1.2.3"><times id="alg1.l9.m1.1.2.3.1.cmml" xref="alg1.l9.m1.1.2.3.1"></times><apply id="alg1.l9.m1.1.2.3.2.cmml" xref="alg1.l9.m1.1.2.3.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.2.3.2.1.cmml" xref="alg1.l9.m1.1.2.3.2">subscript</csymbol><ci id="alg1.l9.m1.1.2.3.2.2.cmml" xref="alg1.l9.m1.1.2.3.2.2">S</ci><ci id="alg1.l9.m1.1.2.3.2.3.cmml" xref="alg1.l9.m1.1.2.3.2.3">ğ‘–</ci></apply><ci id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">y\leftarrow\mathrm{S}_{i}(b)</annotation></semantics></math>

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>Â Â Â Â Â Â Â Â <span id="alg1.l10.2" class="ltx_text ltx_font_bold">if</span>Â <math id="alg1.l10.m1.1" class="ltx_Math" alttext="b\in\omega^{train}_{i}" display="inline"><semantics id="alg1.l10.m1.1a"><mrow id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><mi id="alg1.l10.m1.1.1.2" xref="alg1.l10.m1.1.1.2.cmml">b</mi><mo id="alg1.l10.m1.1.1.1" xref="alg1.l10.m1.1.1.1.cmml">âˆˆ</mo><msubsup id="alg1.l10.m1.1.1.3" xref="alg1.l10.m1.1.1.3.cmml"><mi id="alg1.l10.m1.1.1.3.2.2" xref="alg1.l10.m1.1.1.3.2.2.cmml">Ï‰</mi><mi id="alg1.l10.m1.1.1.3.3" xref="alg1.l10.m1.1.1.3.3.cmml">i</mi><mrow id="alg1.l10.m1.1.1.3.2.3" xref="alg1.l10.m1.1.1.3.2.3.cmml"><mi id="alg1.l10.m1.1.1.3.2.3.2" xref="alg1.l10.m1.1.1.3.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m1.1.1.3.2.3.1" xref="alg1.l10.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="alg1.l10.m1.1.1.3.2.3.3" xref="alg1.l10.m1.1.1.3.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m1.1.1.3.2.3.1a" xref="alg1.l10.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="alg1.l10.m1.1.1.3.2.3.4" xref="alg1.l10.m1.1.1.3.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m1.1.1.3.2.3.1b" xref="alg1.l10.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="alg1.l10.m1.1.1.3.2.3.5" xref="alg1.l10.m1.1.1.3.2.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m1.1.1.3.2.3.1c" xref="alg1.l10.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="alg1.l10.m1.1.1.3.2.3.6" xref="alg1.l10.m1.1.1.3.2.3.6.cmml">n</mi></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><in id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1"></in><ci id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1.2">ğ‘</ci><apply id="alg1.l10.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.3.1.cmml" xref="alg1.l10.m1.1.1.3">subscript</csymbol><apply id="alg1.l10.m1.1.1.3.2.cmml" xref="alg1.l10.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.3.2.1.cmml" xref="alg1.l10.m1.1.1.3">superscript</csymbol><ci id="alg1.l10.m1.1.1.3.2.2.cmml" xref="alg1.l10.m1.1.1.3.2.2">ğœ”</ci><apply id="alg1.l10.m1.1.1.3.2.3.cmml" xref="alg1.l10.m1.1.1.3.2.3"><times id="alg1.l10.m1.1.1.3.2.3.1.cmml" xref="alg1.l10.m1.1.1.3.2.3.1"></times><ci id="alg1.l10.m1.1.1.3.2.3.2.cmml" xref="alg1.l10.m1.1.1.3.2.3.2">ğ‘¡</ci><ci id="alg1.l10.m1.1.1.3.2.3.3.cmml" xref="alg1.l10.m1.1.1.3.2.3.3">ğ‘Ÿ</ci><ci id="alg1.l10.m1.1.1.3.2.3.4.cmml" xref="alg1.l10.m1.1.1.3.2.3.4">ğ‘</ci><ci id="alg1.l10.m1.1.1.3.2.3.5.cmml" xref="alg1.l10.m1.1.1.3.2.3.5">ğ‘–</ci><ci id="alg1.l10.m1.1.1.3.2.3.6.cmml" xref="alg1.l10.m1.1.1.3.2.3.6">ğ‘›</ci></apply></apply><ci id="alg1.l10.m1.1.1.3.3.cmml" xref="alg1.l10.m1.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">b\in\omega^{train}_{i}</annotation></semantics></math>Â <span id="alg1.l10.3" class="ltx_text ltx_font_bold">then</span>



</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span>Â Â Â Â Â Â Â Â Â Â Â Update <math id="alg1.l11.m1.2" class="ltx_Math" alttext="\mathcal{D}\leftarrow\langle y,in\rangle" display="inline"><semantics id="alg1.l11.m1.2a"><mrow id="alg1.l11.m1.2.2" xref="alg1.l11.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l11.m1.2.2.3" xref="alg1.l11.m1.2.2.3.cmml">ğ’Ÿ</mi><mo stretchy="false" id="alg1.l11.m1.2.2.2" xref="alg1.l11.m1.2.2.2.cmml">â†</mo><mrow id="alg1.l11.m1.2.2.1.1" xref="alg1.l11.m1.2.2.1.2.cmml"><mo stretchy="false" id="alg1.l11.m1.2.2.1.1.2" xref="alg1.l11.m1.2.2.1.2.cmml">âŸ¨</mo><mi id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml">y</mi><mo id="alg1.l11.m1.2.2.1.1.3" xref="alg1.l11.m1.2.2.1.2.cmml">,</mo><mrow id="alg1.l11.m1.2.2.1.1.1" xref="alg1.l11.m1.2.2.1.1.1.cmml"><mi id="alg1.l11.m1.2.2.1.1.1.2" xref="alg1.l11.m1.2.2.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="alg1.l11.m1.2.2.1.1.1.1" xref="alg1.l11.m1.2.2.1.1.1.1.cmml">â€‹</mo><mi id="alg1.l11.m1.2.2.1.1.1.3" xref="alg1.l11.m1.2.2.1.1.1.3.cmml">n</mi></mrow><mo stretchy="false" id="alg1.l11.m1.2.2.1.1.4" xref="alg1.l11.m1.2.2.1.2.cmml">âŸ©</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.2b"><apply id="alg1.l11.m1.2.2.cmml" xref="alg1.l11.m1.2.2"><ci id="alg1.l11.m1.2.2.2.cmml" xref="alg1.l11.m1.2.2.2">â†</ci><ci id="alg1.l11.m1.2.2.3.cmml" xref="alg1.l11.m1.2.2.3">ğ’Ÿ</ci><list id="alg1.l11.m1.2.2.1.2.cmml" xref="alg1.l11.m1.2.2.1.1"><ci id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">ğ‘¦</ci><apply id="alg1.l11.m1.2.2.1.1.1.cmml" xref="alg1.l11.m1.2.2.1.1.1"><times id="alg1.l11.m1.2.2.1.1.1.1.cmml" xref="alg1.l11.m1.2.2.1.1.1.1"></times><ci id="alg1.l11.m1.2.2.1.1.1.2.cmml" xref="alg1.l11.m1.2.2.1.1.1.2">ğ‘–</ci><ci id="alg1.l11.m1.2.2.1.1.1.3.cmml" xref="alg1.l11.m1.2.2.1.1.1.3">ğ‘›</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.2c">\mathcal{D}\leftarrow\langle y,in\rangle</annotation></semantics></math>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span>Â Â Â Â Â Â Â Â <span id="alg1.l12.2" class="ltx_text ltx_font_bold">else</span>Â <span id="alg1.l12.3" class="ltx_text ltx_font_bold">if</span>Â <math id="alg1.l12.m1.1" class="ltx_Math" alttext="b\in\omega^{test}_{i}" display="inline"><semantics id="alg1.l12.m1.1a"><mrow id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mi id="alg1.l12.m1.1.1.2" xref="alg1.l12.m1.1.1.2.cmml">b</mi><mo id="alg1.l12.m1.1.1.1" xref="alg1.l12.m1.1.1.1.cmml">âˆˆ</mo><msubsup id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml"><mi id="alg1.l12.m1.1.1.3.2.2" xref="alg1.l12.m1.1.1.3.2.2.cmml">Ï‰</mi><mi id="alg1.l12.m1.1.1.3.3" xref="alg1.l12.m1.1.1.3.3.cmml">i</mi><mrow id="alg1.l12.m1.1.1.3.2.3" xref="alg1.l12.m1.1.1.3.2.3.cmml"><mi id="alg1.l12.m1.1.1.3.2.3.2" xref="alg1.l12.m1.1.1.3.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.3.2.3.1" xref="alg1.l12.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="alg1.l12.m1.1.1.3.2.3.3" xref="alg1.l12.m1.1.1.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.3.2.3.1a" xref="alg1.l12.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="alg1.l12.m1.1.1.3.2.3.4" xref="alg1.l12.m1.1.1.3.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l12.m1.1.1.3.2.3.1b" xref="alg1.l12.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="alg1.l12.m1.1.1.3.2.3.5" xref="alg1.l12.m1.1.1.3.2.3.5.cmml">t</mi></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><in id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1"></in><ci id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1.2">ğ‘</ci><apply id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.3.1.cmml" xref="alg1.l12.m1.1.1.3">subscript</csymbol><apply id="alg1.l12.m1.1.1.3.2.cmml" xref="alg1.l12.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.3.2.1.cmml" xref="alg1.l12.m1.1.1.3">superscript</csymbol><ci id="alg1.l12.m1.1.1.3.2.2.cmml" xref="alg1.l12.m1.1.1.3.2.2">ğœ”</ci><apply id="alg1.l12.m1.1.1.3.2.3.cmml" xref="alg1.l12.m1.1.1.3.2.3"><times id="alg1.l12.m1.1.1.3.2.3.1.cmml" xref="alg1.l12.m1.1.1.3.2.3.1"></times><ci id="alg1.l12.m1.1.1.3.2.3.2.cmml" xref="alg1.l12.m1.1.1.3.2.3.2">ğ‘¡</ci><ci id="alg1.l12.m1.1.1.3.2.3.3.cmml" xref="alg1.l12.m1.1.1.3.2.3.3">ğ‘’</ci><ci id="alg1.l12.m1.1.1.3.2.3.4.cmml" xref="alg1.l12.m1.1.1.3.2.3.4">ğ‘ </ci><ci id="alg1.l12.m1.1.1.3.2.3.5.cmml" xref="alg1.l12.m1.1.1.3.2.3.5">ğ‘¡</ci></apply></apply><ci id="alg1.l12.m1.1.1.3.3.cmml" xref="alg1.l12.m1.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">b\in\omega^{test}_{i}</annotation></semantics></math>Â <span id="alg1.l12.4" class="ltx_text ltx_font_bold">then</span>



</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span>Â Â Â Â Â Â Â Â Â Â Â Update <math id="alg1.l13.m1.2" class="ltx_Math" alttext="\mathcal{D}\leftarrow\langle y,out\rangle" display="inline"><semantics id="alg1.l13.m1.2a"><mrow id="alg1.l13.m1.2.2" xref="alg1.l13.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l13.m1.2.2.3" xref="alg1.l13.m1.2.2.3.cmml">ğ’Ÿ</mi><mo stretchy="false" id="alg1.l13.m1.2.2.2" xref="alg1.l13.m1.2.2.2.cmml">â†</mo><mrow id="alg1.l13.m1.2.2.1.1" xref="alg1.l13.m1.2.2.1.2.cmml"><mo stretchy="false" id="alg1.l13.m1.2.2.1.1.2" xref="alg1.l13.m1.2.2.1.2.cmml">âŸ¨</mo><mi id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml">y</mi><mo id="alg1.l13.m1.2.2.1.1.3" xref="alg1.l13.m1.2.2.1.2.cmml">,</mo><mrow id="alg1.l13.m1.2.2.1.1.1" xref="alg1.l13.m1.2.2.1.1.1.cmml"><mi id="alg1.l13.m1.2.2.1.1.1.2" xref="alg1.l13.m1.2.2.1.1.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="alg1.l13.m1.2.2.1.1.1.1" xref="alg1.l13.m1.2.2.1.1.1.1.cmml">â€‹</mo><mi id="alg1.l13.m1.2.2.1.1.1.3" xref="alg1.l13.m1.2.2.1.1.1.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="alg1.l13.m1.2.2.1.1.1.1a" xref="alg1.l13.m1.2.2.1.1.1.1.cmml">â€‹</mo><mi id="alg1.l13.m1.2.2.1.1.1.4" xref="alg1.l13.m1.2.2.1.1.1.4.cmml">t</mi></mrow><mo stretchy="false" id="alg1.l13.m1.2.2.1.1.4" xref="alg1.l13.m1.2.2.1.2.cmml">âŸ©</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.2b"><apply id="alg1.l13.m1.2.2.cmml" xref="alg1.l13.m1.2.2"><ci id="alg1.l13.m1.2.2.2.cmml" xref="alg1.l13.m1.2.2.2">â†</ci><ci id="alg1.l13.m1.2.2.3.cmml" xref="alg1.l13.m1.2.2.3">ğ’Ÿ</ci><list id="alg1.l13.m1.2.2.1.2.cmml" xref="alg1.l13.m1.2.2.1.1"><ci id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1">ğ‘¦</ci><apply id="alg1.l13.m1.2.2.1.1.1.cmml" xref="alg1.l13.m1.2.2.1.1.1"><times id="alg1.l13.m1.2.2.1.1.1.1.cmml" xref="alg1.l13.m1.2.2.1.1.1.1"></times><ci id="alg1.l13.m1.2.2.1.1.1.2.cmml" xref="alg1.l13.m1.2.2.1.1.1.2">ğ‘œ</ci><ci id="alg1.l13.m1.2.2.1.1.1.3.cmml" xref="alg1.l13.m1.2.2.1.1.1.3">ğ‘¢</ci><ci id="alg1.l13.m1.2.2.1.1.1.4.cmml" xref="alg1.l13.m1.2.2.1.1.1.4">ğ‘¡</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.2c">\mathcal{D}\leftarrow\langle y,out\rangle</annotation></semantics></math>

</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span>Â Â Â Â Â Â Â Â <span id="alg1.l14.2" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l14.3" class="ltx_text ltx_font_bold">if</span>
</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.1.1.1" class="ltx_text" style="font-size:80%;">15:</span></span>Â Â Â Â Â <span id="alg1.l15.2" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l15.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span>Â Â <span id="alg1.l16.2" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l16.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l17.1.1.1" class="ltx_text" style="font-size:80%;">17:</span></span>Â Â Train <math id="alg1.l17.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="alg1.l17.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><ci id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">\mathcal{A}</annotation></semantics></math> with <math id="alg1.l17.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="alg1.l17.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l17.m2.1.1" xref="alg1.l17.m2.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="alg1.l17.m2.1b"><ci id="alg1.l17.m2.1.1.cmml" xref="alg1.l17.m2.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m2.1c">\mathcal{D}</annotation></semantics></math>

</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l18.1.1.1" class="ltx_text" style="font-size:80%;">18:</span></span>Â Â <span id="alg1.l18.2" class="ltx_text ltx_font_bold">return</span> Â <math id="alg1.l18.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="alg1.l18.m1.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l18.m1.1.1" xref="alg1.l18.m1.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.1b"><ci id="alg1.l18.m1.1.1.cmml" xref="alg1.l18.m1.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.1c">\mathcal{A}</annotation></semantics></math>

</div>
</div>
</div>
</div>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Performance Evaluation</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we first define our experimental setup, then we demonstrate the effect of MIA on federally trained ML as opposed to a centrally trained model. Finally, we demonstrate the effect of batch-wise generation of the attack dataset.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.4.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.5.2" class="ltx_text ltx_font_italic">Experimental Setup</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.6" class="ltx_p">We define a centralized FL architecture that trains ML models over a wide range of datasets. The architecture distributes the datasets into <math id="S6.SS1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S6.SS1.p1.1.m1.1a"><mi id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><ci id="S6.SS1.p1.1.m1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">n</annotation></semantics></math> disjoint subsets and sends them to <math id="S6.SS1.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S6.SS1.p1.2.m2.1a"><mi id="S6.SS1.p1.2.m2.1.1" xref="S6.SS1.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.2.m2.1b"><ci id="S6.SS1.p1.2.m2.1.1.cmml" xref="S6.SS1.p1.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.2.m2.1c">n</annotation></semantics></math> clients. Each client trains a local copy of the model architecture on the locally available data. After <math id="S6.SS1.p1.3.m3.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S6.SS1.p1.3.m3.1a"><mi id="S6.SS1.p1.3.m3.1.1" xref="S6.SS1.p1.3.m3.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.3.m3.1b"><ci id="S6.SS1.p1.3.m3.1.1.cmml" xref="S6.SS1.p1.3.m3.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.3.m3.1c">e</annotation></semantics></math> epochs of local training the clients (securely) share the model weights with the orchestrating server which combines all the received model weights through a federated average <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcmahan2017communication</span>]</cite> to define the global model, which is sent back to the clients. For the next round, the client completes <math id="S6.SS1.p1.4.m4.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S6.SS1.p1.4.m4.1a"><mi id="S6.SS1.p1.4.m4.1.1" xref="S6.SS1.p1.4.m4.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.4.m4.1b"><ci id="S6.SS1.p1.4.m4.1.1.cmml" xref="S6.SS1.p1.4.m4.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.4.m4.1c">e</annotation></semantics></math> epochs of local training on the received model and shares the updated weights with the server. The server conducts <math id="S6.SS1.p1.5.m5.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S6.SS1.p1.5.m5.1a"><mi id="S6.SS1.p1.5.m5.1.1" xref="S6.SS1.p1.5.m5.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.5.m5.1b"><ci id="S6.SS1.p1.5.m5.1.1.cmml" xref="S6.SS1.p1.5.m5.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.5.m5.1c">r</annotation></semantics></math> such rounds to arrive at the global model. For a baseline comparison, an ML model with the same architecture is trained for <math id="S6.SS1.p1.6.m6.1" class="ltx_Math" alttext="e\times r" display="inline"><semantics id="S6.SS1.p1.6.m6.1a"><mrow id="S6.SS1.p1.6.m6.1.1" xref="S6.SS1.p1.6.m6.1.1.cmml"><mi id="S6.SS1.p1.6.m6.1.1.2" xref="S6.SS1.p1.6.m6.1.1.2.cmml">e</mi><mo lspace="0.222em" rspace="0.222em" id="S6.SS1.p1.6.m6.1.1.1" xref="S6.SS1.p1.6.m6.1.1.1.cmml">Ã—</mo><mi id="S6.SS1.p1.6.m6.1.1.3" xref="S6.SS1.p1.6.m6.1.1.3.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.6.m6.1b"><apply id="S6.SS1.p1.6.m6.1.1.cmml" xref="S6.SS1.p1.6.m6.1.1"><times id="S6.SS1.p1.6.m6.1.1.1.cmml" xref="S6.SS1.p1.6.m6.1.1.1"></times><ci id="S6.SS1.p1.6.m6.1.1.2.cmml" xref="S6.SS1.p1.6.m6.1.1.2">ğ‘’</ci><ci id="S6.SS1.p1.6.m6.1.1.3.cmml" xref="S6.SS1.p1.6.m6.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.6.m6.1c">e\times r</annotation></semantics></math> epochs.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">For this work, we evaluated the efficientnet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> architecture on the CIFAR10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, CIFAR100 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, and FashionMNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> datasets.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.4.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.5.2" class="ltx_text ltx_font_italic">Membership Inference Attack on FL</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.3" class="ltx_p">In this section, we present how successful membership inference attack is on ML models trained centrally or in a federated manner over <math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mn id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><cn type="integer" id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">2</annotation></semantics></math>, <math id="S6.SS2.p1.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S6.SS2.p1.2.m2.1a"><mn id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><cn type="integer" id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">5</annotation></semantics></math>, and <math id="S6.SS2.p1.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S6.SS2.p1.3.m3.1a"><mn id="S6.SS2.p1.3.m3.1.1" xref="S6.SS2.p1.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.3.m3.1b"><cn type="integer" id="S6.SS2.p1.3.m3.1.1.cmml" xref="S6.SS2.p1.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.3.m3.1c">10</annotation></semantics></math> clients. <a href="#S6.F4" title="In VI-B Membership Inference Attack on FL â€£ VI Performance Evaluation â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> summarizes the accuracy of the MIA over the trained ML models.</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2312.00051/assets/Fig_4.png" id="S6.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="305" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Effectiveness of MIA in FL environment on CIFAR10 dataset for different number of clients.</figcaption>
</figure>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.2" class="ltx_p">When the model is trained centrally, we achieve almost <math id="S6.SS2.p2.1.m1.1" class="ltx_Math" alttext="83.3\%" display="inline"><semantics id="S6.SS2.p2.1.m1.1a"><mrow id="S6.SS2.p2.1.m1.1.1" xref="S6.SS2.p2.1.m1.1.1.cmml"><mn id="S6.SS2.p2.1.m1.1.1.2" xref="S6.SS2.p2.1.m1.1.1.2.cmml">83.3</mn><mo id="S6.SS2.p2.1.m1.1.1.1" xref="S6.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.1.m1.1b"><apply id="S6.SS2.p2.1.m1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S6.SS2.p2.1.m1.1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.SS2.p2.1.m1.1.1.2.cmml" xref="S6.SS2.p2.1.m1.1.1.2">83.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.1.m1.1c">83.3\%</annotation></semantics></math> attack accuracy. In contrast, for a federally trained model, we get a maximum accuracy of <math id="S6.SS2.p2.2.m2.1" class="ltx_Math" alttext="78.6\%" display="inline"><semantics id="S6.SS2.p2.2.m2.1a"><mrow id="S6.SS2.p2.2.m2.1.1" xref="S6.SS2.p2.2.m2.1.1.cmml"><mn id="S6.SS2.p2.2.m2.1.1.2" xref="S6.SS2.p2.2.m2.1.1.2.cmml">78.6</mn><mo id="S6.SS2.p2.2.m2.1.1.1" xref="S6.SS2.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.2.m2.1b"><apply id="S6.SS2.p2.2.m2.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1"><csymbol cd="latexml" id="S6.SS2.p2.2.m2.1.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S6.SS2.p2.2.m2.1.1.2.cmml" xref="S6.SS2.p2.2.m2.1.1.2">78.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.2.m2.1c">78.6\%</annotation></semantics></math> for ten clients. Therefore, when the model is trained federally, the attack is less effective.
However, as the number of contributing clients increases this effect becomes less pronounced. Another observation, elaborated upon in the next section, training the model over federated architecture can mitigate the attackerâ€™s advantage gained by the proposed MIA-BAD approach.</p>
</div>
<figure id="S6.F5" class="ltx_figure"><img src="/html/2312.00051/assets/Fig_5.png" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="387" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Comparison of the advantage of the MIA-BAD approach for 2, 5, and 10 clients as performed using CIFAR10, CIFAR100, MNIST, and FashionMNIST datasets.</figcaption>
</figure>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.4.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.5.2" class="ltx_text ltx_font_italic">Effect of Generating the Attack Dataset Batch-wise</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">In this section, we highlight the experimental results of the proposed MIA-BAD approach. <a href="#S5.T1" title="In V-A The Overall Attack Paradigm â€£ V The MIA-BAD Approach â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">I</span></a> shows the effect of generating the attack dataset batch-wise when the target dataset is CIFAR10. From <a href="#S5.T1" title="In V-A The Overall Attack Paradigm â€£ V The MIA-BAD Approach â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">table</span>Â <span class="ltx_text ltx_ref_tag">I</span></a> we observe that the advantage of the MIA-BAD approach is not affected by the batch size. <a href="#S6.T2" title="In VI-C Effect of Generating the Attack Dataset Batch-wise â€£ VI Performance Evaluation â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">II</span></a> demonstrates the same result for MNIST, FashionMnist, and CIFAR100 respectively.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Comparison of accuracy of MIA-BAD on MNIST, FashionMNIST, and CIFAR100 datasets.</figcaption>
<table id="S6.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T2.3.4.1" class="ltx_tr">
<th id="S6.T2.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S6.T2.3.4.1.1.1" class="ltx_text">Training Mode</span></th>
<th id="S6.T2.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" colspan="2">MNIST</th>
<th id="S6.T2.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">FashionMNIST</th>
<th id="S6.T2.3.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2">CIFAR100</th>
</tr>
<tr id="S6.T2.3.5.2" class="ltx_tr">
<th id="S6.T2.3.5.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Sample</th>
<th id="S6.T2.3.5.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Batch</th>
<th id="S6.T2.3.5.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Sample</th>
<th id="S6.T2.3.5.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Batch</th>
<th id="S6.T2.3.5.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Sample</th>
<th id="S6.T2.3.5.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Batch</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T2.1.1" class="ltx_tr">
<th id="S6.T2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<math id="S6.T2.1.1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.T2.1.1.1.m1.1a"><mn id="S6.T2.1.1.1.m1.1.1" xref="S6.T2.1.1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.T2.1.1.1.m1.1b"><cn type="integer" id="S6.T2.1.1.1.m1.1.1.cmml" xref="S6.T2.1.1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.1.1.1.m1.1c">2</annotation></semantics></math> clients</th>
<td id="S6.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_t">0.838</td>
<td id="S6.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.846</td>
<td id="S6.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_t">0.747</td>
<td id="S6.T2.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.807</td>
<td id="S6.T2.1.1.6" class="ltx_td ltx_align_center ltx_border_t">0.701</td>
<td id="S6.T2.1.1.7" class="ltx_td ltx_align_center ltx_border_t">0.721</td>
</tr>
<tr id="S6.T2.2.2" class="ltx_tr">
<th id="S6.T2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<math id="S6.T2.2.2.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S6.T2.2.2.1.m1.1a"><mn id="S6.T2.2.2.1.m1.1.1" xref="S6.T2.2.2.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.T2.2.2.1.m1.1b"><cn type="integer" id="S6.T2.2.2.1.m1.1.1.cmml" xref="S6.T2.2.2.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.2.2.1.m1.1c">5</annotation></semantics></math> clients</th>
<td id="S6.T2.2.2.2" class="ltx_td ltx_align_center">0.840</td>
<td id="S6.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_r">0.847</td>
<td id="S6.T2.2.2.4" class="ltx_td ltx_align_center">0.749</td>
<td id="S6.T2.2.2.5" class="ltx_td ltx_align_center ltx_border_r">0.805</td>
<td id="S6.T2.2.2.6" class="ltx_td ltx_align_center">0.757</td>
<td id="S6.T2.2.2.7" class="ltx_td ltx_align_center">0.769</td>
</tr>
<tr id="S6.T2.3.3" class="ltx_tr">
<th id="S6.T2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">
<math id="S6.T2.3.3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S6.T2.3.3.1.m1.1a"><mn id="S6.T2.3.3.1.m1.1.1" xref="S6.T2.3.3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S6.T2.3.3.1.m1.1b"><cn type="integer" id="S6.T2.3.3.1.m1.1.1.cmml" xref="S6.T2.3.3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.3.3.1.m1.1c">10</annotation></semantics></math> clients</th>
<td id="S6.T2.3.3.2" class="ltx_td ltx_align_center ltx_border_b">0.849</td>
<td id="S6.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.852</td>
<td id="S6.T2.3.3.4" class="ltx_td ltx_align_center ltx_border_b">0.787</td>
<td id="S6.T2.3.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.798</td>
<td id="S6.T2.3.3.6" class="ltx_td ltx_align_center ltx_border_b">0.786</td>
<td id="S6.T2.3.3.7" class="ltx_td ltx_align_center ltx_border_b">0.798</td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p"><a href="#S5.T1" title="In V-A The Overall Attack Paradigm â€£ V The MIA-BAD Approach â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">I</span></a> demonstrates how batch-wise generation of the attack dataset improves the attackerâ€™s advantage. We also observe that this effect is mostly independent of the batch size itself. Therefore, we only consider batch size 32 for the remaining datasets. We hypothesize that the marginal gain over the greater ensemble effect is perfectly countered by the reduced (attack) dataset size.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS4.4.1.1" class="ltx_text">VI-D</span> </span><span id="S6.SS4.5.2" class="ltx_text ltx_font_italic">Effect of FL on the Proposed Approach</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.2" class="ltx_p">From <a href="#S5.T1" title="In V-A The Overall Attack Paradigm â€£ V The MIA-BAD Approach â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">tables</span>Â <span class="ltx_text ltx_ref_tag">I</span></a> andÂ <a href="#S6.T2" title="Table II â€£ VI-C Effect of Generating the Attack Dataset Batch-wise â€£ VI Performance Evaluation â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we observe that the attackerâ€™s advantage over the MIA-BAD approach can be strongly countered by federated training of the ML model. The attackerâ€™s advantage is determined by the difference between batch-wise and sample-wise accuracy. In the case of CIFAR10, we consider the average batch-wise accuracy, for the remaining we consider batch size <math id="S6.SS4.p1.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S6.SS4.p1.1.m1.1a"><mn id="S6.SS4.p1.1.m1.1.1" xref="S6.SS4.p1.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.1.m1.1b"><cn type="integer" id="S6.SS4.p1.1.m1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.1.m1.1c">32</annotation></semantics></math>. Empirically, we observe the number of federated clients is inversely proportional to the effect of the MIA-BAD approach. <a href="#S6.F5" title="In VI-B Membership Inference Attack on FL â€£ VI Performance Evaluation â€£ MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> demonstrates how the attackerâ€™s advantage through MIA-BAD can be mitigated through the federated training of ML models. In FashionMNIST, we observe the greatest advantage with the MIA-BAD approach, but nevertheless, it is mitigated with a high client count. Furthermore, with <math id="S6.SS4.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S6.SS4.p1.2.m2.1a"><mn id="S6.SS4.p1.2.m2.1.1" xref="S6.SS4.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.2.m2.1b"><cn type="integer" id="S6.SS4.p1.2.m2.1.1.cmml" xref="S6.SS4.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.2.m2.1c">10</annotation></semantics></math> clients we observed a negative advantage in the case of CIFAR10, completely mitigating the MIA-BAD advantage.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Conclusion and future Scope</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we propose a membership inference attack approach, MIA-BAD. We demonstrate that batch-wise attack dataset generation can provide an advantage to the adversary. We also demonstrate how the FL paradigm can be utilized to mitigate this approach. The proposed phenomenon is novel and promising and merits further investigation. In future works, we plan to investigate how the observed trends generalize over different ML models and more diverse datasets. We also plan to investigate if the proposed approach can be utilized with more advanced variants of the membership attacks.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
H.Â McMahan, E.Â Moore, D.Â Ramage, and B.Â Arcas, â€œFederated learning of deep
networks using model averaging. arxiv 2016,â€ <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1602.05629</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
M.Â Vucovich, A.Â Tarcar, P.Â Rebelo, N.Â Gade, R.Â Porwal, A.Â Rahman, C.Â Redino,
K.Â Choi, D.Â Nandakumar, R.Â Schiller <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">etÂ al.</em>, â€œAnomaly detection via
federated learning,â€ <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.06614</em>, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J.Â Chen, X.Â Zhang, R.Â Zhang, C.Â Wang, and L.Â Liu, â€œDe-pois: An attack-agnostic
defense against data poisoning attacks,â€ <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Information Forensics and Security</em>, vol.Â 16, pp. 3412â€“3425, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
C.Â Ma, J.Â Li, M.Â Ding, H.Â H. Yang, F.Â Shu, T.Â Q. Quek, and H.Â V. Poor, â€œOn
safeguarding privacy and security in the framework of federated learning,â€
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE network</em>, vol.Â 34, no.Â 4, pp. 242â€“248, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H.Â Hu, Z.Â Salcic, L.Â Sun, G.Â Dobbie, and X.Â Zhang, â€œSource inference attacks
in federated learning,â€ in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Data
Mining (ICDM)</em>.Â Â Â IEEE, 2021, pp.
1102â€“1107.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
R.Â Shokri, M.Â Stronati, C.Â Song, and V.Â Shmatikov, â€œMembership inference
attacks against machine learning models,â€ in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">2017 IEEE symposium on
security and privacy (SP)</em>.Â Â Â IEEE,
2017, pp. 3â€“18.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M.Â Nasr, R.Â Shokri, and A.Â Houmansadr, â€œComprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,â€ in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2019 IEEE symposium on security and
privacy (SP)</em>.Â Â Â IEEE, 2019, pp.
739â€“753.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M.Â G. Crowson, D.Â Moukheiber, A.Â R. ArÃ©valo, B.Â D. Lam, S.Â Mantena,
A.Â Rana, D.Â Goss, D.Â W. Bates, and L.Â A. Celi, â€œA systematic review of
federated learning applications for biomedical data,â€ <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">PLOS Digital
Health</em>, vol.Â 1, no.Â 5, p. e0000033, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M.Â Ali, F.Â Naeem, M.Â Tariq, and G.Â Kaddoum, â€œFederated learning for privacy
preservation in smart healthcare systems: A comprehensive survey,â€
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE journal of biomedical and health informatics</em>, vol.Â 27, no.Â 2, pp.
778â€“789, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
X.Â Yin, Y.Â Zhu, and J.Â Hu, â€œA comprehensive survey of privacy-preserving
federated learning: A taxonomy, review, and future directions,â€ <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">ACM
Computing Surveys (CSUR)</em>, vol.Â 54, no.Â 6, pp. 1â€“36, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R.Â C. Geyer, T.Â Klein, and M.Â Nabi, â€œDifferentially private federated
learning: A client level perspective,â€ <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1712.07557</em>, 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S.Â Truex, N.Â Baracaldo, A.Â Anwar, T.Â Steinke, H.Â Ludwig, R.Â Zhang, and Y.Â Zhou,
â€œA hybrid approach to privacy-preserving federated learning,â€ in
<em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM workshop on artificial intelligence and
security</em>, 2019, pp. 1â€“11.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
H.Â B. McMahan, D.Â Ramage, K.Â Talwar, and L.Â Zhang, â€œLearning differentially
private recurrent language models,â€ <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.06963</em>,
2017.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L.Â Sun, J.Â Qian, and X.Â Chen, â€œLdp-fl: Practical private aggregation in
federated learning with local differential privacy,â€ <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2007.15789</em>, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
H.Â Lee, J.Â Kim, S.Â Ahn, R.Â Hussain, S.Â Cho, and J.Â Son, â€œDigestive neural
networks: A novel defense strategy against inference attacks in federated
learning,â€ <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">computers &amp; security</em>, vol. 109, p. 102378, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S.Â Truex, L.Â Liu, M.Â E. Gursoy, L.Â Yu, and W.Â Wei, â€œDemystifying membership
inference attacks in machine learning as a service,â€ <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Services Computing</em>, vol.Â 14, no.Â 6, pp. 2073â€“2089, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A.Â Salem, Y.Â Zhang, M.Â Humbert, P.Â Berrang, M.Â Fritz, and M.Â Backes,
â€œMl-leaks: Model and data independent membership inference attacks and
defenses on machine learning models,â€ <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1806.01246</em>, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
X.Â Xu, J.Â Wu, M.Â Yang, T.Â Luo, X.Â Duan, W.Â Li, Y.Â Wu, and B.Â Wu, â€œInformation
leakage by model weights on federated learning,â€ in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2020 workshop on privacy-preserving machine learning in practice</em>, 2020, pp.
31â€“36.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
T.Â G. Dietterich, â€œEnsemble methods in machine learning,â€ in
<em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">International workshop on multiple classifier systems</em>.Â Â Â Springer, 2000, pp. 1â€“15.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
N.Â S. Keskar, D.Â Mudigere, J.Â Nocedal, M.Â Smelyanskiy, and P.Â T.Â P. Tang, â€œOn
large-batch training for deep learning: Generalization gap and sharp
minima,â€ <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1609.04836</em>, 2016.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M.Â Tan and Q.Â Le, â€œEfficientnet: Rethinking model scaling for convolutional
neural networks,â€ in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">International conference on machine
learning</em>.Â Â Â PMLR, 2019, pp. 6105â€“6114.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A.Â Krizhevsky, G.Â Hinton <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">etÂ al.</em>, â€œLearning multiple layers of features
from tiny images,â€ 2009.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y.Â LeCun, â€œThe mnist database of handwritten digits,â€ <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">http://yann.
lecun. com/exdb/mnist/</em>, 1998.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
H.Â Xiao, K.Â Rasul, and R.Â Vollgraf, â€œFashion-mnist: a novel image dataset for
benchmarking machine learning algorithms,â€ <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1708.07747</em>, 2017.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.00050" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.00051" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2312.00051">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.00051" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.00052" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 16:11:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
