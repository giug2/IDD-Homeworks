<article class="ltx_document">
 <h1 class="ltx_title ltx_title_document">
  <span class="ltx_text ltx_font_typewriter" id="id6.id1">
   MapCoder
  </span>
  : Multi-Agent Code Generation
  <br class="ltx_break"/>
  for Competitive Problem Solving
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Md. Ashraful Islam
    <sup class="ltx_sup" id="id7.6.id1">
     1
    </sup>
    ,  Mohammed Eunus Ali
    <sup class="ltx_sup" id="id8.7.id2">
     1
    </sup>
    ,  Md Rizwan Parvez
    <sup class="ltx_sup" id="id9.8.id3">
     2
    </sup>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id10.9.id4">
     1
    </sup>
    Bangladesh University of Engineering and Technology
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id11.10.id5">
     2
    </sup>
    Qatar Computing Research Institute (QCRI)
    <br class="ltx_break"/>
    {mdashrafulpramanic, mohammed.eunus.ali}@gmail.com, mparvez@hbku.edu.qa
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id12.id1">
   Code synthesis, which requires a deep understanding of complex natural language (NL) problem descriptions, generation of code instructions for complex algorithms and data structures, and the successful execution of comprehensive unit tests, presents a significant challenge. Thus, while large language models (LLMs) demonstrate impressive proficiency in natural language processing (NLP), their performance in code generation tasks remains limited. In this paper, we introduce a new approach to code generation tasks leveraging the multi-agent prompting that uniquely replicates the full cycle of program synthesis as observed in human developers. Our framework,
   <span class="ltx_text ltx_font_typewriter" id="id12.id1.1">
    MapCoder
   </span>
   , consists of four LLM agents specifically designed to emulate the stages of this cycle: recalling relevant examples, planning, code generation, and debugging. After conducting thorough experiments, with multiple LLMs ablations and analyses across eight challenging competitive problem-solving and program synthesis benchmarks—
   <span class="ltx_text ltx_font_typewriter" id="id12.id1.2">
    MapCoder
   </span>
   showcases remarkable code generation capabilities, achieving their new state-of-the-art (pass@1) results—(HumanEval
   <span class="ltx_text ltx_font_bold" id="id12.id1.3">
    93.9%
   </span>
   , MBPP
   <span class="ltx_text ltx_font_bold" id="id12.id1.4">
    83.1%
   </span>
   , APPS
   <span class="ltx_text ltx_font_bold" id="id12.id1.5">
    22.0%
   </span>
   , CodeContests
   <span class="ltx_text ltx_font_bold" id="id12.id1.6">
    28.5%
   </span>
   , and xCodeEval
   <span class="ltx_text ltx_font_bold" id="id12.id1.7">
    45.3%
   </span>
   ).
Moreover, our method consistently delivers superior performance across various programming languages and varying problem difficulties. We open-source our framework at
   <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Md-Ashraful-Pramanik/MapCoder" target="_blank" title="">
    https://github.com/Md-Ashraful-Pramanik/MapCoder
   </a>
   .
  </p>
 </div>
 <div class="ltx_para ltx_noindent" id="p1">
  <div class="ltx_block ltx_align_bottom" id="p1.5">
   <p class="ltx_p" id="p1.5.6">
    <span class="ltx_text ltx_font_typewriter" id="p1.5.6.1">
     MapCoder
    </span>
    <span class="ltx_text ltx_font_bold" id="p1.5.6.2">
     : Multi-Agent Code Generation
     <br class="ltx_break"/>
     for Competitive Problem Solving
    </span>
   </p>
   <br class="ltx_break ltx_centering"/>
   <p class="ltx_p ltx_align_center" id="p1.5.5" style="width:433.6pt;">
    <span class="ltx_text ltx_inline-block" id="p1.5.5.5" style="width:0.0pt;">
     <span class="ltx_tabular ltx_align_top" id="p1.5.5.5.5">
      <span class="ltx_tbody">
       <span class="ltx_tr" id="p1.3.3.3.3.3">
        <span class="ltx_td ltx_align_center" id="p1.3.3.3.3.3.3">
         <span class="ltx_text ltx_font_bold" id="p1.3.3.3.3.3.3.3">
          Md. Ashraful Islam
          <sup class="ltx_sup" id="p1.3.3.3.3.3.3.3.1">
           <span class="ltx_text ltx_font_medium" id="p1.3.3.3.3.3.3.3.1.1">
            1
           </span>
          </sup>
          ,  Mohammed Eunus Ali
          <sup class="ltx_sup" id="p1.3.3.3.3.3.3.3.2">
           <span class="ltx_text ltx_font_medium" id="p1.3.3.3.3.3.3.3.2.1">
            1
           </span>
          </sup>
          ,  Md Rizwan Parvez
          <sup class="ltx_sup" id="p1.3.3.3.3.3.3.3.3">
           <span class="ltx_text ltx_font_medium" id="p1.3.3.3.3.3.3.3.3.1">
            2
           </span>
          </sup>
         </span>
        </span>
       </span>
       <span class="ltx_tr" id="p1.4.4.4.4.4">
        <span class="ltx_td ltx_align_center" id="p1.4.4.4.4.4.1">
         <sup class="ltx_sup" id="p1.4.4.4.4.4.1.1">
          1
         </sup>
         Bangladesh University of Engineering and Technology
        </span>
       </span>
       <span class="ltx_tr" id="p1.5.5.5.5.5">
        <span class="ltx_td ltx_align_center" id="p1.5.5.5.5.5.1">
         <sup class="ltx_sup" id="p1.5.5.5.5.5.1.1">
          2
         </sup>
         Qatar Computing Research Institute (QCRI)
        </span>
       </span>
       <span class="ltx_tr" id="p1.5.5.5.5.6.1">
        <span class="ltx_td ltx_align_center" id="p1.5.5.5.5.6.1.1">
         {mdashrafulpramanic, mohammed.eunus.ali}@gmail.com, mparvez@hbku.edu.qa
        </span>
       </span>
      </span>
     </span>
    </span>
   </p>
   <br class="ltx_break ltx_centering"/>
  </div>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Computer Programming has emerged as an ubiquitous problem-solving tool that brings tremendous benefits to every aspects of our life
    <cite class="ltx_cite ltx_citemacro_cite">
     Li et al. (
     <a class="ltx_ref" href="#bib.bib25" title="">
      2022a
     </a>
     ); Parvez et al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2018
     </a>
     ); Knuth (
     <a class="ltx_ref" href="#bib.bib22" title="">
      1992
     </a>
     )
    </cite>
    . To maximize programmers’ productivity, and enhance accessibility, automation in program synthesis is paramount. With the growth of LLMs, significant advancements have been made in program synthesis—driving us in an era where we can generate fully executable code, requiring no human intervention
    <cite class="ltx_cite ltx_citemacro_cite">
     Chowdhery et al. (
     <a class="ltx_ref" href="#bib.bib9" title="">
      2022
     </a>
     ); Nijkamp et al. (
     <a class="ltx_ref" href="#bib.bib29" title="">
      2022
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Despite LLMs’ initial success and the scaling up of model size and data, many of these models still struggle to perform well on complex problem-solving tasks, especially in competitive programming problems
    <cite class="ltx_cite ltx_citemacro_cite">
     Austin et al. (
     <a class="ltx_ref" href="#bib.bib4" title="">
      2021
     </a>
     )
    </cite>
    . To mitigate this gap, in this paper, we introduce
    <span class="ltx_text ltx_font_typewriter" id="S1.p2.1.1">
     MapCoder
    </span>
    : a
    <span class="ltx_text ltx_font_bold" id="S1.p2.1.2">
     M
    </span>
    ulti-
    <span class="ltx_text ltx_font_bold" id="S1.p2.1.3">
     A
    </span>
    gent
    <span class="ltx_text ltx_font_bold" id="S1.p2.1.4">
     P
    </span>
    rompting Based Code Generation approach that can seamlessly synthesize solutions for competition-level programming problems.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    Competitive programming or competition-level code generation, often regarded as the pinnacle of problem-solving, is an challenging task. It requires a deep comprehension of NL problem descriptions, multi-step complex reasoning beyond mere memorization, excellence in algorithms and data structures, and the capability to generate substantial code that produces desired outputs aligned with comprehensive test cases
    <cite class="ltx_cite ltx_citemacro_cite">
     Khan et al. (
     <a class="ltx_ref" href="#bib.bib21" title="">
      2023
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="222" id="S1.F1.g1" src="/html/2405.11403/assets/x1.png" width="456"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    Overview of
    <span class="ltx_text ltx_font_typewriter" id="S1.F1.2.1">
     MapCoder
    </span>
    (top). It starts with a retrieval agent that generates relevant examples itself, followed by planning, coding, and iterative debugging agents. Our dynamic traversal (bottom) considers the confidence of the generated plans as their reward scores and leverages them to guide the code generation accordingly.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    Early approaches utilizing LLMs for code generation employ a direct prompting approach, where LLMs generate code directly from problem descriptions and sample I/O
    <cite class="ltx_cite ltx_citemacro_cite">
     Chen et al. (
     <a class="ltx_ref" href="#bib.bib6" title="">
      2021a
     </a>
     )
    </cite>
    . Recent methods like chain-of-thought
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib44" title="">
      2022a
     </a>
     )
    </cite>
    advocates modular or pseudo code-based generation to enhance planning and reduce errors, while retrieval-based approaches such as
    <cite class="ltx_cite ltx_citemacro_citet">
     Parvez et al. (
     <a class="ltx_ref" href="#bib.bib32" title="">
      2021
     </a>
     )
    </cite>
    leverage relevant problems and solutions to guide LLMs’ code generations. However, gains in such approaches remains limited in such a complex task like code generation where LLMs’ generated code often fails to pass the test cases and they do not feature bug-fixing schema
    <cite class="ltx_cite ltx_citemacro_cite">
     Ridnik et al. (
     <a class="ltx_ref" href="#bib.bib37" title="">
      2024
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    A promising solution to the above challenge is self-reflection
    <cite class="ltx_cite ltx_citemacro_cite">
     Shinn et al. (
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     ); Chen et al. (
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022
     </a>
     )
    </cite>
    , which iteratively evaluates the generated code against test cases, reflects on mistakes and modifies accordingly. However, such approaches have limitations too. Firstly, while previous studies indicate that superior problem-solving capabilities are attained when using in-context exemplars
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shum et al.,
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023
     </a>
     ; Zhang et al.,
     <a class="ltx_ref" href="#bib.bib52" title="">
      2022
     </a>
     ; Wei et al.,
     <a class="ltx_ref" href="#bib.bib44" title="">
      2022a
     </a>
     )
    </cite>
    or plans
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jiang et al.,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2023b
     </a>
     )
    </cite>
    , these approaches, during both code generation and debugging, only leverage the problem description itself in a zero-shot manner. Consequently, their gains can be limited.
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    To confront the above challenge, we develop
    <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.1">
     MapCoder
    </span>
    augmenting the generation procedure with possible auxiliary supervision. We draw inspiration from human programmers, and how they use various signals/feedback while programming. The human problem-solving cycle involves recalling past solutions, planning, code writing, and debugging.
    <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.2">
     MapCoder
    </span>
    imitates these steps using LLM agents - retrieval, planning, coding, and debugging. In contrast to relying on human annotated examples, or external code retrieval models, we empower our retrieval agent to autonomously retrieve relevant problems itself
    <cite class="ltx_cite ltx_citemacro_cite">
     Yasunaga et al. (
     <a class="ltx_ref" href="#bib.bib48" title="">
      2023
     </a>
     )
    </cite>
    .
Moreover, we design a novel structured pipeline schema that intelligently cascades the LLM agents and incorporates a dynamic iteration protocol to enhance the generation procedure at every step. Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    shows an overview of our approach,
    <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.3">
     MapCoder
    </span>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p7">
   <p class="ltx_p" id="S1.p7.1">
    Additionally, existing iterative self-reflection methods rely on extra test cases generated by LLM agents (e.g., AgentCoder
    <cite class="ltx_cite ltx_citemacro_cite">
     Huang et al. (
     <a class="ltx_ref" href="#bib.bib18" title="">
      2023
     </a>
     )
    </cite>
    , LATS
    <cite class="ltx_cite ltx_citemacro_cite">
     Zhou et al. (
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     )
    </cite>
    , self-reflection
    <cite class="ltx_cite ltx_citemacro_cite">
     Shinn et al. (
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     )
    </cite>
    ) or external tools, compounding the challenges. Test case generation is equally challenging as code generation
    <cite class="ltx_cite ltx_citemacro_cite">
     Pacheco et al. (
     <a class="ltx_ref" href="#bib.bib30" title="">
      2007
     </a>
     )
    </cite>
    , and incorrect test cases can lead to erroneous code. Blindly editing code based on these test cases can undermine problem-solving capabilities. For instance, while self-reflection boosts GPT-4’s performance on the HumanEval dataset, it drops by 3% on the MBPP dataset
    <cite class="ltx_cite ltx_citemacro_cite">
     Shinn et al. (
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     )
    </cite>
    . Upon identification, to validate this, on the HumanEval dataset itself, we replace their GPT-4 with ChatGPT, and see that model performance drops by 26.3%. Therefore, our debugging agent performs unit tests and bug fixing using only the sample I/O, without any artifact-more plausible for real-world widespread adoption.
   </p>
  </div>
  <div class="ltx_para" id="S1.p8">
   <p class="ltx_p" id="S1.p8.1">
    We evaluate
    <span class="ltx_text ltx_font_typewriter" id="S1.p8.1.1">
     MapCoder
    </span>
    on seven popular programming synthesis benchmarks including both basic programming like HumanEval, MBPP and challenging competitive program-solving benchmarks like APPS, CodeContests and xCodeEval. With multiple different LLMs including ChatGPT, GPT-4, and Gemini Pro, our approach significantly enhances their problem-solving capabilities - consistently achieving new SOTA performances, outperforming strong baselines like Reflexion
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shinn et al.,
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     )
    </cite>
    , and AlphaCodium
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ridnik et al.,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2024
     </a>
     )
    </cite>
    . Moreover, our method consistently delivers superior performance across various programming languages and varying problem difficulties. Furthermore, with detailed ablation studies, we analyze
    <span class="ltx_text ltx_font_typewriter" id="S1.p8.1.2">
     MapCoder
    </span>
    to provide more insights.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Work
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">
     Program Synthesis:
    </span>
    Program synthesis has a long standing history in AI systems
    <cite class="ltx_cite ltx_citemacro_citep">
     (Manna and Waldinger,
     <a class="ltx_ref" href="#bib.bib28" title="">
      1971
     </a>
     )
    </cite>
    . A large number of prior research attempted to address it via search/data flow approaches
    <cite class="ltx_cite ltx_citemacro_cite">
     Li et al. (
     <a class="ltx_ref" href="#bib.bib25" title="">
      2022a
     </a>
     ); Parisotto and Salakhutdinov (
     <a class="ltx_ref" href="#bib.bib31" title="">
      2017
     </a>
     ); Polozov and Gulwani (
     <a class="ltx_ref" href="#bib.bib35" title="">
      2015
     </a>
     ); Gulwani (
     <a class="ltx_ref" href="#bib.bib14" title="">
      2011
     </a>
     )
    </cite>
    .
LMs, prior to LLMs, attempt to generate code by fine-tuning (i.e., training) neural language models
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wang et al.,
     <a class="ltx_ref" href="#bib.bib42" title="">
      2021
     </a>
     ; Ahmad et al.,
     <a class="ltx_ref" href="#bib.bib1" title="">
      2021
     </a>
     ; Feng et al.,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2020
     </a>
     ; Parvez et al.,
     <a class="ltx_ref" href="#bib.bib33" title="">
      2018
     </a>
     ; Yin and Neubig,
     <a class="ltx_ref" href="#bib.bib49" title="">
      2017
     </a>
     ; Hellendoorn and Devanbu,
     <a class="ltx_ref" href="#bib.bib16" title="">
      2017
     </a>
     ; Rabinovich et al.,
     <a class="ltx_ref" href="#bib.bib36" title="">
      2017
     </a>
     ; Hindle et al.,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2016
     </a>
     )
    </cite>
    , conversational intents or data flow features
    <cite class="ltx_cite ltx_citemacro_citep">
     (Andreas et al.,
     <a class="ltx_ref" href="#bib.bib3" title="">
      2020
     </a>
     ; Yu et al.,
     <a class="ltx_ref" href="#bib.bib50" title="">
      2019
     </a>
     )
    </cite>
    .
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.2">
     Large Language Models:
    </span>
    Various LLMs have been developed for Code synthesis
    <cite class="ltx_cite ltx_citemacro_citep">
     (Li et al.,
     <a class="ltx_ref" href="#bib.bib26" title="">
      2022b
     </a>
     ; Fried et al.,
     <a class="ltx_ref" href="#bib.bib13" title="">
      2022
     </a>
     ; Chen et al.,
     <a class="ltx_ref" href="#bib.bib7" title="">
      2021b
     </a>
     ; Austin et al.,
     <a class="ltx_ref" href="#bib.bib4" title="">
      2021
     </a>
     ; Nijkamp et al.,
     <a class="ltx_ref" href="#bib.bib29" title="">
      2022
     </a>
     ; Allal et al.,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2023
     </a>
     )
    </cite>
    . Recent open source LLMs include Llama-2
    <cite class="ltx_cite ltx_citemacro_citep">
     (Touvron et al.,
     <a class="ltx_ref" href="#bib.bib41" title="">
      2023
     </a>
     )
    </cite>
    , CodeLlama-2
    <cite class="ltx_cite ltx_citemacro_citep">
     (Roziere et al.,
     <a class="ltx_ref" href="#bib.bib38" title="">
      2023
     </a>
     )
    </cite>
    , Mistral
    <cite class="ltx_cite ltx_citemacro_citep">
     (Jiang et al.,
     <a class="ltx_ref" href="#bib.bib19" title="">
      2023a
     </a>
     )
    </cite>
    Deepseek Coder
    <cite class="ltx_cite ltx_citemacro_cite">
     Guo et al. (
     <a class="ltx_ref" href="#bib.bib15" title="">
      2024
     </a>
     )
    </cite>
    , MoTCoder
    <cite class="ltx_cite ltx_citemacro_cite">
     Li et al. (
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023
     </a>
     )
    </cite>
    that are capable of solving many basic programming tasks.
   </p>
  </div>
  <figure class="ltx_table" id="S2.T1">
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T1.1">
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="S2.T1.1.1">
      <td class="ltx_td ltx_align_center" id="S2.T1.1.1.1">
       <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="78" id="S2.T1.1.1.1.g1" src="/html/2405.11403/assets/x2.png" width="226"/>
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    Features in code generation prompt techniques.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S2.p2">
   <p class="ltx_p" id="S2.p2.1">
    <span class="ltx_text ltx_font_bold" id="S2.p2.1.1">
     Prompting LLMs:
    </span>
    As indicated in Section
    <a class="ltx_ref" href="#S1" title="1 Introduction ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    , LLM prompting can be summarized into three categories: retrieval
    <cite class="ltx_cite ltx_citemacro_cite">
     Yasunaga et al. (
     <a class="ltx_ref" href="#bib.bib48" title="">
      2023
     </a>
     ); Parvez et al. (
     <a class="ltx_ref" href="#bib.bib34" title="">
      2023
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2021
     </a>
     )
    </cite>
    ; planning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib45" title="">
      2022b
     </a>
     ; Jiang et al.,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2023b
     </a>
     )
    </cite>
    ; debugging
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ridnik et al.,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2024
     </a>
     ; Chen et al.,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2023
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022
     </a>
     ; Le et al.,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     )
    </cite>
    apart from the direct code generation approaches. In contrast, we combine all these paradigms and bridge their gaps (See Table
    <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    ). Among others, in different contexts of generic problem-solving, Tree-of-thoughts
    <cite class="ltx_cite ltx_citemacro_cite">
     Yao et al. (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023
     </a>
     )
    </cite>
    , and Cumulative reasoning
    <cite class="ltx_cite ltx_citemacro_cite">
     Zhang et al. (
     <a class="ltx_ref" href="#bib.bib51" title="">
      2023
     </a>
     )
    </cite>
    approaches consider a tree traversal approach to explore different sub-steps towards a solution while our code generation approach mirrors the human programming cycle through various LLM agents. Notably, our traversal does not rely on sub-steps toward the solution but instead utilizes different forms of complete solutions.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   <span class="ltx_text ltx_font_typewriter" id="S3.1.1">
    MapCoder
   </span>
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    Our goal is to develop a multi-agent code generation approach for competitive problem-solving. In order to do so, our framework,
    <span class="ltx_text ltx_font_typewriter" id="S3.p1.1.1">
     MapCoder
    </span>
    , replicates the human programming cycle through four LLM agents - retrieval, plan, code, and debug. We devise a pipeline sequence for
    <span class="ltx_text ltx_font_typewriter" id="S3.p1.1.2">
     MapCoder
    </span>
    , intelligently cascading the agents in a structured way and enhancing each agent’s capability by augmenting in-context learning signals from previous agents in the pipeline. However, not all the agent responses/outputs are equally useful. Therefore, additionally,
    <span class="ltx_text ltx_font_typewriter" id="S3.p1.1.3">
     MapCoder
    </span>
    features an adaptive agent traversal schema to interact among corresponding agents dynamically, iteratively enhancing the generated code by, for example, fixing bugs, while maximizing the usage of the LLM agents. In this section, we first discuss the agents (as per the pipeline), their prompts, and interactions, followed by the dynamic agent traversal protocol in
    <span class="ltx_text ltx_font_typewriter" id="S3.p1.1.4">
     MapCoder
    </span>
    towards code generation for competitive problem-solving.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Retrieval Agent
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     Our first agent, the
     <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.1">
      Retrieval Agent
     </em>
     , recalls past relevant problem-solving instances, akin to human memory. It finds
     <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1">
      <semantics id="S3.SS1.p1.1.m1.1a">
       <mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b">
        <ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">
        k
       </annotation>
      </semantics>
     </math>
     (user-defined) similar problems without manual crafting or external retrieval models. Instead, we leverage the LLM agent itself, instructing it to generate such problems. Our prompt extends the analogical prompting principles
     <cite class="ltx_cite ltx_citemacro_cite">
      Yasunaga et al. (
      <a class="ltx_ref" href="#bib.bib48" title="">
       2023
      </a>
      )
     </cite>
     , generating examples and their solutions simultaneously, along with additional metadata (e.g., problem description, code, and plan) to provide the following agents as auxiliary data. We adopt a specific sequence of instructions, which is crucial for the prompt’s effectiveness. In particular, initially, we instruct the LLM to produce similar and distinct problems and their solutions, facilitating problem planning reverse-engineering. Then, we prompt the LLM to generate solution code step-by-step, allowing post-processing to form the corresponding plan. Finally, we direct the LLM to generate relevant algorithms and provide instructional tutorials, enabling the agent to reflect on underlying algorithms and generate algorithmically similar examples.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Planning Agent
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     The second agent, the
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.1">
      Planning Agent
     </em>
     , aims to create a step-by-step plan for the original problem. Our
     <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.1.2">
      Planning Agent
     </em>
     uses examples and their plans obtained from the retrieval agent to generate plans for the original problem. A straightforward approach would be to utilize all examples collectively to generate a single target plan. However, not all retrieved examples hold equal utility. Concatenating examples in a random order may compromise the LLM’s ability to generate accurate planning. For instance,
     <cite class="ltx_cite ltx_citemacro_citet">
      Xu et al. (
      <a class="ltx_ref" href="#bib.bib46" title="">
       2023
      </a>
      )
     </cite>
     demonstrated that even repeating more relevant information (e.g., query) towards the end of the in-context input aids LLM reasoning more effectively than including relatively less relevant contexts. A similar conclusion of "separating noisy in-context data" can also be drawn from the state-of-the-art retrieval augmented generation approaches like
     <cite class="ltx_cite ltx_citemacro_citet">
      Wang et al. (
      <a class="ltx_ref" href="#bib.bib43" title="">
       2023
      </a>
      )
     </cite>
     . Therefore, we generate a distinct target plan for each retrieved example. Additionally, multiple plans offer diverse pathways to success.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS2.p2">
    <p class="ltx_p" id="S3.SS2.p2.1">
     To help the generation steps in the following agents with the utility information for each plan, our designed prompt for the planning agent asks the LLM to generate both plans and a confidence score. Figure
     <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ 3.2 Planning Agent ‣ 3 MapCoder ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     shows our prompt got this agent.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="121" id="S3.F2.g1" src="/html/2405.11403/assets/x3.png" width="226"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2:
     </span>
     Prompt for
     <em class="ltx_emph ltx_font_italic" id="S3.F2.2.1">
      Planning Agent
     </em>
     .
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Coding Agent
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     Next is the
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.1">
      Coding Agent
     </em>
     . It takes the problem description, and a plan from the
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.2">
      Planning Agent
     </em>
     as input and translates the corresponding planning into code to solve the problem. During the traversing of agents,
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.3">
      Coding Agent
     </em>
     takes the original problem and one particular plan from the
     <em class="ltx_emph ltx_font_italic" id="S3.SS3.p1.1.4">
      Planning Agent
     </em>
     , generates the code, and test on sample I/O. If the initial code fails, the agent transfers it to the next agent for debugging. Otherwise, predicts that as the final solution.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.4
    </span>
    Debugging Agent
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     Finally, the
     <em class="ltx_emph ltx_font_italic" id="S3.SS4.p1.1.1">
      Debugging Agent
     </em>
     utilizes sample I/O from the problem description to rectify bugs in the generated code. Similar to humans cross-checking their plan while fixing bugs, our pipeline supplements the
     <em class="ltx_emph ltx_font_italic" id="S3.SS4.p1.1.2">
      Debugging Agent
     </em>
     with plans from the
     <em class="ltx_emph ltx_font_italic" id="S3.SS4.p1.1.3">
      Planning Agent
     </em>
     . This plan-derived debugging significantly enhances bug fixing in
     <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p1.1.4">
      MapCoder
     </span>
     , underscoring the pivotal roles played by both the
     <em class="ltx_emph ltx_font_italic" id="S3.SS4.p1.1.5">
      Debugging Agent
     </em>
     and the
     <em class="ltx_emph ltx_font_italic" id="S3.SS4.p1.1.6">
      Planning Agent
     </em>
     in the generation process. We verify this in Section
     <a class="ltx_ref" href="#S6" title="6 Ablations Studies and Analyses ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     . For each plan, this process is repeated
     <math alttext="t" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1">
      <semantics id="S3.SS4.p1.1.m1.1a">
       <mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b">
        <ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">
        t
       </annotation>
      </semantics>
     </math>
     times. The prompt for this step is illustrated in Figure
     <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.4 Debugging Agent ‣ 3 MapCoder ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     . Note that, different from Reflexion
     <cite class="ltx_cite ltx_citemacro_cite">
      Shinn et al. (
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      )
     </cite>
     and AlphaCodium
     <cite class="ltx_cite ltx_citemacro_cite">
      Ridnik et al. (
      <a class="ltx_ref" href="#bib.bib37" title="">
       2024
      </a>
      )
     </cite>
     , our
     <em class="ltx_emph ltx_font_italic" id="S3.SS4.p1.1.7">
      Debugging Agent
     </em>
     does not require any additional test case generation in the pipeline.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="103" id="S3.F3.g1" src="/html/2405.11403/assets/x4.png" width="226"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Prompt for
     <em class="ltx_emph ltx_font_italic" id="S3.F3.2.1">
      Debugging Agent
     </em>
     .
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S3.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="323" id="S3.F4.g1" src="/html/2405.11403/assets/x5.png" width="456"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Example problem and solution generation using Direct, CoT, Reflexion, and
     <span class="ltx_text ltx_font_typewriter" id="S3.F4.3.1">
      MapCoder
     </span>
     prompts.
     <span class="ltx_text ltx_font_typewriter" id="S3.F4.4.2">
      MapCoder
     </span>
     explores high-utility plans first and uniquely features a plan-derived debugging for enhanced bug fixing.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.5
    </span>
    Dynamic Agent Traversal
   </h3>
   <div class="ltx_para" id="S3.SS5.p1">
    <p class="ltx_p" id="S3.SS5.p1.3">
     The dynamic traversal in
     <span class="ltx_text ltx_font_typewriter" id="S3.SS5.p1.3.1">
      MapCoder
     </span>
     begins with the
     <em class="ltx_emph ltx_font_italic" id="S3.SS5.p1.3.2">
      Planning Agent
     </em>
     , which outputs the plans for the original problem with confidence scores. These plans are sorted, and the highest-scoring one is sent to the Coding Agent. The Coding Agent translates the plan into code, tested with sample I/Os. If all pass, the code is returned; otherwise, it’s passed to
     <em class="ltx_emph ltx_font_italic" id="S3.SS5.p1.3.3">
      Debugging Agent
     </em>
     . They attempt to rectify the code iteratively up to
     <math alttext="t" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1">
      <semantics id="S3.SS5.p1.1.m1.1a">
       <mi id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b">
        <ci id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">
        t
       </annotation>
      </semantics>
     </math>
     times. If successful, the code is returned; otherwise, responsibility shifts back to the
     <em class="ltx_emph ltx_font_italic" id="S3.SS5.p1.3.4">
      Planning Agent
     </em>
     for the next highest confidence plan. This iterative process continues for
     <math alttext="k" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.1">
      <semantics id="S3.SS5.p1.2.m2.1a">
       <mi id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b">
        <ci id="S3.SS5.p1.2.m2.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">
        k
       </annotation>
      </semantics>
     </math>
     iterations, reflecting a programmer’s approach. We summarize our agent traversal in Algorithm
     <a class="ltx_ref" href="#A1" title="Appendix A Algorithm of MapCoder ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       A
      </span>
     </a>
     in Appendix. Our algorithm’s complexity is
     <math alttext="O(kt)" class="ltx_Math" display="inline" id="S3.SS5.p1.3.m3.1">
      <semantics id="S3.SS5.p1.3.m3.1a">
       <mrow id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml">
        <mi id="S3.SS5.p1.3.m3.1.1.3" xref="S3.SS5.p1.3.m3.1.1.3.cmml">
         O
        </mi>
        <mo id="S3.SS5.p1.3.m3.1.1.2" lspace="0em" rspace="0em" xref="S3.SS5.p1.3.m3.1.1.2.cmml">
         ​
        </mo>
        <mrow id="S3.SS5.p1.3.m3.1.1.1.1" xref="S3.SS5.p1.3.m3.1.1.1.1.1.cmml">
         <mo id="S3.SS5.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS5.p1.3.m3.1.1.1.1.1.cmml">
          (
         </mo>
         <mrow id="S3.SS5.p1.3.m3.1.1.1.1.1" xref="S3.SS5.p1.3.m3.1.1.1.1.1.cmml">
          <mi id="S3.SS5.p1.3.m3.1.1.1.1.1.2" xref="S3.SS5.p1.3.m3.1.1.1.1.1.2.cmml">
           k
          </mi>
          <mo id="S3.SS5.p1.3.m3.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S3.SS5.p1.3.m3.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="S3.SS5.p1.3.m3.1.1.1.1.1.3" xref="S3.SS5.p1.3.m3.1.1.1.1.1.3.cmml">
           t
          </mi>
         </mrow>
         <mo id="S3.SS5.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS5.p1.3.m3.1.1.1.1.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b">
        <apply id="S3.SS5.p1.3.m3.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1">
         <times id="S3.SS5.p1.3.m3.1.1.2.cmml" xref="S3.SS5.p1.3.m3.1.1.2">
         </times>
         <ci id="S3.SS5.p1.3.m3.1.1.3.cmml" xref="S3.SS5.p1.3.m3.1.1.3">
          𝑂
         </ci>
         <apply id="S3.SS5.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1">
          <times id="S3.SS5.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1.1.1">
          </times>
          <ci id="S3.SS5.p1.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1.1.2">
           𝑘
          </ci>
          <ci id="S3.SS5.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS5.p1.3.m3.1.1.1.1.1.3">
           𝑡
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">
        O(kt)
       </annotation>
      </semantics>
     </math>
     . An example illustrating
     <span class="ltx_text ltx_font_typewriter" id="S3.SS5.p1.3.5">
      MapCoder
     </span>
     ’s problem-solving compared to Direct, Chain-of-thought, and Reflexion approaches is in Figure
     <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ 3.4 Debugging Agent ‣ 3 MapCoder ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . All detailed prompts for each agent are in Appendix
     <a class="ltx_ref" href="#A2" title="Appendix B Details Promptings of MapCoder ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       B
      </span>
     </a>
     .
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Experimental Setup
  </h2>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Datasets
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     For extensive evaluation, we have used eight benchmark datasets: five from basic programming and three from complex competitive programming domains. Five basic programming datasets are:
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">
      HumanEval
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Chen et al. (
      <a class="ltx_ref" href="#bib.bib6" title="">
       2021a
      </a>
      )
     </cite>
     ,
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.2">
      HumanEval-ET
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Dong et al. (
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023a
      </a>
      )
     </cite>
     ,
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.3">
      EvalPlus
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Liu et al. (
      <a class="ltx_ref" href="#bib.bib27" title="">
       2023
      </a>
      )
     </cite>
     ,
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.4">
      MBPP
     </span>
     )
     <cite class="ltx_cite ltx_citemacro_cite">
      Austin et al. (
      <a class="ltx_ref" href="#bib.bib4" title="">
       2021
      </a>
      )
     </cite>
     , and
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.5">
      MBPP-ET
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Dong et al. (
      <a class="ltx_ref" href="#bib.bib10" title="">
       2023a
      </a>
      )
     </cite>
     . HumanEval-ET, EvalPlus extend HumanEval and MBPP-ET comprehends MBPP by incorporating more test cases. The problem set size of HumanEval and MBPP (and their extensions) are 164 and 397, respectively.
Due to the absence of sample I/O in MBPP and MBPP-ET, our approach for code moderation involves randomly removing one test-case from MBPP-ET for each problem and provide this test-case as a sample I/O for the problem. Importantly, this removed test-case is carefully selected to ensure mutual exclusivity from the hidden test sets in MBPP and MBPP-ET. Three competitive programming datasets are: Automated Programming Progress Standard (
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.6">
      APPS
     </span>
     ),
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.7">
      xCodeEval
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Khan et al. (
      <a class="ltx_ref" href="#bib.bib21" title="">
       2023
      </a>
      )
     </cite>
     , and
     <span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.8">
      CodeContest
     </span>
     , where we have used 150, 106, and 156 problems, respectively, in our experiments.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Baselines
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     We have compared
     <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.1">
      MapCoder
     </span>
     with several baselines and state-of-the-art approaches.
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.2">
      Direct
     </span>
     Prompting instructs language models to generate code without explicit guidance, relying on their inherent capabilities of LLM. Chain of Thought Prompting (
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.3">
      CoT
     </span>
     )
     <cite class="ltx_cite ltx_citemacro_cite">
      Wei et al. (
      <a class="ltx_ref" href="#bib.bib45" title="">
       2022b
      </a>
      )
     </cite>
     breaks down problems into step-by-step solutions, enabling effective tackling of complex tasks.
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.4">
      Self-Planning
     </span>
     Prompting
     <cite class="ltx_cite ltx_citemacro_cite">
      Jiang et al. (
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023b
      </a>
      )
     </cite>
     divides the code generation task into planning and implementation phases.
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.5">
      Analogical Reasoning
     </span>
     Prompting
     <cite class="ltx_cite ltx_citemacro_cite">
      Yasunaga et al. (
      <a class="ltx_ref" href="#bib.bib48" title="">
       2023
      </a>
      )
     </cite>
     instructs models to recall relevant problems from training data.
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.6">
      Reflexion
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Shinn et al. (
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      )
     </cite>
     provides verbal feedback to enhance solutions based on unit test results.
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.7">
      Self-collaboration
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Dong et al. (
      <a class="ltx_ref" href="#bib.bib11" title="">
       2023b
      </a>
      )
     </cite>
     proposes a framework where different LLMs act as analyst, coder, and tester to cooperatively generate code for complex tasks, achieving better performance than directly using a single LLM.
     <span class="ltx_text ltx_font_bold" id="S4.SS2.p1.1.8">
      AlphaCodium
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Ridnik et al. (
      <a class="ltx_ref" href="#bib.bib37" title="">
       2024
      </a>
      )
     </cite>
     iteratively refines code based on AI-generated input-output tests.
    </p>
   </div>
   <figure class="ltx_table" id="S4.T2">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S4.T2.1.1">
       <td class="ltx_td ltx_align_center" id="S4.T2.1.1.1">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="248" id="S4.T2.1.1.1.g1" src="/html/2405.11403/assets/x6.png" width="456"/>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     Pass@1 results for different approaches. The results of the yellow and blue colored cells are obtained from
     <cite class="ltx_cite ltx_citemacro_citet">
      Jiang et al. (
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023b
      </a>
      )
     </cite>
     and
     <cite class="ltx_cite ltx_citemacro_citet">
      Shinn et al. (
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      )
     </cite>
     , respectively. The results of the Self-collaboration
     <cite class="ltx_cite ltx_citemacro_citet">
      Dong et al. (
      <a class="ltx_ref" href="#bib.bib11" title="">
       2023b
      </a>
      )
     </cite>
     paper are collected from their paper. The green texts indicate the state-of-the-art results, and the red text is gain over Direct Prompting approach.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Foundation Models, Evaluation Metric,
    <math alttext="k" class="ltx_Math" display="inline" id="S4.SS3.1.m1.1">
     <semantics id="S4.SS3.1.m1.1b">
      <mi id="S4.SS3.1.m1.1.1" xref="S4.SS3.1.m1.1.1.cmml">
       k
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.SS3.1.m1.1c">
       <ci id="S4.SS3.1.m1.1.1.cmml" xref="S4.SS3.1.m1.1.1">
        𝑘
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.SS3.1.m1.1d">
       k
      </annotation>
     </semantics>
    </math>
    , and
    <math alttext="t" class="ltx_Math" display="inline" id="S4.SS3.2.m2.1">
     <semantics id="S4.SS3.2.m2.1b">
      <mi id="S4.SS3.2.m2.1.1" xref="S4.SS3.2.m2.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="S4.SS3.2.m2.1c">
       <ci id="S4.SS3.2.m2.1.1.cmml" xref="S4.SS3.2.m2.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S4.SS3.2.m2.1d">
       t
      </annotation>
     </semantics>
    </math>
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.3">
     With
     <math alttext="k=t=5" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1">
      <semantics id="S4.SS3.p1.1.m1.1a">
       <mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">
        <mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">
         k
        </mi>
        <mo id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">
         =
        </mo>
        <mi id="S4.SS3.p1.1.m1.1.1.4" xref="S4.SS3.p1.1.m1.1.1.4.cmml">
         t
        </mi>
        <mo id="S4.SS3.p1.1.m1.1.1.5" xref="S4.SS3.p1.1.m1.1.1.5.cmml">
         =
        </mo>
        <mn id="S4.SS3.p1.1.m1.1.1.6" xref="S4.SS3.p1.1.m1.1.1.6.cmml">
         5
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b">
        <apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">
         <and id="S4.SS3.p1.1.m1.1.1a.cmml" xref="S4.SS3.p1.1.m1.1.1">
         </and>
         <apply id="S4.SS3.p1.1.m1.1.1b.cmml" xref="S4.SS3.p1.1.m1.1.1">
          <eq id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">
          </eq>
          <ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">
           𝑘
          </ci>
          <ci id="S4.SS3.p1.1.m1.1.1.4.cmml" xref="S4.SS3.p1.1.m1.1.1.4">
           𝑡
          </ci>
         </apply>
         <apply id="S4.SS3.p1.1.m1.1.1c.cmml" xref="S4.SS3.p1.1.m1.1.1">
          <eq id="S4.SS3.p1.1.m1.1.1.5.cmml" xref="S4.SS3.p1.1.m1.1.1.5">
          </eq>
          <share href="#S4.SS3.p1.1.m1.1.1.4.cmml" id="S4.SS3.p1.1.m1.1.1d.cmml" xref="S4.SS3.p1.1.m1.1.1">
          </share>
          <cn id="S4.SS3.p1.1.m1.1.1.6.cmml" type="integer" xref="S4.SS3.p1.1.m1.1.1.6">
           5
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">
        k=t=5
       </annotation>
      </semantics>
     </math>
     in HumanEval, and
     <math alttext="k=t=3" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1">
      <semantics id="S4.SS3.p1.2.m2.1a">
       <mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">
        <mi id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">
         k
        </mi>
        <mo id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">
         =
        </mo>
        <mi id="S4.SS3.p1.2.m2.1.1.4" xref="S4.SS3.p1.2.m2.1.1.4.cmml">
         t
        </mi>
        <mo id="S4.SS3.p1.2.m2.1.1.5" xref="S4.SS3.p1.2.m2.1.1.5.cmml">
         =
        </mo>
        <mn id="S4.SS3.p1.2.m2.1.1.6" xref="S4.SS3.p1.2.m2.1.1.6.cmml">
         3
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b">
        <apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">
         <and id="S4.SS3.p1.2.m2.1.1a.cmml" xref="S4.SS3.p1.2.m2.1.1">
         </and>
         <apply id="S4.SS3.p1.2.m2.1.1b.cmml" xref="S4.SS3.p1.2.m2.1.1">
          <eq id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">
          </eq>
          <ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">
           𝑘
          </ci>
          <ci id="S4.SS3.p1.2.m2.1.1.4.cmml" xref="S4.SS3.p1.2.m2.1.1.4">
           𝑡
          </ci>
         </apply>
         <apply id="S4.SS3.p1.2.m2.1.1c.cmml" xref="S4.SS3.p1.2.m2.1.1">
          <eq id="S4.SS3.p1.2.m2.1.1.5.cmml" xref="S4.SS3.p1.2.m2.1.1.5">
          </eq>
          <share href="#S4.SS3.p1.2.m2.1.1.4.cmml" id="S4.SS3.p1.2.m2.1.1d.cmml" xref="S4.SS3.p1.2.m2.1.1">
          </share>
          <cn id="S4.SS3.p1.2.m2.1.1.6.cmml" type="integer" xref="S4.SS3.p1.2.m2.1.1.6">
           3
          </cn>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">
        k=t=3
       </annotation>
      </semantics>
     </math>
     for others, we evaluate all the datasets using
     <a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/models/gpt-3-5-turbo" target="_blank" title="">
      ChatGPT (gpt-3.5-turbo-1106)
     </a>
     ,
     <a class="ltx_ref ltx_href" href="https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo" target="_blank" title="">
      GPT-4 (gpt-4-1106-preview)
     </a>
     from OpenAI and
     <a class="ltx_ref ltx_href" href="https://deepmind.google/technologies/gemini/#gemini-1.0" target="_blank" title="">
      Gemini Pro
     </a>
     from Google. We have also evaluated our method using an open-source LLM, Mistral-7B-instruct. We have used the Pass@k evaluation metric, where the model is considered successful if at least one of the
     <math alttext="k" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1">
      <semantics id="S4.SS3.p1.3.m3.1a">
       <mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b">
        <ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">
        k
       </annotation>
      </semantics>
     </math>
     generated solutions is correct.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Results
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    In this section, we evaluate the code generation capabilities of our framework,
    <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.1">
     MapCoder
    </span>
    , for competitive problem solving. Our experimental results are reported in Table
    <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.2 Baselines ‣ 4 Experimental Setup ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    .
Overall,
    <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.2">
     MapCoder
    </span>
    shows a tremendous excellence in code generation, significantly outperforms all baselines, and achieves new state-of-the-art results in all benchmarks. In general the scales with GPT-4 are higher than ChatGPT.
   </p>
  </div>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Performance on basic code generation
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     The highest scale of performance (Pass@1) scores are observed in simple program synthesis tasks like HumanEval, MBPP in Table
     <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.2 Baselines ‣ 4 Experimental Setup ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
Though with the simpler problem (non-contests) datasets such as HumanEval, HumanEval-ET, the current state-of-the-art method, Reflexion
     <cite class="ltx_cite ltx_citemacro_cite">
      Shinn et al. (
      <a class="ltx_ref" href="#bib.bib39" title="">
       2023
      </a>
      )
     </cite>
     perform reasonably well, this approach does not generalize across varying datasets depicting a wide variety of problems.
Self-reflection techniques enhance GPT-4’s performance on HumanEval but result in a 3% decrease on the MBPP dataset. Similarly, with ChatGPT, there’s a notable 26.3% drop in performance where in several cases their AI generated test cases are incorrect. We observe that 8% of failures in HumanEval and 15% in MBPP is caused by their AI generates incorrect test cases while our approach is independent of AI test cases, and consistently improves code generations in general. Consequently, even in HumanEval, with GPT-4, our Pass@1 surpasses Reflexion by
     <math alttext="\sim" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1">
      <semantics id="S5.SS1.p1.1.m1.1a">
       <mo id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">
        ∼
       </mo>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b">
        <csymbol cd="latexml" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">
         similar-to
        </csymbol>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">
        \sim
       </annotation>
      </semantics>
     </math>
     3%. On top, in all four simple programming datasets,
     <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.1">
      MapCoder
     </span>
     enhances the Direct prompting significantly with a maximum of 88% on HumanEvalET by ChatGPT.
    </p>
   </div>
   <figure class="ltx_figure" id="S5.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="213" id="S5.F5.g1" src="/html/2405.11403/assets/figures/results/xcode-algo-diff.png" width="568"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     The number of correct answers wrt algorithm types (tags) and difficulty levels (xCodeEval dataset).
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Performance on competitive problem solving
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     The significance of
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.1">
      MapCoder
     </span>
     shines through clearly when evaluated in competitive problem-solving contexts. Across datasets such as APPS, xCodeEval, and CodeContests,
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.2">
      MapCoder
     </span>
     demonstrates substantial enhancements over Direct prompting methods, with improvements of 41.3%, 52.6%, and 132.8% for ChatGPT, and 73.7%, 41.2%, and 135.1% for GPT4, respectively. Notably, the most challenging datasets are APPS and CodeContest, where
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.3">
      MapCoder
     </span>
     ’s performance stands out prominently. We deliberately compare against strong baselines on these datasets, regardless of whether they are prompt-based or not.
Importantly, on CodeContest our Pass@1 results match the Pass@5 scores of the concurrent state-of-the-art model AlphaCodium
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ridnik et al.,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2024
      </a>
      )
     </cite>
     : 28.5% vs. their 29% (see Table
     <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.2 Performance on competitive problem solving ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     ). Furthermore, our Pass@5 results demonstrate an additional improvement of 12.8%. On APPS,
     <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.1.4">
      MapCoder
     </span>
     consistently surpasses the Pass@1 scores of all baseline prompts for both ChatGPT and GPT-4.
    </p>
   </div>
   <figure class="ltx_table" id="S5.T3">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T3.1.1">
       <td class="ltx_td ltx_align_center" id="S5.T3.1.1.1">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="70" id="S5.T3.1.1.1.g1" src="/html/2405.11403/assets/x7.png" width="221"/>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     Pass@5 results on CodeContest dataset. AlphCodium result are from
     <cite class="ltx_cite ltx_citemacro_citet">
      Ridnik et al. (
      <a class="ltx_ref" href="#bib.bib37" title="">
       2024
      </a>
      )
     </cite>
     . The green cells indicate the SoTA and the red text indicates improvement w.r.t Direct approach.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Performance with Varying Difficulty Levels
   </h3>
   <div class="ltx_para" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     The APPS dataset comprises problems categorized into three difficulty levels: (i) Introductory, (ii) Interview, and (iii) Competition. Figure
     <a class="ltx_ref" href="#S5.F6" title="Figure 6 ‣ 5.3 Performance with Varying Difficulty Levels ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     illustrates the performance of various competitive approaches for these three categories. The results reveal that our
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.1">
      MapCoder
     </span>
     excels across all problem categories, with highest gain in competitive problem-solving indicating its superior code generation capabilities in general, and on top, remarkable effectiveness in competitive problem-solving. In order to gather more understanding on what algorithm problems it’s capable of solving and in fact much difficulty level it can solve, we have also conducted a comparison between
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.2">
      MapCoder
     </span>
     and the Direct approach, considering the difficulty levels
     <span class="ltx_note ltx_role_footnote" id="footnote1">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         1
        </sup>
        <span class="ltx_tag ltx_tag_note">
         1
        </span>
        Difficulty levels in xCodeEval dataset represents an integer number, a higher value means more difficult problem
       </span>
      </span>
     </span>
     and tags
     <span class="ltx_note ltx_role_footnote" id="footnote2">
      <sup class="ltx_note_mark">
       2
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         2
        </sup>
        <span class="ltx_tag ltx_tag_note">
         2
        </span>
        Tags in xCodeEval dataset represents algorithm type that can be used to solve the problem i.e., greedy, dp, brute-force, constructive, and so on.
       </span>
      </span>
     </span>
     present in the xCodeEval dataset. The results of this comparison are depicted in Figure
     <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.1 Performance on basic code generation ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     . This comparison showcases that
     <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.3">
      MapCoder
     </span>
     is effective across various algorithm types and exhibits superior performance even in higher difficulty levels, compared to the Direct approach. However, beyond (mid-level: difficulties&gt;1000), its gains are still limited.
    </p>
   </div>
   <figure class="ltx_figure" id="S5.F6">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S5.F6.g1" src="/html/2405.11403/assets/figures/results/apps-dataset-difficulty-levels.png" width="293"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 6:
     </span>
     Performance vs problem types (APPS).
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S5.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.4
    </span>
    Performance Across Different LLMs
   </h3>
   <div class="ltx_para" id="S5.SS4.p1">
    <p class="ltx_p" id="S5.SS4.p1.1">
     To show the robustness of
     <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.1">
      MapCoder
     </span>
     across various LLMs, we evaluate
     <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.2">
      MapCoder
     </span>
     using Gemini Pro, a different family of SoTA LLM in Table
     <a class="ltx_ref" href="#S5.T4" title="Table 4 ‣ 5.4 Performance Across Different LLMs ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . We also evaluate
     <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.3">
      MapCoder
     </span>
     using an open-source LLM Mistral-7B instruct in Table
     <a class="ltx_ref" href="#S5.T5" title="Table 5 ‣ 5.4 Performance Across Different LLMs ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     . As expected, our method shows performance gains over other baseline approaches in equitable trends on both simple (HumanEval) and contest-level problems (CodeContest).
    </p>
   </div>
   <figure class="ltx_table" id="S5.T4">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T4.1.1">
       <td class="ltx_td ltx_align_center" id="S5.T4.1.1.1">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="52" id="S5.T4.1.1.1.g1" src="/html/2405.11403/assets/x8.png" width="207"/>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     Pass@1 results with using Gemini Pro. The red text is gain over Direct Prompting approach.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S5.T5">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T5.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S5.T5.1.1">
       <td class="ltx_td ltx_align_center" id="S5.T5.1.1.1">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="52" id="S5.T5.1.1.1.g1" src="/html/2405.11403/assets/x9.png" width="207"/>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 5:
     </span>
     Pass@1 results with using Mistral-7B-instruct. The red text is gain over Direct Prompting approach.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S5.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.5
    </span>
    Performance Across Different Programming Languages
   </h3>
   <div class="ltx_para" id="S5.SS5.p1">
    <p class="ltx_p" id="S5.SS5.p1.1">
     Furthermore, we evaluate model performances using
     <span class="ltx_text ltx_font_typewriter" id="S5.SS5.p1.1.1">
      MapCoder
     </span>
     across different programming languages. We utilize the xCodeEval dataset, which features multiple languages. Figure
     <a class="ltx_ref" href="#S5.F7" title="Figure 7 ‣ 5.5 Performance Across Different Programming Languages ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       7
      </span>
     </a>
     shows that consistent proficiency across different programming languages is achieved by
     <span class="ltx_text ltx_font_typewriter" id="S5.SS5.p1.1.2">
      MapCoder
     </span>
     with respect to baselines.
    </p>
   </div>
   <figure class="ltx_figure" id="S5.F7">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="279" id="S5.F7.g1" src="/html/2405.11403/assets/figures/results/multi-lingual.png" width="240"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 7:
     </span>
     The number of correct answers wrt different programming languages (xCodeEval dataset).
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Ablations Studies and Analyses
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    We present the ablation study of the
    <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.1">
     MapCoder
    </span>
    on HumanEval dataset as the problems are simpler and easy to diagnose by us humans.
   </p>
  </div>
  <section class="ltx_subsection" id="S6.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.1
    </span>
    Impact of Different Agents
   </h3>
   <div class="ltx_para" id="S6.SS1.p1">
    <p class="ltx_p" id="S6.SS1.p1.1">
     We have also conducted a study by excluding certain agents from our
     <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p1.1.1">
      MapCoder
     </span>
     , which helps us investigate each agent’s impact in our whole pipeline. As expected, the results (Table
     <a class="ltx_ref" href="#S6.T6" title="Table 6 ‣ 6.1 Impact of Different Agents ‣ 6 Ablations Studies and Analyses ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     ) show that every agent has its role in the pipeline as turning off any agent decreases the performance of
     <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p1.1.2">
      MapCoder
     </span>
     . Furthermore, we observe that the Debugging Agent has the most significant impact on the pipeline, as evidenced by a performance drop of 17.5% when excluding this agent exclusively, and an avg performance drop of 24.83% in all cases. The
     <em class="ltx_emph ltx_font_italic" id="S6.SS1.p1.1.3">
      Planning agent
     </em>
     has the second best important with avg drop of 16.7% in all cases.
In Table
     <a class="ltx_ref" href="#S6.T6" title="Table 6 ‣ 6.1 Impact of Different Agents ‣ 6 Ablations Studies and Analyses ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     ), we perform an ablation study of our multi-agent framework investigate each agent’s impact in our whole pipeline.
    </p>
   </div>
   <figure class="ltx_table" id="S6.T6">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T6.1" style="width:225.5pt;height:89.8pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-2.0pt,0.8pt) scale(0.982866635796339,0.982866635796339) ;">
      <table class="ltx_tabular ltx_align_middle" id="S6.T6.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S6.T6.1.1.1">
         <td class="ltx_td ltx_align_center" id="S6.T6.1.1.1.1">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="91" id="S6.T6.1.1.1.1.g1" src="/html/2405.11403/assets/x10.png" width="221"/>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 6:
     </span>
     Pass@1 results for different versions of
     <span class="ltx_text ltx_font_typewriter" id="S6.T6.3.1">
      MapCoder
     </span>
     (by using ChatGPT on HumanEval dataset).
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S6.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.2
    </span>
    Qualitative Example
   </h3>
   <div class="ltx_para" id="S6.SS2.p1">
    <p class="ltx_p" id="S6.SS2.p1.1">
     To verify the above numerical significance, and to understand how our method enhance the code generation, we have performed a qualitative analysis to find the underlying reason for the superior performance of
     <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.1.1">
      MapCoder
     </span>
     over other competitive prompting approaches. An example problem and the output with the explanation of Direct, CoT, Reflexion, and
     <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.1.2">
      MapCoder
     </span>
     prompting is shown in Figure
     <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ 3.4 Debugging Agent ‣ 3 MapCoder ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . This example demonstrates how the
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p1.1.3">
      Debugging Agent
     </em>
     fixes the bugs leveraging the plan as a guide from the
     <em class="ltx_emph ltx_font_italic" id="S6.SS2.p1.1.4">
      Planning Agent
     </em>
     . This verifies the impact of these two most significant agents. We present more detailed examples in Appendix.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.3
    </span>
    Impact of
    <math alttext="k" class="ltx_Math" display="inline" id="S6.SS3.1.m1.1">
     <semantics id="S6.SS3.1.m1.1b">
      <mi id="S6.SS3.1.m1.1.1" xref="S6.SS3.1.m1.1.1.cmml">
       k
      </mi>
      <annotation-xml encoding="MathML-Content" id="S6.SS3.1.m1.1c">
       <ci id="S6.SS3.1.m1.1.1.cmml" xref="S6.SS3.1.m1.1.1">
        𝑘
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S6.SS3.1.m1.1d">
       k
      </annotation>
     </semantics>
    </math>
    and
    <math alttext="t" class="ltx_Math" display="inline" id="S6.SS3.2.m2.1">
     <semantics id="S6.SS3.2.m2.1b">
      <mi id="S6.SS3.2.m2.1.1" xref="S6.SS3.2.m2.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="S6.SS3.2.m2.1c">
       <ci id="S6.SS3.2.m2.1.1.cmml" xref="S6.SS3.2.m2.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S6.SS3.2.m2.1d">
       t
      </annotation>
     </semantics>
    </math>
   </h3>
   <div class="ltx_para" id="S6.SS3.p1">
    <p class="ltx_p" id="S6.SS3.p1.4">
     <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.4.1">
      MapCoder
     </span>
     involves two hyper-parameters: the number of self-retrieved exemplars,
     <math alttext="k" class="ltx_Math" display="inline" id="S6.SS3.p1.1.m1.1">
      <semantics id="S6.SS3.p1.1.m1.1a">
       <mi id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b">
        <ci id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">
        k
       </annotation>
      </semantics>
     </math>
     , and the number of debugging attempts,
     <math alttext="t" class="ltx_Math" display="inline" id="S6.SS3.p1.2.m2.1">
      <semantics id="S6.SS3.p1.2.m2.1a">
       <mi id="S6.SS3.p1.2.m2.1.1" xref="S6.SS3.p1.2.m2.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="S6.SS3.p1.2.m2.1b">
        <ci id="S6.SS3.p1.2.m2.1.1.cmml" xref="S6.SS3.p1.2.m2.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS3.p1.2.m2.1c">
        t
       </annotation>
      </semantics>
     </math>
     . Our findings (Table
     <a class="ltx_ref" href="#S6.T7" title="Table 7 ‣ 6.3 Impact of 𝑘 and 𝑡 ‣ 6 Ablations Studies and Analyses ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       7
      </span>
     </a>
     ) reveal that higher
     <math alttext="k" class="ltx_Math" display="inline" id="S6.SS3.p1.3.m3.1">
      <semantics id="S6.SS3.p1.3.m3.1a">
       <mi id="S6.SS3.p1.3.m3.1.1" xref="S6.SS3.p1.3.m3.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="S6.SS3.p1.3.m3.1b">
        <ci id="S6.SS3.p1.3.m3.1.1.cmml" xref="S6.SS3.p1.3.m3.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS3.p1.3.m3.1c">
        k
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="t" class="ltx_Math" display="inline" id="S6.SS3.p1.4.m4.1">
      <semantics id="S6.SS3.p1.4.m4.1a">
       <mi id="S6.SS3.p1.4.m4.1.1" xref="S6.SS3.p1.4.m4.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="S6.SS3.p1.4.m4.1b">
        <ci id="S6.SS3.p1.4.m4.1.1.cmml" xref="S6.SS3.p1.4.m4.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.SS3.p1.4.m4.1c">
        t
       </annotation>
      </semantics>
     </math>
     is proportionate performance gain at the expense of time.
    </p>
   </div>
   <figure class="ltx_table" id="S6.T7">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T7.1" style="width:225.5pt;height:60pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-2.0pt,0.5pt) scale(0.982866635796339,0.982866635796339) ;">
      <table class="ltx_tabular ltx_align_middle" id="S6.T7.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S6.T7.1.1.1">
         <td class="ltx_td ltx_align_center" id="S6.T7.1.1.1.1">
          <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="58" id="S6.T7.1.1.1.1.g1" src="/html/2405.11403/assets/x11.png" width="221"/>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 7:
     </span>
     Pass@1 results by varying
     <math alttext="k" class="ltx_Math" display="inline" id="S6.T7.4.m1.1">
      <semantics id="S6.T7.4.m1.1b">
       <mi id="S6.T7.4.m1.1.1" xref="S6.T7.4.m1.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="S6.T7.4.m1.1c">
        <ci id="S6.T7.4.m1.1.1.cmml" xref="S6.T7.4.m1.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.T7.4.m1.1d">
        k
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="t" class="ltx_Math" display="inline" id="S6.T7.5.m2.1">
      <semantics id="S6.T7.5.m2.1b">
       <mi id="S6.T7.5.m2.1.1" xref="S6.T7.5.m2.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="S6.T7.5.m2.1c">
        <ci id="S6.T7.5.m2.1.1.cmml" xref="S6.T7.5.m2.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S6.T7.5.m2.1d">
        t
       </annotation>
      </semantics>
     </math>
     .
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S6.T8">
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T8.1">
     <tbody class="ltx_tbody">
      <tr class="ltx_tr" id="S6.T8.1.1">
       <td class="ltx_td ltx_align_center" id="S6.T8.1.1.1">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="169" id="S6.T8.1.1.1.g1" src="/html/2405.11403/assets/x12.png" width="368"/>
       </td>
      </tr>
     </tbody>
    </table>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 8:
     </span>
     Average number of API calls, thousands of tokens used, required time in minutes to get the API response.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S6.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.4
    </span>
    Impact of Number of Sample I/Os
   </h3>
   <div class="ltx_para" id="S6.SS4.p1">
    <p class="ltx_p" id="S6.SS4.p1.1">
     Given the limited number of sample I/Os in the HumanEval dataset (average of 2.82 per problem), we supplemented it with an additional 5 sample I/Os from the HumanEval-ET dataset. Experiments with this augmented set showed an 1.5% performance gain.
     <br class="ltx_break"/>
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S6.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.5
    </span>
    Error Analysis and Challenges
   </h3>
   <div class="ltx_para" id="S6.SS5.p1">
    <p class="ltx_p" id="S6.SS5.p1.1">
     Although
     <span class="ltx_text ltx_font_typewriter" id="S6.SS5.p1.1.1">
      MapCoder
     </span>
     demonstrates strong performance compared to other methods, it faces challenges in certain algorithmic domains. For example, Figure
     <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.1 Performance on basic code generation ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     illustrates
     <span class="ltx_text ltx_font_typewriter" id="S6.SS5.p1.1.2">
      MapCoder
     </span>
     ’s reduced performance on more difficult problems requiring precise problem understanding and concrete planning—capabilities still lacking in LLMs.
In the xCodeEval dataset (see Figure
     <a class="ltx_ref" href="#S5.F5" title="Figure 5 ‣ 5.1 Performance on basic code generation ‣ 5 Results ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     ), it solves a limited number of problems in categories like Combinatorics, Constructive, Number Theory, Divide and Conquer, and Dynamic Programming (DP). Manual inspection of five DP category problems reveals occasional misinterpretation of problems, attempts to solve using greedy or brute-force approaches, and struggles with accurate DP table construction when recognizing the need for a DP solution.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Conclusion and Future Work
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    In this paper, we introduce
    <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.1">
     MapCoder
    </span>
    , a novel framework for effective code generation in complex problem-solving tasks, leveraging the multi-agent prompting capabilities of LLMs.
    <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.2">
     MapCoder
    </span>
    captures the complete problem-solving cycle by employing four agents - retrieval, planning, coding, and debugging - which dynamically interact to produce high-quality outputs. Evaluation across major benchmarks, including basic and competitive programming datasets, demonstrates
    <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.3">
     MapCoder
    </span>
    ’s consistent outperformance of well-established baselines and SoTA approaches across various metrics. Future work aims to extend this approach to other domains like question answering and mathematical reasoning, expanding its scope and impact.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S8">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    8
   </span>
   Limitations
  </h2>
  <div class="ltx_para" id="S8.p1">
   <p class="ltx_p" id="S8.p1.4">
    Among the limitations of our work, firstly,
    <span class="ltx_text ltx_font_typewriter" id="S8.p1.4.1">
     MapCoder
    </span>
    generates a large number of tokens, which may pose challenges in resource-constrained environments. Table
    <a class="ltx_ref" href="#S6.T8" title="Table 8 ‣ 6.3 Impact of 𝑘 and 𝑡 ‣ 6 Ablations Studies and Analyses ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      8
     </span>
    </a>
    shows the number of average API calls and token consumption with the default
    <math alttext="k" class="ltx_Math" display="inline" id="S8.p1.1.m1.1">
     <semantics id="S8.p1.1.m1.1a">
      <mi id="S8.p1.1.m1.1.1" xref="S8.p1.1.m1.1.1.cmml">
       k
      </mi>
      <annotation-xml encoding="MathML-Content" id="S8.p1.1.m1.1b">
       <ci id="S8.p1.1.m1.1.1.cmml" xref="S8.p1.1.m1.1.1">
        𝑘
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S8.p1.1.m1.1c">
       k
      </annotation>
     </semantics>
    </math>
    and
    <math alttext="t" class="ltx_Math" display="inline" id="S8.p1.2.m2.1">
     <semantics id="S8.p1.2.m2.1a">
      <mi id="S8.p1.2.m2.1.1" xref="S8.p1.2.m2.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="S8.p1.2.m2.1b">
       <ci id="S8.p1.2.m2.1.1.cmml" xref="S8.p1.2.m2.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S8.p1.2.m2.1c">
       t
      </annotation>
     </semantics>
    </math>
    (i.e., with respect to the reported performance) while Table
    <a class="ltx_ref" href="#S6.T7" title="Table 7 ‣ 6.3 Impact of 𝑘 and 𝑡 ‣ 6 Ablations Studies and Analyses ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    ) shows how
    <math alttext="k" class="ltx_Math" display="inline" id="S8.p1.3.m3.1">
     <semantics id="S8.p1.3.m3.1a">
      <mi id="S8.p1.3.m3.1.1" xref="S8.p1.3.m3.1.1.cmml">
       k
      </mi>
      <annotation-xml encoding="MathML-Content" id="S8.p1.3.m3.1b">
       <ci id="S8.p1.3.m3.1.1.cmml" xref="S8.p1.3.m3.1.1">
        𝑘
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S8.p1.3.m3.1c">
       k
      </annotation>
     </semantics>
    </math>
    ,
    <math alttext="t" class="ltx_Math" display="inline" id="S8.p1.4.m4.1">
     <semantics id="S8.p1.4.m4.1a">
      <mi id="S8.p1.4.m4.1.1" xref="S8.p1.4.m4.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="S8.p1.4.m4.1b">
       <ci id="S8.p1.4.m4.1.1.cmml" xref="S8.p1.4.m4.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S8.p1.4.m4.1c">
       t
      </annotation>
     </semantics>
    </math>
    can be adjusted to proportionate the performance gain at the expense of time/token. We have not addressed the problem of minimizing tokens/API-calls in this paper and leave it for future works. Secondly, our method currently relies on sample input-output (I/O) pairs for bug fixing. Although sample I/Os provide valuable insights for LLMs’ code generation, their limited number may not always capture the full spectrum of possible test cases. Consequently, enhancing the quality of additional test case generation could reduce our reliance on sample I/Os and further improve the robustness of our approach. Additionally, future exploration of open-source code generation models, such as CodeLLaMa, LLaMa3, Mixtral 8x7B could offer valuable insights and potential enhancements to our approach. Another important concern is that while running machine-generated code, it is advisable to run it inside a sandbox to avoid any potential risks.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahmad et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021.
    </span>
    <span class="ltx_bibblock">
     Unified pre-training for program understanding and generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint arXiv:2103.06333
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Allal et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Santacoder: don’t reach for the stars!
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2301.03988
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Andreas et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Jacob Andreas, John Bufe, David Burkett, Charles Chen, Josh Clausman, Jean Crawford, Kate Crim, Jordan DeLoach, Leah Dorner, Jason Eisner, Hao Fang, Alan Guo, David Hall, Kristin Hayes, Kellie Hill, Diana Ho, Wendy Iwaszuk, Smriti Jha, Dan Klein, Jayant Krishnamurthy, Theo Lanman, Percy Liang, Christopher H. Lin, Ilya Lintsbakh, Andy McGovern, Aleksandr Nisnevich, Adam Pauls, Dmitrij Petters, Brent Read, Dan Roth, Subhro Roy, Jesse Rusak, Beth Short, Div Slomin, Ben Snyder, Stephon Striplin, Yu Su, Zachary Tellman, Sam Thomson, Andrei Vorobev, Izabela Witoszko, Jason Wolfe, Abby Wray, Yuchen Zhang, and Alexander Zotov. 2020.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00333" target="_blank" title="">
      Task-oriented dialogue as dataflow synthesis
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      Transactions of the Association for Computational Linguistics
     </em>
     , 8:556–571.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Austin et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021.
    </span>
    <span class="ltx_bibblock">
     Program synthesis with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2108.07732
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen. 2022.
    </span>
    <span class="ltx_bibblock">
     Codet: Code generation with generated tests.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      arXiv preprint arXiv:2207.10397
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2021a)
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021a.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2107.03374" target="_blank" title="">
      Evaluating large language models trained on code
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2021b)
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021b.
    </span>
    <span class="ltx_bibblock">
     Evaluating large language models trained on code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      arXiv preprint arXiv:2107.03374
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou. 2023.
    </span>
    <span class="ltx_bibblock">
     Teaching large language models to self-debug.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      arXiv preprint arXiv:2304.05128
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chowdhery et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022.
    </span>
    <span class="ltx_bibblock">
     Palm: Scaling language modeling with pathways.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2204.02311
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Yihong Dong, Jiazheng Ding, Xue Jiang, Zhuo Li, Ge Li, and Zhi Jin. 2023a.
    </span>
    <span class="ltx_bibblock">
     Codescore: Evaluating code generation by learning code execution.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      arXiv preprint arXiv:2301.09043
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. 2023b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.07590" target="_blank" title="">
      Self-collaboration code generation via chatgpt
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. 2020.
    </span>
    <span class="ltx_bibblock">
     Codebert: A pre-trained model for programming and natural languages.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      Findings of the Association for Computational Linguistics: EMNLP 2020
     </em>
     , pages 1536–1547.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fried et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. 2022.
    </span>
    <span class="ltx_bibblock">
     Incoder: A generative model for code infilling and synthesis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      arXiv preprint arXiv:2204.05999
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gulwani (2011)
    </span>
    <span class="ltx_bibblock">
     Sumit Gulwani. 2011.
    </span>
    <span class="ltx_bibblock">
     Automating string processing in spreadsheets using input-output examples.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      ACM Sigplan Notices
     </em>
     , 46(1):317–330.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo et al. (2024)
    </span>
    <span class="ltx_bibblock">
     Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Y Wu, YK Li, et al. 2024.
    </span>
    <span class="ltx_bibblock">
     Deepseek-coder: When the large language model meets programming–the rise of code intelligence.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      arXiv preprint arXiv:2401.14196
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hellendoorn and Devanbu (2017)
    </span>
    <span class="ltx_bibblock">
     Vincent J. Hellendoorn and Premkumar Devanbu. 2017.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3106237.3106290" target="_blank" title="">
      Are deep neural networks the best choice for modeling source code?
     </a>
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering
     </em>
     , ESEC/FSE 2017, pages 763–773, New York, NY, USA. ACM.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hindle et al. (2016)
    </span>
    <span class="ltx_bibblock">
     Abram Hindle, Earl T. Barr, Mark Gabel, Zhendong Su, and Premkumar Devanbu. 2016.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2902362" target="_blank" title="">
      On the naturalness of software
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      Commun. ACM
     </em>
     , 59(5):122–131.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck, and Heming Cui. 2023.
    </span>
    <span class="ltx_bibblock">
     Agentcoder: Multi-agent-based code generation with iterative testing and optimisation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      arXiv preprint arXiv:2312.13010
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023a.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.06825" target="_blank" title="">
      Mistral 7b
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. 2023b.
    </span>
    <span class="ltx_bibblock">
     Self-planning code generation with large language model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2303.06689
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Khan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Mohammad Abdullah Matin Khan, M Saiful Bari, Xuan Long Do, Weishi Wang, Md Rizwan Parvez, and Shafiq Joty. 2023.
    </span>
    <span class="ltx_bibblock">
     xcodeeval: A large scale multilingual multitask benchmark for code understanding, generation, translation and retrieval.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      arXiv preprint arXiv:2303.03004
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Knuth (1992)
    </span>
    <span class="ltx_bibblock">
     Donald E Knuth. 1992.
    </span>
    <span class="ltx_bibblock">
     Literate programming.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      CSLI Lecture Notes, Stanford, CA: Center for the Study of Language and Information (CSLI), 1992
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Le et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, and Steven Chu Hong Hoi. 2022.
    </span>
    <span class="ltx_bibblock">
     Coderl: Mastering code generation through pretrained models and deep reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 35:21314–21328.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jingyao Li, Pengguang Chen, and Jiaya Jia. 2023.
    </span>
    <span class="ltx_bibblock">
     Motcoder: Elevating large language models with modular of thought for challenging programming tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      arXiv preprint arXiv:2312.15960
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. 2022a.
    </span>
    <span class="ltx_bibblock">
     Competition-level code generation with alphacode.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      Science
     </em>
     , 378(6624):1092–1097.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d’Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. 2022b.
    </span>
    <span class="ltx_bibblock">
     Competition-level code generation with alphacode.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=1qvx610Cu7" target="_blank" title="">
      Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      Thirty-seventh Conference on Neural Information Processing Systems
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Manna and Waldinger (1971)
    </span>
    <span class="ltx_bibblock">
     Zohar Manna and Richard J. Waldinger. 1971.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/362566.362568" target="_blank" title="">
      Toward automatic program synthesis
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Commun. ACM
     </em>
     , 14(3):151–165.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nijkamp et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2022.
    </span>
    <span class="ltx_bibblock">
     Codegen: An open large language model for code with multi-turn program synthesis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      arXiv preprint arXiv:2203.13474
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pacheco et al. (2007)
    </span>
    <span class="ltx_bibblock">
     Carlos Pacheco, Shuvendu K Lahiri, Michael D Ernst, and Thomas Ball. 2007.
    </span>
    <span class="ltx_bibblock">
     Feedback-directed random test generation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      29th International Conference on Software Engineering (ICSE’07)
     </em>
     , pages 75–84. IEEE.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parisotto and Salakhutdinov (2017)
    </span>
    <span class="ltx_bibblock">
     Emilio Parisotto and Ruslan Salakhutdinov. 2017.
    </span>
    <span class="ltx_bibblock">
     Neural map: Structured memory for deep reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:1702.08360
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parvez et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Md Rizwan Parvez, Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021.
    </span>
    <span class="ltx_bibblock">
     Retrieval augmented code generation and summarization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2108.11601
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parvez et al. (2018)
    </span>
    <span class="ltx_bibblock">
     Md Rizwan Parvez, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2018.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P18-1221" target="_blank" title="">
      Building language models for text with named entities
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pages 2373–2383, Melbourne, Australia. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parvez et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Md Rizwan Parvez, Jianfeng Chi, Wasi Uddin Ahmad, Yuan Tian, and Kai-Wei Chang. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.eacl-main.16" target="_blank" title="">
      Retrieval enhanced data augmentation for question answering on privacy policies
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics
     </em>
     , pages 201–210, Dubrovnik, Croatia. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Polozov and Gulwani (2015)
    </span>
    <span class="ltx_bibblock">
     Oleksandr Polozov and Sumit Gulwani. 2015.
    </span>
    <span class="ltx_bibblock">
     Flashmeta: A framework for inductive program synthesis.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications
     </em>
     , pages 107–126.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rabinovich et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Maxim Rabinovich, Mitchell Stern, and Dan Klein. 2017.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1704.07535" target="_blank" title="">
      Abstract syntax networks for code generation and semantic parsing
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      CoRR
     </em>
     , abs/1704.07535.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ridnik et al. (2024)
    </span>
    <span class="ltx_bibblock">
     Tal Ridnik, Dedy Kredo, and Itamar Friedman. 2024.
    </span>
    <span class="ltx_bibblock">
     Code generation with alphacodium: From prompt engineering to flow engineering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2401.08500
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Roziere et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Code llama: Open foundation models for code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2308.12950
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and Shunyu Yao. 2023.
    </span>
    <span class="ltx_bibblock">
     Reflexion: Language agents with verbal reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      Thirty-seventh Conference on Neural Information Processing Systems
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shum et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Kashun Shum, Shizhe Diao, and Tong Zhang. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-emnlp.811" target="_blank" title="">
      Automatic prompt augmentation and selection with chain-of-thought from labeled data
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      Findings of the Association for Computational Linguistics: EMNLP 2023
     </em>
     , pages 12113–12139, Singapore. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2307.09288" target="_blank" title="">
      Llama 2: Open foundation and fine-tuned chat models
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      arXiv preprint arXiv:2307.09288
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. 2021.
    </span>
    <span class="ltx_bibblock">
     Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      EMNLP
     </em>
     , pages 8696–8708.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md Rizwan Parvez, and Graham Neubig. 2023.
    </span>
    <span class="ltx_bibblock">
     Learning to filter context for retrieval-augmented generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:2311.08377
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022a.
    </span>
    <span class="ltx_bibblock">
     Chain-of-thought prompting elicits reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 35:24824–24837.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b.
    </span>
    <span class="ltx_bibblock">
     Chain-of-thought prompting elicits reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 35:24824–24837.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong Long, and Jian guang Lou. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.06275" target="_blank" title="">
      Re-reading improves reasoning in language models
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. 2023.
    </span>
    <span class="ltx_bibblock">
     Tree of thoughts: Deliberate problem solving with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:2305.10601
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yasunaga et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Michihiro Yasunaga, Xinyun Chen, Yujia Li, Panupong Pasupat, Jure Leskovec, Percy Liang, Ed H Chi, and Denny Zhou. 2023.
    </span>
    <span class="ltx_bibblock">
     Large language models as analogical reasoners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">
      arXiv preprint arXiv:2310.01714
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yin and Neubig (2017)
    </span>
    <span class="ltx_bibblock">
     Pengcheng Yin and Graham Neubig. 2017.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1704.01696" target="_blank" title="">
      A syntactic neural model for general-purpose code generation
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">
      CoRR
     </em>
     , abs/1704.01696.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yu et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Tao Yu, Rui Zhang, Heyang Er, Suyi Li, Eric Xue, Bo Pang, Xi Victoria Lin, Yi Chern Tan, Tianze Shi, Zihan Li, Youxuan Jiang, Michihiro Yasunaga, Sungrok Shim, Tao Chen, Alexander Fabbri, Zifan Li, Luyao Chen, Yuwen Zhang, Shreya Dixit, Vincent Zhang, Caiming Xiong, Richard Socher, Walter Lasecki, and Dragomir Radev. 2019.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D19-1204" target="_blank" title="">
      CoSQL: A conversational text-to-SQL challenge towards cross-domain natural language interfaces to databases
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">
      Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)
     </em>
     , pages 1962–1979, Hong Kong, China. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao. 2023.
    </span>
    <span class="ltx_bibblock">
     Cumulative reasoning with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      arXiv preprint arXiv:2308.04371
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022.
    </span>
    <span class="ltx_bibblock">
     Automatic chain of thought prompting in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">
      arXiv preprint arXiv:2210.03493
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang. 2023.
    </span>
    <span class="ltx_bibblock">
     Language agent tree search unifies reasoning acting and planning in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">
      arXiv preprint arXiv:2310.04406
     </em>
     .
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_para ltx_noindent" id="p2">
  <p class="ltx_p" id="p2.1">
   <span class="ltx_text ltx_font_bold" id="p2.1.1">
    Appendix
   </span>
   <br class="ltx_break"/>
  </p>
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Algorithm of
   <span class="ltx_text ltx_font_typewriter" id="A1.1.1">
    MapCoder
   </span>
  </h2>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.1">
    Algorithm 1 shows the pseudo-code of our prompting technique.
   </p>
  </div>
  <figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_float">
     <span class="ltx_text ltx_font_bold" id="alg1.3.1.1">
      Algorithm 1
     </span>
    </span>
    <span class="ltx_text ltx_font_typewriter" id="alg1.4.2">
     MapCoder
    </span>
   </figcaption>
   <div class="ltx_listing ltx_listing" id="alg1.5">
    <div class="ltx_listingline" id="alg1.l1">
     <span class="ltx_tag ltx_tag_listingline">
      1:
     </span>
     <math alttext="k\leftarrow" class="ltx_Math" display="inline" id="alg1.l1.m1.1">
      <semantics id="alg1.l1.m1.1a">
       <mrow id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">
        <mi id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2.cmml">
         k
        </mi>
        <mo id="alg1.l1.m1.1.1.1" stretchy="false" xref="alg1.l1.m1.1.1.1.cmml">
         ←
        </mo>
        <mi id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b">
        <apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">
         <ci id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1">
          ←
         </ci>
         <ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">
          𝑘
         </ci>
         <csymbol cd="latexml" id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l1.m1.1c">
        k\leftarrow
       </annotation>
      </semantics>
     </math>
     number of self-retrieved exemplars
    </div>
    <div class="ltx_listingline" id="alg1.l2">
     <span class="ltx_tag ltx_tag_listingline">
      2:
     </span>
     <math alttext="t\leftarrow" class="ltx_Math" display="inline" id="alg1.l2.m1.1">
      <semantics id="alg1.l2.m1.1a">
       <mrow id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">
        <mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">
         t
        </mi>
        <mo id="alg1.l2.m1.1.1.1" stretchy="false" xref="alg1.l2.m1.1.1.1.cmml">
         ←
        </mo>
        <mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b">
        <apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">
         <ci id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1">
          ←
         </ci>
         <ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">
          𝑡
         </ci>
         <csymbol cd="latexml" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l2.m1.1c">
        t\leftarrow
       </annotation>
      </semantics>
     </math>
     number of debugging attempts
    </div>
    <div class="ltx_listingline" id="alg1.l3">
     <span class="ltx_tag ltx_tag_listingline">
      3:
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l4">
     <span class="ltx_tag ltx_tag_listingline">
      4:
     </span>
     <math alttext="exemplars\leftarrow" class="ltx_Math" display="inline" id="alg1.l4.m1.1">
      <semantics id="alg1.l4.m1.1a">
       <mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">
        <mrow id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml">
         <mi id="alg1.l4.m1.1.1.2.2" xref="alg1.l4.m1.1.1.2.2.cmml">
          e
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.3" xref="alg1.l4.m1.1.1.2.3.cmml">
          x
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1a" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.4" xref="alg1.l4.m1.1.1.2.4.cmml">
          e
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1b" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.5" xref="alg1.l4.m1.1.1.2.5.cmml">
          m
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1c" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.6" xref="alg1.l4.m1.1.1.2.6.cmml">
          p
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1d" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.7" xref="alg1.l4.m1.1.1.2.7.cmml">
          l
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1e" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.8" xref="alg1.l4.m1.1.1.2.8.cmml">
          a
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1f" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.9" xref="alg1.l4.m1.1.1.2.9.cmml">
          r
         </mi>
         <mo id="alg1.l4.m1.1.1.2.1g" lspace="0em" rspace="0em" xref="alg1.l4.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l4.m1.1.1.2.10" xref="alg1.l4.m1.1.1.2.10.cmml">
          s
         </mi>
        </mrow>
        <mo id="alg1.l4.m1.1.1.1" stretchy="false" xref="alg1.l4.m1.1.1.1.cmml">
         ←
        </mo>
        <mi id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b">
        <apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">
         <ci id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1">
          ←
         </ci>
         <apply id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2">
          <times id="alg1.l4.m1.1.1.2.1.cmml" xref="alg1.l4.m1.1.1.2.1">
          </times>
          <ci id="alg1.l4.m1.1.1.2.2.cmml" xref="alg1.l4.m1.1.1.2.2">
           𝑒
          </ci>
          <ci id="alg1.l4.m1.1.1.2.3.cmml" xref="alg1.l4.m1.1.1.2.3">
           𝑥
          </ci>
          <ci id="alg1.l4.m1.1.1.2.4.cmml" xref="alg1.l4.m1.1.1.2.4">
           𝑒
          </ci>
          <ci id="alg1.l4.m1.1.1.2.5.cmml" xref="alg1.l4.m1.1.1.2.5">
           𝑚
          </ci>
          <ci id="alg1.l4.m1.1.1.2.6.cmml" xref="alg1.l4.m1.1.1.2.6">
           𝑝
          </ci>
          <ci id="alg1.l4.m1.1.1.2.7.cmml" xref="alg1.l4.m1.1.1.2.7">
           𝑙
          </ci>
          <ci id="alg1.l4.m1.1.1.2.8.cmml" xref="alg1.l4.m1.1.1.2.8">
           𝑎
          </ci>
          <ci id="alg1.l4.m1.1.1.2.9.cmml" xref="alg1.l4.m1.1.1.2.9">
           𝑟
          </ci>
          <ci id="alg1.l4.m1.1.1.2.10.cmml" xref="alg1.l4.m1.1.1.2.10">
           𝑠
          </ci>
         </apply>
         <csymbol cd="latexml" id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l4.m1.1c">
        exemplars\leftarrow
       </annotation>
      </semantics>
     </math>
     RetrivalAgent(
     <math alttext="k" class="ltx_Math" display="inline" id="alg1.l4.m2.1">
      <semantics id="alg1.l4.m2.1a">
       <mi id="alg1.l4.m2.1.1" xref="alg1.l4.m2.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b">
        <ci id="alg1.l4.m2.1.1.cmml" xref="alg1.l4.m2.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l4.m2.1c">
        k
       </annotation>
      </semantics>
     </math>
     )
    </div>
    <div class="ltx_listingline" id="alg1.l5">
     <span class="ltx_tag ltx_tag_listingline">
      5:
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l6">
     <span class="ltx_tag ltx_tag_listingline">
      6:
     </span>
     <math alttext="plans\leftarrow" class="ltx_Math" display="inline" id="alg1.l6.m1.1">
      <semantics id="alg1.l6.m1.1a">
       <mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">
        <mrow id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">
         <mi id="alg1.l6.m1.1.1.2.2" xref="alg1.l6.m1.1.1.2.2.cmml">
          p
         </mi>
         <mo id="alg1.l6.m1.1.1.2.1" lspace="0em" rspace="0em" xref="alg1.l6.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml">
          l
         </mi>
         <mo id="alg1.l6.m1.1.1.2.1a" lspace="0em" rspace="0em" xref="alg1.l6.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l6.m1.1.1.2.4" xref="alg1.l6.m1.1.1.2.4.cmml">
          a
         </mi>
         <mo id="alg1.l6.m1.1.1.2.1b" lspace="0em" rspace="0em" xref="alg1.l6.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l6.m1.1.1.2.5" xref="alg1.l6.m1.1.1.2.5.cmml">
          n
         </mi>
         <mo id="alg1.l6.m1.1.1.2.1c" lspace="0em" rspace="0em" xref="alg1.l6.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l6.m1.1.1.2.6" xref="alg1.l6.m1.1.1.2.6.cmml">
          s
         </mi>
        </mrow>
        <mo id="alg1.l6.m1.1.1.1" stretchy="false" xref="alg1.l6.m1.1.1.1.cmml">
         ←
        </mo>
        <mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b">
        <apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">
         <ci id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1">
          ←
         </ci>
         <apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">
          <times id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2.1">
          </times>
          <ci id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">
           𝑝
          </ci>
          <ci id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3">
           𝑙
          </ci>
          <ci id="alg1.l6.m1.1.1.2.4.cmml" xref="alg1.l6.m1.1.1.2.4">
           𝑎
          </ci>
          <ci id="alg1.l6.m1.1.1.2.5.cmml" xref="alg1.l6.m1.1.1.2.5">
           𝑛
          </ci>
          <ci id="alg1.l6.m1.1.1.2.6.cmml" xref="alg1.l6.m1.1.1.2.6">
           𝑠
          </ci>
         </apply>
         <csymbol cd="latexml" id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l6.m1.1c">
        plans\leftarrow
       </annotation>
      </semantics>
     </math>
     empty array of size
     <math alttext="k" class="ltx_Math" display="inline" id="alg1.l6.m2.1">
      <semantics id="alg1.l6.m2.1a">
       <mi id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b">
        <ci id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l6.m2.1c">
        k
       </annotation>
      </semantics>
     </math>
    </div>
    <div class="ltx_listingline" id="alg1.l7">
     <span class="ltx_tag ltx_tag_listingline">
      7:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l7.1">
      for
     </span>
     <math alttext="example" class="ltx_Math" display="inline" id="alg1.l7.m1.1">
      <semantics id="alg1.l7.m1.1a">
       <mrow id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">
        <mi id="alg1.l7.m1.1.1.2" xref="alg1.l7.m1.1.1.2.cmml">
         e
        </mi>
        <mo id="alg1.l7.m1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l7.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml">
         x
        </mi>
        <mo id="alg1.l7.m1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l7.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m1.1.1.4" xref="alg1.l7.m1.1.1.4.cmml">
         a
        </mi>
        <mo id="alg1.l7.m1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l7.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m1.1.1.5" xref="alg1.l7.m1.1.1.5.cmml">
         m
        </mi>
        <mo id="alg1.l7.m1.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l7.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m1.1.1.6" xref="alg1.l7.m1.1.1.6.cmml">
         p
        </mi>
        <mo id="alg1.l7.m1.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l7.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m1.1.1.7" xref="alg1.l7.m1.1.1.7.cmml">
         l
        </mi>
        <mo id="alg1.l7.m1.1.1.1e" lspace="0em" rspace="0em" xref="alg1.l7.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m1.1.1.8" xref="alg1.l7.m1.1.1.8.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b">
        <apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">
         <times id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1">
         </times>
         <ci id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1.2">
          𝑒
         </ci>
         <ci id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3">
          𝑥
         </ci>
         <ci id="alg1.l7.m1.1.1.4.cmml" xref="alg1.l7.m1.1.1.4">
          𝑎
         </ci>
         <ci id="alg1.l7.m1.1.1.5.cmml" xref="alg1.l7.m1.1.1.5">
          𝑚
         </ci>
         <ci id="alg1.l7.m1.1.1.6.cmml" xref="alg1.l7.m1.1.1.6">
          𝑝
         </ci>
         <ci id="alg1.l7.m1.1.1.7.cmml" xref="alg1.l7.m1.1.1.7">
          𝑙
         </ci>
         <ci id="alg1.l7.m1.1.1.8.cmml" xref="alg1.l7.m1.1.1.8">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l7.m1.1c">
        example
       </annotation>
      </semantics>
     </math>
     in
     <math alttext="exemplars" class="ltx_Math" display="inline" id="alg1.l7.m2.1">
      <semantics id="alg1.l7.m2.1a">
       <mrow id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml">
        <mi id="alg1.l7.m2.1.1.2" xref="alg1.l7.m2.1.1.2.cmml">
         e
        </mi>
        <mo id="alg1.l7.m2.1.1.1" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.3" xref="alg1.l7.m2.1.1.3.cmml">
         x
        </mi>
        <mo id="alg1.l7.m2.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.4" xref="alg1.l7.m2.1.1.4.cmml">
         e
        </mi>
        <mo id="alg1.l7.m2.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.5" xref="alg1.l7.m2.1.1.5.cmml">
         m
        </mi>
        <mo id="alg1.l7.m2.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.6" xref="alg1.l7.m2.1.1.6.cmml">
         p
        </mi>
        <mo id="alg1.l7.m2.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.7" xref="alg1.l7.m2.1.1.7.cmml">
         l
        </mi>
        <mo id="alg1.l7.m2.1.1.1e" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.8" xref="alg1.l7.m2.1.1.8.cmml">
         a
        </mi>
        <mo id="alg1.l7.m2.1.1.1f" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.9" xref="alg1.l7.m2.1.1.9.cmml">
         r
        </mi>
        <mo id="alg1.l7.m2.1.1.1g" lspace="0em" rspace="0em" xref="alg1.l7.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l7.m2.1.1.10" xref="alg1.l7.m2.1.1.10.cmml">
         s
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b">
        <apply id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1">
         <times id="alg1.l7.m2.1.1.1.cmml" xref="alg1.l7.m2.1.1.1">
         </times>
         <ci id="alg1.l7.m2.1.1.2.cmml" xref="alg1.l7.m2.1.1.2">
          𝑒
         </ci>
         <ci id="alg1.l7.m2.1.1.3.cmml" xref="alg1.l7.m2.1.1.3">
          𝑥
         </ci>
         <ci id="alg1.l7.m2.1.1.4.cmml" xref="alg1.l7.m2.1.1.4">
          𝑒
         </ci>
         <ci id="alg1.l7.m2.1.1.5.cmml" xref="alg1.l7.m2.1.1.5">
          𝑚
         </ci>
         <ci id="alg1.l7.m2.1.1.6.cmml" xref="alg1.l7.m2.1.1.6">
          𝑝
         </ci>
         <ci id="alg1.l7.m2.1.1.7.cmml" xref="alg1.l7.m2.1.1.7">
          𝑙
         </ci>
         <ci id="alg1.l7.m2.1.1.8.cmml" xref="alg1.l7.m2.1.1.8">
          𝑎
         </ci>
         <ci id="alg1.l7.m2.1.1.9.cmml" xref="alg1.l7.m2.1.1.9">
          𝑟
         </ci>
         <ci id="alg1.l7.m2.1.1.10.cmml" xref="alg1.l7.m2.1.1.10">
          𝑠
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l7.m2.1c">
        exemplars
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_bold" id="alg1.l7.2">
      do
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l8">
     <span class="ltx_tag ltx_tag_listingline">
      8:
     </span>
     <math alttext="plans[i]\leftarrow" class="ltx_Math" display="inline" id="alg1.l8.m1.1">
      <semantics id="alg1.l8.m1.1a">
       <mrow id="alg1.l8.m1.1.2" xref="alg1.l8.m1.1.2.cmml">
        <mrow id="alg1.l8.m1.1.2.2" xref="alg1.l8.m1.1.2.2.cmml">
         <mi id="alg1.l8.m1.1.2.2.2" xref="alg1.l8.m1.1.2.2.2.cmml">
          p
         </mi>
         <mo id="alg1.l8.m1.1.2.2.1" lspace="0em" rspace="0em" xref="alg1.l8.m1.1.2.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l8.m1.1.2.2.3" xref="alg1.l8.m1.1.2.2.3.cmml">
          l
         </mi>
         <mo id="alg1.l8.m1.1.2.2.1a" lspace="0em" rspace="0em" xref="alg1.l8.m1.1.2.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l8.m1.1.2.2.4" xref="alg1.l8.m1.1.2.2.4.cmml">
          a
         </mi>
         <mo id="alg1.l8.m1.1.2.2.1b" lspace="0em" rspace="0em" xref="alg1.l8.m1.1.2.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l8.m1.1.2.2.5" xref="alg1.l8.m1.1.2.2.5.cmml">
          n
         </mi>
         <mo id="alg1.l8.m1.1.2.2.1c" lspace="0em" rspace="0em" xref="alg1.l8.m1.1.2.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l8.m1.1.2.2.6" xref="alg1.l8.m1.1.2.2.6.cmml">
          s
         </mi>
         <mo id="alg1.l8.m1.1.2.2.1d" lspace="0em" rspace="0em" xref="alg1.l8.m1.1.2.2.1.cmml">
          ​
         </mo>
         <mrow id="alg1.l8.m1.1.2.2.7.2" xref="alg1.l8.m1.1.2.2.7.1.cmml">
          <mo id="alg1.l8.m1.1.2.2.7.2.1" stretchy="false" xref="alg1.l8.m1.1.2.2.7.1.1.cmml">
           [
          </mo>
          <mi id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml">
           i
          </mi>
          <mo id="alg1.l8.m1.1.2.2.7.2.2" stretchy="false" xref="alg1.l8.m1.1.2.2.7.1.1.cmml">
           ]
          </mo>
         </mrow>
        </mrow>
        <mo id="alg1.l8.m1.1.2.1" stretchy="false" xref="alg1.l8.m1.1.2.1.cmml">
         ←
        </mo>
        <mi id="alg1.l8.m1.1.2.3" xref="alg1.l8.m1.1.2.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b">
        <apply id="alg1.l8.m1.1.2.cmml" xref="alg1.l8.m1.1.2">
         <ci id="alg1.l8.m1.1.2.1.cmml" xref="alg1.l8.m1.1.2.1">
          ←
         </ci>
         <apply id="alg1.l8.m1.1.2.2.cmml" xref="alg1.l8.m1.1.2.2">
          <times id="alg1.l8.m1.1.2.2.1.cmml" xref="alg1.l8.m1.1.2.2.1">
          </times>
          <ci id="alg1.l8.m1.1.2.2.2.cmml" xref="alg1.l8.m1.1.2.2.2">
           𝑝
          </ci>
          <ci id="alg1.l8.m1.1.2.2.3.cmml" xref="alg1.l8.m1.1.2.2.3">
           𝑙
          </ci>
          <ci id="alg1.l8.m1.1.2.2.4.cmml" xref="alg1.l8.m1.1.2.2.4">
           𝑎
          </ci>
          <ci id="alg1.l8.m1.1.2.2.5.cmml" xref="alg1.l8.m1.1.2.2.5">
           𝑛
          </ci>
          <ci id="alg1.l8.m1.1.2.2.6.cmml" xref="alg1.l8.m1.1.2.2.6">
           𝑠
          </ci>
          <apply id="alg1.l8.m1.1.2.2.7.1.cmml" xref="alg1.l8.m1.1.2.2.7.2">
           <csymbol cd="latexml" id="alg1.l8.m1.1.2.2.7.1.1.cmml" xref="alg1.l8.m1.1.2.2.7.2.1">
            delimited-[]
           </csymbol>
           <ci id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1">
            𝑖
           </ci>
          </apply>
         </apply>
         <csymbol cd="latexml" id="alg1.l8.m1.1.2.3.cmml" xref="alg1.l8.m1.1.2.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l8.m1.1c">
        plans[i]\leftarrow
       </annotation>
      </semantics>
     </math>
     PlanningAgent(
     <math alttext="example" class="ltx_Math" display="inline" id="alg1.l8.m2.1">
      <semantics id="alg1.l8.m2.1a">
       <mrow id="alg1.l8.m2.1.1" xref="alg1.l8.m2.1.1.cmml">
        <mi id="alg1.l8.m2.1.1.2" xref="alg1.l8.m2.1.1.2.cmml">
         e
        </mi>
        <mo id="alg1.l8.m2.1.1.1" lspace="0em" rspace="0em" xref="alg1.l8.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l8.m2.1.1.3" xref="alg1.l8.m2.1.1.3.cmml">
         x
        </mi>
        <mo id="alg1.l8.m2.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l8.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l8.m2.1.1.4" xref="alg1.l8.m2.1.1.4.cmml">
         a
        </mi>
        <mo id="alg1.l8.m2.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l8.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l8.m2.1.1.5" xref="alg1.l8.m2.1.1.5.cmml">
         m
        </mi>
        <mo id="alg1.l8.m2.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l8.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l8.m2.1.1.6" xref="alg1.l8.m2.1.1.6.cmml">
         p
        </mi>
        <mo id="alg1.l8.m2.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l8.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l8.m2.1.1.7" xref="alg1.l8.m2.1.1.7.cmml">
         l
        </mi>
        <mo id="alg1.l8.m2.1.1.1e" lspace="0em" rspace="0em" xref="alg1.l8.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l8.m2.1.1.8" xref="alg1.l8.m2.1.1.8.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b">
        <apply id="alg1.l8.m2.1.1.cmml" xref="alg1.l8.m2.1.1">
         <times id="alg1.l8.m2.1.1.1.cmml" xref="alg1.l8.m2.1.1.1">
         </times>
         <ci id="alg1.l8.m2.1.1.2.cmml" xref="alg1.l8.m2.1.1.2">
          𝑒
         </ci>
         <ci id="alg1.l8.m2.1.1.3.cmml" xref="alg1.l8.m2.1.1.3">
          𝑥
         </ci>
         <ci id="alg1.l8.m2.1.1.4.cmml" xref="alg1.l8.m2.1.1.4">
          𝑎
         </ci>
         <ci id="alg1.l8.m2.1.1.5.cmml" xref="alg1.l8.m2.1.1.5">
          𝑚
         </ci>
         <ci id="alg1.l8.m2.1.1.6.cmml" xref="alg1.l8.m2.1.1.6">
          𝑝
         </ci>
         <ci id="alg1.l8.m2.1.1.7.cmml" xref="alg1.l8.m2.1.1.7">
          𝑙
         </ci>
         <ci id="alg1.l8.m2.1.1.8.cmml" xref="alg1.l8.m2.1.1.8">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l8.m2.1c">
        example
       </annotation>
      </semantics>
     </math>
     )
    </div>
    <div class="ltx_listingline" id="alg1.l9">
     <span class="ltx_tag ltx_tag_listingline">
      9:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l9.1">
      end
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l9.2">
      for
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l10">
     <span class="ltx_tag ltx_tag_listingline">
      10:
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l11">
     <span class="ltx_tag ltx_tag_listingline">
      11:
     </span>
     <math alttext="plans\leftarrow" class="ltx_Math" display="inline" id="alg1.l11.m1.1">
      <semantics id="alg1.l11.m1.1a">
       <mrow id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml">
        <mrow id="alg1.l11.m1.1.1.2" xref="alg1.l11.m1.1.1.2.cmml">
         <mi id="alg1.l11.m1.1.1.2.2" xref="alg1.l11.m1.1.1.2.2.cmml">
          p
         </mi>
         <mo id="alg1.l11.m1.1.1.2.1" lspace="0em" rspace="0em" xref="alg1.l11.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l11.m1.1.1.2.3" xref="alg1.l11.m1.1.1.2.3.cmml">
          l
         </mi>
         <mo id="alg1.l11.m1.1.1.2.1a" lspace="0em" rspace="0em" xref="alg1.l11.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l11.m1.1.1.2.4" xref="alg1.l11.m1.1.1.2.4.cmml">
          a
         </mi>
         <mo id="alg1.l11.m1.1.1.2.1b" lspace="0em" rspace="0em" xref="alg1.l11.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l11.m1.1.1.2.5" xref="alg1.l11.m1.1.1.2.5.cmml">
          n
         </mi>
         <mo id="alg1.l11.m1.1.1.2.1c" lspace="0em" rspace="0em" xref="alg1.l11.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l11.m1.1.1.2.6" xref="alg1.l11.m1.1.1.2.6.cmml">
          s
         </mi>
        </mrow>
        <mo id="alg1.l11.m1.1.1.1" stretchy="false" xref="alg1.l11.m1.1.1.1.cmml">
         ←
        </mo>
        <mi id="alg1.l11.m1.1.1.3" xref="alg1.l11.m1.1.1.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b">
        <apply id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1">
         <ci id="alg1.l11.m1.1.1.1.cmml" xref="alg1.l11.m1.1.1.1">
          ←
         </ci>
         <apply id="alg1.l11.m1.1.1.2.cmml" xref="alg1.l11.m1.1.1.2">
          <times id="alg1.l11.m1.1.1.2.1.cmml" xref="alg1.l11.m1.1.1.2.1">
          </times>
          <ci id="alg1.l11.m1.1.1.2.2.cmml" xref="alg1.l11.m1.1.1.2.2">
           𝑝
          </ci>
          <ci id="alg1.l11.m1.1.1.2.3.cmml" xref="alg1.l11.m1.1.1.2.3">
           𝑙
          </ci>
          <ci id="alg1.l11.m1.1.1.2.4.cmml" xref="alg1.l11.m1.1.1.2.4">
           𝑎
          </ci>
          <ci id="alg1.l11.m1.1.1.2.5.cmml" xref="alg1.l11.m1.1.1.2.5">
           𝑛
          </ci>
          <ci id="alg1.l11.m1.1.1.2.6.cmml" xref="alg1.l11.m1.1.1.2.6">
           𝑠
          </ci>
         </apply>
         <csymbol cd="latexml" id="alg1.l11.m1.1.1.3.cmml" xref="alg1.l11.m1.1.1.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l11.m1.1c">
        plans\leftarrow
       </annotation>
      </semantics>
     </math>
     SortByConfidence(
     <math alttext="plans" class="ltx_Math" display="inline" id="alg1.l11.m2.1">
      <semantics id="alg1.l11.m2.1a">
       <mrow id="alg1.l11.m2.1.1" xref="alg1.l11.m2.1.1.cmml">
        <mi id="alg1.l11.m2.1.1.2" xref="alg1.l11.m2.1.1.2.cmml">
         p
        </mi>
        <mo id="alg1.l11.m2.1.1.1" lspace="0em" rspace="0em" xref="alg1.l11.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l11.m2.1.1.3" xref="alg1.l11.m2.1.1.3.cmml">
         l
        </mi>
        <mo id="alg1.l11.m2.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l11.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l11.m2.1.1.4" xref="alg1.l11.m2.1.1.4.cmml">
         a
        </mi>
        <mo id="alg1.l11.m2.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l11.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l11.m2.1.1.5" xref="alg1.l11.m2.1.1.5.cmml">
         n
        </mi>
        <mo id="alg1.l11.m2.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l11.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l11.m2.1.1.6" xref="alg1.l11.m2.1.1.6.cmml">
         s
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l11.m2.1b">
        <apply id="alg1.l11.m2.1.1.cmml" xref="alg1.l11.m2.1.1">
         <times id="alg1.l11.m2.1.1.1.cmml" xref="alg1.l11.m2.1.1.1">
         </times>
         <ci id="alg1.l11.m2.1.1.2.cmml" xref="alg1.l11.m2.1.1.2">
          𝑝
         </ci>
         <ci id="alg1.l11.m2.1.1.3.cmml" xref="alg1.l11.m2.1.1.3">
          𝑙
         </ci>
         <ci id="alg1.l11.m2.1.1.4.cmml" xref="alg1.l11.m2.1.1.4">
          𝑎
         </ci>
         <ci id="alg1.l11.m2.1.1.5.cmml" xref="alg1.l11.m2.1.1.5">
          𝑛
         </ci>
         <ci id="alg1.l11.m2.1.1.6.cmml" xref="alg1.l11.m2.1.1.6">
          𝑠
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l11.m2.1c">
        plans
       </annotation>
      </semantics>
     </math>
     )
    </div>
    <div class="ltx_listingline" id="alg1.l12">
     <span class="ltx_tag ltx_tag_listingline">
      12:
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l13">
     <span class="ltx_tag ltx_tag_listingline">
      13:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l13.1">
      for
     </span>
     <math alttext="i\leftarrow 1" class="ltx_Math" display="inline" id="alg1.l13.m1.1">
      <semantics id="alg1.l13.m1.1a">
       <mrow id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml">
        <mi id="alg1.l13.m1.1.1.2" xref="alg1.l13.m1.1.1.2.cmml">
         i
        </mi>
        <mo id="alg1.l13.m1.1.1.1" stretchy="false" xref="alg1.l13.m1.1.1.1.cmml">
         ←
        </mo>
        <mn id="alg1.l13.m1.1.1.3" xref="alg1.l13.m1.1.1.3.cmml">
         1
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b">
        <apply id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1">
         <ci id="alg1.l13.m1.1.1.1.cmml" xref="alg1.l13.m1.1.1.1">
          ←
         </ci>
         <ci id="alg1.l13.m1.1.1.2.cmml" xref="alg1.l13.m1.1.1.2">
          𝑖
         </ci>
         <cn id="alg1.l13.m1.1.1.3.cmml" type="integer" xref="alg1.l13.m1.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l13.m1.1c">
        i\leftarrow 1
       </annotation>
      </semantics>
     </math>
     to
     <math alttext="k" class="ltx_Math" display="inline" id="alg1.l13.m2.1">
      <semantics id="alg1.l13.m2.1a">
       <mi id="alg1.l13.m2.1.1" xref="alg1.l13.m2.1.1.cmml">
        k
       </mi>
       <annotation-xml encoding="MathML-Content" id="alg1.l13.m2.1b">
        <ci id="alg1.l13.m2.1.1.cmml" xref="alg1.l13.m2.1.1">
         𝑘
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l13.m2.1c">
        k
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_bold" id="alg1.l13.2">
      do
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l14">
     <span class="ltx_tag ltx_tag_listingline">
      14:
     </span>
     <math alttext="code\leftarrow" class="ltx_Math" display="inline" id="alg1.l14.m1.1">
      <semantics id="alg1.l14.m1.1a">
       <mrow id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">
        <mrow id="alg1.l14.m1.1.1.2" xref="alg1.l14.m1.1.1.2.cmml">
         <mi id="alg1.l14.m1.1.1.2.2" xref="alg1.l14.m1.1.1.2.2.cmml">
          c
         </mi>
         <mo id="alg1.l14.m1.1.1.2.1" lspace="0em" rspace="0em" xref="alg1.l14.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l14.m1.1.1.2.3" xref="alg1.l14.m1.1.1.2.3.cmml">
          o
         </mi>
         <mo id="alg1.l14.m1.1.1.2.1a" lspace="0em" rspace="0em" xref="alg1.l14.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l14.m1.1.1.2.4" xref="alg1.l14.m1.1.1.2.4.cmml">
          d
         </mi>
         <mo id="alg1.l14.m1.1.1.2.1b" lspace="0em" rspace="0em" xref="alg1.l14.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l14.m1.1.1.2.5" xref="alg1.l14.m1.1.1.2.5.cmml">
          e
         </mi>
        </mrow>
        <mo id="alg1.l14.m1.1.1.1" stretchy="false" xref="alg1.l14.m1.1.1.1.cmml">
         ←
        </mo>
        <mi id="alg1.l14.m1.1.1.3" xref="alg1.l14.m1.1.1.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b">
        <apply id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">
         <ci id="alg1.l14.m1.1.1.1.cmml" xref="alg1.l14.m1.1.1.1">
          ←
         </ci>
         <apply id="alg1.l14.m1.1.1.2.cmml" xref="alg1.l14.m1.1.1.2">
          <times id="alg1.l14.m1.1.1.2.1.cmml" xref="alg1.l14.m1.1.1.2.1">
          </times>
          <ci id="alg1.l14.m1.1.1.2.2.cmml" xref="alg1.l14.m1.1.1.2.2">
           𝑐
          </ci>
          <ci id="alg1.l14.m1.1.1.2.3.cmml" xref="alg1.l14.m1.1.1.2.3">
           𝑜
          </ci>
          <ci id="alg1.l14.m1.1.1.2.4.cmml" xref="alg1.l14.m1.1.1.2.4">
           𝑑
          </ci>
          <ci id="alg1.l14.m1.1.1.2.5.cmml" xref="alg1.l14.m1.1.1.2.5">
           𝑒
          </ci>
         </apply>
         <csymbol cd="latexml" id="alg1.l14.m1.1.1.3.cmml" xref="alg1.l14.m1.1.1.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l14.m1.1c">
        code\leftarrow
       </annotation>
      </semantics>
     </math>
     CodingAgent(
     <math alttext="code" class="ltx_Math" display="inline" id="alg1.l14.m2.1">
      <semantics id="alg1.l14.m2.1a">
       <mrow id="alg1.l14.m2.1.1" xref="alg1.l14.m2.1.1.cmml">
        <mi id="alg1.l14.m2.1.1.2" xref="alg1.l14.m2.1.1.2.cmml">
         c
        </mi>
        <mo id="alg1.l14.m2.1.1.1" lspace="0em" rspace="0em" xref="alg1.l14.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l14.m2.1.1.3" xref="alg1.l14.m2.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l14.m2.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l14.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l14.m2.1.1.4" xref="alg1.l14.m2.1.1.4.cmml">
         d
        </mi>
        <mo id="alg1.l14.m2.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l14.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l14.m2.1.1.5" xref="alg1.l14.m2.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l14.m2.1b">
        <apply id="alg1.l14.m2.1.1.cmml" xref="alg1.l14.m2.1.1">
         <times id="alg1.l14.m2.1.1.1.cmml" xref="alg1.l14.m2.1.1.1">
         </times>
         <ci id="alg1.l14.m2.1.1.2.cmml" xref="alg1.l14.m2.1.1.2">
          𝑐
         </ci>
         <ci id="alg1.l14.m2.1.1.3.cmml" xref="alg1.l14.m2.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l14.m2.1.1.4.cmml" xref="alg1.l14.m2.1.1.4">
          𝑑
         </ci>
         <ci id="alg1.l14.m2.1.1.5.cmml" xref="alg1.l14.m2.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l14.m2.1c">
        code
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="plan[i]" class="ltx_Math" display="inline" id="alg1.l14.m3.1">
      <semantics id="alg1.l14.m3.1a">
       <mrow id="alg1.l14.m3.1.2" xref="alg1.l14.m3.1.2.cmml">
        <mi id="alg1.l14.m3.1.2.2" xref="alg1.l14.m3.1.2.2.cmml">
         p
        </mi>
        <mo id="alg1.l14.m3.1.2.1" lspace="0em" rspace="0em" xref="alg1.l14.m3.1.2.1.cmml">
         ​
        </mo>
        <mi id="alg1.l14.m3.1.2.3" xref="alg1.l14.m3.1.2.3.cmml">
         l
        </mi>
        <mo id="alg1.l14.m3.1.2.1a" lspace="0em" rspace="0em" xref="alg1.l14.m3.1.2.1.cmml">
         ​
        </mo>
        <mi id="alg1.l14.m3.1.2.4" xref="alg1.l14.m3.1.2.4.cmml">
         a
        </mi>
        <mo id="alg1.l14.m3.1.2.1b" lspace="0em" rspace="0em" xref="alg1.l14.m3.1.2.1.cmml">
         ​
        </mo>
        <mi id="alg1.l14.m3.1.2.5" xref="alg1.l14.m3.1.2.5.cmml">
         n
        </mi>
        <mo id="alg1.l14.m3.1.2.1c" lspace="0em" rspace="0em" xref="alg1.l14.m3.1.2.1.cmml">
         ​
        </mo>
        <mrow id="alg1.l14.m3.1.2.6.2" xref="alg1.l14.m3.1.2.6.1.cmml">
         <mo id="alg1.l14.m3.1.2.6.2.1" stretchy="false" xref="alg1.l14.m3.1.2.6.1.1.cmml">
          [
         </mo>
         <mi id="alg1.l14.m3.1.1" xref="alg1.l14.m3.1.1.cmml">
          i
         </mi>
         <mo id="alg1.l14.m3.1.2.6.2.2" stretchy="false" xref="alg1.l14.m3.1.2.6.1.1.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l14.m3.1b">
        <apply id="alg1.l14.m3.1.2.cmml" xref="alg1.l14.m3.1.2">
         <times id="alg1.l14.m3.1.2.1.cmml" xref="alg1.l14.m3.1.2.1">
         </times>
         <ci id="alg1.l14.m3.1.2.2.cmml" xref="alg1.l14.m3.1.2.2">
          𝑝
         </ci>
         <ci id="alg1.l14.m3.1.2.3.cmml" xref="alg1.l14.m3.1.2.3">
          𝑙
         </ci>
         <ci id="alg1.l14.m3.1.2.4.cmml" xref="alg1.l14.m3.1.2.4">
          𝑎
         </ci>
         <ci id="alg1.l14.m3.1.2.5.cmml" xref="alg1.l14.m3.1.2.5">
          𝑛
         </ci>
         <apply id="alg1.l14.m3.1.2.6.1.cmml" xref="alg1.l14.m3.1.2.6.2">
          <csymbol cd="latexml" id="alg1.l14.m3.1.2.6.1.1.cmml" xref="alg1.l14.m3.1.2.6.2.1">
           delimited-[]
          </csymbol>
          <ci id="alg1.l14.m3.1.1.cmml" xref="alg1.l14.m3.1.1">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l14.m3.1c">
        plan[i]
       </annotation>
      </semantics>
     </math>
     )
    </div>
    <div class="ltx_listingline" id="alg1.l15">
     <span class="ltx_tag ltx_tag_listingline">
      15:
     </span>
     <math alttext="passed,log\leftarrow" class="ltx_Math" display="inline" id="alg1.l15.m1.2">
      <semantics id="alg1.l15.m1.2a">
       <mrow id="alg1.l15.m1.2.2" xref="alg1.l15.m1.2.2.cmml">
        <mrow id="alg1.l15.m1.2.2.2.2" xref="alg1.l15.m1.2.2.2.3.cmml">
         <mrow id="alg1.l15.m1.1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.1.cmml">
          <mi id="alg1.l15.m1.1.1.1.1.1.2" xref="alg1.l15.m1.1.1.1.1.1.2.cmml">
           p
          </mi>
          <mo id="alg1.l15.m1.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l15.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l15.m1.1.1.1.1.1.3" xref="alg1.l15.m1.1.1.1.1.1.3.cmml">
           a
          </mi>
          <mo id="alg1.l15.m1.1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l15.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l15.m1.1.1.1.1.1.4" xref="alg1.l15.m1.1.1.1.1.1.4.cmml">
           s
          </mi>
          <mo id="alg1.l15.m1.1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l15.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l15.m1.1.1.1.1.1.5" xref="alg1.l15.m1.1.1.1.1.1.5.cmml">
           s
          </mi>
          <mo id="alg1.l15.m1.1.1.1.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l15.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l15.m1.1.1.1.1.1.6" xref="alg1.l15.m1.1.1.1.1.1.6.cmml">
           e
          </mi>
          <mo id="alg1.l15.m1.1.1.1.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l15.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l15.m1.1.1.1.1.1.7" xref="alg1.l15.m1.1.1.1.1.1.7.cmml">
           d
          </mi>
         </mrow>
         <mo id="alg1.l15.m1.2.2.2.2.3" xref="alg1.l15.m1.2.2.2.3.cmml">
          ,
         </mo>
         <mrow id="alg1.l15.m1.2.2.2.2.2" xref="alg1.l15.m1.2.2.2.2.2.cmml">
          <mi id="alg1.l15.m1.2.2.2.2.2.2" xref="alg1.l15.m1.2.2.2.2.2.2.cmml">
           l
          </mi>
          <mo id="alg1.l15.m1.2.2.2.2.2.1" lspace="0em" rspace="0em" xref="alg1.l15.m1.2.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="alg1.l15.m1.2.2.2.2.2.3" xref="alg1.l15.m1.2.2.2.2.2.3.cmml">
           o
          </mi>
          <mo id="alg1.l15.m1.2.2.2.2.2.1a" lspace="0em" rspace="0em" xref="alg1.l15.m1.2.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="alg1.l15.m1.2.2.2.2.2.4" xref="alg1.l15.m1.2.2.2.2.2.4.cmml">
           g
          </mi>
         </mrow>
        </mrow>
        <mo id="alg1.l15.m1.2.2.3" stretchy="false" xref="alg1.l15.m1.2.2.3.cmml">
         ←
        </mo>
        <mi id="alg1.l15.m1.2.2.4" xref="alg1.l15.m1.2.2.4.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l15.m1.2b">
        <apply id="alg1.l15.m1.2.2.cmml" xref="alg1.l15.m1.2.2">
         <ci id="alg1.l15.m1.2.2.3.cmml" xref="alg1.l15.m1.2.2.3">
          ←
         </ci>
         <list id="alg1.l15.m1.2.2.2.3.cmml" xref="alg1.l15.m1.2.2.2.2">
          <apply id="alg1.l15.m1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1">
           <times id="alg1.l15.m1.1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1.1">
           </times>
           <ci id="alg1.l15.m1.1.1.1.1.1.2.cmml" xref="alg1.l15.m1.1.1.1.1.1.2">
            𝑝
           </ci>
           <ci id="alg1.l15.m1.1.1.1.1.1.3.cmml" xref="alg1.l15.m1.1.1.1.1.1.3">
            𝑎
           </ci>
           <ci id="alg1.l15.m1.1.1.1.1.1.4.cmml" xref="alg1.l15.m1.1.1.1.1.1.4">
            𝑠
           </ci>
           <ci id="alg1.l15.m1.1.1.1.1.1.5.cmml" xref="alg1.l15.m1.1.1.1.1.1.5">
            𝑠
           </ci>
           <ci id="alg1.l15.m1.1.1.1.1.1.6.cmml" xref="alg1.l15.m1.1.1.1.1.1.6">
            𝑒
           </ci>
           <ci id="alg1.l15.m1.1.1.1.1.1.7.cmml" xref="alg1.l15.m1.1.1.1.1.1.7">
            𝑑
           </ci>
          </apply>
          <apply id="alg1.l15.m1.2.2.2.2.2.cmml" xref="alg1.l15.m1.2.2.2.2.2">
           <times id="alg1.l15.m1.2.2.2.2.2.1.cmml" xref="alg1.l15.m1.2.2.2.2.2.1">
           </times>
           <ci id="alg1.l15.m1.2.2.2.2.2.2.cmml" xref="alg1.l15.m1.2.2.2.2.2.2">
            𝑙
           </ci>
           <ci id="alg1.l15.m1.2.2.2.2.2.3.cmml" xref="alg1.l15.m1.2.2.2.2.2.3">
            𝑜
           </ci>
           <ci id="alg1.l15.m1.2.2.2.2.2.4.cmml" xref="alg1.l15.m1.2.2.2.2.2.4">
            𝑔
           </ci>
          </apply>
         </list>
         <csymbol cd="latexml" id="alg1.l15.m1.2.2.4.cmml" xref="alg1.l15.m1.2.2.4">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l15.m1.2c">
        passed,log\leftarrow
       </annotation>
      </semantics>
     </math>
     test(
     <math alttext="code" class="ltx_Math" display="inline" id="alg1.l15.m2.1">
      <semantics id="alg1.l15.m2.1a">
       <mrow id="alg1.l15.m2.1.1" xref="alg1.l15.m2.1.1.cmml">
        <mi id="alg1.l15.m2.1.1.2" xref="alg1.l15.m2.1.1.2.cmml">
         c
        </mi>
        <mo id="alg1.l15.m2.1.1.1" lspace="0em" rspace="0em" xref="alg1.l15.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m2.1.1.3" xref="alg1.l15.m2.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l15.m2.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l15.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m2.1.1.4" xref="alg1.l15.m2.1.1.4.cmml">
         d
        </mi>
        <mo id="alg1.l15.m2.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l15.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m2.1.1.5" xref="alg1.l15.m2.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l15.m2.1b">
        <apply id="alg1.l15.m2.1.1.cmml" xref="alg1.l15.m2.1.1">
         <times id="alg1.l15.m2.1.1.1.cmml" xref="alg1.l15.m2.1.1.1">
         </times>
         <ci id="alg1.l15.m2.1.1.2.cmml" xref="alg1.l15.m2.1.1.2">
          𝑐
         </ci>
         <ci id="alg1.l15.m2.1.1.3.cmml" xref="alg1.l15.m2.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l15.m2.1.1.4.cmml" xref="alg1.l15.m2.1.1.4">
          𝑑
         </ci>
         <ci id="alg1.l15.m2.1.1.5.cmml" xref="alg1.l15.m2.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l15.m2.1c">
        code
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="sample\_io" class="ltx_Math" display="inline" id="alg1.l15.m3.1">
      <semantics id="alg1.l15.m3.1a">
       <mrow id="alg1.l15.m3.1.1" xref="alg1.l15.m3.1.1.cmml">
        <mi id="alg1.l15.m3.1.1.2" xref="alg1.l15.m3.1.1.2.cmml">
         s
        </mi>
        <mo id="alg1.l15.m3.1.1.1" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.3" xref="alg1.l15.m3.1.1.3.cmml">
         a
        </mi>
        <mo id="alg1.l15.m3.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.4" xref="alg1.l15.m3.1.1.4.cmml">
         m
        </mi>
        <mo id="alg1.l15.m3.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.5" xref="alg1.l15.m3.1.1.5.cmml">
         p
        </mi>
        <mo id="alg1.l15.m3.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.6" xref="alg1.l15.m3.1.1.6.cmml">
         l
        </mi>
        <mo id="alg1.l15.m3.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.7" xref="alg1.l15.m3.1.1.7.cmml">
         e
        </mi>
        <mo id="alg1.l15.m3.1.1.1e" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.8" mathvariant="normal" xref="alg1.l15.m3.1.1.8.cmml">
         _
        </mi>
        <mo id="alg1.l15.m3.1.1.1f" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.9" xref="alg1.l15.m3.1.1.9.cmml">
         i
        </mi>
        <mo id="alg1.l15.m3.1.1.1g" lspace="0em" rspace="0em" xref="alg1.l15.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l15.m3.1.1.10" xref="alg1.l15.m3.1.1.10.cmml">
         o
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l15.m3.1b">
        <apply id="alg1.l15.m3.1.1.cmml" xref="alg1.l15.m3.1.1">
         <times id="alg1.l15.m3.1.1.1.cmml" xref="alg1.l15.m3.1.1.1">
         </times>
         <ci id="alg1.l15.m3.1.1.2.cmml" xref="alg1.l15.m3.1.1.2">
          𝑠
         </ci>
         <ci id="alg1.l15.m3.1.1.3.cmml" xref="alg1.l15.m3.1.1.3">
          𝑎
         </ci>
         <ci id="alg1.l15.m3.1.1.4.cmml" xref="alg1.l15.m3.1.1.4">
          𝑚
         </ci>
         <ci id="alg1.l15.m3.1.1.5.cmml" xref="alg1.l15.m3.1.1.5">
          𝑝
         </ci>
         <ci id="alg1.l15.m3.1.1.6.cmml" xref="alg1.l15.m3.1.1.6">
          𝑙
         </ci>
         <ci id="alg1.l15.m3.1.1.7.cmml" xref="alg1.l15.m3.1.1.7">
          𝑒
         </ci>
         <ci id="alg1.l15.m3.1.1.8.cmml" xref="alg1.l15.m3.1.1.8">
          _
         </ci>
         <ci id="alg1.l15.m3.1.1.9.cmml" xref="alg1.l15.m3.1.1.9">
          𝑖
         </ci>
         <ci id="alg1.l15.m3.1.1.10.cmml" xref="alg1.l15.m3.1.1.10">
          𝑜
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l15.m3.1c">
        sample\_io
       </annotation>
      </semantics>
     </math>
     )
    </div>
    <div class="ltx_listingline" id="alg1.l16">
     <span class="ltx_tag ltx_tag_listingline">
      16:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l16.1">
      if
     </span>
     <math alttext="passed" class="ltx_Math" display="inline" id="alg1.l16.m1.1">
      <semantics id="alg1.l16.m1.1a">
       <mrow id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml">
        <mi id="alg1.l16.m1.1.1.2" xref="alg1.l16.m1.1.1.2.cmml">
         p
        </mi>
        <mo id="alg1.l16.m1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l16.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l16.m1.1.1.3" xref="alg1.l16.m1.1.1.3.cmml">
         a
        </mi>
        <mo id="alg1.l16.m1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l16.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l16.m1.1.1.4" xref="alg1.l16.m1.1.1.4.cmml">
         s
        </mi>
        <mo id="alg1.l16.m1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l16.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l16.m1.1.1.5" xref="alg1.l16.m1.1.1.5.cmml">
         s
        </mi>
        <mo id="alg1.l16.m1.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l16.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l16.m1.1.1.6" xref="alg1.l16.m1.1.1.6.cmml">
         e
        </mi>
        <mo id="alg1.l16.m1.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l16.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l16.m1.1.1.7" xref="alg1.l16.m1.1.1.7.cmml">
         d
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b">
        <apply id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1">
         <times id="alg1.l16.m1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1">
         </times>
         <ci id="alg1.l16.m1.1.1.2.cmml" xref="alg1.l16.m1.1.1.2">
          𝑝
         </ci>
         <ci id="alg1.l16.m1.1.1.3.cmml" xref="alg1.l16.m1.1.1.3">
          𝑎
         </ci>
         <ci id="alg1.l16.m1.1.1.4.cmml" xref="alg1.l16.m1.1.1.4">
          𝑠
         </ci>
         <ci id="alg1.l16.m1.1.1.5.cmml" xref="alg1.l16.m1.1.1.5">
          𝑠
         </ci>
         <ci id="alg1.l16.m1.1.1.6.cmml" xref="alg1.l16.m1.1.1.6">
          𝑒
         </ci>
         <ci id="alg1.l16.m1.1.1.7.cmml" xref="alg1.l16.m1.1.1.7">
          𝑑
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l16.m1.1c">
        passed
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_bold" id="alg1.l16.2">
      then
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l17">
     <span class="ltx_tag ltx_tag_listingline">
      17:
     </span>
     Return
     <math alttext="code" class="ltx_Math" display="inline" id="alg1.l17.m1.1">
      <semantics id="alg1.l17.m1.1a">
       <mrow id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml">
        <mi id="alg1.l17.m1.1.1.2" xref="alg1.l17.m1.1.1.2.cmml">
         c
        </mi>
        <mo id="alg1.l17.m1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l17.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l17.m1.1.1.3" xref="alg1.l17.m1.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l17.m1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l17.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l17.m1.1.1.4" xref="alg1.l17.m1.1.1.4.cmml">
         d
        </mi>
        <mo id="alg1.l17.m1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l17.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l17.m1.1.1.5" xref="alg1.l17.m1.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b">
        <apply id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1">
         <times id="alg1.l17.m1.1.1.1.cmml" xref="alg1.l17.m1.1.1.1">
         </times>
         <ci id="alg1.l17.m1.1.1.2.cmml" xref="alg1.l17.m1.1.1.2">
          𝑐
         </ci>
         <ci id="alg1.l17.m1.1.1.3.cmml" xref="alg1.l17.m1.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l17.m1.1.1.4.cmml" xref="alg1.l17.m1.1.1.4">
          𝑑
         </ci>
         <ci id="alg1.l17.m1.1.1.5.cmml" xref="alg1.l17.m1.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l17.m1.1c">
        code
       </annotation>
      </semantics>
     </math>
    </div>
    <div class="ltx_listingline" id="alg1.l18">
     <span class="ltx_tag ltx_tag_listingline">
      18:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l18.1">
      else
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l19">
     <span class="ltx_tag ltx_tag_listingline">
      19:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l19.1">
      for
     </span>
     <math alttext="j\leftarrow 1" class="ltx_Math" display="inline" id="alg1.l19.m1.1">
      <semantics id="alg1.l19.m1.1a">
       <mrow id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml">
        <mi id="alg1.l19.m1.1.1.2" xref="alg1.l19.m1.1.1.2.cmml">
         j
        </mi>
        <mo id="alg1.l19.m1.1.1.1" stretchy="false" xref="alg1.l19.m1.1.1.1.cmml">
         ←
        </mo>
        <mn id="alg1.l19.m1.1.1.3" xref="alg1.l19.m1.1.1.3.cmml">
         1
        </mn>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b">
        <apply id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1">
         <ci id="alg1.l19.m1.1.1.1.cmml" xref="alg1.l19.m1.1.1.1">
          ←
         </ci>
         <ci id="alg1.l19.m1.1.1.2.cmml" xref="alg1.l19.m1.1.1.2">
          𝑗
         </ci>
         <cn id="alg1.l19.m1.1.1.3.cmml" type="integer" xref="alg1.l19.m1.1.1.3">
          1
         </cn>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l19.m1.1c">
        j\leftarrow 1
       </annotation>
      </semantics>
     </math>
     to
     <math alttext="t" class="ltx_Math" display="inline" id="alg1.l19.m2.1">
      <semantics id="alg1.l19.m2.1a">
       <mi id="alg1.l19.m2.1.1" xref="alg1.l19.m2.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="alg1.l19.m2.1b">
        <ci id="alg1.l19.m2.1.1.cmml" xref="alg1.l19.m2.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l19.m2.1c">
        t
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_bold" id="alg1.l19.2">
      do
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l20">
     <span class="ltx_tag ltx_tag_listingline">
      20:
     </span>
     <math alttext="code\leftarrow" class="ltx_Math" display="inline" id="alg1.l20.m1.1">
      <semantics id="alg1.l20.m1.1a">
       <mrow id="alg1.l20.m1.1.1" xref="alg1.l20.m1.1.1.cmml">
        <mrow id="alg1.l20.m1.1.1.2" xref="alg1.l20.m1.1.1.2.cmml">
         <mi id="alg1.l20.m1.1.1.2.2" xref="alg1.l20.m1.1.1.2.2.cmml">
          c
         </mi>
         <mo id="alg1.l20.m1.1.1.2.1" lspace="0em" rspace="0em" xref="alg1.l20.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l20.m1.1.1.2.3" xref="alg1.l20.m1.1.1.2.3.cmml">
          o
         </mi>
         <mo id="alg1.l20.m1.1.1.2.1a" lspace="0em" rspace="0em" xref="alg1.l20.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l20.m1.1.1.2.4" xref="alg1.l20.m1.1.1.2.4.cmml">
          d
         </mi>
         <mo id="alg1.l20.m1.1.1.2.1b" lspace="0em" rspace="0em" xref="alg1.l20.m1.1.1.2.1.cmml">
          ​
         </mo>
         <mi id="alg1.l20.m1.1.1.2.5" xref="alg1.l20.m1.1.1.2.5.cmml">
          e
         </mi>
        </mrow>
        <mo id="alg1.l20.m1.1.1.1" stretchy="false" xref="alg1.l20.m1.1.1.1.cmml">
         ←
        </mo>
        <mi id="alg1.l20.m1.1.1.3" xref="alg1.l20.m1.1.1.3.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l20.m1.1b">
        <apply id="alg1.l20.m1.1.1.cmml" xref="alg1.l20.m1.1.1">
         <ci id="alg1.l20.m1.1.1.1.cmml" xref="alg1.l20.m1.1.1.1">
          ←
         </ci>
         <apply id="alg1.l20.m1.1.1.2.cmml" xref="alg1.l20.m1.1.1.2">
          <times id="alg1.l20.m1.1.1.2.1.cmml" xref="alg1.l20.m1.1.1.2.1">
          </times>
          <ci id="alg1.l20.m1.1.1.2.2.cmml" xref="alg1.l20.m1.1.1.2.2">
           𝑐
          </ci>
          <ci id="alg1.l20.m1.1.1.2.3.cmml" xref="alg1.l20.m1.1.1.2.3">
           𝑜
          </ci>
          <ci id="alg1.l20.m1.1.1.2.4.cmml" xref="alg1.l20.m1.1.1.2.4">
           𝑑
          </ci>
          <ci id="alg1.l20.m1.1.1.2.5.cmml" xref="alg1.l20.m1.1.1.2.5">
           𝑒
          </ci>
         </apply>
         <csymbol cd="latexml" id="alg1.l20.m1.1.1.3.cmml" xref="alg1.l20.m1.1.1.3">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l20.m1.1c">
        code\leftarrow
       </annotation>
      </semantics>
     </math>
     DebuggingAgent(
     <math alttext="code" class="ltx_Math" display="inline" id="alg1.l20.m2.1">
      <semantics id="alg1.l20.m2.1a">
       <mrow id="alg1.l20.m2.1.1" xref="alg1.l20.m2.1.1.cmml">
        <mi id="alg1.l20.m2.1.1.2" xref="alg1.l20.m2.1.1.2.cmml">
         c
        </mi>
        <mo id="alg1.l20.m2.1.1.1" lspace="0em" rspace="0em" xref="alg1.l20.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l20.m2.1.1.3" xref="alg1.l20.m2.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l20.m2.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l20.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l20.m2.1.1.4" xref="alg1.l20.m2.1.1.4.cmml">
         d
        </mi>
        <mo id="alg1.l20.m2.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l20.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l20.m2.1.1.5" xref="alg1.l20.m2.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l20.m2.1b">
        <apply id="alg1.l20.m2.1.1.cmml" xref="alg1.l20.m2.1.1">
         <times id="alg1.l20.m2.1.1.1.cmml" xref="alg1.l20.m2.1.1.1">
         </times>
         <ci id="alg1.l20.m2.1.1.2.cmml" xref="alg1.l20.m2.1.1.2">
          𝑐
         </ci>
         <ci id="alg1.l20.m2.1.1.3.cmml" xref="alg1.l20.m2.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l20.m2.1.1.4.cmml" xref="alg1.l20.m2.1.1.4">
          𝑑
         </ci>
         <ci id="alg1.l20.m2.1.1.5.cmml" xref="alg1.l20.m2.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l20.m2.1c">
        code
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="log" class="ltx_Math" display="inline" id="alg1.l20.m3.1">
      <semantics id="alg1.l20.m3.1a">
       <mrow id="alg1.l20.m3.1.1" xref="alg1.l20.m3.1.1.cmml">
        <mi id="alg1.l20.m3.1.1.2" xref="alg1.l20.m3.1.1.2.cmml">
         l
        </mi>
        <mo id="alg1.l20.m3.1.1.1" lspace="0em" rspace="0em" xref="alg1.l20.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l20.m3.1.1.3" xref="alg1.l20.m3.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l20.m3.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l20.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l20.m3.1.1.4" xref="alg1.l20.m3.1.1.4.cmml">
         g
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l20.m3.1b">
        <apply id="alg1.l20.m3.1.1.cmml" xref="alg1.l20.m3.1.1">
         <times id="alg1.l20.m3.1.1.1.cmml" xref="alg1.l20.m3.1.1.1">
         </times>
         <ci id="alg1.l20.m3.1.1.2.cmml" xref="alg1.l20.m3.1.1.2">
          𝑙
         </ci>
         <ci id="alg1.l20.m3.1.1.3.cmml" xref="alg1.l20.m3.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l20.m3.1.1.4.cmml" xref="alg1.l20.m3.1.1.4">
          𝑔
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l20.m3.1c">
        log
       </annotation>
      </semantics>
     </math>
     )
    </div>
    <div class="ltx_listingline" id="alg1.l21">
     <span class="ltx_tag ltx_tag_listingline">
      21:
     </span>
     <math alttext="passed,log\leftarrow" class="ltx_Math" display="inline" id="alg1.l21.m1.2">
      <semantics id="alg1.l21.m1.2a">
       <mrow id="alg1.l21.m1.2.2" xref="alg1.l21.m1.2.2.cmml">
        <mrow id="alg1.l21.m1.2.2.2.2" xref="alg1.l21.m1.2.2.2.3.cmml">
         <mrow id="alg1.l21.m1.1.1.1.1.1" xref="alg1.l21.m1.1.1.1.1.1.cmml">
          <mi id="alg1.l21.m1.1.1.1.1.1.2" xref="alg1.l21.m1.1.1.1.1.1.2.cmml">
           p
          </mi>
          <mo id="alg1.l21.m1.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l21.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l21.m1.1.1.1.1.1.3" xref="alg1.l21.m1.1.1.1.1.1.3.cmml">
           a
          </mi>
          <mo id="alg1.l21.m1.1.1.1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l21.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l21.m1.1.1.1.1.1.4" xref="alg1.l21.m1.1.1.1.1.1.4.cmml">
           s
          </mi>
          <mo id="alg1.l21.m1.1.1.1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l21.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l21.m1.1.1.1.1.1.5" xref="alg1.l21.m1.1.1.1.1.1.5.cmml">
           s
          </mi>
          <mo id="alg1.l21.m1.1.1.1.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l21.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l21.m1.1.1.1.1.1.6" xref="alg1.l21.m1.1.1.1.1.1.6.cmml">
           e
          </mi>
          <mo id="alg1.l21.m1.1.1.1.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l21.m1.1.1.1.1.1.1.cmml">
           ​
          </mo>
          <mi id="alg1.l21.m1.1.1.1.1.1.7" xref="alg1.l21.m1.1.1.1.1.1.7.cmml">
           d
          </mi>
         </mrow>
         <mo id="alg1.l21.m1.2.2.2.2.3" xref="alg1.l21.m1.2.2.2.3.cmml">
          ,
         </mo>
         <mrow id="alg1.l21.m1.2.2.2.2.2" xref="alg1.l21.m1.2.2.2.2.2.cmml">
          <mi id="alg1.l21.m1.2.2.2.2.2.2" xref="alg1.l21.m1.2.2.2.2.2.2.cmml">
           l
          </mi>
          <mo id="alg1.l21.m1.2.2.2.2.2.1" lspace="0em" rspace="0em" xref="alg1.l21.m1.2.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="alg1.l21.m1.2.2.2.2.2.3" xref="alg1.l21.m1.2.2.2.2.2.3.cmml">
           o
          </mi>
          <mo id="alg1.l21.m1.2.2.2.2.2.1a" lspace="0em" rspace="0em" xref="alg1.l21.m1.2.2.2.2.2.1.cmml">
           ​
          </mo>
          <mi id="alg1.l21.m1.2.2.2.2.2.4" xref="alg1.l21.m1.2.2.2.2.2.4.cmml">
           g
          </mi>
         </mrow>
        </mrow>
        <mo id="alg1.l21.m1.2.2.3" stretchy="false" xref="alg1.l21.m1.2.2.3.cmml">
         ←
        </mo>
        <mi id="alg1.l21.m1.2.2.4" xref="alg1.l21.m1.2.2.4.cmml">
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l21.m1.2b">
        <apply id="alg1.l21.m1.2.2.cmml" xref="alg1.l21.m1.2.2">
         <ci id="alg1.l21.m1.2.2.3.cmml" xref="alg1.l21.m1.2.2.3">
          ←
         </ci>
         <list id="alg1.l21.m1.2.2.2.3.cmml" xref="alg1.l21.m1.2.2.2.2">
          <apply id="alg1.l21.m1.1.1.1.1.1.cmml" xref="alg1.l21.m1.1.1.1.1.1">
           <times id="alg1.l21.m1.1.1.1.1.1.1.cmml" xref="alg1.l21.m1.1.1.1.1.1.1">
           </times>
           <ci id="alg1.l21.m1.1.1.1.1.1.2.cmml" xref="alg1.l21.m1.1.1.1.1.1.2">
            𝑝
           </ci>
           <ci id="alg1.l21.m1.1.1.1.1.1.3.cmml" xref="alg1.l21.m1.1.1.1.1.1.3">
            𝑎
           </ci>
           <ci id="alg1.l21.m1.1.1.1.1.1.4.cmml" xref="alg1.l21.m1.1.1.1.1.1.4">
            𝑠
           </ci>
           <ci id="alg1.l21.m1.1.1.1.1.1.5.cmml" xref="alg1.l21.m1.1.1.1.1.1.5">
            𝑠
           </ci>
           <ci id="alg1.l21.m1.1.1.1.1.1.6.cmml" xref="alg1.l21.m1.1.1.1.1.1.6">
            𝑒
           </ci>
           <ci id="alg1.l21.m1.1.1.1.1.1.7.cmml" xref="alg1.l21.m1.1.1.1.1.1.7">
            𝑑
           </ci>
          </apply>
          <apply id="alg1.l21.m1.2.2.2.2.2.cmml" xref="alg1.l21.m1.2.2.2.2.2">
           <times id="alg1.l21.m1.2.2.2.2.2.1.cmml" xref="alg1.l21.m1.2.2.2.2.2.1">
           </times>
           <ci id="alg1.l21.m1.2.2.2.2.2.2.cmml" xref="alg1.l21.m1.2.2.2.2.2.2">
            𝑙
           </ci>
           <ci id="alg1.l21.m1.2.2.2.2.2.3.cmml" xref="alg1.l21.m1.2.2.2.2.2.3">
            𝑜
           </ci>
           <ci id="alg1.l21.m1.2.2.2.2.2.4.cmml" xref="alg1.l21.m1.2.2.2.2.2.4">
            𝑔
           </ci>
          </apply>
         </list>
         <csymbol cd="latexml" id="alg1.l21.m1.2.2.4.cmml" xref="alg1.l21.m1.2.2.4">
          absent
         </csymbol>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l21.m1.2c">
        passed,log\leftarrow
       </annotation>
      </semantics>
     </math>
     test(
     <math alttext="code" class="ltx_Math" display="inline" id="alg1.l21.m2.1">
      <semantics id="alg1.l21.m2.1a">
       <mrow id="alg1.l21.m2.1.1" xref="alg1.l21.m2.1.1.cmml">
        <mi id="alg1.l21.m2.1.1.2" xref="alg1.l21.m2.1.1.2.cmml">
         c
        </mi>
        <mo id="alg1.l21.m2.1.1.1" lspace="0em" rspace="0em" xref="alg1.l21.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m2.1.1.3" xref="alg1.l21.m2.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l21.m2.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l21.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m2.1.1.4" xref="alg1.l21.m2.1.1.4.cmml">
         d
        </mi>
        <mo id="alg1.l21.m2.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l21.m2.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m2.1.1.5" xref="alg1.l21.m2.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l21.m2.1b">
        <apply id="alg1.l21.m2.1.1.cmml" xref="alg1.l21.m2.1.1">
         <times id="alg1.l21.m2.1.1.1.cmml" xref="alg1.l21.m2.1.1.1">
         </times>
         <ci id="alg1.l21.m2.1.1.2.cmml" xref="alg1.l21.m2.1.1.2">
          𝑐
         </ci>
         <ci id="alg1.l21.m2.1.1.3.cmml" xref="alg1.l21.m2.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l21.m2.1.1.4.cmml" xref="alg1.l21.m2.1.1.4">
          𝑑
         </ci>
         <ci id="alg1.l21.m2.1.1.5.cmml" xref="alg1.l21.m2.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l21.m2.1c">
        code
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="sample\_io" class="ltx_Math" display="inline" id="alg1.l21.m3.1">
      <semantics id="alg1.l21.m3.1a">
       <mrow id="alg1.l21.m3.1.1" xref="alg1.l21.m3.1.1.cmml">
        <mi id="alg1.l21.m3.1.1.2" xref="alg1.l21.m3.1.1.2.cmml">
         s
        </mi>
        <mo id="alg1.l21.m3.1.1.1" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.3" xref="alg1.l21.m3.1.1.3.cmml">
         a
        </mi>
        <mo id="alg1.l21.m3.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.4" xref="alg1.l21.m3.1.1.4.cmml">
         m
        </mi>
        <mo id="alg1.l21.m3.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.5" xref="alg1.l21.m3.1.1.5.cmml">
         p
        </mi>
        <mo id="alg1.l21.m3.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.6" xref="alg1.l21.m3.1.1.6.cmml">
         l
        </mi>
        <mo id="alg1.l21.m3.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.7" xref="alg1.l21.m3.1.1.7.cmml">
         e
        </mi>
        <mo id="alg1.l21.m3.1.1.1e" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.8" mathvariant="normal" xref="alg1.l21.m3.1.1.8.cmml">
         _
        </mi>
        <mo id="alg1.l21.m3.1.1.1f" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.9" xref="alg1.l21.m3.1.1.9.cmml">
         i
        </mi>
        <mo id="alg1.l21.m3.1.1.1g" lspace="0em" rspace="0em" xref="alg1.l21.m3.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l21.m3.1.1.10" xref="alg1.l21.m3.1.1.10.cmml">
         o
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l21.m3.1b">
        <apply id="alg1.l21.m3.1.1.cmml" xref="alg1.l21.m3.1.1">
         <times id="alg1.l21.m3.1.1.1.cmml" xref="alg1.l21.m3.1.1.1">
         </times>
         <ci id="alg1.l21.m3.1.1.2.cmml" xref="alg1.l21.m3.1.1.2">
          𝑠
         </ci>
         <ci id="alg1.l21.m3.1.1.3.cmml" xref="alg1.l21.m3.1.1.3">
          𝑎
         </ci>
         <ci id="alg1.l21.m3.1.1.4.cmml" xref="alg1.l21.m3.1.1.4">
          𝑚
         </ci>
         <ci id="alg1.l21.m3.1.1.5.cmml" xref="alg1.l21.m3.1.1.5">
          𝑝
         </ci>
         <ci id="alg1.l21.m3.1.1.6.cmml" xref="alg1.l21.m3.1.1.6">
          𝑙
         </ci>
         <ci id="alg1.l21.m3.1.1.7.cmml" xref="alg1.l21.m3.1.1.7">
          𝑒
         </ci>
         <ci id="alg1.l21.m3.1.1.8.cmml" xref="alg1.l21.m3.1.1.8">
          _
         </ci>
         <ci id="alg1.l21.m3.1.1.9.cmml" xref="alg1.l21.m3.1.1.9">
          𝑖
         </ci>
         <ci id="alg1.l21.m3.1.1.10.cmml" xref="alg1.l21.m3.1.1.10">
          𝑜
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l21.m3.1c">
        sample\_io
       </annotation>
      </semantics>
     </math>
     )
    </div>
    <div class="ltx_listingline" id="alg1.l22">
     <span class="ltx_tag ltx_tag_listingline">
      22:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l22.1">
      if
     </span>
     <math alttext="passed" class="ltx_Math" display="inline" id="alg1.l22.m1.1">
      <semantics id="alg1.l22.m1.1a">
       <mrow id="alg1.l22.m1.1.1" xref="alg1.l22.m1.1.1.cmml">
        <mi id="alg1.l22.m1.1.1.2" xref="alg1.l22.m1.1.1.2.cmml">
         p
        </mi>
        <mo id="alg1.l22.m1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l22.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l22.m1.1.1.3" xref="alg1.l22.m1.1.1.3.cmml">
         a
        </mi>
        <mo id="alg1.l22.m1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l22.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l22.m1.1.1.4" xref="alg1.l22.m1.1.1.4.cmml">
         s
        </mi>
        <mo id="alg1.l22.m1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l22.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l22.m1.1.1.5" xref="alg1.l22.m1.1.1.5.cmml">
         s
        </mi>
        <mo id="alg1.l22.m1.1.1.1c" lspace="0em" rspace="0em" xref="alg1.l22.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l22.m1.1.1.6" xref="alg1.l22.m1.1.1.6.cmml">
         e
        </mi>
        <mo id="alg1.l22.m1.1.1.1d" lspace="0em" rspace="0em" xref="alg1.l22.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l22.m1.1.1.7" xref="alg1.l22.m1.1.1.7.cmml">
         d
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l22.m1.1b">
        <apply id="alg1.l22.m1.1.1.cmml" xref="alg1.l22.m1.1.1">
         <times id="alg1.l22.m1.1.1.1.cmml" xref="alg1.l22.m1.1.1.1">
         </times>
         <ci id="alg1.l22.m1.1.1.2.cmml" xref="alg1.l22.m1.1.1.2">
          𝑝
         </ci>
         <ci id="alg1.l22.m1.1.1.3.cmml" xref="alg1.l22.m1.1.1.3">
          𝑎
         </ci>
         <ci id="alg1.l22.m1.1.1.4.cmml" xref="alg1.l22.m1.1.1.4">
          𝑠
         </ci>
         <ci id="alg1.l22.m1.1.1.5.cmml" xref="alg1.l22.m1.1.1.5">
          𝑠
         </ci>
         <ci id="alg1.l22.m1.1.1.6.cmml" xref="alg1.l22.m1.1.1.6">
          𝑒
         </ci>
         <ci id="alg1.l22.m1.1.1.7.cmml" xref="alg1.l22.m1.1.1.7">
          𝑑
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l22.m1.1c">
        passed
       </annotation>
      </semantics>
     </math>
     <span class="ltx_text ltx_font_bold" id="alg1.l22.2">
      then
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l23">
     <span class="ltx_tag ltx_tag_listingline">
      23:
     </span>
     Return
     <math alttext="code" class="ltx_Math" display="inline" id="alg1.l23.m1.1">
      <semantics id="alg1.l23.m1.1a">
       <mrow id="alg1.l23.m1.1.1" xref="alg1.l23.m1.1.1.cmml">
        <mi id="alg1.l23.m1.1.1.2" xref="alg1.l23.m1.1.1.2.cmml">
         c
        </mi>
        <mo id="alg1.l23.m1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l23.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l23.m1.1.1.3" xref="alg1.l23.m1.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l23.m1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l23.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l23.m1.1.1.4" xref="alg1.l23.m1.1.1.4.cmml">
         d
        </mi>
        <mo id="alg1.l23.m1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l23.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l23.m1.1.1.5" xref="alg1.l23.m1.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l23.m1.1b">
        <apply id="alg1.l23.m1.1.1.cmml" xref="alg1.l23.m1.1.1">
         <times id="alg1.l23.m1.1.1.1.cmml" xref="alg1.l23.m1.1.1.1">
         </times>
         <ci id="alg1.l23.m1.1.1.2.cmml" xref="alg1.l23.m1.1.1.2">
          𝑐
         </ci>
         <ci id="alg1.l23.m1.1.1.3.cmml" xref="alg1.l23.m1.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l23.m1.1.1.4.cmml" xref="alg1.l23.m1.1.1.4">
          𝑑
         </ci>
         <ci id="alg1.l23.m1.1.1.5.cmml" xref="alg1.l23.m1.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l23.m1.1c">
        code
       </annotation>
      </semantics>
     </math>
    </div>
    <div class="ltx_listingline" id="alg1.l24">
     <span class="ltx_tag ltx_tag_listingline">
      24:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l24.1">
      end
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l24.2">
      if
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l25">
     <span class="ltx_tag ltx_tag_listingline">
      25:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l25.1">
      end
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l25.2">
      for
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l26">
     <span class="ltx_tag ltx_tag_listingline">
      26:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l26.1">
      end
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l26.2">
      if
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l27">
     <span class="ltx_tag ltx_tag_listingline">
      27:
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l27.1">
      end
     </span>
     <span class="ltx_text ltx_font_bold" id="alg1.l27.2">
      for
     </span>
    </div>
    <div class="ltx_listingline" id="alg1.l28">
     <span class="ltx_tag ltx_tag_listingline">
      28:
     </span>
     Return
     <math alttext="code" class="ltx_Math" display="inline" id="alg1.l28.m1.1">
      <semantics id="alg1.l28.m1.1a">
       <mrow id="alg1.l28.m1.1.1" xref="alg1.l28.m1.1.1.cmml">
        <mi id="alg1.l28.m1.1.1.2" xref="alg1.l28.m1.1.1.2.cmml">
         c
        </mi>
        <mo id="alg1.l28.m1.1.1.1" lspace="0em" rspace="0em" xref="alg1.l28.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l28.m1.1.1.3" xref="alg1.l28.m1.1.1.3.cmml">
         o
        </mi>
        <mo id="alg1.l28.m1.1.1.1a" lspace="0em" rspace="0em" xref="alg1.l28.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l28.m1.1.1.4" xref="alg1.l28.m1.1.1.4.cmml">
         d
        </mi>
        <mo id="alg1.l28.m1.1.1.1b" lspace="0em" rspace="0em" xref="alg1.l28.m1.1.1.1.cmml">
         ​
        </mo>
        <mi id="alg1.l28.m1.1.1.5" xref="alg1.l28.m1.1.1.5.cmml">
         e
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="alg1.l28.m1.1b">
        <apply id="alg1.l28.m1.1.1.cmml" xref="alg1.l28.m1.1.1">
         <times id="alg1.l28.m1.1.1.1.cmml" xref="alg1.l28.m1.1.1.1">
         </times>
         <ci id="alg1.l28.m1.1.1.2.cmml" xref="alg1.l28.m1.1.1.2">
          𝑐
         </ci>
         <ci id="alg1.l28.m1.1.1.3.cmml" xref="alg1.l28.m1.1.1.3">
          𝑜
         </ci>
         <ci id="alg1.l28.m1.1.1.4.cmml" xref="alg1.l28.m1.1.1.4">
          𝑑
         </ci>
         <ci id="alg1.l28.m1.1.1.5.cmml" xref="alg1.l28.m1.1.1.5">
          𝑒
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="alg1.l28.m1.1c">
        code
       </annotation>
      </semantics>
     </math>
    </div>
   </div>
  </figure>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Details Promptings of
   <span class="ltx_text ltx_font_typewriter" id="A2.1.1">
    MapCoder
   </span>
  </h2>
  <div class="ltx_para" id="A2.p1">
   <p class="ltx_p" id="A2.p1.1">
    The detailed prompting of the Retrieval Agent, Planning Agent, Coding Agent, and Debugging Agent are shown in Figure
    <a class="ltx_ref" href="#A3.F8" title="Figure 8 ‣ Appendix C Example Problem ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      8
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#A3.F9" title="Figure 9 ‣ Appendix C Example Problem ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      9
     </span>
    </a>
    , and
    <a class="ltx_ref" href="#A3.F10" title="Figure 10 ‣ Appendix C Example Problem ‣ MapCoder: Multi-Agent Code Generation for Competitive Problem Solving">
     <span class="ltx_text ltx_ref_tag">
      10
     </span>
    </a>
    respectively. Note that we adopt a specific sequence of instructions in the prompt for Retrieval Agent which is a crucial design choice.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Example Problem
  </h2>
  <div class="ltx_para" id="A3.p1">
   <p class="ltx_p" id="A3.p1.1">
    Two complete examples of how
    <span class="ltx_text ltx_font_typewriter" id="A3.p1.1.1">
     MapCoder
    </span>
    works by showing all the prompts and responses for all four agents is given in this
    <a class="ltx_ref ltx_href" href="https://github.com/Md-Ashraful-Pramanik/mapcoder.github.io/blob/master/files/example-prompt.pdf" target="_blank" title="">
     link
    </a>
    .
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
  <figure class="ltx_figure" id="A3.F8">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="262" id="A3.F8.g1" src="/html/2405.11403/assets/x13.png" width="456"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 8:
    </span>
    Prompt for self-retrieval Agent.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A3.F9">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="176" id="A3.F9.g1" src="/html/2405.11403/assets/x14.png" width="456"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 9:
    </span>
    Prompt for Planning Agent. The example problems that are mentioned in this figure will come from the Retrieval Agent.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A3.F10">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="155" id="A3.F10.g1" src="/html/2405.11403/assets/x15.png" width="456"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 10:
    </span>
    Prompt for Coding and Debugging Agent.
   </figcaption>
  </figure>
 </section>
</article>
