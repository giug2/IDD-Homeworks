<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.16065] A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective</title><meta property="og:description" content="Federated Learning (FL) has emerged as a powerful paradigm for training Machine Learning (ML), particularly Deep Learning (DL) models on multiple devices or servers while maintaining data localized at owners‚Äô sites. Wi‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.16065">

<!--Generated on Tue Feb 27 16:43:35 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xianghua Xie
</span><span class="ltx_author_notes">Corresponding Author: <a href="mailto:x.xie@swansea.ac.uk" title="" class="ltx_ref ltx_href">x.xie@swansea.ac.uk</a>
<span class="ltx_contact ltx_role_affiliation">Department of Computer Science, Swansea University, United Kingdom
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chen Hu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Computer Science, Swansea University, United Kingdom
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hanchi Ren
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Department of Computer Science, Swansea University, United Kingdom
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jingjing Deng
</span><span class="ltx_author_notes">Corresponding Author: <a href="mailto:jingjing.deng@durham.ac.uk" title="" class="ltx_ref ltx_href">jingjing.deng@durham.ac.uk</a>
<span class="ltx_contact ltx_role_affiliation">Department of Computer Science, Durham University, United Kingdom
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated Learning (FL) has emerged as a powerful paradigm for training Machine Learning (ML), particularly Deep Learning (DL) models on multiple devices or servers while maintaining data localized at owners‚Äô sites. Without centralizing data, FL holds promise for scenarios where data integrity, privacy and security and are critical. However, this decentralized training process also opens up new avenues for opponents to launch unique attacks, where it has been becoming an urgent need to understand the vulnerabilities and corresponding defense mechanisms from a learning algorithm perspective. This review paper takes a comprehensive look at malicious attacks against FL, categorizing them from new perspectives on attack origins and targets, and providing insights into their methodology and impact. In this survey, we focus on threat models targeting the learning process of FL systems. Based on the source and target of the attack, we categorize existing threat models into four types,  <span title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Data to Model</span></span> (<abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr>),  <span title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Model to Data</span></span> (<abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr>),  <span title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Model to Model</span></span> (<abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr>) and composite attacks. For each attack type, we discuss the defense strategies proposed, highlighting their effectiveness, assumptions and potential areas for improvement. Defense strategies have evolved from using a singular metric to excluding malicious clients, to employing a multifaceted approach examining client models at various phases. In this survey paper, our research indicates that the to-learn data, the learning gradients, and the learned model at different stages all can be manipulated to initiate malicious attacks that range from undermining model performance, reconstructing private local data, and to inserting backdoors. We have also seen these threat are becoming more insidious. While earlier studies typically amplified malicious gradients, recent endeavors subtly alter the least significant weights in local models to bypass defense measures. This literature review provides a holistic understanding of the current FL threat landscape and highlights the importance of developing robust, efficient, and privacy-preserving defenses to ensure the safe and trusted adoption of FL in real-world applications. The categorized bibliography can be found at: <a target="_blank" href="https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In the era of  <span title="Artifical Intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Artifical Intelligence</span></span> (<abbr title="Artifical Intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr>) that is built upon big data, the need to extract valuable insights from massive amounts of information is driving innovation across industries. Achievements of data-driven  <span title="Deep Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Deep Learning</span></span> (<abbr title="Deep Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DL</span></abbr>) models have been witnessed in many areas, ranging from  <span title="Natural Language Processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Natural Language Processing</span></span> (<abbr title="Natural Language Processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">NLP</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> to visual computing¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. It is generally agreed upon that the more training data, the greater potential performance of the model. To illustrate, the research work¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> claims if one were able to collect data from all medical facilities, models trained on such dataset would have the potential of ‚Äùanswering many significant questions‚Äù, such as drug discovery and predictive modeling of diseases. Data centralization scheme for training <abbr title="Artifical Intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">AI</span></abbr> model has been the predominant method for decades.
However, methods solely relying on centralized training scheme are becoming less viable, not only due to the cost of computational resources, but more importantly, the growing concerns related to privacy and security,
which has triggered the need for alternative learning paradigms.  <span title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Learning</span></span> (<abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, a distributed learning paradigm emerges as a pioneering solution to address these challenges, where multiple decentralized parties collaborate on a learning task while the data remains with its owner. In contrast to traditional approaches, where all data has to be centralized, <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> stemming from the increasing concerns on data privacy allows model to be trained at the source of data creation. This innovative approach not only minimizes the risk of data leakage, maintains the privacy of sensitive information, but also lifts the computational burden of cloud centers, which is considered as a potential alternative for completing multi-party learning in many domains, such as: healthcare¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, finance¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, smart cities¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and autonomous driving¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. We observed that there is a significant growth related to <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> in both academic research and industrial applications.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2311.16065/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="200" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An Overview of Common Vulnerabilities in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>. Malicious attackers can: (a) manipulate model updates to prevent the global model from converging; (b) tamper data labels to induce erroneous predictions after training; (c) inject backdoors into the global model; (d) reconstruct data or inference data properties by eavesdropping model updates; (e) steal the global model while contribute nothing.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recent studies on exploiting vulnerabilities of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>, have illuminated the fact that the robustness of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> architectures is not as secure as expected, where each building block in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> algorithms, ranging from its data distribution, communication mechanisms, to aggregation processes, is susceptible to malicious attacks¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. These vulnerabilities can potentially compromise the privacy and security of the participants, meanwhile downgrade the integrity and effectiveness of the entire learning system. Figure¬†<a href="#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates various common <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> attacks and provides a comprehensive overview on different stages and components in the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> that can be targeted by opponents. Specifically, a variety of tactics that a malicious attacker can employ, as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Data Tampering:</span> By disrupting data label or introducing sample noisy the adversary misguides the global model making inaccurate or biased predictions.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Model Manipulation:</span> By changing the model weight during aggregation, the attacker forces the global model to deviate from the desirable convergence. It can be a subtle change over time, or a drastic disruption that leads to significant performance degradation.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Data Reconstruction:</span> By exploring the gradient information or model weight, the opponent attempts to reconstruct or infer specific attributes of the original data, thereby breaching the privacy of data owner.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Backdoor Injection:</span> By embedding backdoor into the global model, the contestant deceives the trained model to give designated prediction when the corresponding trigger pattern in the input is presented.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Our proposed taxonomy</figcaption>
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.1.1" class="ltx_tr">
<td id="S1.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;"><span id="S1.T1.1.1.1.1" class="ltx_text ltx_font_bold">Type of Attack</span></td>
<td id="S1.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;"><span id="S1.T1.1.1.2.1" class="ltx_text ltx_font_bold">Definition</span></td>
<td id="S1.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;"><span id="S1.T1.1.1.3.1" class="ltx_text ltx_font_bold">Example</span></td>
</tr>
<tr id="S1.T1.1.2" class="ltx_tr">
<td id="S1.T1.1.2.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 5.0pt;">
<span id="S1.T1.1.2.1.1" class="ltx_text"></span> <span id="S1.T1.1.2.1.2" class="ltx_text">
<span id="S1.T1.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.2.1.2.1.1" class="ltx_tr">
<span id="S1.T1.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 5.0pt;">Data to Model (D2M)</span></span>
</span></span><span id="S1.T1.1.2.1.3" class="ltx_text"></span></td>
<td id="S1.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 5.0pt;">
<span id="S1.T1.1.2.2.1" class="ltx_text"></span> <span id="S1.T1.1.2.2.2" class="ltx_text">
<span id="S1.T1.1.2.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.2.2.2.1.1" class="ltx_tr">
<span id="S1.T1.1.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 5.0pt;">tampering the data alone to degrade model performance</span></span>
</span></span><span id="S1.T1.1.2.2.3" class="ltx_text"></span></td>
<td id="S1.T1.1.2.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 5.0pt;">label-flipping</td>
</tr>
<tr id="S1.T1.1.3" class="ltx_tr">
<td id="S1.T1.1.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;">
<span id="S1.T1.1.3.1.1" class="ltx_text"></span> <span id="S1.T1.1.3.1.2" class="ltx_text">
<span id="S1.T1.1.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.3.1.2.1.1" class="ltx_tr">
<span id="S1.T1.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 5.0pt;">Model to Model (M2M)</span></span>
</span></span><span id="S1.T1.1.3.1.3" class="ltx_text"></span></td>
<td id="S1.T1.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;">
<span id="S1.T1.1.3.2.1" class="ltx_text"></span> <span id="S1.T1.1.3.2.2" class="ltx_text">
<span id="S1.T1.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.3.2.2.1.1" class="ltx_tr">
<span id="S1.T1.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 5.0pt;">tampering updates to prevent learning convergence</span></span>
</span></span><span id="S1.T1.1.3.2.3" class="ltx_text"></span></td>
<td id="S1.T1.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;">Byzantine attack</td>
</tr>
<tr id="S1.T1.1.4" class="ltx_tr">
<td id="S1.T1.1.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;">
<span id="S1.T1.1.4.1.1" class="ltx_text"></span> <span id="S1.T1.1.4.1.2" class="ltx_text">
<span id="S1.T1.1.4.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.4.1.2.1.1" class="ltx_tr">
<span id="S1.T1.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 5.0pt;">Model to Data (M2D)</span></span>
</span></span><span id="S1.T1.1.4.1.3" class="ltx_text"></span></td>
<td id="S1.T1.1.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;">
<span id="S1.T1.1.4.2.1" class="ltx_text"></span> <span id="S1.T1.1.4.2.2" class="ltx_text">
<span id="S1.T1.1.4.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.4.2.2.1.1" class="ltx_tr">
<span id="S1.T1.1.4.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 5.0pt;">intercepting model updates to inference private data information</span></span>
</span></span><span id="S1.T1.1.4.2.3" class="ltx_text"></span></td>
<td id="S1.T1.1.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 5.0pt;">gradient leakage</td>
</tr>
<tr id="S1.T1.1.5" class="ltx_tr">
<td id="S1.T1.1.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:2.5pt 5.0pt;">Composite (D2M+M2M)</td>
<td id="S1.T1.1.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:2.5pt 5.0pt;">
<span id="S1.T1.1.5.2.1" class="ltx_text"></span> <span id="S1.T1.1.5.2.2" class="ltx_text">
<span id="S1.T1.1.5.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.5.2.2.1.1" class="ltx_tr">
<span id="S1.T1.1.5.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 5.0pt;">tampering both data and updates to manipulate model behavior</span></span>
</span></span><span id="S1.T1.1.5.2.3" class="ltx_text"></span></td>
<td id="S1.T1.1.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:2.5pt 5.0pt;">backdoor injection</td>
</tr>
</table>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Despite the promising future of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> aimed at alleviating privacy concerns, <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> still faces a wide variety of threats. In contrast to reviewing <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> from system and network security perspectives, in this survey, we focus on retrospecting the research advancements of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> vulnerability that is inherited from the nature of machine learning algorithms. As shown in Figure¬†<a href="#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we identify that a malicious attacker can attack every component in the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> system. For example, an opponent may masquerade as a participating client of the system and provide toxic data to degrade the prediction performance of the global model, or intercept client updates and inject backdoor or reconstruct private training data.
In this paper, we propose a taxonomy of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> attacks centered around attack origins and attack targets, which are outlined in Table¬†<a href="#S1.T1" title="Table 1 ‚Ä£ 1 Introduction ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Our taxonomy of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> attacks emphasizes exploited vulnerabilities and their direct victims. For instance, label-flipping is a typical <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attack, often described as a data poisoning technique. If the local data is tampered by such a designated attack, the trained global model can be compromised by such training data and exhibit anomalous behavior.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The rest of survey is organized as such: In Section 2, we firstly introduce the essential preliminaries of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> algorithm. Then, following the proposed taxonomy, we review each type of attack, including <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> Attack, <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> Attack, <abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> Attack and Composite Attack in Section 3, 4, 5 and 6 respectively. Within each section, both threat models and the corresponding defense strategies are presented, compared and discussed. Section 7 concludes our findings and provides our recommendation for future research directions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminaries of Federated Learning</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.4" class="ltx_p"><abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> can be categorized into horizontal FL, vertical FL, and federated transfer learning, based on how the training data is organized <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Since the majority of research on FL vulnerabilities focuses on the horizontal FL setting, therefore, we also focus on horizontal FL as the central topic in this review. FedAvg is the most classic horizontal <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> algorithm, where the global model is learned by averaging across all local models trained on clients. Surprisingly, such a simple aggregation scheme has been proven to be effective in many case studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, where the convergence is also mathematically sound¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Improvements upon FedAvg include incorporating local update corrections <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> or adaptive weighting schemes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, however, the fundamental aggregation scheme remains similar. Therefore, we present FedAvg¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> as an example to demonstrate the potential components in FL system that can be targeted by malicious parties. Firstly, all clients receive the identical global model <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\omega_{0}" display="inline"><semantics id="S2.p1.1.m1.1a"><msub id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">œâ</mi><mn id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">ùúî</ci><cn type="integer" id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\omega_{0}</annotation></semantics></math> from the central server that is randomly initialized. Then, the local model is trained on each client with its local data. Once the local training steps finish (i.e., the number of pre-set iteration or epoch is reached), individual clients send either the updated local model <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="\omega_{E}" display="inline"><semantics id="S2.p1.2.m2.1a"><msub id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">œâ</mi><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">E</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">ùúî</ci><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">ùê∏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\omega_{E}</annotation></semantics></math> or the model difference <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S2.p1.3.m3.1a"><mi id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">u</annotation></semantics></math> to the server. The central server aggregates the global model <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="\omega_{r}" display="inline"><semantics id="S2.p1.4.m4.1a"><msub id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">œâ</mi><mi id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">ùúî</ci><ci id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">\omega_{r}</annotation></semantics></math> by averaging the local models, and send the updated model to each client. To speed up the training, a subset of clients are chosen randomly for the current round of training, which is also considered as a dropout regularization for FL. The pseudo code of original FedAvg algorithm is given in Algorithm¬†<a href="#alg1" title="Algorithm 1 ‚Ä£ 2 Preliminaries of Federated Learning ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, where the terms highlighted indicate the entities that can be compromised.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The comparison between surveys on <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> attacks and defenses is summarized in Table <a href="#S2.T2" title="Table 2 ‚Ä£ 2 Preliminaries of Federated Learning ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. While most surveys include detailed discussion on defense strategies, some of them only give high-level overviews on threat models, such as explaining the concept of Byzantine attacks (M2M) without delving into diverse attacks as we summarized in Table <a href="#S4.T4" title="Table 4 ‚Ä£ 4 Model to Model Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Our work reviews <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> vulnerabilities from the perspective of learning algorithms. Our review includes major threat models that exploits the learning paradigm of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> and discusses defense strategies to counter these threats.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of Related Surveys on Federated Learning Attacks and Defenses</figcaption>
<table id="S2.T2.42" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T2.42.43" class="ltx_tr">
<td id="S2.T2.42.43.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;" rowspan="3"><span id="S2.T2.42.43.1.1" class="ltx_text">Surveys</span></td>
<td id="S2.T2.42.43.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="8">Federated Learning Attacks and Defenses</td>
</tr>
<tr id="S2.T2.42.44" class="ltx_tr">
<td id="S2.T2.42.44.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="2">D2M</td>
<td id="S2.T2.42.44.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="2">M2M</td>
<td id="S2.T2.42.44.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="2">M2D</td>
<td id="S2.T2.42.44.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="2">Composite</td>
</tr>
<tr id="S2.T2.42.45" class="ltx_tr">
<td id="S2.T2.42.45.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Threat</td>
<td id="S2.T2.42.45.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Defense</td>
<td id="S2.T2.42.45.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Threat</td>
<td id="S2.T2.42.45.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Defense</td>
<td id="S2.T2.42.45.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Threat</td>
<td id="S2.T2.42.45.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Defense</td>
<td id="S2.T2.42.45.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Threat</td>
<td id="S2.T2.42.45.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Defense</td>
</tr>
<tr id="S2.T2.6.6" class="ltx_tr">
<td id="S2.T2.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">Kairouz et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S2.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.1.1.1.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.1.1.1.m1.1a"><mo id="S2.T2.1.1.1.m1.1.1" xref="S2.T2.1.1.1.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.m1.1b"><compose id="S2.T2.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.2.2.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.2.2.2.m1.1a"><mi mathvariant="normal" id="S2.T2.2.2.2.m1.1.1" xref="S2.T2.2.2.2.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.2.m1.1b"><ci id="S2.T2.2.2.2.m1.1.1.cmml" xref="S2.T2.2.2.2.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.3.3.3.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.3.3.3.m1.1a"><mo id="S2.T2.3.3.3.m1.1.1" xref="S2.T2.3.3.3.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.3.m1.1b"><compose id="S2.T2.3.3.3.m1.1.1.cmml" xref="S2.T2.3.3.3.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.3.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.4.4.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.4.4.4.m1.1a"><mi mathvariant="normal" id="S2.T2.4.4.4.m1.1.1" xref="S2.T2.4.4.4.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.4.4.4.m1.1b"><ci id="S2.T2.4.4.4.m1.1.1.cmml" xref="S2.T2.4.4.4.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.4.4.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.6.6.8" class="ltx_td ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.6.6.9" class="ltx_td ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.5.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.5.5.5.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.5.5.5.m1.1a"><mo id="S2.T2.5.5.5.m1.1.1" xref="S2.T2.5.5.5.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.5.5.5.m1.1b"><compose id="S2.T2.5.5.5.m1.1.1.cmml" xref="S2.T2.5.5.5.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.5.5.5.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.6.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.6.6.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.6.6.6.m1.1a"><mi mathvariant="normal" id="S2.T2.6.6.6.m1.1.1" xref="S2.T2.6.6.6.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.6.6.6.m1.1b"><ci id="S2.T2.6.6.6.m1.1.1.cmml" xref="S2.T2.6.6.6.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.6.6.6.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T2.12.12" class="ltx_tr">
<td id="S2.T2.12.12.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">Nguyen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S2.T2.7.7.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.7.7.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.7.7.1.m1.1a"><mi mathvariant="normal" id="S2.T2.7.7.1.m1.1.1" xref="S2.T2.7.7.1.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.7.7.1.m1.1b"><ci id="S2.T2.7.7.1.m1.1.1.cmml" xref="S2.T2.7.7.1.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.7.7.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.8.8.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.8.8.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.8.8.2.m1.1a"><mi mathvariant="normal" id="S2.T2.8.8.2.m1.1.1" xref="S2.T2.8.8.2.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.8.8.2.m1.1b"><ci id="S2.T2.8.8.2.m1.1.1.cmml" xref="S2.T2.8.8.2.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.8.8.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.9.9.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.9.9.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.9.9.3.m1.1a"><mi mathvariant="normal" id="S2.T2.9.9.3.m1.1.1" xref="S2.T2.9.9.3.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.9.9.3.m1.1b"><ci id="S2.T2.9.9.3.m1.1.1.cmml" xref="S2.T2.9.9.3.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.9.9.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.10.10.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.10.10.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.10.10.4.m1.1a"><mi mathvariant="normal" id="S2.T2.10.10.4.m1.1.1" xref="S2.T2.10.10.4.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.10.10.4.m1.1b"><ci id="S2.T2.10.10.4.m1.1.1.cmml" xref="S2.T2.10.10.4.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.10.10.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.12.12.8" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.12.12.9" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.11.11.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.11.11.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.11.11.5.m1.1a"><mi mathvariant="normal" id="S2.T2.11.11.5.m1.1.1" xref="S2.T2.11.11.5.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.11.11.5.m1.1b"><ci id="S2.T2.11.11.5.m1.1.1.cmml" xref="S2.T2.11.11.5.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.11.11.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.12.12.6" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.12.12.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.12.12.6.m1.1a"><mi mathvariant="normal" id="S2.T2.12.12.6.m1.1.1" xref="S2.T2.12.12.6.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.12.12.6.m1.1b"><ci id="S2.T2.12.12.6.m1.1.1.cmml" xref="S2.T2.12.12.6.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.12.12.6.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T2.20.20" class="ltx_tr">
<td id="S2.T2.20.20.9" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>
</td>
<td id="S2.T2.13.13.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.13.13.1.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.13.13.1.m1.1a"><mo id="S2.T2.13.13.1.m1.1.1" xref="S2.T2.13.13.1.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.13.13.1.m1.1b"><compose id="S2.T2.13.13.1.m1.1.1.cmml" xref="S2.T2.13.13.1.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.13.13.1.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.14.14.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.14.14.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.14.14.2.m1.1a"><mi mathvariant="normal" id="S2.T2.14.14.2.m1.1.1" xref="S2.T2.14.14.2.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.14.14.2.m1.1b"><ci id="S2.T2.14.14.2.m1.1.1.cmml" xref="S2.T2.14.14.2.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.14.14.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.15.15.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.15.15.3.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.15.15.3.m1.1a"><mo id="S2.T2.15.15.3.m1.1.1" xref="S2.T2.15.15.3.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.15.15.3.m1.1b"><compose id="S2.T2.15.15.3.m1.1.1.cmml" xref="S2.T2.15.15.3.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.15.15.3.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.16.16.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.16.16.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.16.16.4.m1.1a"><mi mathvariant="normal" id="S2.T2.16.16.4.m1.1.1" xref="S2.T2.16.16.4.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.16.16.4.m1.1b"><ci id="S2.T2.16.16.4.m1.1.1.cmml" xref="S2.T2.16.16.4.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.16.16.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.17.17.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.17.17.5.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.17.17.5.m1.1a"><mo id="S2.T2.17.17.5.m1.1.1" xref="S2.T2.17.17.5.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.17.17.5.m1.1b"><compose id="S2.T2.17.17.5.m1.1.1.cmml" xref="S2.T2.17.17.5.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.17.17.5.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.18.18.6" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.18.18.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.18.18.6.m1.1a"><mi mathvariant="normal" id="S2.T2.18.18.6.m1.1.1" xref="S2.T2.18.18.6.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.18.18.6.m1.1b"><ci id="S2.T2.18.18.6.m1.1.1.cmml" xref="S2.T2.18.18.6.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.18.18.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.19.19.7" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.19.19.7.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.19.19.7.m1.1a"><mo id="S2.T2.19.19.7.m1.1.1" xref="S2.T2.19.19.7.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.19.19.7.m1.1b"><compose id="S2.T2.19.19.7.m1.1.1.cmml" xref="S2.T2.19.19.7.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.19.19.7.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.20.20.8" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.20.20.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.20.20.8.m1.1a"><mi mathvariant="normal" id="S2.T2.20.20.8.m1.1.1" xref="S2.T2.20.20.8.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.20.20.8.m1.1b"><ci id="S2.T2.20.20.8.m1.1.1.cmml" xref="S2.T2.20.20.8.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.20.20.8.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T2.24.24" class="ltx_tr">
<td id="S2.T2.24.24.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">Gong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="S2.T2.21.21.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.21.21.1.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.21.21.1.m1.1a"><mo id="S2.T2.21.21.1.m1.1.1" xref="S2.T2.21.21.1.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.21.21.1.m1.1b"><compose id="S2.T2.21.21.1.m1.1.1.cmml" xref="S2.T2.21.21.1.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.21.21.1.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.24.24.6" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.22.22.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.22.22.2.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.22.22.2.m1.1a"><mo id="S2.T2.22.22.2.m1.1.1" xref="S2.T2.22.22.2.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.22.22.2.m1.1b"><compose id="S2.T2.22.22.2.m1.1.1.cmml" xref="S2.T2.22.22.2.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.22.22.2.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.24.24.7" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.24.24.8" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.24.24.9" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.23.23.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.23.23.3.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.23.23.3.m1.1a"><mo id="S2.T2.23.23.3.m1.1.1" xref="S2.T2.23.23.3.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.23.23.3.m1.1b"><compose id="S2.T2.23.23.3.m1.1.1.cmml" xref="S2.T2.23.23.3.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.23.23.3.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.24.24.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.24.24.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.24.24.4.m1.1a"><mi mathvariant="normal" id="S2.T2.24.24.4.m1.1.1" xref="S2.T2.24.24.4.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.24.24.4.m1.1b"><ci id="S2.T2.24.24.4.m1.1.1.cmml" xref="S2.T2.24.24.4.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.24.24.4.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T2.26.26" class="ltx_tr">
<td id="S2.T2.26.26.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">Yin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S2.T2.26.26.4" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.26.26.5" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.26.26.6" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.26.26.7" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.25.25.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.25.25.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.25.25.1.m1.1a"><mi mathvariant="normal" id="S2.T2.25.25.1.m1.1.1" xref="S2.T2.25.25.1.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.25.25.1.m1.1b"><ci id="S2.T2.25.25.1.m1.1.1.cmml" xref="S2.T2.25.25.1.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.25.25.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.26.26.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.26.26.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.26.26.2.m1.1a"><mi mathvariant="normal" id="S2.T2.26.26.2.m1.1.1" xref="S2.T2.26.26.2.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.26.26.2.m1.1b"><ci id="S2.T2.26.26.2.m1.1.1.cmml" xref="S2.T2.26.26.2.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.26.26.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.26.26.8" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.26.26.9" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
</tr>
<tr id="S2.T2.32.32" class="ltx_tr">
<td id="S2.T2.32.32.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.0pt;padding-right:5.0pt;">Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>
</td>
<td id="S2.T2.27.27.1" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.27.27.1.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.27.27.1.m1.1a"><mo id="S2.T2.27.27.1.m1.1.1" xref="S2.T2.27.27.1.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.27.27.1.m1.1b"><compose id="S2.T2.27.27.1.m1.1.1.cmml" xref="S2.T2.27.27.1.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.27.27.1.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.28.28.2" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.28.28.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.28.28.2.m1.1a"><mi mathvariant="normal" id="S2.T2.28.28.2.m1.1.1" xref="S2.T2.28.28.2.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.28.28.2.m1.1b"><ci id="S2.T2.28.28.2.m1.1.1.cmml" xref="S2.T2.28.28.2.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.28.28.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.29.29.3" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.29.29.3.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.29.29.3.m1.1a"><mo id="S2.T2.29.29.3.m1.1.1" xref="S2.T2.29.29.3.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.29.29.3.m1.1b"><compose id="S2.T2.29.29.3.m1.1.1.cmml" xref="S2.T2.29.29.3.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.29.29.3.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.30.30.4" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.30.30.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.30.30.4.m1.1a"><mi mathvariant="normal" id="S2.T2.30.30.4.m1.1.1" xref="S2.T2.30.30.4.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.30.30.4.m1.1b"><ci id="S2.T2.30.30.4.m1.1.1.cmml" xref="S2.T2.30.30.4.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.30.30.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.31.31.5" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.31.31.5.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.31.31.5.m1.1a"><mo id="S2.T2.31.31.5.m1.1.1" xref="S2.T2.31.31.5.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.31.31.5.m1.1b"><compose id="S2.T2.31.31.5.m1.1.1.cmml" xref="S2.T2.31.31.5.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.31.31.5.m1.1c">\circ</annotation></semantics></math></td>
<td id="S2.T2.32.32.6" class="ltx_td ltx_align_center" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.32.32.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.32.32.6.m1.1a"><mi mathvariant="normal" id="S2.T2.32.32.6.m1.1.1" xref="S2.T2.32.32.6.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.32.32.6.m1.1b"><ci id="S2.T2.32.32.6.m1.1.1.cmml" xref="S2.T2.32.32.6.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.32.32.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.32.32.8" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.32.32.9" class="ltx_td" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
</tr>
<tr id="S2.T2.40.40" class="ltx_tr">
<td id="S2.T2.40.40.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;">ours</td>
<td id="S2.T2.33.33.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.33.33.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.33.33.1.m1.1a"><mi mathvariant="normal" id="S2.T2.33.33.1.m1.1.1" xref="S2.T2.33.33.1.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.33.33.1.m1.1b"><ci id="S2.T2.33.33.1.m1.1.1.cmml" xref="S2.T2.33.33.1.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.33.33.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.34.34.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.34.34.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.34.34.2.m1.1a"><mi mathvariant="normal" id="S2.T2.34.34.2.m1.1.1" xref="S2.T2.34.34.2.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.34.34.2.m1.1b"><ci id="S2.T2.34.34.2.m1.1.1.cmml" xref="S2.T2.34.34.2.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.34.34.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.35.35.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.35.35.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.35.35.3.m1.1a"><mi mathvariant="normal" id="S2.T2.35.35.3.m1.1.1" xref="S2.T2.35.35.3.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.35.35.3.m1.1b"><ci id="S2.T2.35.35.3.m1.1.1.cmml" xref="S2.T2.35.35.3.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.35.35.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.36.36.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.36.36.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.36.36.4.m1.1a"><mi mathvariant="normal" id="S2.T2.36.36.4.m1.1.1" xref="S2.T2.36.36.4.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.36.36.4.m1.1b"><ci id="S2.T2.36.36.4.m1.1.1.cmml" xref="S2.T2.36.36.4.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.36.36.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.37.37.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.37.37.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.37.37.5.m1.1a"><mi mathvariant="normal" id="S2.T2.37.37.5.m1.1.1" xref="S2.T2.37.37.5.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.37.37.5.m1.1b"><ci id="S2.T2.37.37.5.m1.1.1.cmml" xref="S2.T2.37.37.5.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.37.37.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.38.38.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.38.38.6.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.38.38.6.m1.1a"><mi mathvariant="normal" id="S2.T2.38.38.6.m1.1.1" xref="S2.T2.38.38.6.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.38.38.6.m1.1b"><ci id="S2.T2.38.38.6.m1.1.1.cmml" xref="S2.T2.38.38.6.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.38.38.6.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.39.39.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.39.39.7.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.39.39.7.m1.1a"><mi mathvariant="normal" id="S2.T2.39.39.7.m1.1.1" xref="S2.T2.39.39.7.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.39.39.7.m1.1b"><ci id="S2.T2.39.39.7.m1.1.1.cmml" xref="S2.T2.39.39.7.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.39.39.7.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S2.T2.40.40.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"><math id="S2.T2.40.40.8.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.40.40.8.m1.1a"><mi mathvariant="normal" id="S2.T2.40.40.8.m1.1.1" xref="S2.T2.40.40.8.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.40.40.8.m1.1b"><ci id="S2.T2.40.40.8.m1.1.1.cmml" xref="S2.T2.40.40.8.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.40.40.8.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S2.T2.42.42" class="ltx_tr">
<td id="S2.T2.42.42.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;" colspan="4">
<math id="S2.T2.41.41.1.m1.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.T2.41.41.1.m1.1a"><mo mathsize="90%" id="S2.T2.41.41.1.m1.1.1" xref="S2.T2.41.41.1.m1.1.1.cmml">‚àò</mo><annotation-xml encoding="MathML-Content" id="S2.T2.41.41.1.m1.1b"><compose id="S2.T2.41.41.1.m1.1.1.cmml" xref="S2.T2.41.41.1.m1.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.41.41.1.m1.1c">\circ</annotation></semantics></math><span id="S2.T2.42.42.2.1" class="ltx_text" style="font-size:90%;">: high-level overview ¬†¬†<math id="S2.T2.42.42.2.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S2.T2.42.42.2.1.m1.1a"><mi mathvariant="normal" id="S2.T2.42.42.2.1.m1.1.1" xref="S2.T2.42.42.2.1.m1.1.1.cmml">‚úì</mi><annotation-xml encoding="MathML-Content" id="S2.T2.42.42.2.1.m1.1b"><ci id="S2.T2.42.42.2.1.m1.1.1.cmml" xref="S2.T2.42.42.2.1.m1.1.1">‚úì</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.42.42.2.1.m1.1c">\checkmark</annotation></semantics></math>: detailed review.</span>
</td>
<td id="S2.T2.42.42.3" class="ltx_td ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.42.42.4" class="ltx_td ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.42.42.5" class="ltx_td ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.42.42.6" class="ltx_td ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
<td id="S2.T2.42.42.7" class="ltx_td ltx_border_t" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
</tr>
</table>
</figure>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.9.2.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> FedAvg for Horizontal FL. (<span id="alg1.2.1" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.2.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0,0}Terms}" display="inline"><semantics id="alg1.2.1.m1.1b"><mrow id="alg1.2.1.m1.1.1" xref="alg1.2.1.m1.1.1.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.2.1.m1.1.1.2" xref="alg1.2.1.m1.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="alg1.2.1.m1.1.1.1" xref="alg1.2.1.m1.1.1.1.cmml">‚Äã</mo><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.2.1.m1.1.1.3" xref="alg1.2.1.m1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.2.1.m1.1.1.1b" xref="alg1.2.1.m1.1.1.1.cmml">‚Äã</mo><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.2.1.m1.1.1.4" xref="alg1.2.1.m1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="alg1.2.1.m1.1.1.1c" xref="alg1.2.1.m1.1.1.1.cmml">‚Äã</mo><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.2.1.m1.1.1.5" xref="alg1.2.1.m1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.2.1.m1.1.1.1d" xref="alg1.2.1.m1.1.1.1.cmml">‚Äã</mo><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.2.1.m1.1.1.6" xref="alg1.2.1.m1.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.2.1.m1.1c"><apply id="alg1.2.1.m1.1.1.cmml" xref="alg1.2.1.m1.1.1"><times id="alg1.2.1.m1.1.1.1.cmml" xref="alg1.2.1.m1.1.1.1"></times><ci id="alg1.2.1.m1.1.1.2.cmml" xref="alg1.2.1.m1.1.1.2">ùëá</ci><ci id="alg1.2.1.m1.1.1.3.cmml" xref="alg1.2.1.m1.1.1.3">ùëí</ci><ci id="alg1.2.1.m1.1.1.4.cmml" xref="alg1.2.1.m1.1.1.4">ùëü</ci><ci id="alg1.2.1.m1.1.1.5.cmml" xref="alg1.2.1.m1.1.1.5">ùëö</ci><ci id="alg1.2.1.m1.1.1.6.cmml" xref="alg1.2.1.m1.1.1.6">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.1.m1.1d">{\color[rgb]{1,0,0}Terms}</annotation></semantics></math></span> highlighted are the vulnerable components can be targeted by adversaries.)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.6" class="ltx_p ltx_figure_panel"><math id="alg1.3.m1.1" class="ltx_Math" alttext="n_{i}" display="inline"><semantics id="alg1.3.m1.1a"><msub id="alg1.3.m1.1.1" xref="alg1.3.m1.1.1.cmml"><mi id="alg1.3.m1.1.1.2" xref="alg1.3.m1.1.1.2.cmml">n</mi><mi id="alg1.3.m1.1.1.3" xref="alg1.3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.3.m1.1b"><apply id="alg1.3.m1.1.1.cmml" xref="alg1.3.m1.1.1"><csymbol cd="ambiguous" id="alg1.3.m1.1.1.1.cmml" xref="alg1.3.m1.1.1">subscript</csymbol><ci id="alg1.3.m1.1.1.2.cmml" xref="alg1.3.m1.1.1.2">ùëõ</ci><ci id="alg1.3.m1.1.1.3.cmml" xref="alg1.3.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.m1.1c">n_{i}</annotation></semantics></math> is the number of local samples, <math id="alg1.4.m2.1" class="ltx_Math" alttext="N_{S}" display="inline"><semantics id="alg1.4.m2.1a"><msub id="alg1.4.m2.1.1" xref="alg1.4.m2.1.1.cmml"><mi id="alg1.4.m2.1.1.2" xref="alg1.4.m2.1.1.2.cmml">N</mi><mi id="alg1.4.m2.1.1.3" xref="alg1.4.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.4.m2.1b"><apply id="alg1.4.m2.1.1.cmml" xref="alg1.4.m2.1.1"><csymbol cd="ambiguous" id="alg1.4.m2.1.1.1.cmml" xref="alg1.4.m2.1.1">subscript</csymbol><ci id="alg1.4.m2.1.1.2.cmml" xref="alg1.4.m2.1.1.2">ùëÅ</ci><ci id="alg1.4.m2.1.1.3.cmml" xref="alg1.4.m2.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.m2.1c">N_{S}</annotation></semantics></math> is the total number of samples among selected clients, <math id="alg1.5.m3.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="alg1.5.m3.1a"><msub id="alg1.5.m3.1.1" xref="alg1.5.m3.1.1.cmml"><mi id="alg1.5.m3.1.1.2" xref="alg1.5.m3.1.1.2.cmml">D</mi><mi id="alg1.5.m3.1.1.3" xref="alg1.5.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.5.m3.1b"><apply id="alg1.5.m3.1.1.cmml" xref="alg1.5.m3.1.1"><csymbol cd="ambiguous" id="alg1.5.m3.1.1.1.cmml" xref="alg1.5.m3.1.1">subscript</csymbol><ci id="alg1.5.m3.1.1.2.cmml" xref="alg1.5.m3.1.1.2">ùê∑</ci><ci id="alg1.5.m3.1.1.3.cmml" xref="alg1.5.m3.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.m3.1c">D_{i}</annotation></semantics></math> is the local training data, <math id="alg1.6.m4.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="alg1.6.m4.1a"><mi id="alg1.6.m4.1.1" xref="alg1.6.m4.1.1.cmml">œâ</mi><annotation-xml encoding="MathML-Content" id="alg1.6.m4.1b"><ci id="alg1.6.m4.1.1.cmml" xref="alg1.6.m4.1.1">ùúî</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.m4.1c">\omega</annotation></semantics></math> is model weights</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.10" class="ltx_p ltx_figure_panel"><span id="alg1.10.1" class="ltx_text ltx_font_bold">Server:</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.11" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>¬†¬†create and send model to all clients

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>¬†¬†clients own their respective data <math id="alg1.l2.m1.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="alg1.l2.m1.1a"><msub id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">D</mi><mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">ùê∑</ci><ci id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">D_{i}</annotation></semantics></math>

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>¬†¬†initialize <math id="alg1.l3.m1.1" class="ltx_Math" alttext="\omega_{0}" display="inline"><semantics id="alg1.l3.m1.1a"><msub id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mi id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml">œâ</mi><mn id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1">subscript</csymbol><ci id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2">ùúî</ci><cn type="integer" id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">\omega_{0}</annotation></semantics></math>

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>¬†¬†<span id="alg1.l4.2" class="ltx_text ltx_font_bold">for</span>¬†each round <math id="alg1.l4.m1.4" class="ltx_Math" alttext="r=1,2,...,R" display="inline"><semantics id="alg1.l4.m1.4a"><mrow id="alg1.l4.m1.4.5" xref="alg1.l4.m1.4.5.cmml"><mi id="alg1.l4.m1.4.5.2" xref="alg1.l4.m1.4.5.2.cmml">r</mi><mo id="alg1.l4.m1.4.5.1" xref="alg1.l4.m1.4.5.1.cmml">=</mo><mrow id="alg1.l4.m1.4.5.3.2" xref="alg1.l4.m1.4.5.3.1.cmml"><mn id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">1</mn><mo id="alg1.l4.m1.4.5.3.2.1" xref="alg1.l4.m1.4.5.3.1.cmml">,</mo><mn id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml">2</mn><mo id="alg1.l4.m1.4.5.3.2.2" xref="alg1.l4.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l4.m1.3.3" xref="alg1.l4.m1.3.3.cmml">‚Ä¶</mi><mo id="alg1.l4.m1.4.5.3.2.3" xref="alg1.l4.m1.4.5.3.1.cmml">,</mo><mi id="alg1.l4.m1.4.4" xref="alg1.l4.m1.4.4.cmml">R</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.4b"><apply id="alg1.l4.m1.4.5.cmml" xref="alg1.l4.m1.4.5"><eq id="alg1.l4.m1.4.5.1.cmml" xref="alg1.l4.m1.4.5.1"></eq><ci id="alg1.l4.m1.4.5.2.cmml" xref="alg1.l4.m1.4.5.2">ùëü</ci><list id="alg1.l4.m1.4.5.3.1.cmml" xref="alg1.l4.m1.4.5.3.2"><cn type="integer" id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">1</cn><cn type="integer" id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2">2</cn><ci id="alg1.l4.m1.3.3.cmml" xref="alg1.l4.m1.3.3">‚Ä¶</ci><ci id="alg1.l4.m1.4.4.cmml" xref="alg1.l4.m1.4.4">ùëÖ</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.4c">r=1,2,...,R</annotation></semantics></math>¬†<span id="alg1.l4.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>¬†¬†¬†¬†¬†sample <math id="alg1.l5.m1.1" class="ltx_Math" alttext="|S|" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.2.2" xref="alg1.l5.m1.1.2.1.cmml"><mo stretchy="false" id="alg1.l5.m1.1.2.2.1" xref="alg1.l5.m1.1.2.1.1.cmml">|</mo><mi id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml">S</mi><mo stretchy="false" id="alg1.l5.m1.1.2.2.2" xref="alg1.l5.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.2.1.cmml" xref="alg1.l5.m1.1.2.2"><abs id="alg1.l5.m1.1.2.1.1.cmml" xref="alg1.l5.m1.1.2.2.1"></abs><ci id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">|S|</annotation></semantics></math> clients, send <math id="alg1.l5.m2.1" class="ltx_Math" alttext="\omega_{r-1}" display="inline"><semantics id="alg1.l5.m2.1a"><msub id="alg1.l5.m2.1.1" xref="alg1.l5.m2.1.1.cmml"><mi id="alg1.l5.m2.1.1.2" xref="alg1.l5.m2.1.1.2.cmml">œâ</mi><mrow id="alg1.l5.m2.1.1.3" xref="alg1.l5.m2.1.1.3.cmml"><mi id="alg1.l5.m2.1.1.3.2" xref="alg1.l5.m2.1.1.3.2.cmml">r</mi><mo id="alg1.l5.m2.1.1.3.1" xref="alg1.l5.m2.1.1.3.1.cmml">‚àí</mo><mn id="alg1.l5.m2.1.1.3.3" xref="alg1.l5.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><apply id="alg1.l5.m2.1.1.cmml" xref="alg1.l5.m2.1.1"><csymbol cd="ambiguous" id="alg1.l5.m2.1.1.1.cmml" xref="alg1.l5.m2.1.1">subscript</csymbol><ci id="alg1.l5.m2.1.1.2.cmml" xref="alg1.l5.m2.1.1.2">ùúî</ci><apply id="alg1.l5.m2.1.1.3.cmml" xref="alg1.l5.m2.1.1.3"><minus id="alg1.l5.m2.1.1.3.1.cmml" xref="alg1.l5.m2.1.1.3.1"></minus><ci id="alg1.l5.m2.1.1.3.2.cmml" xref="alg1.l5.m2.1.1.3.2">ùëü</ci><cn type="integer" id="alg1.l5.m2.1.1.3.3.cmml" xref="alg1.l5.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">\omega_{r-1}</annotation></semantics></math> to each clients in <math id="alg1.l5.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="alg1.l5.m3.1a"><mi id="alg1.l5.m3.1.1" xref="alg1.l5.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg1.l5.m3.1b"><ci id="alg1.l5.m3.1.1.cmml" xref="alg1.l5.m3.1.1">ùëÜ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m3.1c">S</annotation></semantics></math>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>¬†¬†¬†¬†¬†<span id="alg1.l6.2" class="ltx_text ltx_font_bold">for</span>¬†each client <math id="alg1.l6.m1.1" class="ltx_Math" alttext="i\in S" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">i</mi><mo id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">‚àà</mo><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><in id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"></in><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">ùëñ</ci><ci id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">i\in S</annotation></semantics></math>¬†<span id="alg1.l6.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.2.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>¬†¬†¬†¬†¬†¬†¬†¬†<math id="alg1.l7.m1.1" class="ltx_Math" alttext="\omega_{r}^{i}" display="inline"><semantics id="alg1.l7.m1.1a"><msubsup id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><mi id="alg1.l7.m1.1.1.2.2" xref="alg1.l7.m1.1.1.2.2.cmml">œâ</mi><mi id="alg1.l7.m1.1.1.2.3" xref="alg1.l7.m1.1.1.2.3.cmml">r</mi><mi id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1">superscript</csymbol><apply id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.2.1.cmml" xref="alg1.l7.m1.1.1">subscript</csymbol><ci id="alg1.l7.m1.1.1.2.2.cmml" xref="alg1.l7.m1.1.1.2.2">ùúî</ci><ci id="alg1.l7.m1.1.1.2.3.cmml" xref="alg1.l7.m1.1.1.2.3">ùëü</ci></apply><ci id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">\omega_{r}^{i}</annotation></semantics></math> or <math id="alg1.l7.m2.1" class="ltx_Math" alttext="u_{i}\leftarrow" display="inline"><semantics id="alg1.l7.m2.1a"><mrow id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml"><msub id="alg1.l7.m2.1.1.2" xref="alg1.l7.m2.1.1.2.cmml"><mi id="alg1.l7.m2.1.1.2.2" xref="alg1.l7.m2.1.1.2.2.cmml">u</mi><mi id="alg1.l7.m2.1.1.2.3" xref="alg1.l7.m2.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l7.m2.1.1.1" xref="alg1.l7.m2.1.1.1.cmml">‚Üê</mo><mi id="alg1.l7.m2.1.1.3" xref="alg1.l7.m2.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><apply id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1"><ci id="alg1.l7.m2.1.1.1.cmml" xref="alg1.l7.m2.1.1.1">‚Üê</ci><apply id="alg1.l7.m2.1.1.2.cmml" xref="alg1.l7.m2.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m2.1.1.2.1.cmml" xref="alg1.l7.m2.1.1.2">subscript</csymbol><ci id="alg1.l7.m2.1.1.2.2.cmml" xref="alg1.l7.m2.1.1.2.2">ùë¢</ci><ci id="alg1.l7.m2.1.1.2.3.cmml" xref="alg1.l7.m2.1.1.2.3">ùëñ</ci></apply><csymbol cd="latexml" id="alg1.l7.m2.1.1.3.cmml" xref="alg1.l7.m2.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">u_{i}\leftarrow</annotation></semantics></math>Client<math id="alg1.l7.m3.1" class="ltx_math_unparsed" alttext="(i," display="inline"><semantics id="alg1.l7.m3.1a"><mrow id="alg1.l7.m3.1b"><mo stretchy="false" id="alg1.l7.m3.1.1">(</mo><mi id="alg1.l7.m3.1.2">i</mi><mo id="alg1.l7.m3.1.3">,</mo></mrow><annotation encoding="application/x-tex" id="alg1.l7.m3.1c">(i,</annotation></semantics></math> <span id="alg1.l7.1" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.l7.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0,0}\omega_{r-1}}" display="inline"><semantics id="alg1.l7.1.m1.1a"><msub id="alg1.l7.1.m1.1.1" xref="alg1.l7.1.m1.1.1.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l7.1.m1.1.1.2" xref="alg1.l7.1.m1.1.1.2.cmml">œâ</mi><mrow id="alg1.l7.1.m1.1.1.3" xref="alg1.l7.1.m1.1.1.3.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l7.1.m1.1.1.3.2" xref="alg1.l7.1.m1.1.1.3.2.cmml">r</mi><mo mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l7.1.m1.1.1.3.1" xref="alg1.l7.1.m1.1.1.3.1.cmml">‚àí</mo><mn mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l7.1.m1.1.1.3.3" xref="alg1.l7.1.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.1.m1.1b"><apply id="alg1.l7.1.m1.1.1.cmml" xref="alg1.l7.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7.1.m1.1.1.1.cmml" xref="alg1.l7.1.m1.1.1">subscript</csymbol><ci id="alg1.l7.1.m1.1.1.2.cmml" xref="alg1.l7.1.m1.1.1.2">ùúî</ci><apply id="alg1.l7.1.m1.1.1.3.cmml" xref="alg1.l7.1.m1.1.1.3"><minus id="alg1.l7.1.m1.1.1.3.1.cmml" xref="alg1.l7.1.m1.1.1.3.1"></minus><ci id="alg1.l7.1.m1.1.1.3.2.cmml" xref="alg1.l7.1.m1.1.1.3.2">ùëü</ci><cn type="integer" id="alg1.l7.1.m1.1.1.3.3.cmml" xref="alg1.l7.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.1.m1.1c">{\color[rgb]{1,0,0}\omega_{r-1}}</annotation></semantics></math></span>)

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>¬†¬†¬†¬†¬†<span id="alg1.l8.2" class="ltx_text ltx_font_bold">end</span>¬†<span id="alg1.l8.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.3.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>¬†¬†¬†¬†¬†<math id="alg1.l9.m1.1" class="ltx_Math" alttext="\omega_{r}\leftarrow\sum_{i=1}^{|S|}" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.2" xref="alg1.l9.m1.1.2.cmml"><msub id="alg1.l9.m1.1.2.2" xref="alg1.l9.m1.1.2.2.cmml"><mi id="alg1.l9.m1.1.2.2.2" xref="alg1.l9.m1.1.2.2.2.cmml">œâ</mi><mi id="alg1.l9.m1.1.2.2.3" xref="alg1.l9.m1.1.2.2.3.cmml">r</mi></msub><mo rspace="0.111em" stretchy="false" id="alg1.l9.m1.1.2.1" xref="alg1.l9.m1.1.2.1.cmml">‚Üê</mo><msubsup id="alg1.l9.m1.1.2.3" xref="alg1.l9.m1.1.2.3.cmml"><mo id="alg1.l9.m1.1.2.3.2.2" xref="alg1.l9.m1.1.2.3.2.2.cmml">‚àë</mo><mrow id="alg1.l9.m1.1.2.3.2.3" xref="alg1.l9.m1.1.2.3.2.3.cmml"><mi id="alg1.l9.m1.1.2.3.2.3.2" xref="alg1.l9.m1.1.2.3.2.3.2.cmml">i</mi><mo id="alg1.l9.m1.1.2.3.2.3.1" xref="alg1.l9.m1.1.2.3.2.3.1.cmml">=</mo><mn id="alg1.l9.m1.1.2.3.2.3.3" xref="alg1.l9.m1.1.2.3.2.3.3.cmml">1</mn></mrow><mrow id="alg1.l9.m1.1.1.1.3" xref="alg1.l9.m1.1.1.1.2.cmml"><mo stretchy="false" id="alg1.l9.m1.1.1.1.3.1" xref="alg1.l9.m1.1.1.1.2.1.cmml">|</mo><mi id="alg1.l9.m1.1.1.1.1" xref="alg1.l9.m1.1.1.1.1.cmml">S</mi><mo stretchy="false" id="alg1.l9.m1.1.1.1.3.2" xref="alg1.l9.m1.1.1.1.2.1.cmml">|</mo></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.2.cmml" xref="alg1.l9.m1.1.2"><ci id="alg1.l9.m1.1.2.1.cmml" xref="alg1.l9.m1.1.2.1">‚Üê</ci><apply id="alg1.l9.m1.1.2.2.cmml" xref="alg1.l9.m1.1.2.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.2.2.1.cmml" xref="alg1.l9.m1.1.2.2">subscript</csymbol><ci id="alg1.l9.m1.1.2.2.2.cmml" xref="alg1.l9.m1.1.2.2.2">ùúî</ci><ci id="alg1.l9.m1.1.2.2.3.cmml" xref="alg1.l9.m1.1.2.2.3">ùëü</ci></apply><apply id="alg1.l9.m1.1.2.3.cmml" xref="alg1.l9.m1.1.2.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.2.3.1.cmml" xref="alg1.l9.m1.1.2.3">superscript</csymbol><apply id="alg1.l9.m1.1.2.3.2.cmml" xref="alg1.l9.m1.1.2.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.2.3.2.1.cmml" xref="alg1.l9.m1.1.2.3">subscript</csymbol><sum id="alg1.l9.m1.1.2.3.2.2.cmml" xref="alg1.l9.m1.1.2.3.2.2"></sum><apply id="alg1.l9.m1.1.2.3.2.3.cmml" xref="alg1.l9.m1.1.2.3.2.3"><eq id="alg1.l9.m1.1.2.3.2.3.1.cmml" xref="alg1.l9.m1.1.2.3.2.3.1"></eq><ci id="alg1.l9.m1.1.2.3.2.3.2.cmml" xref="alg1.l9.m1.1.2.3.2.3.2">ùëñ</ci><cn type="integer" id="alg1.l9.m1.1.2.3.2.3.3.cmml" xref="alg1.l9.m1.1.2.3.2.3.3">1</cn></apply></apply><apply id="alg1.l9.m1.1.1.1.2.cmml" xref="alg1.l9.m1.1.1.1.3"><abs id="alg1.l9.m1.1.1.1.2.1.cmml" xref="alg1.l9.m1.1.1.1.3.1"></abs><ci id="alg1.l9.m1.1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1.1">ùëÜ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">\omega_{r}\leftarrow\sum_{i=1}^{|S|}</annotation></semantics></math> <span id="alg1.l9.1" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.l9.1.m1.1" class="ltx_Math" alttext="\frac{{\color[rgb]{1,0,0}n_{i}}}{N_{S}}" display="inline"><semantics id="alg1.l9.1.m1.1a"><mfrac id="alg1.l9.1.m1.1.1" xref="alg1.l9.1.m1.1.1.cmml"><msub id="alg1.l9.1.m1.1.1.2" xref="alg1.l9.1.m1.1.1.2.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l9.1.m1.1.1.2.2" xref="alg1.l9.1.m1.1.1.2.2.cmml">n</mi><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l9.1.m1.1.1.2.3" xref="alg1.l9.1.m1.1.1.2.3.cmml">i</mi></msub><msub id="alg1.l9.1.m1.1.1.3" xref="alg1.l9.1.m1.1.1.3.cmml"><mi mathbackground="#FFFF00" id="alg1.l9.1.m1.1.1.3.2" xref="alg1.l9.1.m1.1.1.3.2.cmml">N</mi><mi mathbackground="#FFFF00" id="alg1.l9.1.m1.1.1.3.3" xref="alg1.l9.1.m1.1.1.3.3.cmml">S</mi></msub></mfrac><annotation-xml encoding="MathML-Content" id="alg1.l9.1.m1.1b"><apply id="alg1.l9.1.m1.1.1.cmml" xref="alg1.l9.1.m1.1.1"><divide id="alg1.l9.1.m1.1.1.1.cmml" xref="alg1.l9.1.m1.1.1"></divide><apply id="alg1.l9.1.m1.1.1.2.cmml" xref="alg1.l9.1.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.1.m1.1.1.2.1.cmml" xref="alg1.l9.1.m1.1.1.2">subscript</csymbol><ci id="alg1.l9.1.m1.1.1.2.2.cmml" xref="alg1.l9.1.m1.1.1.2.2">ùëõ</ci><ci id="alg1.l9.1.m1.1.1.2.3.cmml" xref="alg1.l9.1.m1.1.1.2.3">ùëñ</ci></apply><apply id="alg1.l9.1.m1.1.1.3.cmml" xref="alg1.l9.1.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l9.1.m1.1.1.3.1.cmml" xref="alg1.l9.1.m1.1.1.3">subscript</csymbol><ci id="alg1.l9.1.m1.1.1.3.2.cmml" xref="alg1.l9.1.m1.1.1.3.2">ùëÅ</ci><ci id="alg1.l9.1.m1.1.1.3.3.cmml" xref="alg1.l9.1.m1.1.1.3.3">ùëÜ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.1.m1.1c">\frac{{\color[rgb]{1,0,0}n_{i}}}{N_{S}}</annotation></semantics></math></span> <math id="alg1.l9.m2.1" class="ltx_Math" alttext="\omega_{r}^{i}" display="inline"><semantics id="alg1.l9.m2.1a"><msubsup id="alg1.l9.m2.1.1" xref="alg1.l9.m2.1.1.cmml"><mi id="alg1.l9.m2.1.1.2.2" xref="alg1.l9.m2.1.1.2.2.cmml">œâ</mi><mi id="alg1.l9.m2.1.1.2.3" xref="alg1.l9.m2.1.1.2.3.cmml">r</mi><mi id="alg1.l9.m2.1.1.3" xref="alg1.l9.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l9.m2.1b"><apply id="alg1.l9.m2.1.1.cmml" xref="alg1.l9.m2.1.1"><csymbol cd="ambiguous" id="alg1.l9.m2.1.1.1.cmml" xref="alg1.l9.m2.1.1">superscript</csymbol><apply id="alg1.l9.m2.1.1.2.cmml" xref="alg1.l9.m2.1.1"><csymbol cd="ambiguous" id="alg1.l9.m2.1.1.2.1.cmml" xref="alg1.l9.m2.1.1">subscript</csymbol><ci id="alg1.l9.m2.1.1.2.2.cmml" xref="alg1.l9.m2.1.1.2.2">ùúî</ci><ci id="alg1.l9.m2.1.1.2.3.cmml" xref="alg1.l9.m2.1.1.2.3">ùëü</ci></apply><ci id="alg1.l9.m2.1.1.3.cmml" xref="alg1.l9.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m2.1c">\omega_{r}^{i}</annotation></semantics></math> or <math id="alg1.l9.m3.1" class="ltx_Math" alttext="\omega_{r}\leftarrow\omega_{r-1}+\sum_{i=1}^{|S|}" display="inline"><semantics id="alg1.l9.m3.1a"><mrow id="alg1.l9.m3.1.2" xref="alg1.l9.m3.1.2.cmml"><msub id="alg1.l9.m3.1.2.2" xref="alg1.l9.m3.1.2.2.cmml"><mi id="alg1.l9.m3.1.2.2.2" xref="alg1.l9.m3.1.2.2.2.cmml">œâ</mi><mi id="alg1.l9.m3.1.2.2.3" xref="alg1.l9.m3.1.2.2.3.cmml">r</mi></msub><mo stretchy="false" id="alg1.l9.m3.1.2.1" xref="alg1.l9.m3.1.2.1.cmml">‚Üê</mo><mrow id="alg1.l9.m3.1.2.3" xref="alg1.l9.m3.1.2.3.cmml"><msub id="alg1.l9.m3.1.2.3.2" xref="alg1.l9.m3.1.2.3.2.cmml"><mi id="alg1.l9.m3.1.2.3.2.2" xref="alg1.l9.m3.1.2.3.2.2.cmml">œâ</mi><mrow id="alg1.l9.m3.1.2.3.2.3" xref="alg1.l9.m3.1.2.3.2.3.cmml"><mi id="alg1.l9.m3.1.2.3.2.3.2" xref="alg1.l9.m3.1.2.3.2.3.2.cmml">r</mi><mo id="alg1.l9.m3.1.2.3.2.3.1" xref="alg1.l9.m3.1.2.3.2.3.1.cmml">‚àí</mo><mn id="alg1.l9.m3.1.2.3.2.3.3" xref="alg1.l9.m3.1.2.3.2.3.3.cmml">1</mn></mrow></msub><mo rspace="0.055em" id="alg1.l9.m3.1.2.3.1" xref="alg1.l9.m3.1.2.3.1.cmml">+</mo><msubsup id="alg1.l9.m3.1.2.3.3" xref="alg1.l9.m3.1.2.3.3.cmml"><mo id="alg1.l9.m3.1.2.3.3.2.2" xref="alg1.l9.m3.1.2.3.3.2.2.cmml">‚àë</mo><mrow id="alg1.l9.m3.1.2.3.3.2.3" xref="alg1.l9.m3.1.2.3.3.2.3.cmml"><mi id="alg1.l9.m3.1.2.3.3.2.3.2" xref="alg1.l9.m3.1.2.3.3.2.3.2.cmml">i</mi><mo id="alg1.l9.m3.1.2.3.3.2.3.1" xref="alg1.l9.m3.1.2.3.3.2.3.1.cmml">=</mo><mn id="alg1.l9.m3.1.2.3.3.2.3.3" xref="alg1.l9.m3.1.2.3.3.2.3.3.cmml">1</mn></mrow><mrow id="alg1.l9.m3.1.1.1.3" xref="alg1.l9.m3.1.1.1.2.cmml"><mo stretchy="false" id="alg1.l9.m3.1.1.1.3.1" xref="alg1.l9.m3.1.1.1.2.1.cmml">|</mo><mi id="alg1.l9.m3.1.1.1.1" xref="alg1.l9.m3.1.1.1.1.cmml">S</mi><mo stretchy="false" id="alg1.l9.m3.1.1.1.3.2" xref="alg1.l9.m3.1.1.1.2.1.cmml">|</mo></mrow></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m3.1b"><apply id="alg1.l9.m3.1.2.cmml" xref="alg1.l9.m3.1.2"><ci id="alg1.l9.m3.1.2.1.cmml" xref="alg1.l9.m3.1.2.1">‚Üê</ci><apply id="alg1.l9.m3.1.2.2.cmml" xref="alg1.l9.m3.1.2.2"><csymbol cd="ambiguous" id="alg1.l9.m3.1.2.2.1.cmml" xref="alg1.l9.m3.1.2.2">subscript</csymbol><ci id="alg1.l9.m3.1.2.2.2.cmml" xref="alg1.l9.m3.1.2.2.2">ùúî</ci><ci id="alg1.l9.m3.1.2.2.3.cmml" xref="alg1.l9.m3.1.2.2.3">ùëü</ci></apply><apply id="alg1.l9.m3.1.2.3.cmml" xref="alg1.l9.m3.1.2.3"><plus id="alg1.l9.m3.1.2.3.1.cmml" xref="alg1.l9.m3.1.2.3.1"></plus><apply id="alg1.l9.m3.1.2.3.2.cmml" xref="alg1.l9.m3.1.2.3.2"><csymbol cd="ambiguous" id="alg1.l9.m3.1.2.3.2.1.cmml" xref="alg1.l9.m3.1.2.3.2">subscript</csymbol><ci id="alg1.l9.m3.1.2.3.2.2.cmml" xref="alg1.l9.m3.1.2.3.2.2">ùúî</ci><apply id="alg1.l9.m3.1.2.3.2.3.cmml" xref="alg1.l9.m3.1.2.3.2.3"><minus id="alg1.l9.m3.1.2.3.2.3.1.cmml" xref="alg1.l9.m3.1.2.3.2.3.1"></minus><ci id="alg1.l9.m3.1.2.3.2.3.2.cmml" xref="alg1.l9.m3.1.2.3.2.3.2">ùëü</ci><cn type="integer" id="alg1.l9.m3.1.2.3.2.3.3.cmml" xref="alg1.l9.m3.1.2.3.2.3.3">1</cn></apply></apply><apply id="alg1.l9.m3.1.2.3.3.cmml" xref="alg1.l9.m3.1.2.3.3"><csymbol cd="ambiguous" id="alg1.l9.m3.1.2.3.3.1.cmml" xref="alg1.l9.m3.1.2.3.3">superscript</csymbol><apply id="alg1.l9.m3.1.2.3.3.2.cmml" xref="alg1.l9.m3.1.2.3.3"><csymbol cd="ambiguous" id="alg1.l9.m3.1.2.3.3.2.1.cmml" xref="alg1.l9.m3.1.2.3.3">subscript</csymbol><sum id="alg1.l9.m3.1.2.3.3.2.2.cmml" xref="alg1.l9.m3.1.2.3.3.2.2"></sum><apply id="alg1.l9.m3.1.2.3.3.2.3.cmml" xref="alg1.l9.m3.1.2.3.3.2.3"><eq id="alg1.l9.m3.1.2.3.3.2.3.1.cmml" xref="alg1.l9.m3.1.2.3.3.2.3.1"></eq><ci id="alg1.l9.m3.1.2.3.3.2.3.2.cmml" xref="alg1.l9.m3.1.2.3.3.2.3.2">ùëñ</ci><cn type="integer" id="alg1.l9.m3.1.2.3.3.2.3.3.cmml" xref="alg1.l9.m3.1.2.3.3.2.3.3">1</cn></apply></apply><apply id="alg1.l9.m3.1.1.1.2.cmml" xref="alg1.l9.m3.1.1.1.3"><abs id="alg1.l9.m3.1.1.1.2.1.cmml" xref="alg1.l9.m3.1.1.1.3.1"></abs><ci id="alg1.l9.m3.1.1.1.1.cmml" xref="alg1.l9.m3.1.1.1.1">ùëÜ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m3.1c">\omega_{r}\leftarrow\omega_{r-1}+\sum_{i=1}^{|S|}</annotation></semantics></math> <span id="alg1.l9.2" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.l9.2.m1.1" class="ltx_Math" alttext="\frac{{\color[rgb]{1,0,0}n_{i}}}{N_{S}}" display="inline"><semantics id="alg1.l9.2.m1.1a"><mfrac id="alg1.l9.2.m1.1.1" xref="alg1.l9.2.m1.1.1.cmml"><msub id="alg1.l9.2.m1.1.1.2" xref="alg1.l9.2.m1.1.1.2.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l9.2.m1.1.1.2.2" xref="alg1.l9.2.m1.1.1.2.2.cmml">n</mi><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l9.2.m1.1.1.2.3" xref="alg1.l9.2.m1.1.1.2.3.cmml">i</mi></msub><msub id="alg1.l9.2.m1.1.1.3" xref="alg1.l9.2.m1.1.1.3.cmml"><mi mathbackground="#FFFF00" id="alg1.l9.2.m1.1.1.3.2" xref="alg1.l9.2.m1.1.1.3.2.cmml">N</mi><mi mathbackground="#FFFF00" id="alg1.l9.2.m1.1.1.3.3" xref="alg1.l9.2.m1.1.1.3.3.cmml">S</mi></msub></mfrac><annotation-xml encoding="MathML-Content" id="alg1.l9.2.m1.1b"><apply id="alg1.l9.2.m1.1.1.cmml" xref="alg1.l9.2.m1.1.1"><divide id="alg1.l9.2.m1.1.1.1.cmml" xref="alg1.l9.2.m1.1.1"></divide><apply id="alg1.l9.2.m1.1.1.2.cmml" xref="alg1.l9.2.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.2.m1.1.1.2.1.cmml" xref="alg1.l9.2.m1.1.1.2">subscript</csymbol><ci id="alg1.l9.2.m1.1.1.2.2.cmml" xref="alg1.l9.2.m1.1.1.2.2">ùëõ</ci><ci id="alg1.l9.2.m1.1.1.2.3.cmml" xref="alg1.l9.2.m1.1.1.2.3">ùëñ</ci></apply><apply id="alg1.l9.2.m1.1.1.3.cmml" xref="alg1.l9.2.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l9.2.m1.1.1.3.1.cmml" xref="alg1.l9.2.m1.1.1.3">subscript</csymbol><ci id="alg1.l9.2.m1.1.1.3.2.cmml" xref="alg1.l9.2.m1.1.1.3.2">ùëÅ</ci><ci id="alg1.l9.2.m1.1.1.3.3.cmml" xref="alg1.l9.2.m1.1.1.3.3">ùëÜ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.2.m1.1c">\frac{{\color[rgb]{1,0,0}n_{i}}}{N_{S}}</annotation></semantics></math></span> <math id="alg1.l9.m4.1" class="ltx_Math" alttext="u_{i}" display="inline"><semantics id="alg1.l9.m4.1a"><msub id="alg1.l9.m4.1.1" xref="alg1.l9.m4.1.1.cmml"><mi id="alg1.l9.m4.1.1.2" xref="alg1.l9.m4.1.1.2.cmml">u</mi><mi id="alg1.l9.m4.1.1.3" xref="alg1.l9.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l9.m4.1b"><apply id="alg1.l9.m4.1.1.cmml" xref="alg1.l9.m4.1.1"><csymbol cd="ambiguous" id="alg1.l9.m4.1.1.1.cmml" xref="alg1.l9.m4.1.1">subscript</csymbol><ci id="alg1.l9.m4.1.1.2.cmml" xref="alg1.l9.m4.1.1.2">ùë¢</ci><ci id="alg1.l9.m4.1.1.3.cmml" xref="alg1.l9.m4.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m4.1c">u_{i}</annotation></semantics></math>

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>¬†¬†¬†¬†¬†validate the model with <math id="alg1.l10.m1.1" class="ltx_Math" alttext="\omega_{r}" display="inline"><semantics id="alg1.l10.m1.1a"><msub id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><mi id="alg1.l10.m1.1.1.2" xref="alg1.l10.m1.1.1.2.cmml">œâ</mi><mi id="alg1.l10.m1.1.1.3" xref="alg1.l10.m1.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><csymbol cd="ambiguous" id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1">subscript</csymbol><ci id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1.2">ùúî</ci><ci id="alg1.l10.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.3">ùëü</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">\omega_{r}</annotation></semantics></math>

</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span>¬†¬†<span id="alg1.l11.2" class="ltx_text ltx_font_bold">end</span>¬†<span id="alg1.l11.3" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.7" class="ltx_p ltx_figure_panel"><span id="alg1.7.1" class="ltx_text ltx_font_bold">Client(<math id="alg1.7.1.m1.2" class="ltx_Math" alttext="i,\omega" display="inline"><semantics id="alg1.7.1.m1.2a"><mrow id="alg1.7.1.m1.2.3.2" xref="alg1.7.1.m1.2.3.1.cmml"><mi id="alg1.7.1.m1.1.1" xref="alg1.7.1.m1.1.1.cmml">i</mi><mo id="alg1.7.1.m1.2.3.2.1" xref="alg1.7.1.m1.2.3.1.cmml">,</mo><mi id="alg1.7.1.m1.2.2" xref="alg1.7.1.m1.2.2.cmml">œâ</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.7.1.m1.2b"><list id="alg1.7.1.m1.2.3.1.cmml" xref="alg1.7.1.m1.2.3.2"><ci id="alg1.7.1.m1.1.1.cmml" xref="alg1.7.1.m1.1.1">ùëñ</ci><ci id="alg1.7.1.m1.2.2.cmml" xref="alg1.7.1.m1.2.2">ùúî</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.1.m1.2c">i,\omega</annotation></semantics></math>):</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.12" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg1.l1a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1a.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>¬†¬†<span id="alg1.l1a.2" class="ltx_text ltx_font_bold">for</span>¬†each epoch <math id="alg1.l1a.m1.4" class="ltx_Math" alttext="e=1,2,...,E" display="inline"><semantics id="alg1.l1a.m1.4a"><mrow id="alg1.l1a.m1.4.5" xref="alg1.l1a.m1.4.5.cmml"><mi id="alg1.l1a.m1.4.5.2" xref="alg1.l1a.m1.4.5.2.cmml">e</mi><mo id="alg1.l1a.m1.4.5.1" xref="alg1.l1a.m1.4.5.1.cmml">=</mo><mrow id="alg1.l1a.m1.4.5.3.2" xref="alg1.l1a.m1.4.5.3.1.cmml"><mn id="alg1.l1a.m1.1.1" xref="alg1.l1a.m1.1.1.cmml">1</mn><mo id="alg1.l1a.m1.4.5.3.2.1" xref="alg1.l1a.m1.4.5.3.1.cmml">,</mo><mn id="alg1.l1a.m1.2.2" xref="alg1.l1a.m1.2.2.cmml">2</mn><mo id="alg1.l1a.m1.4.5.3.2.2" xref="alg1.l1a.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="alg1.l1a.m1.3.3" xref="alg1.l1a.m1.3.3.cmml">‚Ä¶</mi><mo id="alg1.l1a.m1.4.5.3.2.3" xref="alg1.l1a.m1.4.5.3.1.cmml">,</mo><mi id="alg1.l1a.m1.4.4" xref="alg1.l1a.m1.4.4.cmml">E</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1a.m1.4b"><apply id="alg1.l1a.m1.4.5.cmml" xref="alg1.l1a.m1.4.5"><eq id="alg1.l1a.m1.4.5.1.cmml" xref="alg1.l1a.m1.4.5.1"></eq><ci id="alg1.l1a.m1.4.5.2.cmml" xref="alg1.l1a.m1.4.5.2">ùëí</ci><list id="alg1.l1a.m1.4.5.3.1.cmml" xref="alg1.l1a.m1.4.5.3.2"><cn type="integer" id="alg1.l1a.m1.1.1.cmml" xref="alg1.l1a.m1.1.1">1</cn><cn type="integer" id="alg1.l1a.m1.2.2.cmml" xref="alg1.l1a.m1.2.2">2</cn><ci id="alg1.l1a.m1.3.3.cmml" xref="alg1.l1a.m1.3.3">‚Ä¶</ci><ci id="alg1.l1a.m1.4.4.cmml" xref="alg1.l1a.m1.4.4">ùê∏</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1a.m1.4c">e=1,2,...,E</annotation></semantics></math>¬†<span id="alg1.l1a.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l2a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2a.4.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>¬†¬†¬†¬†¬†<math id="alg1.l2a.m1.1" class="ltx_Math" alttext="\omega_{e}\leftarrow" display="inline"><semantics id="alg1.l2a.m1.1a"><mrow id="alg1.l2a.m1.1.1" xref="alg1.l2a.m1.1.1.cmml"><msub id="alg1.l2a.m1.1.1.2" xref="alg1.l2a.m1.1.1.2.cmml"><mi id="alg1.l2a.m1.1.1.2.2" xref="alg1.l2a.m1.1.1.2.2.cmml">œâ</mi><mi id="alg1.l2a.m1.1.1.2.3" xref="alg1.l2a.m1.1.1.2.3.cmml">e</mi></msub><mo stretchy="false" id="alg1.l2a.m1.1.1.1" xref="alg1.l2a.m1.1.1.1.cmml">‚Üê</mo><mi id="alg1.l2a.m1.1.1.3" xref="alg1.l2a.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2a.m1.1b"><apply id="alg1.l2a.m1.1.1.cmml" xref="alg1.l2a.m1.1.1"><ci id="alg1.l2a.m1.1.1.1.cmml" xref="alg1.l2a.m1.1.1.1">‚Üê</ci><apply id="alg1.l2a.m1.1.1.2.cmml" xref="alg1.l2a.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l2a.m1.1.1.2.1.cmml" xref="alg1.l2a.m1.1.1.2">subscript</csymbol><ci id="alg1.l2a.m1.1.1.2.2.cmml" xref="alg1.l2a.m1.1.1.2.2">ùúî</ci><ci id="alg1.l2a.m1.1.1.2.3.cmml" xref="alg1.l2a.m1.1.1.2.3">ùëí</ci></apply><csymbol cd="latexml" id="alg1.l2a.m1.1.1.3.cmml" xref="alg1.l2a.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2a.m1.1c">\omega_{e}\leftarrow</annotation></semantics></math> <span id="alg1.l2a.1" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.l2a.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0,0}\omega_{e-1}}" display="inline"><semantics id="alg1.l2a.1.m1.1a"><msub id="alg1.l2a.1.m1.1.1" xref="alg1.l2a.1.m1.1.1.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.1.m1.1.1.2" xref="alg1.l2a.1.m1.1.1.2.cmml">œâ</mi><mrow id="alg1.l2a.1.m1.1.1.3" xref="alg1.l2a.1.m1.1.1.3.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.1.m1.1.1.3.2" xref="alg1.l2a.1.m1.1.1.3.2.cmml">e</mi><mo mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.1.m1.1.1.3.1" xref="alg1.l2a.1.m1.1.1.3.1.cmml">‚àí</mo><mn mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.1.m1.1.1.3.3" xref="alg1.l2a.1.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l2a.1.m1.1b"><apply id="alg1.l2a.1.m1.1.1.cmml" xref="alg1.l2a.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2a.1.m1.1.1.1.cmml" xref="alg1.l2a.1.m1.1.1">subscript</csymbol><ci id="alg1.l2a.1.m1.1.1.2.cmml" xref="alg1.l2a.1.m1.1.1.2">ùúî</ci><apply id="alg1.l2a.1.m1.1.1.3.cmml" xref="alg1.l2a.1.m1.1.1.3"><minus id="alg1.l2a.1.m1.1.1.3.1.cmml" xref="alg1.l2a.1.m1.1.1.3.1"></minus><ci id="alg1.l2a.1.m1.1.1.3.2.cmml" xref="alg1.l2a.1.m1.1.1.3.2">ùëí</ci><cn type="integer" id="alg1.l2a.1.m1.1.1.3.3.cmml" xref="alg1.l2a.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2a.1.m1.1c">{\color[rgb]{1,0,0}\omega_{e-1}}</annotation></semantics></math></span> <math id="alg1.l2a.m2.1" class="ltx_math_unparsed" alttext="-\eta\cdot" display="inline"><semantics id="alg1.l2a.m2.1a"><mrow id="alg1.l2a.m2.1b"><mo id="alg1.l2a.m2.1.1">‚àí</mo><mi id="alg1.l2a.m2.1.2">Œ∑</mi><mo lspace="0.222em" id="alg1.l2a.m2.1.3">‚ãÖ</mo></mrow><annotation encoding="application/x-tex" id="alg1.l2a.m2.1c">-\eta\cdot</annotation></semantics></math> <span id="alg1.l2a.2" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.l2a.2.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0,0}\nabla_{\omega_{e-1}}}" display="inline"><semantics id="alg1.l2a.2.m1.1a"><msub id="alg1.l2a.2.m1.1.1" xref="alg1.l2a.2.m1.1.1.cmml"><mo mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.2.m1.1.1.2" xref="alg1.l2a.2.m1.1.1.2.cmml">‚àá</mo><msub id="alg1.l2a.2.m1.1.1.3" xref="alg1.l2a.2.m1.1.1.3.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.2.m1.1.1.3.2" xref="alg1.l2a.2.m1.1.1.3.2.cmml">œâ</mi><mrow id="alg1.l2a.2.m1.1.1.3.3" xref="alg1.l2a.2.m1.1.1.3.3.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.2.m1.1.1.3.3.2" xref="alg1.l2a.2.m1.1.1.3.3.2.cmml">e</mi><mo mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.2.m1.1.1.3.3.1" xref="alg1.l2a.2.m1.1.1.3.3.1.cmml">‚àí</mo><mn mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.2.m1.1.1.3.3.3" xref="alg1.l2a.2.m1.1.1.3.3.3.cmml">1</mn></mrow></msub></msub><annotation-xml encoding="MathML-Content" id="alg1.l2a.2.m1.1b"><apply id="alg1.l2a.2.m1.1.1.cmml" xref="alg1.l2a.2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2a.2.m1.1.1.1.cmml" xref="alg1.l2a.2.m1.1.1">subscript</csymbol><ci id="alg1.l2a.2.m1.1.1.2.cmml" xref="alg1.l2a.2.m1.1.1.2">‚àá</ci><apply id="alg1.l2a.2.m1.1.1.3.cmml" xref="alg1.l2a.2.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l2a.2.m1.1.1.3.1.cmml" xref="alg1.l2a.2.m1.1.1.3">subscript</csymbol><ci id="alg1.l2a.2.m1.1.1.3.2.cmml" xref="alg1.l2a.2.m1.1.1.3.2">ùúî</ci><apply id="alg1.l2a.2.m1.1.1.3.3.cmml" xref="alg1.l2a.2.m1.1.1.3.3"><minus id="alg1.l2a.2.m1.1.1.3.3.1.cmml" xref="alg1.l2a.2.m1.1.1.3.3.1"></minus><ci id="alg1.l2a.2.m1.1.1.3.3.2.cmml" xref="alg1.l2a.2.m1.1.1.3.3.2">ùëí</ci><cn type="integer" id="alg1.l2a.2.m1.1.1.3.3.3.cmml" xref="alg1.l2a.2.m1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2a.2.m1.1c">{\color[rgb]{1,0,0}\nabla_{\omega_{e-1}}}</annotation></semantics></math></span> <math id="alg1.l2a.m3.1" class="ltx_math_unparsed" alttext="\mathcal{L}(" display="inline"><semantics id="alg1.l2a.m3.1a"><mrow id="alg1.l2a.m3.1b"><mi class="ltx_font_mathcaligraphic" id="alg1.l2a.m3.1.1">‚Ñí</mi><mo stretchy="false" id="alg1.l2a.m3.1.2">(</mo></mrow><annotation encoding="application/x-tex" id="alg1.l2a.m3.1c">\mathcal{L}(</annotation></semantics></math><span id="alg1.l2a.3" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.l2a.3.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0,0}D_{i}}" display="inline"><semantics id="alg1.l2a.3.m1.1a"><msub id="alg1.l2a.3.m1.1.1" xref="alg1.l2a.3.m1.1.1.cmml"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.3.m1.1.1.2" xref="alg1.l2a.3.m1.1.1.2.cmml">D</mi><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l2a.3.m1.1.1.3" xref="alg1.l2a.3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l2a.3.m1.1b"><apply id="alg1.l2a.3.m1.1.1.cmml" xref="alg1.l2a.3.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2a.3.m1.1.1.1.cmml" xref="alg1.l2a.3.m1.1.1">subscript</csymbol><ci id="alg1.l2a.3.m1.1.1.2.cmml" xref="alg1.l2a.3.m1.1.1.2">ùê∑</ci><ci id="alg1.l2a.3.m1.1.1.3.cmml" xref="alg1.l2a.3.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2a.3.m1.1c">{\color[rgb]{1,0,0}D_{i}}</annotation></semantics></math></span><math id="alg1.l2a.m4.1" class="ltx_Math" alttext=")" display="inline"><semantics id="alg1.l2a.m4.1a"><mo stretchy="false" id="alg1.l2a.m4.1.1" xref="alg1.l2a.m4.1.1.cmml">)</mo><annotation-xml encoding="MathML-Content" id="alg1.l2a.m4.1b"><ci id="alg1.l2a.m4.1.1.cmml" xref="alg1.l2a.m4.1.1">)</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2a.m4.1c">)</annotation></semantics></math>

</div>
<div id="alg1.l3a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3a.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>¬†¬†<span id="alg1.l3a.2" class="ltx_text ltx_font_bold">end</span>¬†<span id="alg1.l3a.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l4a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4a.2.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>¬†¬†<span id="alg1.l4a.1" class="ltx_text" style="background-color:#FFFF00;"><math id="alg1.l4a.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0,0}u}" display="inline"><semantics id="alg1.l4a.1.m1.1a"><mi mathbackground="#FFFF00" mathcolor="#FF0000" id="alg1.l4a.1.m1.1.1" xref="alg1.l4a.1.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="alg1.l4a.1.m1.1b"><ci id="alg1.l4a.1.m1.1.1.cmml" xref="alg1.l4a.1.m1.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4a.1.m1.1c">{\color[rgb]{1,0,0}u}</annotation></semantics></math></span> <math id="alg1.l4a.m1.1" class="ltx_Math" alttext="\leftarrow\omega_{E}-\omega" display="inline"><semantics id="alg1.l4a.m1.1a"><mrow id="alg1.l4a.m1.1.1" xref="alg1.l4a.m1.1.1.cmml"><mi id="alg1.l4a.m1.1.1.2" xref="alg1.l4a.m1.1.1.2.cmml"></mi><mo stretchy="false" id="alg1.l4a.m1.1.1.1" xref="alg1.l4a.m1.1.1.1.cmml">‚Üê</mo><mrow id="alg1.l4a.m1.1.1.3" xref="alg1.l4a.m1.1.1.3.cmml"><msub id="alg1.l4a.m1.1.1.3.2" xref="alg1.l4a.m1.1.1.3.2.cmml"><mi id="alg1.l4a.m1.1.1.3.2.2" xref="alg1.l4a.m1.1.1.3.2.2.cmml">œâ</mi><mi id="alg1.l4a.m1.1.1.3.2.3" xref="alg1.l4a.m1.1.1.3.2.3.cmml">E</mi></msub><mo id="alg1.l4a.m1.1.1.3.1" xref="alg1.l4a.m1.1.1.3.1.cmml">‚àí</mo><mi id="alg1.l4a.m1.1.1.3.3" xref="alg1.l4a.m1.1.1.3.3.cmml">œâ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4a.m1.1b"><apply id="alg1.l4a.m1.1.1.cmml" xref="alg1.l4a.m1.1.1"><ci id="alg1.l4a.m1.1.1.1.cmml" xref="alg1.l4a.m1.1.1.1">‚Üê</ci><csymbol cd="latexml" id="alg1.l4a.m1.1.1.2.cmml" xref="alg1.l4a.m1.1.1.2">absent</csymbol><apply id="alg1.l4a.m1.1.1.3.cmml" xref="alg1.l4a.m1.1.1.3"><minus id="alg1.l4a.m1.1.1.3.1.cmml" xref="alg1.l4a.m1.1.1.3.1"></minus><apply id="alg1.l4a.m1.1.1.3.2.cmml" xref="alg1.l4a.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l4a.m1.1.1.3.2.1.cmml" xref="alg1.l4a.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l4a.m1.1.1.3.2.2.cmml" xref="alg1.l4a.m1.1.1.3.2.2">ùúî</ci><ci id="alg1.l4a.m1.1.1.3.2.3.cmml" xref="alg1.l4a.m1.1.1.3.2.3">ùê∏</ci></apply><ci id="alg1.l4a.m1.1.1.3.3.cmml" xref="alg1.l4a.m1.1.1.3.3">ùúî</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4a.m1.1c">\leftarrow\omega_{E}-\omega</annotation></semantics></math>

</div>
<div id="alg1.l5a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5a.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>¬†¬†return <math id="alg1.l5a.m1.1" class="ltx_Math" alttext="\omega_{E}" display="inline"><semantics id="alg1.l5a.m1.1a"><msub id="alg1.l5a.m1.1.1" xref="alg1.l5a.m1.1.1.cmml"><mi id="alg1.l5a.m1.1.1.2" xref="alg1.l5a.m1.1.1.2.cmml">œâ</mi><mi id="alg1.l5a.m1.1.1.3" xref="alg1.l5a.m1.1.1.3.cmml">E</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l5a.m1.1b"><apply id="alg1.l5a.m1.1.1.cmml" xref="alg1.l5a.m1.1.1"><csymbol cd="ambiguous" id="alg1.l5a.m1.1.1.1.cmml" xref="alg1.l5a.m1.1.1">subscript</csymbol><ci id="alg1.l5a.m1.1.1.2.cmml" xref="alg1.l5a.m1.1.1.2">ùúî</ci><ci id="alg1.l5a.m1.1.1.3.cmml" xref="alg1.l5a.m1.1.1.3">ùê∏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5a.m1.1c">\omega_{E}</annotation></semantics></math> or <math id="alg1.l5a.m2.1" class="ltx_Math" alttext="u" display="inline"><semantics id="alg1.l5a.m2.1a"><mi id="alg1.l5a.m2.1.1" xref="alg1.l5a.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="alg1.l5a.m2.1b"><ci id="alg1.l5a.m2.1.1.cmml" xref="alg1.l5a.m2.1.1">ùë¢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5a.m2.1c">u</annotation></semantics></math> to server

</div>
</div>
</div>
</div>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data to Model Attacks</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2311.16065/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="153" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An illustration for D2M attack.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We describe Data to Model (D2M) attacks in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> as threat models that are launched by manipulating the local data while the models in training are being targeted as victims. <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks are also considered as black-box attacks because the attackers do not need to access inside information such as client model weights or updates, tampering the data alone is often suffice to launch a <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attack. However, the attackers can also draw information from local dataset or client models to enhance the effectiveness of <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks. We present the timeline of <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> research in Figure¬†<a href="#S3.F3" title="Figure 3 ‚Ä£ 3 Data to Model Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The characteristics of discussed <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks are shown in Table¬†<a href="#S3.T3" title="Table 3 ‚Ä£ 3.1 D2M Attacks on Class Labels ‚Ä£ 3 Data to Model Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2311.16065/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The timeline of research on <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> attacks and defenses.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>D2M Attacks on Class Labels</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attack of poisoning data labels is called label-flipping. Such an attack aims at misleading the training models by feeding tampered labels for training. For instance, the attackers may switch the labels for car images to ‚Äúplanes‚Äù, resulting in the model to classify car images as planes after training.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Label-flipping attack is first studied and proved its effectiveness in the centralized setting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Later on, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> demonstrate label-flipping attack in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> scenarios. Theses studies follow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> and flip the labels from the victim class to a different target class. Authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> show that with only 4% of total clients being malicious, label-flipping attack can cause the recall on victim class to drop by 10% on the Fashion-MNIST dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, indicating that even a small number of malicious clients can effectively degrade the performance of a defenseless <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> system through label-flipping attack. In PoisonGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, the label-flipping attack is further improved. Targeting a <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> system for image classification, the authors of PoisonGAN use the global model received on clients as the discriminator for  <span title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Generative Adversarial Network</span></span> (<abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr>). The attacker trains a local generator until the global model classifies generated images as the victim class. The attackers can then flip labels of generated images, compromising client models by feeding fake images along with flipped labels. The noteworthy advantage of PoisonGAN is that the attacker now does not need to access clients‚Äô data. The attacker can simply generate their own poisonous data samples. Instead of arbitrarily choosing the target class to flip, studies such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> investigate different heuristic for choosing the target class. Semi-targeted attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> uses distance measures to determine which target class can more easily affect model predictions. The intuition of this attack is that if samples of two different classes are relatively close in the feature space, then label-flipping attack on these two classes is more likely to succeed as the proximity of features suggests easier learning convergence. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> consider both the  <span title="Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Independent and Identically Distributed</span></span> (<abbr title="Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IID</span></abbr>) and  <span title="non-Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">non-Independent and Identically Distributed</span></span> (<abbr title="non-Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">non-IID</span></abbr>) scenarios. If client data is <abbr title="Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IID</span></abbr>, the attacker uses the global model to extract features for the local training data. The geometric center of each class is computed based on features of local data and the target class should be the one closest to the victim class. In the <abbr title="non-Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">non-IID</span></abbr> scenario, the local feature space no longer well represents the structure of the global feature space. Thus, the authors leverages the scale of updates to measure which class is closer to the victim class. The attacker feeds local samples of the victim class to the global model and examines the scale of gradients when these samples are annotated as different classes. The class label that induces the smallest gradient is chosen as the target class. Different from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> that exploit the global model for their attacks, the heuristic of the edge-case attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> is built on the distribution of the training data. The edge-case attack flips labels into classes in the tail of the data distribution. Although the edge-case attack only affects a minority of samples, it can severely impair the model‚Äôs fairness for underrepresented input and may pose great threats in autonomous driving systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. Experiments in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> show that the attack is most effective when the attacker holds most of the edge samples. As honest clients possess larger portions of edge samples, the attack is erased by benign updates.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Characteristics of <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> Attacks.</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.2.1.1" class="ltx_text ltx_font_bold">Threat Model</span></td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.2.2.1" class="ltx_text ltx_font_bold">Threat Objective</span></td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.2.3.1" class="ltx_text ltx_font_bold">Poisoned Data</span></td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.3.1.1" class="ltx_text"></span> <span id="S3.T3.1.3.1.2" class="ltx_text">
<span id="S3.T3.1.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†Label-Flipping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite></span></span>
</span></span><span id="S3.T3.1.3.1.3" class="ltx_text"></span></td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†mislassification</td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†class labels</td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.4.1.1" class="ltx_text"></span> <span id="S3.T3.1.4.1.2" class="ltx_text">
<span id="S3.T3.1.4.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.4.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†Semi-Target Poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite></span></span>
</span></span><span id="S3.T3.1.4.1.3" class="ltx_text"></span></td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†misclassification</td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†class labels</td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.5.1.1" class="ltx_text"></span> <span id="S3.T3.1.5.1.2" class="ltx_text">
<span id="S3.T3.1.5.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.5.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.5.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†Edge-case Attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite></span></span>
</span></span><span id="S3.T3.1.5.1.3" class="ltx_text"></span></td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†misclassification</td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†class labels</td>
</tr>
<tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†AT<sup id="S3.T3.1.1.1.1" class="ltx_sup">2</sup>FT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite></td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†misclassification</td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†general samples</td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†PoisonGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†misclassification</td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.6.3.1" class="ltx_text"></span> <span id="S3.T3.1.6.3.2" class="ltx_text">
<span id="S3.T3.1.6.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.6.3.2.1.1" class="ltx_tr">
<span id="S3.T3.1.6.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†general samples and</span></span>
<span id="S3.T3.1.6.3.2.1.2" class="ltx_tr">
<span id="S3.T3.1.6.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†class labels</span></span>
</span></span><span id="S3.T3.1.6.3.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.7.1.1" class="ltx_text"></span> <span id="S3.T3.1.7.1.2" class="ltx_text">
<span id="S3.T3.1.7.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.7.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.7.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†Covert Channel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite></span></span>
</span></span><span id="S3.T3.1.7.1.3" class="ltx_text"></span></td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.7.2.1" class="ltx_text"></span> <span id="S3.T3.1.7.2.2" class="ltx_text">
<span id="S3.T3.1.7.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.7.2.2.1.1" class="ltx_tr">
<span id="S3.T3.1.7.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†secretly passing messages</span></span>
</span></span><span id="S3.T3.1.7.2.3" class="ltx_text"></span></td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†edge samples</td>
</tr>
<tr id="S3.T3.1.8" class="ltx_tr">
<td id="S3.T3.1.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.8.1.1" class="ltx_text"></span> <span id="S3.T3.1.8.1.2" class="ltx_text">
<span id="S3.T3.1.8.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.8.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.8.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†Fake Sample Size <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite></span></span>
</span></span><span id="S3.T3.1.8.1.3" class="ltx_text"></span></td>
<td id="S3.T3.1.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†disrupting convergence</td>
<td id="S3.T3.1.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†client dataset size</td>
</tr>
<tr id="S3.T3.1.9" class="ltx_tr">
<td id="S3.T3.1.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.9.1.1" class="ltx_text"></span> <span id="S3.T3.1.9.1.2" class="ltx_text">
<span id="S3.T3.1.9.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.9.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.9.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†Local Environment Poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite></span></span>
</span></span><span id="S3.T3.1.9.1.3" class="ltx_text"></span></td>
<td id="S3.T3.1.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†poisoning policy</td>
<td id="S3.T3.1.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†agent rewards</td>
</tr>
<tr id="S3.T3.1.10" class="ltx_tr">
<td id="S3.T3.1.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.10.1.1" class="ltx_text"></span> <span id="S3.T3.1.10.1.2" class="ltx_text">
<span id="S3.T3.1.10.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.10.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.10.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†Poisonous Ratings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite></span></span>
</span></span><span id="S3.T3.1.10.1.3" class="ltx_text"></span></td>
<td id="S3.T3.1.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†<span id="S3.T3.1.10.2.1" class="ltx_text"></span> <span id="S3.T3.1.10.2.2" class="ltx_text">
<span id="S3.T3.1.10.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.10.2.2.1.1" class="ltx_tr">
<span id="S3.T3.1.10.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†controlling item</span></span>
<span id="S3.T3.1.10.2.2.1.2" class="ltx_tr">
<span id="S3.T3.1.10.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†recommendation</span></span>
</span></span><span id="S3.T3.1.10.2.3" class="ltx_text"></span></td>
<td id="S3.T3.1.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:2.5pt 18.0pt;">¬†¬†¬†¬†¬†¬†item ratings</td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>D2M Attacks on Samples</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">Labels are not the only target in <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks. Depending on the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> scenario, the attackers may choose to poison other relevant client data. A threat model that targets the sample size on clients is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. Based on the fact that FedAvg computes the weighted average of client weights based on the numbers of their corresponding local samples, the attacker can simply falsely report the number of local samples to be a large number such that the aggregated model will be dominated by the attacker‚Äôs chosen model. AT<sup id="S3.SS2.p1.4.1" class="ltx_sup">2</sup>FT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> is another <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attack that generate poisonous samples. The difference between AT<sup id="S3.SS2.p1.4.2" class="ltx_sup">2</sup>FT and PoisonGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> is that the former does not flip labels. Authors of AT<sup id="S3.SS2.p1.4.3" class="ltx_sup">2</sup>FT formulates their attack as a bilevel optimization problem in which the attacker tries to perturb subsets of local training samples such that losses on local clean data are maximized. In essence, the AT<sup id="S3.SS2.p1.4.4" class="ltx_sup">2</sup>FT algorithm maximizes local losses through gradient ascent where gradients <em id="S3.SS2.p1.4.5" class="ltx_emph ltx_font_italic">w.r.t</em> the perturbed data are approximated by minimizing a dual problem. The <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks are also not limited to classification tasks. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> propose a <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> threat model, local environment poisoning, targeting federated  <span title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Reinforcement Learning</span></span> (<abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr>). The attacker can influence the learned policy by providing fake rewards during local agent training. Fake rewards are derived from gradient descent such that they minimize the objective function of <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr>. A <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> threat model on  <span title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Federated Recommendation</span></span> (<abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr>) systems is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. Specifically, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> focused on the graph neural network based <abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr> system proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. By feeding compromised client models with fake item ratings during training, the attacker can force the recommendation system to show specified item ratings for specific users.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Unlike the above methods that use <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks to influence model predictions, the covert channel attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> aims at secretly transmitting messages between two clients. On the receiver client, the attacker first looks for edge samples from its local training data such that even a small perturbation in the data results in different classification outcomes. Perturbed edge samples along with the transmission interval, the clean and poisoned class predictions are sent to the sender client. The sender client decides whether to fine-tune its local model with the perturbed data depending on the message bit it wishes to send and the local model‚Äôs prediction. Once the receiver client receives the updated model, it can decode the message bit based on the classification outcome of perturbed samples.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">For <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks to be successful, studies in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> show that it is vital to ensure the availability of malicious clients during training. If no malicious client are selected to participate in the global model update, the effects of their attacks can be quickly erased by updates from benign clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Recent studies on <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> threat models tend to combine <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks with <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks to launch more powerful composite attacks. Since the attacker also manipulates model updates, composite attacks can be stealthier and more persistent. Such attacks also give the attacker more freedom of when and how to trigger the attack.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Defense Against D2M Attacks</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In this section we introduce defense strategies proposed along with studies on label-flipping attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. Since <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attacks ultimately induce changes in model updates, <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> system administrators may also consider defense mechanisms designed for <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> or composite attacks.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Strategies proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> are both inspired by the observation that gradients in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> behave differently in terms of benign and malicious clients. In particular, because of the <abbr title="non-Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">non-IID</span></abbr> nature of data, it is observed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> that gradients from benign clients are more diverse than those from malicious clients. This is because benign gradients conform to the <abbr title="non-Independent and Identically Distributed" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">non-IID</span></abbr> distribution of local data while malicious models have a shared poisoning goal. The defense strategy FoolsGold <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> thus aims at reducing the learning rate of similar model updates while maintaining the learning rate of diverse updates. To determine the similarity of model updates, the history of all model updates are stored and pair-wise cosine similarity between current and historical updates are computed. The defense strategy in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> requires prior knowledge on the attack target. This method needs the user to first choose a suspect class that is believed to be poisoned. Then only model updates directly contributing to the prediction of the suspect class are collected. These model weights subsequently go through  <span title="Principal Component Analysis" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Principal Component Analysis</span></span> (<abbr title="Principal Component Analysis" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PCA</span></abbr>) and are clustered based on their principal components. Principal components of benign and malicious clients fall in different clusters. Similar to gradients, model weights can also be used to differentiate benign and malicious clients. Sniper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> is a defense strategy based on the Euclidean distances between model weights. The central server first computes the pair-wise distances between received client models. Then the server constructs a graph based on the distances. Client models are the nodes of the graph, and if the distance between two client models are smaller than the given threshold, these two models are then linked by an edge. If the number of models in the maximum clique of the graph is larger than half of the total number of clients, models in this clique are aggregated to update the global model. Otherwise, the server increases the distance threshold and repeat the above process until a suitable clique can be found.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Parallel learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> is a paradigm of <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr> in which multiple agents learn concurrently to solve a problem. Parallel learning not only alleviates data deficiency but also stabilizes training, as agents learn from diverse experiences. Unlike multi-agent <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr>, which aims to develop competitive or cooperative strategies among clients, parallel <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr> focuses on solving single-agent problems through parallel training. This objective is similar to that of conventional federated learning, in which the goal is to obtain a global model through distributed local model training. Therefore, federated reinforcement learning becomes imperative when the learning environment of <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr> is privacy-sensitive. For the <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> threat model targeting federated <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr>, a corresponding defense strategy was also proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. This method requires the central server to evaluate client agent performance to determine their credibility. Specifically, the central server tests client policies and computes their corresponding rewards. The central server aggregates client policies based on a set of weights derived from normalized rewards.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation Metrics for Attacks and Defenses on Classification Tasks</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Since the majority of studies on D2M attacks focus on image classification, the most commonly used datasets for <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attack evaluation are MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, Fashion-MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and CIFAR-10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. Natural language and domain-specific datasets can also be seen <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.  <span title="Attack Success Rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Attack Success Rate</span></span> (<abbr title="Attack Success Rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ASR</span></abbr>) is widely used to evaluate the effectiveness of an attack. Specifically, for D2M attacks targeting classification tasks, <abbr title="Attack Success Rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ASR</span></abbr> is defined as the proportion of targeted test samples being misclassified, namely,</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="ASR=\frac{\Sigma_{(x_{i},y_{i})\in D}\mathbbm{1}\{f(x_{i})=y_{t},y_{t}\neq y_{i}\}}{|D|}" display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.5" xref="S3.E1.m1.4.5.cmml"><mrow id="S3.E1.m1.4.5.2" xref="S3.E1.m1.4.5.2.cmml"><mi id="S3.E1.m1.4.5.2.2" xref="S3.E1.m1.4.5.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.5.2.1" xref="S3.E1.m1.4.5.2.1.cmml">‚Äã</mo><mi id="S3.E1.m1.4.5.2.3" xref="S3.E1.m1.4.5.2.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.5.2.1a" xref="S3.E1.m1.4.5.2.1.cmml">‚Äã</mo><mi id="S3.E1.m1.4.5.2.4" xref="S3.E1.m1.4.5.2.4.cmml">R</mi></mrow><mo id="S3.E1.m1.4.5.1" xref="S3.E1.m1.4.5.1.cmml">=</mo><mfrac id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><msub id="S3.E1.m1.3.3.3.5" xref="S3.E1.m1.3.3.3.5.cmml"><mi mathvariant="normal" id="S3.E1.m1.3.3.3.5.2" xref="S3.E1.m1.3.3.3.5.2.cmml">Œ£</mi><mrow id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E1.m1.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.E1.m1.2.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.2.2.2.2.2.2.2.5" xref="S3.E1.m1.2.2.2.2.2.2.3.cmml">)</mo></mrow><mo id="S3.E1.m1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.3.cmml">‚àà</mo><mi id="S3.E1.m1.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.4.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.4" xref="S3.E1.m1.3.3.3.4.cmml">‚Äã</mo><mn id="S3.E1.m1.3.3.3.6" xref="S3.E1.m1.3.3.3.6.cmml">ùüô</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.4a" xref="S3.E1.m1.3.3.3.4.cmml">‚Äã</mo><mrow id="S3.E1.m1.3.3.3.3.1" xref="S3.E1.m1.3.3.3.3.2.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.3.1.2" xref="S3.E1.m1.3.3.3.3.2.cmml">{</mo><mrow id="S3.E1.m1.3.3.3.3.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.3.cmml"><mrow id="S3.E1.m1.3.3.3.3.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.cmml"><mrow id="S3.E1.m1.3.3.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.3.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.1.1.2.cmml">=</mo><msub id="S3.E1.m1.3.3.3.3.1.1.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.1.1.3.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.1.1.3.2" xref="S3.E1.m1.3.3.3.3.1.1.1.1.3.2.cmml">y</mi><mi id="S3.E1.m1.3.3.3.3.1.1.1.1.3.3" xref="S3.E1.m1.3.3.3.3.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.3.3.3.3.1.1.2.3" xref="S3.E1.m1.3.3.3.3.1.1.3a.cmml">,</mo><mrow id="S3.E1.m1.3.3.3.3.1.1.2.2" xref="S3.E1.m1.3.3.3.3.1.1.2.2.cmml"><msub id="S3.E1.m1.3.3.3.3.1.1.2.2.2" xref="S3.E1.m1.3.3.3.3.1.1.2.2.2.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.2.2.2.2" xref="S3.E1.m1.3.3.3.3.1.1.2.2.2.2.cmml">y</mi><mi id="S3.E1.m1.3.3.3.3.1.1.2.2.2.3" xref="S3.E1.m1.3.3.3.3.1.1.2.2.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.3.3.3.3.1.1.2.2.1" xref="S3.E1.m1.3.3.3.3.1.1.2.2.1.cmml">‚â†</mo><msub id="S3.E1.m1.3.3.3.3.1.1.2.2.3" xref="S3.E1.m1.3.3.3.3.1.1.2.2.3.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.2.2.3.2" xref="S3.E1.m1.3.3.3.3.1.1.2.2.3.2.cmml">y</mi><mi id="S3.E1.m1.3.3.3.3.1.1.2.2.3.3" xref="S3.E1.m1.3.3.3.3.1.1.2.2.3.3.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S3.E1.m1.3.3.3.3.1.3" xref="S3.E1.m1.3.3.3.3.2.cmml">}</mo></mrow></mrow><mrow id="S3.E1.m1.4.4.4.3" xref="S3.E1.m1.4.4.4.2.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.4.3.1" xref="S3.E1.m1.4.4.4.2.1.cmml">|</mo><mi id="S3.E1.m1.4.4.4.1" xref="S3.E1.m1.4.4.4.1.cmml">D</mi><mo stretchy="false" id="S3.E1.m1.4.4.4.3.2" xref="S3.E1.m1.4.4.4.2.1.cmml">|</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.5.cmml" xref="S3.E1.m1.4.5"><eq id="S3.E1.m1.4.5.1.cmml" xref="S3.E1.m1.4.5.1"></eq><apply id="S3.E1.m1.4.5.2.cmml" xref="S3.E1.m1.4.5.2"><times id="S3.E1.m1.4.5.2.1.cmml" xref="S3.E1.m1.4.5.2.1"></times><ci id="S3.E1.m1.4.5.2.2.cmml" xref="S3.E1.m1.4.5.2.2">ùê¥</ci><ci id="S3.E1.m1.4.5.2.3.cmml" xref="S3.E1.m1.4.5.2.3">ùëÜ</ci><ci id="S3.E1.m1.4.5.2.4.cmml" xref="S3.E1.m1.4.5.2.4">ùëÖ</ci></apply><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><divide id="S3.E1.m1.4.4.5.cmml" xref="S3.E1.m1.4.4"></divide><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><times id="S3.E1.m1.3.3.3.4.cmml" xref="S3.E1.m1.3.3.3.4"></times><apply id="S3.E1.m1.3.3.3.5.cmml" xref="S3.E1.m1.3.3.3.5"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.5.1.cmml" xref="S3.E1.m1.3.3.3.5">subscript</csymbol><ci id="S3.E1.m1.3.3.3.5.2.cmml" xref="S3.E1.m1.3.3.3.5.2">Œ£</ci><apply id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2"><in id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.3"></in><interval closure="open" id="S3.E1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">ùë•</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">ùëñ</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2">ùë¶</ci><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.3">ùëñ</ci></apply></interval><ci id="S3.E1.m1.2.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.2.2.4">ùê∑</ci></apply></apply><cn type="integer" id="S3.E1.m1.3.3.3.6.cmml" xref="S3.E1.m1.3.3.3.6">1</cn><set id="S3.E1.m1.3.3.3.3.2.cmml" xref="S3.E1.m1.3.3.3.3.1"><apply id="S3.E1.m1.3.3.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.3a.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.3.3.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1"><eq id="S3.E1.m1.3.3.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.2"></eq><apply id="S3.E1.m1.3.3.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1"><times id="S3.E1.m1.3.3.3.3.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.2"></times><ci id="S3.E1.m1.3.3.3.3.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.3">ùëì</ci><apply id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.2">ùë•</ci><ci id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.3">ùëñ</ci></apply></apply><apply id="S3.E1.m1.3.3.3.3.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.3.2">ùë¶</ci><ci id="S3.E1.m1.3.3.3.3.1.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.3.3">ùë°</ci></apply></apply><apply id="S3.E1.m1.3.3.3.3.1.1.2.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2"><neq id="S3.E1.m1.3.3.3.3.1.1.2.2.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.1"></neq><apply id="S3.E1.m1.3.3.3.3.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.2.2.2.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.1.1.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.2.2">ùë¶</ci><ci id="S3.E1.m1.3.3.3.3.1.1.2.2.2.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.2.3">ùë°</ci></apply><apply id="S3.E1.m1.3.3.3.3.1.1.2.2.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.2.2.3.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.3">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.1.1.2.2.3.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.3.2">ùë¶</ci><ci id="S3.E1.m1.3.3.3.3.1.1.2.2.3.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2.2.3.3">ùëñ</ci></apply></apply></apply></set></apply><apply id="S3.E1.m1.4.4.4.2.cmml" xref="S3.E1.m1.4.4.4.3"><abs id="S3.E1.m1.4.4.4.2.1.cmml" xref="S3.E1.m1.4.4.4.3.1"></abs><ci id="S3.E1.m1.4.4.4.1.cmml" xref="S3.E1.m1.4.4.4.1">ùê∑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">ASR=\frac{\Sigma_{(x_{i},y_{i})\in D}\mathbbm{1}\{f(x_{i})=y_{t},y_{t}\neq y_{i}\}}{|D|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS4.p3" class="ltx_para ltx_noindent">
<p id="S3.SS4.p3.6" class="ltx_p">where <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><mi id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><ci id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">D</annotation></semantics></math> is the test set for evaluation, <math id="S3.SS4.p3.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS4.p3.2.m2.1a"><msub id="S3.SS4.p3.2.m2.1.1" xref="S3.SS4.p3.2.m2.1.1.cmml"><mi id="S3.SS4.p3.2.m2.1.1.2" xref="S3.SS4.p3.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS4.p3.2.m2.1.1.3" xref="S3.SS4.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m2.1b"><apply id="S3.SS4.p3.2.m2.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.2">ùë•</ci><ci id="S3.SS4.p3.2.m2.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m2.1c">x_{i}</annotation></semantics></math> is the data sample while <math id="S3.SS4.p3.3.m3.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S3.SS4.p3.3.m3.1a"><msub id="S3.SS4.p3.3.m3.1.1" xref="S3.SS4.p3.3.m3.1.1.cmml"><mi id="S3.SS4.p3.3.m3.1.1.2" xref="S3.SS4.p3.3.m3.1.1.2.cmml">y</mi><mi id="S3.SS4.p3.3.m3.1.1.3" xref="S3.SS4.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m3.1b"><apply id="S3.SS4.p3.3.m3.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.3.m3.1.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p3.3.m3.1.1.2.cmml" xref="S3.SS4.p3.3.m3.1.1.2">ùë¶</ci><ci id="S3.SS4.p3.3.m3.1.1.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m3.1c">y_{i}</annotation></semantics></math> is its corresponding groundtruth label, <math id="S3.SS4.p3.4.m4.1" class="ltx_Math" alttext="y_{t}" display="inline"><semantics id="S3.SS4.p3.4.m4.1a"><msub id="S3.SS4.p3.4.m4.1.1" xref="S3.SS4.p3.4.m4.1.1.cmml"><mi id="S3.SS4.p3.4.m4.1.1.2" xref="S3.SS4.p3.4.m4.1.1.2.cmml">y</mi><mi id="S3.SS4.p3.4.m4.1.1.3" xref="S3.SS4.p3.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m4.1b"><apply id="S3.SS4.p3.4.m4.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.4.m4.1.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p3.4.m4.1.1.2.cmml" xref="S3.SS4.p3.4.m4.1.1.2">ùë¶</ci><ci id="S3.SS4.p3.4.m4.1.1.3.cmml" xref="S3.SS4.p3.4.m4.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m4.1c">y_{t}</annotation></semantics></math> is the label chosen by the attacker, <math id="S3.SS4.p3.5.m5.1" class="ltx_Math" alttext="f(\cdot)" display="inline"><semantics id="S3.SS4.p3.5.m5.1a"><mrow id="S3.SS4.p3.5.m5.1.2" xref="S3.SS4.p3.5.m5.1.2.cmml"><mi id="S3.SS4.p3.5.m5.1.2.2" xref="S3.SS4.p3.5.m5.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.1.2.1" xref="S3.SS4.p3.5.m5.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS4.p3.5.m5.1.2.3.2" xref="S3.SS4.p3.5.m5.1.2.cmml"><mo stretchy="false" id="S3.SS4.p3.5.m5.1.2.3.2.1" xref="S3.SS4.p3.5.m5.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS4.p3.5.m5.1.1" xref="S3.SS4.p3.5.m5.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S3.SS4.p3.5.m5.1.2.3.2.2" xref="S3.SS4.p3.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m5.1b"><apply id="S3.SS4.p3.5.m5.1.2.cmml" xref="S3.SS4.p3.5.m5.1.2"><times id="S3.SS4.p3.5.m5.1.2.1.cmml" xref="S3.SS4.p3.5.m5.1.2.1"></times><ci id="S3.SS4.p3.5.m5.1.2.2.cmml" xref="S3.SS4.p3.5.m5.1.2.2">ùëì</ci><ci id="S3.SS4.p3.5.m5.1.1.cmml" xref="S3.SS4.p3.5.m5.1.1">‚ãÖ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m5.1c">f(\cdot)</annotation></semantics></math> is the attacked global model, and <math id="S3.SS4.p3.6.m6.1" class="ltx_Math" alttext="\mathbbm{1}\{\cdot\}" display="inline"><semantics id="S3.SS4.p3.6.m6.1a"><mrow id="S3.SS4.p3.6.m6.1.2" xref="S3.SS4.p3.6.m6.1.2.cmml"><mn id="S3.SS4.p3.6.m6.1.2.2" xref="S3.SS4.p3.6.m6.1.2.2.cmml">ùüô</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p3.6.m6.1.2.1" xref="S3.SS4.p3.6.m6.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS4.p3.6.m6.1.2.3.2" xref="S3.SS4.p3.6.m6.1.2.3.1.cmml"><mo stretchy="false" id="S3.SS4.p3.6.m6.1.2.3.2.1" xref="S3.SS4.p3.6.m6.1.2.3.1.cmml">{</mo><mo lspace="0em" rspace="0em" id="S3.SS4.p3.6.m6.1.1" xref="S3.SS4.p3.6.m6.1.1.cmml">‚ãÖ</mo><mo stretchy="false" id="S3.SS4.p3.6.m6.1.2.3.2.2" xref="S3.SS4.p3.6.m6.1.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.6.m6.1b"><apply id="S3.SS4.p3.6.m6.1.2.cmml" xref="S3.SS4.p3.6.m6.1.2"><times id="S3.SS4.p3.6.m6.1.2.1.cmml" xref="S3.SS4.p3.6.m6.1.2.1"></times><cn type="integer" id="S3.SS4.p3.6.m6.1.2.2.cmml" xref="S3.SS4.p3.6.m6.1.2.2">1</cn><set id="S3.SS4.p3.6.m6.1.2.3.1.cmml" xref="S3.SS4.p3.6.m6.1.2.3.2"><ci id="S3.SS4.p3.6.m6.1.1.cmml" xref="S3.SS4.p3.6.m6.1.1">‚ãÖ</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.6.m6.1c">\mathbbm{1}\{\cdot\}</annotation></semantics></math> equals to 1 if the condition inside the brackets is met. ASR is also used to evaluate M2M or composite attacks. The metric respectively reflects how severely the attack disrupts model convergence and how sensitive the model is to backdoor triggers. In addition, the performance of the attack can also be demonstrated by the decrease in overall classification accuracy. For regression tasks, mean absolute error and root mean squared error are employed. While some defenses provide formal proof for their effectiveness, most work on <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> defenses is empirically validated by demonstrating the robustness of model performance when the defense is adopted in a malicious environment.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Model to Model Attacks</h2>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2311.16065/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An illustration of <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attack.</figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We define Model to Model (M2M) attacks in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> as threat models that manipulate local model updates or weights to affect the global model, as depicted in Figure¬†<a href="#S4.F4" title="Figure 4 ‚Ä£ 4 Model to Model Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The primary objective of an <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attack is to disrupt the convergence of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> algorithms. The presence of <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks is also described as the Byzantine problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. In a distributed system affected by the Byzantine problem, benign and malicious participants coexist in the system. Malicious participants deliberately disseminate confusing or contradicting information to undermine the system‚Äôs normal operations. Therefore the challenge for the system administrator lies in achieving consensus among benign participants despite the presence of malicious ones. Defending against these <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks means ensuring that the learning algorithm to converge to an optimal minima regardless of poisoned updates from malicious clients. In addition to the above threat model, a special case of <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks, called the free-rider attack, aims to steal the global model itself, infringing on the intellectual property rights of the model owner. An malicious party may pretend to join the FL system solely to obtain the distributed global model, without contributing to the learning task. Since the threat model of free-rider attack is comparatively straightforward, we discuss this type of attack along with its defense mechanisms in the same section. The characteristics of discussed <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks are shown in Table¬†<a href="#S4.T4" title="Table 4 ‚Ä£ 4 Model to Model Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Various <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> threat models</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.1.2" class="ltx_tr">
<td id="S4.T4.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S4.T4.1.2.1.1" class="ltx_text ltx_font_bold">Threat Model</span></td>
<td id="S4.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S4.T4.1.2.2.1" class="ltx_text ltx_font_bold">Approach</span></td>
<td id="S4.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S4.T4.1.2.3.1" class="ltx_text ltx_font_bold">Type</span></td>
<td id="S4.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S4.T4.1.2.4.1" class="ltx_text ltx_font_bold">Objective</span></td>
</tr>
<tr id="S4.T4.1.3" class="ltx_tr">
<td id="S4.T4.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">free-riding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>
</td>
<td id="S4.T4.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">pretend as a client</td>
<td id="S4.T4.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;" rowspan="6"><span id="S4.T4.1.3.3.1" class="ltx_text">a priori</span></td>
<td id="S4.T4.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">stealing global model</td>
</tr>
<tr id="S4.T4.1.4" class="ltx_tr">
<td id="S4.T4.1.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.4.1.1" class="ltx_text"></span> <span id="S4.T4.1.4.1.2" class="ltx_text">
<span id="S4.T4.1.4.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.4.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">Byzantine Gaussian<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite></span></span>
</span></span><span id="S4.T4.1.4.1.3" class="ltx_text"></span></td>
<td id="S4.T4.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.4.2.1" class="ltx_text"></span> <span id="S4.T4.1.4.2.2" class="ltx_text">
<span id="S4.T4.1.4.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.4.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.4.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">uploading Gaussian noise</span></span>
</span></span><span id="S4.T4.1.4.2.3" class="ltx_text"></span></td>
<td id="S4.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;" rowspan="7"><span id="S4.T4.1.4.3.1" class="ltx_text"><span id="S4.T4.1.4.3.1.1" class="ltx_text"></span> <span id="S4.T4.1.4.3.1.2" class="ltx_text">
<span id="S4.T4.1.4.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.4.3.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.4.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">inhibiting convergence</span></span>
</span></span> <span id="S4.T4.1.4.3.1.3" class="ltx_text"></span></span></td>
</tr>
<tr id="S4.T4.1.5" class="ltx_tr">
<td id="S4.T4.1.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">bit-flipping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</td>
<td id="S4.T4.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.5.2.1" class="ltx_text"></span> <span id="S4.T4.1.5.2.2" class="ltx_text">
<span id="S4.T4.1.5.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.5.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.5.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">flipping significant bits</span></span>
<span id="S4.T4.1.5.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.5.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">of floating numbers</span></span>
</span></span><span id="S4.T4.1.5.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T4.1.6" class="ltx_tr">
<td id="S4.T4.1.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.6.1.1" class="ltx_text"></span> <span id="S4.T4.1.6.1.2" class="ltx_text">
<span id="S4.T4.1.6.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.6.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.6.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">same-value attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite></span></span>
</span></span><span id="S4.T4.1.6.1.3" class="ltx_text"></span></td>
<td id="S4.T4.1.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.6.2.1" class="ltx_text"></span> <span id="S4.T4.1.6.2.2" class="ltx_text">
<span id="S4.T4.1.6.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.6.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.6.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">uploading vectors with</span></span>
<span id="S4.T4.1.6.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.6.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">identical values across</span></span>
<span id="S4.T4.1.6.2.2.1.3" class="ltx_tr">
<span id="S4.T4.1.6.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">all dimensions</span></span>
</span></span><span id="S4.T4.1.6.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T4.1.7" class="ltx_tr">
<td id="S4.T4.1.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">sign-flipping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>
</td>
<td id="S4.T4.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.7.2.1" class="ltx_text"></span> <span id="S4.T4.1.7.2.2" class="ltx_text">
<span id="S4.T4.1.7.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.7.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.7.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">flipping signs of gradients</span></span>
<span id="S4.T4.1.7.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.7.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">on attacked clients</span></span>
</span></span><span id="S4.T4.1.7.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T4.1.8" class="ltx_tr">
<td id="S4.T4.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.8.1.1" class="ltx_text"></span> <span id="S4.T4.1.8.1.2" class="ltx_text">
<span id="S4.T4.1.8.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.8.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.8.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">median cheating <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite></span></span>
</span></span><span id="S4.T4.1.8.1.3" class="ltx_text"></span></td>
<td id="S4.T4.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.8.2.1" class="ltx_text"></span> <span id="S4.T4.1.8.2.2" class="ltx_text">
<span id="S4.T4.1.8.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.8.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.8.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">cheating the aggregation</span></span>
<span id="S4.T4.1.8.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.8.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">rule to pick the false</span></span>
<span id="S4.T4.1.8.2.2.1.3" class="ltx_tr">
<span id="S4.T4.1.8.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">median</span></span>
</span></span><span id="S4.T4.1.8.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T4.1.9" class="ltx_tr">
<td id="S4.T4.1.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.9.1.1" class="ltx_text"></span> <span id="S4.T4.1.9.1.2" class="ltx_text">
<span id="S4.T4.1.9.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.9.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.9.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">negative gradient <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite></span></span>
</span></span><span id="S4.T4.1.9.1.3" class="ltx_text"></span></td>
<td id="S4.T4.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.9.2.1" class="ltx_text"></span> <span id="S4.T4.1.9.2.2" class="ltx_text">
<span id="S4.T4.1.9.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.9.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.9.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">uploading the scaled</span></span>
<span id="S4.T4.1.9.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.9.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">sum of benign gradients from</span></span>
<span id="S4.T4.1.9.2.2.1.3" class="ltx_tr">
<span id="S4.T4.1.9.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">malicious clients</span></span>
</span></span><span id="S4.T4.1.9.2.3" class="ltx_text"></span></td>
<td id="S4.T4.1.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;" rowspan="12"><span id="S4.T4.1.9.3.1" class="ltx_text">a posteriori</span></td>
</tr>
<tr id="S4.T4.1.10" class="ltx_tr">
<td id="S4.T4.1.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">norm attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>
</td>
<td id="S4.T4.1.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.10.2.1" class="ltx_text"></span> <span id="S4.T4.1.10.2.2" class="ltx_text">
<span id="S4.T4.1.10.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.10.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.10.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">scaling certain dimensions</span></span>
<span id="S4.T4.1.10.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.10.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">of gradients</span></span>
</span></span><span id="S4.T4.1.10.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T4.1.11" class="ltx_tr">
<td id="S4.T4.1.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.11.1.1" class="ltx_text"></span> <span id="S4.T4.1.11.1.2" class="ltx_text">
<span id="S4.T4.1.11.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.11.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.11.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">colluding attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite></span></span>
</span></span><span id="S4.T4.1.11.1.3" class="ltx_text"></span></td>
<td id="S4.T4.1.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.11.2.1" class="ltx_text"></span> <span id="S4.T4.1.11.2.2" class="ltx_text">
<span id="S4.T4.1.11.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.11.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.11.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">deceiving the aggregation</span></span>
<span id="S4.T4.1.11.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.11.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">rule to pick the chosen</span></span>
<span id="S4.T4.1.11.2.2.1.3" class="ltx_tr">
<span id="S4.T4.1.11.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">malicious client</span></span>
</span></span><span id="S4.T4.1.11.2.3" class="ltx_text"></span></td>
<td id="S4.T4.1.11.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.11.3.1" class="ltx_text"></span> <span id="S4.T4.1.11.3.2" class="ltx_text">
<span id="S4.T4.1.11.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.11.3.2.1.1" class="ltx_tr">
<span id="S4.T4.1.11.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">converging to an inferior</span></span>
<span id="S4.T4.1.11.3.2.1.2" class="ltx_tr">
<span id="S4.T4.1.11.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">minima</span></span>
</span></span><span id="S4.T4.1.11.3.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">PipAttack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>
</td>
<td id="S4.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.1.3.1" class="ltx_text"></span> <span id="S4.T4.1.1.3.2" class="ltx_text">
<span id="S4.T4.1.1.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.1.3.2.1.1" class="ltx_tr">
<span id="S4.T4.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">generating item embeddings</span></span>
<span id="S4.T4.1.1.3.2.1.2" class="ltx_tr">
<span id="S4.T4.1.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">based on public information</span></span>
</span></span><span id="S4.T4.1.1.3.3" class="ltx_text"></span></td>
<td id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;" rowspan="6"><span id="S4.T4.1.1.1.1" class="ltx_text"><span id="S4.T4.1.1.1.1.2" class="ltx_text"></span> <span id="S4.T4.1.1.1.1.1" class="ltx_text">
<span id="S4.T4.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.T4.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">increasing <math id="S4.T4.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="ER@K" display="inline"><semantics id="S4.T4.1.1.1.1.1.1.1.1.m1.1a"><mrow id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1a" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">‚Äã</mo><mi mathvariant="normal" id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.4" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.4.cmml">@</mi><mo lspace="0em" rspace="0em" id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1b" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1.cmml">‚Äã</mo><mi id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.5" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.5.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1"><times id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.1"></times><ci id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.2">ùê∏</ci><ci id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.3">ùëÖ</ci><ci id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.4.cmml" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.4">@</ci><ci id="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.5.cmml" xref="S4.T4.1.1.1.1.1.1.1.1.m1.1.1.5">ùêæ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.1.1.1.m1.1c">ER@K</annotation></semantics></math> of target</span></span>
<span id="S4.T4.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S4.T4.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">items</span></span>
</span></span> <span id="S4.T4.1.1.1.1.3" class="ltx_text"></span></span></td>
</tr>
<tr id="S4.T4.1.12" class="ltx_tr">
<td id="S4.T4.1.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">FedRecAttack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>
</td>
<td id="S4.T4.1.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.12.2.1" class="ltx_text"></span> <span id="S4.T4.1.12.2.2" class="ltx_text">
<span id="S4.T4.1.12.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.12.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.12.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">minimizing the rating</span></span>
<span id="S4.T4.1.12.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.12.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">scores of untargeted items</span></span>
</span></span><span id="S4.T4.1.12.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T4.1.13" class="ltx_tr">
<td id="S4.T4.1.13.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.13.1.1" class="ltx_text"></span> <span id="S4.T4.1.13.1.2" class="ltx_text">
<span id="S4.T4.1.13.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.13.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.13.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">User Approximation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite></span></span>
</span></span><span id="S4.T4.1.13.1.3" class="ltx_text"></span></td>
<td id="S4.T4.1.13.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S4.T4.1.13.2.1" class="ltx_text"></span> <span id="S4.T4.1.13.2.2" class="ltx_text">
<span id="S4.T4.1.13.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.13.2.2.1.1" class="ltx_tr">
<span id="S4.T4.1.13.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">generating item embeddings</span></span>
<span id="S4.T4.1.13.2.2.1.2" class="ltx_tr">
<span id="S4.T4.1.13.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">through approximated user</span></span>
<span id="S4.T4.1.13.2.2.1.3" class="ltx_tr">
<span id="S4.T4.1.13.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">embeddings</span></span>
</span></span><span id="S4.T4.1.13.2.3" class="ltx_text"></span></td>
</tr>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>General M2M Threat Models</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Existing <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> threat models can be divided into <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">a priori</span> and <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">a posteriori</span> attacks.<span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_italic">A priori</span> attacks do not require any knowledge of benign clients while <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_italic">a posteriori</span> attacks need to forge poisonous model updates based on information from benign clients.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Priori M2M Attacks</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">A straightforward <span id="S4.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_italic">a priori</span> <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> (prioM2M) attack is sending noise to the central server. This method is dubbed as Gaussian Byzantine in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. The Gaussian distribution for noise sampling often has zero mean but large variance to disrupt the convergence of the learning algorithm. Gaussian Byzantine is often used as the baseline attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. Bit-flipping is a prioM2M attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. On malicious clients, the bit-flipping attack flips four significant bits of certain 32-bit floating numbers in the original gradients as poisoned model updates. Another two prioM2M attacks, same-value attack and sign-flipping attack, are proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. For the same-value attack, malicious clients upload vectors with an identical random value on each dimension to the server. In the sign-flipping attack, malicious clients computes their own gradient as normal but flip the sign of gradients before uploading them to the central server. The prioriM2M attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> takes secure aggregation rules into account. It specifically attacks <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> systems equipped with median-based aggregation rules such as TrimMedian <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> or Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. The basic idea of the attack is to report false updates on multiple malicious clients such that with high probability the aggregation rule picks one of the malicious updates as the median for global update. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> use a statistical heuristic to find the maximum deviation range which is used to forge the malicious updates. The value on each dimension of the original updates on malicious clients is transformed by the maximum deviation range to attain forged malicious updates. The authors also augment this attack with the <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attack, which is discussed in Section¬†<a href="#S3.SS4" title="3.4 Evaluation Metrics for Attacks and Defenses on Classification Tasks ‚Ä£ 3 Data to Model Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Posteriori M2M Attacks</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.2" class="ltx_p">For <span id="S4.SS1.SSS2.p1.2.1" class="ltx_text ltx_font_italic">a posteriori</span> <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> (postM2M) attacks, omniscient negative gradient approach proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> is an equally straightforward approach compared to Gaussian Byzantine. This method assumes that the attacker have full knowledge of benign clients, then malicious clients only need to send scaled negative sum of benign gradients to the central server. The scaling factor is a large number on the order of magnitude of <math id="S4.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="10^{20}" display="inline"><semantics id="S4.SS1.SSS2.p1.1.m1.1a"><msup id="S4.SS1.SSS2.p1.1.m1.1.1" xref="S4.SS1.SSS2.p1.1.m1.1.1.cmml"><mn id="S4.SS1.SSS2.p1.1.m1.1.1.2" xref="S4.SS1.SSS2.p1.1.m1.1.1.2.cmml">10</mn><mn id="S4.SS1.SSS2.p1.1.m1.1.1.3" xref="S4.SS1.SSS2.p1.1.m1.1.1.3.cmml">20</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.1.m1.1b"><apply id="S4.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1.2">10</cn><cn type="integer" id="S4.SS1.SSS2.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.1.m1.1c">10^{20}</annotation></semantics></math>. The postM2M attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> takes Bayzantine-resilient aggregation rules into account. Specifically, this attack targets aggregation rules that compute the norms of client gradients to filter out malicious updates. The problem with norm-based aggregation rules is that <math id="S4.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="L^{p}" display="inline"><semantics id="S4.SS1.SSS2.p1.2.m2.1a"><msup id="S4.SS1.SSS2.p1.2.m2.1.1" xref="S4.SS1.SSS2.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS2.p1.2.m2.1.1.2" xref="S4.SS1.SSS2.p1.2.m2.1.1.2.cmml">L</mi><mi id="S4.SS1.SSS2.p1.2.m2.1.1.3" xref="S4.SS1.SSS2.p1.2.m2.1.1.3.cmml">p</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.2.m2.1b"><apply id="S4.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1.2">ùêø</ci><ci id="S4.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1.3">ùëù</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.2.m2.1c">L^{p}</annotation></semantics></math> norms cannot tell if two norms only differ in one specific dimension or every dimension. Thus, the attacker can exploit this by only poisoning one dimension of the gradients. The poisoned value can be scaled by a large factor while still being accepted by the aggregation rule as its norm is not far away from those of the benign gradients. Moreover, as the norm chosen by the aggregation rule approaches the infinite norm, the attacker can poison every dimension of model updates.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">The above attacks can be launched individually on clients controlled by the attacker, these approaches does not require malicious clients to coordinate with each other. A colluding postM2M attack is later proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>. This method targets aggregation rules such as Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> and Buylan <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> that use the Euclidean distance between client models as the criterion for choosing trustworthy models. The threat model in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> aims at pushing the global model towards the opposite of the benign update direction. To achieve this at the presence of aforementioned aggregation rules, a chosen malicious client is responsible for generating model updates that maximizes the global model update in the opposite direction. Other malicious clients generate updates that are close to the chosen one, conceiving the aggregation rules that malicious clients form a benign cluster and the chosen malicious client should be picked by the aggregation rule.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>M2M Threat Models on Federated Recommendation Systems</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">As mentioned in the introduction section, <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> is well-suited for recommendation systems thanks to its ability to provide personalized recommendations and reduce privacy risks. A commonly used <abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr> framework is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. Research on the vulnerabilities of domain-specific <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> like <abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr> is still a nascent area. In this section, we introduce three noteworthy studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> focusing on exploiting security vulnerabilities of <abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The common goal of existing attacks on <abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr> is to increase the exposure rate of certain items. The affected recommendation system may always present or never show certain items to users. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, the attackers are assumed to only have access to item embeddings, local and global models. Embeddings that characterize users are always hidden from the attackers. In PipAttack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, the attacker increases target items‚Äô exposure rate by forging their embeddings to be similar to those of popular items. Since the attacker have no access to the popularity of items in the system, this information is retrieved from the Internet. Based on the retrieved information, the attacker locally train a popularity classifier with item embeddings as input. The weights of the classifier are then fixed, target item embeddings are poisoned by enforcing them to be classified as popular by the classifier. The poisoned item embeddings are uploaded to the central server to mislead the <abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr> system.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.3" class="ltx_p">Authors of FedRecAttack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> later points out that major limitations of PipAttack include that it may severely degrade the recommendation performance and it needs around 10% of clients to be attacked for it to be effective. Since the exposure rate at rank <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">K</annotation></semantics></math> (<math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="ER@K" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.1.1.1a" xref="S4.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi mathvariant="normal" id="S4.SS2.p3.2.m2.1.1.4" xref="S4.SS2.p3.2.m2.1.1.4.cmml">@</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.1.1.1b" xref="S4.SS2.p3.2.m2.1.1.1.cmml">‚Äã</mo><mi id="S4.SS2.p3.2.m2.1.1.5" xref="S4.SS2.p3.2.m2.1.1.5.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><times id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"></times><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">ùê∏</ci><ci id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">ùëÖ</ci><ci id="S4.SS2.p3.2.m2.1.1.4.cmml" xref="S4.SS2.p3.2.m2.1.1.4">@</ci><ci id="S4.SS2.p3.2.m2.1.1.5.cmml" xref="S4.SS2.p3.2.m2.1.1.5">ùêæ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">ER@K</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, meaning the fraction of users whose top-<math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">K</annotation></semantics></math> recommended items include the target item, is a non-differentiable function, FedRecAttack uses a surrogate loss function to facilitate the attack. FedRecAttack also assumes that around 5% of user-item interaction histories are publicly available for the attacker to use. The loss function of FedRecAttack encourages the rating scores of recommended non-target items to be smaller than the scores of target items with no interaction history, then the gradients of target item embeddings <em id="S4.SS2.p3.3.1" class="ltx_emph ltx_font_italic">w.r.t</em> this loss function are uploaded to the central server. To further eschew being detected by secure aggregation rules, these gradients are normalized before uploading if their norms are larger than the threshold.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.5" class="ltx_p">Both PipAttack and FedRedAttack require public prior knowledge to work. In contrast, the <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="A-ra/A-hum" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mrow id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml">A</mi><mo id="S4.SS2.p4.1.m1.1.1.1" xref="S4.SS2.p4.1.m1.1.1.1.cmml">‚àí</mo><mrow id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml"><mrow id="S4.SS2.p4.1.m1.1.1.3.2" xref="S4.SS2.p4.1.m1.1.1.3.2.cmml"><mi id="S4.SS2.p4.1.m1.1.1.3.2.2" xref="S4.SS2.p4.1.m1.1.1.3.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.3.2.1" xref="S4.SS2.p4.1.m1.1.1.3.2.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.1.m1.1.1.3.2.3" xref="S4.SS2.p4.1.m1.1.1.3.2.3.cmml">a</mi></mrow><mo id="S4.SS2.p4.1.m1.1.1.3.1" xref="S4.SS2.p4.1.m1.1.1.3.1.cmml">/</mo><mi id="S4.SS2.p4.1.m1.1.1.3.3" xref="S4.SS2.p4.1.m1.1.1.3.3.cmml">A</mi></mrow><mo id="S4.SS2.p4.1.m1.1.1.1a" xref="S4.SS2.p4.1.m1.1.1.1.cmml">‚àí</mo><mrow id="S4.SS2.p4.1.m1.1.1.4" xref="S4.SS2.p4.1.m1.1.1.4.cmml"><mi id="S4.SS2.p4.1.m1.1.1.4.2" xref="S4.SS2.p4.1.m1.1.1.4.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.4.1" xref="S4.SS2.p4.1.m1.1.1.4.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.1.m1.1.1.4.3" xref="S4.SS2.p4.1.m1.1.1.4.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.1.m1.1.1.4.1a" xref="S4.SS2.p4.1.m1.1.1.4.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.1.m1.1.1.4.4" xref="S4.SS2.p4.1.m1.1.1.4.4.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><minus id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1.1"></minus><ci id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2">ùê¥</ci><apply id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3"><divide id="S4.SS2.p4.1.m1.1.1.3.1.cmml" xref="S4.SS2.p4.1.m1.1.1.3.1"></divide><apply id="S4.SS2.p4.1.m1.1.1.3.2.cmml" xref="S4.SS2.p4.1.m1.1.1.3.2"><times id="S4.SS2.p4.1.m1.1.1.3.2.1.cmml" xref="S4.SS2.p4.1.m1.1.1.3.2.1"></times><ci id="S4.SS2.p4.1.m1.1.1.3.2.2.cmml" xref="S4.SS2.p4.1.m1.1.1.3.2.2">ùëü</ci><ci id="S4.SS2.p4.1.m1.1.1.3.2.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3.2.3">ùëé</ci></apply><ci id="S4.SS2.p4.1.m1.1.1.3.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3.3">ùê¥</ci></apply><apply id="S4.SS2.p4.1.m1.1.1.4.cmml" xref="S4.SS2.p4.1.m1.1.1.4"><times id="S4.SS2.p4.1.m1.1.1.4.1.cmml" xref="S4.SS2.p4.1.m1.1.1.4.1"></times><ci id="S4.SS2.p4.1.m1.1.1.4.2.cmml" xref="S4.SS2.p4.1.m1.1.1.4.2">‚Ñé</ci><ci id="S4.SS2.p4.1.m1.1.1.4.3.cmml" xref="S4.SS2.p4.1.m1.1.1.4.3">ùë¢</ci><ci id="S4.SS2.p4.1.m1.1.1.4.4.cmml" xref="S4.SS2.p4.1.m1.1.1.4.4">ùëö</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">A-ra/A-hum</annotation></semantics></math> attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> does not have this requirement. <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="A-ra/A-hum" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mrow id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">A</mi><mo id="S4.SS2.p4.2.m2.1.1.1" xref="S4.SS2.p4.2.m2.1.1.1.cmml">‚àí</mo><mrow id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml"><mrow id="S4.SS2.p4.2.m2.1.1.3.2" xref="S4.SS2.p4.2.m2.1.1.3.2.cmml"><mi id="S4.SS2.p4.2.m2.1.1.3.2.2" xref="S4.SS2.p4.2.m2.1.1.3.2.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.1.1.3.2.1" xref="S4.SS2.p4.2.m2.1.1.3.2.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.2.m2.1.1.3.2.3" xref="S4.SS2.p4.2.m2.1.1.3.2.3.cmml">a</mi></mrow><mo id="S4.SS2.p4.2.m2.1.1.3.1" xref="S4.SS2.p4.2.m2.1.1.3.1.cmml">/</mo><mi id="S4.SS2.p4.2.m2.1.1.3.3" xref="S4.SS2.p4.2.m2.1.1.3.3.cmml">A</mi></mrow><mo id="S4.SS2.p4.2.m2.1.1.1a" xref="S4.SS2.p4.2.m2.1.1.1.cmml">‚àí</mo><mrow id="S4.SS2.p4.2.m2.1.1.4" xref="S4.SS2.p4.2.m2.1.1.4.cmml"><mi id="S4.SS2.p4.2.m2.1.1.4.2" xref="S4.SS2.p4.2.m2.1.1.4.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.1.1.4.1" xref="S4.SS2.p4.2.m2.1.1.4.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.2.m2.1.1.4.3" xref="S4.SS2.p4.2.m2.1.1.4.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.2.m2.1.1.4.1a" xref="S4.SS2.p4.2.m2.1.1.4.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.2.m2.1.1.4.4" xref="S4.SS2.p4.2.m2.1.1.4.4.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><minus id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1.1"></minus><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">ùê¥</ci><apply id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3"><divide id="S4.SS2.p4.2.m2.1.1.3.1.cmml" xref="S4.SS2.p4.2.m2.1.1.3.1"></divide><apply id="S4.SS2.p4.2.m2.1.1.3.2.cmml" xref="S4.SS2.p4.2.m2.1.1.3.2"><times id="S4.SS2.p4.2.m2.1.1.3.2.1.cmml" xref="S4.SS2.p4.2.m2.1.1.3.2.1"></times><ci id="S4.SS2.p4.2.m2.1.1.3.2.2.cmml" xref="S4.SS2.p4.2.m2.1.1.3.2.2">ùëü</ci><ci id="S4.SS2.p4.2.m2.1.1.3.2.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3.2.3">ùëé</ci></apply><ci id="S4.SS2.p4.2.m2.1.1.3.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3.3">ùê¥</ci></apply><apply id="S4.SS2.p4.2.m2.1.1.4.cmml" xref="S4.SS2.p4.2.m2.1.1.4"><times id="S4.SS2.p4.2.m2.1.1.4.1.cmml" xref="S4.SS2.p4.2.m2.1.1.4.1"></times><ci id="S4.SS2.p4.2.m2.1.1.4.2.cmml" xref="S4.SS2.p4.2.m2.1.1.4.2">‚Ñé</ci><ci id="S4.SS2.p4.2.m2.1.1.4.3.cmml" xref="S4.SS2.p4.2.m2.1.1.4.3">ùë¢</ci><ci id="S4.SS2.p4.2.m2.1.1.4.4.cmml" xref="S4.SS2.p4.2.m2.1.1.4.4">ùëö</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">A-ra/A-hum</annotation></semantics></math> also uses a surrogate loss function to promote the <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="ER@K" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mrow id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml"><mi id="S4.SS2.p4.3.m3.1.1.2" xref="S4.SS2.p4.3.m3.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1" xref="S4.SS2.p4.3.m3.1.1.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.3.m3.1.1.3" xref="S4.SS2.p4.3.m3.1.1.3.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1a" xref="S4.SS2.p4.3.m3.1.1.1.cmml">‚Äã</mo><mi mathvariant="normal" id="S4.SS2.p4.3.m3.1.1.4" xref="S4.SS2.p4.3.m3.1.1.4.cmml">@</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.3.m3.1.1.1b" xref="S4.SS2.p4.3.m3.1.1.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.3.m3.1.1.5" xref="S4.SS2.p4.3.m3.1.1.5.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><apply id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1"><times id="S4.SS2.p4.3.m3.1.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1.1"></times><ci id="S4.SS2.p4.3.m3.1.1.2.cmml" xref="S4.SS2.p4.3.m3.1.1.2">ùê∏</ci><ci id="S4.SS2.p4.3.m3.1.1.3.cmml" xref="S4.SS2.p4.3.m3.1.1.3">ùëÖ</ci><ci id="S4.SS2.p4.3.m3.1.1.4.cmml" xref="S4.SS2.p4.3.m3.1.1.4">@</ci><ci id="S4.SS2.p4.3.m3.1.1.5.cmml" xref="S4.SS2.p4.3.m3.1.1.5">ùêæ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">ER@K</annotation></semantics></math> for target items, but this attack focuses on approximating the user embeddings which are inaccessible in <abbr title="Federated Recommendation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FedRec</span></abbr>. <math id="S4.SS2.p4.4.m4.1" class="ltx_Math" alttext="A-ra" display="inline"><semantics id="S4.SS2.p4.4.m4.1a"><mrow id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml"><mi id="S4.SS2.p4.4.m4.1.1.2" xref="S4.SS2.p4.4.m4.1.1.2.cmml">A</mi><mo id="S4.SS2.p4.4.m4.1.1.1" xref="S4.SS2.p4.4.m4.1.1.1.cmml">‚àí</mo><mrow id="S4.SS2.p4.4.m4.1.1.3" xref="S4.SS2.p4.4.m4.1.1.3.cmml"><mi id="S4.SS2.p4.4.m4.1.1.3.2" xref="S4.SS2.p4.4.m4.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.4.m4.1.1.3.1" xref="S4.SS2.p4.4.m4.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.4.m4.1.1.3.3" xref="S4.SS2.p4.4.m4.1.1.3.3.cmml">a</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.1b"><apply id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1"><minus id="S4.SS2.p4.4.m4.1.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1.1"></minus><ci id="S4.SS2.p4.4.m4.1.1.2.cmml" xref="S4.SS2.p4.4.m4.1.1.2">ùê¥</ci><apply id="S4.SS2.p4.4.m4.1.1.3.cmml" xref="S4.SS2.p4.4.m4.1.1.3"><times id="S4.SS2.p4.4.m4.1.1.3.1.cmml" xref="S4.SS2.p4.4.m4.1.1.3.1"></times><ci id="S4.SS2.p4.4.m4.1.1.3.2.cmml" xref="S4.SS2.p4.4.m4.1.1.3.2">ùëü</ci><ci id="S4.SS2.p4.4.m4.1.1.3.3.cmml" xref="S4.SS2.p4.4.m4.1.1.3.3">ùëé</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.1c">A-ra</annotation></semantics></math> assumes that the user embeddings are distributed by a zero mean Gaussian with the variance as a hyper-parameter. The attacker first samples a number of user embeddings from the Gaussian distribution, then maximized the interaction scores target items and sampled user embeddings to derive poisonous item embeddings. Instead of sampling from a Gaussian, <math id="S4.SS2.p4.5.m5.1" class="ltx_Math" alttext="A-hum" display="inline"><semantics id="S4.SS2.p4.5.m5.1a"><mrow id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml"><mi id="S4.SS2.p4.5.m5.1.1.2" xref="S4.SS2.p4.5.m5.1.1.2.cmml">A</mi><mo id="S4.SS2.p4.5.m5.1.1.1" xref="S4.SS2.p4.5.m5.1.1.1.cmml">‚àí</mo><mrow id="S4.SS2.p4.5.m5.1.1.3" xref="S4.SS2.p4.5.m5.1.1.3.cmml"><mi id="S4.SS2.p4.5.m5.1.1.3.2" xref="S4.SS2.p4.5.m5.1.1.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.5.m5.1.1.3.1" xref="S4.SS2.p4.5.m5.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.5.m5.1.1.3.3" xref="S4.SS2.p4.5.m5.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p4.5.m5.1.1.3.1a" xref="S4.SS2.p4.5.m5.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS2.p4.5.m5.1.1.3.4" xref="S4.SS2.p4.5.m5.1.1.3.4.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><apply id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1"><minus id="S4.SS2.p4.5.m5.1.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1.1"></minus><ci id="S4.SS2.p4.5.m5.1.1.2.cmml" xref="S4.SS2.p4.5.m5.1.1.2">ùê¥</ci><apply id="S4.SS2.p4.5.m5.1.1.3.cmml" xref="S4.SS2.p4.5.m5.1.1.3"><times id="S4.SS2.p4.5.m5.1.1.3.1.cmml" xref="S4.SS2.p4.5.m5.1.1.3.1"></times><ci id="S4.SS2.p4.5.m5.1.1.3.2.cmml" xref="S4.SS2.p4.5.m5.1.1.3.2">‚Ñé</ci><ci id="S4.SS2.p4.5.m5.1.1.3.3.cmml" xref="S4.SS2.p4.5.m5.1.1.3.3">ùë¢</ci><ci id="S4.SS2.p4.5.m5.1.1.3.4.cmml" xref="S4.SS2.p4.5.m5.1.1.3.4">ùëö</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">A-hum</annotation></semantics></math> uses online hard user mining to generate user embeddings. The attacker first generate hard user embeddings that are not likely to interact with existing items. Then target item embeddings are optimized to increase their interaction chances with the synthesized hard users.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Characteristics of M2M Defenses</figcaption>
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S4.T5.1.1.1.1" class="ltx_text ltx_font_bold">Type of Defense</span></td>
<td id="S4.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S4.T5.1.1.2.1" class="ltx_text ltx_font_bold">Aggregation Criterion</span></td>
</tr>
<tr id="S4.T5.1.2" class="ltx_tr">
<td id="S4.T5.1.2.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">GeoMed<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>
</td>
<td id="S4.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">geometric median</td>
</tr>
<tr id="S4.T5.1.3" class="ltx_tr">
<td id="S4.T5.1.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">RFA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>
</td>
<td id="S4.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.3.2.1" class="ltx_text"></span> <span id="S4.T5.1.3.2.2" class="ltx_text">
<span id="S4.T5.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.1.3.2.2.1.1" class="ltx_tr">
<span id="S4.T5.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Weiszfeld-smoothed</span></span>
<span id="S4.T5.1.3.2.2.1.2" class="ltx_tr">
<span id="S4.T5.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">geometric median</span></span>
</span></span><span id="S4.T5.1.3.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T5.1.4" class="ltx_tr">
<td id="S4.T5.1.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">MarMed<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</td>
<td id="S4.T5.1.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">dimension-wise median</td>
</tr>
<tr id="S4.T5.1.5" class="ltx_tr">
<td id="S4.T5.1.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">MeaMed<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</td>
<td id="S4.T5.1.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">mean-around median</td>
</tr>
<tr id="S4.T5.1.6" class="ltx_tr">
<td id="S4.T5.1.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">TrimMean<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>
</td>
<td id="S4.T5.1.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">dimension-wise trimmed mean</td>
</tr>
<tr id="S4.T5.1.7" class="ltx_tr">
<td id="S4.T5.1.7.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Krum/Multi-Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>
</td>
<td id="S4.T5.1.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Euclidean distance</td>
</tr>
<tr id="S4.T5.1.8" class="ltx_tr">
<td id="S4.T5.1.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bulyan<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>
</td>
<td id="S4.T5.1.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S4.T5.1.8.2.1" class="ltx_text"></span> <span id="S4.T5.1.8.2.2" class="ltx_text">
<span id="S4.T5.1.8.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.1.8.2.2.1.1" class="ltx_tr">
<span id="S4.T5.1.8.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Euclidean distance and mean-</span></span>
<span id="S4.T5.1.8.2.2.1.2" class="ltx_tr">
<span id="S4.T5.1.8.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">around median</span></span>
</span></span><span id="S4.T5.1.8.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T5.1.9" class="ltx_tr">
<td id="S4.T5.1.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">ELITE<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>
</td>
<td id="S4.T5.1.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">gradient information gain</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Defense Against M2M Attack</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Because the median is robust to outliers in statistics, it is widely used in <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> defenses to filter out malicious updates. GeoMed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> is an exemplar of median-based <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> defenses. In GeoMed, the central server first divides received client gradients into multiple groups and computes the mean of each group. Then the geometric median of group means is used as the gradient for updating the global model. The approach of using geometric median for robust aggregation is further improved by authors of RFA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. In RFA, clients compute their aggregation weights based on the aggregation rule inspired by the Weiszfeld algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>. Including the geometric median, more median-based defenses are studied in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.  <span title="Marginal Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Marginal Median</span></span> (<abbr title="Marginal Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MarMed</span></abbr>) is a generalized form of median proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. It computes the median on each dimension for client gradients.  <span title="Mean-around-Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Mean-around-Median</span></span> (<abbr title="Mean-around-Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MeaMed</span></abbr>) in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> further leverages more values around the median. Built upon <abbr title="Marginal Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MarMed</span></abbr>, <abbr title="Mean-around-Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MeaMed</span></abbr> finds the top-<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">k</annotation></semantics></math> values that are nearest to the median of each dimension, then the mean of these nearest values is used as the gradient on their corresponding dimensions.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Besides median, trimmed mean also has the benefit of being less sensitive to outliers. The authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> introduce coordinate-wise trimmed mean as an aggregation rule. For each dimension of client gradients, this rule removes the top-<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">k</annotation></semantics></math> largest and smallest values, the mean of the remaining values is treated as the gradient on the corresponding dimension.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.5" class="ltx_p">Another criterion for filtering out malicious updates is the Euclidean distance between norms. Krum¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> and Bulyan¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> are two exemplary defenses built on this criterion. Krum is motivated by avoiding the drawbacks of square-distance or majority based aggregation rules. The problem pointed out in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> is that malicious attackers can collude and misguide the center of norms to a bad minima for the sqaure-distance based aggregation, and the majority based aggregation is too computationally expensive as it needs to find a subset of gradients with the smallest distances among them. For a central server that adopts Krum as its aggregation rule, it first finds the <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="(n-f-2)" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mrow id="S4.SS3.p3.1.m1.1.1.1" xref="S4.SS3.p3.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.1.m1.1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p3.1.m1.1.1.1.1" xref="S4.SS3.p3.1.m1.1.1.1.1.cmml"><mi id="S4.SS3.p3.1.m1.1.1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.1.1.2.cmml">n</mi><mo id="S4.SS3.p3.1.m1.1.1.1.1.1" xref="S4.SS3.p3.1.m1.1.1.1.1.1.cmml">‚àí</mo><mi id="S4.SS3.p3.1.m1.1.1.1.1.3" xref="S4.SS3.p3.1.m1.1.1.1.1.3.cmml">f</mi><mo id="S4.SS3.p3.1.m1.1.1.1.1.1a" xref="S4.SS3.p3.1.m1.1.1.1.1.1.cmml">‚àí</mo><mn id="S4.SS3.p3.1.m1.1.1.1.1.4" xref="S4.SS3.p3.1.m1.1.1.1.1.4.cmml">2</mn></mrow><mo stretchy="false" id="S4.SS3.p3.1.m1.1.1.1.3" xref="S4.SS3.p3.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1.1"><minus id="S4.SS3.p3.1.m1.1.1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1.1.1.1"></minus><ci id="S4.SS3.p3.1.m1.1.1.1.1.2.cmml" xref="S4.SS3.p3.1.m1.1.1.1.1.2">ùëõ</ci><ci id="S4.SS3.p3.1.m1.1.1.1.1.3.cmml" xref="S4.SS3.p3.1.m1.1.1.1.1.3">ùëì</ci><cn type="integer" id="S4.SS3.p3.1.m1.1.1.1.1.4.cmml" xref="S4.SS3.p3.1.m1.1.1.1.1.4">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">(n-f-2)</annotation></semantics></math> nearest neighbors for each client based on the Euclidean distances between their updates, where <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">ùëõ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">n</annotation></semantics></math> is the number of clients that participate the training, <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">ùëì</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">f</annotation></semantics></math> is the estimated number of malicious clients. Then the central server sums up the distances between each client and their corresponding neighbors as Krum scores. The client with lowest score is chosen by the central server, and its gradient is used to update the global model for the current training round. Multi-Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> is a variation of Krum that balances averaging and Krum. It chooses top-<math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mi id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><ci id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">k</annotation></semantics></math> clients with highest Krum scores. The average of chosen clients‚Äô updates is used to update the global model. The prerequisite for Krum to be effective is that the number of malicious clients needs to satisfy <math id="S4.SS3.p3.5.m5.1" class="ltx_Math" alttext="f&gt;(n-2)/2" display="inline"><semantics id="S4.SS3.p3.5.m5.1a"><mrow id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml"><mi id="S4.SS3.p3.5.m5.1.1.3" xref="S4.SS3.p3.5.m5.1.1.3.cmml">f</mi><mo id="S4.SS3.p3.5.m5.1.1.2" xref="S4.SS3.p3.5.m5.1.1.2.cmml">&gt;</mo><mrow id="S4.SS3.p3.5.m5.1.1.1" xref="S4.SS3.p3.5.m5.1.1.1.cmml"><mrow id="S4.SS3.p3.5.m5.1.1.1.1.1" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p3.5.m5.1.1.1.1.1.2" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p3.5.m5.1.1.1.1.1.1" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.cmml"><mi id="S4.SS3.p3.5.m5.1.1.1.1.1.1.2" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.2.cmml">n</mi><mo id="S4.SS3.p3.5.m5.1.1.1.1.1.1.1" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.1.cmml">‚àí</mo><mn id="S4.SS3.p3.5.m5.1.1.1.1.1.1.3" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="S4.SS3.p3.5.m5.1.1.1.1.1.3" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS3.p3.5.m5.1.1.1.2" xref="S4.SS3.p3.5.m5.1.1.1.2.cmml">/</mo><mn id="S4.SS3.p3.5.m5.1.1.1.3" xref="S4.SS3.p3.5.m5.1.1.1.3.cmml">2</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.1b"><apply id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1"><gt id="S4.SS3.p3.5.m5.1.1.2.cmml" xref="S4.SS3.p3.5.m5.1.1.2"></gt><ci id="S4.SS3.p3.5.m5.1.1.3.cmml" xref="S4.SS3.p3.5.m5.1.1.3">ùëì</ci><apply id="S4.SS3.p3.5.m5.1.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1.1"><divide id="S4.SS3.p3.5.m5.1.1.1.2.cmml" xref="S4.SS3.p3.5.m5.1.1.1.2"></divide><apply id="S4.SS3.p3.5.m5.1.1.1.1.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1.1.1.1"><minus id="S4.SS3.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.1"></minus><ci id="S4.SS3.p3.5.m5.1.1.1.1.1.1.2.cmml" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.2">ùëõ</ci><cn type="integer" id="S4.SS3.p3.5.m5.1.1.1.1.1.1.3.cmml" xref="S4.SS3.p3.5.m5.1.1.1.1.1.1.3">2</cn></apply><cn type="integer" id="S4.SS3.p3.5.m5.1.1.1.3.cmml" xref="S4.SS3.p3.5.m5.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.1c">f&gt;(n-2)/2</annotation></semantics></math>.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.2" class="ltx_p">Although the convergence of Krum has been proven in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, authors of Bulyan¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> point out that the attacker can simply deceive Krum to pick the malicious client that converges to an ineffective local minima. Such an attack is launched by manipulating the gradient norms as discussed above. Bulyan refines norm-based aggregation rules such as Krum by adding an extra stage after a client has been chosen by the central server. The added stage is akin to <abbr title="Mean-around-Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MeaMed</span></abbr> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. Bulyan first iteratively move clients chosen by Krum or other rules to a candidate set. Once the number of candidates passes the threshold <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="2f+3" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mrow id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mrow id="S4.SS3.p4.1.m1.1.1.2" xref="S4.SS3.p4.1.m1.1.1.2.cmml"><mn id="S4.SS3.p4.1.m1.1.1.2.2" xref="S4.SS3.p4.1.m1.1.1.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p4.1.m1.1.1.2.1" xref="S4.SS3.p4.1.m1.1.1.2.1.cmml">‚Äã</mo><mi id="S4.SS3.p4.1.m1.1.1.2.3" xref="S4.SS3.p4.1.m1.1.1.2.3.cmml">f</mi></mrow><mo id="S4.SS3.p4.1.m1.1.1.1" xref="S4.SS3.p4.1.m1.1.1.1.cmml">+</mo><mn id="S4.SS3.p4.1.m1.1.1.3" xref="S4.SS3.p4.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><plus id="S4.SS3.p4.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1.1"></plus><apply id="S4.SS3.p4.1.m1.1.1.2.cmml" xref="S4.SS3.p4.1.m1.1.1.2"><times id="S4.SS3.p4.1.m1.1.1.2.1.cmml" xref="S4.SS3.p4.1.m1.1.1.2.1"></times><cn type="integer" id="S4.SS3.p4.1.m1.1.1.2.2.cmml" xref="S4.SS3.p4.1.m1.1.1.2.2">2</cn><ci id="S4.SS3.p4.1.m1.1.1.2.3.cmml" xref="S4.SS3.p4.1.m1.1.1.2.3">ùëì</ci></apply><cn type="integer" id="S4.SS3.p4.1.m1.1.1.3.cmml" xref="S4.SS3.p4.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">2f+3</annotation></semantics></math>, Bulyan computes the <abbr title="Mean-around-Median" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MeaMed</span></abbr> on each dimension of candidate gradients. The resulting vector is regarded as the output of Bulyan and subsequently used to update to global model. For Bulyan to be effective, the number of malicious clients needs to satisfy <math id="S4.SS3.p4.2.m2.1" class="ltx_Math" alttext="f&gt;(n-3)/4" display="inline"><semantics id="S4.SS3.p4.2.m2.1a"><mrow id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml"><mi id="S4.SS3.p4.2.m2.1.1.3" xref="S4.SS3.p4.2.m2.1.1.3.cmml">f</mi><mo id="S4.SS3.p4.2.m2.1.1.2" xref="S4.SS3.p4.2.m2.1.1.2.cmml">&gt;</mo><mrow id="S4.SS3.p4.2.m2.1.1.1" xref="S4.SS3.p4.2.m2.1.1.1.cmml"><mrow id="S4.SS3.p4.2.m2.1.1.1.1.1" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p4.2.m2.1.1.1.1.1.2" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p4.2.m2.1.1.1.1.1.1" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.cmml"><mi id="S4.SS3.p4.2.m2.1.1.1.1.1.1.2" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.2.cmml">n</mi><mo id="S4.SS3.p4.2.m2.1.1.1.1.1.1.1" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.1.cmml">‚àí</mo><mn id="S4.SS3.p4.2.m2.1.1.1.1.1.1.3" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.3.cmml">3</mn></mrow><mo stretchy="false" id="S4.SS3.p4.2.m2.1.1.1.1.1.3" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS3.p4.2.m2.1.1.1.2" xref="S4.SS3.p4.2.m2.1.1.1.2.cmml">/</mo><mn id="S4.SS3.p4.2.m2.1.1.1.3" xref="S4.SS3.p4.2.m2.1.1.1.3.cmml">4</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.1b"><apply id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1"><gt id="S4.SS3.p4.2.m2.1.1.2.cmml" xref="S4.SS3.p4.2.m2.1.1.2"></gt><ci id="S4.SS3.p4.2.m2.1.1.3.cmml" xref="S4.SS3.p4.2.m2.1.1.3">ùëì</ci><apply id="S4.SS3.p4.2.m2.1.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1.1"><divide id="S4.SS3.p4.2.m2.1.1.1.2.cmml" xref="S4.SS3.p4.2.m2.1.1.1.2"></divide><apply id="S4.SS3.p4.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1.1.1.1"><minus id="S4.SS3.p4.2.m2.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.1"></minus><ci id="S4.SS3.p4.2.m2.1.1.1.1.1.1.2.cmml" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.2">ùëõ</ci><cn type="integer" id="S4.SS3.p4.2.m2.1.1.1.1.1.1.3.cmml" xref="S4.SS3.p4.2.m2.1.1.1.1.1.1.3">3</cn></apply><cn type="integer" id="S4.SS3.p4.2.m2.1.1.1.3.cmml" xref="S4.SS3.p4.2.m2.1.1.1.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1c">f&gt;(n-3)/4</annotation></semantics></math>.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">Different from the above approaches, ELITE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> uses information gain to filter out malicious updates. ELITE first computes the empirical probability density function for each dimension of gradients, which allows for deriving the dimension-wise information entropy. The sum of all entropy is computed as the total entropy of updates for the current training round. Then for each participating client, their information gain is defined as the difference between the original total entropy and the total entropy with this client being removed. Clients with largest information gains are considered as malicious and hence excluded from the aggregation. The intuition behind ELITE is that benign gradients tend to roughly point at the same direction, namely the direction of the optimal gradient, whereas malicious gradients tend to point at rather different directions. When the majority of clients are benign, removing malicious gradients results in less total entropy as the uncertainty of gradients is reduced.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Defense Against Free-Rider Attacks</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Since the objective of free-rider attacks is to obtain the global model in the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> system, free-rider clients need to upload their own local model such that they can pretend to be benign clients. Free-rider models are constructed with minimum cost. The free-rider can simply upload their received global model to the server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, or Gaussian noise may be added to the received model before uploading <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. The key of defending against free-rider attacks is to identify which clients submit free-rider models. Existing defenses can be categorized into watermarking methods and anomaly detection methods. Watermarking methods incorporate watermark learning tasks on clients, while anomaly detection approaches are learned on the server. If a client model fails to trigger watermarked behaviors or being classified as an anomaly, such client is considered as a free-rider.</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p">Watermarking neural networks has been studied in the centralized setting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> to verify the ownership of deep neural networks. Watermarks are commonly embedded into intermediate features or backdoored test samples. In the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> scenario, WAFFLE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> is an early work of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> watermarking in which the server embeds watermarks by retraining the aggregated model with backdoored samples. However, watermarking on the server side is not suitable for defending against free-rider attacks, as the free-rider model is identical to the global model. FedIPR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> addresses the problem by generating secret watermarks on clients. At the initialization stage of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>, FedIPR requires each client to generate their own trigger dataset, watermark embedding matrix and the location of watermarks. In addition to the primary learning task, local models now learns to embed watermarks in both the intermediate features and local trigger set. In the verification stage, client models are fed with their respective trigger set. If the detection error of trigger samples is smaller than a given threshold, this client passes the verification. FedIPR also verifies feature-based watermarks by evaluating the Hamming distance between the watermark in the global model and local secret watermark. One major challenge of FedIPR is that clients may generate conflicting watermarks. Authors of FedIPR proves that different client watermarks can be embedded without conflicts when the total bit-length of watermarks is bounded by the channel number of the global model. If the bit-length exceeds the threshold, FedIPR also gives a lower bound for detecting watermarks.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p">Anomaly detection based free-rider defense are inspired by anomaly detection approaches in the centralized setting, such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. Authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> concatenate client updates on the server to train an auto-encoder. The auto-encoder learns to reconstruct received client updates. In the verification stage, if the reconstruction error induced by updates from one client is larger than then given threshold, this client is deemed as a free-rider. Another approach proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> is using DAGMM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> instead of the vanilla auto-encoder. DAGMM detects anomaly data by feeding the latent representation of the auto-encoder to a Gaussian mixture network to estimate the likelihood of the representation being abnormal.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Model to Data Attacks</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we will introduce the Model to Data (M2D) attacks in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>, which is to reveal a specific attribute, partial or full of the data. We summarized the methods to be non-gradient-based leakage and gradient-based data leakage.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2311.16065/assets/x5.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="140" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> Attack.</figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Non-Gradient-Based Data Leakage</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We define non-gradient-based data leakage as the disclosure of private information that occurs independently of the gradient generated during the training stage. For instance, the leakage can involve identifying specific attributes or membership details within the training data, or recovering original training images from obscured or masked versions. Typically, such leakage exploits the capabilities of a well-trained model to execute these attacks.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Attribute Inference</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">The paper¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite> is one of the earliest works that targets the leakage of private information from an  <span title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Machine Learning</span></span> (<abbr title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ML</span></abbr>) model. In this paper, the authors construct a novel meta-classifier that is used to attack other <abbr title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ML</span></abbr> classifiers with the aim of revealing sensitive information from the training data. This is considered a white-box attack, as the adversary has knowledge of both the structure and the parameters of the target model. Specifically, the method assumes full access to a well-trained target model and pre-sets a particular attribute to be identified, determining whether or not it exists in the training data. To do this, the authors first create multiple synthetic training datasets, some of which partially contain the pre-set attributes, while the rest do not. They then train several classification models on these synthetic datasets; the architecture of these classification models is identical to that of the target model. Subsequently, the parameters of these classification models are used as input for training the meta-classifier. Finally, the parameters from the well-trained target model are fed into this meta-classifier to determine if the particular attribute exists in the training data. Both the target model and the meta-classifier are <abbr title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ML</span></abbr> models, <em id="S5.SS1.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>,  <span title="Artificial Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Artificial Neural Network</span></span> (<abbr title="Artificial Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ANN</span></abbr>),  <span title="Hidden Markov Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Hidden Markov Model</span></span> (<abbr title="Hidden Markov Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">HMM</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>,  <span title="Support Vector Machine" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Support Vector Machine</span></span> (<abbr title="Support Vector Machine" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SVM</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, or  <span title="Decision Tree" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Decision Tree</span></span> (<abbr title="Decision Tree" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DT</span></abbr>). The authors provide two example cases to evaluate their method. In one example, they identify the speaker‚Äôs nationality using a speech recognition dataset processed by an <abbr title="Hidden Markov Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">HMM</span></abbr>. Later, they use an <abbr title="Support Vector Machine" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">SVM</span></abbr> to set up a network traffic classifier to distinguish between two kinds of traffic conditions, using the meta-classifier to identify the type of traffic. In both examples, the meta-classifiers are <abbr title="Decision Tree" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DT</span></abbr>s.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Membership Identification</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">The above work is further improved by¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>, who focus on membership identification attacks. They propose a shadow training technique to identify whether specific samples are part of the training dataset. The membership inference problem is formulated as a classification task. An attack model is trained to distinguish between the behavior of shadow models when fed with forged training data. These shadow models are designed to behave similarly to the target model. The approach qualifies as a black-box attack, meaning that the attacker only possesses knowledge of the output for a given input. Several effective methods have been developed for generating forged training data for the shadow models. The first method utilizes black-box access to the target model to synthesize the data. The second method leverages statistical information related to the target model‚Äôs training dataset. In the third method, it is assumed that the adversary has access to a noisy version of the target model‚Äôs training dataset. While the first method operates without assuming any prior knowledge about the distribution of the target model‚Äôs training data, the second and third methods allow the attacker to query the target model just once before determining whether a particular record was part of its training dataset.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Image Recovery</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">In terms of recovering valuable information from obfuscated images, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> is one of the earliest works to the best of our knowledge. Obfuscated images are easily accessible through various data protection techniques (<em id="S5.SS1.SSS3.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, blur, mask, corrupt, and P3)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. In the study¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>, the authors utilized a <abbr title="Deep Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DL</span></abbr> model to recover valuable information from obfuscated images for classification tasks. They assumed that the adversary has access to a portion of the original training data and applied one of the encryption methods to those images to train the attack model. For this reason, their method is generally not suitable for most real-world scenarios.</p>
</div>
<div id="S5.SS1.SSS3.p2" class="ltx_para">
<p id="S5.SS1.SSS3.p2.1" class="ltx_p">To demonstrate how neural networks can overcome privacy protection measures, they employed four commonly used datasets for recognizing faces, objects, and handwritten digits. Each of these tasks carries substantial privacy concerns. For instance, the successful identification of a face could infringe upon the privacy of an individual featured in a captured video. Recognizing digits could enable the deduction of written text content or vehicular registration numbers.</p>
</div>
<div id="S5.SS1.SSS3.p3" class="ltx_para">
<p id="S5.SS1.SSS3.p3.4" class="ltx_p">The final results are impressive. On the MNIST¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> dataset, they achieved an accuracy of about 80% for images encrypted by P3 with a recommended threshold level of 20. Conversely, the accuracy exceeds 80% when the images are masked by windows of resolution <math id="S5.SS1.SSS3.p3.1.m1.1" class="ltx_Math" alttext="8\times 8" display="inline"><semantics id="S5.SS1.SSS3.p3.1.m1.1a"><mrow id="S5.SS1.SSS3.p3.1.m1.1.1" xref="S5.SS1.SSS3.p3.1.m1.1.1.cmml"><mn id="S5.SS1.SSS3.p3.1.m1.1.1.2" xref="S5.SS1.SSS3.p3.1.m1.1.1.2.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS3.p3.1.m1.1.1.1" xref="S5.SS1.SSS3.p3.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.SS1.SSS3.p3.1.m1.1.1.3" xref="S5.SS1.SSS3.p3.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.1.m1.1b"><apply id="S5.SS1.SSS3.p3.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1"><times id="S5.SS1.SSS3.p3.1.m1.1.1.1.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.1"></times><cn type="integer" id="S5.SS1.SSS3.p3.1.m1.1.1.2.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.2">8</cn><cn type="integer" id="S5.SS1.SSS3.p3.1.m1.1.1.3.cmml" xref="S5.SS1.SSS3.p3.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.1.m1.1c">8\times 8</annotation></semantics></math>. On the CIFAR-10¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> dataset, only vehicle and animal images were used for experiments, achieving an accuracy of 75% against P3 with a threshold of 20. When deploying a <math id="S5.SS1.SSS3.p3.2.m2.1" class="ltx_Math" alttext="4\times 4" display="inline"><semantics id="S5.SS1.SSS3.p3.2.m2.1a"><mrow id="S5.SS1.SSS3.p3.2.m2.1.1" xref="S5.SS1.SSS3.p3.2.m2.1.1.cmml"><mn id="S5.SS1.SSS3.p3.2.m2.1.1.2" xref="S5.SS1.SSS3.p3.2.m2.1.1.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS3.p3.2.m2.1.1.1" xref="S5.SS1.SSS3.p3.2.m2.1.1.1.cmml">√ó</mo><mn id="S5.SS1.SSS3.p3.2.m2.1.1.3" xref="S5.SS1.SSS3.p3.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.2.m2.1b"><apply id="S5.SS1.SSS3.p3.2.m2.1.1.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1"><times id="S5.SS1.SSS3.p3.2.m2.1.1.1.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.1"></times><cn type="integer" id="S5.SS1.SSS3.p3.2.m2.1.1.2.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.2">4</cn><cn type="integer" id="S5.SS1.SSS3.p3.2.m2.1.1.3.cmml" xref="S5.SS1.SSS3.p3.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.2.m2.1c">4\times 4</annotation></semantics></math> mask on the images, the accuracy is approximately 70%, and it drops to 50% when masking with <math id="S5.SS1.SSS3.p3.3.m3.1" class="ltx_Math" alttext="8\times 8" display="inline"><semantics id="S5.SS1.SSS3.p3.3.m3.1a"><mrow id="S5.SS1.SSS3.p3.3.m3.1.1" xref="S5.SS1.SSS3.p3.3.m3.1.1.cmml"><mn id="S5.SS1.SSS3.p3.3.m3.1.1.2" xref="S5.SS1.SSS3.p3.3.m3.1.1.2.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS3.p3.3.m3.1.1.1" xref="S5.SS1.SSS3.p3.3.m3.1.1.1.cmml">√ó</mo><mn id="S5.SS1.SSS3.p3.3.m3.1.1.3" xref="S5.SS1.SSS3.p3.3.m3.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.3.m3.1b"><apply id="S5.SS1.SSS3.p3.3.m3.1.1.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1"><times id="S5.SS1.SSS3.p3.3.m3.1.1.1.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.1"></times><cn type="integer" id="S5.SS1.SSS3.p3.3.m3.1.1.2.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.2">8</cn><cn type="integer" id="S5.SS1.SSS3.p3.3.m3.1.1.3.cmml" xref="S5.SS1.SSS3.p3.3.m3.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.3.m3.1c">8\times 8</annotation></semantics></math> resolution. On the AT&amp;T¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite> dataset, the proposed method achieved a remarkable accuracy of 97% against P3 with a threshold of 20, over 95% against various mask sizes, and 57% against face blurring. On the FaceScrub¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> dataset, they achieved an accuracy of 57% against masking the face with a <math id="S5.SS1.SSS3.p3.4.m4.1" class="ltx_Math" alttext="16\times 16" display="inline"><semantics id="S5.SS1.SSS3.p3.4.m4.1a"><mrow id="S5.SS1.SSS3.p3.4.m4.1.1" xref="S5.SS1.SSS3.p3.4.m4.1.1.cmml"><mn id="S5.SS1.SSS3.p3.4.m4.1.1.2" xref="S5.SS1.SSS3.p3.4.m4.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS1.SSS3.p3.4.m4.1.1.1" xref="S5.SS1.SSS3.p3.4.m4.1.1.1.cmml">√ó</mo><mn id="S5.SS1.SSS3.p3.4.m4.1.1.3" xref="S5.SS1.SSS3.p3.4.m4.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p3.4.m4.1b"><apply id="S5.SS1.SSS3.p3.4.m4.1.1.cmml" xref="S5.SS1.SSS3.p3.4.m4.1.1"><times id="S5.SS1.SSS3.p3.4.m4.1.1.1.cmml" xref="S5.SS1.SSS3.p3.4.m4.1.1.1"></times><cn type="integer" id="S5.SS1.SSS3.p3.4.m4.1.1.2.cmml" xref="S5.SS1.SSS3.p3.4.m4.1.1.2">16</cn><cn type="integer" id="S5.SS1.SSS3.p3.4.m4.1.1.3.cmml" xref="S5.SS1.SSS3.p3.4.m4.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p3.4.m4.1c">16\times 16</annotation></semantics></math> window and 40% against P3 with a threshold of 20.</p>
</div>
<div id="S5.SS1.SSS3.p4" class="ltx_para">
<p id="S5.SS1.SSS3.p4.1" class="ltx_p">In more recent work¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>, the authors utilize a <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr>, trained on a public dataset, to recover missing sensitive regions in images; this is termed the  <span title="Generative Model-Inversion" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Generative Model-Inversion</span></span> (<abbr title="Generative Model-Inversion" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GMI</span></abbr>) attack, as shown in Figure¬†<a href="#S5.F6" title="Figure 6 ‚Ä£ 5.1.3 Image Recovery ‚Ä£ 5.1 Non-Gradient-Based Data Leakage ‚Ä£ 5 Model to Data Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. A diversity loss is proposed to encourage diversity in the images synthesized by the generator when projected into the target network‚Äôs feature space. This is essential during the training of the <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr> on the public dataset because the adversary aims for the generated images to be distinct in the feature space of the target model. If different images map to the same feature space, the adversary cannot discern which generated image corresponds to the private data‚Äôs features, thus failing to reveal the private information.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2311.16065/assets/GMI.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Overview of the <abbr title="Generative Model-Inversion" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GMI</span></abbr> attack method. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite></figcaption>
</figure>
<div id="S5.SS1.SSS3.p5" class="ltx_para">
<p id="S5.SS1.SSS3.p5.1" class="ltx_p">The authors assume that the adversary has access to the well-trained target model, which serves as a discriminator, as well as to the target label of the input corrupted image. Initially, the generator is used to create an image, which is then fed into two separate discriminators to calculate the prior loss and identity loss. In subsequent rounds, these two losses, along with the corrupted image, are used as inputs for the generator to produce the next iteration of the reconstructed image. Upon completing the training of the <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr>, the adversary, during the reveal phase, only needs to continue optimizing the generator‚Äôs inputs so that the generated images are sufficiently realistic while also maximizing likelihood in the target model.</p>
</div>
<div id="S5.SS1.SSS3.p6" class="ltx_para">
<p id="S5.SS1.SSS3.p6.1" class="ltx_p">The datasets employed for evaluation are MNIST¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, ChestX-ray8¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, and CelebA¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. The experimental results indicate that without using the corrupted image as an input for the generator, the attack‚Äôs success rate is approximately 28%, 44%, and 46% on target networks VGG-16¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>, ResNet-152¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>, and face.evoLVe¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, respectively. However, when the corrupted image is incorporated, the accuracy increases to 43%, 50%, and 51% for blurred input images; 78%, 80%, and 82% for center-masked images; and 58%, 63%, and 64% for face T-masked images. Consequently, the inclusion of corrupted images as auxiliary information has a significant impact on the attack‚Äôs accuracy.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Gradient-Based Data Leakage</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Concerning gradient-based data leakage, this refers to techniques that exploit gradients from the target model to expose privacy-sensitive information. <abbr title="Deep Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DL</span></abbr> models are trained on datasets, and parameter updates occur through alignment with the feature space. This establishes an inherent relationship between the weights or gradients and the dataset. Consequently, numerous studies aim to reveal private information by leveraging these gradients. The effectiveness and success rates of gradient-based approaches have consistently surpassed those of non-gradient-based methods. Unlike non-gradient-based leakage, gradient-based data leakage can occur even in models that have not yet converged.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Partial Recovery</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Hitaj <em id="S5.SS2.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> proposed a data recovery method that utilizes a trained victim model and a target label. The method aims to generate new data closely resembling the distribution of the training dataset. This attack is formulated as a generative process using a <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr>. In a <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> system, an attacker can pose as a participant to reveal private data from the victim by modeling the feature space. Suppose the attacker masquerades as a malicious participant with a portion of training samples that have correct labels, along with a portion of samples generated via <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr> with incorrect labels. The attacker‚Äôs goal is to produce a dataset that shares the same feature distribution as the other participants, leveraging <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr> and the global gradients downloaded from the parameter server.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p">In Algorithm¬†<a href="#alg2" title="Algorithm 2 ‚Ä£ 5.2.1 Partial Recovery ‚Ä£ 5.2 Gradient-Based Data Leakage ‚Ä£ 5 Model to Data Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the victim trains its local model on its own dataset for several iterations until it achieves an accuracy beyond a preset threshold. Subsequently, the malicious actor uses the updated local model as the discriminator. The weights in the discriminator are fixed, and a generator is trained to maximize the confidence of a specific class. This is an indirect data recovery method, sensitive to the variance in the victim‚Äôs training data¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>. Although the generated images are consistent with the data distribution, they do not correspond to the actual training dataset. In other words, the generated images cannot be mapped back to the training data.</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para">
<p id="S5.SS2.SSS1.p3.1" class="ltx_p">Another related work by  <span title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Generative Gradient Leakage</span></span> (<abbr title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GGL</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite> also employs a <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr> to generate fake data. In this approach, the weights of the <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr> are pretrained and fixed, while the trainable parameters in <abbr title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GGL</span></abbr> are the input sequences to the <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr>. The label inference part is adapted from  <span title="Improved DLG" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Improved DLG</span></span> (<abbr title="Improved DLG" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">iDLG</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>, requiring a batch size of 1. Unlike other methods, <abbr title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GGL</span></abbr> uses  <span title="Covariance Matrix Adaptation Evolution Strategy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Covariance Matrix Adaptation Evolution Strategy</span></span> (<abbr title="Covariance Matrix Adaptation Evolution Strategy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CMA-ES</span></abbr>) and  <span title="Bayesian Optimization" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Bayesian Optimization</span></span> (<abbr title="Bayesian Optimization" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BO</span></abbr>) as optimizers to reduce the variability in the generated data. Although the data generated by <abbr title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GGL</span></abbr> is not identical to true data, it is sufficiently similar (see Table¬†<a href="#S5.T6" title="Table 6 ‚Ä£ 5.2.1 Partial Recovery ‚Ä£ 5.2 Gradient-Based Data Leakage ‚Ä£ 5 Model to Data Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>), providing <abbr title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GGL</span></abbr> with robustness against various defense strategies like gradient noising, clipping, or compression. The generated images are influenced by two factors: 1) the inferred ground-truth label, which specifies the image classification, and 2) fine-tuning based on gradient information to make the image as similar as possible to the true image.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Typical experimental results performed on <abbr title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GGL</span></abbr> are shown below. The backbone network is <em id="S5.T6.39.1" class="ltx_emph ltx_font_italic">ResNet-18</em> and the dataset is ILSVRC2012 with a resolution of <math id="S5.T6.2.2.m1.1" class="ltx_Math" alttext="256*256" display="inline"><semantics id="S5.T6.2.2.m1.1b"><mrow id="S5.T6.2.2.m1.1.1" xref="S5.T6.2.2.m1.1.1.cmml"><mn id="S5.T6.2.2.m1.1.1.2" xref="S5.T6.2.2.m1.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T6.2.2.m1.1.1.1" xref="S5.T6.2.2.m1.1.1.1.cmml">‚àó</mo><mn id="S5.T6.2.2.m1.1.1.3" xref="S5.T6.2.2.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.m1.1c"><apply id="S5.T6.2.2.m1.1.1.cmml" xref="S5.T6.2.2.m1.1.1"><times id="S5.T6.2.2.m1.1.1.1.cmml" xref="S5.T6.2.2.m1.1.1.1"></times><cn type="integer" id="S5.T6.2.2.m1.1.1.2.cmml" xref="S5.T6.2.2.m1.1.1.2">256</cn><cn type="integer" id="S5.T6.2.2.m1.1.1.3.cmml" xref="S5.T6.2.2.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.m1.1d">256*256</annotation></semantics></math>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite></figcaption>
<table id="S5.T6.37.37" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T6.37.37.36" class="ltx_tr">
<td id="S5.T6.37.37.36.1" class="ltx_td"></td>
<td id="S5.T6.37.37.36.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.37.37.36.2.1" class="ltx_text ltx_font_bold">Ground True</span></td>
<td id="S5.T6.37.37.36.3" class="ltx_td ltx_align_center" colspan="4">Generated Images</td>
</tr>
<tr id="S5.T6.7.7.5" class="ltx_tr">
<td id="S5.T6.7.7.5.6" class="ltx_td ltx_align_left">
<div id="S5.T6.7.7.5.6.1" class="ltx_inline-block ltx_align_top ltx_transformed_outer" style="width:8.9pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:54.0pt;transform:translate(-22.54pt,-21.57pt) rotate(-90deg) ;">
<p id="S5.T6.7.7.5.6.1.1" class="ltx_p"><span id="S5.T6.7.7.5.6.1.1.1" class="ltx_text ltx_font_bold">black grouse</span></p>
</span></div>
</td>
<td id="S5.T6.3.3.1.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T6.3.3.1.1.2" class="ltx_text"></span> <span id="S5.T6.3.3.1.1.1" class="ltx_text">
<span id="S5.T6.3.3.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.3.3.1.1.1.1.1.1" class="ltx_tr">
<span id="S5.T6.3.3.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/1/true.png" id="S5.T6.3.3.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.3.3.1.1.3" class="ltx_text"></span></td>
<td id="S5.T6.4.4.2.2" class="ltx_td ltx_align_center">
<span id="S5.T6.4.4.2.2.2" class="ltx_text"></span> <span id="S5.T6.4.4.2.2.1" class="ltx_text">
<span id="S5.T6.4.4.2.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.4.4.2.2.1.1.1.1" class="ltx_tr">
<span id="S5.T6.4.4.2.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/1/without_1.png" id="S5.T6.4.4.2.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.4.4.2.2.3" class="ltx_text"></span></td>
<td id="S5.T6.5.5.3.3" class="ltx_td ltx_align_center">
<span id="S5.T6.5.5.3.3.2" class="ltx_text"></span> <span id="S5.T6.5.5.3.3.1" class="ltx_text">
<span id="S5.T6.5.5.3.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.5.5.3.3.1.1.1.1" class="ltx_tr">
<span id="S5.T6.5.5.3.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/1/without_2.png" id="S5.T6.5.5.3.3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.5.5.3.3.3" class="ltx_text"></span></td>
<td id="S5.T6.6.6.4.4" class="ltx_td ltx_align_center">
<span id="S5.T6.6.6.4.4.2" class="ltx_text"></span> <span id="S5.T6.6.6.4.4.1" class="ltx_text">
<span id="S5.T6.6.6.4.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.6.6.4.4.1.1.1.1" class="ltx_tr">
<span id="S5.T6.6.6.4.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/1/without_3.png" id="S5.T6.6.6.4.4.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.6.6.4.4.3" class="ltx_text"></span></td>
<td id="S5.T6.7.7.5.5" class="ltx_td ltx_align_center">
<span id="S5.T6.7.7.5.5.2" class="ltx_text"></span> <span id="S5.T6.7.7.5.5.1" class="ltx_text">
<span id="S5.T6.7.7.5.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.7.7.5.5.1.1.1.1" class="ltx_tr">
<span id="S5.T6.7.7.5.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/1/without_4.png" id="S5.T6.7.7.5.5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.7.7.5.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T6.12.12.10" class="ltx_tr">
<td id="S5.T6.12.12.10.6" class="ltx_td ltx_align_left">
<div id="S5.T6.12.12.10.6.1" class="ltx_inline-block ltx_align_top ltx_transformed_outer" style="width:8.9pt;height:49.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:49.2pt;transform:translate(-20.15pt,-19.18pt) rotate(-90deg) ;">
<p id="S5.T6.12.12.10.6.1.1" class="ltx_p"><span id="S5.T6.12.12.10.6.1.1.1" class="ltx_text ltx_font_bold">tiger beetle</span></p>
</span></div>
</td>
<td id="S5.T6.8.8.6.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T6.8.8.6.1.2" class="ltx_text"></span> <span id="S5.T6.8.8.6.1.1" class="ltx_text">
<span id="S5.T6.8.8.6.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.8.8.6.1.1.1.1.1" class="ltx_tr">
<span id="S5.T6.8.8.6.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/2/true.png" id="S5.T6.8.8.6.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.8.8.6.1.3" class="ltx_text"></span></td>
<td id="S5.T6.9.9.7.2" class="ltx_td ltx_align_center">
<span id="S5.T6.9.9.7.2.2" class="ltx_text"></span> <span id="S5.T6.9.9.7.2.1" class="ltx_text">
<span id="S5.T6.9.9.7.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.9.9.7.2.1.1.1.1" class="ltx_tr">
<span id="S5.T6.9.9.7.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/2/without_1.png" id="S5.T6.9.9.7.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.9.9.7.2.3" class="ltx_text"></span></td>
<td id="S5.T6.10.10.8.3" class="ltx_td ltx_align_center">
<span id="S5.T6.10.10.8.3.2" class="ltx_text"></span> <span id="S5.T6.10.10.8.3.1" class="ltx_text">
<span id="S5.T6.10.10.8.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.10.10.8.3.1.1.1.1" class="ltx_tr">
<span id="S5.T6.10.10.8.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/2/without_2.png" id="S5.T6.10.10.8.3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.10.10.8.3.3" class="ltx_text"></span></td>
<td id="S5.T6.11.11.9.4" class="ltx_td ltx_align_center">
<span id="S5.T6.11.11.9.4.2" class="ltx_text"></span> <span id="S5.T6.11.11.9.4.1" class="ltx_text">
<span id="S5.T6.11.11.9.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.11.11.9.4.1.1.1.1" class="ltx_tr">
<span id="S5.T6.11.11.9.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/2/without_3.png" id="S5.T6.11.11.9.4.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.11.11.9.4.3" class="ltx_text"></span></td>
<td id="S5.T6.12.12.10.5" class="ltx_td ltx_align_center">
<span id="S5.T6.12.12.10.5.2" class="ltx_text"></span> <span id="S5.T6.12.12.10.5.1" class="ltx_text">
<span id="S5.T6.12.12.10.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.12.12.10.5.1.1.1.1" class="ltx_tr">
<span id="S5.T6.12.12.10.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/2/without_4.png" id="S5.T6.12.12.10.5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.12.12.10.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T6.17.17.15" class="ltx_tr">
<td id="S5.T6.17.17.15.6" class="ltx_td ltx_align_left">
<div id="S5.T6.17.17.15.6.1" class="ltx_inline-block ltx_align_top ltx_transformed_outer" style="width:8.9pt;height:55.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:55.3pt;transform:translate(-23.19pt,-22.22pt) rotate(-90deg) ;">
<p id="S5.T6.17.17.15.6.1.1" class="ltx_p"><span id="S5.T6.17.17.15.6.1.1.1" class="ltx_text ltx_font_bold">cliff dwelling</span></p>
</span></div>
</td>
<td id="S5.T6.13.13.11.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T6.13.13.11.1.2" class="ltx_text"></span> <span id="S5.T6.13.13.11.1.1" class="ltx_text">
<span id="S5.T6.13.13.11.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.13.13.11.1.1.1.1.1" class="ltx_tr">
<span id="S5.T6.13.13.11.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/3/true.png" id="S5.T6.13.13.11.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.13.13.11.1.3" class="ltx_text"></span></td>
<td id="S5.T6.14.14.12.2" class="ltx_td ltx_align_center">
<span id="S5.T6.14.14.12.2.2" class="ltx_text"></span> <span id="S5.T6.14.14.12.2.1" class="ltx_text">
<span id="S5.T6.14.14.12.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.14.14.12.2.1.1.1.1" class="ltx_tr">
<span id="S5.T6.14.14.12.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/3/without_1.png" id="S5.T6.14.14.12.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.14.14.12.2.3" class="ltx_text"></span></td>
<td id="S5.T6.15.15.13.3" class="ltx_td ltx_align_center">
<span id="S5.T6.15.15.13.3.2" class="ltx_text"></span> <span id="S5.T6.15.15.13.3.1" class="ltx_text">
<span id="S5.T6.15.15.13.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.15.15.13.3.1.1.1.1" class="ltx_tr">
<span id="S5.T6.15.15.13.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/3/without_2.png" id="S5.T6.15.15.13.3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.15.15.13.3.3" class="ltx_text"></span></td>
<td id="S5.T6.16.16.14.4" class="ltx_td ltx_align_center">
<span id="S5.T6.16.16.14.4.2" class="ltx_text"></span> <span id="S5.T6.16.16.14.4.1" class="ltx_text">
<span id="S5.T6.16.16.14.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.16.16.14.4.1.1.1.1" class="ltx_tr">
<span id="S5.T6.16.16.14.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/3/without_3.png" id="S5.T6.16.16.14.4.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.16.16.14.4.3" class="ltx_text"></span></td>
<td id="S5.T6.17.17.15.5" class="ltx_td ltx_align_center">
<span id="S5.T6.17.17.15.5.2" class="ltx_text"></span> <span id="S5.T6.17.17.15.5.1" class="ltx_text">
<span id="S5.T6.17.17.15.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.17.17.15.5.1.1.1.1" class="ltx_tr">
<span id="S5.T6.17.17.15.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/3/without_4.png" id="S5.T6.17.17.15.5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.17.17.15.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T6.22.22.20" class="ltx_tr">
<td id="S5.T6.22.22.20.6" class="ltx_td ltx_align_left">
<div id="S5.T6.22.22.20.6.1" class="ltx_inline-block ltx_align_top ltx_transformed_outer" style="width:6.9pt;height:57.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:57.3pt;transform:translate(-25.19pt,-25.19pt) rotate(-90deg) ;">
<p id="S5.T6.22.22.20.6.1.1" class="ltx_p"><span id="S5.T6.22.22.20.6.1.1.1" class="ltx_text ltx_font_bold">basset hound</span></p>
</span></div>
</td>
<td id="S5.T6.18.18.16.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T6.18.18.16.1.2" class="ltx_text"></span> <span id="S5.T6.18.18.16.1.1" class="ltx_text">
<span id="S5.T6.18.18.16.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.18.18.16.1.1.1.1.1" class="ltx_tr">
<span id="S5.T6.18.18.16.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/4/true.png" id="S5.T6.18.18.16.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.18.18.16.1.3" class="ltx_text"></span></td>
<td id="S5.T6.19.19.17.2" class="ltx_td ltx_align_center">
<span id="S5.T6.19.19.17.2.2" class="ltx_text"></span> <span id="S5.T6.19.19.17.2.1" class="ltx_text">
<span id="S5.T6.19.19.17.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.19.19.17.2.1.1.1.1" class="ltx_tr">
<span id="S5.T6.19.19.17.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/4/without_1.png" id="S5.T6.19.19.17.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.19.19.17.2.3" class="ltx_text"></span></td>
<td id="S5.T6.20.20.18.3" class="ltx_td ltx_align_center">
<span id="S5.T6.20.20.18.3.2" class="ltx_text"></span> <span id="S5.T6.20.20.18.3.1" class="ltx_text">
<span id="S5.T6.20.20.18.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.20.20.18.3.1.1.1.1" class="ltx_tr">
<span id="S5.T6.20.20.18.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/4/without_2.png" id="S5.T6.20.20.18.3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.20.20.18.3.3" class="ltx_text"></span></td>
<td id="S5.T6.21.21.19.4" class="ltx_td ltx_align_center">
<span id="S5.T6.21.21.19.4.2" class="ltx_text"></span> <span id="S5.T6.21.21.19.4.1" class="ltx_text">
<span id="S5.T6.21.21.19.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.21.21.19.4.1.1.1.1" class="ltx_tr">
<span id="S5.T6.21.21.19.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/4/without_3.png" id="S5.T6.21.21.19.4.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.21.21.19.4.3" class="ltx_text"></span></td>
<td id="S5.T6.22.22.20.5" class="ltx_td ltx_align_center">
<span id="S5.T6.22.22.20.5.2" class="ltx_text"></span> <span id="S5.T6.22.22.20.5.1" class="ltx_text">
<span id="S5.T6.22.22.20.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.22.22.20.5.1.1.1.1" class="ltx_tr">
<span id="S5.T6.22.22.20.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/4/without_4.png" id="S5.T6.22.22.20.5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.22.22.20.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T6.27.27.25" class="ltx_tr">
<td id="S5.T6.27.27.25.6" class="ltx_td ltx_align_left">
<div id="S5.T6.27.27.25.6.1" class="ltx_inline-block ltx_align_top ltx_transformed_outer" style="width:6.9pt;height:44.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:44.3pt;transform:translate(-18.68pt,-18.68pt) rotate(-90deg) ;">
<p id="S5.T6.27.27.25.6.1.1" class="ltx_p"><span id="S5.T6.27.27.25.6.1.1.1" class="ltx_text ltx_font_bold">sweatshirt</span></p>
</span></div>
</td>
<td id="S5.T6.23.23.21.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T6.23.23.21.1.2" class="ltx_text"></span> <span id="S5.T6.23.23.21.1.1" class="ltx_text">
<span id="S5.T6.23.23.21.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.23.23.21.1.1.1.1.1" class="ltx_tr">
<span id="S5.T6.23.23.21.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/5/true.png" id="S5.T6.23.23.21.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.23.23.21.1.3" class="ltx_text"></span></td>
<td id="S5.T6.24.24.22.2" class="ltx_td ltx_align_center">
<span id="S5.T6.24.24.22.2.2" class="ltx_text"></span> <span id="S5.T6.24.24.22.2.1" class="ltx_text">
<span id="S5.T6.24.24.22.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.24.24.22.2.1.1.1.1" class="ltx_tr">
<span id="S5.T6.24.24.22.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/5/without_1.png" id="S5.T6.24.24.22.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.24.24.22.2.3" class="ltx_text"></span></td>
<td id="S5.T6.25.25.23.3" class="ltx_td ltx_align_center">
<span id="S5.T6.25.25.23.3.2" class="ltx_text"></span> <span id="S5.T6.25.25.23.3.1" class="ltx_text">
<span id="S5.T6.25.25.23.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.25.25.23.3.1.1.1.1" class="ltx_tr">
<span id="S5.T6.25.25.23.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/5/without_2.png" id="S5.T6.25.25.23.3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.25.25.23.3.3" class="ltx_text"></span></td>
<td id="S5.T6.26.26.24.4" class="ltx_td ltx_align_center">
<span id="S5.T6.26.26.24.4.2" class="ltx_text"></span> <span id="S5.T6.26.26.24.4.1" class="ltx_text">
<span id="S5.T6.26.26.24.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.26.26.24.4.1.1.1.1" class="ltx_tr">
<span id="S5.T6.26.26.24.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/5/without_3.png" id="S5.T6.26.26.24.4.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.26.26.24.4.3" class="ltx_text"></span></td>
<td id="S5.T6.27.27.25.5" class="ltx_td ltx_align_center">
<span id="S5.T6.27.27.25.5.2" class="ltx_text"></span> <span id="S5.T6.27.27.25.5.1" class="ltx_text">
<span id="S5.T6.27.27.25.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.27.27.25.5.1.1.1.1" class="ltx_tr">
<span id="S5.T6.27.27.25.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/5/without_4.png" id="S5.T6.27.27.25.5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.27.27.25.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T6.32.32.30" class="ltx_tr">
<td id="S5.T6.32.32.30.6" class="ltx_td ltx_align_left">
<div id="S5.T6.32.32.30.6.1" class="ltx_inline-block ltx_align_top ltx_transformed_outer" style="width:8.9pt;height:60.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:60.1pt;transform:translate(-25.6pt,-24.63pt) rotate(-90deg) ;">
<p id="S5.T6.32.32.30.6.1.1" class="ltx_p"><span id="S5.T6.32.32.30.6.1.1.1" class="ltx_text ltx_font_bold">radiator grille</span></p>
</span></div>
</td>
<td id="S5.T6.28.28.26.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T6.28.28.26.1.2" class="ltx_text"></span> <span id="S5.T6.28.28.26.1.1" class="ltx_text">
<span id="S5.T6.28.28.26.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.28.28.26.1.1.1.1.1" class="ltx_tr">
<span id="S5.T6.28.28.26.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/6/true.png" id="S5.T6.28.28.26.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.28.28.26.1.3" class="ltx_text"></span></td>
<td id="S5.T6.29.29.27.2" class="ltx_td ltx_align_center">
<span id="S5.T6.29.29.27.2.2" class="ltx_text"></span> <span id="S5.T6.29.29.27.2.1" class="ltx_text">
<span id="S5.T6.29.29.27.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.29.29.27.2.1.1.1.1" class="ltx_tr">
<span id="S5.T6.29.29.27.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/6/without_1.png" id="S5.T6.29.29.27.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.29.29.27.2.3" class="ltx_text"></span></td>
<td id="S5.T6.30.30.28.3" class="ltx_td ltx_align_center">
<span id="S5.T6.30.30.28.3.2" class="ltx_text"></span> <span id="S5.T6.30.30.28.3.1" class="ltx_text">
<span id="S5.T6.30.30.28.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.30.30.28.3.1.1.1.1" class="ltx_tr">
<span id="S5.T6.30.30.28.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/6/without_2.png" id="S5.T6.30.30.28.3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.30.30.28.3.3" class="ltx_text"></span></td>
<td id="S5.T6.31.31.29.4" class="ltx_td ltx_align_center">
<span id="S5.T6.31.31.29.4.2" class="ltx_text"></span> <span id="S5.T6.31.31.29.4.1" class="ltx_text">
<span id="S5.T6.31.31.29.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.31.31.29.4.1.1.1.1" class="ltx_tr">
<span id="S5.T6.31.31.29.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/6/without_3.png" id="S5.T6.31.31.29.4.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.31.31.29.4.3" class="ltx_text"></span></td>
<td id="S5.T6.32.32.30.5" class="ltx_td ltx_align_center">
<span id="S5.T6.32.32.30.5.2" class="ltx_text"></span> <span id="S5.T6.32.32.30.5.1" class="ltx_text">
<span id="S5.T6.32.32.30.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.32.32.30.5.1.1.1.1" class="ltx_tr">
<span id="S5.T6.32.32.30.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/6/without_4.png" id="S5.T6.32.32.30.5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.32.32.30.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T6.37.37.35" class="ltx_tr">
<td id="S5.T6.37.37.35.6" class="ltx_td ltx_align_left">
<div id="S5.T6.37.37.35.6.1" class="ltx_inline-block ltx_align_top ltx_transformed_outer" style="width:8.6pt;height:13.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:13.3pt;transform:translate(-2.36pt,-1.38pt) rotate(-90deg) ;">
<p id="S5.T6.37.37.35.6.1.1" class="ltx_p"><span id="S5.T6.37.37.35.6.1.1.1" class="ltx_text ltx_font_bold">pig</span></p>
</span></div>
</td>
<td id="S5.T6.33.33.31.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T6.33.33.31.1.2" class="ltx_text"></span> <span id="S5.T6.33.33.31.1.1" class="ltx_text">
<span id="S5.T6.33.33.31.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.33.33.31.1.1.1.1.1" class="ltx_tr">
<span id="S5.T6.33.33.31.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/7/true.png" id="S5.T6.33.33.31.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.33.33.31.1.3" class="ltx_text"></span></td>
<td id="S5.T6.34.34.32.2" class="ltx_td ltx_align_center">
<span id="S5.T6.34.34.32.2.2" class="ltx_text"></span> <span id="S5.T6.34.34.32.2.1" class="ltx_text">
<span id="S5.T6.34.34.32.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.34.34.32.2.1.1.1.1" class="ltx_tr">
<span id="S5.T6.34.34.32.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/7/without_1.png" id="S5.T6.34.34.32.2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.34.34.32.2.3" class="ltx_text"></span></td>
<td id="S5.T6.35.35.33.3" class="ltx_td ltx_align_center">
<span id="S5.T6.35.35.33.3.2" class="ltx_text"></span> <span id="S5.T6.35.35.33.3.1" class="ltx_text">
<span id="S5.T6.35.35.33.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.35.35.33.3.1.1.1.1" class="ltx_tr">
<span id="S5.T6.35.35.33.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/7/without_2.png" id="S5.T6.35.35.33.3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.35.35.33.3.3" class="ltx_text"></span></td>
<td id="S5.T6.36.36.34.4" class="ltx_td ltx_align_center">
<span id="S5.T6.36.36.34.4.2" class="ltx_text"></span> <span id="S5.T6.36.36.34.4.1" class="ltx_text">
<span id="S5.T6.36.36.34.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.36.36.34.4.1.1.1.1" class="ltx_tr">
<span id="S5.T6.36.36.34.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/7/without_3.png" id="S5.T6.36.36.34.4.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.36.36.34.4.3" class="ltx_text"></span></td>
<td id="S5.T6.37.37.35.5" class="ltx_td ltx_align_center">
<span id="S5.T6.37.37.35.5.2" class="ltx_text"></span> <span id="S5.T6.37.37.35.5.1" class="ltx_text">
<span id="S5.T6.37.37.35.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.37.37.35.5.1.1.1.1" class="ltx_tr">
<span id="S5.T6.37.37.35.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><img src="/html/2311.16065/assets/GGL-results/7/without_4.png" id="S5.T6.37.37.35.5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="72" height="72" alt="[Uncaptioned image]"></span></span>
</span></span><span id="S5.T6.37.37.35.5.3" class="ltx_text"></span></td>
</tr>
</table>
</figure>
<figure id="alg2" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg2.2.1.1" class="ltx_text ltx_font_bold">Algorithm 2</span> </span> The proposed work from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg2.3" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg2.l0" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l0.1.1.1" class="ltx_text" style="font-size:80%;">0:</span></span>¬†¬†two participants V and M who have common learning goals.

</div>
<div id="alg2.l0a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l0a.1.1.1" class="ltx_text" style="font-size:80%;">0:</span></span>¬†¬†V‚Äôs local dataset <math id="alg2.l0a.m1.1" class="ltx_Math" alttext="D_{v}" display="inline"><semantics id="alg2.l0a.m1.1a"><msub id="alg2.l0a.m1.1.1" xref="alg2.l0a.m1.1.1.cmml"><mi id="alg2.l0a.m1.1.1.2" xref="alg2.l0a.m1.1.1.2.cmml">D</mi><mi id="alg2.l0a.m1.1.1.3" xref="alg2.l0a.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l0a.m1.1b"><apply id="alg2.l0a.m1.1.1.cmml" xref="alg2.l0a.m1.1.1"><csymbol cd="ambiguous" id="alg2.l0a.m1.1.1.1.cmml" xref="alg2.l0a.m1.1.1">subscript</csymbol><ci id="alg2.l0a.m1.1.1.2.cmml" xref="alg2.l0a.m1.1.1.2">ùê∑</ci><ci id="alg2.l0a.m1.1.1.3.cmml" xref="alg2.l0a.m1.1.1.3">ùë£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m1.1c">D_{v}</annotation></semantics></math> with label <math id="alg2.l0a.m2.1" class="ltx_Math" alttext="L_{a}" display="inline"><semantics id="alg2.l0a.m2.1a"><msub id="alg2.l0a.m2.1.1" xref="alg2.l0a.m2.1.1.cmml"><mi id="alg2.l0a.m2.1.1.2" xref="alg2.l0a.m2.1.1.2.cmml">L</mi><mi id="alg2.l0a.m2.1.1.3" xref="alg2.l0a.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l0a.m2.1b"><apply id="alg2.l0a.m2.1.1.cmml" xref="alg2.l0a.m2.1.1"><csymbol cd="ambiguous" id="alg2.l0a.m2.1.1.1.cmml" xref="alg2.l0a.m2.1.1">subscript</csymbol><ci id="alg2.l0a.m2.1.1.2.cmml" xref="alg2.l0a.m2.1.1.2">ùêø</ci><ci id="alg2.l0a.m2.1.1.3.cmml" xref="alg2.l0a.m2.1.1.3">ùëé</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m2.1c">L_{a}</annotation></semantics></math> and <math id="alg2.l0a.m3.1" class="ltx_Math" alttext="L_{b}" display="inline"><semantics id="alg2.l0a.m3.1a"><msub id="alg2.l0a.m3.1.1" xref="alg2.l0a.m3.1.1.cmml"><mi id="alg2.l0a.m3.1.1.2" xref="alg2.l0a.m3.1.1.2.cmml">L</mi><mi id="alg2.l0a.m3.1.1.3" xref="alg2.l0a.m3.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l0a.m3.1b"><apply id="alg2.l0a.m3.1.1.cmml" xref="alg2.l0a.m3.1.1"><csymbol cd="ambiguous" id="alg2.l0a.m3.1.1.1.cmml" xref="alg2.l0a.m3.1.1">subscript</csymbol><ci id="alg2.l0a.m3.1.1.2.cmml" xref="alg2.l0a.m3.1.1.2">ùêø</ci><ci id="alg2.l0a.m3.1.1.3.cmml" xref="alg2.l0a.m3.1.1.3">ùëè</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m3.1c">L_{b}</annotation></semantics></math>. ‚ÄÉ‚ÄÉ‚ÄÉM‚Äôs local dataset <math id="alg2.l0a.m4.1" class="ltx_Math" alttext="D_{m}" display="inline"><semantics id="alg2.l0a.m4.1a"><msub id="alg2.l0a.m4.1.1" xref="alg2.l0a.m4.1.1.cmml"><mi id="alg2.l0a.m4.1.1.2" xref="alg2.l0a.m4.1.1.2.cmml">D</mi><mi id="alg2.l0a.m4.1.1.3" xref="alg2.l0a.m4.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l0a.m4.1b"><apply id="alg2.l0a.m4.1.1.cmml" xref="alg2.l0a.m4.1.1"><csymbol cd="ambiguous" id="alg2.l0a.m4.1.1.1.cmml" xref="alg2.l0a.m4.1.1">subscript</csymbol><ci id="alg2.l0a.m4.1.1.2.cmml" xref="alg2.l0a.m4.1.1.2">ùê∑</ci><ci id="alg2.l0a.m4.1.1.3.cmml" xref="alg2.l0a.m4.1.1.3">ùëö</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m4.1c">D_{m}</annotation></semantics></math> with label <math id="alg2.l0a.m5.1" class="ltx_Math" alttext="L_{b}" display="inline"><semantics id="alg2.l0a.m5.1a"><msub id="alg2.l0a.m5.1.1" xref="alg2.l0a.m5.1.1.cmml"><mi id="alg2.l0a.m5.1.1.2" xref="alg2.l0a.m5.1.1.2.cmml">L</mi><mi id="alg2.l0a.m5.1.1.3" xref="alg2.l0a.m5.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l0a.m5.1b"><apply id="alg2.l0a.m5.1.1.cmml" xref="alg2.l0a.m5.1.1"><csymbol cd="ambiguous" id="alg2.l0a.m5.1.1.1.cmml" xref="alg2.l0a.m5.1.1">subscript</csymbol><ci id="alg2.l0a.m5.1.1.2.cmml" xref="alg2.l0a.m5.1.1.2">ùêø</ci><ci id="alg2.l0a.m5.1.1.3.cmml" xref="alg2.l0a.m5.1.1.3">ùëè</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m5.1c">L_{b}</annotation></semantics></math> and <math id="alg2.l0a.m6.1" class="ltx_Math" alttext="L_{c}" display="inline"><semantics id="alg2.l0a.m6.1a"><msub id="alg2.l0a.m6.1.1" xref="alg2.l0a.m6.1.1.cmml"><mi id="alg2.l0a.m6.1.1.2" xref="alg2.l0a.m6.1.1.2.cmml">L</mi><mi id="alg2.l0a.m6.1.1.3" xref="alg2.l0a.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l0a.m6.1b"><apply id="alg2.l0a.m6.1.1.cmml" xref="alg2.l0a.m6.1.1"><csymbol cd="ambiguous" id="alg2.l0a.m6.1.1.1.cmml" xref="alg2.l0a.m6.1.1">subscript</csymbol><ci id="alg2.l0a.m6.1.1.2.cmml" xref="alg2.l0a.m6.1.1.2">ùêø</ci><ci id="alg2.l0a.m6.1.1.3.cmml" xref="alg2.l0a.m6.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m6.1c">L_{c}</annotation></semantics></math>.

</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg2.4" class="ltx_p ltx_figure_panel"><span id="alg2.4.1" class="ltx_text ltx_font_bold">a. Parameter Server</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg2.5" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg2.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>¬†¬†build model and initialize weights.

</div>
<div id="alg2.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>¬†¬†send the initial weights to the clients.

</div>
<div id="alg2.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>¬†¬†local training on victim and malicious clients.

</div>
<div id="alg2.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>¬†¬†receive the trained local weights and generate the global model.

</div>
<div id="alg2.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>¬†¬†repeat Step 2 and 3 until the model converges.

</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg2.6" class="ltx_p ltx_figure_panel"><span id="alg2.6.1" class="ltx_text ltx_font_bold">b. Victim Client</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg2.7" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg2.l1a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l1a.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>¬†¬†download the global weights from parameter server.

</div>
<div id="alg2.l2a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l2a.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>¬†¬†train the local model on its local dataset <math id="alg2.l2a.m1.1" class="ltx_Math" alttext="D_{v}" display="inline"><semantics id="alg2.l2a.m1.1a"><msub id="alg2.l2a.m1.1.1" xref="alg2.l2a.m1.1.1.cmml"><mi id="alg2.l2a.m1.1.1.2" xref="alg2.l2a.m1.1.1.2.cmml">D</mi><mi id="alg2.l2a.m1.1.1.3" xref="alg2.l2a.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l2a.m1.1b"><apply id="alg2.l2a.m1.1.1.cmml" xref="alg2.l2a.m1.1.1"><csymbol cd="ambiguous" id="alg2.l2a.m1.1.1.1.cmml" xref="alg2.l2a.m1.1.1">subscript</csymbol><ci id="alg2.l2a.m1.1.1.2.cmml" xref="alg2.l2a.m1.1.1.2">ùê∑</ci><ci id="alg2.l2a.m1.1.1.3.cmml" xref="alg2.l2a.m1.1.1.3">ùë£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2a.m1.1c">D_{v}</annotation></semantics></math>.

</div>
<div id="alg2.l3a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l3a.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>¬†¬†upload the local model to the parameter server.

</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg2.8" class="ltx_p ltx_figure_panel"><span id="alg2.8.1" class="ltx_text ltx_font_bold">c. Malicious Client</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg2.9" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg2.l1b" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l1b.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>¬†¬†download the global weights from parameter server.

</div>
<div id="alg2.l2b" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l2b.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>¬†¬†train a GAN model to generate fake data of class <math id="alg2.l2b.m1.1" class="ltx_Math" alttext="L_{a}" display="inline"><semantics id="alg2.l2b.m1.1a"><msub id="alg2.l2b.m1.1.1" xref="alg2.l2b.m1.1.1.cmml"><mi id="alg2.l2b.m1.1.1.2" xref="alg2.l2b.m1.1.1.2.cmml">L</mi><mi id="alg2.l2b.m1.1.1.3" xref="alg2.l2b.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l2b.m1.1b"><apply id="alg2.l2b.m1.1.1.cmml" xref="alg2.l2b.m1.1.1"><csymbol cd="ambiguous" id="alg2.l2b.m1.1.1.1.cmml" xref="alg2.l2b.m1.1.1">subscript</csymbol><ci id="alg2.l2b.m1.1.1.2.cmml" xref="alg2.l2b.m1.1.1.2">ùêø</ci><ci id="alg2.l2b.m1.1.1.3.cmml" xref="alg2.l2b.m1.1.1.3">ùëé</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2b.m1.1c">L_{a}</annotation></semantics></math>.

</div>
<div id="alg2.l3b" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l3b.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>¬†¬†generate many fake data using GAN and relabel them with <math id="alg2.l3b.m1.1" class="ltx_Math" alttext="L_{c}" display="inline"><semantics id="alg2.l3b.m1.1a"><msub id="alg2.l3b.m1.1.1" xref="alg2.l3b.m1.1.1.cmml"><mi id="alg2.l3b.m1.1.1.2" xref="alg2.l3b.m1.1.1.2.cmml">L</mi><mi id="alg2.l3b.m1.1.1.3" xref="alg2.l3b.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l3b.m1.1b"><apply id="alg2.l3b.m1.1.1.cmml" xref="alg2.l3b.m1.1.1"><csymbol cd="ambiguous" id="alg2.l3b.m1.1.1.1.cmml" xref="alg2.l3b.m1.1.1">subscript</csymbol><ci id="alg2.l3b.m1.1.1.2.cmml" xref="alg2.l3b.m1.1.1.2">ùêø</ci><ci id="alg2.l3b.m1.1.1.3.cmml" xref="alg2.l3b.m1.1.1.3">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l3b.m1.1c">L_{c}</annotation></semantics></math> to update the local dataset <math id="alg2.l3b.m2.1" class="ltx_Math" alttext="D_{m}" display="inline"><semantics id="alg2.l3b.m2.1a"><msub id="alg2.l3b.m2.1.1" xref="alg2.l3b.m2.1.1.cmml"><mi id="alg2.l3b.m2.1.1.2" xref="alg2.l3b.m2.1.1.2.cmml">D</mi><mi id="alg2.l3b.m2.1.1.3" xref="alg2.l3b.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l3b.m2.1b"><apply id="alg2.l3b.m2.1.1.cmml" xref="alg2.l3b.m2.1.1"><csymbol cd="ambiguous" id="alg2.l3b.m2.1.1.1.cmml" xref="alg2.l3b.m2.1.1">subscript</csymbol><ci id="alg2.l3b.m2.1.1.2.cmml" xref="alg2.l3b.m2.1.1.2">ùê∑</ci><ci id="alg2.l3b.m2.1.1.3.cmml" xref="alg2.l3b.m2.1.1.3">ùëö</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l3b.m2.1c">D_{m}</annotation></semantics></math>.

</div>
<div id="alg2.l4a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l4a.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>¬†¬†train the local model on the updated local dataset <math id="alg2.l4a.m1.1" class="ltx_Math" alttext="D_{m}" display="inline"><semantics id="alg2.l4a.m1.1a"><msub id="alg2.l4a.m1.1.1" xref="alg2.l4a.m1.1.1.cmml"><mi id="alg2.l4a.m1.1.1.2" xref="alg2.l4a.m1.1.1.2.cmml">D</mi><mi id="alg2.l4a.m1.1.1.3" xref="alg2.l4a.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l4a.m1.1b"><apply id="alg2.l4a.m1.1.1.cmml" xref="alg2.l4a.m1.1.1"><csymbol cd="ambiguous" id="alg2.l4a.m1.1.1.1.cmml" xref="alg2.l4a.m1.1.1">subscript</csymbol><ci id="alg2.l4a.m1.1.1.2.cmml" xref="alg2.l4a.m1.1.1.2">ùê∑</ci><ci id="alg2.l4a.m1.1.1.3.cmml" xref="alg2.l4a.m1.1.1.3">ùëö</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l4a.m1.1c">D_{m}</annotation></semantics></math>.

</div>
<div id="alg2.l5a" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg2.l5a.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>¬†¬†upload the local model to the parameter server.

</div>
</div>
</div>
</div>
</figure>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Full Recovery (Discriminative)</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">Zhu <em id="S5.SS2.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> introduced  <span title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Deep Leakage from Gradients</span></span> (<abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr>), framing the image recovery task as a regression problem. Initially, the shared local gradient is derived from a victim participant, and a batch of ‚Äúdummy‚Äù images and labels is randomly initialized. These are then used to calculate the ‚Äúdummy‚Äù gradient through standard forward-backward propagation, employing the L-BFGS optimizer¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>. This process leverages regression techniques to decipher intricate patterns within the gradient, thereby reconstructing the private image data. The approach provides a powerful framework for <abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> attacks. Importantly, it is the input ‚Äúdummy‚Äù data that is updated‚Äînot the model parameters‚Äîby minimizing the  <span title="Mean Square Error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Mean Square Error</span></span> (<abbr title="Mean Square Error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSE</span></abbr>) between the ‚Äúdummy‚Äù gradient and the shared local gradient. This strategy prioritizes the fidelity of the reconstructed image, ensuring preservation of essential features and details. Among existing leakage methods, <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> is unique in achieving precise pixel-wise data revelation without requiring additional information. The technique is innovative and deploys unique algorithms to achieve an unparalleled level of precision. Some results from <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> of batch data are provided in Figure¬†<a href="#S5.F7" title="Figure 7 ‚Ä£ 5.2.2 Full Recovery (Discriminative) ‚Ä£ 5.2 Gradient-Based Data Leakage ‚Ä£ 5 Model to Data Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. It marks a significant advancement in the field of gradient leakage, opening new avenues for research and application. Although <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> can perform attacks on multiple images simultaneously, the accuracy in label inference remains suboptimal. This limitation is an active area of research, with ongoing efforts to improve label inference accuracy without compromising image recovery fidelity. In conclusion, <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> offers a novel approach to image recovery, utilizing groundbreaking algorithms to attain high precision. Its potential applications extend far beyond existing methods, positioning it at the forefront of technological advancements in the field.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2311.16065/assets/DLG-results/DLG-results.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="207" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Although the sequence might differ and additional artifact pixels are present, deep leakage in batched data still generates images that closely resemble the original versions. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite></figcaption>
</figure>
<div id="S5.SS2.SSS2.p2" class="ltx_para">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p">Zhao <em id="S5.SS2.SSS2.p2.1.1" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> introduced a novel method known as <abbr title="Improved DLG" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">iDLG</span></abbr>, which focuses on the identification of labels in a more accurate manner. This technique involves calculating the derivative of the cross-entropy loss with respect to one-hot labels for each class in the classification task. The crux of this approach lies in the distinct ranges of the derivative values that correspond to different labels. The authors discovered that the derivative value for the ground-truth label uniquely falls within the range of [-1, 0], while the derivatives corresponding to incorrect labels lie within the range of [0, 1]. This separation of value ranges provides a solid basis for identifying the correct label. By simply examining the derivative value, the system can distinguish the correct label from incorrect ones. However, this method has a limitation concerning the batch size: the batch size must not exceed 1 during the process. While this constraint may affect efficiency in large-scale applications, the <abbr title="Improved DLG" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">iDLG</span></abbr> method‚Äôs unique approach to label identification through derivative analysis represents a significant contribution to the field of gradient leakage. It opens avenues for future research to potentially refine this technique and mitigate its limitations.</p>
</div>
<div id="S5.SS2.SSS2.p3" class="ltx_para">
<p id="S5.SS2.SSS2.p3.2" class="ltx_p">In addition to the low accuracy of label inference, <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> often fails to recover the image from the gradient when the data variance is large, see Figure¬†<a href="#S5.F8" title="Figure 8 ‚Ä£ 5.2.2 Full Recovery (Discriminative) ‚Ä£ 5.2 Gradient-Based Data Leakage ‚Ä£ 5 Model to Data Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. This is particularly common for datasets with a large number of classes.  <span title="Inverting Gradient" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Inverting Gradient</span></span> (<abbr title="Inverting Gradient" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IG</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite> improved the stability of <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> and <abbr title="Improved DLG" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">iDLG</span></abbr> by introducing a magnitude-invariant cosine similarity metric for the loss function, termed  <span title="Cosine Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Cosine Distance</span></span> (<abbr title="Cosine Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CD</span></abbr>). This approach aims to find images that yield similar prediction changes in the classification model, rather than images that produce closely matching values with a shared gradient. The method demonstrates promising results in recovering high-resolution images (<em id="S5.SS2.SSS2.p3.2.1" class="ltx_emph ltx_font_italic">i.e.</em>, <math id="S5.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S5.SS2.SSS2.p3.1.m1.1a"><mrow id="S5.SS2.SSS2.p3.1.m1.1.1" xref="S5.SS2.SSS2.p3.1.m1.1.1.cmml"><mn id="S5.SS2.SSS2.p3.1.m1.1.1.2" xref="S5.SS2.SSS2.p3.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.SSS2.p3.1.m1.1.1.1" xref="S5.SS2.SSS2.p3.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.SS2.SSS2.p3.1.m1.1.1.3" xref="S5.SS2.SSS2.p3.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p3.1.m1.1b"><apply id="S5.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p3.1.m1.1.1"><times id="S5.SS2.SSS2.p3.1.m1.1.1.1.cmml" xref="S5.SS2.SSS2.p3.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.SSS2.p3.1.m1.1.1.2.cmml" xref="S5.SS2.SSS2.p3.1.m1.1.1.2">224</cn><cn type="integer" id="S5.SS2.SSS2.p3.1.m1.1.1.3.cmml" xref="S5.SS2.SSS2.p3.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p3.1.m1.1c">224\times 224</annotation></semantics></math>) when trained with large batch sizes (<em id="S5.SS2.SSS2.p3.2.2" class="ltx_emph ltx_font_italic">i.e.</em>, <math id="S5.SS2.SSS2.p3.2.m2.1" class="ltx_Math" alttext="\#Batch=100" display="inline"><semantics id="S5.SS2.SSS2.p3.2.m2.1a"><mrow id="S5.SS2.SSS2.p3.2.m2.1.1" xref="S5.SS2.SSS2.p3.2.m2.1.1.cmml"><mrow id="S5.SS2.SSS2.p3.2.m2.1.1.2" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.cmml"><mi mathvariant="normal" id="S5.SS2.SSS2.p3.2.m2.1.1.2.2" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.2.cmml">#</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.p3.2.m2.1.1.2.1" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS2.p3.2.m2.1.1.2.3" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.3.cmml">B</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.p3.2.m2.1.1.2.1a" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS2.p3.2.m2.1.1.2.4" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.p3.2.m2.1.1.2.1b" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS2.p3.2.m2.1.1.2.5" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.p3.2.m2.1.1.2.1c" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS2.p3.2.m2.1.1.2.6" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS2.p3.2.m2.1.1.2.1d" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS2.p3.2.m2.1.1.2.7" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.7.cmml">h</mi></mrow><mo id="S5.SS2.SSS2.p3.2.m2.1.1.1" xref="S5.SS2.SSS2.p3.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS2.p3.2.m2.1.1.3" xref="S5.SS2.SSS2.p3.2.m2.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p3.2.m2.1b"><apply id="S5.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1"><eq id="S5.SS2.SSS2.p3.2.m2.1.1.1.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.1"></eq><apply id="S5.SS2.SSS2.p3.2.m2.1.1.2.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2"><times id="S5.SS2.SSS2.p3.2.m2.1.1.2.1.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.1"></times><ci id="S5.SS2.SSS2.p3.2.m2.1.1.2.2.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.2">#</ci><ci id="S5.SS2.SSS2.p3.2.m2.1.1.2.3.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.3">ùêµ</ci><ci id="S5.SS2.SSS2.p3.2.m2.1.1.2.4.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.4">ùëé</ci><ci id="S5.SS2.SSS2.p3.2.m2.1.1.2.5.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.5">ùë°</ci><ci id="S5.SS2.SSS2.p3.2.m2.1.1.2.6.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.6">ùëê</ci><ci id="S5.SS2.SSS2.p3.2.m2.1.1.2.7.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.2.7">‚Ñé</ci></apply><cn type="integer" id="S5.SS2.SSS2.p3.2.m2.1.1.3.cmml" xref="S5.SS2.SSS2.p3.2.m2.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p3.2.m2.1c">\#Batch=100</annotation></semantics></math>); however, the  <span title="Peak Signal-to-Noise Ratio" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Peak Signal-to-Noise Ratio</span></span> (<abbr title="Peak Signal-to-Noise Ratio" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PSNR</span></abbr>) remains unacceptably low.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2311.16065/assets/IG-results/IG-results.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="161" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Reconstructed image using its gradient features. On the left is the ground true image taken from the validation dataset. The center image is reconstructed using a trained ResNet-18 model that has been trained on ILSVRC2012 dataset. On the right is the image rebuilt using a trained ResNet-152 model. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite></figcaption>
</figure>
<div id="S5.SS2.SSS2.p4" class="ltx_para">
<p id="S5.SS2.SSS2.p4.1" class="ltx_p">Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>, Jeon <em id="S5.SS2.SSS2.p4.1.1" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> argued that relying solely on gradient information is insufficient for revealing private training data. They introduced GIAS, which employs a pre-trained model for data revelation. Yin <em id="S5.SS2.SSS2.p4.1.2" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite> reported that in image classification tasks, the ground-truth label can be easily inferred from the gradient of the last fully-connected layer. Additionally,  <span title="Batch Normalization" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Batch Normalization</span></span> (<abbr title="Batch Normalization" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BN</span></abbr>) statistics can significantly improve the efficacy of gradient leakage attacks and facilitate the revelation of high-resolution private training images.</p>
</div>
<div id="S5.SS2.SSS2.p5" class="ltx_para">
<p id="S5.SS2.SSS2.p5.1" class="ltx_p">Another approach to gradient leakage attacks is based on generative models. Wang <em id="S5.SS2.SSS2.p5.1.1" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite> trained a <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr> with a multi-task discriminator, named mGAN-AI, to generate private information based on gradients.</p>
</div>
</section>
<section id="S5.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.3 </span>Full Recovery (Generative)</h4>

<div id="S5.SS2.SSS3.p1" class="ltx_para">
<p id="S5.SS2.SSS3.p1.1" class="ltx_p">In the work¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>, the  <span title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Generative Regression Neural Network</span></span> (<abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr>) was proposed as a method for reconstructing private training data along with its associated labels. The model is capable of handling large batch sizes and high-resolution images. Some examples are provided in Figure¬†<a href="#S5.F9" title="Figure 9 ‚Ä£ 5.2.3 Full Recovery (Generative) ‚Ä£ 5.2 Gradient-Based Data Leakage ‚Ä£ 5 Model to Data Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> Inspired by both <abbr title="Generative Adversarial Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GAN</span></abbr> and <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> methods, <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr> introduces a gradient-driven approach for image creation that effectively addresses the challenges of stability and data quality commonly associated with <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr> methodologies.</p>
</div>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2311.16065/assets/GRNN-results/GRNN-results.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="389" height="680" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Examples of data leakage attack using the <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr> on the global model. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite></figcaption>
</figure>
<div id="S5.SS2.SSS3.p2" class="ltx_para">
<p id="S5.SS2.SSS3.p2.11" class="ltx_p">The novel <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr>, which serves as an innovative data leakage attack technique, is capable of retrieving private training images with resolutions up to <math id="S5.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="S5.SS2.SSS3.p2.1.m1.1a"><mrow id="S5.SS2.SSS3.p2.1.m1.1.1" xref="S5.SS2.SSS3.p2.1.m1.1.1.cmml"><mn id="S5.SS2.SSS3.p2.1.m1.1.1.2" xref="S5.SS2.SSS3.p2.1.m1.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.SSS3.p2.1.m1.1.1.1" xref="S5.SS2.SSS3.p2.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.SS2.SSS3.p2.1.m1.1.1.3" xref="S5.SS2.SSS3.p2.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.1.m1.1b"><apply id="S5.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1"><times id="S5.SS2.SSS3.p2.1.m1.1.1.1.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.SSS3.p2.1.m1.1.1.2.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.2">256</cn><cn type="integer" id="S5.SS2.SSS3.p2.1.m1.1.1.3.cmml" xref="S5.SS2.SSS3.p2.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.1.m1.1c">256\times 256</annotation></semantics></math> and batch sizes of <math id="S5.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S5.SS2.SSS3.p2.2.m2.1a"><mn id="S5.SS2.SSS3.p2.2.m2.1.1" xref="S5.SS2.SSS3.p2.2.m2.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.2.m2.1b"><cn type="integer" id="S5.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S5.SS2.SSS3.p2.2.m2.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.2.m2.1c">256</annotation></semantics></math>. This makes it particularly well-suited for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> applications, as both the local gradient <math id="S5.SS2.SSS3.p2.3.m3.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S5.SS2.SSS3.p2.3.m3.1a"><mi id="S5.SS2.SSS3.p2.3.m3.1.1" xref="S5.SS2.SSS3.p2.3.m3.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.3.m3.1b"><ci id="S5.SS2.SSS3.p2.3.m3.1.1.cmml" xref="S5.SS2.SSS3.p2.3.m3.1.1">ùëî</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.3.m3.1c">g</annotation></semantics></math> and the global model <math id="S5.SS2.SSS3.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{F}(\bullet)" display="inline"><semantics id="S5.SS2.SSS3.p2.4.m4.1a"><mrow id="S5.SS2.SSS3.p2.4.m4.1.2" xref="S5.SS2.SSS3.p2.4.m4.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS3.p2.4.m4.1.2.2" xref="S5.SS2.SSS3.p2.4.m4.1.2.2.cmml">‚Ñ±</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS3.p2.4.m4.1.2.1" xref="S5.SS2.SSS3.p2.4.m4.1.2.1.cmml">‚Äã</mo><mrow id="S5.SS2.SSS3.p2.4.m4.1.2.3.2" xref="S5.SS2.SSS3.p2.4.m4.1.2.cmml"><mo stretchy="false" id="S5.SS2.SSS3.p2.4.m4.1.2.3.2.1" xref="S5.SS2.SSS3.p2.4.m4.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S5.SS2.SSS3.p2.4.m4.1.1" xref="S5.SS2.SSS3.p2.4.m4.1.1.cmml">‚àô</mo><mo stretchy="false" id="S5.SS2.SSS3.p2.4.m4.1.2.3.2.2" xref="S5.SS2.SSS3.p2.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.4.m4.1b"><apply id="S5.SS2.SSS3.p2.4.m4.1.2.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.2"><times id="S5.SS2.SSS3.p2.4.m4.1.2.1.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.2.1"></times><ci id="S5.SS2.SSS3.p2.4.m4.1.2.2.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.2.2">‚Ñ±</ci><ci id="S5.SS2.SSS3.p2.4.m4.1.1.cmml" xref="S5.SS2.SSS3.p2.4.m4.1.1">‚àô</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.4.m4.1c">\mathcal{F}(\bullet)</annotation></semantics></math> are easily accessible within the system‚Äôs configuration. The <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr> algorithm employs a dual-branch structure to generate fake training data <math id="S5.SS2.SSS3.p2.5.m5.1" class="ltx_Math" alttext="\hat{x}" display="inline"><semantics id="S5.SS2.SSS3.p2.5.m5.1a"><mover accent="true" id="S5.SS2.SSS3.p2.5.m5.1.1" xref="S5.SS2.SSS3.p2.5.m5.1.1.cmml"><mi id="S5.SS2.SSS3.p2.5.m5.1.1.2" xref="S5.SS2.SSS3.p2.5.m5.1.1.2.cmml">x</mi><mo id="S5.SS2.SSS3.p2.5.m5.1.1.1" xref="S5.SS2.SSS3.p2.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.5.m5.1b"><apply id="S5.SS2.SSS3.p2.5.m5.1.1.cmml" xref="S5.SS2.SSS3.p2.5.m5.1.1"><ci id="S5.SS2.SSS3.p2.5.m5.1.1.1.cmml" xref="S5.SS2.SSS3.p2.5.m5.1.1.1">^</ci><ci id="S5.SS2.SSS3.p2.5.m5.1.1.2.cmml" xref="S5.SS2.SSS3.p2.5.m5.1.1.2">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.5.m5.1c">\hat{x}</annotation></semantics></math> and corresponding labels <math id="S5.SS2.SSS3.p2.6.m6.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S5.SS2.SSS3.p2.6.m6.1a"><mover accent="true" id="S5.SS2.SSS3.p2.6.m6.1.1" xref="S5.SS2.SSS3.p2.6.m6.1.1.cmml"><mi id="S5.SS2.SSS3.p2.6.m6.1.1.2" xref="S5.SS2.SSS3.p2.6.m6.1.1.2.cmml">y</mi><mo id="S5.SS2.SSS3.p2.6.m6.1.1.1" xref="S5.SS2.SSS3.p2.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.6.m6.1b"><apply id="S5.SS2.SSS3.p2.6.m6.1.1.cmml" xref="S5.SS2.SSS3.p2.6.m6.1.1"><ci id="S5.SS2.SSS3.p2.6.m6.1.1.1.cmml" xref="S5.SS2.SSS3.p2.6.m6.1.1.1">^</ci><ci id="S5.SS2.SSS3.p2.6.m6.1.1.2.cmml" xref="S5.SS2.SSS3.p2.6.m6.1.1.2">ùë¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.6.m6.1c">\hat{y}</annotation></semantics></math>. It is trained to estimate a fake gradient <math id="S5.SS2.SSS3.p2.7.m7.1" class="ltx_Math" alttext="\hat{g}" display="inline"><semantics id="S5.SS2.SSS3.p2.7.m7.1a"><mover accent="true" id="S5.SS2.SSS3.p2.7.m7.1.1" xref="S5.SS2.SSS3.p2.7.m7.1.1.cmml"><mi id="S5.SS2.SSS3.p2.7.m7.1.1.2" xref="S5.SS2.SSS3.p2.7.m7.1.1.2.cmml">g</mi><mo id="S5.SS2.SSS3.p2.7.m7.1.1.1" xref="S5.SS2.SSS3.p2.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.7.m7.1b"><apply id="S5.SS2.SSS3.p2.7.m7.1.1.cmml" xref="S5.SS2.SSS3.p2.7.m7.1.1"><ci id="S5.SS2.SSS3.p2.7.m7.1.1.1.cmml" xref="S5.SS2.SSS3.p2.7.m7.1.1.1">^</ci><ci id="S5.SS2.SSS3.p2.7.m7.1.1.2.cmml" xref="S5.SS2.SSS3.p2.7.m7.1.1.2">ùëî</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.7.m7.1c">\hat{g}</annotation></semantics></math>, computed from the generated data <math id="S5.SS2.SSS3.p2.8.m8.1" class="ltx_Math" alttext="\hat{x}" display="inline"><semantics id="S5.SS2.SSS3.p2.8.m8.1a"><mover accent="true" id="S5.SS2.SSS3.p2.8.m8.1.1" xref="S5.SS2.SSS3.p2.8.m8.1.1.cmml"><mi id="S5.SS2.SSS3.p2.8.m8.1.1.2" xref="S5.SS2.SSS3.p2.8.m8.1.1.2.cmml">x</mi><mo id="S5.SS2.SSS3.p2.8.m8.1.1.1" xref="S5.SS2.SSS3.p2.8.m8.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.8.m8.1b"><apply id="S5.SS2.SSS3.p2.8.m8.1.1.cmml" xref="S5.SS2.SSS3.p2.8.m8.1.1"><ci id="S5.SS2.SSS3.p2.8.m8.1.1.1.cmml" xref="S5.SS2.SSS3.p2.8.m8.1.1.1">^</ci><ci id="S5.SS2.SSS3.p2.8.m8.1.1.2.cmml" xref="S5.SS2.SSS3.p2.8.m8.1.1.2">ùë•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.8.m8.1c">\hat{x}</annotation></semantics></math> and labels <math id="S5.SS2.SSS3.p2.9.m9.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S5.SS2.SSS3.p2.9.m9.1a"><mover accent="true" id="S5.SS2.SSS3.p2.9.m9.1.1" xref="S5.SS2.SSS3.p2.9.m9.1.1.cmml"><mi id="S5.SS2.SSS3.p2.9.m9.1.1.2" xref="S5.SS2.SSS3.p2.9.m9.1.1.2.cmml">y</mi><mo id="S5.SS2.SSS3.p2.9.m9.1.1.1" xref="S5.SS2.SSS3.p2.9.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.9.m9.1b"><apply id="S5.SS2.SSS3.p2.9.m9.1.1.cmml" xref="S5.SS2.SSS3.p2.9.m9.1.1"><ci id="S5.SS2.SSS3.p2.9.m9.1.1.1.cmml" xref="S5.SS2.SSS3.p2.9.m9.1.1.1">^</ci><ci id="S5.SS2.SSS3.p2.9.m9.1.1.2.cmml" xref="S5.SS2.SSS3.p2.9.m9.1.1.2">ùë¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.9.m9.1c">\hat{y}</annotation></semantics></math>, such that it closely matches the true gradient <math id="S5.SS2.SSS3.p2.10.m10.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S5.SS2.SSS3.p2.10.m10.1a"><mi id="S5.SS2.SSS3.p2.10.m10.1.1" xref="S5.SS2.SSS3.p2.10.m10.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.10.m10.1b"><ci id="S5.SS2.SSS3.p2.10.m10.1.1.cmml" xref="S5.SS2.SSS3.p2.10.m10.1.1">ùëî</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.10.m10.1c">g</annotation></semantics></math> associated with the global model. The divergence <math id="S5.SS2.SSS3.p2.11.m11.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S5.SS2.SSS3.p2.11.m11.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.SSS3.p2.11.m11.1.1" xref="S5.SS2.SSS3.p2.11.m11.1.1.cmml">ùíü</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p2.11.m11.1b"><ci id="S5.SS2.SSS3.p2.11.m11.1.1.cmml" xref="S5.SS2.SSS3.p2.11.m11.1.1">ùíü</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p2.11.m11.1c">\mathcal{D}</annotation></semantics></math> between the true and fake gradients is evaluated using a combination of <abbr title="Mean Square Error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSE</span></abbr>,  <span title="Wasserstein Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Wasserstein Distance</span></span> (<abbr title="Wasserstein Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">WD</span></abbr>), and  <span title="Total Variation Loss" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Total Variation Loss</span></span> (<abbr title="Total Variation Loss" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TVLoss</span></abbr>) metrics.</p>
</div>
<div id="S5.SS2.SSS3.p3" class="ltx_para">
<p id="S5.SS2.SSS3.p3.1" class="ltx_p">Through empirical testing on various image classification challenges, the <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr> approach has been rigorously compared to cutting-edge alternatives, showing significantly better results across multiple metrics. The trial findings confirm that the proposed method is notably more stable and capable of generating images of superior quality, especially when applied to large batch sizes and high resolutions.</p>
</div>
<div id="S5.SS2.SSS3.p4" class="ltx_para">
<p id="S5.SS2.SSS3.p4.2" class="ltx_p">Compared to the most latest work¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>, <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr> takes a generative approach, which shows high stability for recovering high-resolution images (<em id="S5.SS2.SSS3.p4.2.1" class="ltx_emph ltx_font_italic">i.e.</em> up to <math id="S5.SS2.SSS3.p4.1.m1.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="S5.SS2.SSS3.p4.1.m1.1a"><mrow id="S5.SS2.SSS3.p4.1.m1.1.1" xref="S5.SS2.SSS3.p4.1.m1.1.1.cmml"><mn id="S5.SS2.SSS3.p4.1.m1.1.1.2" xref="S5.SS2.SSS3.p4.1.m1.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.SSS3.p4.1.m1.1.1.1" xref="S5.SS2.SSS3.p4.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.SS2.SSS3.p4.1.m1.1.1.3" xref="S5.SS2.SSS3.p4.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p4.1.m1.1b"><apply id="S5.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S5.SS2.SSS3.p4.1.m1.1.1"><times id="S5.SS2.SSS3.p4.1.m1.1.1.1.cmml" xref="S5.SS2.SSS3.p4.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.SSS3.p4.1.m1.1.1.2.cmml" xref="S5.SS2.SSS3.p4.1.m1.1.1.2">256</cn><cn type="integer" id="S5.SS2.SSS3.p4.1.m1.1.1.3.cmml" xref="S5.SS2.SSS3.p4.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p4.1.m1.1c">256\times 256</annotation></semantics></math>) with a large batch size (<em id="S5.SS2.SSS3.p4.2.2" class="ltx_emph ltx_font_italic">i.e.</em> <math id="S5.SS2.SSS3.p4.2.m2.1" class="ltx_Math" alttext="\#Batch=256" display="inline"><semantics id="S5.SS2.SSS3.p4.2.m2.1a"><mrow id="S5.SS2.SSS3.p4.2.m2.1.1" xref="S5.SS2.SSS3.p4.2.m2.1.1.cmml"><mrow id="S5.SS2.SSS3.p4.2.m2.1.1.2" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.cmml"><mi mathvariant="normal" id="S5.SS2.SSS3.p4.2.m2.1.1.2.2" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.2.cmml">#</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS3.p4.2.m2.1.1.2.1" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS3.p4.2.m2.1.1.2.3" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.3.cmml">B</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS3.p4.2.m2.1.1.2.1a" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS3.p4.2.m2.1.1.2.4" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS3.p4.2.m2.1.1.2.1b" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS3.p4.2.m2.1.1.2.5" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS3.p4.2.m2.1.1.2.1c" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS3.p4.2.m2.1.1.2.6" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS2.SSS3.p4.2.m2.1.1.2.1d" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.1.cmml">‚Äã</mo><mi id="S5.SS2.SSS3.p4.2.m2.1.1.2.7" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.7.cmml">h</mi></mrow><mo id="S5.SS2.SSS3.p4.2.m2.1.1.1" xref="S5.SS2.SSS3.p4.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS2.SSS3.p4.2.m2.1.1.3" xref="S5.SS2.SSS3.p4.2.m2.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS3.p4.2.m2.1b"><apply id="S5.SS2.SSS3.p4.2.m2.1.1.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1"><eq id="S5.SS2.SSS3.p4.2.m2.1.1.1.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.1"></eq><apply id="S5.SS2.SSS3.p4.2.m2.1.1.2.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2"><times id="S5.SS2.SSS3.p4.2.m2.1.1.2.1.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.1"></times><ci id="S5.SS2.SSS3.p4.2.m2.1.1.2.2.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.2">#</ci><ci id="S5.SS2.SSS3.p4.2.m2.1.1.2.3.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.3">ùêµ</ci><ci id="S5.SS2.SSS3.p4.2.m2.1.1.2.4.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.4">ùëé</ci><ci id="S5.SS2.SSS3.p4.2.m2.1.1.2.5.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.5">ùë°</ci><ci id="S5.SS2.SSS3.p4.2.m2.1.1.2.6.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.6">ùëê</ci><ci id="S5.SS2.SSS3.p4.2.m2.1.1.2.7.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.2.7">‚Ñé</ci></apply><cn type="integer" id="S5.SS2.SSS3.p4.2.m2.1.1.3.cmml" xref="S5.SS2.SSS3.p4.2.m2.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS3.p4.2.m2.1c">\#Batch=256</annotation></semantics></math>). Table¬†<a href="#S5.T7" title="Table 7 ‚Ä£ 5.2.3 Full Recovery (Generative) ‚Ä£ 5.2 Gradient-Based Data Leakage ‚Ä£ 5 Model to Data Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> presents the key differences between <abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr>, <abbr title="Improved DLG" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">iDLG</span></abbr> <abbr title="Inverting Gradient" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IG</span></abbr> and <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr>.</p>
</div>
<figure id="alg3" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg3.2.1.1" class="ltx_text ltx_font_bold">Algorithm 3</span> </span> GRNN: Data Leakage Attack¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite></figcaption>
<div id="alg3.3" class="ltx_listing ltx_listing">
<div id="alg3.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>¬†¬†<math id="alg3.l1.m1.2" class="ltx_math_unparsed" alttext="g\leftarrow\partial\mathcal{L}(\mathcal{F}(&lt;x,y&gt;,\theta))/\partial\theta" display="inline"><semantics id="alg3.l1.m1.2a"><mrow id="alg3.l1.m1.2b"><mi id="alg3.l1.m1.2.3">g</mi><mo rspace="0.1389em" stretchy="false" id="alg3.l1.m1.2.4">‚Üê</mo><mo lspace="0.1389em" rspace="0em" id="alg3.l1.m1.2.5">‚àÇ</mo><mi class="ltx_font_mathcaligraphic" id="alg3.l1.m1.2.6">‚Ñí</mi><mrow id="alg3.l1.m1.2.7"><mo stretchy="false" id="alg3.l1.m1.2.7.1">(</mo><mi class="ltx_font_mathcaligraphic" id="alg3.l1.m1.2.7.2">‚Ñ±</mi><mrow id="alg3.l1.m1.2.7.3"><mo stretchy="false" id="alg3.l1.m1.2.7.3.1">(</mo><mo lspace="0em" id="alg3.l1.m1.2.7.3.2">&lt;</mo><mi id="alg3.l1.m1.1.1">x</mi><mo id="alg3.l1.m1.2.7.3.3">,</mo><mi id="alg3.l1.m1.2.2">y</mi><mo rspace="0em" id="alg3.l1.m1.2.7.3.4">&gt;</mo><mo id="alg3.l1.m1.2.7.3.5">,</mo><mi id="alg3.l1.m1.2.7.3.6">Œ∏</mi><mo stretchy="false" id="alg3.l1.m1.2.7.3.7">)</mo></mrow><mo stretchy="false" id="alg3.l1.m1.2.7.4">)</mo></mrow><mo id="alg3.l1.m1.2.8">/</mo><mo lspace="0em" rspace="0em" id="alg3.l1.m1.2.9">‚àÇ</mo><mi id="alg3.l1.m1.2.10">Œ∏</mi></mrow><annotation encoding="application/x-tex" id="alg3.l1.m1.2c">g\leftarrow\partial\mathcal{L}(\mathcal{F}(&lt;x,y&gt;,\theta))/\partial\theta</annotation></semantics></math>; <span id="alg3.l1.2" class="ltx_text" style="float:right;">#Produce true gradient on local client.
</span>
</div>
<div id="alg3.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>¬†¬†<math id="alg3.l2.m1.1" class="ltx_Math" alttext="v\leftarrow" display="inline"><semantics id="alg3.l2.m1.1a"><mrow id="alg3.l2.m1.1.1" xref="alg3.l2.m1.1.1.cmml"><mi id="alg3.l2.m1.1.1.2" xref="alg3.l2.m1.1.1.2.cmml">v</mi><mo stretchy="false" id="alg3.l2.m1.1.1.1" xref="alg3.l2.m1.1.1.1.cmml">‚Üê</mo><mi id="alg3.l2.m1.1.1.3" xref="alg3.l2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg3.l2.m1.1b"><apply id="alg3.l2.m1.1.1.cmml" xref="alg3.l2.m1.1.1"><ci id="alg3.l2.m1.1.1.1.cmml" xref="alg3.l2.m1.1.1.1">‚Üê</ci><ci id="alg3.l2.m1.1.1.2.cmml" xref="alg3.l2.m1.1.1.2">ùë£</ci><csymbol cd="latexml" id="alg3.l2.m1.1.1.3.cmml" xref="alg3.l2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l2.m1.1c">v\leftarrow</annotation></semantics></math> Sampling from <math id="alg3.l2.m2.2" class="ltx_Math" alttext="\mathcal{N}(0,1)" display="inline"><semantics id="alg3.l2.m2.2a"><mrow id="alg3.l2.m2.2.3" xref="alg3.l2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l2.m2.2.3.2" xref="alg3.l2.m2.2.3.2.cmml">ùí©</mi><mo lspace="0em" rspace="0em" id="alg3.l2.m2.2.3.1" xref="alg3.l2.m2.2.3.1.cmml">‚Äã</mo><mrow id="alg3.l2.m2.2.3.3.2" xref="alg3.l2.m2.2.3.3.1.cmml"><mo stretchy="false" id="alg3.l2.m2.2.3.3.2.1" xref="alg3.l2.m2.2.3.3.1.cmml">(</mo><mn id="alg3.l2.m2.1.1" xref="alg3.l2.m2.1.1.cmml">0</mn><mo id="alg3.l2.m2.2.3.3.2.2" xref="alg3.l2.m2.2.3.3.1.cmml">,</mo><mn id="alg3.l2.m2.2.2" xref="alg3.l2.m2.2.2.cmml">1</mn><mo stretchy="false" id="alg3.l2.m2.2.3.3.2.3" xref="alg3.l2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l2.m2.2b"><apply id="alg3.l2.m2.2.3.cmml" xref="alg3.l2.m2.2.3"><times id="alg3.l2.m2.2.3.1.cmml" xref="alg3.l2.m2.2.3.1"></times><ci id="alg3.l2.m2.2.3.2.cmml" xref="alg3.l2.m2.2.3.2">ùí©</ci><interval closure="open" id="alg3.l2.m2.2.3.3.1.cmml" xref="alg3.l2.m2.2.3.3.2"><cn type="integer" id="alg3.l2.m2.1.1.cmml" xref="alg3.l2.m2.1.1">0</cn><cn type="integer" id="alg3.l2.m2.2.2.cmml" xref="alg3.l2.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l2.m2.2c">\mathcal{N}(0,1)</annotation></semantics></math>; <span id="alg3.l2.2" class="ltx_text" style="float:right;">#Initialize random vector inputs.
</span>
</div>
<div id="alg3.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>¬†¬†<span id="alg3.l3.2" class="ltx_text ltx_font_bold">for</span>¬†each iteration <math id="alg3.l3.m1.4" class="ltx_Math" alttext="i\in[1,2,...,I]" display="inline"><semantics id="alg3.l3.m1.4a"><mrow id="alg3.l3.m1.4.5" xref="alg3.l3.m1.4.5.cmml"><mi id="alg3.l3.m1.4.5.2" xref="alg3.l3.m1.4.5.2.cmml">i</mi><mo id="alg3.l3.m1.4.5.1" xref="alg3.l3.m1.4.5.1.cmml">‚àà</mo><mrow id="alg3.l3.m1.4.5.3.2" xref="alg3.l3.m1.4.5.3.1.cmml"><mo stretchy="false" id="alg3.l3.m1.4.5.3.2.1" xref="alg3.l3.m1.4.5.3.1.cmml">[</mo><mn id="alg3.l3.m1.1.1" xref="alg3.l3.m1.1.1.cmml">1</mn><mo id="alg3.l3.m1.4.5.3.2.2" xref="alg3.l3.m1.4.5.3.1.cmml">,</mo><mn id="alg3.l3.m1.2.2" xref="alg3.l3.m1.2.2.cmml">2</mn><mo id="alg3.l3.m1.4.5.3.2.3" xref="alg3.l3.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="alg3.l3.m1.3.3" xref="alg3.l3.m1.3.3.cmml">‚Ä¶</mi><mo id="alg3.l3.m1.4.5.3.2.4" xref="alg3.l3.m1.4.5.3.1.cmml">,</mo><mi id="alg3.l3.m1.4.4" xref="alg3.l3.m1.4.4.cmml">I</mi><mo stretchy="false" id="alg3.l3.m1.4.5.3.2.5" xref="alg3.l3.m1.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l3.m1.4b"><apply id="alg3.l3.m1.4.5.cmml" xref="alg3.l3.m1.4.5"><in id="alg3.l3.m1.4.5.1.cmml" xref="alg3.l3.m1.4.5.1"></in><ci id="alg3.l3.m1.4.5.2.cmml" xref="alg3.l3.m1.4.5.2">ùëñ</ci><list id="alg3.l3.m1.4.5.3.1.cmml" xref="alg3.l3.m1.4.5.3.2"><cn type="integer" id="alg3.l3.m1.1.1.cmml" xref="alg3.l3.m1.1.1">1</cn><cn type="integer" id="alg3.l3.m1.2.2.cmml" xref="alg3.l3.m1.2.2">2</cn><ci id="alg3.l3.m1.3.3.cmml" xref="alg3.l3.m1.3.3">‚Ä¶</ci><ci id="alg3.l3.m1.4.4.cmml" xref="alg3.l3.m1.4.4">ùêº</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l3.m1.4c">i\in[1,2,...,I]</annotation></semantics></math>¬†<span id="alg3.l3.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg3.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>¬†¬†¬†¬†¬†<math id="alg3.l4.m1.3" class="ltx_Math" alttext="(\hat{x}_{i},\hat{y}_{i})\leftarrow\mathcal{G}(v|\hat{\theta}_{i})" display="inline"><semantics id="alg3.l4.m1.3a"><mrow id="alg3.l4.m1.3.3" xref="alg3.l4.m1.3.3.cmml"><mrow id="alg3.l4.m1.2.2.2.2" xref="alg3.l4.m1.2.2.2.3.cmml"><mo stretchy="false" id="alg3.l4.m1.2.2.2.2.3" xref="alg3.l4.m1.2.2.2.3.cmml">(</mo><msub id="alg3.l4.m1.1.1.1.1.1" xref="alg3.l4.m1.1.1.1.1.1.cmml"><mover accent="true" id="alg3.l4.m1.1.1.1.1.1.2" xref="alg3.l4.m1.1.1.1.1.1.2.cmml"><mi id="alg3.l4.m1.1.1.1.1.1.2.2" xref="alg3.l4.m1.1.1.1.1.1.2.2.cmml">x</mi><mo id="alg3.l4.m1.1.1.1.1.1.2.1" xref="alg3.l4.m1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="alg3.l4.m1.1.1.1.1.1.3" xref="alg3.l4.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg3.l4.m1.2.2.2.2.4" xref="alg3.l4.m1.2.2.2.3.cmml">,</mo><msub id="alg3.l4.m1.2.2.2.2.2" xref="alg3.l4.m1.2.2.2.2.2.cmml"><mover accent="true" id="alg3.l4.m1.2.2.2.2.2.2" xref="alg3.l4.m1.2.2.2.2.2.2.cmml"><mi id="alg3.l4.m1.2.2.2.2.2.2.2" xref="alg3.l4.m1.2.2.2.2.2.2.2.cmml">y</mi><mo id="alg3.l4.m1.2.2.2.2.2.2.1" xref="alg3.l4.m1.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="alg3.l4.m1.2.2.2.2.2.3" xref="alg3.l4.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg3.l4.m1.2.2.2.2.5" xref="alg3.l4.m1.2.2.2.3.cmml">)</mo></mrow><mo stretchy="false" id="alg3.l4.m1.3.3.4" xref="alg3.l4.m1.3.3.4.cmml">‚Üê</mo><mrow id="alg3.l4.m1.3.3.3" xref="alg3.l4.m1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l4.m1.3.3.3.3" xref="alg3.l4.m1.3.3.3.3.cmml">ùí¢</mi><mo lspace="0em" rspace="0em" id="alg3.l4.m1.3.3.3.2" xref="alg3.l4.m1.3.3.3.2.cmml">‚Äã</mo><mrow id="alg3.l4.m1.3.3.3.1.1" xref="alg3.l4.m1.3.3.3.1.1.1.cmml"><mo stretchy="false" id="alg3.l4.m1.3.3.3.1.1.2" xref="alg3.l4.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="alg3.l4.m1.3.3.3.1.1.1" xref="alg3.l4.m1.3.3.3.1.1.1.cmml"><mi id="alg3.l4.m1.3.3.3.1.1.1.2" xref="alg3.l4.m1.3.3.3.1.1.1.2.cmml">v</mi><mo fence="false" id="alg3.l4.m1.3.3.3.1.1.1.1" xref="alg3.l4.m1.3.3.3.1.1.1.1.cmml">|</mo><msub id="alg3.l4.m1.3.3.3.1.1.1.3" xref="alg3.l4.m1.3.3.3.1.1.1.3.cmml"><mover accent="true" id="alg3.l4.m1.3.3.3.1.1.1.3.2" xref="alg3.l4.m1.3.3.3.1.1.1.3.2.cmml"><mi id="alg3.l4.m1.3.3.3.1.1.1.3.2.2" xref="alg3.l4.m1.3.3.3.1.1.1.3.2.2.cmml">Œ∏</mi><mo id="alg3.l4.m1.3.3.3.1.1.1.3.2.1" xref="alg3.l4.m1.3.3.3.1.1.1.3.2.1.cmml">^</mo></mover><mi id="alg3.l4.m1.3.3.3.1.1.1.3.3" xref="alg3.l4.m1.3.3.3.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="alg3.l4.m1.3.3.3.1.1.3" xref="alg3.l4.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l4.m1.3b"><apply id="alg3.l4.m1.3.3.cmml" xref="alg3.l4.m1.3.3"><ci id="alg3.l4.m1.3.3.4.cmml" xref="alg3.l4.m1.3.3.4">‚Üê</ci><interval closure="open" id="alg3.l4.m1.2.2.2.3.cmml" xref="alg3.l4.m1.2.2.2.2"><apply id="alg3.l4.m1.1.1.1.1.1.cmml" xref="alg3.l4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l4.m1.1.1.1.1.1.1.cmml" xref="alg3.l4.m1.1.1.1.1.1">subscript</csymbol><apply id="alg3.l4.m1.1.1.1.1.1.2.cmml" xref="alg3.l4.m1.1.1.1.1.1.2"><ci id="alg3.l4.m1.1.1.1.1.1.2.1.cmml" xref="alg3.l4.m1.1.1.1.1.1.2.1">^</ci><ci id="alg3.l4.m1.1.1.1.1.1.2.2.cmml" xref="alg3.l4.m1.1.1.1.1.1.2.2">ùë•</ci></apply><ci id="alg3.l4.m1.1.1.1.1.1.3.cmml" xref="alg3.l4.m1.1.1.1.1.1.3">ùëñ</ci></apply><apply id="alg3.l4.m1.2.2.2.2.2.cmml" xref="alg3.l4.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="alg3.l4.m1.2.2.2.2.2.1.cmml" xref="alg3.l4.m1.2.2.2.2.2">subscript</csymbol><apply id="alg3.l4.m1.2.2.2.2.2.2.cmml" xref="alg3.l4.m1.2.2.2.2.2.2"><ci id="alg3.l4.m1.2.2.2.2.2.2.1.cmml" xref="alg3.l4.m1.2.2.2.2.2.2.1">^</ci><ci id="alg3.l4.m1.2.2.2.2.2.2.2.cmml" xref="alg3.l4.m1.2.2.2.2.2.2.2">ùë¶</ci></apply><ci id="alg3.l4.m1.2.2.2.2.2.3.cmml" xref="alg3.l4.m1.2.2.2.2.2.3">ùëñ</ci></apply></interval><apply id="alg3.l4.m1.3.3.3.cmml" xref="alg3.l4.m1.3.3.3"><times id="alg3.l4.m1.3.3.3.2.cmml" xref="alg3.l4.m1.3.3.3.2"></times><ci id="alg3.l4.m1.3.3.3.3.cmml" xref="alg3.l4.m1.3.3.3.3">ùí¢</ci><apply id="alg3.l4.m1.3.3.3.1.1.1.cmml" xref="alg3.l4.m1.3.3.3.1.1"><csymbol cd="latexml" id="alg3.l4.m1.3.3.3.1.1.1.1.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.1">conditional</csymbol><ci id="alg3.l4.m1.3.3.3.1.1.1.2.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.2">ùë£</ci><apply id="alg3.l4.m1.3.3.3.1.1.1.3.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l4.m1.3.3.3.1.1.1.3.1.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.3">subscript</csymbol><apply id="alg3.l4.m1.3.3.3.1.1.1.3.2.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.3.2"><ci id="alg3.l4.m1.3.3.3.1.1.1.3.2.1.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.3.2.1">^</ci><ci id="alg3.l4.m1.3.3.3.1.1.1.3.2.2.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.3.2.2">ùúÉ</ci></apply><ci id="alg3.l4.m1.3.3.3.1.1.1.3.3.cmml" xref="alg3.l4.m1.3.3.3.1.1.1.3.3">ùëñ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l4.m1.3c">(\hat{x}_{i},\hat{y}_{i})\leftarrow\mathcal{G}(v|\hat{\theta}_{i})</annotation></semantics></math>; <span id="alg3.l4.2" class="ltx_text" style="float:right;">#Generate fake images and labels.
</span>
</div>
<div id="alg3.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>¬†¬†¬†¬†¬†<math id="alg3.l5.m1.1" class="ltx_math_unparsed" alttext="\hat{g}_{i}\leftarrow{\partial\mathcal{L}(\mathcal{F}(&lt;\hat{x}_{i},\hat{y}_{i}&gt;,\theta))}/{\partial\theta}" display="inline"><semantics id="alg3.l5.m1.1a"><mrow id="alg3.l5.m1.1b"><msub id="alg3.l5.m1.1.1"><mover accent="true" id="alg3.l5.m1.1.1.2"><mi id="alg3.l5.m1.1.1.2.2">g</mi><mo id="alg3.l5.m1.1.1.2.1">^</mo></mover><mi id="alg3.l5.m1.1.1.3">i</mi></msub><mo rspace="0.1389em" stretchy="false" id="alg3.l5.m1.1.2">‚Üê</mo><mo lspace="0.1389em" rspace="0em" id="alg3.l5.m1.1.3">‚àÇ</mo><mi class="ltx_font_mathcaligraphic" id="alg3.l5.m1.1.4">‚Ñí</mi><mrow id="alg3.l5.m1.1.5"><mo stretchy="false" id="alg3.l5.m1.1.5.1">(</mo><mi class="ltx_font_mathcaligraphic" id="alg3.l5.m1.1.5.2">‚Ñ±</mi><mrow id="alg3.l5.m1.1.5.3"><mo stretchy="false" id="alg3.l5.m1.1.5.3.1">(</mo><mo lspace="0em" id="alg3.l5.m1.1.5.3.2">&lt;</mo><msub id="alg3.l5.m1.1.5.3.3"><mover accent="true" id="alg3.l5.m1.1.5.3.3.2"><mi id="alg3.l5.m1.1.5.3.3.2.2">x</mi><mo id="alg3.l5.m1.1.5.3.3.2.1">^</mo></mover><mi id="alg3.l5.m1.1.5.3.3.3">i</mi></msub><mo id="alg3.l5.m1.1.5.3.4">,</mo><msub id="alg3.l5.m1.1.5.3.5"><mover accent="true" id="alg3.l5.m1.1.5.3.5.2"><mi id="alg3.l5.m1.1.5.3.5.2.2">y</mi><mo id="alg3.l5.m1.1.5.3.5.2.1">^</mo></mover><mi id="alg3.l5.m1.1.5.3.5.3">i</mi></msub><mo rspace="0em" id="alg3.l5.m1.1.5.3.6">&gt;</mo><mo id="alg3.l5.m1.1.5.3.7">,</mo><mi id="alg3.l5.m1.1.5.3.8">Œ∏</mi><mo stretchy="false" id="alg3.l5.m1.1.5.3.9">)</mo></mrow><mo stretchy="false" id="alg3.l5.m1.1.5.4">)</mo></mrow><mo id="alg3.l5.m1.1.6">/</mo><mo lspace="0em" rspace="0em" id="alg3.l5.m1.1.7">‚àÇ</mo><mi id="alg3.l5.m1.1.8">Œ∏</mi></mrow><annotation encoding="application/x-tex" id="alg3.l5.m1.1c">\hat{g}_{i}\leftarrow{\partial\mathcal{L}(\mathcal{F}(&lt;\hat{x}_{i},\hat{y}_{i}&gt;,\theta))}/{\partial\theta}</annotation></semantics></math>; <span id="alg3.l5.2" class="ltx_text" style="float:right;">#Get fake gradient on global model.
</span>
</div>
<div id="alg3.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>¬†¬†¬†¬†¬†<math id="alg3.l6.m1.3" class="ltx_Math" alttext="\mathcal{D}_{i}\leftarrow\hat{\mathcal{L}}(g,\hat{g}_{i},\hat{x}_{i})" display="inline"><semantics id="alg3.l6.m1.3a"><mrow id="alg3.l6.m1.3.3" xref="alg3.l6.m1.3.3.cmml"><msub id="alg3.l6.m1.3.3.4" xref="alg3.l6.m1.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l6.m1.3.3.4.2" xref="alg3.l6.m1.3.3.4.2.cmml">ùíü</mi><mi id="alg3.l6.m1.3.3.4.3" xref="alg3.l6.m1.3.3.4.3.cmml">i</mi></msub><mo stretchy="false" id="alg3.l6.m1.3.3.3" xref="alg3.l6.m1.3.3.3.cmml">‚Üê</mo><mrow id="alg3.l6.m1.3.3.2" xref="alg3.l6.m1.3.3.2.cmml"><mover accent="true" id="alg3.l6.m1.3.3.2.4" xref="alg3.l6.m1.3.3.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l6.m1.3.3.2.4.2" xref="alg3.l6.m1.3.3.2.4.2.cmml">‚Ñí</mi><mo id="alg3.l6.m1.3.3.2.4.1" xref="alg3.l6.m1.3.3.2.4.1.cmml">^</mo></mover><mo lspace="0em" rspace="0em" id="alg3.l6.m1.3.3.2.3" xref="alg3.l6.m1.3.3.2.3.cmml">‚Äã</mo><mrow id="alg3.l6.m1.3.3.2.2.2" xref="alg3.l6.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="alg3.l6.m1.3.3.2.2.2.3" xref="alg3.l6.m1.3.3.2.2.3.cmml">(</mo><mi id="alg3.l6.m1.1.1" xref="alg3.l6.m1.1.1.cmml">g</mi><mo id="alg3.l6.m1.3.3.2.2.2.4" xref="alg3.l6.m1.3.3.2.2.3.cmml">,</mo><msub id="alg3.l6.m1.2.2.1.1.1.1" xref="alg3.l6.m1.2.2.1.1.1.1.cmml"><mover accent="true" id="alg3.l6.m1.2.2.1.1.1.1.2" xref="alg3.l6.m1.2.2.1.1.1.1.2.cmml"><mi id="alg3.l6.m1.2.2.1.1.1.1.2.2" xref="alg3.l6.m1.2.2.1.1.1.1.2.2.cmml">g</mi><mo id="alg3.l6.m1.2.2.1.1.1.1.2.1" xref="alg3.l6.m1.2.2.1.1.1.1.2.1.cmml">^</mo></mover><mi id="alg3.l6.m1.2.2.1.1.1.1.3" xref="alg3.l6.m1.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="alg3.l6.m1.3.3.2.2.2.5" xref="alg3.l6.m1.3.3.2.2.3.cmml">,</mo><msub id="alg3.l6.m1.3.3.2.2.2.2" xref="alg3.l6.m1.3.3.2.2.2.2.cmml"><mover accent="true" id="alg3.l6.m1.3.3.2.2.2.2.2" xref="alg3.l6.m1.3.3.2.2.2.2.2.cmml"><mi id="alg3.l6.m1.3.3.2.2.2.2.2.2" xref="alg3.l6.m1.3.3.2.2.2.2.2.2.cmml">x</mi><mo id="alg3.l6.m1.3.3.2.2.2.2.2.1" xref="alg3.l6.m1.3.3.2.2.2.2.2.1.cmml">^</mo></mover><mi id="alg3.l6.m1.3.3.2.2.2.2.3" xref="alg3.l6.m1.3.3.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="alg3.l6.m1.3.3.2.2.2.6" xref="alg3.l6.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l6.m1.3b"><apply id="alg3.l6.m1.3.3.cmml" xref="alg3.l6.m1.3.3"><ci id="alg3.l6.m1.3.3.3.cmml" xref="alg3.l6.m1.3.3.3">‚Üê</ci><apply id="alg3.l6.m1.3.3.4.cmml" xref="alg3.l6.m1.3.3.4"><csymbol cd="ambiguous" id="alg3.l6.m1.3.3.4.1.cmml" xref="alg3.l6.m1.3.3.4">subscript</csymbol><ci id="alg3.l6.m1.3.3.4.2.cmml" xref="alg3.l6.m1.3.3.4.2">ùíü</ci><ci id="alg3.l6.m1.3.3.4.3.cmml" xref="alg3.l6.m1.3.3.4.3">ùëñ</ci></apply><apply id="alg3.l6.m1.3.3.2.cmml" xref="alg3.l6.m1.3.3.2"><times id="alg3.l6.m1.3.3.2.3.cmml" xref="alg3.l6.m1.3.3.2.3"></times><apply id="alg3.l6.m1.3.3.2.4.cmml" xref="alg3.l6.m1.3.3.2.4"><ci id="alg3.l6.m1.3.3.2.4.1.cmml" xref="alg3.l6.m1.3.3.2.4.1">^</ci><ci id="alg3.l6.m1.3.3.2.4.2.cmml" xref="alg3.l6.m1.3.3.2.4.2">‚Ñí</ci></apply><vector id="alg3.l6.m1.3.3.2.2.3.cmml" xref="alg3.l6.m1.3.3.2.2.2"><ci id="alg3.l6.m1.1.1.cmml" xref="alg3.l6.m1.1.1">ùëî</ci><apply id="alg3.l6.m1.2.2.1.1.1.1.cmml" xref="alg3.l6.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l6.m1.2.2.1.1.1.1.1.cmml" xref="alg3.l6.m1.2.2.1.1.1.1">subscript</csymbol><apply id="alg3.l6.m1.2.2.1.1.1.1.2.cmml" xref="alg3.l6.m1.2.2.1.1.1.1.2"><ci id="alg3.l6.m1.2.2.1.1.1.1.2.1.cmml" xref="alg3.l6.m1.2.2.1.1.1.1.2.1">^</ci><ci id="alg3.l6.m1.2.2.1.1.1.1.2.2.cmml" xref="alg3.l6.m1.2.2.1.1.1.1.2.2">ùëî</ci></apply><ci id="alg3.l6.m1.2.2.1.1.1.1.3.cmml" xref="alg3.l6.m1.2.2.1.1.1.1.3">ùëñ</ci></apply><apply id="alg3.l6.m1.3.3.2.2.2.2.cmml" xref="alg3.l6.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="alg3.l6.m1.3.3.2.2.2.2.1.cmml" xref="alg3.l6.m1.3.3.2.2.2.2">subscript</csymbol><apply id="alg3.l6.m1.3.3.2.2.2.2.2.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.2"><ci id="alg3.l6.m1.3.3.2.2.2.2.2.1.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.2.1">^</ci><ci id="alg3.l6.m1.3.3.2.2.2.2.2.2.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.2.2">ùë•</ci></apply><ci id="alg3.l6.m1.3.3.2.2.2.2.3.cmml" xref="alg3.l6.m1.3.3.2.2.2.2.3">ùëñ</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l6.m1.3c">\mathcal{D}_{i}\leftarrow\hat{\mathcal{L}}(g,\hat{g}_{i},\hat{x}_{i})</annotation></semantics></math>; <span id="alg3.l6.2" class="ltx_text" style="float:right;">#Loss between true and fake gradient.
</span>
</div>
<div id="alg3.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>¬†¬†¬†¬†¬†<math id="alg3.l7.m1.1" class="ltx_Math" alttext="\hat{\theta}_{i+1}\leftarrow{\hat{\theta}_{i}-\eta(\partial\mathcal{D}_{i}}/{\partial\hat{\theta}_{i})}" display="inline"><semantics id="alg3.l7.m1.1a"><mrow id="alg3.l7.m1.1.1" xref="alg3.l7.m1.1.1.cmml"><msub id="alg3.l7.m1.1.1.3" xref="alg3.l7.m1.1.1.3.cmml"><mover accent="true" id="alg3.l7.m1.1.1.3.2" xref="alg3.l7.m1.1.1.3.2.cmml"><mi id="alg3.l7.m1.1.1.3.2.2" xref="alg3.l7.m1.1.1.3.2.2.cmml">Œ∏</mi><mo id="alg3.l7.m1.1.1.3.2.1" xref="alg3.l7.m1.1.1.3.2.1.cmml">^</mo></mover><mrow id="alg3.l7.m1.1.1.3.3" xref="alg3.l7.m1.1.1.3.3.cmml"><mi id="alg3.l7.m1.1.1.3.3.2" xref="alg3.l7.m1.1.1.3.3.2.cmml">i</mi><mo id="alg3.l7.m1.1.1.3.3.1" xref="alg3.l7.m1.1.1.3.3.1.cmml">+</mo><mn id="alg3.l7.m1.1.1.3.3.3" xref="alg3.l7.m1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="alg3.l7.m1.1.1.2" xref="alg3.l7.m1.1.1.2.cmml">‚Üê</mo><mrow id="alg3.l7.m1.1.1.1" xref="alg3.l7.m1.1.1.1.cmml"><msub id="alg3.l7.m1.1.1.1.3" xref="alg3.l7.m1.1.1.1.3.cmml"><mover accent="true" id="alg3.l7.m1.1.1.1.3.2" xref="alg3.l7.m1.1.1.1.3.2.cmml"><mi id="alg3.l7.m1.1.1.1.3.2.2" xref="alg3.l7.m1.1.1.1.3.2.2.cmml">Œ∏</mi><mo id="alg3.l7.m1.1.1.1.3.2.1" xref="alg3.l7.m1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="alg3.l7.m1.1.1.1.3.3" xref="alg3.l7.m1.1.1.1.3.3.cmml">i</mi></msub><mo id="alg3.l7.m1.1.1.1.2" xref="alg3.l7.m1.1.1.1.2.cmml">‚àí</mo><mrow id="alg3.l7.m1.1.1.1.1" xref="alg3.l7.m1.1.1.1.1.cmml"><mi id="alg3.l7.m1.1.1.1.1.3" xref="alg3.l7.m1.1.1.1.1.3.cmml">Œ∑</mi><mo lspace="0em" rspace="0em" id="alg3.l7.m1.1.1.1.1.2" xref="alg3.l7.m1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="alg3.l7.m1.1.1.1.1.1.1" xref="alg3.l7.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="alg3.l7.m1.1.1.1.1.1.1.2" xref="alg3.l7.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="alg3.l7.m1.1.1.1.1.1.1.1" xref="alg3.l7.m1.1.1.1.1.1.1.1.cmml"><mo lspace="0em" rspace="0em" id="alg3.l7.m1.1.1.1.1.1.1.1.1" xref="alg3.l7.m1.1.1.1.1.1.1.1.1.cmml">‚àÇ</mo><mrow id="alg3.l7.m1.1.1.1.1.1.1.1.2" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.cmml"><msub id="alg3.l7.m1.1.1.1.1.1.1.1.2.2" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg3.l7.m1.1.1.1.1.1.1.1.2.2.2" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.2.2.cmml">ùíü</mi><mi id="alg3.l7.m1.1.1.1.1.1.1.1.2.2.3" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="alg3.l7.m1.1.1.1.1.1.1.1.2.1" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.1.cmml">/</mo><mrow id="alg3.l7.m1.1.1.1.1.1.1.1.2.3" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.cmml"><mo lspace="0em" rspace="0em" id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.1" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.1.cmml">‚àÇ</mo><msub id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.cmml"><mover accent="true" id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.cmml"><mi id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.2" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.2.cmml">Œ∏</mi><mo id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.1" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.1.cmml">^</mo></mover><mi id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.3" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.3.cmml">i</mi></msub></mrow></mrow></mrow><mo stretchy="false" id="alg3.l7.m1.1.1.1.1.1.1.3" xref="alg3.l7.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg3.l7.m1.1b"><apply id="alg3.l7.m1.1.1.cmml" xref="alg3.l7.m1.1.1"><ci id="alg3.l7.m1.1.1.2.cmml" xref="alg3.l7.m1.1.1.2">‚Üê</ci><apply id="alg3.l7.m1.1.1.3.cmml" xref="alg3.l7.m1.1.1.3"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.3.1.cmml" xref="alg3.l7.m1.1.1.3">subscript</csymbol><apply id="alg3.l7.m1.1.1.3.2.cmml" xref="alg3.l7.m1.1.1.3.2"><ci id="alg3.l7.m1.1.1.3.2.1.cmml" xref="alg3.l7.m1.1.1.3.2.1">^</ci><ci id="alg3.l7.m1.1.1.3.2.2.cmml" xref="alg3.l7.m1.1.1.3.2.2">ùúÉ</ci></apply><apply id="alg3.l7.m1.1.1.3.3.cmml" xref="alg3.l7.m1.1.1.3.3"><plus id="alg3.l7.m1.1.1.3.3.1.cmml" xref="alg3.l7.m1.1.1.3.3.1"></plus><ci id="alg3.l7.m1.1.1.3.3.2.cmml" xref="alg3.l7.m1.1.1.3.3.2">ùëñ</ci><cn type="integer" id="alg3.l7.m1.1.1.3.3.3.cmml" xref="alg3.l7.m1.1.1.3.3.3">1</cn></apply></apply><apply id="alg3.l7.m1.1.1.1.cmml" xref="alg3.l7.m1.1.1.1"><minus id="alg3.l7.m1.1.1.1.2.cmml" xref="alg3.l7.m1.1.1.1.2"></minus><apply id="alg3.l7.m1.1.1.1.3.cmml" xref="alg3.l7.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.1.3.1.cmml" xref="alg3.l7.m1.1.1.1.3">subscript</csymbol><apply id="alg3.l7.m1.1.1.1.3.2.cmml" xref="alg3.l7.m1.1.1.1.3.2"><ci id="alg3.l7.m1.1.1.1.3.2.1.cmml" xref="alg3.l7.m1.1.1.1.3.2.1">^</ci><ci id="alg3.l7.m1.1.1.1.3.2.2.cmml" xref="alg3.l7.m1.1.1.1.3.2.2">ùúÉ</ci></apply><ci id="alg3.l7.m1.1.1.1.3.3.cmml" xref="alg3.l7.m1.1.1.1.3.3">ùëñ</ci></apply><apply id="alg3.l7.m1.1.1.1.1.cmml" xref="alg3.l7.m1.1.1.1.1"><times id="alg3.l7.m1.1.1.1.1.2.cmml" xref="alg3.l7.m1.1.1.1.1.2"></times><ci id="alg3.l7.m1.1.1.1.1.3.cmml" xref="alg3.l7.m1.1.1.1.1.3">ùúÇ</ci><apply id="alg3.l7.m1.1.1.1.1.1.1.1.cmml" xref="alg3.l7.m1.1.1.1.1.1.1"><partialdiff id="alg3.l7.m1.1.1.1.1.1.1.1.1.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.1"></partialdiff><apply id="alg3.l7.m1.1.1.1.1.1.1.1.2.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2"><divide id="alg3.l7.m1.1.1.1.1.1.1.1.2.1.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.1"></divide><apply id="alg3.l7.m1.1.1.1.1.1.1.1.2.2.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="alg3.l7.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.2.2">ùíü</ci><ci id="alg3.l7.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.2.3">ùëñ</ci></apply><apply id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3"><partialdiff id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.1.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.1"></partialdiff><apply id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2">subscript</csymbol><apply id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2"><ci id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.1.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.1">^</ci><ci id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.2.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.2.2">ùúÉ</ci></apply><ci id="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="alg3.l7.m1.1.1.1.1.1.1.1.2.3.2.3">ùëñ</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg3.l7.m1.1c">\hat{\theta}_{i+1}\leftarrow{\hat{\theta}_{i}-\eta(\partial\mathcal{D}_{i}}/{\partial\hat{\theta}_{i})}</annotation></semantics></math>; <span id="alg3.l7.2" class="ltx_text" style="float:right;">#Update <abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr> model.
</span>
</div>
<div id="alg3.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>¬†¬†<span id="alg3.l8.2" class="ltx_text ltx_font_bold">end</span>¬†<span id="alg3.l8.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg3.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg3.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>¬†¬†<span id="alg3.l9.2" class="ltx_text ltx_font_bold">return</span> <math id="alg3.l9.m1.2" class="ltx_Math" alttext="(\hat{x}_{I},\hat{y}_{I})" display="inline"><semantics id="alg3.l9.m1.2a"><mrow id="alg3.l9.m1.2.2.2" xref="alg3.l9.m1.2.2.3.cmml"><mo stretchy="false" id="alg3.l9.m1.2.2.2.3" xref="alg3.l9.m1.2.2.3.cmml">(</mo><msub id="alg3.l9.m1.1.1.1.1" xref="alg3.l9.m1.1.1.1.1.cmml"><mover accent="true" id="alg3.l9.m1.1.1.1.1.2" xref="alg3.l9.m1.1.1.1.1.2.cmml"><mi id="alg3.l9.m1.1.1.1.1.2.2" xref="alg3.l9.m1.1.1.1.1.2.2.cmml">x</mi><mo id="alg3.l9.m1.1.1.1.1.2.1" xref="alg3.l9.m1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="alg3.l9.m1.1.1.1.1.3" xref="alg3.l9.m1.1.1.1.1.3.cmml">I</mi></msub><mo id="alg3.l9.m1.2.2.2.4" xref="alg3.l9.m1.2.2.3.cmml">,</mo><msub id="alg3.l9.m1.2.2.2.2" xref="alg3.l9.m1.2.2.2.2.cmml"><mover accent="true" id="alg3.l9.m1.2.2.2.2.2" xref="alg3.l9.m1.2.2.2.2.2.cmml"><mi id="alg3.l9.m1.2.2.2.2.2.2" xref="alg3.l9.m1.2.2.2.2.2.2.cmml">y</mi><mo id="alg3.l9.m1.2.2.2.2.2.1" xref="alg3.l9.m1.2.2.2.2.2.1.cmml">^</mo></mover><mi id="alg3.l9.m1.2.2.2.2.3" xref="alg3.l9.m1.2.2.2.2.3.cmml">I</mi></msub><mo stretchy="false" id="alg3.l9.m1.2.2.2.5" xref="alg3.l9.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg3.l9.m1.2b"><interval closure="open" id="alg3.l9.m1.2.2.3.cmml" xref="alg3.l9.m1.2.2.2"><apply id="alg3.l9.m1.1.1.1.1.cmml" xref="alg3.l9.m1.1.1.1.1"><csymbol cd="ambiguous" id="alg3.l9.m1.1.1.1.1.1.cmml" xref="alg3.l9.m1.1.1.1.1">subscript</csymbol><apply id="alg3.l9.m1.1.1.1.1.2.cmml" xref="alg3.l9.m1.1.1.1.1.2"><ci id="alg3.l9.m1.1.1.1.1.2.1.cmml" xref="alg3.l9.m1.1.1.1.1.2.1">^</ci><ci id="alg3.l9.m1.1.1.1.1.2.2.cmml" xref="alg3.l9.m1.1.1.1.1.2.2">ùë•</ci></apply><ci id="alg3.l9.m1.1.1.1.1.3.cmml" xref="alg3.l9.m1.1.1.1.1.3">ùêº</ci></apply><apply id="alg3.l9.m1.2.2.2.2.cmml" xref="alg3.l9.m1.2.2.2.2"><csymbol cd="ambiguous" id="alg3.l9.m1.2.2.2.2.1.cmml" xref="alg3.l9.m1.2.2.2.2">subscript</csymbol><apply id="alg3.l9.m1.2.2.2.2.2.cmml" xref="alg3.l9.m1.2.2.2.2.2"><ci id="alg3.l9.m1.2.2.2.2.2.1.cmml" xref="alg3.l9.m1.2.2.2.2.2.1">^</ci><ci id="alg3.l9.m1.2.2.2.2.2.2.cmml" xref="alg3.l9.m1.2.2.2.2.2.2">ùë¶</ci></apply><ci id="alg3.l9.m1.2.2.2.2.3.cmml" xref="alg3.l9.m1.2.2.2.2.3">ùêº</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="alg3.l9.m1.2c">(\hat{x}_{I},\hat{y}_{I})</annotation></semantics></math>; <span id="alg3.l9.3" class="ltx_text" style="float:right;">#Return generated fake images and labels.
</span>
</div>
</div>
</figure>
<figure id="S5.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Comparison of different related works on gradient leakage.¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite></figcaption>
<table id="S5.T7.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T7.5.6" class="ltx_tr">
<td id="S5.T7.5.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;"><span id="S5.T7.5.6.1.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S5.T7.5.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">
<span id="S5.T7.5.6.2.1" class="ltx_text"></span><span id="S5.T7.5.6.2.2" class="ltx_text ltx_font_bold"> <span id="S5.T7.5.6.2.2.1" class="ltx_text">
<span id="S5.T7.5.6.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T7.5.6.2.2.1.1.1" class="ltx_tr">
<span id="S5.T7.5.6.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 10.0pt;">Recovery</span></span>
<span id="S5.T7.5.6.2.2.1.1.2" class="ltx_tr">
<span id="S5.T7.5.6.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 10.0pt;">Mode</span></span>
</span></span><span id="S5.T7.5.6.2.2.2" class="ltx_text"></span></span>
</td>
<td id="S5.T7.5.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;"><span id="S5.T7.5.6.3.1" class="ltx_text ltx_font_bold">#Batch</span></td>
<td id="S5.T7.5.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;"><span id="S5.T7.5.6.4.1" class="ltx_text ltx_font_bold">Resolution</span></td>
<td id="S5.T7.5.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 10.0pt;">
<span id="S5.T7.5.6.5.1" class="ltx_text"></span><span id="S5.T7.5.6.5.2" class="ltx_text ltx_font_bold"> <span id="S5.T7.5.6.5.2.1" class="ltx_text">
<span id="S5.T7.5.6.5.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T7.5.6.5.2.1.1.1" class="ltx_tr">
<span id="S5.T7.5.6.5.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 10.0pt;">Loss Function</span></span>
</span></span><span id="S5.T7.5.6.5.2.2" class="ltx_text"></span></span>
</td>
</tr>
<tr id="S5.T7.1.1" class="ltx_tr">
<td id="S5.T7.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">
<abbr title="Deep Leakage from Gradients" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DLG</span></abbr><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>
</td>
<td id="S5.T7.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Discriminative</td>
<td id="S5.T7.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Small, up to 8</td>
<td id="S5.T7.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Low <math id="S5.T7.1.1.1.m1.1" class="ltx_Math" alttext="64\times 64" display="inline"><semantics id="S5.T7.1.1.1.m1.1a"><mrow id="S5.T7.1.1.1.m1.1.1" xref="S5.T7.1.1.1.m1.1.1.cmml"><mn id="S5.T7.1.1.1.m1.1.1.2" xref="S5.T7.1.1.1.m1.1.1.2.cmml">64</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T7.1.1.1.m1.1.1.1" xref="S5.T7.1.1.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.T7.1.1.1.m1.1.1.3" xref="S5.T7.1.1.1.m1.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T7.1.1.1.m1.1b"><apply id="S5.T7.1.1.1.m1.1.1.cmml" xref="S5.T7.1.1.1.m1.1.1"><times id="S5.T7.1.1.1.m1.1.1.1.cmml" xref="S5.T7.1.1.1.m1.1.1.1"></times><cn type="integer" id="S5.T7.1.1.1.m1.1.1.2.cmml" xref="S5.T7.1.1.1.m1.1.1.2">64</cn><cn type="integer" id="S5.T7.1.1.1.m1.1.1.3.cmml" xref="S5.T7.1.1.1.m1.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.1.1.1.m1.1c">64\times 64</annotation></semantics></math>
</td>
<td id="S5.T7.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 10.0pt;"><abbr title="Mean Square Error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSE</span></abbr></td>
</tr>
<tr id="S5.T7.2.2" class="ltx_tr">
<td id="S5.T7.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">
<abbr title="Improved DLG" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">iDLG</span></abbr><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>
</td>
<td id="S5.T7.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Discriminative</td>
<td id="S5.T7.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Small, only 1</td>
<td id="S5.T7.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Low <math id="S5.T7.2.2.1.m1.1" class="ltx_Math" alttext="64\times 64" display="inline"><semantics id="S5.T7.2.2.1.m1.1a"><mrow id="S5.T7.2.2.1.m1.1.1" xref="S5.T7.2.2.1.m1.1.1.cmml"><mn id="S5.T7.2.2.1.m1.1.1.2" xref="S5.T7.2.2.1.m1.1.1.2.cmml">64</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T7.2.2.1.m1.1.1.1" xref="S5.T7.2.2.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.T7.2.2.1.m1.1.1.3" xref="S5.T7.2.2.1.m1.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T7.2.2.1.m1.1b"><apply id="S5.T7.2.2.1.m1.1.1.cmml" xref="S5.T7.2.2.1.m1.1.1"><times id="S5.T7.2.2.1.m1.1.1.1.cmml" xref="S5.T7.2.2.1.m1.1.1.1"></times><cn type="integer" id="S5.T7.2.2.1.m1.1.1.2.cmml" xref="S5.T7.2.2.1.m1.1.1.2">64</cn><cn type="integer" id="S5.T7.2.2.1.m1.1.1.3.cmml" xref="S5.T7.2.2.1.m1.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.2.2.1.m1.1c">64\times 64</annotation></semantics></math>
</td>
<td id="S5.T7.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 10.0pt;"><abbr title="Mean Square Error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSE</span></abbr></td>
</tr>
<tr id="S5.T7.3.3" class="ltx_tr">
<td id="S5.T7.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">
<abbr title="Inverting Gradient" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">IG</span></abbr><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>
</td>
<td id="S5.T7.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Discriminative</td>
<td id="S5.T7.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Medium, up to 100</td>
<td id="S5.T7.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">High <math id="S5.T7.3.3.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S5.T7.3.3.1.m1.1a"><mrow id="S5.T7.3.3.1.m1.1.1" xref="S5.T7.3.3.1.m1.1.1.cmml"><mn id="S5.T7.3.3.1.m1.1.1.2" xref="S5.T7.3.3.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T7.3.3.1.m1.1.1.1" xref="S5.T7.3.3.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.T7.3.3.1.m1.1.1.3" xref="S5.T7.3.3.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T7.3.3.1.m1.1b"><apply id="S5.T7.3.3.1.m1.1.1.cmml" xref="S5.T7.3.3.1.m1.1.1"><times id="S5.T7.3.3.1.m1.1.1.1.cmml" xref="S5.T7.3.3.1.m1.1.1.1"></times><cn type="integer" id="S5.T7.3.3.1.m1.1.1.2.cmml" xref="S5.T7.3.3.1.m1.1.1.2">224</cn><cn type="integer" id="S5.T7.3.3.1.m1.1.1.3.cmml" xref="S5.T7.3.3.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.3.3.1.m1.1c">224\times 224</annotation></semantics></math>
</td>
<td id="S5.T7.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 10.0pt;">
<span id="S5.T7.3.3.5.1" class="ltx_text"></span> <span id="S5.T7.3.3.5.2" class="ltx_text">
<span id="S5.T7.3.3.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T7.3.3.5.2.1.1" class="ltx_tr">
<span id="S5.T7.3.3.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 10.0pt;"><abbr title="Cosine Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CD</span></abbr> &amp; <abbr title="Total Variation Loss" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TVLoss</span></abbr></span></span>
</span></span><span id="S5.T7.3.3.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T7.4.4" class="ltx_tr">
<td id="S5.T7.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">
<abbr title="Generative Gradient Leakage" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GGL</span></abbr><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>
</td>
<td id="S5.T7.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Generative</td>
<td id="S5.T7.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Small, only 1</td>
<td id="S5.T7.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">High <math id="S5.T7.4.4.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S5.T7.4.4.1.m1.1a"><mrow id="S5.T7.4.4.1.m1.1.1" xref="S5.T7.4.4.1.m1.1.1.cmml"><mn id="S5.T7.4.4.1.m1.1.1.2" xref="S5.T7.4.4.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T7.4.4.1.m1.1.1.1" xref="S5.T7.4.4.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.T7.4.4.1.m1.1.1.3" xref="S5.T7.4.4.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T7.4.4.1.m1.1b"><apply id="S5.T7.4.4.1.m1.1.1.cmml" xref="S5.T7.4.4.1.m1.1.1"><times id="S5.T7.4.4.1.m1.1.1.1.cmml" xref="S5.T7.4.4.1.m1.1.1.1"></times><cn type="integer" id="S5.T7.4.4.1.m1.1.1.2.cmml" xref="S5.T7.4.4.1.m1.1.1.2">224</cn><cn type="integer" id="S5.T7.4.4.1.m1.1.1.3.cmml" xref="S5.T7.4.4.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.4.4.1.m1.1c">224\times 224</annotation></semantics></math>
</td>
<td id="S5.T7.4.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 10.0pt;">
<span id="S5.T7.4.4.5.1" class="ltx_text"></span> <span id="S5.T7.4.4.5.2" class="ltx_text">
<span id="S5.T7.4.4.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T7.4.4.5.2.1.1" class="ltx_tr">
<span id="S5.T7.4.4.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 10.0pt;"><abbr title="Covariance Matrix Adaptation Evolution Strategy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CMA-ES</span></abbr> &amp; <abbr title="Bayesian Optimization" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BO</span></abbr></span></span>
</span></span><span id="S5.T7.4.4.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S5.T7.5.5" class="ltx_tr">
<td id="S5.T7.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">
<abbr title="Generative Regression Neural Network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">GRNN</span></abbr><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>
</td>
<td id="S5.T7.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Generative</td>
<td id="S5.T7.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">Large, up to 256</td>
<td id="S5.T7.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding:2.5pt 10.0pt;">High <math id="S5.T7.5.5.1.m1.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="S5.T7.5.5.1.m1.1a"><mrow id="S5.T7.5.5.1.m1.1.1" xref="S5.T7.5.5.1.m1.1.1.cmml"><mn id="S5.T7.5.5.1.m1.1.1.2" xref="S5.T7.5.5.1.m1.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S5.T7.5.5.1.m1.1.1.1" xref="S5.T7.5.5.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.T7.5.5.1.m1.1.1.3" xref="S5.T7.5.5.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T7.5.5.1.m1.1b"><apply id="S5.T7.5.5.1.m1.1.1.cmml" xref="S5.T7.5.5.1.m1.1.1"><times id="S5.T7.5.5.1.m1.1.1.1.cmml" xref="S5.T7.5.5.1.m1.1.1.1"></times><cn type="integer" id="S5.T7.5.5.1.m1.1.1.2.cmml" xref="S5.T7.5.5.1.m1.1.1.2">256</cn><cn type="integer" id="S5.T7.5.5.1.m1.1.1.3.cmml" xref="S5.T7.5.5.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.5.5.1.m1.1c">256\times 256</annotation></semantics></math>
</td>
<td id="S5.T7.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding:2.5pt 10.0pt;">
<span id="S5.T7.5.5.5.1" class="ltx_text"></span> <span id="S5.T7.5.5.5.2" class="ltx_text">
<span id="S5.T7.5.5.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T7.5.5.5.2.1.1" class="ltx_tr">
<span id="S5.T7.5.5.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 10.0pt;"><abbr title="Mean Square Error" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MSE</span></abbr> &amp; <abbr title="Wasserstein Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">WD</span></abbr> &amp; <abbr title="Total Variation Loss" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">TVLoss</span></abbr></span></span>
</span></span><span id="S5.T7.5.5.5.3" class="ltx_text"></span></td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Defense Against M2D Attacks</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The issue of <abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> attack methods has garnered significant attention in the world of <abbr title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ML</span></abbr> and <abbr title="Deep Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DL</span></abbr>. This issue has sparked concern as it can lead to the unintended exposure of information. In response, numerous methods and techniques have been proposed to understand, mitigate, and control this leakage, <em id="S5.SS3.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, gradient perturbation¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib110" title="" class="ltx_ref">110</a>, <a href="#bib.bib111" title="" class="ltx_ref">111</a>, <a href="#bib.bib112" title="" class="ltx_ref">112</a>, <a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>, data obfuscation or sanitization¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib114" title="" class="ltx_ref">114</a>, <a href="#bib.bib115" title="" class="ltx_ref">115</a>, <a href="#bib.bib116" title="" class="ltx_ref">116</a>, <a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>, and other methods¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib119" title="" class="ltx_ref">119</a>, <a href="#bib.bib120" title="" class="ltx_ref">120</a>, <a href="#bib.bib121" title="" class="ltx_ref">121</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>. These methods aim to limit the extent of information that can be exposed, ensuring that models operate with the requisite confidentiality and integrity. Defense against <abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> attacks has emerged as a compelling and dynamic research area within the field. <abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> attacks involve malicious attempts to extract or manipulate sensitive information directly from the data used in training models. This field of research explores various strategies and mechanisms to shield against these attacks, preserving the privacy of the data and maintaining the robustness of the models.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Numerous measures have been undertaken to safeguard personal data against the <abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> attack. Techniques such as gradient perturbation, data obfuscation or sanitization,  <span title="Differential Privacy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Differential Privacy</span></span> (<abbr title="Differential Privacy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DP</span></abbr>),  <span title="Homomorphic Encryption" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Homomorphic Encryption</span></span> (<abbr title="Homomorphic Encryption" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">HE</span></abbr>), and  <span title="Secure Multi-Party Computation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Secure Multi-Party Computation</span></span> (<abbr title="Secure Multi-Party Computation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">MPC</span></abbr>) are among the most prominent methods for ensuring the privacy of both the private training data and the publicly shared gradient exchanged between the client and server. Experiments conducted by Zhu <em id="S5.SS3.p2.1.1" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite> focused on two specific noise types: Gaussian and Laplacian. Their findings revealed that the key factor affecting the outcome was the magnitude of the distribution variance, rather than the type of noise itself. When the variance exceeds <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="10^{-2}" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><msup id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mn id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml">10</mn><mrow id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml"><mo id="S5.SS3.p2.1.m1.1.1.3a" xref="S5.SS3.p2.1.m1.1.1.3.cmml">‚àí</mo><mn id="S5.SS3.p2.1.m1.1.1.3.2" xref="S5.SS3.p2.1.m1.1.1.3.2.cmml">2</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">10</cn><apply id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3"><minus id="S5.SS3.p2.1.m1.1.1.3.1.cmml" xref="S5.SS3.p2.1.m1.1.1.3"></minus><cn type="integer" id="S5.SS3.p2.1.m1.1.1.3.2.cmml" xref="S5.SS3.p2.1.m1.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">10^{-2}</annotation></semantics></math>, the leakage attack fails; concurrently, there is a significant decline in the model‚Äôs performance at this variance level. Chamikara <em id="S5.SS3.p2.1.2" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> introduced a technique for perturbing data, affirming that this approach maintains model performance without compromising the confidentiality of the training data. In this context, the dataset is treated as a data matrix, and a multidimensional transformation is applied to project it into a new feature space. Various degrees of transformation are used to perturb the input data, guaranteeing an adequate level of alteration. A central server is responsible for creating global perturbation parameters in this technique. Notably, a potential drawback is that the perturbation process could distort the architectural structure of image-related data. Wei <em id="S5.SS3.p2.1.3" class="ltx_emph ltx_font_italic">et al.</em>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> employed <abbr title="Differential Privacy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DP</span></abbr> to introduce noise into the training datasets of each client and formulated a per-example-based <abbr title="Differential Privacy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DP</span></abbr> method known as Fed-CDP. They developed a dynamic decay noise injection strategy to improve both inference performance and the level of gradient leakage defense. Nevertheless, experimental findings indicate that, despite successfully hindering the reconstruction of training data from the gradient, this method leads to a considerable decline in inference accuracy. Additionally, since <abbr title="Differential Privacy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DP</span></abbr> is applied to every training instance, the computational overhead becomes substantial.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">When computing the gradient,  <span title="Privacy Enhancing Module" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Privacy Enhancing Module</span></span> (<abbr title="Privacy Enhancing Module" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PRECODE</span></abbr>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> aims to prevent the input information from propagating through the model. <abbr title="Privacy Enhancing Module" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PRECODE</span></abbr> introduces a module before the output layer to transform the latent representation of features using a probabilistic encoder-decoder. This encoder-decoder is comprised of two fully-connected layers. The first layer encodes the input features into a sequence and then normalizes this sequence based on calculated mean and standard deviation values. The mean is computed from the first half of the sequence, while the standard deviation is derived from the remaining half. Finally, the decoder translates the normalized sequence back into a latent representation, which then serves as input to the output layer. This normalization step between the encoder and decoder prevents the input information from affecting the gradient, thereby allowing <abbr title="Privacy Enhancing Module" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PRECODE</span></abbr> to resist the leakage of input information through the gradient. However, the insertion of two fully-connected layers in front of the output layer results in a significant computational cost. This is why only three very shallow neural networks were used for experiments in their paper.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">Recent studies have uncovered that shared gradients can result in the potential exposure of sensitive data, leading to privacy violations. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> presents an exhaustive examination and offers a fresh perspective on the issue of gradient leakage. These theoretical endeavors have culminated in the development of an innovative gradient leakage defense strategy that fortifies any model architecture by implementing a private key-lock mechanism. The only gradient communicated to the parameter server for global model aggregation is the one that has been secured with this lock. The newly formulated learning approach, termed FedKL, is designed to withstand attacks that attempt to exploit gradient leakage.</p>
</div>
<div id="S5.SS3.p5" class="ltx_para">
<p id="S5.SS3.p5.1" class="ltx_p">The key-lock component has been meticulously designed and trained to ensure that without access to the private details of the key-lock system: a) the task of reconstructing private training data from the shared gradient becomes unattainable, and b) there is a considerable deterioration in the global model‚Äôs ability to make inferences. The underlying theoretical reasons for gradients potentially leaking confidential information are explored, and a theoretical proof confirming the efficacy of our method is provided.</p>
</div>
<div id="S5.SS3.p6" class="ltx_para">
<p id="S5.SS3.p6.1" class="ltx_p">The method‚Äôs robustness has been verified through extensive empirical testing across a variety of models on numerous widely-used benchmarks, showcasing its effectiveness in both maintaining model performance and protecting against gradient leakage.</p>
</div>
<div id="S5.SS3.p7" class="ltx_para">
<p id="S5.SS3.p7.1" class="ltx_p">In the study¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>, a theoretical foundation is laid to demonstrate that the feature maps extracted from the fully-connected layer, convolutional layer, and <abbr title="Batch Normalization" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">BN</span></abbr> layer contain confidential details of the input data. These details are not only encompassed within the feature maps but also coexist within the gradient during the process of backward propagation. Furthermore, it is posited that gradient leakage attacks can only succeed if there is adequate alignment between the gradient spaces of the global and local models.</p>
</div>
<div id="S5.SS3.p8" class="ltx_para">
<p id="S5.SS3.p8.1" class="ltx_p">As a solution, they proposed FedKL, a specialized key-lock module that excels at differentiating, misaligning, and safeguarding the gradient spaces using a private key. This is accomplished while preserving federated aggregation comparable to conventional <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> schemes. Specifically, the operations of scaling and shifting in the normalization layer are restructured. A private key, generated randomly, is fed into two fully-connected layers. The resulting outputs function as exclusive coefficients for the scaling and shifting procedures. Both theoretical analysis and experimental results affirm that the proposed key-lock module is efficient and effective in protecting against gradient leakage attacks. This is achieved by masking the uniformity of confidential data in the gradient, thus making it challenging for a malicious attacker to perform forward-backward propagation in the absence of the private key and the lock layer‚Äôs gradient. Consequently, the task of approximating the shared gradient in the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> framework to reconstruct local training data becomes unachievable.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Composite Attacks</h2>

<figure id="S6.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Characteristics of Composite Attacks</figcaption>
<table id="S6.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S6.T8.1.1" class="ltx_tr">
<td id="S6.T8.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S6.T8.1.1.1.1" class="ltx_text ltx_font_bold">Name of Attack</span></td>
<td id="S6.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S6.T8.1.1.2.1" class="ltx_text ltx_font_bold">Distinctive Feature</span></td>
</tr>
<tr id="S6.T8.1.2" class="ltx_tr">
<td id="S6.T8.1.2.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Direct Boosting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>
</td>
<td id="S6.T8.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">boosting malicious updates</td>
</tr>
<tr id="S6.T8.1.3" class="ltx_tr">
<td id="S6.T8.1.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Separated Boosting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>
</td>
<td id="S6.T8.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">regularized update boosting</td>
</tr>
<tr id="S6.T8.1.4" class="ltx_tr">
<td id="S6.T8.1.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Model Replacement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>
</td>
<td id="S6.T8.1.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">replace converging global model</td>
</tr>
<tr id="S6.T8.1.5" class="ltx_tr">
<td id="S6.T8.1.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">PGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>
</td>
<td id="S6.T8.1.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">bounded update projection</td>
</tr>
<tr id="S6.T8.1.6" class="ltx_tr">
<td id="S6.T8.1.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Edge case + PGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>
</td>
<td id="S6.T8.1.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">PGD on minority samples</td>
</tr>
<tr id="S6.T8.1.7" class="ltx_tr">
<td id="S6.T8.1.7.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Median Interval <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>
</td>
<td id="S6.T8.1.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.7.2.1" class="ltx_text"></span> <span id="S6.T8.1.7.2.2" class="ltx_text">
<span id="S6.T8.1.7.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.7.2.2.1.1" class="ltx_tr">
<span id="S6.T8.1.7.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">median cheating with</span></span>
<span id="S6.T8.1.7.2.2.1.2" class="ltx_tr">
<span id="S6.T8.1.7.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">normalized updates</span></span>
</span></span><span id="S6.T8.1.7.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S6.T8.1.8" class="ltx_tr">
<td id="S6.T8.1.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">DBA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>
</td>
<td id="S6.T8.1.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">distributed backdoor trigger</td>
</tr>
<tr id="S6.T8.1.9" class="ltx_tr">
<td id="S6.T8.1.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">TrojanDBA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>
</td>
<td id="S6.T8.1.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">distributed and learnable trigger</td>
</tr>
<tr id="S6.T8.1.10" class="ltx_tr">
<td id="S6.T8.1.10.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Neurotoxin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite>
</td>
<td id="S6.T8.1.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.10.2.1" class="ltx_text"></span> <span id="S6.T8.1.10.2.2" class="ltx_text">
<span id="S6.T8.1.10.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.10.2.2.1.1" class="ltx_tr">
<span id="S6.T8.1.10.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">tampering insignificant</span></span>
<span id="S6.T8.1.10.2.2.1.2" class="ltx_tr">
<span id="S6.T8.1.10.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">model weights</span></span>
</span></span><span id="S6.T8.1.10.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S6.T8.1.11" class="ltx_tr">
<td id="S6.T8.1.11.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">RL Neurotoxin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite>
</td>
<td id="S6.T8.1.11.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.11.2.1" class="ltx_text"></span> <span id="S6.T8.1.11.2.2" class="ltx_text">
<span id="S6.T8.1.11.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.11.2.2.1.1" class="ltx_tr">
<span id="S6.T8.1.11.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">searching Neurotoxin</span></span>
<span id="S6.T8.1.11.2.2.1.2" class="ltx_tr">
<span id="S6.T8.1.11.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">parameters with RL</span></span>
</span></span><span id="S6.T8.1.11.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S6.T8.1.12" class="ltx_tr">
<td id="S6.T8.1.12.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">F3BA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite>
</td>
<td id="S6.T8.1.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.12.2.1" class="ltx_text"></span> <span id="S6.T8.1.12.2.2" class="ltx_text">
<span id="S6.T8.1.12.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.12.2.2.1.1" class="ltx_tr">
<span id="S6.T8.1.12.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">sign-flipping on</span></span>
<span id="S6.T8.1.12.2.2.1.2" class="ltx_tr">
<span id="S6.T8.1.12.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">insignificant weights</span></span>
</span></span><span id="S6.T8.1.12.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S6.T8.1.13" class="ltx_tr">
<td id="S6.T8.1.13.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.13.1.1" class="ltx_text"></span> <span id="S6.T8.1.13.1.2" class="ltx_text">
<span id="S6.T8.1.13.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.13.1.2.1.1" class="ltx_tr">
<span id="S6.T8.1.13.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Rare Word</span></span>
<span id="S6.T8.1.13.1.2.1.2" class="ltx_tr">
<span id="S6.T8.1.13.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Embedding</span></span>
</span></span> <span id="S6.T8.1.13.1.3" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>
</td>
<td id="S6.T8.1.13.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.13.2.1" class="ltx_text"></span> <span id="S6.T8.1.13.2.2" class="ltx_text">
<span id="S6.T8.1.13.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.13.2.2.1.1" class="ltx_tr">
<span id="S6.T8.1.13.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">tampering stale</span></span>
<span id="S6.T8.1.13.2.2.1.2" class="ltx_tr">
<span id="S6.T8.1.13.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">word embeddings</span></span>
</span></span><span id="S6.T8.1.13.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S6.T8.1.14" class="ltx_tr">
<td id="S6.T8.1.14.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.14.1.1" class="ltx_text"></span> <span id="S6.T8.1.14.1.2" class="ltx_text">
<span id="S6.T8.1.14.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.14.1.2.1.1" class="ltx_tr">
<span id="S6.T8.1.14.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Future Update</span></span>
<span id="S6.T8.1.14.1.2.1.2" class="ltx_tr">
<span id="S6.T8.1.14.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Approximation</span></span>
</span></span> <span id="S6.T8.1.14.1.3" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>
</td>
<td id="S6.T8.1.14.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.14.2.1" class="ltx_text"></span> <span id="S6.T8.1.14.2.2" class="ltx_text">
<span id="S6.T8.1.14.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.14.2.2.1.1" class="ltx_tr">
<span id="S6.T8.1.14.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">estimating future updates</span></span>
<span id="S6.T8.1.14.2.2.1.2" class="ltx_tr">
<span id="S6.T8.1.14.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">from malicious clients</span></span>
</span></span><span id="S6.T8.1.14.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S6.T8.1.15" class="ltx_tr">
<td id="S6.T8.1.15.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Sudden Collapse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>
</td>
<td id="S6.T8.1.15.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T8.1.15.2.1" class="ltx_text"></span> <span id="S6.T8.1.15.2.2" class="ltx_text">
<span id="S6.T8.1.15.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S6.T8.1.15.2.2.1.1" class="ltx_tr">
<span id="S6.T8.1.15.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">estimating potent</span></span>
<span id="S6.T8.1.15.2.2.1.2" class="ltx_tr">
<span id="S6.T8.1.15.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">malicious gradients</span></span>
</span></span><span id="S6.T8.1.15.2.3" class="ltx_text"></span></td>
</tr>
</table>
</figure>
<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We define composite attacks as threat models that corrupt multiple aspects of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>. The attacker can combine <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> and <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks to launch backdoor attacks. The attacker surreptitiously adds trigger patterns to local training data, then poisons model updates such that the global model learns how to react to triggers. Backdoored models behave normally when fed with clean data. In the presence of trigger data, these models are trained to give predictions designated by the attacker.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Trigger patterns vary from one attack to the other. We summarize existing triggers in Figure¬†<a href="#S6.F10" title="Figure 10 ‚Ä£ 6 Composite Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. Generic samples of a class or samples with shared patterns are commonly used in label-flipping attacks, these attacks can be further enhanced by incorporating <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks. Triggers based on certain natural patterns are also known as semantic triggers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite> . Handpicked logos or icons are common trigger patterns for backdoor injection. Edge samples, namely samples at the tail of the data distribution, are used in attacks targeting underrepresented data, which can significantly damage the fairness for the minority group. Lastly, learnable triggers is a relatively new strategy appears in recent studies.</p>
</div>
<figure id="S6.F10" class="ltx_figure"><img src="/html/2311.16065/assets/x6.png" id="S6.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="369" height="137" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>An Overview of Trigger Patterns. Among these trigger types, a and b are mostly associated with label-flipping. Type c is a common strategy for injecting triggers into arbitrary samples. Type d uses samples at the tail of the data distribution to induce erroneous predictions for underrepresented data. Type d appears in more recent studies.</figcaption>
</figure>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Compared to <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> or <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks, now that the attacker also has control over client model updates, composite attacks tend to be stealthier and more destructive. A high-level view of such attacks is illustrated in Figure¬†<a href="#S6.F11" title="Figure 11 ‚Ä£ 6 Composite Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. We group recent composite attacks based on their most notable features. These attacks may also use techniques proposed in other groups. We show the characteristics of composite attacks in Table¬†<a href="#S6.T8" title="Table 8 ‚Ä£ 6 Composite Attacks ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure id="S6.F11" class="ltx_figure"><img src="/html/2311.16065/assets/x7.png" id="S6.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="323" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>A High-level View of Injecting Backdoors with a Composite Attack. The attacker chooses a preferable trigger and tampers local data with the trigger. Local model is also trained on clean data to avoid detection. Most attacks aim at poisoning the global model with only a few clients.</figcaption>
</figure>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Composite Threat Models</h3>

<section id="S6.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.1 </span>Update Boosting</h4>

<div id="S6.SS1.SSS1.p1" class="ltx_para">
<p id="S6.SS1.SSS1.p1.1" class="ltx_p">To boost the effectiveness of model updates derived from poisoned data, scaling up malicious updates is a common strategy in early studies on composite attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>. Given poisoned data with their labels being flipped, authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> propose two types of threat models. The explicit approach is to train client models with the poisoned data, then boost model updates by scaling it up with a predefined coefficient. Although this approach is easy to implement, the boosted updates are statistically different from benign updates, suggesting that secure aggregation rules can easily identify boosted malicious updates. As for the stealthy approach in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>, the attacker instead trains client models on both the clean and poisoned data. Updates from the poisoned data are boosted as the explicit approach while a regularization term is used to ensure that the differences between current malicious updates and last round‚Äôs average benign updates are bounded. Instead of boosting only the malicious updates, the model replacement attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite> seeks to entirely replace the global model with the backdoored model. As the training goes on, benign updates from converging client models tend to cancel each other out. By solving the linear aggregation equation, the attacker can find the solution to scale up malicious updates such that the global model is equal to the model trained with poisoned data, namely the global model is replaced with the one with backdoors.</p>
</div>
</section>
<section id="S6.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.2 </span>Bounded Updates</h4>

<div id="S6.SS1.SSS2.p1" class="ltx_para">
<p id="S6.SS1.SSS2.p1.1" class="ltx_p">Boosting model updates is an effective way to inject backdoors. However, these updates have distinctive norms compared to benign updates. As mentioned above, boosted updates can be easily filtered out by norm-based aggregation rules.  <span title="Projected Gradient Descent" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Projected Gradient Descent</span></span> (<abbr title="Projected Gradient Descent" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PGD</span></abbr>) proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite> aims at bypassing norm-based aggregation by projecting boosted updates onto a small ball around the norm of global model weights. <abbr title="Projected Gradient Descent" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PGD</span></abbr> can be also seen in later studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. On top of the edge case <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr> attack in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, the attacker can further cover up their intention by projecting model updates derived from edge case data. Another threat model proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> combines <abbr title="Projected Gradient Descent" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PGD</span></abbr> with model replacement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite> in which the boosted malicious updates is bounded through projection before replacing the global model. Another way to generate bounded updates is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. In stead of projecting malicious updates, they are normalized by the maximum deviation range discussed in the <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attack section.</p>
</div>
</section>
<section id="S6.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.3 </span>Distributed Triggers</h4>

<div id="S6.SS1.SSS3.p1" class="ltx_para">
<p id="S6.SS1.SSS3.p1.1" class="ltx_p">One common trait of the above composite attacks is that their backdoor triggers are stand-alone, namely the trigger patterns are identical across all clients and tampered samples. Even though there are experiments on concurrently employing multiple triggers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>, these triggers are still independent from each other and they lack the ability to collude. The  <span title="Distributed Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Distributed Backdoor Attack</span></span> (<abbr title="Distributed Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DBA</span></abbr>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite> instead assigns local triggers to multiple clients. Local triggers can be assembled to form a stronger global trigger. The triggers used in <abbr title="Distributed Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DBA</span></abbr> is similar to the ones used in BadNets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite>, which are colored rectangles placed around the corners of images. Malicious updates of <abbr title="Distributed Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DBA</span></abbr> are scaled up by a coefficient similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>. Another attack with distributed triggers is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>. Unlike <abbr title="Distributed Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DBA</span></abbr> whose triggers are predefined, triggers in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite> are based on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite> with learn-able parameters that generate local trigger patterns. In the trigger generation stage of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>, the attacker first determines the target class. By feeding various samples of the target class to the received global model, the attacker finds the internal neuron that is most sensitive to the target class. This is achieved by comparing the sum of connected weights and the number of activation. The attacker then optimizes trigger pattern parameters such that they maximize the activated value of the most sensitive neuron. In the distributed training stage of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>, each malicious client only trains from the most sensitive neuron‚Äôs layer to the final output layer.</p>
</div>
</section>
<section id="S6.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.4 </span>Insidious Tampering</h4>

<div id="S6.SS1.SSS4.p1" class="ltx_para">
<p id="S6.SS1.SSS4.p1.1" class="ltx_p">More recent composite attacks focus on making malicious updates more insidious and persistent, which is usually achieved by tampering with weights that are unimportant to the clean data. For instance, Neurotoxin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite> only updates insignificant parameters to prevent backdoors from being erased by benign updates. Neurotoxin considers parameters with largest gradients to be most used by benign clients, therefore parameters with with smaller gradients are less accessed by benign clients. The attacker can only optimize less important parameters to achieve their backdoor objectives. Neurotoxin is recently enhanced by authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite> who employ <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr> to find better hyperparameters for the attack. Rare word embedding attack proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite> shares a similar idea with Neurotoxin in the sense that it manipulates word embeddings of rare words as they are not likely to be updated by benign clients. The effectiveness of the rare word embedding attack can be further amplified by the gradient ensembling method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>. The attacker intentionally stores the global models from multiple rounds, then gradients of backdoor word embeddings are computed for all these models. The exponential moving average of these gradients is used to update backdoor embeddings in the current round.  <span title="Focused Flip Federated Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Focused Flip Federated Backdoor Attack</span></span> (<abbr title="Focused Flip Federated Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">F3BA</span></abbr>) is a recent threat model that falls into the category of insidious tampering. Intuitively, <abbr title="Focused Flip Federated Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">F3BA</span></abbr> tries to flip the signs of lease important weights such that they are most sensitive to trigger patterns. The importance of a weight is measured by the product of its gradient and weight value. <abbr title="Focused Flip Federated Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">F3BA</span></abbr> only modifies least important weights found by this metric, and empirically <math id="S6.SS1.SSS4.p1.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S6.SS1.SSS4.p1.1.m1.1a"><mrow id="S6.SS1.SSS4.p1.1.m1.1.1" xref="S6.SS1.SSS4.p1.1.m1.1.1.cmml"><mn id="S6.SS1.SSS4.p1.1.m1.1.1.2" xref="S6.SS1.SSS4.p1.1.m1.1.1.2.cmml">1</mn><mo id="S6.SS1.SSS4.p1.1.m1.1.1.1" xref="S6.SS1.SSS4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS4.p1.1.m1.1b"><apply id="S6.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS4.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.SS1.SSS4.p1.1.m1.1.1.1.cmml" xref="S6.SS1.SSS4.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.SS1.SSS4.p1.1.m1.1.1.2.cmml" xref="S6.SS1.SSS4.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS4.p1.1.m1.1c">1\%</annotation></semantics></math> of weights are enough to degrade model performance. Sign-flipping of <abbr title="Focused Flip Federated Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">F3BA</span></abbr> is conducted between consecutive layers. In the first layer, the attacker reshapes the trigger patterns such that it aligns with the convolution kernel. Signs of least important weights of this kernel are flipped if they are different from the signs of the aligned trigger pixels. In subsequent layers, the attacker respectively feeds the model with clean and poisoned data, records their activation differences, and flips signs of the chosen weights such that the activation differences are maximized. When sign-flipping is completed, the model is fine-tuned to associate flipped weights with the labels of poisoned data. The model‚Äôs local updates will also be more similar to benign updates after fine-tuning. Like <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>, trigger patterns is also learn-able. <abbr title="Focused Flip Federated Backdoor Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">F3BA</span></abbr> learns the trigger pattern‚Äôs pixel values by maximizing the clean-poisoned activation difference of the first layer.</p>
</div>
</section>
<section id="S6.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.1.5 </span>Update Approximation</h4>

<div id="S6.SS1.SSS5.p1" class="ltx_para">
<p id="S6.SS1.SSS5.p1.1" class="ltx_p">Composite attacks introduced so far directly optimize model weights on the backdoor classification task. There are also attacks seeking to optimize niche objectives. These objectives are often intractable (<em id="S6.SS1.SSS5.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em> estimating future updates of other clients), thus the attacker needs to find proper approximations to implement practical solutions. If an omniscient attacker knows all future updates of a <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> system, the optimal way of injecting backdoors is differentiating through the computation graph of all future updates <em id="S6.SS1.SSS5.p1.1.2" class="ltx_emph ltx_font_italic">w.r.t</em> the weights of the attacker‚Äôs model. This is the intuition behind <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> and the authors propose a method to approximate updates in the near future. The attack in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> requires the attacker to control a subset of client models. The attacker uses these models to simulate future updates by running FedAvg. Throughout the simulation, only clean data sampled from the malicious client is used. In the first round of the simulation, all models are fed with data. The malicious models are left out in the following rounds, which is simulating the scenario in which the malicious client is not chosen by the central server. Once future updates are approximated, client model weights are optimized through the classification losses on both clean and poisoned data similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>.  <span title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Accumulative Poisoning Attack</span></span> (<abbr title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APA</span></abbr>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> is another method that indirectly optimizes model weights for the backdoor task. The objective of <abbr title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APA</span></abbr> is to clandestinely poison model weights while maintaining a good test performance. As soon as the model is fed with trigger data, its performance drastically drops, leaving the system administrator with minimum time to respond to the attack. <abbr title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APA</span></abbr> learns two functions: an accumulative function and a poisoning function. The accumulative function is used to manipulate model updates such that the model is more sensitive to trigger gradients. The poisoning function is used to transform benign gradients from validation data into malicious gradients, leading to performance degradation. Intuitively, degrading model performance can be viewed as maximizing the validation loss. By taking the first order Taylor polynomial of the validation loss, the maximization problem is transformed into minimizing the first order gradient <em id="S6.SS1.SSS5.p1.1.3" class="ltx_emph ltx_font_italic">w.r.t</em> the accumulative and poisoning functions. The authors of <abbr title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APA</span></abbr> further simplify the minimization problem with its first order approximation. The final optimization objective then becomes simultaneously aligning the directions of poisoned gradients with benign gradients as well as the second order gradients of the validation loss. All gradients from <abbr title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APA</span></abbr> are all projected through <abbr title="Projected Gradient Descent" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">PGD</span></abbr> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite> to enhance stealth. While it is not mandatory to use trigger patterns with <abbr title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APA</span></abbr>, the authors demonstrate that explicit triggers makes <abbr title="Accumulative Poisoning Attack" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">APA</span></abbr> more potent.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Defense Against Composite Attack</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In this section, we introduce defenses that are specifically designed to counter <abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr>+<abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> composite attacks. Since this type of attack also manipulates model weights or updates, defenses against <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks such as Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> or Bulyan <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> are also evaluated in many existing studies on defense against composite attacks. Depending on the subjects being processed by the defense strategy, we divide defenses again composite attacks into update cleansing and model cleansing.</p>
</div>
<section id="S6.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1 </span>Update Cleansing</h4>

<div id="S6.SS2.SSS1.p1" class="ltx_para">
<p id="S6.SS2.SSS1.p1.1" class="ltx_p">Defenses based on update cleansing filter out uploads or mitigate influence from malicious clients by examining model updates. Robust-LR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite> is an update cleansing defense built on the heuristics that directions of malicious updates are different from benign ones. The authors of Robust-LR take a majority voting over model updates. The voting computes the sum of signs of model updates on each dimension. If the sum is below a pre-defined threshold, meaning that malicious clients participate in the current round of update, the learning rate on that dimension is multiplied by <math id="S6.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="-1" display="inline"><semantics id="S6.SS2.SSS1.p1.1.m1.1a"><mrow id="S6.SS2.SSS1.p1.1.m1.1.1" xref="S6.SS2.SSS1.p1.1.m1.1.1.cmml"><mo id="S6.SS2.SSS1.p1.1.m1.1.1a" xref="S6.SS2.SSS1.p1.1.m1.1.1.cmml">‚àí</mo><mn id="S6.SS2.SSS1.p1.1.m1.1.1.2" xref="S6.SS2.SSS1.p1.1.m1.1.1.2.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p1.1.m1.1b"><apply id="S6.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1"><minus id="S6.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1"></minus><cn type="integer" id="S6.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S6.SS2.SSS1.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p1.1.m1.1c">-1</annotation></semantics></math> to apply gradient ascent to suspicious updates.</p>
</div>
<div id="S6.SS2.SSS1.p2" class="ltx_para">
<p id="S6.SS2.SSS1.p2.1" class="ltx_p">Training models with <abbr title="Differential Privacy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DP</span></abbr> has been mathematically proven as an effective way of defending against backdoor injections <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>, <a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. This approach is first introduced to <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> by authors of DP-FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>. Compared to the vanilla FedAvg shown in Algorithm¬†<a href="#alg1" title="Algorithm 1 ‚Ä£ 2 Preliminaries of Federated Learning ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, DP-FedAvg requires the central server to bound client updates first. Client updates are clipped by comparing its <math id="S6.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S6.SS2.SSS1.p2.1.m1.1a"><mrow id="S6.SS2.SSS1.p2.1.m1.1.1" xref="S6.SS2.SSS1.p2.1.m1.1.1.cmml"><mi id="S6.SS2.SSS1.p2.1.m1.1.1.2" xref="S6.SS2.SSS1.p2.1.m1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S6.SS2.SSS1.p2.1.m1.1.1.1" xref="S6.SS2.SSS1.p2.1.m1.1.1.1.cmml">‚Äã</mo><mn id="S6.SS2.SSS1.p2.1.m1.1.1.3" xref="S6.SS2.SSS1.p2.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS1.p2.1.m1.1b"><apply id="S6.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.1.1"><times id="S6.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S6.SS2.SSS1.p2.1.m1.1.1.1"></times><ci id="S6.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S6.SS2.SSS1.p2.1.m1.1.1.2">ùêø</ci><cn type="integer" id="S6.SS2.SSS1.p2.1.m1.1.1.3.cmml" xref="S6.SS2.SSS1.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS1.p2.1.m1.1c">L2</annotation></semantics></math>-norm against a given parameter, which could be an overall parameter for all model weights or a set of layer-wise clipping parameter. When the global model is updated by taking in bounded client updates, noise from a zero-mean Gaussian is also added.</p>
</div>
</section>
<section id="S6.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2 </span>Model Cleansing</h4>

<div id="S6.SS2.SSS2.p1" class="ltx_para">
<p id="S6.SS2.SSS2.p1.1" class="ltx_p">A pruning based method is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite>. This approach asks clients to rank the average activation values of the last layer of their models. The central server prunes neurons in the descending order based on the aggregated rankings of neurons. Knowledge distillation is also considered as a defense against composite backdoor attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite>. By aligning the attention maps of the teacher model and the student model,  <span title="Neural Attention Distillation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Neural Attention Distillation</span></span> (<abbr title="Neural Attention Distillation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">NAD</span></abbr>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite> manages to erase backdoors injected in the model. The distillation process of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite> assumes that clean data is available to the defender. This requirement is also inherited by FedRAD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite>, a knowledge distillation based defense for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>. FedRAD needs to prepare synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite> on the central server for model evaluation. Client models are fed with the synthesized data for evaluation, then the central server counts how many times a client‚Äôs logit obtains the median value for its corresponding class. The median frequencies of client models are normalized and used as global model aggregation coefficients. The distillation process of FedRAD is built on FedDF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite>. The central server distills knowledge from client models by minimizing the KL divergence between the global model‚Äôs predictions and the average prediction of client models.</p>
</div>
<div id="S6.SS2.SSS2.p2" class="ltx_para">
<p id="S6.SS2.SSS2.p2.3" class="ltx_p">Some research considers certified robustness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite> as the way to defend against composite backdoor attacks. A <abbr title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ML</span></abbr> model is said to have certified robustness if its predictions are still stable even if the input is perturbed. CRFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> is a defense designed to counter the model replacement attack. By controlling how the global model parameters update during training, CRFL grants the global model certified robustness under the condition that the backdoor trigger is bounded. Specifically, when the conventional global model aggregation completes, parameters of the global model are first clipped, then Gaussian noise is added to these parameters. At test time, a set of Gaussian noise is sampled from the previous noise distribution and added to the aggregated global model, resulting in a set of noisy global models. A majority voting is conducted among these noisy models to decide the classification results of test samples. Another defense with certified robustness is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite>. This method achieves certified robustness through the majority voting among a number of concurrently trained global models. Given <math id="S6.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S6.SS2.SSS2.p2.1.m1.1a"><mi id="S6.SS2.SSS2.p2.1.m1.1.1" xref="S6.SS2.SSS2.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.1.m1.1b"><ci id="S6.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p2.1.m1.1.1">ùëõ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.1.m1.1c">n</annotation></semantics></math> clients, the defense in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite> trains <math id="S6.SS2.SSS2.p2.2.m2.2" class="ltx_Math" alttext="\binom{n}{k}" display="inline"><semantics id="S6.SS2.SSS2.p2.2.m2.2a"><mrow id="S6.SS2.SSS2.p2.2.m2.2.2.4" xref="S6.SS2.SSS2.p2.2.m2.2.2.3.cmml"><mo id="S6.SS2.SSS2.p2.2.m2.2.2.4.1" xref="S6.SS2.SSS2.p2.2.m2.2.2.3.1.cmml">(</mo><mfrac linethickness="0pt" id="S6.SS2.SSS2.p2.2.m2.2.2.2.2" xref="S6.SS2.SSS2.p2.2.m2.2.2.3.cmml"><mi id="S6.SS2.SSS2.p2.2.m2.1.1.1.1.1.1" xref="S6.SS2.SSS2.p2.2.m2.1.1.1.1.1.1.cmml">n</mi><mi id="S6.SS2.SSS2.p2.2.m2.2.2.2.2.2.1" xref="S6.SS2.SSS2.p2.2.m2.2.2.2.2.2.1.cmml">k</mi></mfrac><mo id="S6.SS2.SSS2.p2.2.m2.2.2.4.2" xref="S6.SS2.SSS2.p2.2.m2.2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.2.m2.2b"><apply id="S6.SS2.SSS2.p2.2.m2.2.2.3.cmml" xref="S6.SS2.SSS2.p2.2.m2.2.2.4"><csymbol cd="latexml" id="S6.SS2.SSS2.p2.2.m2.2.2.3.1.cmml" xref="S6.SS2.SSS2.p2.2.m2.2.2.4.1">binomial</csymbol><ci id="S6.SS2.SSS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S6.SS2.SSS2.p2.2.m2.1.1.1.1.1.1">ùëõ</ci><ci id="S6.SS2.SSS2.p2.2.m2.2.2.2.2.2.1.cmml" xref="S6.SS2.SSS2.p2.2.m2.2.2.2.2.2.1">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.2.m2.2c">\binom{n}{k}</annotation></semantics></math> global models, where <math id="S6.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS2.SSS2.p2.3.m3.1a"><mi id="S6.SS2.SSS2.p2.3.m3.1.1" xref="S6.SS2.SSS2.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.3.m3.1b"><ci id="S6.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S6.SS2.SSS2.p2.3.m3.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.3.m3.1c">k</annotation></semantics></math> is the number clients chosen without replacement for each model. Although the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite> applies Monte Carlo approximation to speed up the defense, it still needs to train hundreds of global models, making this method more computationally expensive than other defenses.</p>
</div>
<div id="S6.SS2.SSS2.p3" class="ltx_para">
<p id="S6.SS2.SSS2.p3.1" class="ltx_p">The idea of majority voting is not exclusive to defenses with certified robustness. Authors of BaFFLe <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> rely on diversified client data to validate and provide feedback to the global model. BaFFLe adds an extra stage to conventional <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> pipeline. When the global model for current global training round is aggregated, it is sent to randomly selected clients to validate if the global model is poisoned. A set of recently accepted global models are also sent to selected clients as reference. The validation process s of BaFFLe requires these clients to test global models with their local data. In particular, each client computes the misclassification rate for samples of a specific class, the client also computes the rate of other classes‚Äô samples being misclassified as the examined class. For benign models, the gap between these two rates are relatively stable during training. However, drastic changes can happen for backdoored models. If the misclassification gap of the newly aggregated global model deviates too much from the average gap of past models, the client votes the global model as malicious. Finally, based on the result of the majority voting, the central server decides whether to discard the newly obtained global model.</p>
</div>
</section>
<section id="S6.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.3 </span>Composite Cleansing</h4>

<div id="S6.SS2.SSS3.p1" class="ltx_para">
<p id="S6.SS2.SSS3.p1.1" class="ltx_p">Like composite attacks that manipulate multiple aspects of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> to enhance their capability, recent defenses also examine both model updates and weights to systematically mitigate composite attacks.</p>
</div>
<div id="S6.SS2.SSS3.p2" class="ltx_para">
<p id="S6.SS2.SSS3.p2.1" class="ltx_p">Authors of DeepSight <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> propose various metrics to evaluate if the upload from a client is malicious. The central server first computes the pairwise cosine similarities between received updates. Two other metrics, clients‚Äô  <span title="Division Differences" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">Division Differences</span></span> (<abbr title="Division Differences" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DDif</span></abbr>) and  <span title="NormalizEd UPdate Energy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long">NormalizEd UPdate Energy</span></span> (<abbr title="NormalizEd UPdate Energy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">NEUP</span></abbr>), are also computed. <abbr title="Division Differences" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DDif</span></abbr> measures the prediction differences between the global and client models. This is achieved by feeding models with random input on the server. Backdoored models are prone to produce larger activation for the trigger class even if the input is merely random noise <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite>, which is a telltale sign for <abbr title="Division Differences" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">DDif</span></abbr> to identify compromised models. <abbr title="NormalizEd UPdate Energy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">NEUP</span></abbr> measures the update magnitude for neurons in the output layer. Local data with similar distributions results in models with similar <abbr title="NormalizEd UPdate Energy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">NEUP</span></abbr> patterns. Based on the above metrics, DeepSight clusters received client models on the central server with HDBSCAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite>. The server also needs to maintain a classifier based on <abbr title="NormalizEd UPdate Energy" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">NEUP</span></abbr> to label client models as either benign or malicious. Depending on the number of models being labeled as malicious, the server determines whether to accept or reject a client model cluster. Models from accepted clusters are deemed as safe for aggregation.</p>
</div>
<div id="S6.SS2.SSS3.p3" class="ltx_para">
<p id="S6.SS2.SSS3.p3.1" class="ltx_p">FLAME <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite> is another example of composite defense. Authors of FLAME summarize the pipeline of their approach as clustering, clipping and noising. In the clustering stage, the central server computes <abbr title="Cosine Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CD</span></abbr>s between model updates. HDBSCAN is subsequently used to filter out malicious models based on the angular differences derived from <abbr title="Cosine Distance" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">CD</span></abbr>s. In the clipping stage, the median of remaining models‚Äô updates is chosen as the bound to clip model updates. In the final noising stage, Gaussian noise is added to the global model weights to further erase injected back doors.</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Directions</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Conclusion</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">In recent years, <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> has become a transformative paradigm for training <abbr title="Machine Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">ML</span></abbr> models, especially in decentralized environments where data privacy and security are critical. Our comprehensive review categorized known <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> attacks according to attack origin and target. It provides a clear structure for understanding the scope and depth of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> inherent vulnerabilities:

<br class="ltx_break"></p>
</div>
<div id="S7.SS1.p2" class="ltx_para ltx_noindent">
<p id="S7.SS1.p2.1" class="ltx_p"><abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr><span id="S7.SS1.p2.1.1" class="ltx_text ltx_font_bold"> Attacks:</span> These attacks (<em id="S7.SS1.p2.1.2" class="ltx_emph ltx_font_italic">e.g.</em>, label-flipping) manipulate data to corrupt the global model. Since <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> often relies on data from numerous potentially untrusted sources, it is highly vulnerable to such threats.

<br class="ltx_break"></p>
</div>
<div id="S7.SS1.p3" class="ltx_para ltx_noindent">
<p id="S7.SS1.p3.1" class="ltx_p"><abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr><span id="S7.SS1.p3.1.1" class="ltx_text ltx_font_bold"> Attacks:</span> This type of attack tampers with model updates, thereby disrupting the learning process. For example, Byzantine attacks involve sending malformed or misleading model updates, indicating that one or more malicious clients have the potential to degrade the performance of the global model. Such attacks emphasize the importance of a robust aggregation approach in a federated environment.

<br class="ltx_break"></p>
</div>
<div id="S7.SS1.p4" class="ltx_para ltx_noindent">
<p id="S7.SS1.p4.1" class="ltx_p"><abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr><span id="S7.SS1.p4.1.1" class="ltx_text ltx_font_bold"> Attacks:</span> Focus on exploiting vulnerabilities that arise when models interact with data, such as gradient leakage, where an attacker can infer private data from gradient updates. Gradient leakage is a prime example where malicious entities exploit the shared model updates to infer sensitive information about the training data, emphasizing on the need for defense strategies that mask or generalize gradients.

<br class="ltx_break"></p>
</div>
<div id="S7.SS1.p5" class="ltx_para ltx_noindent">
<p id="S7.SS1.p5.1" class="ltx_p"><span id="S7.SS1.p5.1.1" class="ltx_text ltx_font_bold">Composite Attacks:</span> These attacks are more sophisticated in nature and often combine multiple attack methods or vectors to enhance their impact. Backdoor injection is a classic example, where an attacker subtly introduces a backdoor during training and then exploits it during reasoning.</p>
</div>
<div id="S7.SS1.p6" class="ltx_para">
<p id="S7.SS1.p6.1" class="ltx_p">A summarization of defense techniques toward different types of attacks is provided in Table¬†<a href="#S7.T9" title="Table 9 ‚Ä£ 7.1 Conclusion ‚Ä£ 7 Conclusion and Future Directions ‚Ä£ A Survey on Vulnerability of Federated Learning: A Learning Algorithm Perspective" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a></p>
</div>
<figure id="S7.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Summarization of defense techniques toward different types of attacks</figcaption>
<table id="S7.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S7.T9.1.1" class="ltx_tr">
<td id="S7.T9.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Defense Method</td>
<td id="S7.T9.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Defense Strategy</td>
<td id="S7.T9.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Type of Attack</td>
<td id="S7.T9.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Attack Strategy</td>
</tr>
<tr id="S7.T9.1.2" class="ltx_tr">
<td id="S7.T9.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.2.1.1" class="ltx_text"></span> <span id="S7.T9.1.2.1.2" class="ltx_text">
<span id="S7.T9.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.2.1.2.1.1" class="ltx_tr">
<span id="S7.T9.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Fung et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> (FoolsGold)</span></span>
<span id="S7.T9.1.2.1.2.1.2" class="ltx_tr">
<span id="S7.T9.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Tolpegin et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite></span></span>
<span id="S7.T9.1.2.1.2.1.3" class="ltx_tr">
<span id="S7.T9.1.2.1.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Cao et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> (Sniper)</span></span>
<span id="S7.T9.1.2.1.2.1.4" class="ltx_tr">
<span id="S7.T9.1.2.1.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Ma et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite></span></span>
</span></span><span id="S7.T9.1.2.1.3" class="ltx_text"></span></td>
<td id="S7.T9.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.2.2.1" class="ltx_text"></span> <span id="S7.T9.1.2.2.2" class="ltx_text">
<span id="S7.T9.1.2.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.2.2.2.1.1" class="ltx_tr">
<span id="S7.T9.1.2.2.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Dynamic learning rate</span></span>
<span id="S7.T9.1.2.2.2.1.2" class="ltx_tr">
<span id="S7.T9.1.2.2.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Cluster for PCA</span></span>
<span id="S7.T9.1.2.2.2.1.3" class="ltx_tr">
<span id="S7.T9.1.2.2.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Clique from Euclidean distance</span></span>
<span id="S7.T9.1.2.2.2.1.4" class="ltx_tr">
<span id="S7.T9.1.2.2.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Rewards based aggregation</span></span>
</span></span><span id="S7.T9.1.2.2.3" class="ltx_text"></span></td>
<td id="S7.T9.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><abbr title="Data to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">D2M</span></abbr></td>
<td id="S7.T9.1.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.2.4.1" class="ltx_text"></span> <span id="S7.T9.1.2.4.2" class="ltx_text">
<span id="S7.T9.1.2.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.2.4.2.1.1" class="ltx_tr">
<span id="S7.T9.1.2.4.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Label Attack</span></span>
<span id="S7.T9.1.2.4.2.1.2" class="ltx_tr">
<span id="S7.T9.1.2.4.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Sample Attack</span></span>
</span></span><span id="S7.T9.1.2.4.3" class="ltx_text"></span></td>
</tr>
<tr id="S7.T9.1.3" class="ltx_tr">
<td id="S7.T9.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.3.1.1" class="ltx_text"></span> <span id="S7.T9.1.3.1.2" class="ltx_text">
<span id="S7.T9.1.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.3.1.2.1.1" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Chen et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> (GeoMed)</span></span>
<span id="S7.T9.1.3.1.2.1.2" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Pillutla et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> (RFA)</span></span>
<span id="S7.T9.1.3.1.2.1.3" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Xie et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> (MarMed)</span></span>
<span id="S7.T9.1.3.1.2.1.4" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Xie et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> (MeaMed)</span></span>
<span id="S7.T9.1.3.1.2.1.5" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Yin et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> (TrimMean)</span></span>
<span id="S7.T9.1.3.1.2.1.6" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Blanchard et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> (Krum)</span></span>
<span id="S7.T9.1.3.1.2.1.7" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">El Mhamdi et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> (Bulyan)</span></span>
<span id="S7.T9.1.3.1.2.1.8" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Wang et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> (ELITE)</span></span>
<span id="S7.T9.1.3.1.2.1.9" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Tekgul et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> (WAFFLE)</span></span>
<span id="S7.T9.1.3.1.2.1.10" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Li et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> (FedIPR)</span></span>
<span id="S7.T9.1.3.1.2.1.11" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Lin et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite></span></span>
<span id="S7.T9.1.3.1.2.1.12" class="ltx_tr">
<span id="S7.T9.1.3.1.2.1.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Zong et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> (DAGMM)</span></span>
</span></span><span id="S7.T9.1.3.1.3" class="ltx_text"></span></td>
<td id="S7.T9.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.3.2.1" class="ltx_text"></span> <span id="S7.T9.1.3.2.2" class="ltx_text">
<span id="S7.T9.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.3.2.2.1.1" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Geometric median</span></span>
<span id="S7.T9.1.3.2.2.1.2" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Weiszfeld-smoothed geometric median</span></span>
<span id="S7.T9.1.3.2.2.1.3" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Dimension-wise median</span></span>
<span id="S7.T9.1.3.2.2.1.4" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Mean-around median</span></span>
<span id="S7.T9.1.3.2.2.1.5" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Dimension-wise trimmed mean</span></span>
<span id="S7.T9.1.3.2.2.1.6" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Euclidean distance</span></span>
<span id="S7.T9.1.3.2.2.1.7" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Euclidean distance</span></span>
<span id="S7.T9.1.3.2.2.1.8" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Gradient information gain</span></span>
<span id="S7.T9.1.3.2.2.1.9" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">The server embeds watermarks</span></span>
<span id="S7.T9.1.3.2.2.1.10" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Generate secret watermarks on client</span></span>
<span id="S7.T9.1.3.2.2.1.11" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Auto-encoder</span></span>
<span id="S7.T9.1.3.2.2.1.12" class="ltx_tr">
<span id="S7.T9.1.3.2.2.1.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Gaussian mixture network</span></span>
</span></span><span id="S7.T9.1.3.2.3" class="ltx_text"></span></td>
<td id="S7.T9.1.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr></td>
<td id="S7.T9.1.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.3.4.1" class="ltx_text"></span> <span id="S7.T9.1.3.4.2" class="ltx_text">
<span id="S7.T9.1.3.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.3.4.2.1.1" class="ltx_tr">
<span id="S7.T9.1.3.4.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Priori Attack</span></span>
<span id="S7.T9.1.3.4.2.1.2" class="ltx_tr">
<span id="S7.T9.1.3.4.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Posteriori Attack</span></span>
</span></span><span id="S7.T9.1.3.4.3" class="ltx_text"></span></td>
</tr>
<tr id="S7.T9.1.4" class="ltx_tr">
<td id="S7.T9.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.4.1.1" class="ltx_text"></span> <span id="S7.T9.1.4.1.2" class="ltx_text">
<span id="S7.T9.1.4.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.4.1.2.1.1" class="ltx_tr">
<span id="S7.T9.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Zhu et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite></span></span>
<span id="S7.T9.1.4.1.2.1.2" class="ltx_tr">
<span id="S7.T9.1.4.1.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Chamikara et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite></span></span>
<span id="S7.T9.1.4.1.2.1.3" class="ltx_tr">
<span id="S7.T9.1.4.1.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Wei et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite></span></span>
<span id="S7.T9.1.4.1.2.1.4" class="ltx_tr">
<span id="S7.T9.1.4.1.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Scheliga et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> (PRECODE)</span></span>
<span id="S7.T9.1.4.1.2.1.5" class="ltx_tr">
<span id="S7.T9.1.4.1.2.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Ren et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> (FedKL)</span></span>
</span></span><span id="S7.T9.1.4.1.3" class="ltx_text"></span></td>
<td id="S7.T9.1.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.4.2.1" class="ltx_text"></span> <span id="S7.T9.1.4.2.2" class="ltx_text">
<span id="S7.T9.1.4.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.4.2.2.1.1" class="ltx_tr">
<span id="S7.T9.1.4.2.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Adding noise to gradients</span></span>
<span id="S7.T9.1.4.2.2.1.2" class="ltx_tr">
<span id="S7.T9.1.4.2.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Perturbing data</span></span>
<span id="S7.T9.1.4.2.2.1.3" class="ltx_tr">
<span id="S7.T9.1.4.2.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">DP on data</span></span>
<span id="S7.T9.1.4.2.2.1.4" class="ltx_tr">
<span id="S7.T9.1.4.2.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Transform feature representation</span></span>
<span id="S7.T9.1.4.2.2.1.5" class="ltx_tr">
<span id="S7.T9.1.4.2.2.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Hide the input from gradient</span></span>
</span></span><span id="S7.T9.1.4.2.3" class="ltx_text"></span></td>
<td id="S7.T9.1.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr></td>
<td id="S7.T9.1.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.4.4.1" class="ltx_text"></span> <span id="S7.T9.1.4.4.2" class="ltx_text">
<span id="S7.T9.1.4.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.4.4.2.1.1" class="ltx_tr">
<span id="S7.T9.1.4.4.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Attribute Inference</span></span>
<span id="S7.T9.1.4.4.2.1.2" class="ltx_tr">
<span id="S7.T9.1.4.4.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Membership Identification</span></span>
<span id="S7.T9.1.4.4.2.1.3" class="ltx_tr">
<span id="S7.T9.1.4.4.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Image Recovery</span></span>
</span></span><span id="S7.T9.1.4.4.3" class="ltx_text"></span></td>
</tr>
<tr id="S7.T9.1.5" class="ltx_tr">
<td id="S7.T9.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.5.1.1" class="ltx_text"></span> <span id="S7.T9.1.5.1.2" class="ltx_text">
<span id="S7.T9.1.5.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.5.1.2.1.1" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Ozdayi et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite> (Robust-LR)</span></span>
<span id="S7.T9.1.5.1.2.1.2" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">McMahan et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite> (DP-FedAvg)</span></span>
<span id="S7.T9.1.5.1.2.1.3" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Wu et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite></span></span>
<span id="S7.T9.1.5.1.2.1.4" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Sturluson et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite> (FedRAD)</span></span>
<span id="S7.T9.1.5.1.2.1.5" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Xie et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> (CRFL)</span></span>
<span id="S7.T9.1.5.1.2.1.6" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Cao et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite></span></span>
<span id="S7.T9.1.5.1.2.1.7" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Andreina et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> (BaFFLe)</span></span>
<span id="S7.T9.1.5.1.2.1.8" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Rieger et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> (DeepSight)</span></span>
<span id="S7.T9.1.5.1.2.1.9" class="ltx_tr">
<span id="S7.T9.1.5.1.2.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Nguyen et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite> (FLAME)</span></span>
</span></span><span id="S7.T9.1.5.1.3" class="ltx_text"></span></td>
<td id="S7.T9.1.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.5.2.1" class="ltx_text"></span> <span id="S7.T9.1.5.2.2" class="ltx_text">
<span id="S7.T9.1.5.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.5.2.2.1.1" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Update cleansing</span></span>
<span id="S7.T9.1.5.2.2.1.2" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">DP</span></span>
<span id="S7.T9.1.5.2.2.1.3" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Model pruning</span></span>
<span id="S7.T9.1.5.2.2.1.4" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Knowledge distillation</span></span>
<span id="S7.T9.1.5.2.2.1.5" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Certified robustness from updates</span></span>
<span id="S7.T9.1.5.2.2.1.6" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Certified robustness</span></span>
<span id="S7.T9.1.5.2.2.1.7" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Validation on diversified client data</span></span>
<span id="S7.T9.1.5.2.2.1.8" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Various metrics</span></span>
<span id="S7.T9.1.5.2.2.1.9" class="ltx_tr">
<span id="S7.T9.1.5.2.2.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Clustering, clipping and noising</span></span>
</span></span><span id="S7.T9.1.5.2.3" class="ltx_text"></span></td>
<td id="S7.T9.1.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Composite</td>
<td id="S7.T9.1.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S7.T9.1.5.4.1" class="ltx_text"></span> <span id="S7.T9.1.5.4.2" class="ltx_text">
<span id="S7.T9.1.5.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S7.T9.1.5.4.2.1.1" class="ltx_tr">
<span id="S7.T9.1.5.4.2.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Updates Attack</span></span>
<span id="S7.T9.1.5.4.2.1.2" class="ltx_tr">
<span id="S7.T9.1.5.4.2.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Distributed Triggers</span></span>
<span id="S7.T9.1.5.4.2.1.3" class="ltx_tr">
<span id="S7.T9.1.5.4.2.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Insidious Tampering</span></span>
</span></span><span id="S7.T9.1.5.4.3" class="ltx_text"></span></td>
</tr>
</table>
</figure>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Future Directions</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">As <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> continues to evolve, the sophistication of potential attacks will continue to increase. By reviewing the recent advancements in this domain, we identify several promising research directions that include:

<br class="ltx_break"></p>
</div>
<div id="S7.SS2.p2" class="ltx_para ltx_noindent">
<p id="S7.SS2.p2.1" class="ltx_p"><span id="S7.SS2.p2.1.1" class="ltx_text ltx_font_bold">Robust Aggregation Mechanisms:</span> The aggregation process in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> is a key link where local model updates from different participants are combined to update the global model. Given its central role, the aggregation step becomes a vulnerable point, especially to malicious interference. For example, a single participant with malicious intentions may submit misleading updates with the intention of degrading the performance of the global model. This adverse activity is of particular concern in <abbr title="Model to Model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2M</span></abbr> attacks, of which the Byzantine attack is a prime example. In a Byzantine attack, an adversary sends arbitrary or strategically designed updates to a server with the intent of disrupting the aggregated model. Addressing these vulnerabilities requires re-evaluating and redesigning the traditional aggregation mechanisms used in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>. By delving into the development of more resilient aggregation strategies, methods can can be designed to identify, isolate, or reduce the impact of these malicious updates. These advanced aggregation techniques, based on robust statistical measures, consensus algorithms and even outlier detection methods, can ensure that the integrity of the global model remains intact in the presence of hostile participants.

<br class="ltx_break"></p>
</div>
<div id="S7.SS2.p3" class="ltx_para ltx_noindent">
<p id="S7.SS2.p3.1" class="ltx_p"><span id="S7.SS2.p3.1.1" class="ltx_text ltx_font_bold">Gradient Sparse Attack:</span>
In terms of <abbr title="Model to Data" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">M2D</span></abbr> attack methods, it is worth noting that the gradients exchanged between the server and the client often contain a large amount of redundant details¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, and this redundancy may play a negative role in the effectiveness of the attack. If an attacker can filter out valuable gradients, the efficiency of the attack can be dramatically improved, especially in large-scale model training. This gradient sparse process eliminates irrelevant and noisy data, thus potentially improving the accuracy of the attack.

<br class="ltx_break"></p>
</div>
<div id="S7.SS2.p4" class="ltx_para ltx_noindent">
<p id="S7.SS2.p4.1" class="ltx_p"><span id="S7.SS2.p4.1.1" class="ltx_text ltx_font_bold">Automatic Attack Detection:</span> As the complexity and scale of <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> environments continues to grow, automated safety measures become critical. Meta-learning¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>, <a href="#bib.bib153" title="" class="ltx_ref">153</a>, <a href="#bib.bib154" title="" class="ltx_ref">154</a>, <a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite>, often referred to as ‚Äúlearning to learn‚Äù, offers a promising avenue to address this challenge. By employing meta-learning techniques, systems can be trained to leverage prior knowledge about different types of attacks to quickly adapt to new, unforeseen threats. In addition, anomaly detection algorithms help identify outliers or unusual patterns in traditional datasets that can be fine-tuned for federated environments. These algorithms can monitor incoming model updates from different clients or nodes and flag any updates that deviate from the expected pattern to indicate potential malicious activity. Such an automated system not only identifies threats, but also combines with defense mechanisms to immediately counteract or eliminate suspicious activity, ensuring a smoother and safer <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> process.

<br class="ltx_break"></p>
</div>
<div id="S7.SS2.p5" class="ltx_para ltx_noindent">
<p id="S7.SS2.p5.1" class="ltx_p"><span id="S7.SS2.p5.1.1" class="ltx_text ltx_font_bold">Holistic Defense Strategies:</span> In the rapidly evolving <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> environment, the need for holistic defense strategies is becoming increasingly prominent. These strategies advocate the development and implementation of defense mechanisms that are inherently versatile and capable of responding to multiple attack vectors simultaneously. A holistic approach would integrate various protection measures to create a more resilient and adaptive security framework, rather than a solo approach that develops defenses against specific threats. This multi-pronged defense system not only ensures broader security coverage, but also minimizes potential vulnerabilities and overlaps. As adversarial tactics become increasingly complex, utilizing an integrated solution that anticipates and responds to a wide range of threats will be key to protecting the <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> ecosystem.

<br class="ltx_break"></p>
</div>
<div id="S7.SS2.p6" class="ltx_para ltx_noindent">
<p id="S7.SS2.p6.1" class="ltx_p"><span id="S7.SS2.p6.1.1" class="ltx_text ltx_font_bold">Domain-specific Attacks and Defenses</span>
Although we have witnessed nascent studies on exploiting the vulnerabilities in Federated Recommendation System and Federated <abbr title="Reinforcement Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">RL</span></abbr>, few defenses are proposed to defend against such threats. Furthermore, a majority of the current research tends to focus on image classification as the principal learning task for both attacks and defenses. This observation underscores a pressing need and opportunity to delve deeper into domain-specific threat models and tailored defense strategies for federated learning. Investigating this avenue not only holds promise for enhancing security but also ensures the more comprehensive protection of diverse applications within <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>.

<br class="ltx_break"></p>
</div>
<div id="S7.SS2.p7" class="ltx_para ltx_noindent">
<p id="S7.SS2.p7.1" class="ltx_p"><span id="S7.SS2.p7.1.1" class="ltx_text ltx_font_bold">Interdisciplinary Approaches:</span> Harnessing the wealth of insights from different fields is particularly instructive for enhancing <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> systems. For example, frameworks and theories from disciplines such as game theory and behavioral science can help to understand the motivations and behaviors of participants in a <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> environment. By understanding these motivations, tailored incentive structures or deterrence mechanisms can be designed to encourage positive contributions and discourage malicious or negligent behaviors in <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> ecosystems. In addition, the fields of cryptography and cyber-security are constantly evolving, offering a plethora of innovative techniques and protocols. By integrating these advances into <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr>, we can strengthen systems against identified vulnerabilities and ensure not only the privacy and integrity of data, but also the trustworthiness of the learning process. As the stakes for <abbr title="Federated Learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short">FL</span></abbr> grow, especially in critical areas of application, the convergence of these areas is critical to creating a robust, secure and collaborative learning environment.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A.¬†Radford, K.¬†Narasimhan, T.¬†Salimans, I.¬†Sutskever, et¬†al., Improving
language understanding by generative pre-training (2018).

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A.¬†Radford, J.¬†Wu, R.¬†Child, D.¬†Luan, D.¬†Amodei, I.¬†Sutskever, et¬†al., Language
models are unsupervised multitask learners, OpenAI blog 1¬†(8) (2019) 9.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
T.¬†Brown, B.¬†Mann, N.¬†Ryder, M.¬†Subbiah, J.¬†D. Kaplan, P.¬†Dhariwal,
A.¬†Neelakantan, P.¬†Shyam, G.¬†Sastry, A.¬†Askell, et¬†al., Language models are
few-shot learners, NIPs 33 (2020) 1877‚Äì1901.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J.¬†Ho, A.¬†Jain, P.¬†Abbeel, Denoising diffusion probabilistic models, NIPs 33
(2020) 6840‚Äì6851.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J.¬†Sohl-Dickstein, E.¬†Weiss, N.¬†Maheswaranathan, S.¬†Ganguli, Deep unsupervised
learning using nonequilibrium thermodynamics, in: ICML, PMLR, 2015, pp.
2256‚Äì2265.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y.¬†Song, S.¬†Ermon, Generative modeling by estimating gradients of the data
distribution, NIPs 32 (2019).

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Y.¬†Song, J.¬†Sohl-Dickstein, D.¬†P. Kingma, A.¬†Kumar, S.¬†Ermon, B.¬†Poole,
Score-based generative modeling through stochastic differential equations,
arXiv (2020).

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
G.¬†A. Kaissis, M.¬†R. Makowski, D.¬†R√ºckert, R.¬†F. Braren, Secure,
privacy-preserving and federated machine learning in medical imaging, NMI
2¬†(6) (2020) 305‚Äì311.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J.¬†Koneƒçn·ª≥, H.¬†B. McMahan, F.¬†X. Yu, P.¬†Richt√°rik, A.¬†T. Suresh,
D.¬†Bacon, Federated learning: Strategies for improving communication
efficiency, arXiv (2016).

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
B.¬†McMahan, E.¬†Moore, D.¬†Ramage, S.¬†Hampson, B.¬†A. y¬†Arcas,
Communication-efficient learning of deep networks from decentralized data,
in: PMLR AISTATS, 2017, pp. 1273‚Äì1282.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R.¬†S. Antunes, C.¬†Andr√©¬†da Costa, A.¬†K√ºderle, I.¬†A. Yari, B.¬†Eskofier,
Federated learning for healthcare: Systematic review and architecture
proposal, TIST 13¬†(4) (2022) 1‚Äì23.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
D.¬†C. Nguyen, Q.-V. Pham, P.¬†N. Pathirana, M.¬†Ding, A.¬†Seneviratne, Z.¬†Lin,
O.¬†Dobre, W.-J. Hwang, Federated learning for smart healthcare: A survey,
CSUR 55¬†(3) (2022) 1‚Äì37.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J.¬†Xu, B.¬†S. Glicksberg, C.¬†Su, P.¬†Walker, J.¬†Bian, F.¬†Wang, Federated learning
for healthcare informatics, JHIR 5 (2021) 1‚Äì19.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
G.¬†Long, Y.¬†Tan, J.¬†Jiang, C.¬†Zhang, Federated learning for open banking, in:
FLPI, Springer, 2020, pp. 240‚Äì254.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
D.¬†Byrd, A.¬†Polychroniadou, Differentially private secure multi-party
computation for federated learning in financial applications, in: ICAIF,
2020, pp. 1‚Äì9.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
W.¬†Yang, Y.¬†Zhang, K.¬†Ye, L.¬†Li, C.-Z. Xu, Ffd: A federated learning based
method for credit card fraud detection, in: BigData, Springer, 2019, pp.
18‚Äì32.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Z.¬†Zheng, Y.¬†Zhou, Y.¬†Sun, Z.¬†Wang, B.¬†Liu, K.¬†Li, Applications of federated
learning in smart cities: recent advances, taxonomy, and open challenges,
Connection Science 34¬†(1) (2022) 1‚Äì28.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J.¬†C. Jiang, B.¬†Kantarci, S.¬†Oktug, T.¬†Soyata, Federated learning in smart city
sensing: Challenges and opportunities, Sensors 20¬†(21) (2020) 6230.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
D.¬†C. Nguyen, M.¬†Ding, P.¬†N. Pathirana, A.¬†Seneviratne, J.¬†Li, H.¬†V. Poor,
Federated learning for internet of things: A comprehensive survey, CST 23¬†(3)
(2021) 1622‚Äì1658.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
H.¬†Zhang, J.¬†Bosch, H.¬†H. Olsson, End-to-end federated learning for autonomous
driving vehicles, in: IJCNN, IEEE, 2021, pp. 1‚Äì8.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
A.¬†Nguyen, T.¬†Do, M.¬†Tran, B.¬†X. Nguyen, C.¬†Duong, T.¬†Phan, E.¬†Tjiputra, Q.¬†D.
Tran, Deep federated learning for autonomous driving, in: IV, IEEE, 2022, pp.
1824‚Äì1830.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
H.¬†Zhang, J.¬†Bosch, H.¬†H. Olsson, Real-time end-to-end federated learning: An
automotive case study, in: COMPSAC, IEEE, 2021, pp. 459‚Äì468.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
P.¬†Kairouz, H.¬†B. McMahan, et¬†al., Advances and open problems in federated
learning, Foundations and Trends¬Æ in Machine Learning (2021).

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
L.¬†Lyu, H.¬†Yu, Q.¬†Yang, Threats to federated learning: A survey, arXiv preprint
arXiv:2003.02133 (2020).

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
R.¬†Zhang, S.¬†Guo, J.¬†Wang, X.¬†Xie, D.¬†Tao, A survey on gradient inversion:
Attacks, defenses and future directions, arXiv preprint arXiv:2206.07284
(2022).

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y.¬†Liu, Y.¬†Kang, T.¬†Zou, Y.¬†Pu, Y.¬†He, X.¬†Ye, Y.¬†Ouyang, Y.-Q. Zhang, Q.¬†Yang,
Vertical federated learning, arXiv preprint arXiv:2211.12814 (2022).

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
H.¬†Zhu, J.¬†Xu, S.¬†Liu, Y.¬†Jin, Federated learning on non-iid data: A survey,
Neurocomput. (2021).

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
M.¬†Rasouli, T.¬†Sun, R.¬†Rajagopal, Fedgan: Federated generative adversarial
networks for distributed data, arXiv preprint arXiv:2006.07228 (2020).

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
M.¬†Liu, S.¬†Ho, M.¬†Wang, L.¬†Gao, Y.¬†Jin, H.¬†Zhang, Federated learning meets
natural language processing: A survey, arXiv preprint arXiv:2107.12603
(2021).

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Y.¬†Liu, A.¬†Huang, Y.¬†Luo, H.¬†Huang, Y.¬†Liu, Y.¬†Chen, L.¬†Feng, T.¬†Chen, H.¬†Yu,
Q.¬†Yang, Fedvision: An online visual object detection platform powered by
federated learning, Proceedings of the AAAI Conference on Artificial
Intelligence (2020).

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
X.¬†Li, K.¬†Huang, W.¬†Yang, S.¬†Wang, Z.¬†Zhang, On the convergence of fedavg on
non-iid data, arXiv preprint arXiv:1907.02189 (2019).

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S.¬†P. Karimireddy, S.¬†Kale, M.¬†Mohri, S.¬†Reddi, S.¬†Stich, A.¬†T. Suresh,
Scaffold: Stochastic controlled averaging for federated learning, in: ICML,
PMLR, 2020, pp. 5132‚Äì5143.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
T.¬†Li, A.¬†K. Sahu, M.¬†Zaheer, M.¬†Sanjabi, A.¬†Talwalkar, V.¬†Smith, Federated
optimization in heterogeneous networks, Proceedings of Machine learning and
systems 2 (2020) 429‚Äì450.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S.¬†Ji, S.¬†Pan, G.¬†Long, X.¬†Li, J.¬†Jiang, Z.¬†Huang, Learning private neural
language modeling with attentive aggregation, in: 2019 International joint
conference on neural networks (IJCNN), IEEE, 2019, pp. 1‚Äì8.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
X.¬†Wu, Z.¬†Liang, J.¬†Wang, Fedmed: A federated learning framework for language
modeling, Sensors (2020).

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
H.¬†Ren, J.¬†Deng, X.¬†Xie, X.¬†Ma, Y.¬†Wang, Fedboosting: Federated learning with
gradient protected boosting for text recognition, arXiv (2020).

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
T.¬†D. Nguyen, T.¬†Nguyen, P.¬†L. Nguyen, H.¬†H. Pham, K.¬†D. Doan, K.-S. Wong,
Backdoor attacks and defenses in federated learning: Survey, challenges and
future research directions, Engineering Applications of Artificial
Intelligence 127 (2024) 107166.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Y.¬†Zhang, D.¬†Zeng, J.¬†Luo, Z.¬†Xu, I.¬†King, A survey of trustworthy federated
learning with perspectives on security, robustness and privacy (2023).

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
X.¬†Gong, Y.¬†Chen, Q.¬†Wang, W.¬†Kong, Backdoor attacks and defenses in federated
learning: State-of-the-art, taxonomy, and future directions (2023).

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
X.¬†Yin, Y.¬†Zhu, J.¬†Hu, A comprehensive survey of privacy-preserving federated
learning: A taxonomy, review, and future directions (2021).

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
J.¬†Zhang, M.¬†Li, S.¬†Zeng, B.¬†Xie, D.¬†Zhao, A survey on security and privacy
threats to federated learning (2021).

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
B.¬†Biggio, B.¬†Nelson, P.¬†Laskov, Poisoning attacks against support vector
machines, in: ICICML, ICML‚Äô12, 2012, p. 1467‚Äì1474.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
C.¬†Fung, C.¬†J. Yoon, I.¬†Beschastnikh, Mitigating sybils in federated learning
poisoning, arXiv preprint arXiv:1808.04866 (2018).

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
V.¬†Tolpegin, S.¬†Truex, M.¬†E. Gursoy, L.¬†Liu, Data poisoning attacks against
federated learning systems, in: ESORICS 2020, Springer, 2020, pp. 480‚Äì501.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
H.¬†Xiao, K.¬†Rasul, R.¬†Vollgraf, Fashion-mnist: a novel image dataset for
benchmarking machine learning algorithms, arXiv preprint arXiv:1708.07747
(2017).

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
J.¬†Zhang, B.¬†Chen, X.¬†Cheng, H.¬†T.¬†T. Binh, S.¬†Yu, Poisongan: Generative
poisoning attacks against federated learning in edge computing systems, ITJ
8¬†(5) (2021) 3310‚Äì3322.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
H.¬†Wang, K.¬†Sreenivasan, S.¬†Rajput, H.¬†Vishwakarma, S.¬†Agarwal, J.-y. Sohn,
K.¬†Lee, D.¬†Papailiopoulos, Attack of the tails: Yes, you really can backdoor
federated learning, NIPs 33 (2020) 16070‚Äì16084.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Y.¬†Sun, H.¬†Ochiai, J.¬†Sakuma, Semi-targeted model poisoning attack on federated
learning via backward error analysis, in: IJCNN, IEEE, 2022, pp. 1‚Äì8.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
D.¬†Cao, S.¬†Chang, Z.¬†Lin, G.¬†Liu, D.¬†Sun, Understanding distributed poisoning
attack in federated learning, in: ICPADS, 2019.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
G.¬†Sun, Y.¬†Cong, J.¬†Dong, Q.¬†Wang, L.¬†Lyu, J.¬†Liu, Data poisoning attacks on
federated machine learning, ITJ (2022).

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
G.¬†Costa, F.¬†Pinelli, S.¬†Soderi, G.¬†Tolomei, Turning federated learning systems
into covert channels, IEEE Access (2022).

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
J.¬†Shi, W.¬†Wan, S.¬†Hu, J.¬†Lu, L.¬†Y. Zhang, Challenges and approaches for
mitigating byzantine attacks in federated learning, in: TrustCom, IEEE, 2022,
pp. 139‚Äì146.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
E.¬†Ma, R.¬†Etesami, et¬†al., Local environment poisoning attacks on federated
reinforcement learning, arXiv preprint arXiv:2303.02725 (2023).

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
M.¬†Arazzi, M.¬†Conti, A.¬†Nocera, S.¬†Picek, Turning privacy-preserving mechanisms
against federated learning, arXiv preprint arXiv:2305.05355 (2023).

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Z.¬†Liu, L.¬†Yang, Z.¬†Fan, H.¬†Peng, P.¬†S. Yu, Federated social recommendation
with graph neural network, TIST 13¬†(4) (aug 2022).

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
A.¬†V. Clemente, H.¬†N. Castej√≥n, A.¬†Chandra, Efficient parallel methods for
deep reinforcement learning, arXiv preprint arXiv:1705.04862 (2017).

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Y.¬†LeCun, The mnist database of handwritten digits, http://yann. lecun.
com/exdb/mnist/ (1998).

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
A.¬†Krizhevsky, G.¬†Hinton, et¬†al., Learning multiple layers of features from
tiny images (2009).

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
L.¬†Lamport, R.¬†Shostak, M.¬†Pease, The byzantine generals problem, TPLS (1982).

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Y.¬†Fraboni, R.¬†Vidal, M.¬†Lorenzi, Free-rider attacks on model aggregation in
federated learning, in: ICAIS, PMLR, 2021, pp. 1846‚Äì1854.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
P.¬†Blanchard, E.¬†M. El¬†Mhamdi, R.¬†Guerraoui, J.¬†Stainer, Machine learning with
adversaries: Byzantine tolerant gradient descent, NIPs 30 (2017).

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
C.¬†Xie, O.¬†Koyejo, I.¬†Gupta, Generalized byzantine-tolerant sgd, arXiv preprint
arXiv:1802.10116 (2018).

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
L.¬†Li, W.¬†Xu, T.¬†Chen, G.¬†B. Giannakis, Q.¬†Ling, Rsa: Byzantine-robust
stochastic aggregation methods for distributed learning from heterogeneous
datasets, in: AAAI, Vol.¬†33, 2019, pp. 1544‚Äì1551.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
G.¬†Baruch, M.¬†Baruch, Y.¬†Goldberg, A little is enough: Circumventing defenses
for distributed learning, NIPs 32 (2019).

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
E.¬†M. El¬†Mhamdi, R.¬†Guerraoui, S.¬†L.¬†A. Rouault, The hidden vulnerability of
distributed learning in byzantium, in: ICML, 2018, p.¬†13.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
M.¬†Fang, X.¬†Cao, J.¬†Jia, N.¬†Gong, Local model poisoning attacks to
<math id="bib.bib66.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib66.1.m1.1a"><mo stretchy="false" id="bib.bib66.1.m1.1.1" xref="bib.bib66.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib66.1.m1.1b"><ci id="bib.bib66.1.m1.1.1.cmml" xref="bib.bib66.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib66.1.m1.1c">\{</annotation></semantics></math>Byzantine-Robust<math id="bib.bib66.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib66.2.m2.1a"><mo stretchy="false" id="bib.bib66.2.m2.1.1" xref="bib.bib66.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib66.2.m2.1b"><ci id="bib.bib66.2.m2.1.1.cmml" xref="bib.bib66.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib66.2.m2.1c">\}</annotation></semantics></math> federated learning, in: 29th USENIX security
symposium (USENIX Security 20), 2020, pp. 1605‚Äì1622.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
S.¬†Zhang, H.¬†Yin, T.¬†Chen, Z.¬†Huang, Q.¬†V.¬†H. Nguyen, L.¬†Cui, Pipattack:
Poisoning federated recommender systems for manipulating item promotion, in:
ACM ICWSDM, 2022, pp. 1415‚Äì1423.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
D.¬†Rong, S.¬†Ye, R.¬†Zhao, H.¬†N. Yuen, J.¬†Chen, Q.¬†He, Fedrecattack: model
poisoning attack to federated recommendation, in: ICDE, IEEE, 2022, pp.
2643‚Äì2655.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
D.¬†Rong, Q.¬†He, J.¬†Chen, Poisoning deep learning based recommender model in
federated learning scenarios, arXiv preprint arXiv:2204.13594 (2022).

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
D.¬†Yin, Y.¬†Chen, R.¬†Kannan, P.¬†Bartlett, Byzantine-robust distributed
learning: Towards optimal statistical rates, in: J.¬†Dy, A.¬†Krause (Eds.),
ICML, Vol.¬†80 of Proceedings of Machine Learning Research, PMLR, 2018, pp.
5650‚Äì5659.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
M.¬†Ammad-Ud-Din, E.¬†Ivannikova, S.¬†A. Khan, W.¬†Oyomno, Q.¬†Fu, K.¬†E. Tan,
A.¬†Flanagan, Federated collaborative filtering for privacy-preserving
personalized recommendation system, arXiv preprint arXiv:1901.09888 (2019).

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Y.¬†Chen, L.¬†Su, J.¬†Xu, Distributed statistical machine learning in adversarial
settings: Byzantine gradient descent, MACS 1¬†(2) (2017) 1‚Äì25.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
K.¬†Pillutla, S.¬†M. Kakade, Z.¬†Harchaoui, Robust aggregation for federated
learning, IEEE Transactions on Signal Processing (2022).

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Y.¬†Wang, Y.¬†Xia, Y.¬†Zhan, Elite: Defending federated learning against byzantine
attacks based on information entropy, in: CAC, 2021, pp. 6049‚Äì6054.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
E.¬†Weiszfeld, F.¬†Plastria, On the point for which the sum of the distances to n
given points is minimum, Ann Oper Res (2009).

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
J.¬†Lin, M.¬†Du, J.¬†Liu, Free-riders in federated learning: Attacks and defenses,
arXiv preprint arXiv:1911.12560 (2019).

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Y.¬†Adi, C.¬†Baum, M.¬†Cisse, B.¬†Pinkas, J.¬†Keshet, Turning your weakness into a
strength: Watermarking deep neural networks by backdooring, in: 27th USENIX
Security Symposium (USENIX Security 18), 2018, pp. 1615‚Äì1631.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Y.¬†Uchida, Y.¬†Nagai, S.¬†Sakazawa, S.¬†Satoh, Embedding watermarks into deep
neural networks, in: ACM ICMR, 2017, pp. 269‚Äì277.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
B.¬†A. Tekgul, Y.¬†Xia, S.¬†Marchal, N.¬†Asokan, Waffle: Watermarking in federated
learning (2021).

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
B.¬†Li, L.¬†Fan, H.¬†Gu, J.¬†Li, Q.¬†Yang, Fedipr: Ownership verification for
federated deep neural network models, TPAMI 45¬†(4) (2022) 4521‚Äì4536.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
M.¬†Sakurada, T.¬†Yairi, Anomaly detection using autoencoders with nonlinear
dimensionality reduction, in: MLSDAW, 2014, pp. 4‚Äì11.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
B.¬†Zong, Q.¬†Song, M.¬†R. Min, W.¬†Cheng, C.¬†Lumezanu, D.¬†Cho, H.¬†Chen, Deep
autoencoding gaussian mixture model for unsupervised anomaly detection, in:
ICLR, 2018.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
G.¬†Ateniese, L.¬†V. Mancini, A.¬†Spognardi, A.¬†Villani, D.¬†Vitali, G.¬†Felici,
Hacking smart machines with smarter ones: How to extract meaningful data from
machine learning classifiers, IJSN 10¬†(3) (2015) 137‚Äì150.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
L.¬†E. Baum, T.¬†Petrie, Statistical inference for probabilistic functions of
finite state markov chains, The annals of mathematical statistics 37¬†(6)
(1966) 1554‚Äì1563.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
B.¬†E. Boser, I.¬†M. Guyon, V.¬†N. Vapnik, A training algorithm for optimal margin
classifiers, in: CLTW, 1992, pp. 144‚Äì152.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
R.¬†Shokri, M.¬†Stronati, C.¬†Song, V.¬†Shmatikov, Membership inference attacks
against machine learning models, in: SP, IEEE, 2017, pp. 3‚Äì18.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
R.¬†McPherson, R.¬†Shokri, V.¬†Shmatikov, Defeating image obfuscation with deep
learning, arXiv (2016).

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
D.¬†Carrell, B.¬†Malin, J.¬†Aberdeen, S.¬†Bayer, C.¬†Clark, B.¬†Wellner,
L.¬†Hirschman, Hiding in plain sight: use of realistic surrogates to reduce
exposure of protected health information in clinical text, JAMIIA 20¬†(2)
(2013) 342‚Äì348.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
F.¬†Li, Z.¬†Sun, A.¬†Li, B.¬†Niu, H.¬†Li, G.¬†Cao, Hideme: Privacy-preserving photo
sharing on social networks, in: INFOCOM, IEEE, 2019, pp. 154‚Äì162.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
L.¬†C. AT&amp;T, The database of faces (1994).

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
H.-W. Ng, S.¬†Winkler, A data-driven approach to cleaning large face datasets,
in: ICIP, 2014, pp. 343‚Äì347.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Y.¬†Zhang, R.¬†Jia, H.¬†Pei, W.¬†Wang, B.¬†Li, D.¬†Song, The secret revealer:
Generative model-inversion attacks against deep neural networks, in: CVPR,
2020, pp. 253‚Äì261.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
X.¬†Wang, Y.¬†Peng, L.¬†Lu, Z.¬†Lu, M.¬†Bagheri, R.¬†M. Summers, Chestx-ray8:
Hospital-scale chest x-ray database and benchmarks on weakly-supervised
classification and localization of common thorax diseases, in: CVPR, 2017,
pp. 2097‚Äì2106.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Z.¬†Liu, P.¬†Luo, X.¬†Wang, X.¬†Tang, Deep learning face attributes in the wild,
in: ICCV, 2015, pp. 3730‚Äì3738.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
K.¬†Simonyan, A.¬†Zisserman, Very deep convolutional networks for large-scale
image recognition, arXiv (2014).

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
K.¬†He, X.¬†Zhang, S.¬†Ren, J.¬†Sun, Deep residual learning for image recognition,
in: CVPR, 2016, pp. 770‚Äì778.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Y.¬†Cheng, J.¬†Zhao, Z.¬†Wang, Y.¬†Xu, K.¬†Jayashree, S.¬†Shen, J.¬†Feng, Know you at
one glance: A compact vector representation for low-shot learning, in:
ICCVW, 2017, pp. 1924‚Äì1932.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
B.¬†Hitaj, G.¬†Ateniese, F.¬†Perez-Cruz, Deep models under the gan: Information
leakage from collaborative deep learning, in: CCCS, 2017, pp. 603‚Äì618.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
L.¬†Melis, C.¬†Song, E.¬†De¬†Cristofaro, V.¬†Shmatikov, Exploiting unintended
feature leakage in collaborative learning, in: SP, 2019, pp. 691‚Äì706.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Z.¬†Li, J.¬†Zhang, L.¬†Liu, J.¬†Liu, Auditing privacy defenses in federated
learning via generative gradient leakage, in: CVPR, 2022, pp. 10132‚Äì10142.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
B.¬†Zhao, K.¬†R. Mopuri, H.¬†Bilen, Idlg: Improved deep leakage from gradients,
arXiv (2020).

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
H.¬†Ren, J.¬†Deng, X.¬†Xie, X.¬†Ma, J.¬†Ma, Gradient leakage defense with key-lock
module for federated learning, arXiv (2023).

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
L.¬†Zhu, Z.¬†Liu, S.¬†Han, Deep leakage from gradients, NIPs 32 (2019).

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
D.¬†C. Liu, J.¬†Nocedal, On the limited memory bfgs method for large scale
optimization, Mathematical programming 45¬†(1-3) (1989) 503‚Äì528.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
J.¬†Geiping, H.¬†Bauermeister, H.¬†Dr√∂ge, M.¬†Moeller, Inverting gradients-how
easy is it to break privacy in federated learning?, NIPs 33 (2020)
16937‚Äì16947.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
J.¬†Jeon, K.¬†Lee, S.¬†Oh, J.¬†Ok, Gradient inversion with generative image prior,
NIPs 34 (2021) 29898‚Äì29908.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
H.¬†Yin, A.¬†Mallya, A.¬†Vahdat, J.¬†M. Alvarez, J.¬†Kautz, P.¬†Molchanov, See
through gradients: Image batch recovery via gradinversion, in: CVPR,
2021, pp. 16337‚Äì16346.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
Z.¬†Wang, M.¬†Song, Z.¬†Zhang, Y.¬†Song, Q.¬†Wang, H.¬†Qi, Beyond inferring class
representatives: User-level privacy leakage from federated learning, in:
ICCC, 2019, pp. 2512‚Äì2520.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
H.¬†Ren, J.¬†Deng, X.¬†Xie, Grnn: Generative regression neural network‚Äîa data leakage attack for federated learning, TIST 13¬†(4) (2022) 1‚Äì24.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
X.¬†Yang, Y.¬†Feng, W.¬†Fang, J.¬†Shao, X.¬†Tang, S.-T. Xia, R.¬†Lu, An
accuracy-lossless perturbation method for defending privacy attacks in
federated learning, in: WC, 2022, pp. 732‚Äì742.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
L.¬†Sun, J.¬†Qian, X.¬†Chen, LDP-FL: Practical private aggregation in
federated learning with local differential privacy, arXiv (2020).

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
J.¬†Sun, A.¬†Li, B.¬†Wang, H.¬†Yang, H.¬†Li, Y.¬†Chen, Soteria: Provable defense
against privacy leakage in federated learning from representation
perspective, in: CVPR, 2021, pp. 9307‚Äì9315.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
A.¬†T. Hasan, Q.¬†Jiang, J.¬†Luo, C.¬†Li, L.¬†Chen, An effective value swapping
method for privacy preserving data publishing, SCN 9¬†(16) (2016) 3219‚Äì3228.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
M.¬†A.¬†P. Chamikara, P.¬†Bert√≥k, D.¬†Liu, S.¬†Camtepe, I.¬†Khalil, Efficient
data perturbation for privacy preserving and accurate data stream mining, PMC
48 (2018) 1‚Äì19.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
M.¬†Chamikara, P.¬†Bertok, D.¬†Liu, S.¬†Camtepe, I.¬†Khalil, Efficient privacy
preservation of big data for accurate data mining, IS 527 (2020) 420‚Äì443.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
H.¬†Lee, J.¬†Kim, S.¬†Ahn, R.¬†Hussain, S.¬†Cho, J.¬†Son, Digestive neural networks:
A novel defense strategy against inference attacks in federated learning,
Computers &amp; Security 109 (2021) 102378.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
M.¬†A.¬†P. Chamikara, P.¬†Bertok, I.¬†Khalil, D.¬†Liu, S.¬†Camtepe, Privacy
preserving distributed machine learning with federated learning, Computer
Communications 171 (2021) 112‚Äì125.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Z.¬†Bu, J.¬†Dong, Q.¬†Long, W.¬†J. Su, Deep learning with gaussian differential
privacy, Harvard data science review 2020¬†(23) (2020).

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
Y.¬†Li, Y.¬†Zhou, A.¬†Jolfaei, D.¬†Yu, G.¬†Xu, X.¬†Zheng, Privacy-preserving
federated learning framework based on chained secure multiparty computing,
ITJ 8¬†(8) (2020) 6178‚Äì6186.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
K.¬†Yadav, B.¬†B. Gupta, K.¬†T. Chui, K.¬†Psannis, Differential privacy approach to
solve gradient leakage attack in a federated machine learning environment,
in: ICCDSN, Springer, 2020, pp. 378‚Äì385.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
W.¬†Wei, L.¬†Liu, Y.¬†Wut, G.¬†Su, A.¬†Iyengar, Gradient-leakage resilient federated
learning, in: ICDCS, IEEE, 2021, pp. 797‚Äì807.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
D.¬†Scheliga, P.¬†M√§der, M.¬†Seeland, Precode-a generic model extension to
prevent deep gradient leakage, in: WCACV, 2022, pp. 1849‚Äì1858.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
A.¬†N. Bhagoji, S.¬†Chakraborty, P.¬†Mittal, S.¬†Calo, Analyzing federated learning
through an adversarial lens, in: ICML, PMLR, 2019, pp. 634‚Äì643.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
E.¬†Bagdasaryan, A.¬†Veit, Y.¬†Hua, D.¬†Estrin, V.¬†Shmatikov, How to backdoor
federated learning, in: ICAIS, PMLR, 2020, pp. 2938‚Äì2948.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
Z.¬†Sun, P.¬†Kairouz, A.¬†T. Suresh, H.¬†B. McMahan, Can you really backdoor
federated learning?, arXiv preprint arXiv:1911.07963 (2019).

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
C.¬†Xie, K.¬†Huang, P.-Y. Chen, B.¬†Li, Dba: Distributed backdoor attacks against
federated learning, in: ICLR, 2019.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
X.¬†Gong, Y.¬†Chen, H.¬†Huang, Y.¬†Liao, S.¬†Wang, Q.¬†Wang, Coordinated backdoor
attacks against federated learning with model-dependent triggers, IEEE
Network 36¬†(1) (2022) 84‚Äì90.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
Z.¬†Zhang, A.¬†Panda, L.¬†Song, Y.¬†Yang, M.¬†Mahoney, P.¬†Mittal, R.¬†Kannan,
J.¬†Gonzalez, Neurotoxin: Durable backdoors in federated learning, in: ICML,
2022, pp. 26429‚Äì26446.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
H.¬†Li, C.¬†Wu, S.¬†Zhu, Z.¬†Zheng, Learning to backdoor federated learning, arXiv
preprint arXiv:2303.03320 (2023).

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
P.¬†Fang, J.¬†Chen, On the vulnerability of backdoor defenses for federated
learning, arXiv preprint arXiv:2301.08170 (2023).

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
K.¬†Yoo, N.¬†Kwak, Backdoor attacks in federated learning by rare embeddings and
gradient ensembling, arXiv preprint arXiv:2204.14017 (2022).

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
Y.¬†Wen, J.¬†Geiping, L.¬†Fowl, H.¬†Souri, R.¬†Chellappa, M.¬†Goldblum, T.¬†Goldstein,
Thinking two moves ahead: Anticipating other users improves backdoor attacks
in federated learning, arXiv preprint arXiv:2210.09305 (2022).

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
T.¬†Pang, X.¬†Yang, Y.¬†Dong, H.¬†Su, J.¬†Zhu, Accumulative poisoning attacks on
real-time data, NIPs 34 (2021) 2899‚Äì2912.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
T.¬†Gu, B.¬†Dolan-Gavitt, S.¬†Garg, Badnets: Identifying vulnerabilities in the
machine learning model supply chain, arXiv preprint arXiv:1708.06733 (2017).

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
Y.¬†Liu, S.¬†Ma, Y.¬†Aafer, W.-C. Lee, J.¬†Zhai, W.¬†Wang, X.¬†Zhang, Trojaning
attack on neural networks, in: NDSS, Internet Soc, 2018.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
M.¬†S. Ozdayi, M.¬†Kantarcioglu, Y.¬†R. Gel, Defending against backdoors in
federated learning with robust learning rate, in: AAAI, Vol.¬†35, 2021, pp.
9268‚Äì9276.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
Y.¬†Ma, X.¬†Zhu, J.¬†Hsu, Data poisoning against differentially-private learners:
Attacks and defenses, arXiv preprint arXiv:1903.09860 (2019).

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
H.¬†B. McMahan, D.¬†Ramage, K.¬†Talwar, L.¬†Zhang, Learning differentially private
recurrent language models, arXiv preprint arXiv:1710.06963 (2017).

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
C.¬†Wu, X.¬†Yang, S.¬†Zhu, P.¬†Mitra, Mitigating backdoor attacks in federated
learning, arXiv preprint arXiv:2011.01767 (2020).

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
Y.¬†Li, X.¬†Lyu, N.¬†Koren, L.¬†Lyu, B.¬†Li, X.¬†Ma, Neural attention distillation:
Erasing backdoor triggers from deep neural networks, arXiv preprint
arXiv:2101.05930 (2021).

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
S.¬†P. Sturluson, S.¬†Trew, L.¬†Mu√±oz-Gonz√°lez, M.¬†Grama,
J.¬†Passerat-Palmbach, D.¬†Rueckert, A.¬†Alansary, Fedrad: Federated robust
adaptive distillation, arXiv preprint arXiv:2112.01405 (2021).

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
G.¬†K. Nayak, K.¬†R. Mopuri, V.¬†Shaj, V.¬†B. Radhakrishnan, A.¬†Chakraborty,
Zero-shot knowledge distillation in deep networks, in: ICML, PMLR, 2019, pp.
4743‚Äì4751.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
T.¬†Lin, L.¬†Kong, S.¬†U. Stich, M.¬†Jaggi, Ensemble distillation for robust model
fusion in federated learning, NIPs 33 (2020) 2351‚Äì2363.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
M.¬†Lecuyer, V.¬†Atlidakis, R.¬†Geambasu, D.¬†Hsu, S.¬†Jana, Certified robustness to
adversarial examples with differential privacy, in: SP, IEEE, 2019, pp.
656‚Äì672.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
C.¬†Xie, M.¬†Chen, P.-Y. Chen, B.¬†Li, Crfl: Certifiably robust federated learning
against backdoor attacks, in: ICML, PMLR, 2021, pp. 11372‚Äì11382.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
X.¬†Cao, Z.¬†Zhang, J.¬†Jia, N.¬†Z. Gong, Flcert: Provably secure federated
learning against poisoning attacks, TIFS (2022).

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
S.¬†Andreina, G.¬†A. Marson, H.¬†M√∂llering, G.¬†Karame, Baffle: Backdoor
detection via feedback-based federated learning, in: ICDCS, IEEE, 2021, pp.
852‚Äì863.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
P.¬†Rieger, T.¬†D. Nguyen, M.¬†Miettinen, A.-R. Sadeghi, Deepsight: Mitigating
backdoor attacks in federated learning through deep model inspection, arXiv
preprint arXiv:2201.00763 (2022).

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
Y.¬†Liu, S.¬†Ma, Y.¬†Aafer, W.-C. Lee, J.¬†Zhai, W.¬†Wang, X.¬†Zhang, Trojaning
attack on neural networks, in: 25th Annual Network And Distributed System
Security Symposium (NDSS 2018), Internet Soc, 2018.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
R.¬†J. Campello, D.¬†Moulavi, J.¬†Sander, Density-based clustering based on
hierarchical density estimates, in: Pacific-Asia conference on knowledge
discovery and data mining, Springer, 2013, pp. 160‚Äì172.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
T.¬†D. Nguyen, P.¬†Rieger, e.¬†a. De¬†Viti, <math id="bib.bib151.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib151.1.m1.1a"><mo stretchy="false" id="bib.bib151.1.m1.1.1" xref="bib.bib151.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib151.1.m1.1b"><ci id="bib.bib151.1.m1.1.1.cmml" xref="bib.bib151.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib151.1.m1.1c">\{</annotation></semantics></math>FLAME<math id="bib.bib151.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib151.2.m2.1a"><mo stretchy="false" id="bib.bib151.2.m2.1.1" xref="bib.bib151.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib151.2.m2.1b"><ci id="bib.bib151.2.m2.1.1.cmml" xref="bib.bib151.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib151.2.m2.1c">\}</annotation></semantics></math>: Taming backdoors in
federated learning, in: 31st USENIX Security Symposium (USENIX Security 22),
2022, pp. 1415‚Äì1432.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
C.¬†Finn, P.¬†Abbeel, S.¬†Levine, Model-agnostic meta-learning for fast adaptation
of deep networks, in: ICML, PMLR, 2017, pp. 1126‚Äì1135.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
J.¬†Snell, K.¬†Swersky, R.¬†Zemel, Prototypical networks for few-shot learning,
NIPs 30 (2017).

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
K.¬†Lee, S.¬†Maji, A.¬†Ravichandran, S.¬†Soatto, Meta-learning with differentiable
convex optimization, in: CVPR, 2019, pp. 10657‚Äì10665.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
K.¬†Cao, J.¬†You, J.¬†Leskovec, Relational multi-task learning: Modeling relations
between data and tasks, arXiv preprint arXiv:2303.07666 (2023).

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.16064" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.16065" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.16065">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.16065" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.16066" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 16:43:35 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
