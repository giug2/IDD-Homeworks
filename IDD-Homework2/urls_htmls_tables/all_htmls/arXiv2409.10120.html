<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge</title>
<!--Generated on Sat Sep 14 11:53:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Generalization Misalignments Data-Centric AI PET/CT Lesion Segmentation" lang="en" name="keywords"/>
<base href="/html/2409.10120v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S1" title="In Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2" title="In Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2.SS1" title="In 2 Methods ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Challenge Design - The Data-Centric Task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2.SS2" title="In 2 Methods ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Data augmentation strategy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2.SS3" title="In 2 Methods ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Network training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2.SS4" title="In 2 Methods ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Image segmentation postprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2.SS5" title="In 2 Methods ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Dynamic ensembling and test-time augmentation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2.SS6" title="In 2 Methods ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.6 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S3" title="In Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S4" title="In Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion and conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S4.SS0.SSS1" title="In 4 Discussion and conclusion ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.0.1 </span>Acknowledgements</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
German Cancer Research Center (DKFZ) Heidelberg,
<br class="ltx_break"/>Division of Medical Image Computing, Heidelberg, Germany
</span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Medical Faculty Heidelberg, Heidelberg University, Heidelberg, Germany</span></span></span><span class="ltx_note ltx_role_institutetext" id="id3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Faculty of Mathematics and Computer Science,
<br class="ltx_break"/>Heidelberg University, Heidelberg, Germany</span></span></span><span class="ltx_note ltx_role_institutetext" id="id4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>Helmholtz Imaging, DKFZ, Heidelberg, Germany</span></span></span><span class="ltx_note ltx_role_institutetext" id="id5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">institutetext: </span>Pattern Analysis and Learning Group, Department of Radiation Oncology, Heidelberg University Hospital, Heidelberg, Germany

<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id5.1"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">email: </span>{balint.kovacs, s.xiao}@dkfz-heidelberg.de</span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">

Data-Centric Strategies for Overcoming
<br class="ltx_break"/>PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Balint Kovacs<span class="ltx_ERROR undefined" id="id1.1.id1">\orcidlink</span>0000-0002-1191-0646
</span><span class="ltx_author_notes">1122<span class="ltx_text" id="id2.2.id1">✉</span><span class="ltx_text" id="id3.3.id1">✉</span>⋆⋆</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shuhan Xiao<span class="ltx_ERROR undefined" id="id4.1.id1">\orcidlink</span>0000-0001-5397-814X
</span><span class="ltx_author_notes">1133<span class="ltx_text" id="id5.2.id1">✉</span><span class="ltx_text" id="id6.3.id1">✉</span>⋆⋆</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Maximilian Rokuss<span class="ltx_ERROR undefined" id="id7.1.id1">\orcidlink</span>0009-0004-4560-0760
</span><span class="ltx_author_notes">1133</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/>Constantin Ulrich<span class="ltx_ERROR undefined" id="id8.1.id1">\orcidlink</span>0000-0003-3002-8170
</span><span class="ltx_author_notes">1122</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fabian Isensee<span class="ltx_ERROR undefined" id="id9.1.id1">\orcidlink</span>0000-0002-3519-5886
</span><span class="ltx_author_notes">1144<span class="ltx_text ltx_font_italic" id="id10.2.id1">μ</span><span class="ltx_text ltx_font_italic" id="id11.3.id1">μ</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Klaus H. Maier-Hein<span class="ltx_ERROR undefined" id="id12.1.id1">\orcidlink</span>0000-0002-6626-2463
</span><span class="ltx_author_notes">114455<span class="ltx_text ltx_font_italic" id="id13.2.id1">μ</span><span class="ltx_text ltx_font_italic" id="id14.3.id1">μ</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id15.id1">The third autoPET challenge introduced a new data-centric task this year, shifting the focus from model development to improving metastatic lesion segmentation on PET/CT images through data quality and handling strategies. In response, we developed targeted strategies to enhance segmentation performance tailored to the characteristics of PET/CT imaging. Our approach encompasses two key elements. First, to address potential misalignments between CT and PET modalities as well as the prevalence of punctate lesions, we modified the baseline data augmentation scheme and extended it with misalignment augmentation. This adaptation aims to improve segmentation accuracy, particularly for tiny metastatic lesions. Second, to tackle the variability in image dimensions significantly affecting the prediction time, we implemented a dynamic ensembling and test-time augmentation (TTA) strategy. This method optimizes the use of ensembling and TTA within a 5-minute prediction time limit, effectively leveraging the generalization potential for both small and large images. Both of our solutions are designed to be robust across different tracers and institutional settings, offering a general, yet imaging-specific approach to the multi-tracer and multi-institutional challenges of the competition. We made the challenge repository with our modifications publicly available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MIC-DKFZ/miccai2024_autopet3_datacentric" title="">https://github.com/MIC-DKFZ/miccai2024_autopet3_datacentric</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Generalization Misalignments Data-Centric AI PET/CT Lesion Segmentation
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotetext: </span>Equal contribution</span></span></span><span class="ltx_note ltx_role_footnotetext" id="footnotex2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotetext: </span>Shared last authorship</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Accurate automated tumor lesion segmentation from whole-body PET/CT scans has become increasingly essential in oncological diagnostics, supporting tumor characterization, treatment planning, and response monitoring <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib2" title="">2</a>]</cite>. The international AutoPET competition, now in its third year, is aimed at improving this task using artificial intelligence (AI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib5" title="">5</a>]</cite>. While the general goal of the challenge remains to achieve the most accurate lesion segmentation with a strong emphasis on generalizability using a multi-institutional test set, the 2024 challenge edition introduces a new focus on cross-center and tracer generalizability. The publicly available dataset of 1014 FDG PET/CT studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib3" title="">3</a>]</cite> has been extended by 597 exams with a new PSMA tracer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib7" title="">7</a>]</cite>, alongside an extended hidden test dataset, prompting participants to develop even more robust AI solutions.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Motivated by the inherent complexity and imperfections of real-world data, a new data-centric task has been also introduced. Unlike traditional model-centric approaches, where performance gains are often sought by building larger and more complex models, this task focuses on improving data quality and handling, such as image pre- and post-processing, and data augmentation. In this case, the model architecture is fixed and cannot be modified. Data-centric AI, an emerging field, demonstrates that in many cases, enhancing the quality of the data is the most effective way to improve performance in practical machine learning applications <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib12" title="">12</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Though PET and CT images are acquired from the same machine during the same examination, misalignments between the modalities can occur due to patient movements. Involuntary organ movements can be further exaggerated by attenuation correction or imaging artifacts during the imaging process <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib10" title="">10</a>]</cite>. These misalignments can result in inconsistencies in the ground truth between image modalities and may be particularly critical when dealing with tiny metastatic lesions prominent in the dataset. Since semantic segmentation networks rely heavily on spatial information, such inconsistencies can potentially limit segmentation performance.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The addition of PSMA cases to the autoPET III training dataset has significantly increased the already high variability in geometrical image properties. The dataset includes scans with varying dimensions, ranging from smaller, regional scans (mid-femur to neck) to full-body scans (feet to head), as well as differences in image spacing, further contributing to variability. These factors lead to substantially varying prediction times between cases. To ensure that all scans, especially the larger ones, meet the 5-minute inference time limit, a fixed ensembling and test-time augmentation (TTA) strategy would require setting conservative parameters, which would significantly limit their generalization ability for smaller images.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper, we present our solutions to the challenges outlined above. To address potential misalignments between the image sequences and the prevalence of punctate lesions in the dataset, we modified and extended the data augmentation (DA) scheme of the baseline model provided by the challenge organizers, incorporating misalignment augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib9" title="">9</a>]</cite>. To fully exploit the generalization ability of ensembling and TTA for all cases with different dimensions, we implemented a dynamic prediction strategy by optimizing the extent of ensembling and the number of TTA, while still ensuring timely scan processing. These general, yet imaging-specific approaches are independent of tracer type and institutional device settings, offering a potentially robust solution for the multi-tracer, multi-institutional nature of the challenge.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Challenge Design - The Data-Centric Task</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">This work proposes solutions for the data-centric task (Category 2) of the challenge. The challenge organizers provided a framework (<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ClinicalDataScience/datacentric-challenge/tree/main" title="">https://github.com/ClinicalDataScience/datacentric-challenge/tree/main</a>) for this task, which is based on the nnU-Net  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib6" title="">6</a>]</cite> training configuration and to which no modifications are allowed.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data augmentation strategy</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">We adapt the baseline DA scheme to be more suitable for our image modalities PET and CT. We perform less aggressive and more realistic random affine transformations by reducing all amplitudes of its hyperparameters. While the baseline DA scheme adds random Gaussian smoothing, we remove this transformation to avoid blurring small lesions and to preserve fine image details. To prevent overexposure of the images leading to information loss, we also remove the contrast transforms that invert the images before performing gamma transformations and re-inverting them back after. We refer to this setting as <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">subtleDA</span>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S2.F1.1.g1" src="x1.png" width="581"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Misalignment augmentation applied to the dataset. The PET image remains unchanged, while the CT image is transformed to introduce additional slight plausible misalignments between the image modalities. The ground truth is coupled with the PET modality due to its stronger relevance for identifying metastatic lesions.
</figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.2">Further, to address potential misalignments between the CT and PET images, we extended the DA scheme with misalignment DA (<span class="ltx_text ltx_font_italic" id="S2.SS2.p2.2.1">misalDA</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#bib.bib9" title="">9</a>]</cite>. This approach has the potential advantage of improving sensitivity for punctate lesions with small voxel segmentation volumes, which was suggested, though not proven, in the original study. Given the prevalence of such lesions in our dataset, the segmentation of such punctate lesions plays a particularly crucial role. The amplitude of the transformations used to generate misalignments was sampled randomly from a uniform distribution, constrained by a maximum amplitude in both positive and negative directions. The transformation included an initial rotation with a maximum angle of <math alttext="5\text{\,}\mathrm{\SIUnitSymbolDegree}" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.3"><semantics id="S2.SS2.p2.1.m1.3a"><mrow id="S2.SS2.p2.1.m1.3.3" xref="S2.SS2.p2.1.m1.3.3.cmml"><mn id="S2.SS2.p2.1.m1.1.1.1.1.1.1" xref="S2.SS2.p2.1.m1.1.1.1.1.1.1.cmml">5</mn><mtext id="S2.SS2.p2.1.m1.2.2.2.2.2.2" xref="S2.SS2.p2.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS2.p2.1.m1.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS2.p2.1.m1.3.3.3.3.3.3.cmml">°</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.3b"><apply id="S2.SS2.p2.1.m1.3.3.cmml" xref="S2.SS2.p2.1.m1.3.3"><csymbol cd="latexml" id="S2.SS2.p2.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS2.p2.1.m1.2.2.2.2.2.2">times</csymbol><cn id="S2.SS2.p2.1.m1.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS2.p2.1.m1.1.1.1.1.1.1">5</cn><csymbol cd="latexml" id="S2.SS2.p2.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS2.p2.1.m1.3.3.3.3.3.3">degree</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.3c">5\text{\,}\mathrm{\SIUnitSymbolDegree}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.3d">start_ARG 5 end_ARG start_ARG times end_ARG start_ARG ° end_ARG</annotation></semantics></math>, followed by translations with maximum voxel shifts of [2, 2, 0] in the x, y, and z directions, respectively. Both transformations were applied with <math alttext="10\text{\,}\mathrm{\char 37\relax}" class="ltx_Math" display="inline" id="S2.SS2.p2.2.m2.3"><semantics id="S2.SS2.p2.2.m2.3a"><mrow id="S2.SS2.p2.2.m2.3.3" xref="S2.SS2.p2.2.m2.3.3.cmml"><mn id="S2.SS2.p2.2.m2.1.1.1.1.1.1" xref="S2.SS2.p2.2.m2.1.1.1.1.1.1.cmml">10</mn><mtext id="S2.SS2.p2.2.m2.2.2.2.2.2.2" xref="S2.SS2.p2.2.m2.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS2.p2.2.m2.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS2.p2.2.m2.3.3.3.3.3.3.cmml">%</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.3b"><apply id="S2.SS2.p2.2.m2.3.3.cmml" xref="S2.SS2.p2.2.m2.3.3"><csymbol cd="latexml" id="S2.SS2.p2.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS2.p2.2.m2.2.2.2.2.2.2">times</csymbol><cn id="S2.SS2.p2.2.m2.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS2.p2.2.m2.1.1.1.1.1.1">10</cn><csymbol cd="latexml" id="S2.SS2.p2.2.m2.3.3.3.3.3.3.cmml" xref="S2.SS2.p2.2.m2.3.3.3.3.3.3">percent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.3c">10\text{\,}\mathrm{\char 37\relax}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.2.m2.3d">start_ARG 10 end_ARG start_ARG times end_ARG start_ARG % end_ARG</annotation></semantics></math> probability. Since the PET modality contains the most important information regarding metastatic lesions and correlates more closely with the ground truth than the CT modality, only the CT images were displaced, while the PET and ground truth images remained unchanged after the transformation (see <a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S2.F1" title="In 2.2 Data augmentation strategy ‣ 2 Methods ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_tag">figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">We hypothesize that the large prevalence of small metastatic lesions can be effectively addressed by preserving fine image details using the subtleDA scheme and meanwhile increasing the sensitivity to punctate lesions using misalDA.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">To achieve maximum variability in the training data, we opt for online data augmentation rather than offline augmentation, where pre-computed augmented images are saved.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Network training</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">We perform 5-fold cross-validation and train 3D U-Net models on the dataset according to the fixed architecture and training scheme baseline for 250k training steps. We train the network with both the baseline and subtleDA scheme with and without misalDA (see section 2.2.).</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Image segmentation postprocessing</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">For the postprocessing step following our predictions, we mask the predicted segmentation regions in areas where the standard uptake value (SUV) in the PET images was lower than 1.0 to reduce false positive volumes, similarly to the baseline framework.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Dynamic ensembling and test-time augmentation</h3>
<div class="ltx_para" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.4">Due to the time limit of <math alttext="5\text{\,}\min" class="ltx_Math" display="inline" id="S2.SS5.p1.1.m1.3"><semantics id="S2.SS5.p1.1.m1.3a"><mrow id="S2.SS5.p1.1.m1.3.3" xref="S2.SS5.p1.1.m1.3.3.cmml"><mn id="S2.SS5.p1.1.m1.1.1.1.1.1.1" xref="S2.SS5.p1.1.m1.1.1.1.1.1.1.cmml">5</mn><mtext id="S2.SS5.p1.1.m1.2.2.2.2.2.2" xref="S2.SS5.p1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi id="S2.SS5.p1.1.m1.3.3.3.3.3.3" xref="S2.SS5.p1.1.m1.3.3.3.3.3.3.cmml">min</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p1.1.m1.3b"><apply id="S2.SS5.p1.1.m1.3.3.cmml" xref="S2.SS5.p1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS5.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS5.p1.1.m1.2.2.2.2.2.2">times</csymbol><cn id="S2.SS5.p1.1.m1.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS5.p1.1.m1.1.1.1.1.1.1">5</cn><min id="S2.SS5.p1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS5.p1.1.m1.3.3.3.3.3.3"></min></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p1.1.m1.3c">5\text{\,}\min</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p1.1.m1.3d">start_ARG 5 end_ARG start_ARG times end_ARG start_ARG roman_min end_ARG</annotation></semantics></math> per case set by the challenge, we constrain the extent of model ensembling and the number of TTAs that can be applied. In many cases, a full 5-fold ensembling with multiple TTAs is feasible within this time limit. However, for samples that require resampling or have large image sizes, the maximum number of ensembled models is reduced to 2-3, often without any TTA. To stay within the time limit while maintaining the benefits of both ensembling and TTA, we implemented a case-specific dynamic ensembling approach in addition to the dynamic TTA approach in the baseline framework. Specifically, we set a maximum time of <math alttext="25\text{\,}\sec" class="ltx_Math" display="inline" id="S2.SS5.p1.2.m2.3"><semantics id="S2.SS5.p1.2.m2.3a"><mrow id="S2.SS5.p1.2.m2.3.3" xref="S2.SS5.p1.2.m2.3.3.cmml"><mn id="S2.SS5.p1.2.m2.1.1.1.1.1.1" xref="S2.SS5.p1.2.m2.1.1.1.1.1.1.cmml">25</mn><mtext id="S2.SS5.p1.2.m2.2.2.2.2.2.2" xref="S2.SS5.p1.2.m2.2.2.2.2.2.2.cmml"> </mtext><mi id="S2.SS5.p1.2.m2.3.3.3.3.3.3" xref="S2.SS5.p1.2.m2.3.3.3.3.3.3.cmml">sec</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p1.2.m2.3b"><apply id="S2.SS5.p1.2.m2.3.3.cmml" xref="S2.SS5.p1.2.m2.3.3"><csymbol cd="latexml" id="S2.SS5.p1.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS5.p1.2.m2.2.2.2.2.2.2">times</csymbol><cn id="S2.SS5.p1.2.m2.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS5.p1.2.m2.1.1.1.1.1.1">25</cn><sec id="S2.SS5.p1.2.m2.3.3.3.3.3.3.cmml" xref="S2.SS5.p1.2.m2.3.3.3.3.3.3"></sec></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p1.2.m2.3c">25\text{\,}\sec</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p1.2.m2.3d">start_ARG 25 end_ARG start_ARG times end_ARG start_ARG roman_sec end_ARG</annotation></semantics></math> per model for TTA and <math alttext="170\text{\,}\sec" class="ltx_Math" display="inline" id="S2.SS5.p1.3.m3.3"><semantics id="S2.SS5.p1.3.m3.3a"><mrow id="S2.SS5.p1.3.m3.3.3" xref="S2.SS5.p1.3.m3.3.3.cmml"><mn id="S2.SS5.p1.3.m3.1.1.1.1.1.1" xref="S2.SS5.p1.3.m3.1.1.1.1.1.1.cmml">170</mn><mtext id="S2.SS5.p1.3.m3.2.2.2.2.2.2" xref="S2.SS5.p1.3.m3.2.2.2.2.2.2.cmml"> </mtext><mi id="S2.SS5.p1.3.m3.3.3.3.3.3.3" xref="S2.SS5.p1.3.m3.3.3.3.3.3.3.cmml">sec</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p1.3.m3.3b"><apply id="S2.SS5.p1.3.m3.3.3.cmml" xref="S2.SS5.p1.3.m3.3.3"><csymbol cd="latexml" id="S2.SS5.p1.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS5.p1.3.m3.2.2.2.2.2.2">times</csymbol><cn id="S2.SS5.p1.3.m3.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS5.p1.3.m3.1.1.1.1.1.1">170</cn><sec id="S2.SS5.p1.3.m3.3.3.3.3.3.3.cmml" xref="S2.SS5.p1.3.m3.3.3.3.3.3.3"></sec></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p1.3.m3.3c">170\text{\,}\sec</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p1.3.m3.3d">start_ARG 170 end_ARG start_ARG times end_ARG start_ARG roman_sec end_ARG</annotation></semantics></math> for the whole ensembling including TTA. In the dynamic TTA approach, the initial prediction by each model, the number of TTAs that can be applied within the given time constraint (<math alttext="25\text{\,}\sec" class="ltx_Math" display="inline" id="S2.SS5.p1.4.m4.3"><semantics id="S2.SS5.p1.4.m4.3a"><mrow id="S2.SS5.p1.4.m4.3.3" xref="S2.SS5.p1.4.m4.3.3.cmml"><mn id="S2.SS5.p1.4.m4.1.1.1.1.1.1" xref="S2.SS5.p1.4.m4.1.1.1.1.1.1.cmml">25</mn><mtext id="S2.SS5.p1.4.m4.2.2.2.2.2.2" xref="S2.SS5.p1.4.m4.2.2.2.2.2.2.cmml"> </mtext><mi id="S2.SS5.p1.4.m4.3.3.3.3.3.3" xref="S2.SS5.p1.4.m4.3.3.3.3.3.3.cmml">sec</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p1.4.m4.3b"><apply id="S2.SS5.p1.4.m4.3.3.cmml" xref="S2.SS5.p1.4.m4.3.3"><csymbol cd="latexml" id="S2.SS5.p1.4.m4.2.2.2.2.2.2.cmml" xref="S2.SS5.p1.4.m4.2.2.2.2.2.2">times</csymbol><cn id="S2.SS5.p1.4.m4.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS5.p1.4.m4.1.1.1.1.1.1">25</cn><sec id="S2.SS5.p1.4.m4.3.3.3.3.3.3.cmml" xref="S2.SS5.p1.4.m4.3.3.3.3.3.3"></sec></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p1.4.m4.3c">25\text{\,}\sec</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p1.4.m4.3d">start_ARG 25 end_ARG start_ARG times end_ARG start_ARG roman_sec end_ARG</annotation></semantics></math>) is determined by the time of the first inference pass, but not more than a predefined maximum number of TTA of 2. Similarly, we approximate the maximum number of models that can be ensembled within the remaining ensemble time limit based on the time it takes for the first model including the possible TTAs to finish its predictions.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.6 </span>Evaluation</h3>
<div class="ltx_para" id="S2.SS6.p1">
<p class="ltx_p" id="S2.SS6.p1.6">The mean Dice score of the segmented lesions (<math alttext="50\text{\,}\mathrm{\char 37\relax}" class="ltx_Math" display="inline" id="S2.SS6.p1.1.m1.3"><semantics id="S2.SS6.p1.1.m1.3a"><mrow id="S2.SS6.p1.1.m1.3.3" xref="S2.SS6.p1.1.m1.3.3.cmml"><mn id="S2.SS6.p1.1.m1.1.1.1.1.1.1" xref="S2.SS6.p1.1.m1.1.1.1.1.1.1.cmml">50</mn><mtext id="S2.SS6.p1.1.m1.2.2.2.2.2.2" xref="S2.SS6.p1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS6.p1.1.m1.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS6.p1.1.m1.3.3.3.3.3.3.cmml">%</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.1.m1.3b"><apply id="S2.SS6.p1.1.m1.3.3.cmml" xref="S2.SS6.p1.1.m1.3.3"><csymbol cd="latexml" id="S2.SS6.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS6.p1.1.m1.2.2.2.2.2.2">times</csymbol><cn id="S2.SS6.p1.1.m1.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS6.p1.1.m1.1.1.1.1.1.1">50</cn><csymbol cd="latexml" id="S2.SS6.p1.1.m1.3.3.3.3.3.3.cmml" xref="S2.SS6.p1.1.m1.3.3.3.3.3.3">percent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.1.m1.3c">50\text{\,}\mathrm{\char 37\relax}</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.1.m1.3d">start_ARG 50 end_ARG start_ARG times end_ARG start_ARG % end_ARG</annotation></semantics></math> contribution), false positive volume (FPvol) with <math alttext="25\text{\,}\mathrm{\char 37\relax}" class="ltx_Math" display="inline" id="S2.SS6.p1.2.m2.3"><semantics id="S2.SS6.p1.2.m2.3a"><mrow id="S2.SS6.p1.2.m2.3.3" xref="S2.SS6.p1.2.m2.3.3.cmml"><mn id="S2.SS6.p1.2.m2.1.1.1.1.1.1" xref="S2.SS6.p1.2.m2.1.1.1.1.1.1.cmml">25</mn><mtext id="S2.SS6.p1.2.m2.2.2.2.2.2.2" xref="S2.SS6.p1.2.m2.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS6.p1.2.m2.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS6.p1.2.m2.3.3.3.3.3.3.cmml">%</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.2.m2.3b"><apply id="S2.SS6.p1.2.m2.3.3.cmml" xref="S2.SS6.p1.2.m2.3.3"><csymbol cd="latexml" id="S2.SS6.p1.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS6.p1.2.m2.2.2.2.2.2.2">times</csymbol><cn id="S2.SS6.p1.2.m2.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS6.p1.2.m2.1.1.1.1.1.1">25</cn><csymbol cd="latexml" id="S2.SS6.p1.2.m2.3.3.3.3.3.3.cmml" xref="S2.SS6.p1.2.m2.3.3.3.3.3.3">percent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.2.m2.3c">25\text{\,}\mathrm{\char 37\relax}</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.2.m2.3d">start_ARG 25 end_ARG start_ARG times end_ARG start_ARG % end_ARG</annotation></semantics></math> contribution, and false negative volume (FNvol) with <math alttext="25\text{\,}\mathrm{\char 37\relax}" class="ltx_Math" display="inline" id="S2.SS6.p1.3.m3.3"><semantics id="S2.SS6.p1.3.m3.3a"><mrow id="S2.SS6.p1.3.m3.3.3" xref="S2.SS6.p1.3.m3.3.3.cmml"><mn id="S2.SS6.p1.3.m3.1.1.1.1.1.1" xref="S2.SS6.p1.3.m3.1.1.1.1.1.1.cmml">25</mn><mtext id="S2.SS6.p1.3.m3.2.2.2.2.2.2" xref="S2.SS6.p1.3.m3.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS6.p1.3.m3.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS6.p1.3.m3.3.3.3.3.3.3.cmml">%</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.3.m3.3b"><apply id="S2.SS6.p1.3.m3.3.3.cmml" xref="S2.SS6.p1.3.m3.3.3"><csymbol cd="latexml" id="S2.SS6.p1.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS6.p1.3.m3.2.2.2.2.2.2">times</csymbol><cn id="S2.SS6.p1.3.m3.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS6.p1.3.m3.1.1.1.1.1.1">25</cn><csymbol cd="latexml" id="S2.SS6.p1.3.m3.3.3.3.3.3.3.cmml" xref="S2.SS6.p1.3.m3.3.3.3.3.3.3">percent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.3.m3.3c">25\text{\,}\mathrm{\char 37\relax}</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.3.m3.3d">start_ARG 25 end_ARG start_ARG times end_ARG start_ARG % end_ARG</annotation></semantics></math> contribution will be used as metrics in the final evaluation of the challenge. Given that the test set consists of <math alttext="50\text{\,}\mathrm{\char 37\relax}" class="ltx_Math" display="inline" id="S2.SS6.p1.4.m4.3"><semantics id="S2.SS6.p1.4.m4.3a"><mrow id="S2.SS6.p1.4.m4.3.3" xref="S2.SS6.p1.4.m4.3.3.cmml"><mn id="S2.SS6.p1.4.m4.1.1.1.1.1.1" xref="S2.SS6.p1.4.m4.1.1.1.1.1.1.cmml">50</mn><mtext id="S2.SS6.p1.4.m4.2.2.2.2.2.2" xref="S2.SS6.p1.4.m4.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS6.p1.4.m4.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS6.p1.4.m4.3.3.3.3.3.3.cmml">%</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.4.m4.3b"><apply id="S2.SS6.p1.4.m4.3.3.cmml" xref="S2.SS6.p1.4.m4.3.3"><csymbol cd="latexml" id="S2.SS6.p1.4.m4.2.2.2.2.2.2.cmml" xref="S2.SS6.p1.4.m4.2.2.2.2.2.2">times</csymbol><cn id="S2.SS6.p1.4.m4.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS6.p1.4.m4.1.1.1.1.1.1">50</cn><csymbol cd="latexml" id="S2.SS6.p1.4.m4.3.3.3.3.3.3.cmml" xref="S2.SS6.p1.4.m4.3.3.3.3.3.3">percent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.4.m4.3c">50\text{\,}\mathrm{\char 37\relax}</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.4.m4.3d">start_ARG 50 end_ARG start_ARG times end_ARG start_ARG % end_ARG</annotation></semantics></math> FDG and <math alttext="50\text{\,}\mathrm{\char 37\relax}" class="ltx_Math" display="inline" id="S2.SS6.p1.5.m5.3"><semantics id="S2.SS6.p1.5.m5.3a"><mrow id="S2.SS6.p1.5.m5.3.3" xref="S2.SS6.p1.5.m5.3.3.cmml"><mn id="S2.SS6.p1.5.m5.1.1.1.1.1.1" xref="S2.SS6.p1.5.m5.1.1.1.1.1.1.cmml">50</mn><mtext id="S2.SS6.p1.5.m5.2.2.2.2.2.2" xref="S2.SS6.p1.5.m5.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS6.p1.5.m5.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS6.p1.5.m5.3.3.3.3.3.3.cmml">%</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.5.m5.3b"><apply id="S2.SS6.p1.5.m5.3.3.cmml" xref="S2.SS6.p1.5.m5.3.3"><csymbol cd="latexml" id="S2.SS6.p1.5.m5.2.2.2.2.2.2.cmml" xref="S2.SS6.p1.5.m5.2.2.2.2.2.2">times</csymbol><cn id="S2.SS6.p1.5.m5.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS6.p1.5.m5.1.1.1.1.1.1">50</cn><csymbol cd="latexml" id="S2.SS6.p1.5.m5.3.3.3.3.3.3.cmml" xref="S2.SS6.p1.5.m5.3.3.3.3.3.3">percent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.5.m5.3c">50\text{\,}\mathrm{\char 37\relax}</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.5.m5.3d">start_ARG 50 end_ARG start_ARG times end_ARG start_ARG % end_ARG</annotation></semantics></math> PSMA exams, we additionally focus on the balanced (bal.) Dice score, weighted by the number of exams from each tracer, to simulate the tracer distribution of <math alttext="50\text{\,}\mathrm{\char 37\relax}" class="ltx_Math" display="inline" id="S2.SS6.p1.6.m6.3"><semantics id="S2.SS6.p1.6.m6.3a"><mrow id="S2.SS6.p1.6.m6.3.3" xref="S2.SS6.p1.6.m6.3.3.cmml"><mn id="S2.SS6.p1.6.m6.1.1.1.1.1.1" xref="S2.SS6.p1.6.m6.1.1.1.1.1.1.cmml">50</mn><mtext id="S2.SS6.p1.6.m6.2.2.2.2.2.2" xref="S2.SS6.p1.6.m6.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S2.SS6.p1.6.m6.3.3.3.3.3.3" mathvariant="normal" xref="S2.SS6.p1.6.m6.3.3.3.3.3.3.cmml">%</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS6.p1.6.m6.3b"><apply id="S2.SS6.p1.6.m6.3.3.cmml" xref="S2.SS6.p1.6.m6.3.3"><csymbol cd="latexml" id="S2.SS6.p1.6.m6.2.2.2.2.2.2.cmml" xref="S2.SS6.p1.6.m6.2.2.2.2.2.2">times</csymbol><cn id="S2.SS6.p1.6.m6.1.1.1.1.1.1.cmml" type="integer" xref="S2.SS6.p1.6.m6.1.1.1.1.1.1">50</cn><csymbol cd="latexml" id="S2.SS6.p1.6.m6.3.3.3.3.3.3.cmml" xref="S2.SS6.p1.6.m6.3.3.3.3.3.3">percent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS6.p1.6.m6.3c">50\text{\,}\mathrm{\char 37\relax}</annotation><annotation encoding="application/x-llamapun" id="S2.SS6.p1.6.m6.3d">start_ARG 50 end_ARG start_ARG times end_ARG start_ARG % end_ARG</annotation></semantics></math> of the data in the hidden test set. Since no separate development test set is available in the challenge, we are unable to fully validate the effectiveness of the dynamic ensembling and TTA strategy. Therefore, we evaluate all of our trained models using all mirroring transformations as part of the TTA on our validation folds.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We systematically summarize our results in <a class="ltx_ref" href="https://arxiv.org/html/2409.10120v1#S3.T1" title="In 3 Results ‣ Data-Centric Strategies for Overcoming PET/CT Heterogeneity: Insights from the AutoPET III Lesion Segmentation Challenge"><span class="ltx_text ltx_ref_tag">table</span> <span class="ltx_text ltx_ref_tag">1</span></a>. Using the subtleDA scheme alone or extending the baseline DA scheme with misalDA does not lead to an improvement with respect to the mean or balanced Dice scores. However, combining the subtle DA scheme with misalDA resulted in the best Dice score with an improvement of 0.81 dice points over the baseline and a decrease of average FPvol by about <math alttext="6\text{\,}\mathrm{mL}" class="ltx_Math" display="inline" id="S3.p1.1.m1.3"><semantics id="S3.p1.1.m1.3a"><mrow id="S3.p1.1.m1.3.3" xref="S3.p1.1.m1.3.3.cmml"><mn id="S3.p1.1.m1.1.1.1.1.1.1" xref="S3.p1.1.m1.1.1.1.1.1.1.cmml">6</mn><mtext id="S3.p1.1.m1.2.2.2.2.2.2" xref="S3.p1.1.m1.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S3.p1.1.m1.3.3.3.3.3.3" xref="S3.p1.1.m1.3.3.3.3.3.3.cmml">mL</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.3b"><apply id="S3.p1.1.m1.3.3.cmml" xref="S3.p1.1.m1.3.3"><csymbol cd="latexml" id="S3.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.p1.1.m1.2.2.2.2.2.2">times</csymbol><cn id="S3.p1.1.m1.1.1.1.1.1.1.cmml" type="integer" xref="S3.p1.1.m1.1.1.1.1.1.1">6</cn><csymbol cd="latexml" id="S3.p1.1.m1.3.3.3.3.3.3.cmml" xref="S3.p1.1.m1.3.3.3.3.3.3">milliliter</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.3c">6\text{\,}\mathrm{mL}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.3d">start_ARG 6 end_ARG start_ARG times end_ARG start_ARG roman_mL end_ARG</annotation></semantics></math>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Five-fold cross-validation results for our data-centric solutions showing the mean Dice score as well as the FP and FN volume in <math alttext="\mathrm{mL}" class="ltx_Math" display="inline" id="S3.T1.2.2.m1.1"><semantics id="S3.T1.2.2.m1.1b"><mi class="ltx_unit" id="S3.T1.2.2.m1.1.1" xref="S3.T1.2.2.m1.1.1.cmml">mL</mi><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.m1.1c"><csymbol cd="latexml" id="S3.T1.2.2.m1.1.1.cmml" xref="S3.T1.2.2.m1.1.1">milliliter</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.m1.1d">\mathrm{mL}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.m1.1e">roman_mL</annotation></semantics></math>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.5.5">
<tr class="ltx_tr" id="S3.T1.3.3.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.3.3.1.2" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.3.3.1.2.1">
<span class="ltx_p" id="S3.T1.3.3.1.2.1.1" style="width:151.8pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_center ltx_align_top" colspan="4" id="S3.T1.3.3.1.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">Dice<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.3.3.1.1.m1.1"><semantics id="S3.T1.3.3.1.1.m1.1a"><mo id="S3.T1.3.3.1.1.m1.1.1" stretchy="false" xref="S3.T1.3.3.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.1.m1.1b"><ci id="S3.T1.3.3.1.1.m1.1.1.cmml" xref="S3.T1.3.3.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.3.3.1.3" style="padding-top:1.25pt;padding-bottom:1.25pt;"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.3.3.1.4" style="padding-top:1.25pt;padding-bottom:1.25pt;"></td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.3.3" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.3.3.1">
<span class="ltx_p" id="S3.T1.5.5.3.3.1.1" style="width:151.8pt;">DA scheme</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.3.4" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.3.4.1">
<span class="ltx_p" id="S3.T1.5.5.3.4.1.1" style="width:39.0pt;">FDG</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.3.5" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.3.5.1">
<span class="ltx_p" id="S3.T1.5.5.3.5.1.1" style="width:39.0pt;">PSMA</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.3.6" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.3.6.1">
<span class="ltx_p" id="S3.T1.5.5.3.6.1.1" style="width:39.0pt;">mean</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.3.7" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.3.7.1">
<span class="ltx_p" id="S3.T1.5.5.3.7.1.1" style="width:39.0pt;">bal.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.4.4.2.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.4.4.2.1.1">
<span class="ltx_p" id="S3.T1.4.4.2.1.1.1" style="width:39.0pt;">FPvol<math alttext="\downarrow" class="ltx_centering" display="inline" id="S3.T1.4.4.2.1.1.1.m1.1"><semantics id="S3.T1.4.4.2.1.1.1.m1.1a"><mo id="S3.T1.4.4.2.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.4.4.2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.2.1.1.1.m1.1b"><ci id="S3.T1.4.4.2.1.1.1.m1.1.1.cmml" xref="S3.T1.4.4.2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.2.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.2.1.1.1.m1.1d">↓</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.3.2" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.3.2.1">
<span class="ltx_p" id="S3.T1.5.5.3.2.1.1" style="width:39.0pt;">FNvol<math alttext="\downarrow" class="ltx_centering" display="inline" id="S3.T1.5.5.3.2.1.1.m1.1"><semantics id="S3.T1.5.5.3.2.1.1.m1.1a"><mo id="S3.T1.5.5.3.2.1.1.m1.1.1" stretchy="false" xref="S3.T1.5.5.3.2.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.3.2.1.1.m1.1b"><ci id="S3.T1.5.5.3.2.1.1.m1.1.1.cmml" xref="S3.T1.5.5.3.2.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.3.2.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.3.2.1.1.m1.1d">↓</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.4.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.4.1.1">
<span class="ltx_p" id="S3.T1.5.5.4.1.1.1" style="width:151.8pt;">baseline</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.4.2" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.4.2.1">
<span class="ltx_p" id="S3.T1.5.5.4.2.1.1" style="width:39.0pt;">57.64</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.4.3" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.4.3.1">
<span class="ltx_p" id="S3.T1.5.5.4.3.1.1" style="width:39.0pt;">49.05</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.4.4" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.4.4.1">
<span class="ltx_p" id="S3.T1.5.5.4.4.1.1" style="width:39.0pt;">53.27</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.4.5" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.4.5.1">
<span class="ltx_p" id="S3.T1.5.5.4.5.1.1" style="width:39.0pt;">52.23</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.4.6" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.4.6.1">
<span class="ltx_p" id="S3.T1.5.5.4.6.1.1" style="width:39.0pt;">6.09</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T1.5.5.4.7" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.4.7.1">
<span class="ltx_p" id="S3.T1.5.5.4.7.1.1" style="width:39.0pt;">30.90</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.5.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.5.1.1">
<span class="ltx_p" id="S3.T1.5.5.5.1.1.1" style="width:151.8pt;">baseline+misalDA</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.5.2" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.5.2.1">
<span class="ltx_p" id="S3.T1.5.5.5.2.1.1" style="width:39.0pt;">54.09</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.5.3" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.5.3.1">
<span class="ltx_p" id="S3.T1.5.5.5.3.1.1" style="width:39.0pt;">47.64</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.5.4" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.5.4.1">
<span class="ltx_p" id="S3.T1.5.5.5.4.1.1" style="width:39.0pt;">50.76</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.5.5" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.5.5.1">
<span class="ltx_p" id="S3.T1.5.5.5.5.1.1" style="width:39.0pt;">50.03</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.5.6" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.5.6.1">
<span class="ltx_p" id="S3.T1.5.5.5.6.1.1" style="width:39.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.5.5.5.6.1.1.1">5.69</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.5.7" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.5.7.1">
<span class="ltx_p" id="S3.T1.5.5.5.7.1.1" style="width:39.0pt;">33.37</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.6.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.6.1.1">
<span class="ltx_p" id="S3.T1.5.5.6.1.1.1" style="width:151.8pt;">subtleDA</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.6.2" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.6.2.1">
<span class="ltx_p" id="S3.T1.5.5.6.2.1.1" style="width:39.0pt;">55.26</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.6.3" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.6.3.1">
<span class="ltx_p" id="S3.T1.5.5.6.3.1.1" style="width:39.0pt;">47.65</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.6.4" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.6.4.1">
<span class="ltx_p" id="S3.T1.5.5.6.4.1.1" style="width:39.0pt;">51.36</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.6.5" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.6.5.1">
<span class="ltx_p" id="S3.T1.5.5.6.5.1.1" style="width:39.0pt;">50.47</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.6.6" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.6.6.1">
<span class="ltx_p" id="S3.T1.5.5.6.6.1.1" style="width:39.0pt;">6.74</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.6.7" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.6.7.1">
<span class="ltx_p" id="S3.T1.5.5.6.7.1.1" style="width:39.0pt;">29.82</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.7.1" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.7.1.1">
<span class="ltx_p" id="S3.T1.5.5.7.1.1.1" style="width:151.8pt;">subtleDA+misalDA</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.7.2" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.7.2.1">
<span class="ltx_p" id="S3.T1.5.5.7.2.1.1" style="width:39.0pt;">57.50</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.7.3" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.7.3.1">
<span class="ltx_p" id="S3.T1.5.5.7.3.1.1" style="width:39.0pt;">50.92</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.7.4" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.7.4.1">
<span class="ltx_p" id="S3.T1.5.5.7.4.1.1" style="width:39.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.5.5.7.4.1.1.1">54.08</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.7.5" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.7.5.1">
<span class="ltx_p" id="S3.T1.5.5.7.5.1.1" style="width:39.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.5.5.7.5.1.1.1">53.36</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.7.6" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.7.6.1">
<span class="ltx_p" id="S3.T1.5.5.7.6.1.1" style="width:39.0pt;">8.37</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="S3.T1.5.5.7.7" style="padding-top:1.25pt;padding-bottom:1.25pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.T1.5.5.7.7.1">
<span class="ltx_p" id="S3.T1.5.5.7.7.1.1" style="width:39.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.5.5.7.7.1.1.1">24.75</span></span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Considering the distribution shift among the public development set and hidden test set, our contribution to the challenge aimed to leverage the potential of heterogeneity in PET/CT imaging to provide robust predictions accounting for multi-modal misalignments and geometrical image properties.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">As no separate validation set is available, the true impact of our dynamic ensembling and TTA strategy will only be revealed once the results from the hidden challenge test set are made public.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Removing transformations from the baseline DA scheme that could potentially eliminate the detection of punctate metastatic lesions and meanwhile extending it with misalignment augmentation led us to the settings we used for our final solution. This result indicates the success of our strategy to be sensitive for segmenting tiny metastatic lesions, but its confirmation needs further detailed analysis. The decrease in performance for the baseline DA scheme with misalDA highlights the importance of the transformation combination to leverage their full synergies.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">Overall, our approach demonstrates the importance of data augmentation to improve segmentation accuracy, though further analysis is needed to fully validate these findings.</p>
</div>
<div class="ltx_para" id="S4.p5">
<span class="ltx_ERROR undefined" id="S4.p5.1">{credits}</span>
</div>
<section class="ltx_subsubsection" id="S4.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.0.1 </span>Acknowledgements</h4>
<div class="ltx_para" id="S4.SS0.SSS1.p1">
<p class="ltx_p" id="S4.SS0.SSS1.p1.1">Part of this work was funded by Helmholtz Imaging (HI), a platform of the Helmholtz Incubator on Information and Data Science.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Alessio, A.M., Kinahan, P.E., Cheng, P.M., Vesselle, H., Karp, J.S.: PET/CT scanner instrumentation, challenges, and solutions. Radiologic Clinics <span class="ltx_text ltx_font_bold" id="bib.bib1.1.1">42</span>(6), 1017–1032 (2004). https://doi.org/doi:10.1016/j.rcl.2004.08.001

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Foster, B., Bagci, U., Mansoor, A., Xu, Z., Mollura, D.J.: A review on segmentation of positron emission tomography images. Computers in biology and medicine <span class="ltx_text ltx_font_bold" id="bib.bib2.1.1">50</span>, 76–96 (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Gatidis, S., Kuestner, T.: A whole-body fdg-pet/ct dataset with manually annotated tumor lesions (fdg-pet-ct-lesions). <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.7937/GKR0-XV29" title="">https://doi.org/10.7937/GKR0-XV29</a> (2022), the Cancer Imaging Archive

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Hunter, C.R., Klein, R., Beanlands, R.S., deKemp, R.A.: Patient motion effects on the quantification of regional myocardial blood flow with dynamic PET imaging. Medical physics <span class="ltx_text ltx_font_bold" id="bib.bib4.1.1">43</span>(4), 1829–1840 (2016). https://doi.org/DOI: 10.1118/1.4943565

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Ingrisch, M., Dexl, J., Jeblick, K., Cyran, C., Gatidis, S., Kuestner, T.: Automated Lesion Segmentation in Whole-Body PET/CT - Multitracer Multicenter generalization (Apr 2024). https://doi.org/10.5281/zenodo.10990932

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Isensee, F., Jaeger, P.F., Kohl, S.A., Petersen, J., Maier-Hein, K.H.: nnu-net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods <span class="ltx_text ltx_font_bold" id="bib.bib6.1.1">18</span>(2), 203–211 (2021). https://doi.org/https://doi.org/10.1038/s41592-020-01008-z

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Jeblick, K., et al.: A whole-body psma-pet/ct dataset with manually annotated tumor lesions (psma-pet-ct-lesions). <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.7937/r7ep-3x37" title="">https://doi.org/10.7937/r7ep-3x37</a> (2024), the Cancer Imaging Archive

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Kaji, T., Osanai, K., Takahashi, A., Kinoshita, A., Satoh, D., Nakata, T., Tamaki, N.: Improvement of motion artifacts using dynamic whole-body 18F-FDG PET/CT imaging. Japanese Journal of Radiology <span class="ltx_text ltx_font_bold" id="bib.bib8.1.1">42</span>(4), 374–381 (2024). https://doi.org/https://doi.org/10.1007/s11604-023-01513-z

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Kovacs, B., Netzer, N., Baumgartner, M., Schrader, A., Isensee, F., Weißer, C., Wolf, I., Görtz, M., Jaeger, P.F., Schütz, V., et al.: Addressing image misalignments in multi-parametric prostate MRI for enhanced computer-aided diagnosis of prostate cancer. Scientific Reports <span class="ltx_text ltx_font_bold" id="bib.bib9.1.1">13</span>(1), 19805 (2023). https://doi.org/https://doi.org/10.1038/s41598-023-46747-z

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Lodge, M.A., Mhlanga, J.C., Cho, S.Y., Wahl, R.L.: Effect of patient arm motion in whole-body PET/CT. Journal of Nuclear Medicine <span class="ltx_text ltx_font_bold" id="bib.bib10.1.1">52</span>(12), 1891–1897 (2011). https://doi.org/10.2967/jnumed.111.093583

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Singh, P.: Systematic review of data-centric approaches in artificial intelligence and machine learning. Data Science and Management <span class="ltx_text ltx_font_bold" id="bib.bib11.1.1">6</span>(3), 144–157 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Zha, D., Bhat, Z.P., Lai, K.H., Yang, F., Jiang, Z., Zhong, S., Hu, X.: Data-centric artificial intelligence: A survey. arXiv preprint arXiv:2303.10158 (2023)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Sep 14 11:53:04 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
