<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds</title>
<!--Generated on Fri Sep 13 21:52:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.09213v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S1" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S2" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.SS1" title="In III Methodology ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Caption Augmentation for ReCLAP</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.SS2" title="In III Methodology ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Prompt Augmentation for ZSAC</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S4" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Setup</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S5" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S6" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Result Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S7" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Hyper-parameter Tuning</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S8" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VIII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S9" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IX </span><span class="ltx_text ltx_font_smallcaps">Limitations and Future Work</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document"> <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="28" id="id1.g1" src="extracted/5852114/reclap.png" width="28"/> ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sreyan Ghosh<sup class="ltx_sup" id="id10.9.id1"><span class="ltx_text ltx_font_italic" id="id10.9.id1.1">♠</span></sup>  Sonal Kumar<math alttext="{}^{\spadesuit\vardiamondsuit}" class="ltx_Math" display="inline" id="id3.2.m2.1"><semantics id="id3.2.m2.1a"><msup id="id3.2.m2.1.1" xref="id3.2.m2.1.1.cmml"><mi id="id3.2.m2.1.1a" xref="id3.2.m2.1.1.cmml"></mi><mrow id="id3.2.m2.1.1.1" xref="id3.2.m2.1.1.1.cmml"><mi id="id3.2.m2.1.1.1.2" mathvariant="normal" xref="id3.2.m2.1.1.1.2.cmml">♠</mi><mo id="id3.2.m2.1.1.1.1" xref="id3.2.m2.1.1.1.1.cmml">⁢</mo><merror class="ltx_ERROR undefined undefined" id="id3.2.m2.1.1.1.3" xref="id3.2.m2.1.1.1.3b.cmml"><mtext id="id3.2.m2.1.1.1.3a" xref="id3.2.m2.1.1.1.3b.cmml">\vardiamondsuit</mtext></merror></mrow></msup><annotation-xml encoding="MathML-Content" id="id3.2.m2.1b"><apply id="id3.2.m2.1.1.cmml" xref="id3.2.m2.1.1"><apply id="id3.2.m2.1.1.1.cmml" xref="id3.2.m2.1.1.1"><times id="id3.2.m2.1.1.1.1.cmml" xref="id3.2.m2.1.1.1.1"></times><ci id="id3.2.m2.1.1.1.2.cmml" xref="id3.2.m2.1.1.1.2">♠</ci><ci id="id3.2.m2.1.1.1.3b.cmml" xref="id3.2.m2.1.1.1.3"><merror class="ltx_ERROR undefined undefined" id="id3.2.m2.1.1.1.3.cmml" xref="id3.2.m2.1.1.1.3"><mtext id="id3.2.m2.1.1.1.3a.cmml" xref="id3.2.m2.1.1.1.3">\vardiamondsuit</mtext></merror></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.2.m2.1c">{}^{\spadesuit\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id3.2.m2.1d">start_FLOATSUPERSCRIPT ♠ end_FLOATSUPERSCRIPT</annotation></semantics></math>  Chandra Kiran Reddy Evuru <math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id4.3.m3.1"><semantics id="id4.3.m3.1a"><msup id="id4.3.m3.1.1" xref="id4.3.m3.1.1.cmml"><mi id="id4.3.m3.1.1a" xref="id4.3.m3.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id4.3.m3.1.1.1" xref="id4.3.m3.1.1.1b.cmml"><mtext id="id4.3.m3.1.1.1a" xref="id4.3.m3.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id4.3.m3.1b"><apply id="id4.3.m3.1.1.cmml" xref="id4.3.m3.1.1"><ci id="id4.3.m3.1.1.1b.cmml" xref="id4.3.m3.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id4.3.m3.1.1.1.cmml" xref="id4.3.m3.1.1.1"><mtext id="id4.3.m3.1.1.1a.cmml" xref="id4.3.m3.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.3.m3.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id4.3.m3.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>  Oriol Nieto<math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id5.4.m4.1"><semantics id="id5.4.m4.1a"><msup id="id5.4.m4.1.1" xref="id5.4.m4.1.1.cmml"><mi id="id5.4.m4.1.1a" xref="id5.4.m4.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id5.4.m4.1.1.1" xref="id5.4.m4.1.1.1b.cmml"><mtext id="id5.4.m4.1.1.1a" xref="id5.4.m4.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id5.4.m4.1b"><apply id="id5.4.m4.1.1.cmml" xref="id5.4.m4.1.1"><ci id="id5.4.m4.1.1.1b.cmml" xref="id5.4.m4.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id5.4.m4.1.1.1.cmml" xref="id5.4.m4.1.1.1"><mtext id="id5.4.m4.1.1.1a.cmml" xref="id5.4.m4.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.4.m4.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id5.4.m4.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"/>Ramani Duraiswami<math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id6.5.m5.1"><semantics id="id6.5.m5.1a"><msup id="id6.5.m5.1.1" xref="id6.5.m5.1.1.cmml"><mi id="id6.5.m5.1.1a" xref="id6.5.m5.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id6.5.m5.1.1.1" xref="id6.5.m5.1.1.1b.cmml"><mtext id="id6.5.m5.1.1.1a" xref="id6.5.m5.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id6.5.m5.1b"><apply id="id6.5.m5.1.1.cmml" xref="id6.5.m5.1.1"><ci id="id6.5.m5.1.1.1b.cmml" xref="id6.5.m5.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id6.5.m5.1.1.1.cmml" xref="id6.5.m5.1.1.1"><mtext id="id6.5.m5.1.1.1a.cmml" xref="id6.5.m5.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.5.m5.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id6.5.m5.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>  Dinesh Manocha<math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id7.6.m6.1"><semantics id="id7.6.m6.1a"><msup id="id7.6.m6.1.1" xref="id7.6.m6.1.1.cmml"><mi id="id7.6.m6.1.1a" xref="id7.6.m6.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id7.6.m6.1.1.1" xref="id7.6.m6.1.1.1b.cmml"><mtext id="id7.6.m6.1.1.1a" xref="id7.6.m6.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id7.6.m6.1b"><apply id="id7.6.m6.1.1.cmml" xref="id7.6.m6.1.1"><ci id="id7.6.m6.1.1.1b.cmml" xref="id7.6.m6.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id7.6.m6.1.1.1.cmml" xref="id7.6.m6.1.1.1"><mtext id="id7.6.m6.1.1.1a.cmml" xref="id7.6.m6.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.6.m6.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id7.6.m6.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><sup class="ltx_sup" id="id11.10.id1"><span class="ltx_text ltx_font_italic" id="id11.10.id1.1">♠</span></sup>University of Maryland, College Park, MD, USA  <math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id9.8.m2.1"><semantics id="id9.8.m2.1a"><msup id="id9.8.m2.1.1" xref="id9.8.m2.1.1.cmml"><mi id="id9.8.m2.1.1a" xref="id9.8.m2.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id9.8.m2.1.1.1" xref="id9.8.m2.1.1.1b.cmml"><mtext id="id9.8.m2.1.1.1a" xref="id9.8.m2.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id9.8.m2.1b"><apply id="id9.8.m2.1.1.cmml" xref="id9.8.m2.1.1"><ci id="id9.8.m2.1.1.1b.cmml" xref="id9.8.m2.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id9.8.m2.1.1.1.cmml" xref="id9.8.m2.1.1.1"><mtext id="id9.8.m2.1.1.1a.cmml" xref="id9.8.m2.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.8.m2.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id9.8.m2.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>Adobe Research, San Francisco, CA, USA 
<br class="ltx_break"/>{sreyang, sonalkum, ckevuru, ramanid, dmanocha}@umd.edu
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id12.id1">Open-vocabulary audio-language models, like CLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>, offer a promising approach for zero-shot audio classification (ZSAC) by enabling classification with any arbitrary set of categories specified with natural language prompts. In this paper, we propose a simple but effective method to improve ZSAC with CLAP. Specifically, we shift from the conventional method of using prompts with abstract category labels (e.g., <span class="ltx_text ltx_font_italic" id="id12.id1.1">Sound of an organ</span>) to prompts that describe sounds using their inherent descriptive features in a diverse context (e.g., <span class="ltx_text ltx_font_italic" id="id12.id1.2">The organ’s deep and resonant tones filled the cathedral.</span>). To achieve this, we first propose <span class="ltx_text ltx_font_bold" id="id12.id1.3">ReCLAP</span>, a CLAP model trained with <span class="ltx_text ltx_framed ltx_framed_underline" id="id12.id1.4">re</span>written audio captions for improved understanding of sounds in the wild. These rewritten captions describe each sound event in the original caption using their unique discriminative characteristics. ReCLAP outperforms all baselines on both multi-modal audio-text retrieval and ZSAC. Next, to improve zero-shot audio classification with ReCLAP, we propose <span class="ltx_text ltx_font_italic" id="id12.id1.5">prompt augmentation</span>. In contrast to the traditional method of employing hand-written template prompts, we generate custom prompts for each unique label in the dataset. These custom prompts first describe the sound event in the label and then employ them in diverse scenes. Our proposed method improves ReCLAP’s performance on ZSAC by 1%-18% and outperforms all baselines by 1% - 55%<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code and Checkpoints: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/Sreyan88/ReCLAP</span></span></span></span>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Audio classification, the foundational task of assigning a category label to an audio sample, remains one of the most important tasks in audio processing and has numerous real-world applications. Zero-shot audio classification (ZSAC) presents a promising approach that provides greater flexibility at the inference stage than supervised methods. Unlike supervised methods that map input audio to a fixed set of categories, models classify by computing a similarity score between an input audio example and a caption. To perform inference, one can generate a caption or “prompt” associated with each desired category and match each audio sample to the best prompt. This means that categories can be selected ad hoc and adjusted without additional training.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Open-vocabulary audio-language models like Contrastive Language-Audio Pre-training (CLAP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite> have outperformed most other models on ZSAC. CLAP is trained on contrastive objectives between audio-caption pairs, where each audio sample corresponds to non-speech sounds and non-verbal speech, and the captions describe the acoustic events and the scene, not the spoken content. Beyond ZSAC, CLAP has also achieved superior performance on cross-modal audio-text retrieval <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> and has been used as a backbone audio encoder for a variety of audio-language tasks, including generalist audio agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib3" title="">3</a>]</cite>, open-domain chat assistants <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib4" title="">4</a>]</cite>, audio captioning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib5" title="">5</a>]</cite> and text-to-audio generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib6" title="">6</a>]</cite>. However, ZSAC with CLAP currently remains subpar compared to standard supervised methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib7" title="">7</a>]</cite>. We attribute this to 3 main reasons:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Limited access to large-scale audio-caption datasets</span>: Unlike CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib8" title="">8</a>]</cite>, CLAP has not been trained on large-scale, open-source audio-caption datasets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>. This constrains its ability to fully understand and perceive the diverse range of audio and language interactions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Lack of generalization beyond training category labels</span>: CLAP struggles to generalize beyond the specific category labels used in its training prompts. For instance, research by Tiago <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.2">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib9" title="">9</a>]</cite> indicates that a model’s ZSAC accuracy is closely related to the clusters in its audio embedding space. Consequently, if CLAP was trained on a dataset where the prompt is <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.3">“Sound of a toothbrush”</span> from AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib10" title="">10</a>]</cite>, it might not accurately generalize to a similar label like “brushing teeth” in the ESC50 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib11" title="">11</a>]</cite>, even though the sounds are similar (<span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.4">both sound like a soft scrubbing or swishing noise, often with a light, scratchy texture</span>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Limitations of hand-written prompts for ZSAC</span>: The current ZSAC setup relies on hand-written prompts that correspond directly to dataset category labels. These prompts fail to provide additional context beyond the label itself. For example, CLAP may struggle to classify a label like “Residential Area” in the CochlScene dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib12" title="">12</a>]</cite> if it has not encountered that label during training. The label alone offers very little information about what sounds characterize a residential area, leading to potential misclassification.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Main Contributions.</span> In this paper, we propose a simple, scalable, and effective approach to improve ZSAC with CLAP. Our contributions are twofold and are summarized as follows:</p>
<ol class="ltx_enumerate" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.1">We present ReCLAP, a CLAP model trained using <span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.1.1">caption augmentation</span>. Specifically, we prompt a Large Language Model (LLM) to generate multiple diverse rewrites of the caption associated with each audio. Each rewrite describes the sounds in a unique way. Additionally, they exhibit diversity in sentence structure and vocabulary while preserving the original key concepts and meanings (example in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.F1" title="Figure 1 ‣ III-A Caption Augmentation for ReCLAP ‣ III Methodology ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">1</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.SS1" title="III-A Caption Augmentation for ReCLAP ‣ III Methodology ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>). This simple data augmentation technique has several advantages, including <span class="ltx_text ltx_font_bold" id="S1.I2.i1.p1.1.2">(1)</span> It enables the model to learn about the distinct acoustic features of sound events beyond what abstract labels alone can provide. This leads to more accurate clustering of sounds based on their actual acoustic properties rather than relying solely on predefined labels. <span class="ltx_text ltx_font_bold" id="S1.I2.i1.p1.1.3">(2)</span> Text-based augmentation via LLM-generated captions provides an effective and scalable method for training-time data augmentation. Unlike traditional data augmentation techniques, which typically involve random audio perturbations, our method is more interpretable and avoids the complexities and limitations of generating synthetic audio. ReCLAP achieves state-of-the-art performance across various retrieval, and ZSAC benchmarks with standard setups.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I2.i2.p1">
<p class="ltx_p" id="S1.I2.i2.p1.1">To further improve ZSAC performance with ReCLAP, we go beyond simple hand-written template prompts (e.g., “The sound of a {category}”) by generating multiple custom prompts for each category. This process involves two steps: <span class="ltx_text ltx_font_bold" id="S1.I2.i2.p1.1.1">(1)</span> We prompt an LLM to describe the sound of each category label in <math alttext="t" class="ltx_Math" display="inline" id="S1.I2.i2.p1.1.m1.1"><semantics id="S1.I2.i2.p1.1.m1.1a"><mi id="S1.I2.i2.p1.1.m1.1.1" xref="S1.I2.i2.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S1.I2.i2.p1.1.m1.1b"><ci id="S1.I2.i2.p1.1.m1.1.1.cmml" xref="S1.I2.i2.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I2.i2.p1.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S1.I2.i2.p1.1.m1.1d">italic_t</annotation></semantics></math> distinct ways, focusing on its unique acoustic characteristics (e.g., Gasp: “a sharp intake of breath”). <span class="ltx_text ltx_font_bold" id="S1.I2.i2.p1.1.2">(2)</span> We then create prompts that place the sound event in diverse scenes, incorporating the descriptions generated in the previous step (e.g., “A sharp intake of breath sliced through the silence as the verdict was announced”). Our proposed method improves the performance of ReCLAP across various ZSAC benchmarks by 1%-55%.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Following the initial work on CLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>, several works have worked to improve its performance. For example, Wu <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>]</cite> scaled CLAP to 630k audio-caption pairs (including proprietary datasets) and showed a considerable boost in performance. Following this, Elizade <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">et al.</span> scaled their data to 4.6M audio-caption pairs and included speech samples in their training. Ghosh <span class="ltx_text ltx_font_italic" id="S2.p1.1.3">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> employed 660k pairs using only public domain data to build CompA-CLAP. They also proposed novel techniques to improve the compositional reasoning abilities of CLAP. CLAP has also been employed as an audio or text backbone for a variety of foundational audio processing tasks including text-to-audio generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib16" title="">16</a>]</cite>, audio captioning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib5" title="">5</a>]</cite> and audio chat models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib3" title="">3</a>]</cite>. Despite its gaining popularity, research efforts to enhance CLAP’s audio and language comprehension skills have been limited, with prior work focusing mainly on scaling.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methodology</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Caption Augmentation for ReCLAP</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.6">CLAP is trained on a contrastive objective between audio-caption pairs to learn a shared representation between the audio and language modalities. Specifically, let <math alttext="X_{a}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝑋</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">X_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_X start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="X_{t}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝑋</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">X_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> be the audio and its corresponding caption. Additionally, let <math alttext="f_{a}(.)" class="ltx_math_unparsed" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1b"><msub id="S3.SS1.p1.3.m3.1.1"><mi id="S3.SS1.p1.3.m3.1.1.2">f</mi><mi id="S3.SS1.p1.3.m3.1.1.3">a</mi></msub><mrow id="S3.SS1.p1.3.m3.1.2"><mo id="S3.SS1.p1.3.m3.1.2.1" stretchy="false">(</mo><mo id="S3.SS1.p1.3.m3.1.2.2" lspace="0em" rspace="0.167em">.</mo><mo id="S3.SS1.p1.3.m3.1.2.3" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">f_{a}(.)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( . )</annotation></semantics></math> and <math alttext="f_{b}(.)" class="ltx_math_unparsed" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1b"><msub id="S3.SS1.p1.4.m4.1.1"><mi id="S3.SS1.p1.4.m4.1.1.2">f</mi><mi id="S3.SS1.p1.4.m4.1.1.3">b</mi></msub><mrow id="S3.SS1.p1.4.m4.1.2"><mo id="S3.SS1.p1.4.m4.1.2.1" stretchy="false">(</mo><mo id="S3.SS1.p1.4.m4.1.2.2" lspace="0em" rspace="0.167em">.</mo><mo id="S3.SS1.p1.4.m4.1.2.3" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">f_{b}(.)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_f start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ( . )</annotation></semantics></math> be the audio and text encoders respectively. We first obtain audio and text representations <math alttext="\hat{X}_{a}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mover accent="true" id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">X</mi><mo id="S3.SS1.p1.5.m5.1.1.2.1" xref="S3.SS1.p1.5.m5.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"><ci id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2.1">^</ci><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">𝑋</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\hat{X}_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\hat{X}_{b}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mover accent="true" id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2.2" xref="S3.SS1.p1.6.m6.1.1.2.2.cmml">X</mi><mo id="S3.SS1.p1.6.m6.1.1.2.1" xref="S3.SS1.p1.6.m6.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><apply id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2"><ci id="S3.SS1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS1.p1.6.m6.1.1.2.1">^</ci><ci id="S3.SS1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2.2">𝑋</ci></apply><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\hat{X}_{b}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{X}_{a}=f_{a}\left(X_{a}\right);\hat{X}_{t}=f_{t}\left(X_{t}\right)" class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">X</mi><mo id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml">a</mi></msub><mo id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.3.2.cmml">f</mi><mi id="S3.E1.m1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.3.3.cmml">a</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.3a.cmml">;</mo><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><msub id="S3.E1.m1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml"><mover accent="true" id="S3.E1.m1.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.3.2.cmml"><mi id="S3.E1.m1.2.2.2.2.3.2.2" xref="S3.E1.m1.2.2.2.2.3.2.2.cmml">X</mi><mo id="S3.E1.m1.2.2.2.2.3.2.1" xref="S3.E1.m1.2.2.2.2.3.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.1.cmml"><msub id="S3.E1.m1.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.2.1.3.cmml"><mi id="S3.E1.m1.2.2.2.2.1.3.2" xref="S3.E1.m1.2.2.2.2.1.3.2.cmml">f</mi><mi id="S3.E1.m1.2.2.2.2.1.3.3" xref="S3.E1.m1.2.2.2.2.1.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.2.2.1.1.1.2" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.2.2.2.2.1.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.2.2.1.1.1.1.2.cmml">X</mi><mi id="S3.E1.m1.2.2.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1">^</ci><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">𝑋</ci></apply><ci id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3">𝑎</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></times><apply id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2">𝑓</ci><ci id="S3.E1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3">𝑎</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">𝑋</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">𝑎</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><eq id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2"></eq><apply id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.3">subscript</csymbol><apply id="S3.E1.m1.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.3.2"><ci id="S3.E1.m1.2.2.2.2.3.2.1.cmml" xref="S3.E1.m1.2.2.2.2.3.2.1">^</ci><ci id="S3.E1.m1.2.2.2.2.3.2.2.cmml" xref="S3.E1.m1.2.2.2.2.3.2.2">𝑋</ci></apply><ci id="S3.E1.m1.2.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3">𝑡</ci></apply><apply id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1"><times id="S3.E1.m1.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.2"></times><apply id="S3.E1.m1.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.3.1.cmml" xref="S3.E1.m1.2.2.2.2.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.3.2.cmml" xref="S3.E1.m1.2.2.2.2.1.3.2">𝑓</ci><ci id="S3.E1.m1.2.2.2.2.1.3.3.cmml" xref="S3.E1.m1.2.2.2.2.1.3.3">𝑡</ci></apply><apply id="S3.E1.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.2">𝑋</ci><ci id="S3.E1.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\hat{X}_{a}=f_{a}\left(X_{a}\right);\hat{X}_{t}=f_{t}\left(X_{t}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ) ; over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.10">where <math alttext="\hat{X}_{a}\in\mathbb{R}^{N\times D}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m1.1"><semantics id="S3.SS1.p1.7.m1.1a"><mrow id="S3.SS1.p1.7.m1.1.1" xref="S3.SS1.p1.7.m1.1.1.cmml"><msub id="S3.SS1.p1.7.m1.1.1.2" xref="S3.SS1.p1.7.m1.1.1.2.cmml"><mover accent="true" id="S3.SS1.p1.7.m1.1.1.2.2" xref="S3.SS1.p1.7.m1.1.1.2.2.cmml"><mi id="S3.SS1.p1.7.m1.1.1.2.2.2" xref="S3.SS1.p1.7.m1.1.1.2.2.2.cmml">X</mi><mo id="S3.SS1.p1.7.m1.1.1.2.2.1" xref="S3.SS1.p1.7.m1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.7.m1.1.1.2.3" xref="S3.SS1.p1.7.m1.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS1.p1.7.m1.1.1.1" xref="S3.SS1.p1.7.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.7.m1.1.1.3" xref="S3.SS1.p1.7.m1.1.1.3.cmml"><mi id="S3.SS1.p1.7.m1.1.1.3.2" xref="S3.SS1.p1.7.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.7.m1.1.1.3.3" xref="S3.SS1.p1.7.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.7.m1.1.1.3.3.2" xref="S3.SS1.p1.7.m1.1.1.3.3.2.cmml">N</mi><mo id="S3.SS1.p1.7.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.7.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.7.m1.1.1.3.3.3" xref="S3.SS1.p1.7.m1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m1.1b"><apply id="S3.SS1.p1.7.m1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1"><in id="S3.SS1.p1.7.m1.1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1.1"></in><apply id="S3.SS1.p1.7.m1.1.1.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m1.1.1.2.1.cmml" xref="S3.SS1.p1.7.m1.1.1.2">subscript</csymbol><apply id="S3.SS1.p1.7.m1.1.1.2.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2.2"><ci id="S3.SS1.p1.7.m1.1.1.2.2.1.cmml" xref="S3.SS1.p1.7.m1.1.1.2.2.1">^</ci><ci id="S3.SS1.p1.7.m1.1.1.2.2.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2.2.2">𝑋</ci></apply><ci id="S3.SS1.p1.7.m1.1.1.2.3.cmml" xref="S3.SS1.p1.7.m1.1.1.2.3">𝑎</ci></apply><apply id="S3.SS1.p1.7.m1.1.1.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m1.1.1.3.1.cmml" xref="S3.SS1.p1.7.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.7.m1.1.1.3.2.cmml" xref="S3.SS1.p1.7.m1.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.7.m1.1.1.3.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3"><times id="S3.SS1.p1.7.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.7.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.2">𝑁</ci><ci id="S3.SS1.p1.7.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m1.1c">\hat{X}_{a}\in\mathbb{R}^{N\times D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m1.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\hat{X}_{b}\in\mathbb{R}^{N\times D}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m2.1"><semantics id="S3.SS1.p1.8.m2.1a"><mrow id="S3.SS1.p1.8.m2.1.1" xref="S3.SS1.p1.8.m2.1.1.cmml"><msub id="S3.SS1.p1.8.m2.1.1.2" xref="S3.SS1.p1.8.m2.1.1.2.cmml"><mover accent="true" id="S3.SS1.p1.8.m2.1.1.2.2" xref="S3.SS1.p1.8.m2.1.1.2.2.cmml"><mi id="S3.SS1.p1.8.m2.1.1.2.2.2" xref="S3.SS1.p1.8.m2.1.1.2.2.2.cmml">X</mi><mo id="S3.SS1.p1.8.m2.1.1.2.2.1" xref="S3.SS1.p1.8.m2.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.8.m2.1.1.2.3" xref="S3.SS1.p1.8.m2.1.1.2.3.cmml">b</mi></msub><mo id="S3.SS1.p1.8.m2.1.1.1" xref="S3.SS1.p1.8.m2.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.8.m2.1.1.3" xref="S3.SS1.p1.8.m2.1.1.3.cmml"><mi id="S3.SS1.p1.8.m2.1.1.3.2" xref="S3.SS1.p1.8.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.8.m2.1.1.3.3" xref="S3.SS1.p1.8.m2.1.1.3.3.cmml"><mi id="S3.SS1.p1.8.m2.1.1.3.3.2" xref="S3.SS1.p1.8.m2.1.1.3.3.2.cmml">N</mi><mo id="S3.SS1.p1.8.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.8.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.8.m2.1.1.3.3.3" xref="S3.SS1.p1.8.m2.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m2.1b"><apply id="S3.SS1.p1.8.m2.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1"><in id="S3.SS1.p1.8.m2.1.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1.1"></in><apply id="S3.SS1.p1.8.m2.1.1.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m2.1.1.2.1.cmml" xref="S3.SS1.p1.8.m2.1.1.2">subscript</csymbol><apply id="S3.SS1.p1.8.m2.1.1.2.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2.2"><ci id="S3.SS1.p1.8.m2.1.1.2.2.1.cmml" xref="S3.SS1.p1.8.m2.1.1.2.2.1">^</ci><ci id="S3.SS1.p1.8.m2.1.1.2.2.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2.2.2">𝑋</ci></apply><ci id="S3.SS1.p1.8.m2.1.1.2.3.cmml" xref="S3.SS1.p1.8.m2.1.1.2.3">𝑏</ci></apply><apply id="S3.SS1.p1.8.m2.1.1.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m2.1.1.3.1.cmml" xref="S3.SS1.p1.8.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.8.m2.1.1.3.2.cmml" xref="S3.SS1.p1.8.m2.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.8.m2.1.1.3.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3"><times id="S3.SS1.p1.8.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3.1"></times><ci id="S3.SS1.p1.8.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3.2">𝑁</ci><ci id="S3.SS1.p1.8.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m2.1c">\hat{X}_{b}\in\mathbb{R}^{N\times D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m2.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_N × italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>. <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m3.1"><semantics id="S3.SS1.p1.9.m3.1a"><mi id="S3.SS1.p1.9.m3.1.1" xref="S3.SS1.p1.9.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m3.1b"><ci id="S3.SS1.p1.9.m3.1.1.cmml" xref="S3.SS1.p1.9.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m3.1d">italic_N</annotation></semantics></math> here is the batch size and <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m4.1"><semantics id="S3.SS1.p1.10.m4.1a"><mi id="S3.SS1.p1.10.m4.1.1" xref="S3.SS1.p1.10.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m4.1b"><ci id="S3.SS1.p1.10.m4.1.1.cmml" xref="S3.SS1.p1.10.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m4.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m4.1d">italic_D</annotation></semantics></math> is the embedding dimension. Next, we measure similarity as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="C=\tau*\left(\hat{X}_{a}\cdot\hat{X}_{t}^{\top}\right)" class="ltx_Math" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mi id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">C</mi><mo id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">τ</mi><mo id="S3.E2.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.1.1.1.2.cmml">∗</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml">X</mi><mo id="S3.E2.m1.1.1.1.1.1.1.2.2.1" xref="S3.E2.m1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml">a</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">⋅</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml">X</mi><mo id="S3.E2.m1.1.1.1.1.1.1.3.2.2.1" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml">⊤</mo></msubsup></mrow><mo id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"></eq><ci id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3">𝐶</ci><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">𝜏</ci><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><ci id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1">⋅</ci><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2"><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2">𝑋</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">𝑎</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2"><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2">𝑋</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3">𝑡</ci></apply><csymbol cd="latexml" id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">C=\tau*\left(\hat{X}_{a}\cdot\hat{X}_{t}^{\top}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">italic_C = italic_τ ∗ ( over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ⋅ over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.11">where <math alttext="C" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m1.1"><semantics id="S3.SS1.p1.11.m1.1a"><mi id="S3.SS1.p1.11.m1.1.1" xref="S3.SS1.p1.11.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m1.1b"><ci id="S3.SS1.p1.11.m1.1.1.cmml" xref="S3.SS1.p1.11.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.11.m1.1d">italic_C</annotation></semantics></math> is any similarity function that measures distance using the dot product (cosine similarity in our case). Finally, the contrastive loss is calculated as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=0.5*\left(\ell_{\text{text }}(C)+\ell_{\text{audio }}(C)\right)" class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml">ℒ</mi><mo id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml"><mn id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.3.3.1.3.cmml">0.5</mn><mo id="S3.E3.m1.3.3.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E3.m1.3.3.1.2.cmml">∗</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.2.2.2" mathvariant="normal" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml">ℓ</mi><mtext id="S3.E3.m1.3.3.1.1.1.1.2.2.3" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3a.cmml">text </mtext></msub><mo id="S3.E3.m1.3.3.1.1.1.1.2.1" xref="S3.E3.m1.3.3.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.2.3.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.2.3.2.1" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">C</mi><mo id="S3.E3.m1.3.3.1.1.1.1.2.3.2.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml">+</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.2.2" mathvariant="normal" xref="S3.E3.m1.3.3.1.1.1.1.3.2.2.cmml">ℓ</mi><mtext id="S3.E3.m1.3.3.1.1.1.1.3.2.3" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3a.cmml">audio </mtext></msub><mo id="S3.E3.m1.3.3.1.1.1.1.3.1" xref="S3.E3.m1.3.3.1.1.1.1.3.1.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.3.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.2.1" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">C</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.2.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"></eq><ci id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3">ℒ</ci><apply id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1"><times id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.2"></times><cn id="S3.E3.m1.3.3.1.3.cmml" type="float" xref="S3.E3.m1.3.3.1.3">0.5</cn><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"><plus id="S3.E3.m1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1"></plus><apply id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"><times id="S3.E3.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.1"></times><apply id="S3.E3.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2">ℓ</ci><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.3a.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3"><mtext id="S3.E3.m1.3.3.1.1.1.1.2.2.3.cmml" mathsize="70%" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3">text </mtext></ci></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝐶</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><times id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.1"></times><apply id="S3.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2.2">ℓ</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.3a.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3"><mtext id="S3.E3.m1.3.3.1.1.1.1.3.2.3.cmml" mathsize="70%" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3">audio </mtext></ci></apply><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝐶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mathcal{L}=0.5*\left(\ell_{\text{text }}(C)+\ell_{\text{audio }}(C)\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">caligraphic_L = 0.5 ∗ ( roman_ℓ start_POSTSUBSCRIPT text end_POSTSUBSCRIPT ( italic_C ) + roman_ℓ start_POSTSUBSCRIPT audio end_POSTSUBSCRIPT ( italic_C ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\ell_{k}=\frac{1}{N}\sum_{i=0}^{N}\log\operatorname{diag}(\operatorname{%
softmax}(C))" class="ltx_Math" display="block" id="S3.E4.m1.4"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.4" xref="S3.E4.m1.4.4.cmml"><msub id="S3.E4.m1.4.4.3" xref="S3.E4.m1.4.4.3.cmml"><mi id="S3.E4.m1.4.4.3.2" mathvariant="normal" xref="S3.E4.m1.4.4.3.2.cmml">ℓ</mi><mi id="S3.E4.m1.4.4.3.3" xref="S3.E4.m1.4.4.3.3.cmml">k</mi></msub><mo id="S3.E4.m1.4.4.2" xref="S3.E4.m1.4.4.2.cmml">=</mo><mrow id="S3.E4.m1.4.4.1" xref="S3.E4.m1.4.4.1.cmml"><mfrac id="S3.E4.m1.4.4.1.3" xref="S3.E4.m1.4.4.1.3.cmml"><mn id="S3.E4.m1.4.4.1.3.2" xref="S3.E4.m1.4.4.1.3.2.cmml">1</mn><mi id="S3.E4.m1.4.4.1.3.3" xref="S3.E4.m1.4.4.1.3.3.cmml">N</mi></mfrac><mo id="S3.E4.m1.4.4.1.2" xref="S3.E4.m1.4.4.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.4.4.1.1" xref="S3.E4.m1.4.4.1.1.cmml"><munderover id="S3.E4.m1.4.4.1.1.2" xref="S3.E4.m1.4.4.1.1.2.cmml"><mo id="S3.E4.m1.4.4.1.1.2.2.2" movablelimits="false" xref="S3.E4.m1.4.4.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E4.m1.4.4.1.1.2.2.3" xref="S3.E4.m1.4.4.1.1.2.2.3.cmml"><mi id="S3.E4.m1.4.4.1.1.2.2.3.2" xref="S3.E4.m1.4.4.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E4.m1.4.4.1.1.2.2.3.1" xref="S3.E4.m1.4.4.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.4.4.1.1.2.2.3.3" xref="S3.E4.m1.4.4.1.1.2.2.3.3.cmml">0</mn></mrow><mi id="S3.E4.m1.4.4.1.1.2.3" xref="S3.E4.m1.4.4.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E4.m1.4.4.1.1.1" xref="S3.E4.m1.4.4.1.1.1.cmml"><mi id="S3.E4.m1.4.4.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.2.cmml">log</mi><mo id="S3.E4.m1.4.4.1.1.1a" lspace="0.167em" xref="S3.E4.m1.4.4.1.1.1.cmml">⁡</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml">diag</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1a" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">⁡</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml"><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">(</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">softmax</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2a" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml">⁡</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.1.1" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">C</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.1.2" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.4.cmml" xref="S3.E4.m1.4.4"><eq id="S3.E4.m1.4.4.2.cmml" xref="S3.E4.m1.4.4.2"></eq><apply id="S3.E4.m1.4.4.3.cmml" xref="S3.E4.m1.4.4.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.3.1.cmml" xref="S3.E4.m1.4.4.3">subscript</csymbol><ci id="S3.E4.m1.4.4.3.2.cmml" xref="S3.E4.m1.4.4.3.2">ℓ</ci><ci id="S3.E4.m1.4.4.3.3.cmml" xref="S3.E4.m1.4.4.3.3">𝑘</ci></apply><apply id="S3.E4.m1.4.4.1.cmml" xref="S3.E4.m1.4.4.1"><times id="S3.E4.m1.4.4.1.2.cmml" xref="S3.E4.m1.4.4.1.2"></times><apply id="S3.E4.m1.4.4.1.3.cmml" xref="S3.E4.m1.4.4.1.3"><divide id="S3.E4.m1.4.4.1.3.1.cmml" xref="S3.E4.m1.4.4.1.3"></divide><cn id="S3.E4.m1.4.4.1.3.2.cmml" type="integer" xref="S3.E4.m1.4.4.1.3.2">1</cn><ci id="S3.E4.m1.4.4.1.3.3.cmml" xref="S3.E4.m1.4.4.1.3.3">𝑁</ci></apply><apply id="S3.E4.m1.4.4.1.1.cmml" xref="S3.E4.m1.4.4.1.1"><apply id="S3.E4.m1.4.4.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.2.1.cmml" xref="S3.E4.m1.4.4.1.1.2">superscript</csymbol><apply id="S3.E4.m1.4.4.1.1.2.2.cmml" xref="S3.E4.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.2.2.1.cmml" xref="S3.E4.m1.4.4.1.1.2">subscript</csymbol><sum id="S3.E4.m1.4.4.1.1.2.2.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2.2"></sum><apply id="S3.E4.m1.4.4.1.1.2.2.3.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3"><eq id="S3.E4.m1.4.4.1.1.2.2.3.1.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3.1"></eq><ci id="S3.E4.m1.4.4.1.1.2.2.3.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3.2">𝑖</ci><cn id="S3.E4.m1.4.4.1.1.2.2.3.3.cmml" type="integer" xref="S3.E4.m1.4.4.1.1.2.2.3.3">0</cn></apply></apply><ci id="S3.E4.m1.4.4.1.1.2.3.cmml" xref="S3.E4.m1.4.4.1.1.2.3">𝑁</ci></apply><apply id="S3.E4.m1.4.4.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1"><log id="S3.E4.m1.4.4.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.2"></log><apply id="S3.E4.m1.4.4.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1"><ci id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3">diag</ci><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.2"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">softmax</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝐶</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\ell_{k}=\frac{1}{N}\sum_{i=0}^{N}\log\operatorname{diag}(\operatorname{%
softmax}(C))</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.4d">roman_ℓ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ∑ start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_log roman_diag ( roman_softmax ( italic_C ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.15">We train ReCLAP with a training objective similar to that in CLAP but with <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.15.1">caption augmentation</span>. Specifically, we augment each training sample with <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.12.m1.1"><semantics id="S3.SS1.p1.12.m1.1a"><mi id="S3.SS1.p1.12.m1.1.1" xref="S3.SS1.p1.12.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m1.1b"><ci id="S3.SS1.p1.12.m1.1.1.cmml" xref="S3.SS1.p1.12.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.12.m1.1d">italic_K</annotation></semantics></math> additional text captions by rewriting the original caption associated with each audio sample in the dataset in <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.13.m2.1"><semantics id="S3.SS1.p1.13.m2.1a"><mi id="S3.SS1.p1.13.m2.1.1" xref="S3.SS1.p1.13.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m2.1b"><ci id="S3.SS1.p1.13.m2.1.1.cmml" xref="S3.SS1.p1.13.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.13.m2.1d">italic_K</annotation></semantics></math> diverse ways. During training, for each audio sample, ReCLAP chooses the original caption with a probability <math alttext="p=0.4" class="ltx_Math" display="inline" id="S3.SS1.p1.14.m3.1"><semantics id="S3.SS1.p1.14.m3.1a"><mrow id="S3.SS1.p1.14.m3.1.1" xref="S3.SS1.p1.14.m3.1.1.cmml"><mi id="S3.SS1.p1.14.m3.1.1.2" xref="S3.SS1.p1.14.m3.1.1.2.cmml">p</mi><mo id="S3.SS1.p1.14.m3.1.1.1" xref="S3.SS1.p1.14.m3.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.14.m3.1.1.3" xref="S3.SS1.p1.14.m3.1.1.3.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m3.1b"><apply id="S3.SS1.p1.14.m3.1.1.cmml" xref="S3.SS1.p1.14.m3.1.1"><eq id="S3.SS1.p1.14.m3.1.1.1.cmml" xref="S3.SS1.p1.14.m3.1.1.1"></eq><ci id="S3.SS1.p1.14.m3.1.1.2.cmml" xref="S3.SS1.p1.14.m3.1.1.2">𝑝</ci><cn id="S3.SS1.p1.14.m3.1.1.3.cmml" type="float" xref="S3.SS1.p1.14.m3.1.1.3">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m3.1c">p=0.4</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.14.m3.1d">italic_p = 0.4</annotation></semantics></math> or one of the rewritten versions (with a probability <math alttext="1-p" class="ltx_Math" display="inline" id="S3.SS1.p1.15.m4.1"><semantics id="S3.SS1.p1.15.m4.1a"><mrow id="S3.SS1.p1.15.m4.1.1" xref="S3.SS1.p1.15.m4.1.1.cmml"><mn id="S3.SS1.p1.15.m4.1.1.2" xref="S3.SS1.p1.15.m4.1.1.2.cmml">1</mn><mo id="S3.SS1.p1.15.m4.1.1.1" xref="S3.SS1.p1.15.m4.1.1.1.cmml">−</mo><mi id="S3.SS1.p1.15.m4.1.1.3" xref="S3.SS1.p1.15.m4.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m4.1b"><apply id="S3.SS1.p1.15.m4.1.1.cmml" xref="S3.SS1.p1.15.m4.1.1"><minus id="S3.SS1.p1.15.m4.1.1.1.cmml" xref="S3.SS1.p1.15.m4.1.1.1"></minus><cn id="S3.SS1.p1.15.m4.1.1.2.cmml" type="integer" xref="S3.SS1.p1.15.m4.1.1.2">1</cn><ci id="S3.SS1.p1.15.m4.1.1.3.cmml" xref="S3.SS1.p1.15.m4.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m4.1c">1-p</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.15.m4.1d">1 - italic_p</annotation></semantics></math>) where each rewritten caption has an equal probability of selection. Thus, Eqn. <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.E2" title="In III-A Caption Augmentation for ReCLAP ‣ III Methodology ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">2</span></a> can be re-written as:</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="C=\tau*\left(\hat{X}_{a}\cdot f_{t}(\operatorname{aug}_{t}(X_{t}))^{\top}\right)" class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><mi id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml">C</mi><mo id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.3.cmml">τ</mi><mo id="S3.E5.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E5.m1.1.1.1.2.cmml">∗</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.1.3.2.cmml"><mover accent="true" id="S3.E5.m1.1.1.1.1.1.1.3.2.2" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.3.2.2.2" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.2.cmml">X</mi><mo id="S3.E5.m1.1.1.1.1.1.1.3.2.2.1" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.1.1.1.1.1.1.3.2.3" xref="S3.E5.m1.1.1.1.1.1.1.3.2.3.cmml">a</mi></msub><mo id="S3.E5.m1.1.1.1.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E5.m1.1.1.1.1.1.1.3.1.cmml">⋅</mo><msub id="S3.E5.m1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2.cmml">f</mi><mi id="S3.E5.m1.1.1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.cmml">t</mi></msub></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml">⁢</mo><msup id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">aug</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2a" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">⁡</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2.cmml">X</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3.cmml">t</mi></msub><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.3.cmml">⊤</mo></msup></mrow><mo id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"></eq><ci id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3">𝐶</ci><apply id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><times id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.2"></times><ci id="S3.E5.m1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.3">𝜏</ci><apply id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><times id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2"></times><apply id="S3.E5.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3"><ci id="S3.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.1">⋅</ci><apply id="S3.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2">subscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2"><ci id="S3.E5.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.1">^</ci><ci id="S3.E5.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.2">𝑋</ci></apply><ci id="S3.E5.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.3">𝑎</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2">𝑓</ci><ci id="S3.E5.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2"><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">aug</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2">𝑋</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3">𝑡</ci></apply></apply><csymbol cd="latexml" id="S3.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">C=\tau*\left(\hat{X}_{a}\cdot f_{t}(\operatorname{aug}_{t}(X_{t}))^{\top}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_C = italic_τ ∗ ( over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ⋅ italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( roman_aug start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">where <math alttext="\operatorname{aug}_{t}(.)" class="ltx_math_unparsed" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1b"><msub id="S3.SS1.p3.1.m1.1.1"><mi id="S3.SS1.p3.1.m1.1.1.2">aug</mi><mi id="S3.SS1.p3.1.m1.1.1.3">t</mi></msub><mrow id="S3.SS1.p3.1.m1.1.2"><mo id="S3.SS1.p3.1.m1.1.2.1" stretchy="false">(</mo><mo id="S3.SS1.p3.1.m1.1.2.2" lspace="0em" rspace="0.167em">.</mo><mo id="S3.SS1.p3.1.m1.1.2.3" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\operatorname{aug}_{t}(.)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">roman_aug start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( . )</annotation></semantics></math> denotes the rewriting and choosing operation. The primary objective of the rewriting operation is to rewrite the caption so that each sound in the caption is described using its unique acoustic characteristics. An example is as follows:</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<span class="ltx_ERROR undefined" id="S3.SS1.p4.1">{mdframed}</span>
<p class="ltx_p" id="S3.SS1.p4.2">[linewidth=1pt, linecolor=black, leftmargin=1pt, rightmargin=1pt, innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=4pt, innerbottommargin=2pt, backgroundcolor=gray!20, roundcorner=5pt]
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p4.2.1">(1) Original Caption:</span> A traction engine is idling.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p5.1.1">(1) Rewritten Caption:</span> A low, rumbling diesel engine hums steadily, its vibrations resonating through the air.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p6.1.1">(2) Original Caption:</span> Cars are starting in pairs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p7.1.1">(2) Rewritten Caption:</span> Rapid, low-pitched revving of engines, followed by the synchronized, high-pitched roar of multiple cars starting in unison.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1">We instruct an LLM to complete this task, which ensures that the rewritten captions or augmentations exhibit high levels of diversity in sentence structure and vocabulary while preserving the original key concepts and meanings. The instruction used to prompt the LLM is provided in our GitHub. We employ LLaMa-3.1-8B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib18" title="">18</a>]</cite> with in-context examples written by humans. We randomly sample 5 in-context examples for every prompt from a collection of 50.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="953" id="S3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text" id="S3.F1.2.1" style="font-size:90%;">Illustration of our proposed method for improving Zero Shot Audio Classification (ZSAC) with language augmentation. <span class="ltx_text ltx_font_bold" id="S3.F1.2.1.1">Top:</span> We enhance CLAP training through <span class="ltx_text ltx_font_italic" id="S3.F1.2.1.2">caption augmentation</span>, where each audio’s caption is expanded and rewritten by prompting LLMs to provide detailed descriptions of the sound events. During training, we choose either the original caption or one of the rewritten captions. <span class="ltx_text ltx_font_bold" id="S3.F1.2.1.3">Bottom:</span> We perform <span class="ltx_text ltx_font_italic" id="S3.F1.2.1.4">prompt augmentation</span> and generate custom prompts for each label category in the dataset. These prompts describe the sound in the category in diverse scenes.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Prompt Augmentation for ZSAC</span>
</h3>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span><span class="ltx_text" id="S3.T1.2.1" style="font-size:90%;">Performance comparison of ReCLAP with baselines on Text-to-Audio and Audio-to-Text retrieval on AudioCaps and Clotho. ReCLAP outperforms baselines by 0.4%-38.9%.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.3" style="width:867.2pt;height:327.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(171.2pt,-64.6pt) scale(1.65249537226375,1.65249537226375) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt ltx_border_tt" id="S3.T1.3.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="6" id="S3.T1.3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.1.1.2.1">AudioCaps</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" colspan="6" id="S3.T1.3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.1.1.3.1">Clotho</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T1.3.1.2.2.1">Model</th>
<td class="ltx_td ltx_align_center" colspan="3" id="S3.T1.3.1.2.2.2">Text-to-Audio</td>
<td class="ltx_td ltx_align_center ltx_border_r" colspan="3" id="S3.T1.3.1.2.2.3">Audio-to-Text</td>
<td class="ltx_td ltx_align_center" colspan="3" id="S3.T1.3.1.2.2.4">Text-to-Audio</td>
<td class="ltx_td ltx_align_center" colspan="3" id="S3.T1.3.1.2.2.5">Audio-to-Text</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.3.3">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T1.3.1.3.3.1"></th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.2">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.3">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.3.3.4">R@10</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.5">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.6">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.3.3.7">R@10</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.8">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.9">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.3.3.10">R@10</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.11">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.12">R@5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.13">R@10</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.3.1.4.4.1">MMT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.2">36.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.3">72.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.4.4.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.4.4.4.1">84.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.5">39.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.6">76.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.4.4.7">86.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.8">6.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.9">21.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.4.4.10">33.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.11">7.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.12">22.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.13">34.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.5.5.1">ML-ACT</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.2">33.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.3">69.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.5.5.4">82.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.5">39.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.6">72.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.5.5.7">83.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.8">14.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.9">36.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.5.5.10">49.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.11">16.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.12">37.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.13">50.2</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.6.6.1">CLAP</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.2">34.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.3">70.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.6.6.4">82.0</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.5">41.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.6">41.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.6.6.7">84.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.8">16.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.9">41.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.6.6.10">54.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.11"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.6.6.11.1">20.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.12">44.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.13">58.7</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.7.7.1">CompA-CLAP</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.2">36.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.3">72.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.7.7.4">81.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.5">45.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.7.7.6.1">80.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.7.7.7">86.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.8">16.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.9">43.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.7.7.10">56.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.11">19.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.12"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.7.7.12.1">45.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.13">55.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.8.8.1">LAION-CLAP (repro.)</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.2">34.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.3">70.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.8.8.4">80.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.5">42.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.6">77.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.8.8.7">87.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.8">15.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.9">39.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.8.8.10">52.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.11">19.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.12">44.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.13">54.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.3.1.9.9.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.1.1" style="background-color:#F2F2F2;">CLAP-2.3M</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.2" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.2.1" style="background-color:#F2F2F2;">36.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.3" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.3.1" style="background-color:#F2F2F2;">72.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.9.9.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.4.1" style="background-color:#F2F2F2;">82.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.5" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.5.1" style="background-color:#F2F2F2;">46.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.6.1" style="background-color:#F2F2F2;">79.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.9.9.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.7.1" style="background-color:#F2F2F2;">87.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.8" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.8.1" style="background-color:#F2F2F2;">17.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.9" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.9.1" style="background-color:#F2F2F2;">43.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.9.9.10" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.10.1" style="background-color:#F2F2F2;">56.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.11" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.11.1" style="background-color:#F2F2F2;">19.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.12" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.12.1" style="background-color:#F2F2F2;">41.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.13" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.13.1" style="background-color:#F2F2F2;">56.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.10.10.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.1.1" style="background-color:#F2F2F2;">ReCLAP-660k</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.2.1" style="background-color:#F2F2F2;">35.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.3.1" style="background-color:#F2F2F2;">72.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.10.10.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.4.1" style="background-color:#F2F2F2;">82.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.5.1" style="background-color:#F2F2F2;">45.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.6.1" style="background-color:#F2F2F2;">79.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.10.10.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.7.1" style="background-color:#F2F2F2;">87.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.8.1" style="background-color:#F2F2F2;">16.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.9" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.10.10.9.1" style="background-color:#F2F2F2;">44.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.10.10.10" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.10.1" style="background-color:#F2F2F2;">55.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.11" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.11.1" style="background-color:#F2F2F2;">18.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.12" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.12.1" style="background-color:#F2F2F2;">42.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.13" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.10.10.13.1" style="background-color:#F2F2F2;">57.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.3.1.11.11.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.11.11.1.1" style="background-color:#F2F2F2;">ReCLAP</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.2" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.2.1" style="background-color:#F2F2F2;">37.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.3" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.3.1" style="background-color:#F2F2F2;">73.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.3.1.11.11.4" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.4.1" style="background-color:#F2F2F2;">85.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.5" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.5.1" style="background-color:#F2F2F2;">48.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.6" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.6.1" style="background-color:#F2F2F2;">80.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.3.1.11.11.7" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.7.1" style="background-color:#F2F2F2;">90.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.8" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.8.1" style="background-color:#F2F2F2;">18.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.9" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.9.1" style="background-color:#F2F2F2;">44.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.3.1.11.11.10" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.10.1" style="background-color:#F2F2F2;">59.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.11" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.11.1" style="background-color:#F2F2F2;">20.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.12" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.12.1" style="background-color:#F2F2F2;">45.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.13" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.13.1" style="background-color:#F2F2F2;">58.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">After training ReCLAP with rewritten captions, we can now employ ReCLAP for ZSAC. However, the standard approach for ZSAC is to handwrite a prompt template and use it for every category in the classification dataset (e.g.,<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">“The sound of a </span>{<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.2">category</span>}<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.3">”</span>), like  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>. However, this method has a major drawback: The prompt merely specifies the category without providing details about the unique acoustic characteristics of the audio concept corresponding to the category. This limits CLAP’s understanding of arbitrary categories in the wild, which are just abstract definitions of audio concepts. Therefore, incorporating descriptions of a category’s acoustic features into the prompt provides CLAP with an intermediate level of understanding regarding the expected sound of that category. Our proposed method also complements ReCLAP, which possesses additional knowledge about the acoustic features of many audio concepts.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.2">Thus, moving from one standard prompt for every category, we propose employing <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_N</annotation></semantics></math> custom prompts for every category in the dataset. Since manually hand-writing such custom prompts is infeasible, we instruct an LLM for this task. We instruct an LLM in two stages, with two different instructions. In the first stage, we instruct an LLM to describe the sound of each category label in <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_t</annotation></semantics></math> distinct ways,
focusing on its unique acoustic characteristics:</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<span class="ltx_ERROR undefined" id="S3.SS2.p3.1">{mdframed}</span>
<p class="ltx_p" id="S3.SS2.p3.2">[linewidth=1pt, linecolor=black, leftmargin=1pt, rightmargin=1pt, innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=4pt, innerbottommargin=2pt, backgroundcolor=gray!20, roundcorner=5pt]</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.1">(1) Category:</span> Bicycle bell (FSD50k)</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p5.1.1">(1) Acoustic Properties:</span> (i) metallic ring, (ii) high-pitched, tinkling chime <math alttext="\cdots" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p5.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">\cdots</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">⋯</annotation></semantics></math></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p6.1.1">(2) Category:</span> mallet (NSynth)</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p7.1.1">(2) Acoustic Properties:</span> (i) dull thud, (ii) resonant knock (iii) deep thump, <math alttext="\cdots" class="ltx_Math" display="inline" id="S3.SS2.p7.1.m1.1"><semantics id="S3.SS2.p7.1.m1.1a"><mi id="S3.SS2.p7.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p7.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.1.m1.1b"><ci id="S3.SS2.p7.1.m1.1.1.cmml" xref="S3.SS2.p7.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.1.m1.1c">\cdots</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.1.m1.1d">⋯</annotation></semantics></math></p>
</div>
<div class="ltx_para" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.1">Next, using these descriptions, we instruct an LLM to generate <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p8.1.m1.1"><semantics id="S3.SS2.p8.1.m1.1a"><mi id="S3.SS2.p8.1.m1.1.1" xref="S3.SS2.p8.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.1.m1.1b"><ci id="S3.SS2.p8.1.m1.1.1.cmml" xref="S3.SS2.p8.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.1.m1.1d">italic_n</annotation></semantics></math> different captions for each property, with the sound described in the category occurring in diverse scenes:</p>
</div>
<div class="ltx_para" id="S3.SS2.p9">
<span class="ltx_ERROR undefined" id="S3.SS2.p9.1">{mdframed}</span>
<p class="ltx_p" id="S3.SS2.p9.2">[linewidth=1pt, linecolor=black, leftmargin=1pt, rightmargin=1pt, innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=4pt, innerbottommargin=2pt, backgroundcolor=gray!20, roundcorner=5pt]
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p9.2.1">(1) Prompt Caption:</span> A bicycle bell’s clear, <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.p9.2.2">metallic ring</span> slices the silence as a rider announces their presence in the peaceful park.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p10">
<p class="ltx_p" id="S3.SS2.p10.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p10.1.1">(2) Prompt Caption:</span> The mallet’s <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.p10.1.2">dull thud</span> reverberated through the silent courtroom as the judge announced the verdict.</p>
</div>
<div class="ltx_para" id="S3.SS2.p11">
<p class="ltx_p" id="S3.SS2.p11.5">Finally, for every category, we randomly sample <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p11.1.m1.1"><semantics id="S3.SS2.p11.1.m1.1a"><mi id="S3.SS2.p11.1.m1.1.1" xref="S3.SS2.p11.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.1.m1.1b"><ci id="S3.SS2.p11.1.m1.1.1.cmml" xref="S3.SS2.p11.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.1.m1.1d">italic_N</annotation></semantics></math> unique prompts from the pool of <math alttext="n\times t" class="ltx_Math" display="inline" id="S3.SS2.p11.2.m2.1"><semantics id="S3.SS2.p11.2.m2.1a"><mrow id="S3.SS2.p11.2.m2.1.1" xref="S3.SS2.p11.2.m2.1.1.cmml"><mi id="S3.SS2.p11.2.m2.1.1.2" xref="S3.SS2.p11.2.m2.1.1.2.cmml">n</mi><mo id="S3.SS2.p11.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p11.2.m2.1.1.1.cmml">×</mo><mi id="S3.SS2.p11.2.m2.1.1.3" xref="S3.SS2.p11.2.m2.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.2.m2.1b"><apply id="S3.SS2.p11.2.m2.1.1.cmml" xref="S3.SS2.p11.2.m2.1.1"><times id="S3.SS2.p11.2.m2.1.1.1.cmml" xref="S3.SS2.p11.2.m2.1.1.1"></times><ci id="S3.SS2.p11.2.m2.1.1.2.cmml" xref="S3.SS2.p11.2.m2.1.1.2">𝑛</ci><ci id="S3.SS2.p11.2.m2.1.1.3.cmml" xref="S3.SS2.p11.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.2.m2.1c">n\times t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.2.m2.1d">italic_n × italic_t</annotation></semantics></math> total prompts. For ZSC, we mean pool <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p11.3.m3.1"><semantics id="S3.SS2.p11.3.m3.1a"><mi id="S3.SS2.p11.3.m3.1.1" xref="S3.SS2.p11.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.3.m3.1b"><ci id="S3.SS2.p11.3.m3.1.1.cmml" xref="S3.SS2.p11.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.3.m3.1d">italic_N</annotation></semantics></math> text embeddings corresponding to the prompts for every label (<math alttext="\mathbb{R}^{N\times d}\rightarrow\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS2.p11.4.m4.1"><semantics id="S3.SS2.p11.4.m4.1a"><mrow id="S3.SS2.p11.4.m4.1.1" xref="S3.SS2.p11.4.m4.1.1.cmml"><msup id="S3.SS2.p11.4.m4.1.1.2" xref="S3.SS2.p11.4.m4.1.1.2.cmml"><mi id="S3.SS2.p11.4.m4.1.1.2.2" xref="S3.SS2.p11.4.m4.1.1.2.2.cmml">ℝ</mi><mrow id="S3.SS2.p11.4.m4.1.1.2.3" xref="S3.SS2.p11.4.m4.1.1.2.3.cmml"><mi id="S3.SS2.p11.4.m4.1.1.2.3.2" xref="S3.SS2.p11.4.m4.1.1.2.3.2.cmml">N</mi><mo id="S3.SS2.p11.4.m4.1.1.2.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p11.4.m4.1.1.2.3.1.cmml">×</mo><mi id="S3.SS2.p11.4.m4.1.1.2.3.3" xref="S3.SS2.p11.4.m4.1.1.2.3.3.cmml">d</mi></mrow></msup><mo id="S3.SS2.p11.4.m4.1.1.1" stretchy="false" xref="S3.SS2.p11.4.m4.1.1.1.cmml">→</mo><msup id="S3.SS2.p11.4.m4.1.1.3" xref="S3.SS2.p11.4.m4.1.1.3.cmml"><mi id="S3.SS2.p11.4.m4.1.1.3.2" xref="S3.SS2.p11.4.m4.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS2.p11.4.m4.1.1.3.3" xref="S3.SS2.p11.4.m4.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.4.m4.1b"><apply id="S3.SS2.p11.4.m4.1.1.cmml" xref="S3.SS2.p11.4.m4.1.1"><ci id="S3.SS2.p11.4.m4.1.1.1.cmml" xref="S3.SS2.p11.4.m4.1.1.1">→</ci><apply id="S3.SS2.p11.4.m4.1.1.2.cmml" xref="S3.SS2.p11.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p11.4.m4.1.1.2.1.cmml" xref="S3.SS2.p11.4.m4.1.1.2">superscript</csymbol><ci id="S3.SS2.p11.4.m4.1.1.2.2.cmml" xref="S3.SS2.p11.4.m4.1.1.2.2">ℝ</ci><apply id="S3.SS2.p11.4.m4.1.1.2.3.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3"><times id="S3.SS2.p11.4.m4.1.1.2.3.1.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3.1"></times><ci id="S3.SS2.p11.4.m4.1.1.2.3.2.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3.2">𝑁</ci><ci id="S3.SS2.p11.4.m4.1.1.2.3.3.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3.3">𝑑</ci></apply></apply><apply id="S3.SS2.p11.4.m4.1.1.3.cmml" xref="S3.SS2.p11.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p11.4.m4.1.1.3.1.cmml" xref="S3.SS2.p11.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p11.4.m4.1.1.3.2.cmml" xref="S3.SS2.p11.4.m4.1.1.3.2">ℝ</ci><ci id="S3.SS2.p11.4.m4.1.1.3.3.cmml" xref="S3.SS2.p11.4.m4.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.4.m4.1c">\mathbb{R}^{N\times d}\rightarrow\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.4.m4.1d">blackboard_R start_POSTSUPERSCRIPT italic_N × italic_d end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.p11.5.m5.1"><semantics id="S3.SS2.p11.5.m5.1a"><mi id="S3.SS2.p11.5.m5.1.1" xref="S3.SS2.p11.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.5.m5.1b"><ci id="S3.SS2.p11.5.m5.1.1.cmml" xref="S3.SS2.p11.5.m5.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.5.m5.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.5.m5.1d">italic_d</annotation></semantics></math> is the shape of embedding output by CLAP). Finally, we calculate the cosine similarity between each audio embedding and all text embedding for all the labels for ZSAC.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Setup</span>
</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">ReCLAP Training Datasets.</span> We train ReCLAP from scratch on a collection of multiple datasets including Sound-VECaps <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib19" title="">19</a>]</cite> and CompA-660k <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>. Detailed statistics about each dataset are provided on our GitHub. Our dataset has <math alttext="\approx" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><approx id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">≈</annotation></semantics></math>2.3M audio-caption pairs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Evaluation Datasets.</span> For ZSAC, we adopt an evaluation setup similar to prior works <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> and employ AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib10" title="">10</a>]</cite>, ESC-50 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib11" title="">11</a>]</cite>, FSD50k <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib20" title="">20</a>]</cite>, NSynth <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib21" title="">21</a>]</cite>, TUT-Urban <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib22" title="">22</a>]</cite>, UrbanSound8K <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib23" title="">23</a>]</cite> and VGGSound <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib24" title="">24</a>]</cite>. We evaluate for accuracy on multi-class and mAP for multi-label.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.2"><span class="ltx_text ltx_font_bold" id="S4.p3.2.1">Model Architecture and Hyper-parameters.</span> We follow the same model architecture as CompA-CLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> with a T5 <sub class="ltx_sub" id="S4.p3.2.2">large</sub> text encoder <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib25" title="">25</a>]</cite> and HTSAT <sub class="ltx_sub" id="S4.p3.2.3">base</sub> audio encoder <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib26" title="">26</a>]</cite>. We train ReCLAP with a learning rate of 5e-4 and an effective batch size (BS) of 256. This BS is smaller than that in the literature, but we do so due to computational constraints. We employed <math alttext="k" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><mi id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">italic_k</annotation></semantics></math>=4 for caption and <math alttext="N" class="ltx_Math" display="inline" id="S4.p3.2.m2.1"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.1d">italic_N</annotation></semantics></math> = 2 for prompt augmentation.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span><span class="ltx_text" id="S4.T2.2.1" style="font-size:90%;">Performance comparison of ReCLAP with baselines on Zero-shot Audio classification benchmarks. ReCLAP outperforms baselines by 0.6%-54.8%.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.3" style="width:650.4pt;height:329.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(58.8pt,-29.8pt) scale(1.22076225264085,1.22076225264085) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt ltx_border_tt" colspan="2" id="S4.T2.3.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.2">ESC-50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.3">US8K</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.4">VGGSound</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.5">FSD50K</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.6">TUT</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.7">AudioSet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.8">NSynth</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.1.2.1.1" rowspan="7"><span class="ltx_text" id="S4.T2.3.1.2.1.1.1">w/o Prompt Aug.</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.1.2.1.2">Wav2CLIP</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.3">41.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.4">40.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.5">10.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.6">3.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.7">28.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.8">5.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.9">5.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.3.2.1">AudioClip</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.2">69.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.3">65.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.4">9.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.5">6.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.6">29.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.7">3.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.8">6.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.4.3.1">CLAP</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.2">82.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.3">73.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.4">16.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.5">14.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.6">29.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.7">5.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.8">9.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.5.4.1">LAION-CLAP (repro.)</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.2">88.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.3">74.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.4">21.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.5">22.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.6">58.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.7">20.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.8">11.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.6.5.1">CoLLAT</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.2">84.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.3">77.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.5">19.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.6">29.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.7">9.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.8">-</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.7.6.1">CompA-CLAP</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.2">86.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.3">88.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.4">21.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.5">19.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.6">56.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.7">21.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.8">11.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.8.7.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.1.1" style="background-color:#F2F2F2;">CLAP-2.3M</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.2.1" style="background-color:#F2F2F2;">88.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.3.1" style="background-color:#F2F2F2;">90.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.4.1" style="background-color:#F2F2F2;">24.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.5.1" style="background-color:#F2F2F2;">30.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.6.1" style="background-color:#F2F2F2;">61.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.7.1" style="background-color:#F2F2F2;">21.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.8.1" style="background-color:#F2F2F2;">11.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.9.8.1">
<span class="ltx_ERROR undefined" id="S4.T2.3.1.9.8.1.1">\cdashline</span>2-9</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.9.8.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.2.1" style="background-color:#F2F2F2;">ReCLAP</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.3.1" style="background-color:#F2F2F2;">90.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.4.1" style="background-color:#F2F2F2;">94.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.5.1" style="background-color:#F2F2F2;">24.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.6.1" style="background-color:#F2F2F2;">27.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.7.1" style="background-color:#F2F2F2;">63.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.8.1" style="background-color:#F2F2F2;">23.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.9" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.9.1" style="background-color:#F2F2F2;">11.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T2.3.1.10.9.1" rowspan="5"><span class="ltx_text" id="S4.T2.3.1.10.9.1.1">w/ Prompt Aug.</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T2.3.1.10.9.2">CLAP</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.3">83.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.4">74.5</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.5">16.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.6">14.9</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.7">33.7</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.8">6.2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.9">10.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.11.10.1">LAION-CLAP (repro.)</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.2">89.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.3">76.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.4">23.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.5">24.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.6">61.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.7">21.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.8">12.4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.12.11.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.1.1" style="background-color:#F2F2F2;">CLAP-2.3M</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.2.1" style="background-color:#F2F2F2;">89.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.3.1" style="background-color:#F2F2F2;">91.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.4.1" style="background-color:#F2F2F2;">25.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.5" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.12.11.5.1" style="background-color:#F2F2F2;">37.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.6.1" style="background-color:#F2F2F2;">63.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.7.1" style="background-color:#F2F2F2;">23.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.8.1" style="background-color:#F2F2F2;">13.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.13.12.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.1.1" style="background-color:#F2F2F2;">ReCLAP-660k</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.2.1" style="background-color:#F2F2F2;">89.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.3.1" style="background-color:#F2F2F2;">79.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.4.1" style="background-color:#F2F2F2;">25.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.5.1" style="background-color:#F2F2F2;">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.6.1" style="background-color:#F2F2F2;">60.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.7.1" style="background-color:#F2F2F2;">22.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.8.1" style="background-color:#F2F2F2;">13.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.14.13.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.14.13.1.1" style="background-color:#F2F2F2;">ReCLAP w/ only desc.</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.2" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.2.1" style="background-color:#F2F2F2;">89.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.3" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.3.1" style="background-color:#F2F2F2;">92.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.4" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.4.1" style="background-color:#F2F2F2;">26.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.14.13.5.1" style="background-color:#F2F2F2;">37.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.6" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.6.1" style="background-color:#F2F2F2;">65.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.7" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.7.1" style="background-color:#F2F2F2;">25.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.8" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.8.1" style="background-color:#F2F2F2;">14.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T2.3.1.15.14.1">
<span class="ltx_ERROR undefined" id="S4.T2.3.1.15.14.1.1">\cdashline</span>2-9</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T2.3.1.15.14.2" style="background-color:#D9D9D9;"><span class="ltx_text" id="S4.T2.3.1.15.14.2.1" style="background-color:#D9D9D9;">ReCLAP</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.3" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.3.1" style="background-color:#D9D9D9;">92.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.4" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.4.1" style="background-color:#D9D9D9;">95.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.5" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.5.1" style="background-color:#D9D9D9;">29.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.6" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.6.1" style="background-color:#D9D9D9;">40.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.7" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.7.1" style="background-color:#D9D9D9;">67.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.8" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.8.1" style="background-color:#D9D9D9;">26.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.9" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.9.1" style="background-color:#D9D9D9;">14.7</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.p4.1.1">Baselines.</span> We use the following baselines for comparison: MMT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib27" title="">27</a>]</cite>, ML-ACT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib28" title="">28</a>]</cite>, CLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>, CompA-CLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>, LAION-CLAP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>]</cite> and LAION-CLAP <span class="ltx_text ltx_font_italic" id="S4.p4.1.2">(ours)</span> (reproduced with BS=256 and excluding non-open-source datasets). For ZSAC, we compare with all the baselines mentioned earlier as well as Wav2CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib29" title="">29</a>]</cite>, AudioClip <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib30" title="">30</a>]</cite>, CoLLAT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib7" title="">7</a>]</cite> and ReCLAP w/ only desc. where we only employ <math alttext="t" class="ltx_Math" display="inline" id="S4.p4.1.m1.1"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.p4.1.m1.1d">italic_t</annotation></semantics></math> acoustic properties as prompts and don’t generate captions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p5">
<p class="ltx_p" id="S4.p5.2"><span class="ltx_text ltx_font_bold" id="S4.p5.2.1">Ablations.</span> We perform several ablations to prove the effectiveness of our approach. <span class="ltx_text ltx_font_bold" id="S4.p5.2.2">For multi-modal retrieval:</span> (i) ReCLAP-660k: ReCLAP trained with caption augmentations on 660k pairs from  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>; (ii) CLAP-2.3M.: CLAP trained on our 2.3M audio-caption dataset (without caption augmentations). <span class="ltx_text ltx_font_bold" id="S4.p5.2.3">For ZSAC:</span> For ZSAC we add another ablation which is: ReCLAP w/ only desc: ZSAC with ReCLAP with only the <math alttext="t" class="ltx_Math" display="inline" id="S4.p5.1.m1.1"><semantics id="S4.p5.1.m1.1a"><mi id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><ci id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.p5.1.m1.1d">italic_t</annotation></semantics></math> descriptions as prompts from the prompt augmentation stage and do not generate the <math alttext="N" class="ltx_Math" display="inline" id="S4.p5.2.m2.1"><semantics id="S4.p5.2.m2.1a"><mi id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b"><ci id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.p5.2.m2.1d">italic_N</annotation></semantics></math> diverse scenario prompts.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.T1" title="TABLE I ‣ III-B Prompt Augmentation for ZSAC ‣ III Methodology ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">I</span></a> compares ReCLAP to prior works on AudioCaps and Clotho for text-to-audio and audio-to-text retrieval, showing SOTA performance in most cases. ReCLAP-660k, trained on the same data as CompA-CLAP, surpasses it on all metrics, and similar results are seen for CLAP-2.3M vs. ReCLAP. This demonstrates that ReCLAP’s improvements are not due to dataset size alone. Inspired by  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>, we argue that current benchmarks do not fully capture ReCLAP’s capabilities in free-form T-A and A-T retrieval.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S4.T2" title="TABLE II ‣ IV Experimental Setup ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">II</span></a> compares our prompt augmentation method (“w/ Prompt Aug”) with standard template-based prompting (“w/o Prompt Aug”). Prompt augmentation consistently outperforms baselines, with gains of 0.6%-54.8%. ReCLAP shows a 0.9%-17.5% improvement with prompt augmentation. In contrast, CLAP and LAION-CLAP show limited gains, indicating they don’t interpret sound descriptions as effectively as ReCLAP. This highlights the importance of caption augmentation training as a prior step.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Result Analysis</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S6.F2" title="Figure 2 ‣ VI Result Analysis ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates how ReCLAP and prompt augmentation increase the number of correct predictions for 4 labels from different datasets on ZSAC. As we can see, training CLAP on caption augmentation on the same dataset (CLAP-2.3M vs ReCLAP) improves retrieval of the correct label, which is further boosted by prompt augmentation.</p>
</div>
<figure class="ltx_figure" id="S6.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="S6.F2.g1" src="x2.png" width="300"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text" id="S6.F2.2.1" style="font-size:90%;">Comparison of accurately classified instances for 4 labels.</span></figcaption>
</figure>
<figure class="ltx_table" id="S6.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span><span class="ltx_text" id="S6.T3.2.1" style="font-size:90%;">Examples of ambiguous labels where prompt augmentations provide additional context.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S6.T3.3" style="width:433.6pt;height:183.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(25.5pt,-10.8pt) scale(1.13323389690788,1.13323389690788) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T3.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T3.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S6.T3.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T3.3.1.1.1.1.1">Label</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S6.T3.3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T3.3.1.1.1.2.1">Prompt Augmentation</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.3.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.2.1.1">metro station (TUT)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.2.1.2">A metallic rhapsody performed by the tireless locomotives,</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.3.2">
<td class="ltx_td" id="S6.T3.3.1.3.2.1"></td>
<td class="ltx_td ltx_align_left" id="S6.T3.3.1.3.2.2">with a recurring refrain from the station’s vocal spirit.</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.4.3.1">airport (TUT)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.4.3.2">A chorus of engines hums persistently, interspersed with the</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.5.4">
<td class="ltx_td" id="S6.T3.3.1.5.4.1"></td>
<td class="ltx_td ltx_align_left" id="S6.T3.3.1.5.4.2">murmur of voices and authoritative announcements.</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.6.5.1">organ (NSynth)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.6.5.2">The organ unfurled a tapestry of majestic harmonies, filling</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.7.6">
<td class="ltx_td" id="S6.T3.3.1.7.6.1"></td>
<td class="ltx_td ltx_align_left" id="S6.T3.3.1.7.6.2">the cathedral with its thunderous hymn.</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.8.7.1">writing (FSD50K)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.8.7.2">In the hush of the library, the rhythmic scratch of pen on</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.9.8">
<td class="ltx_td ltx_border_bb" id="S6.T3.3.1.9.8.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T3.3.1.9.8.2">paper becomes a soft dance of intellect and ink.</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">For example, the sound of an "organ" could refer to either a human organ or a musical instrument. By adding useful contextual information, prompt augmentations assist in clarifying such ambiguities, leading to more accurate retrievals.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Hyper-parameter Tuning</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.4">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S7.T4" title="TABLE IV ‣ VII Hyper-parameter Tuning ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">IV</span></a> compares performance across <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.1.m1.1"><semantics id="S7.p1.1.m1.1a"><mi id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><ci id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.1.m1.1d">italic_N</annotation></semantics></math>={1,2,3,4,5} to show the effect of the number of custom prompts <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.2.m2.1"><semantics id="S7.p1.2.m2.1a"><mi id="S7.p1.2.m2.1.1" xref="S7.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.2.m2.1b"><ci id="S7.p1.2.m2.1.1.cmml" xref="S7.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.2.m2.1d">italic_N</annotation></semantics></math> on the final ZSAC performance. As we see, the optimal performance is achieved at <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.3.m3.1"><semantics id="S7.p1.3.m3.1a"><mi id="S7.p1.3.m3.1.1" xref="S7.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.3.m3.1b"><ci id="S7.p1.3.m3.1.1.cmml" xref="S7.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.3.m3.1d">italic_N</annotation></semantics></math>=2, and model performance decreases with an increase in <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.4.m4.1"><semantics id="S7.p1.4.m4.1a"><mi id="S7.p1.4.m4.1.1" xref="S7.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.4.m4.1b"><ci id="S7.p1.4.m4.1.1.cmml" xref="S7.p1.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.4.m4.1d">italic_N</annotation></semantics></math>. This decline is hypothesized to be due to the introduction of more noise into the process with each additional caption.</p>
</div>
<figure class="ltx_table" id="S7.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span><span class="ltx_text" id="S7.T4.2.1" style="font-size:90%;">Impact of <math alttext="N" class="ltx_Math" display="inline" id="S7.T4.2.1.m1.1"><semantics id="S7.T4.2.1.m1.1b"><mi id="S7.T4.2.1.m1.1.1" xref="S7.T4.2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.T4.2.1.m1.1c"><ci id="S7.T4.2.1.m1.1.1.cmml" xref="S7.T4.2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.2.1.m1.1d">N</annotation><annotation encoding="application/x-llamapun" id="S7.T4.2.1.m1.1e">italic_N</annotation></semantics></math> on ZSAC with ReCLAP.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T4.3" style="width:325.2pt;height:56.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(59.3pt,-10.3pt) scale(1.57425286235649,1.57425286235649) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T4.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S7.T4.3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S7.T4.3.1.1.1"><math alttext="N" class="ltx_Math" display="inline" id="S7.T4.3.1.1.1.m1.1"><semantics id="S7.T4.3.1.1.1.m1.1a"><mi id="S7.T4.3.1.1.1.m1.1.1" xref="S7.T4.3.1.1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.T4.3.1.1.1.m1.1b"><ci id="S7.T4.3.1.1.1.m1.1.1.cmml" xref="S7.T4.3.1.1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.3.1.1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.T4.3.1.1.1.m1.1d">italic_N</annotation></semantics></math></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.2">1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.3">2</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.4">3</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.5">4</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.6">5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T4.3.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S7.T4.3.1.2.1.1">Score</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.2">48.56</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S7.T4.3.1.2.1.3.1">52.22</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S7.T4.3.1.2.1.4.1">49.37</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.5">47.24</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.6">44.35</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Additionally, Table <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S7.T5" title="TABLE V ‣ VII Hyper-parameter Tuning ‣ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">V</span></a> shows the effect of probability <math alttext="p" class="ltx_Math" display="inline" id="S7.p2.1.m1.1"><semantics id="S7.p2.1.m1.1a"><mi id="S7.p2.1.m1.1.1" xref="S7.p2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.p2.1.m1.1b"><ci id="S7.p2.1.m1.1.1.cmml" xref="S7.p2.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p2.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S7.p2.1.m1.1d">italic_p</annotation></semantics></math> on the final ZSAC performance.</p>
</div>
<figure class="ltx_table" id="S7.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE V: </span><span class="ltx_text" id="S7.T5.2.1" style="font-size:90%;">Impact of <math alttext="p" class="ltx_Math" display="inline" id="S7.T5.2.1.m1.1"><semantics id="S7.T5.2.1.m1.1b"><mi id="S7.T5.2.1.m1.1.1" xref="S7.T5.2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.T5.2.1.m1.1c"><ci id="S7.T5.2.1.m1.1.1.cmml" xref="S7.T5.2.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.2.1.m1.1d">p</annotation><annotation encoding="application/x-llamapun" id="S7.T5.2.1.m1.1e">italic_p</annotation></semantics></math> on ZSAC with ReCLAP.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T5.3" style="width:325.2pt;height:65.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(73.7pt,-14.9pt) scale(1.82904540884783,1.82904540884783) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T5.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S7.T5.3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S7.T5.3.1.1.1"><math alttext="p" class="ltx_Math" display="inline" id="S7.T5.3.1.1.1.m1.1"><semantics id="S7.T5.3.1.1.1.m1.1a"><mi id="S7.T5.3.1.1.1.m1.1.1" xref="S7.T5.3.1.1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.T5.3.1.1.1.m1.1b"><ci id="S7.T5.3.1.1.1.m1.1.1.cmml" xref="S7.T5.3.1.1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.3.1.1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S7.T5.3.1.1.1.m1.1d">italic_p</annotation></semantics></math></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.2">0.2</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.3">0.4</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.4">0.6</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.5">0.8</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T5.3.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.3.1.2.1.1">Score</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.2">47.16</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S7.T5.3.1.2.1.3.1">52.22</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S7.T5.3.1.2.1.4.1">48.29</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.5">45.64</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span class="ltx_text ltx_font_smallcaps" id="S8.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">In this paper, we propose to improve ZSAC by interpreting sounds using their descriptive features. To achieve this, we first propose ReCLAP, a CLAP model trained using additional caption augmentations that improve CLAP’s understanding of sounds in the wild. Next, we propose to improve ZSAC with prompt augmentation, where we move beyond standard hand-written prompts and generate custom prompts for each category in the dataset. Our proposed method improves ZSAC over our baselines by significant margins.</p>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IX </span><span class="ltx_text ltx_font_smallcaps" id="S9.1.1">Limitations and Future Work</span>
</h2>
<div class="ltx_para" id="S9.p1">
<ol class="ltx_enumerate" id="S9.I1">
<li class="ltx_item" id="S9.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S9.I1.i1.p1">
<p class="ltx_p" id="S9.I1.i1.p1.1">LLM-generated augmentations may result in errors or repetitive captions, which require substantial human oversight. Future work will explore methods to improve quality control.</p>
</div>
</li>
<li class="ltx_item" id="S9.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S9.I1.i2.p1">
<p class="ltx_p" id="S9.I1.i2.p1.1">Synthetic augmentations from LLMs may introduce biases into models. Future efforts will focus on mitigating these biases.</p>
</div>
</li>
<li class="ltx_item" id="S9.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S9.I1.i3.p1">
<p class="ltx_p" id="S9.I1.i3.p1.1">Representations from ReCLAP can be employed to improve a range of tasks, including audio generation and understanding. Future work includes exploring these tasks.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Benjamin Elizalde, Soham Deshmukh, Mahmoud Al Ismail, and Huaming Wang,

</span>
<span class="ltx_bibblock">“Clap learning audio concepts from natural language supervision,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2023, pp. 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Sreyan Ghosh, Ashish Seth, Sonal Kumar, Utkarsh Tyagi, Chandra Kiran Reddy Evuru, Ramaneswaran S, S Sakshi, Oriol Nieto, Ramani Duraiswami, and Dinesh Manocha,

</span>
<span class="ltx_bibblock">“Compa: Addressing the gap in compositional reasoning in audio-language models,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Soham Deshmukh, Benjamin Elizalde, Rita Singh, and Huaming Wang,

</span>
<span class="ltx_bibblock">“Pengi: An audio language model for audio tasks,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Zhifeng Kong, Arushi Goel, Rohan Badlani, Wei Ping, Rafael Valle, and Bryan Catanzaro,

</span>
<span class="ltx_bibblock">“Audio flamingo: A novel audio language model with few-shot learning and dialogue abilities,” 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Sreyan Ghosh, Sonal Kumar, Chandra Kiran Reddy Evuru, Ramani Duraiswami, and Dinesh Manocha,

</span>
<span class="ltx_bibblock">“Recap: Retrieval-augmented audio captioning,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and Mark D Plumbley,

</span>
<span class="ltx_bibblock">“Audioldm: Text-to-audio generation with latent diffusion models,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2301.12503</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Amila Silva, Spencer Whitehead, Chris Lengerich, and Hugh James Leather,

</span>
<span class="ltx_bibblock">“CoLLAT: On adding fine-grained audio understanding to language models using token-level locked-language tuning,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Thirty-seventh Conference on Neural Information Processing Systems</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.,

</span>
<span class="ltx_bibblock">“Learning transferable visual models from natural language supervision,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">International conference on machine learning</span>. PMLR, 2021, pp. 8748–8763.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Tiago Tavares, Fabio Ayres, Zhepei Wang, and Paris Smaragdis,

</span>
<span class="ltx_bibblock">“On class separability pitfalls in audio-text contrastive zero-shot learning,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2408.13068</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Jort F Gemmeke, Daniel PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R Channing Moore, Manoj Plakal, and Marvin Ritter,

</span>
<span class="ltx_bibblock">“Audio set: An ontology and human-labeled dataset for audio events,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span>. IEEE, 2017, pp. 776–780.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Karol J. Piczak,

</span>
<span class="ltx_bibblock">“ESC: Dataset for Environmental Sound Classification,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 23rd Annual ACM Conference on Multimedia</span>. pp. 1015–1018, ACM Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Il-Young Jeong and Jeongsoo Park,

</span>
<span class="ltx_bibblock">“Cochlscene: Acquisition of acoustic scene data using crowdsourcing,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">2022 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</span>. IEEE, 2022, pp. 17–21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Yusong Wu*, Ke Chen*, Tianyu Zhang*, Yuchen Hui*, Taylor Berg-Kirkpatrick, and Shlomo Dubnov,

</span>
<span class="ltx_bibblock">“Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Deepanway Ghosal, Navonil Majumder, Ambuj Mehrish, and Soujanya Poria,

</span>
<span class="ltx_bibblock">“Text-to-audio generation using instruction tuned llm and latent diffusion model,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2304.13731</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao,

</span>
<span class="ltx_bibblock">“Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2301.12661</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Andrea Agostinelli, Timo I. Denk, Zalán Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco Tagliasacchi, Matt Sharifi, Neil Zeghidour, and Christian Frank,

</span>
<span class="ltx_bibblock">“Musiclm: Generating music from text,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Yuan Gong, Hongyin Luo, Alexander H. Liu, Leonid Karlinsky, and James R. Glass,

</span>
<span class="ltx_bibblock">“Listen, think, and understand,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Hugo Touvron et al.,

</span>
<span class="ltx_bibblock">“Llama 2: Open foundation and fine-tuned chat models,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Yi Yuan, Dongya Jia, Xiaobin Zhuang, Yuanzhe Chen, Zhengxi Liu, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xubo Liu, Mark D Plumbley, et al.,

</span>
<span class="ltx_bibblock">“Improving audio generation with visual enhanced caption,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2407.04416</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Eduardo Fonseca, Xavier Favory, Jordi Pons, Frederic Font, and Xavier Serra,

</span>
<span class="ltx_bibblock">“Fsd50k: An open dataset of human-labeled sound events,” 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Jesse Engel, Cinjon Resnick, Adam Roberts, Sander Dieleman, Mohammad Norouzi, Douglas Eck, and Karen Simonyan,

</span>
<span class="ltx_bibblock">“Neural audio synthesis of musical notes with wavenet autoencoders,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">International Conference on Machine Learning</span>. PMLR, 2017, pp. 1068–1077.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Annamaria Mesaros, Toni Heittola, and Tuomas Virtanen,

</span>
<span class="ltx_bibblock">“A multi-device dataset for urban acoustic scene classification,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:1807.09840</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Justin Salamon and Juan Pablo Bello,

</span>
<span class="ltx_bibblock">“Deep convolutional neural networks and data augmentation for environmental sound classification,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">IEEE Signal processing letters</span>, vol. 24, no. 3, pp. 279–283, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Honglie Chen, Weidi Xie, Andrea Vedaldi, and Andrew Zisserman,

</span>
<span class="ltx_bibblock">“Vggsound: A large-scale audio-visual dataset,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu,

</span>
<span class="ltx_bibblock">“Exploring the limits of transfer learning with a unified text-to-text transformer,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Journal of Machine Learning Research</span>, vol. 21, no. 140, pp. 1–67, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Ke Chen, Xingjian Du, Bilei Zhu, Zejun Ma, Taylor Berg-Kirkpatrick, and Shlomo Dubnov,

</span>
<span class="ltx_bibblock">“Hts-at: A hierarchical token-semantic audio transformer for sound classification and detection,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">ICASSP 2022</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Andreea-Maria Oncescu, A Koepke, Joao F Henriques, Zeynep Akata, and Samuel Albanie,

</span>
<span class="ltx_bibblock">“Audio retrieval with natural language queries,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2105.02192</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Xinhao Mei, Xubo Liu, Jianyuan Sun, Mark D Plumbley, and Wenwu Wang,

</span>
<span class="ltx_bibblock">“On metric learning for audio-text cross-modal retrieval,”

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2203.15537</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ho-Hsiang Wu, Prem Seetharaman, Kundan Kumar, and Juan Pablo Bello,

</span>
<span class="ltx_bibblock">“Wav2clip: Learning robust audio representations from clip,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">ICASSP 2022</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Andrey Guzhov, Federico Raue, Jörn Hees, and Andreas Dengel,

</span>
<span class="ltx_bibblock">“Audioclip: Extending clip to image, text and audio,”

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">ICASSP 2022</span>, 2022.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 13 21:52:14 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
