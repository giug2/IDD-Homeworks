<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds</title>
<!--Generated on Fri Sep 13 21:52:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.09213v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S1" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S2" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.SS1" title="In III Methodology â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Caption Augmentation for ReCLAP</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.SS2" title="In III Methodology â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Prompt Augmentation for ZSAC</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S4" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental Setup</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S5" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S6" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Result Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S7" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Hyper-parameter Tuning</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S8" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VIII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S9" title="In ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IX </span><span class="ltx_text ltx_font_smallcaps">Limitations and Future Work</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Â <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="28" id="id1.g1" src="extracted/5852114/reclap.png" width="28"/> ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sreyan Ghosh<sup class="ltx_sup" id="id10.9.id1"><span class="ltx_text ltx_font_italic" id="id10.9.id1.1">â™ </span></sup> â€ƒSonal Kumar<math alttext="{}^{\spadesuit\vardiamondsuit}" class="ltx_Math" display="inline" id="id3.2.m2.1"><semantics id="id3.2.m2.1a"><msup id="id3.2.m2.1.1" xref="id3.2.m2.1.1.cmml"><mi id="id3.2.m2.1.1a" xref="id3.2.m2.1.1.cmml"></mi><mrow id="id3.2.m2.1.1.1" xref="id3.2.m2.1.1.1.cmml"><mi id="id3.2.m2.1.1.1.2" mathvariant="normal" xref="id3.2.m2.1.1.1.2.cmml">â™ </mi><mo id="id3.2.m2.1.1.1.1" xref="id3.2.m2.1.1.1.1.cmml">â¢</mo><merror class="ltx_ERROR undefined undefined" id="id3.2.m2.1.1.1.3" xref="id3.2.m2.1.1.1.3b.cmml"><mtext id="id3.2.m2.1.1.1.3a" xref="id3.2.m2.1.1.1.3b.cmml">\vardiamondsuit</mtext></merror></mrow></msup><annotation-xml encoding="MathML-Content" id="id3.2.m2.1b"><apply id="id3.2.m2.1.1.cmml" xref="id3.2.m2.1.1"><apply id="id3.2.m2.1.1.1.cmml" xref="id3.2.m2.1.1.1"><times id="id3.2.m2.1.1.1.1.cmml" xref="id3.2.m2.1.1.1.1"></times><ci id="id3.2.m2.1.1.1.2.cmml" xref="id3.2.m2.1.1.1.2">â™ </ci><ci id="id3.2.m2.1.1.1.3b.cmml" xref="id3.2.m2.1.1.1.3"><merror class="ltx_ERROR undefined undefined" id="id3.2.m2.1.1.1.3.cmml" xref="id3.2.m2.1.1.1.3"><mtext id="id3.2.m2.1.1.1.3a.cmml" xref="id3.2.m2.1.1.1.3">\vardiamondsuit</mtext></merror></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.2.m2.1c">{}^{\spadesuit\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id3.2.m2.1d">start_FLOATSUPERSCRIPT â™  end_FLOATSUPERSCRIPT</annotation></semantics></math> â€ƒChandra Kiran Reddy Evuru <math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id4.3.m3.1"><semantics id="id4.3.m3.1a"><msup id="id4.3.m3.1.1" xref="id4.3.m3.1.1.cmml"><mi id="id4.3.m3.1.1a" xref="id4.3.m3.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id4.3.m3.1.1.1" xref="id4.3.m3.1.1.1b.cmml"><mtext id="id4.3.m3.1.1.1a" xref="id4.3.m3.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id4.3.m3.1b"><apply id="id4.3.m3.1.1.cmml" xref="id4.3.m3.1.1"><ci id="id4.3.m3.1.1.1b.cmml" xref="id4.3.m3.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id4.3.m3.1.1.1.cmml" xref="id4.3.m3.1.1.1"><mtext id="id4.3.m3.1.1.1a.cmml" xref="id4.3.m3.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.3.m3.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id4.3.m3.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math> â€ƒOriol Nieto<math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id5.4.m4.1"><semantics id="id5.4.m4.1a"><msup id="id5.4.m4.1.1" xref="id5.4.m4.1.1.cmml"><mi id="id5.4.m4.1.1a" xref="id5.4.m4.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id5.4.m4.1.1.1" xref="id5.4.m4.1.1.1b.cmml"><mtext id="id5.4.m4.1.1.1a" xref="id5.4.m4.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id5.4.m4.1b"><apply id="id5.4.m4.1.1.cmml" xref="id5.4.m4.1.1"><ci id="id5.4.m4.1.1.1b.cmml" xref="id5.4.m4.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id5.4.m4.1.1.1.cmml" xref="id5.4.m4.1.1.1"><mtext id="id5.4.m4.1.1.1a.cmml" xref="id5.4.m4.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.4.m4.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id5.4.m4.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"/>Ramani Duraiswami<math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id6.5.m5.1"><semantics id="id6.5.m5.1a"><msup id="id6.5.m5.1.1" xref="id6.5.m5.1.1.cmml"><mi id="id6.5.m5.1.1a" xref="id6.5.m5.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id6.5.m5.1.1.1" xref="id6.5.m5.1.1.1b.cmml"><mtext id="id6.5.m5.1.1.1a" xref="id6.5.m5.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id6.5.m5.1b"><apply id="id6.5.m5.1.1.cmml" xref="id6.5.m5.1.1"><ci id="id6.5.m5.1.1.1b.cmml" xref="id6.5.m5.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id6.5.m5.1.1.1.cmml" xref="id6.5.m5.1.1.1"><mtext id="id6.5.m5.1.1.1a.cmml" xref="id6.5.m5.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.5.m5.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id6.5.m5.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math> â€ƒDinesh Manocha<math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id7.6.m6.1"><semantics id="id7.6.m6.1a"><msup id="id7.6.m6.1.1" xref="id7.6.m6.1.1.cmml"><mi id="id7.6.m6.1.1a" xref="id7.6.m6.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id7.6.m6.1.1.1" xref="id7.6.m6.1.1.1b.cmml"><mtext id="id7.6.m6.1.1.1a" xref="id7.6.m6.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id7.6.m6.1b"><apply id="id7.6.m6.1.1.cmml" xref="id7.6.m6.1.1"><ci id="id7.6.m6.1.1.1b.cmml" xref="id7.6.m6.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id7.6.m6.1.1.1.cmml" xref="id7.6.m6.1.1.1"><mtext id="id7.6.m6.1.1.1a.cmml" xref="id7.6.m6.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.6.m6.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id7.6.m6.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><sup class="ltx_sup" id="id11.10.id1"><span class="ltx_text ltx_font_italic" id="id11.10.id1.1">â™ </span></sup>University of Maryland, College Park, MD, USA â€ƒ<math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id9.8.m2.1"><semantics id="id9.8.m2.1a"><msup id="id9.8.m2.1.1" xref="id9.8.m2.1.1.cmml"><mi id="id9.8.m2.1.1a" xref="id9.8.m2.1.1.cmml"></mi><merror class="ltx_ERROR undefined undefined" id="id9.8.m2.1.1.1" xref="id9.8.m2.1.1.1b.cmml"><mtext id="id9.8.m2.1.1.1a" xref="id9.8.m2.1.1.1b.cmml">\vardiamondsuit</mtext></merror></msup><annotation-xml encoding="MathML-Content" id="id9.8.m2.1b"><apply id="id9.8.m2.1.1.cmml" xref="id9.8.m2.1.1"><ci id="id9.8.m2.1.1.1b.cmml" xref="id9.8.m2.1.1.1"><merror class="ltx_ERROR undefined undefined" id="id9.8.m2.1.1.1.cmml" xref="id9.8.m2.1.1.1"><mtext id="id9.8.m2.1.1.1a.cmml" xref="id9.8.m2.1.1.1">\vardiamondsuit</mtext></merror></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.8.m2.1c">{}^{\vardiamondsuit}</annotation><annotation encoding="application/x-llamapun" id="id9.8.m2.1d">start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT</annotation></semantics></math>Adobe Research, San Francisco, CA, USA 
<br class="ltx_break"/>{sreyang, sonalkum, ckevuru, ramanid, dmanocha}@umd.edu
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id12.id1">Open-vocabulary audio-language models, like CLAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>, offer a promising approach for zero-shot audio classification (ZSAC) by enabling classification with any arbitrary set of categories specified with natural language prompts. In this paper, we propose a simple but effective method to improve ZSAC with CLAP. Specifically, we shift from the conventional method of using prompts with abstract category labels (e.g.,Â <span class="ltx_text ltx_font_italic" id="id12.id1.1">Sound of an organ</span>) to prompts that describe sounds using their inherent descriptive features in a diverse context (e.g.,Â <span class="ltx_text ltx_font_italic" id="id12.id1.2">The organâ€™s deep and resonant tones filled the cathedral.</span>). To achieve this, we first propose <span class="ltx_text ltx_font_bold" id="id12.id1.3">ReCLAP</span>, a CLAP model trained with <span class="ltx_text ltx_framed ltx_framed_underline" id="id12.id1.4">re</span>written audio captions for improved understanding of sounds in the wild. These rewritten captions describe each sound event in the original caption using their unique discriminative characteristics. ReCLAP outperforms all baselines on both multi-modal audio-text retrieval and ZSAC. Next, to improve zero-shot audio classification with ReCLAP, we propose <span class="ltx_text ltx_font_italic" id="id12.id1.5">prompt augmentation</span>. In contrast to the traditional method of employing hand-written template prompts, we generate custom prompts for each unique label in the dataset. These custom prompts first describe the sound event in the label and then employ them in diverse scenes. Our proposed method improves ReCLAPâ€™s performance on ZSAC by 1%-18% and outperforms all baselines by 1% - 55%<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code and Checkpoints: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/Sreyan88/ReCLAP</span></span></span></span>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Audio classification, the foundational task of assigning a category label to an audio sample, remains one of the most important tasks in audio processing and has numerous real-world applications. Zero-shot audio classification (ZSAC) presents a promising approach that provides greater flexibility at the inference stage than supervised methods. Unlike supervised methods that map input audio to a fixed set of categories, models classify by computing a similarity score between an input audio example and a caption. To perform inference, one can generate a caption or â€œpromptâ€ associated with each desired category and match each audio sample to the best prompt. This means that categories can be selected ad hoc and adjusted without additional training.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Open-vocabulary audio-language models like Contrastive Language-Audio Pre-training (CLAP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite> have outperformed most other models on ZSAC. CLAP is trained on contrastive objectives between audio-caption pairs, where each audio sample corresponds to non-speech sounds and non-verbal speech, and the captions describe the acoustic events and the scene, not the spoken content. Beyond ZSAC, CLAP has also achieved superior performance on cross-modal audio-text retrievalÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> and has been used as a backbone audio encoder for a variety of audio-language tasks, including generalist audio agentsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib3" title="">3</a>]</cite>, open-domain chat assistantsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib4" title="">4</a>]</cite>, audio captioningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib5" title="">5</a>]</cite> and text-to-audio generationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib6" title="">6</a>]</cite>. However, ZSAC with CLAP currently remains subpar compared to standard supervised methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib7" title="">7</a>]</cite>. We attribute this to 3 main reasons:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Limited access to large-scale audio-caption datasets</span>: Unlike CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib8" title="">8</a>]</cite>, CLAP has not been trained on large-scale, open-source audio-caption datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>. This constrains its ability to fully understand and perceive the diverse range of audio and language interactionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Lack of generalization beyond training category labels</span>: CLAP struggles to generalize beyond the specific category labels used in its training prompts. For instance, research by Tiago <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.2">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib9" title="">9</a>]</cite> indicates that a modelâ€™s ZSAC accuracy is closely related to the clusters in its audio embedding space. Consequently, if CLAP was trained on a dataset where the prompt is <span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.3">â€œSound of a toothbrushâ€</span> from AudioSetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib10" title="">10</a>]</cite>, it might not accurately generalize to a similar label like â€œbrushing teethâ€ in the ESC50 datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib11" title="">11</a>]</cite>, even though the sounds are similar (<span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.4">both sound like a soft scrubbing or swishing noise, often with a light, scratchy texture</span>).</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Limitations of hand-written prompts for ZSAC</span>: The current ZSAC setup relies on hand-written prompts that correspond directly to dataset category labels. These prompts fail to provide additional context beyond the label itself. For example, CLAP may struggle to classify a label like â€œResidential Areaâ€ in the CochlScene datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib12" title="">12</a>]</cite> if it has not encountered that label during training. The label alone offers very little information about what sounds characterize a residential area, leading to potential misclassification.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Main Contributions.</span> In this paper, we propose a simple, scalable, and effective approach to improve ZSAC with CLAP. Our contributions are twofold and are summarized as follows:</p>
<ol class="ltx_enumerate" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.1">We present ReCLAP, a CLAP model trained using <span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.1.1">caption augmentation</span>. Specifically, we prompt a Large Language Model (LLM) to generate multiple diverse rewrites of the caption associated with each audio. Each rewrite describes the sounds in a unique way. Additionally, they exhibit diversity in sentence structure and vocabulary while preserving the original key concepts and meanings (example in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.F1" title="Figure 1 â€£ III-A Caption Augmentation for ReCLAP â€£ III Methodology â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">1</span></a> and SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.SS1" title="III-A Caption Augmentation for ReCLAP â€£ III Methodology â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>). This simple data augmentation technique has several advantages, including <span class="ltx_text ltx_font_bold" id="S1.I2.i1.p1.1.2">(1)</span> It enables the model to learn about the distinct acoustic features of sound events beyond what abstract labels alone can provide. This leads to more accurate clustering of sounds based on their actual acoustic properties rather than relying solely on predefined labels. <span class="ltx_text ltx_font_bold" id="S1.I2.i1.p1.1.3">(2)</span> Text-based augmentation via LLM-generated captions provides an effective and scalable method for training-time data augmentation. Unlike traditional data augmentation techniques, which typically involve random audio perturbations, our method is more interpretable and avoids the complexities and limitations of generating synthetic audio. ReCLAP achieves state-of-the-art performance across various retrieval, and ZSAC benchmarks with standard setups.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I2.i2.p1">
<p class="ltx_p" id="S1.I2.i2.p1.1">To further improve ZSAC performance with ReCLAP, we go beyond simple hand-written template prompts (e.g., â€œThe sound of a {category}â€) by generating multiple custom prompts for each category. This process involves two steps: <span class="ltx_text ltx_font_bold" id="S1.I2.i2.p1.1.1">(1)</span> We prompt an LLM to describe the sound of each category label in <math alttext="t" class="ltx_Math" display="inline" id="S1.I2.i2.p1.1.m1.1"><semantics id="S1.I2.i2.p1.1.m1.1a"><mi id="S1.I2.i2.p1.1.m1.1.1" xref="S1.I2.i2.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S1.I2.i2.p1.1.m1.1b"><ci id="S1.I2.i2.p1.1.m1.1.1.cmml" xref="S1.I2.i2.p1.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I2.i2.p1.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S1.I2.i2.p1.1.m1.1d">italic_t</annotation></semantics></math> distinct ways, focusing on its unique acoustic characteristics (e.g., Gasp: â€œa sharp intake of breathâ€). <span class="ltx_text ltx_font_bold" id="S1.I2.i2.p1.1.2">(2)</span> We then create prompts that place the sound event in diverse scenes, incorporating the descriptions generated in the previous step (e.g., â€œA sharp intake of breath sliced through the silence as the verdict was announcedâ€). Our proposed method improves the performance of ReCLAP across various ZSAC benchmarks by 1%-55%.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Following the initial work on CLAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>, several works have worked to improve its performance. For example, Wu <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>]</cite> scaled CLAP to 630k audio-caption pairs (including proprietary datasets) and showed a considerable boost in performance. Following this, Elizade <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">et al.</span> scaled their data to 4.6M audio-caption pairs and included speech samples in their training. Ghosh <span class="ltx_text ltx_font_italic" id="S2.p1.1.3">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> employed 660k pairs using only public domain data to build CompA-CLAP. They also proposed novel techniques to improve the compositional reasoning abilities of CLAP. CLAP has also been employed as an audio or text backbone for a variety of foundational audio processing tasks including text-to-audio generationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib16" title="">16</a>]</cite>, audio captioningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib5" title="">5</a>]</cite> and audio chat modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib3" title="">3</a>]</cite>. Despite its gaining popularity, research efforts to enhance CLAPâ€™s audio and language comprehension skills have been limited, with prior work focusing mainly on scaling.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methodology</span>
</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Caption Augmentation for ReCLAP</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.6">CLAP is trained on a contrastive objective between audio-caption pairs to learn a shared representation between the audio and language modalities. Specifically, let <math alttext="X_{a}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">X_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_X start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="X_{t}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">X_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> be the audio and its corresponding caption. Additionally, let <math alttext="f_{a}(.)" class="ltx_math_unparsed" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1b"><msub id="S3.SS1.p1.3.m3.1.1"><mi id="S3.SS1.p1.3.m3.1.1.2">f</mi><mi id="S3.SS1.p1.3.m3.1.1.3">a</mi></msub><mrow id="S3.SS1.p1.3.m3.1.2"><mo id="S3.SS1.p1.3.m3.1.2.1" stretchy="false">(</mo><mo id="S3.SS1.p1.3.m3.1.2.2" lspace="0em" rspace="0.167em">.</mo><mo id="S3.SS1.p1.3.m3.1.2.3" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">f_{a}(.)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( . )</annotation></semantics></math> and <math alttext="f_{b}(.)" class="ltx_math_unparsed" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1b"><msub id="S3.SS1.p1.4.m4.1.1"><mi id="S3.SS1.p1.4.m4.1.1.2">f</mi><mi id="S3.SS1.p1.4.m4.1.1.3">b</mi></msub><mrow id="S3.SS1.p1.4.m4.1.2"><mo id="S3.SS1.p1.4.m4.1.2.1" stretchy="false">(</mo><mo id="S3.SS1.p1.4.m4.1.2.2" lspace="0em" rspace="0.167em">.</mo><mo id="S3.SS1.p1.4.m4.1.2.3" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">f_{b}(.)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_f start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ( . )</annotation></semantics></math> be the audio and text encoders respectively. We first obtain audio and text representations <math alttext="\hat{X}_{a}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mover accent="true" id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">X</mi><mo id="S3.SS1.p1.5.m5.1.1.2.1" xref="S3.SS1.p1.5.m5.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"><ci id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2.1">^</ci><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">ğ‘‹</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\hat{X}_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\hat{X}_{b}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mover accent="true" id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2.2" xref="S3.SS1.p1.6.m6.1.1.2.2.cmml">X</mi><mo id="S3.SS1.p1.6.m6.1.1.2.1" xref="S3.SS1.p1.6.m6.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><apply id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2"><ci id="S3.SS1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS1.p1.6.m6.1.1.2.1">^</ci><ci id="S3.SS1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2.2">ğ‘‹</ci></apply><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\hat{X}_{b}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{X}_{a}=f_{a}\left(X_{a}\right);\hat{X}_{t}=f_{t}\left(X_{t}\right)" class="ltx_Math" display="block" id="S3.E1.m1.2"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">X</mi><mo id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml">a</mi></msub><mo id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.3.2.cmml">f</mi><mi id="S3.E1.m1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.3.3.cmml">a</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.3a.cmml">;</mo><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><msub id="S3.E1.m1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml"><mover accent="true" id="S3.E1.m1.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.3.2.cmml"><mi id="S3.E1.m1.2.2.2.2.3.2.2" xref="S3.E1.m1.2.2.2.2.3.2.2.cmml">X</mi><mo id="S3.E1.m1.2.2.2.2.3.2.1" xref="S3.E1.m1.2.2.2.2.3.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.1.cmml"><msub id="S3.E1.m1.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.2.1.3.cmml"><mi id="S3.E1.m1.2.2.2.2.1.3.2" xref="S3.E1.m1.2.2.2.2.1.3.2.cmml">f</mi><mi id="S3.E1.m1.2.2.2.2.1.3.3" xref="S3.E1.m1.2.2.2.2.1.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.2.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.2.2.1.1.1.2" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.2.2.2.2.1.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.2.2.1.1.1.1.2.cmml">X</mi><mi id="S3.E1.m1.2.2.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1">^</ci><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">ğ‘‹</ci></apply><ci id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></times><apply id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.3.2">ğ‘“</ci><ci id="S3.E1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">ğ‘‹</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><eq id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2"></eq><apply id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.3">subscript</csymbol><apply id="S3.E1.m1.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.3.2"><ci id="S3.E1.m1.2.2.2.2.3.2.1.cmml" xref="S3.E1.m1.2.2.2.2.3.2.1">^</ci><ci id="S3.E1.m1.2.2.2.2.3.2.2.cmml" xref="S3.E1.m1.2.2.2.2.3.2.2">ğ‘‹</ci></apply><ci id="S3.E1.m1.2.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1"><times id="S3.E1.m1.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.2"></times><apply id="S3.E1.m1.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.3.1.cmml" xref="S3.E1.m1.2.2.2.2.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.3.2.cmml" xref="S3.E1.m1.2.2.2.2.1.3.2">ğ‘“</ci><ci id="S3.E1.m1.2.2.2.2.1.3.3.cmml" xref="S3.E1.m1.2.2.2.2.1.3.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.2">ğ‘‹</ci><ci id="S3.E1.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\hat{X}_{a}=f_{a}\left(X_{a}\right);\hat{X}_{t}=f_{t}\left(X_{t}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.2d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ) ; over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.10">where <math alttext="\hat{X}_{a}\in\mathbb{R}^{N\times D}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m1.1"><semantics id="S3.SS1.p1.7.m1.1a"><mrow id="S3.SS1.p1.7.m1.1.1" xref="S3.SS1.p1.7.m1.1.1.cmml"><msub id="S3.SS1.p1.7.m1.1.1.2" xref="S3.SS1.p1.7.m1.1.1.2.cmml"><mover accent="true" id="S3.SS1.p1.7.m1.1.1.2.2" xref="S3.SS1.p1.7.m1.1.1.2.2.cmml"><mi id="S3.SS1.p1.7.m1.1.1.2.2.2" xref="S3.SS1.p1.7.m1.1.1.2.2.2.cmml">X</mi><mo id="S3.SS1.p1.7.m1.1.1.2.2.1" xref="S3.SS1.p1.7.m1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.7.m1.1.1.2.3" xref="S3.SS1.p1.7.m1.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS1.p1.7.m1.1.1.1" xref="S3.SS1.p1.7.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.7.m1.1.1.3" xref="S3.SS1.p1.7.m1.1.1.3.cmml"><mi id="S3.SS1.p1.7.m1.1.1.3.2" xref="S3.SS1.p1.7.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.7.m1.1.1.3.3" xref="S3.SS1.p1.7.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.7.m1.1.1.3.3.2" xref="S3.SS1.p1.7.m1.1.1.3.3.2.cmml">N</mi><mo id="S3.SS1.p1.7.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.7.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.7.m1.1.1.3.3.3" xref="S3.SS1.p1.7.m1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m1.1b"><apply id="S3.SS1.p1.7.m1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1"><in id="S3.SS1.p1.7.m1.1.1.1.cmml" xref="S3.SS1.p1.7.m1.1.1.1"></in><apply id="S3.SS1.p1.7.m1.1.1.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m1.1.1.2.1.cmml" xref="S3.SS1.p1.7.m1.1.1.2">subscript</csymbol><apply id="S3.SS1.p1.7.m1.1.1.2.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2.2"><ci id="S3.SS1.p1.7.m1.1.1.2.2.1.cmml" xref="S3.SS1.p1.7.m1.1.1.2.2.1">^</ci><ci id="S3.SS1.p1.7.m1.1.1.2.2.2.cmml" xref="S3.SS1.p1.7.m1.1.1.2.2.2">ğ‘‹</ci></apply><ci id="S3.SS1.p1.7.m1.1.1.2.3.cmml" xref="S3.SS1.p1.7.m1.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS1.p1.7.m1.1.1.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m1.1.1.3.1.cmml" xref="S3.SS1.p1.7.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.7.m1.1.1.3.2.cmml" xref="S3.SS1.p1.7.m1.1.1.3.2">â„</ci><apply id="S3.SS1.p1.7.m1.1.1.3.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3"><times id="S3.SS1.p1.7.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.7.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.2">ğ‘</ci><ci id="S3.SS1.p1.7.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m1.1.1.3.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m1.1c">\hat{X}_{a}\in\mathbb{R}^{N\times D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m1.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\hat{X}_{b}\in\mathbb{R}^{N\times D}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m2.1"><semantics id="S3.SS1.p1.8.m2.1a"><mrow id="S3.SS1.p1.8.m2.1.1" xref="S3.SS1.p1.8.m2.1.1.cmml"><msub id="S3.SS1.p1.8.m2.1.1.2" xref="S3.SS1.p1.8.m2.1.1.2.cmml"><mover accent="true" id="S3.SS1.p1.8.m2.1.1.2.2" xref="S3.SS1.p1.8.m2.1.1.2.2.cmml"><mi id="S3.SS1.p1.8.m2.1.1.2.2.2" xref="S3.SS1.p1.8.m2.1.1.2.2.2.cmml">X</mi><mo id="S3.SS1.p1.8.m2.1.1.2.2.1" xref="S3.SS1.p1.8.m2.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p1.8.m2.1.1.2.3" xref="S3.SS1.p1.8.m2.1.1.2.3.cmml">b</mi></msub><mo id="S3.SS1.p1.8.m2.1.1.1" xref="S3.SS1.p1.8.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.8.m2.1.1.3" xref="S3.SS1.p1.8.m2.1.1.3.cmml"><mi id="S3.SS1.p1.8.m2.1.1.3.2" xref="S3.SS1.p1.8.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.8.m2.1.1.3.3" xref="S3.SS1.p1.8.m2.1.1.3.3.cmml"><mi id="S3.SS1.p1.8.m2.1.1.3.3.2" xref="S3.SS1.p1.8.m2.1.1.3.3.2.cmml">N</mi><mo id="S3.SS1.p1.8.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.8.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.8.m2.1.1.3.3.3" xref="S3.SS1.p1.8.m2.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m2.1b"><apply id="S3.SS1.p1.8.m2.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1"><in id="S3.SS1.p1.8.m2.1.1.1.cmml" xref="S3.SS1.p1.8.m2.1.1.1"></in><apply id="S3.SS1.p1.8.m2.1.1.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m2.1.1.2.1.cmml" xref="S3.SS1.p1.8.m2.1.1.2">subscript</csymbol><apply id="S3.SS1.p1.8.m2.1.1.2.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2.2"><ci id="S3.SS1.p1.8.m2.1.1.2.2.1.cmml" xref="S3.SS1.p1.8.m2.1.1.2.2.1">^</ci><ci id="S3.SS1.p1.8.m2.1.1.2.2.2.cmml" xref="S3.SS1.p1.8.m2.1.1.2.2.2">ğ‘‹</ci></apply><ci id="S3.SS1.p1.8.m2.1.1.2.3.cmml" xref="S3.SS1.p1.8.m2.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS1.p1.8.m2.1.1.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m2.1.1.3.1.cmml" xref="S3.SS1.p1.8.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.8.m2.1.1.3.2.cmml" xref="S3.SS1.p1.8.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p1.8.m2.1.1.3.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3"><times id="S3.SS1.p1.8.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3.1"></times><ci id="S3.SS1.p1.8.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3.2">ğ‘</ci><ci id="S3.SS1.p1.8.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.8.m2.1.1.3.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m2.1c">\hat{X}_{b}\in\mathbb{R}^{N\times D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m2.1d">over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>. <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m3.1"><semantics id="S3.SS1.p1.9.m3.1a"><mi id="S3.SS1.p1.9.m3.1.1" xref="S3.SS1.p1.9.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m3.1b"><ci id="S3.SS1.p1.9.m3.1.1.cmml" xref="S3.SS1.p1.9.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m3.1d">italic_N</annotation></semantics></math> here is the batch size and <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m4.1"><semantics id="S3.SS1.p1.10.m4.1a"><mi id="S3.SS1.p1.10.m4.1.1" xref="S3.SS1.p1.10.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m4.1b"><ci id="S3.SS1.p1.10.m4.1.1.cmml" xref="S3.SS1.p1.10.m4.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m4.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m4.1d">italic_D</annotation></semantics></math> is the embedding dimension. Next, we measure similarity as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="C=\tau*\left(\hat{X}_{a}\cdot\hat{X}_{t}^{\top}\right)" class="ltx_Math" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mi id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">C</mi><mo id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">Ï„</mi><mo id="S3.E2.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.1.1.1.2.cmml">âˆ—</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml">X</mi><mo id="S3.E2.m1.1.1.1.1.1.1.2.2.1" xref="S3.E2.m1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml">a</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">â‹…</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml">X</mi><mo id="S3.E2.m1.1.1.1.1.1.1.3.2.2.1" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml">âŠ¤</mo></msubsup></mrow><mo id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"></eq><ci id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3">ğ¶</ci><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">ğœ</ci><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><ci id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1">â‹…</ci><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2"><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2">ğ‘‹</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2"><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2">ğ‘‹</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3">ğ‘¡</ci></apply><csymbol cd="latexml" id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">C=\tau*\left(\hat{X}_{a}\cdot\hat{X}_{t}^{\top}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">italic_C = italic_Ï„ âˆ— ( over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT â‹… over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.11">where <math alttext="C" class="ltx_Math" display="inline" id="S3.SS1.p1.11.m1.1"><semantics id="S3.SS1.p1.11.m1.1a"><mi id="S3.SS1.p1.11.m1.1.1" xref="S3.SS1.p1.11.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m1.1b"><ci id="S3.SS1.p1.11.m1.1.1.cmml" xref="S3.SS1.p1.11.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m1.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.11.m1.1d">italic_C</annotation></semantics></math> is any similarity function that measures distance using the dot product (cosine similarity in our case). Finally, the contrastive loss is calculated as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=0.5*\left(\ell_{\text{text }}(C)+\ell_{\text{audio }}(C)\right)" class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml">â„’</mi><mo id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml"><mn id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.3.3.1.3.cmml">0.5</mn><mo id="S3.E3.m1.3.3.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E3.m1.3.3.1.2.cmml">âˆ—</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mo id="S3.E3.m1.3.3.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.2.2" xref="S3.E3.m1.3.3.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.2.2.2" mathvariant="normal" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml">â„“</mi><mtext id="S3.E3.m1.3.3.1.1.1.1.2.2.3" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3a.cmml">textÂ </mtext></msub><mo id="S3.E3.m1.3.3.1.1.1.1.2.1" xref="S3.E3.m1.3.3.1.1.1.1.2.1.cmml">â¢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.2.3.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.2.3.2.1" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">C</mi><mo id="S3.E3.m1.3.3.1.1.1.1.2.3.2.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.cmml">+</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><msub id="S3.E3.m1.3.3.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.2.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.2.2" mathvariant="normal" xref="S3.E3.m1.3.3.1.1.1.1.3.2.2.cmml">â„“</mi><mtext id="S3.E3.m1.3.3.1.1.1.1.3.2.3" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3a.cmml">audioÂ </mtext></msub><mo id="S3.E3.m1.3.3.1.1.1.1.3.1" xref="S3.E3.m1.3.3.1.1.1.1.3.1.cmml">â¢</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.3.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.2.1" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml">(</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">C</mi><mo id="S3.E3.m1.3.3.1.1.1.1.3.3.2.2" stretchy="false" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"></eq><ci id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3">â„’</ci><apply id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1"><times id="S3.E3.m1.3.3.1.2.cmml" xref="S3.E3.m1.3.3.1.2"></times><cn id="S3.E3.m1.3.3.1.3.cmml" type="float" xref="S3.E3.m1.3.3.1.3">0.5</cn><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"><plus id="S3.E3.m1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1"></plus><apply id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"><times id="S3.E3.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.1"></times><apply id="S3.E3.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.2">â„“</ci><ci id="S3.E3.m1.3.3.1.1.1.1.2.2.3a.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3"><mtext id="S3.E3.m1.3.3.1.1.1.1.2.2.3.cmml" mathsize="70%" xref="S3.E3.m1.3.3.1.1.1.1.2.2.3">textÂ </mtext></ci></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ¶</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><times id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.1"></times><apply id="S3.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2.2">â„“</ci><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.3a.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3"><mtext id="S3.E3.m1.3.3.1.1.1.1.3.2.3.cmml" mathsize="70%" xref="S3.E3.m1.3.3.1.1.1.1.3.2.3">audioÂ </mtext></ci></apply><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">ğ¶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mathcal{L}=0.5*\left(\ell_{\text{text }}(C)+\ell_{\text{audio }}(C)\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">caligraphic_L = 0.5 âˆ— ( roman_â„“ start_POSTSUBSCRIPT text end_POSTSUBSCRIPT ( italic_C ) + roman_â„“ start_POSTSUBSCRIPT audio end_POSTSUBSCRIPT ( italic_C ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\ell_{k}=\frac{1}{N}\sum_{i=0}^{N}\log\operatorname{diag}(\operatorname{%
softmax}(C))" class="ltx_Math" display="block" id="S3.E4.m1.4"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.4" xref="S3.E4.m1.4.4.cmml"><msub id="S3.E4.m1.4.4.3" xref="S3.E4.m1.4.4.3.cmml"><mi id="S3.E4.m1.4.4.3.2" mathvariant="normal" xref="S3.E4.m1.4.4.3.2.cmml">â„“</mi><mi id="S3.E4.m1.4.4.3.3" xref="S3.E4.m1.4.4.3.3.cmml">k</mi></msub><mo id="S3.E4.m1.4.4.2" xref="S3.E4.m1.4.4.2.cmml">=</mo><mrow id="S3.E4.m1.4.4.1" xref="S3.E4.m1.4.4.1.cmml"><mfrac id="S3.E4.m1.4.4.1.3" xref="S3.E4.m1.4.4.1.3.cmml"><mn id="S3.E4.m1.4.4.1.3.2" xref="S3.E4.m1.4.4.1.3.2.cmml">1</mn><mi id="S3.E4.m1.4.4.1.3.3" xref="S3.E4.m1.4.4.1.3.3.cmml">N</mi></mfrac><mo id="S3.E4.m1.4.4.1.2" xref="S3.E4.m1.4.4.1.2.cmml">â¢</mo><mrow id="S3.E4.m1.4.4.1.1" xref="S3.E4.m1.4.4.1.1.cmml"><munderover id="S3.E4.m1.4.4.1.1.2" xref="S3.E4.m1.4.4.1.1.2.cmml"><mo id="S3.E4.m1.4.4.1.1.2.2.2" movablelimits="false" xref="S3.E4.m1.4.4.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E4.m1.4.4.1.1.2.2.3" xref="S3.E4.m1.4.4.1.1.2.2.3.cmml"><mi id="S3.E4.m1.4.4.1.1.2.2.3.2" xref="S3.E4.m1.4.4.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E4.m1.4.4.1.1.2.2.3.1" xref="S3.E4.m1.4.4.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.4.4.1.1.2.2.3.3" xref="S3.E4.m1.4.4.1.1.2.2.3.3.cmml">0</mn></mrow><mi id="S3.E4.m1.4.4.1.1.2.3" xref="S3.E4.m1.4.4.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E4.m1.4.4.1.1.1" xref="S3.E4.m1.4.4.1.1.1.cmml"><mi id="S3.E4.m1.4.4.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.2.cmml">log</mi><mo id="S3.E4.m1.4.4.1.1.1a" lspace="0.167em" xref="S3.E4.m1.4.4.1.1.1.cmml">â¡</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml"><mi id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml">diag</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1a" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">â¡</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml"><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">(</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">softmax</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2a" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml">â¡</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.1.1" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">C</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.1.2" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.4.cmml" xref="S3.E4.m1.4.4"><eq id="S3.E4.m1.4.4.2.cmml" xref="S3.E4.m1.4.4.2"></eq><apply id="S3.E4.m1.4.4.3.cmml" xref="S3.E4.m1.4.4.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.3.1.cmml" xref="S3.E4.m1.4.4.3">subscript</csymbol><ci id="S3.E4.m1.4.4.3.2.cmml" xref="S3.E4.m1.4.4.3.2">â„“</ci><ci id="S3.E4.m1.4.4.3.3.cmml" xref="S3.E4.m1.4.4.3.3">ğ‘˜</ci></apply><apply id="S3.E4.m1.4.4.1.cmml" xref="S3.E4.m1.4.4.1"><times id="S3.E4.m1.4.4.1.2.cmml" xref="S3.E4.m1.4.4.1.2"></times><apply id="S3.E4.m1.4.4.1.3.cmml" xref="S3.E4.m1.4.4.1.3"><divide id="S3.E4.m1.4.4.1.3.1.cmml" xref="S3.E4.m1.4.4.1.3"></divide><cn id="S3.E4.m1.4.4.1.3.2.cmml" type="integer" xref="S3.E4.m1.4.4.1.3.2">1</cn><ci id="S3.E4.m1.4.4.1.3.3.cmml" xref="S3.E4.m1.4.4.1.3.3">ğ‘</ci></apply><apply id="S3.E4.m1.4.4.1.1.cmml" xref="S3.E4.m1.4.4.1.1"><apply id="S3.E4.m1.4.4.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.2.1.cmml" xref="S3.E4.m1.4.4.1.1.2">superscript</csymbol><apply id="S3.E4.m1.4.4.1.1.2.2.cmml" xref="S3.E4.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.2.2.1.cmml" xref="S3.E4.m1.4.4.1.1.2">subscript</csymbol><sum id="S3.E4.m1.4.4.1.1.2.2.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2.2"></sum><apply id="S3.E4.m1.4.4.1.1.2.2.3.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3"><eq id="S3.E4.m1.4.4.1.1.2.2.3.1.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3.1"></eq><ci id="S3.E4.m1.4.4.1.1.2.2.3.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3.2">ğ‘–</ci><cn id="S3.E4.m1.4.4.1.1.2.2.3.3.cmml" type="integer" xref="S3.E4.m1.4.4.1.1.2.2.3.3">0</cn></apply></apply><ci id="S3.E4.m1.4.4.1.1.2.3.cmml" xref="S3.E4.m1.4.4.1.1.2.3">ğ‘</ci></apply><apply id="S3.E4.m1.4.4.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1"><log id="S3.E4.m1.4.4.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.2"></log><apply id="S3.E4.m1.4.4.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1"><ci id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3">diag</ci><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.2"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">softmax</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">ğ¶</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\ell_{k}=\frac{1}{N}\sum_{i=0}^{N}\log\operatorname{diag}(\operatorname{%
softmax}(C))</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.4d">roman_â„“ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG âˆ‘ start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_log roman_diag ( roman_softmax ( italic_C ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.15">We train ReCLAP with a training objective similar to that in CLAP but with <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.15.1">caption augmentation</span>. Specifically, we augment each training sample with <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.12.m1.1"><semantics id="S3.SS1.p1.12.m1.1a"><mi id="S3.SS1.p1.12.m1.1.1" xref="S3.SS1.p1.12.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m1.1b"><ci id="S3.SS1.p1.12.m1.1.1.cmml" xref="S3.SS1.p1.12.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.12.m1.1d">italic_K</annotation></semantics></math> additional text captions by rewriting the original caption associated with each audio sample in the dataset in <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.13.m2.1"><semantics id="S3.SS1.p1.13.m2.1a"><mi id="S3.SS1.p1.13.m2.1.1" xref="S3.SS1.p1.13.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m2.1b"><ci id="S3.SS1.p1.13.m2.1.1.cmml" xref="S3.SS1.p1.13.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.13.m2.1d">italic_K</annotation></semantics></math> diverse ways. During training, for each audio sample, ReCLAP chooses the original caption with a probability <math alttext="p=0.4" class="ltx_Math" display="inline" id="S3.SS1.p1.14.m3.1"><semantics id="S3.SS1.p1.14.m3.1a"><mrow id="S3.SS1.p1.14.m3.1.1" xref="S3.SS1.p1.14.m3.1.1.cmml"><mi id="S3.SS1.p1.14.m3.1.1.2" xref="S3.SS1.p1.14.m3.1.1.2.cmml">p</mi><mo id="S3.SS1.p1.14.m3.1.1.1" xref="S3.SS1.p1.14.m3.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.14.m3.1.1.3" xref="S3.SS1.p1.14.m3.1.1.3.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m3.1b"><apply id="S3.SS1.p1.14.m3.1.1.cmml" xref="S3.SS1.p1.14.m3.1.1"><eq id="S3.SS1.p1.14.m3.1.1.1.cmml" xref="S3.SS1.p1.14.m3.1.1.1"></eq><ci id="S3.SS1.p1.14.m3.1.1.2.cmml" xref="S3.SS1.p1.14.m3.1.1.2">ğ‘</ci><cn id="S3.SS1.p1.14.m3.1.1.3.cmml" type="float" xref="S3.SS1.p1.14.m3.1.1.3">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m3.1c">p=0.4</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.14.m3.1d">italic_p = 0.4</annotation></semantics></math> or one of the rewritten versions (with a probability <math alttext="1-p" class="ltx_Math" display="inline" id="S3.SS1.p1.15.m4.1"><semantics id="S3.SS1.p1.15.m4.1a"><mrow id="S3.SS1.p1.15.m4.1.1" xref="S3.SS1.p1.15.m4.1.1.cmml"><mn id="S3.SS1.p1.15.m4.1.1.2" xref="S3.SS1.p1.15.m4.1.1.2.cmml">1</mn><mo id="S3.SS1.p1.15.m4.1.1.1" xref="S3.SS1.p1.15.m4.1.1.1.cmml">âˆ’</mo><mi id="S3.SS1.p1.15.m4.1.1.3" xref="S3.SS1.p1.15.m4.1.1.3.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m4.1b"><apply id="S3.SS1.p1.15.m4.1.1.cmml" xref="S3.SS1.p1.15.m4.1.1"><minus id="S3.SS1.p1.15.m4.1.1.1.cmml" xref="S3.SS1.p1.15.m4.1.1.1"></minus><cn id="S3.SS1.p1.15.m4.1.1.2.cmml" type="integer" xref="S3.SS1.p1.15.m4.1.1.2">1</cn><ci id="S3.SS1.p1.15.m4.1.1.3.cmml" xref="S3.SS1.p1.15.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m4.1c">1-p</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.15.m4.1d">1 - italic_p</annotation></semantics></math>) where each rewritten caption has an equal probability of selection. Thus, Eqn.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.E2" title="In III-A Caption Augmentation for ReCLAP â€£ III Methodology â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">2</span></a> can be re-written as:</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="C=\tau*\left(\hat{X}_{a}\cdot f_{t}(\operatorname{aug}_{t}(X_{t}))^{\top}\right)" class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><mi id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml">C</mi><mo id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.3.cmml">Ï„</mi><mo id="S3.E5.m1.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.E5.m1.1.1.1.2.cmml">âˆ—</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.1.3.2.cmml"><mover accent="true" id="S3.E5.m1.1.1.1.1.1.1.3.2.2" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.3.2.2.2" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.2.cmml">X</mi><mo id="S3.E5.m1.1.1.1.1.1.1.3.2.2.1" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S3.E5.m1.1.1.1.1.1.1.3.2.3" xref="S3.E5.m1.1.1.1.1.1.1.3.2.3.cmml">a</mi></msub><mo id="S3.E5.m1.1.1.1.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E5.m1.1.1.1.1.1.1.3.1.cmml">â‹…</mo><msub id="S3.E5.m1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2.cmml">f</mi><mi id="S3.E5.m1.1.1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3.cmml">t</mi></msub></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.2.cmml">â¢</mo><msup id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">aug</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2a" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">â¡</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2.cmml">X</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3.cmml">t</mi></msub><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E5.m1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.3.cmml">âŠ¤</mo></msup></mrow><mo id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"></eq><ci id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3">ğ¶</ci><apply id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><times id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.2"></times><ci id="S3.E5.m1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.3">ğœ</ci><apply id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><times id="S3.E5.m1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.2"></times><apply id="S3.E5.m1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3"><ci id="S3.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.1">â‹…</ci><apply id="S3.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2">subscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2"><ci id="S3.E5.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.1">^</ci><ci id="S3.E5.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.2.2">ğ‘‹</ci></apply><ci id="S3.E5.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.2.3">ğ‘</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.2">ğ‘“</ci><ci id="S3.E5.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.3.3.3">ğ‘¡</ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2"><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">aug</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.2">ğ‘‹</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.3">ğ‘¡</ci></apply></apply><csymbol cd="latexml" id="S3.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">C=\tau*\left(\hat{X}_{a}\cdot f_{t}(\operatorname{aug}_{t}(X_{t}))^{\top}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_C = italic_Ï„ âˆ— ( over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT â‹… italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( roman_aug start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">where <math alttext="\operatorname{aug}_{t}(.)" class="ltx_math_unparsed" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1b"><msub id="S3.SS1.p3.1.m1.1.1"><mi id="S3.SS1.p3.1.m1.1.1.2">aug</mi><mi id="S3.SS1.p3.1.m1.1.1.3">t</mi></msub><mrow id="S3.SS1.p3.1.m1.1.2"><mo id="S3.SS1.p3.1.m1.1.2.1" stretchy="false">(</mo><mo id="S3.SS1.p3.1.m1.1.2.2" lspace="0em" rspace="0.167em">.</mo><mo id="S3.SS1.p3.1.m1.1.2.3" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\operatorname{aug}_{t}(.)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">roman_aug start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( . )</annotation></semantics></math> denotes the rewriting and choosing operation. The primary objective of the rewriting operation is to rewrite the caption so that each sound in the caption is described using its unique acoustic characteristics. An example is as follows:</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<span class="ltx_ERROR undefined" id="S3.SS1.p4.1">{mdframed}</span>
<p class="ltx_p" id="S3.SS1.p4.2">[linewidth=1pt, linecolor=black, leftmargin=1pt, rightmargin=1pt, innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=4pt, innerbottommargin=2pt, backgroundcolor=gray!20, roundcorner=5pt]
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p4.2.1">(1) Original Caption:</span> A traction engine is idling.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p5.1.1">(1) Rewritten Caption:</span> A low, rumbling diesel engine hums steadily, its vibrations resonating through the air.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p6.1.1">(2) Original Caption:</span> Cars are starting in pairs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS1.p7.1.1">(2) Rewritten Caption:</span> Rapid, low-pitched revving of engines, followed by the synchronized, high-pitched roar of multiple cars starting in unison.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1">We instruct an LLM to complete this task, which ensures that the rewritten captions or augmentations exhibit high levels of diversity in sentence structure and vocabulary while preserving the original key concepts and meanings. The instruction used to prompt the LLM is provided in our GitHub. We employ LLaMa-3.1-8BÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib18" title="">18</a>]</cite> with in-context examples written by humans. We randomly sample 5 in-context examples for every prompt from a collection of 50.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="953" id="S3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text" id="S3.F1.2.1" style="font-size:90%;">Illustration of our proposed method for improving Zero Shot Audio Classification (ZSAC) with language augmentation. <span class="ltx_text ltx_font_bold" id="S3.F1.2.1.1">Top:</span> We enhance CLAP training through <span class="ltx_text ltx_font_italic" id="S3.F1.2.1.2">caption augmentation</span>, where each audioâ€™s caption is expanded and rewritten by prompting LLMs to provide detailed descriptions of the sound events. During training, we choose either the original caption or one of the rewritten captions. <span class="ltx_text ltx_font_bold" id="S3.F1.2.1.3">Bottom:</span> We perform <span class="ltx_text ltx_font_italic" id="S3.F1.2.1.4">prompt augmentation</span> and generate custom prompts for each label category in the dataset. These prompts describe the sound in the category in diverse scenes.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Prompt Augmentation for ZSAC</span>
</h3>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span><span class="ltx_text" id="S3.T1.2.1" style="font-size:90%;">Performance comparison of ReCLAP with baselines on Text-to-Audio and Audio-to-Text retrieval on AudioCaps and Clotho. ReCLAP outperforms baselines by 0.4%-38.9%.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.3" style="width:867.2pt;height:327.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(171.2pt,-64.6pt) scale(1.65249537226375,1.65249537226375) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt ltx_border_tt" id="S3.T1.3.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="6" id="S3.T1.3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.1.1.2.1">AudioCaps</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" colspan="6" id="S3.T1.3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.1.1.3.1">Clotho</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T1.3.1.2.2.1">Model</th>
<td class="ltx_td ltx_align_center" colspan="3" id="S3.T1.3.1.2.2.2">Text-to-Audio</td>
<td class="ltx_td ltx_align_center ltx_border_r" colspan="3" id="S3.T1.3.1.2.2.3">Audio-to-Text</td>
<td class="ltx_td ltx_align_center" colspan="3" id="S3.T1.3.1.2.2.4">Text-to-Audio</td>
<td class="ltx_td ltx_align_center" colspan="3" id="S3.T1.3.1.2.2.5">Audio-to-Text</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.3.3">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T1.3.1.3.3.1"></th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.2">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.3">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.3.3.4">R@10</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.5">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.6">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.3.3.7">R@10</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.8">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.9">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.3.3.10">R@10</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.11">R@1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.12">R@5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.3.3.13">R@10</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.3.1.4.4.1">MMT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.2">36.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.3">72.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.4.4.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.4.4.4.1">84.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.5">39.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.6">76.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.4.4.7">86.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.8">6.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.9">21.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.4.4.10">33.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.11">7.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.12">22.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.4.4.13">34.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.5.5.1">ML-ACT</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.2">33.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.3">69.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.5.5.4">82.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.5">39.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.6">72.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.5.5.7">83.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.8">14.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.9">36.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.5.5.10">49.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.11">16.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.12">37.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.5.5.13">50.2</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.6.6.1">CLAP</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.2">34.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.3">70.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.6.6.4">82.0</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.5">41.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.6">41.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.6.6.7">84.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.8">16.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.9">41.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.6.6.10">54.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.11"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.6.6.11.1">20.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.12">44.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.6.6.13">58.7</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.7.7.1">CompA-CLAP</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.2">36.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.3">72.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.7.7.4">81.6</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.5">45.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.7.7.6.1">80.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.7.7.7">86.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.8">16.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.9">43.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.7.7.10">56.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.11">19.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.12"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.7.7.12.1">45.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.7.7.13">55.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.8.8.1">LAION-CLAP (repro.)</th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.2">34.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.3">70.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.8.8.4">80.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.5">42.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.6">77.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.8.8.7">87.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.8">15.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.9">39.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.8.8.10">52.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.11">19.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.12">44.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.8.8.13">54.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.3.1.9.9.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.1.1" style="background-color:#F2F2F2;">CLAP-2.3M</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.2" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.2.1" style="background-color:#F2F2F2;">36.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.3" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.3.1" style="background-color:#F2F2F2;">72.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.9.9.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.4.1" style="background-color:#F2F2F2;">82.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.5" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.5.1" style="background-color:#F2F2F2;">46.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.6.1" style="background-color:#F2F2F2;">79.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.9.9.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.7.1" style="background-color:#F2F2F2;">87.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.8" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.8.1" style="background-color:#F2F2F2;">17.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.9" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.9.1" style="background-color:#F2F2F2;">43.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.3.1.9.9.10" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.9.9.10.1" style="background-color:#F2F2F2;">56.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.11" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.11.1" style="background-color:#F2F2F2;">19.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.12" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.12.1" style="background-color:#F2F2F2;">41.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.1.9.9.13" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.9.9.13.1" style="background-color:#F2F2F2;">56.4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.3.1.10.10.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.1.1" style="background-color:#F2F2F2;">ReCLAP-660k</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.2.1" style="background-color:#F2F2F2;">35.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.3.1" style="background-color:#F2F2F2;">72.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.10.10.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.4.1" style="background-color:#F2F2F2;">82.5</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.5.1" style="background-color:#F2F2F2;">45.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.6.1" style="background-color:#F2F2F2;">79.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.10.10.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.7.1" style="background-color:#F2F2F2;">87.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.8.1" style="background-color:#F2F2F2;">16.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.9" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.10.10.9.1" style="background-color:#F2F2F2;">44.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.3.1.10.10.10" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.10.1" style="background-color:#F2F2F2;">55.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.11" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.11.1" style="background-color:#F2F2F2;">18.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.12" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.10.10.12.1" style="background-color:#F2F2F2;">42.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.1.10.10.13" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.3.1.10.10.13.1" style="background-color:#F2F2F2;">57.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.3.1.11.11.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S3.T1.3.1.11.11.1.1" style="background-color:#F2F2F2;">ReCLAP</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.2" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.2.1" style="background-color:#F2F2F2;">37.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.3" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.3.1" style="background-color:#F2F2F2;">73.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.3.1.11.11.4" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.4.1" style="background-color:#F2F2F2;">85.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.5" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.5.1" style="background-color:#F2F2F2;">48.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.6" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.6.1" style="background-color:#F2F2F2;">80.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.3.1.11.11.7" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.7.1" style="background-color:#F2F2F2;">90.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.8" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.8.1" style="background-color:#F2F2F2;">18.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.9" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.9.1" style="background-color:#F2F2F2;">44.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.3.1.11.11.10" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.10.1" style="background-color:#F2F2F2;">59.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.11" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.11.1" style="background-color:#F2F2F2;">20.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.12" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.12.1" style="background-color:#F2F2F2;">45.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.1.11.11.13" style="background-color:#F2F2F2;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.1.11.11.13.1" style="background-color:#F2F2F2;">58.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">After training ReCLAP with rewritten captions, we can now employ ReCLAP for ZSAC. However, the standard approach for ZSAC is to handwrite a prompt template and use it for every category in the classification dataset (e.g.,<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">â€œThe sound of a </span>{<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.2">category</span>}<span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.3">â€</span>), like Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>. However, this method has a major drawback: The prompt merely specifies the category without providing details about the unique acoustic characteristics of the audio concept corresponding to the category. This limits CLAPâ€™s understanding of arbitrary categories in the wild, which are just abstract definitions of audio concepts. Therefore, incorporating descriptions of a categoryâ€™s acoustic features into the prompt provides CLAP with an intermediate level of understanding regarding the expected sound of that category. Our proposed method also complements ReCLAP, which possesses additional knowledge about the acoustic features of many audio concepts.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.2">Thus, moving from one standard prompt for every category, we propose employing <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_N</annotation></semantics></math> custom prompts for every category in the dataset. Since manually hand-writing such custom prompts is infeasible, we instruct an LLM for this task. We instruct an LLM in two stages, with two different instructions. In the first stage, we instruct an LLM to describe the sound of each category label in <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_t</annotation></semantics></math> distinct ways,
focusing on its unique acoustic characteristics:</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<span class="ltx_ERROR undefined" id="S3.SS2.p3.1">{mdframed}</span>
<p class="ltx_p" id="S3.SS2.p3.2">[linewidth=1pt, linecolor=black, leftmargin=1pt, rightmargin=1pt, innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=4pt, innerbottommargin=2pt, backgroundcolor=gray!20, roundcorner=5pt]</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p4.1.1">(1) Category:</span> Bicycle bell (FSD50k)</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p5.1.1">(1) Acoustic Properties:</span> (i) metallic ring, (ii) high-pitched, tinkling chime <math alttext="\cdots" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p5.1.m1.1.1.cmml">â‹¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">â‹¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">\cdots</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">â‹¯</annotation></semantics></math></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p6.1.1">(2) Category:</span> mallet (NSynth)</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p7.1.1">(2) Acoustic Properties:</span> (i) dull thud, (ii) resonant knock (iii) deep thump, <math alttext="\cdots" class="ltx_Math" display="inline" id="S3.SS2.p7.1.m1.1"><semantics id="S3.SS2.p7.1.m1.1a"><mi id="S3.SS2.p7.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p7.1.m1.1.1.cmml">â‹¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.1.m1.1b"><ci id="S3.SS2.p7.1.m1.1.1.cmml" xref="S3.SS2.p7.1.m1.1.1">â‹¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.1.m1.1c">\cdots</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p7.1.m1.1d">â‹¯</annotation></semantics></math></p>
</div>
<div class="ltx_para" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.1">Next, using these descriptions, we instruct an LLM to generate <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.p8.1.m1.1"><semantics id="S3.SS2.p8.1.m1.1a"><mi id="S3.SS2.p8.1.m1.1.1" xref="S3.SS2.p8.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p8.1.m1.1b"><ci id="S3.SS2.p8.1.m1.1.1.cmml" xref="S3.SS2.p8.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p8.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p8.1.m1.1d">italic_n</annotation></semantics></math> different captions for each property, with the sound described in the category occurring in diverse scenes:</p>
</div>
<div class="ltx_para" id="S3.SS2.p9">
<span class="ltx_ERROR undefined" id="S3.SS2.p9.1">{mdframed}</span>
<p class="ltx_p" id="S3.SS2.p9.2">[linewidth=1pt, linecolor=black, leftmargin=1pt, rightmargin=1pt, innerleftmargin=10pt, innerrightmargin=10pt, innertopmargin=4pt, innerbottommargin=2pt, backgroundcolor=gray!20, roundcorner=5pt]
<span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p9.2.1">(1) Prompt Caption:</span> A bicycle bellâ€™s clear, <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.p9.2.2">metallic ring</span> slices the silence as a rider announces their presence in the peaceful park.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p10">
<p class="ltx_p" id="S3.SS2.p10.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.SS2.p10.1.1">(2) Prompt Caption:</span> The malletâ€™s <span class="ltx_text ltx_framed ltx_framed_underline" id="S3.SS2.p10.1.2">dull thud</span> reverberated through the silent courtroom as the judge announced the verdict.</p>
</div>
<div class="ltx_para" id="S3.SS2.p11">
<p class="ltx_p" id="S3.SS2.p11.5">Finally, for every category, we randomly sample <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p11.1.m1.1"><semantics id="S3.SS2.p11.1.m1.1a"><mi id="S3.SS2.p11.1.m1.1.1" xref="S3.SS2.p11.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.1.m1.1b"><ci id="S3.SS2.p11.1.m1.1.1.cmml" xref="S3.SS2.p11.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.1.m1.1d">italic_N</annotation></semantics></math> unique prompts from the pool of <math alttext="n\times t" class="ltx_Math" display="inline" id="S3.SS2.p11.2.m2.1"><semantics id="S3.SS2.p11.2.m2.1a"><mrow id="S3.SS2.p11.2.m2.1.1" xref="S3.SS2.p11.2.m2.1.1.cmml"><mi id="S3.SS2.p11.2.m2.1.1.2" xref="S3.SS2.p11.2.m2.1.1.2.cmml">n</mi><mo id="S3.SS2.p11.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p11.2.m2.1.1.1.cmml">Ã—</mo><mi id="S3.SS2.p11.2.m2.1.1.3" xref="S3.SS2.p11.2.m2.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.2.m2.1b"><apply id="S3.SS2.p11.2.m2.1.1.cmml" xref="S3.SS2.p11.2.m2.1.1"><times id="S3.SS2.p11.2.m2.1.1.1.cmml" xref="S3.SS2.p11.2.m2.1.1.1"></times><ci id="S3.SS2.p11.2.m2.1.1.2.cmml" xref="S3.SS2.p11.2.m2.1.1.2">ğ‘›</ci><ci id="S3.SS2.p11.2.m2.1.1.3.cmml" xref="S3.SS2.p11.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.2.m2.1c">n\times t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.2.m2.1d">italic_n Ã— italic_t</annotation></semantics></math> total prompts. For ZSC, we mean pool <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p11.3.m3.1"><semantics id="S3.SS2.p11.3.m3.1a"><mi id="S3.SS2.p11.3.m3.1.1" xref="S3.SS2.p11.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.3.m3.1b"><ci id="S3.SS2.p11.3.m3.1.1.cmml" xref="S3.SS2.p11.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.3.m3.1d">italic_N</annotation></semantics></math> text embeddings corresponding to the prompts for every label (<math alttext="\mathbb{R}^{N\times d}\rightarrow\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS2.p11.4.m4.1"><semantics id="S3.SS2.p11.4.m4.1a"><mrow id="S3.SS2.p11.4.m4.1.1" xref="S3.SS2.p11.4.m4.1.1.cmml"><msup id="S3.SS2.p11.4.m4.1.1.2" xref="S3.SS2.p11.4.m4.1.1.2.cmml"><mi id="S3.SS2.p11.4.m4.1.1.2.2" xref="S3.SS2.p11.4.m4.1.1.2.2.cmml">â„</mi><mrow id="S3.SS2.p11.4.m4.1.1.2.3" xref="S3.SS2.p11.4.m4.1.1.2.3.cmml"><mi id="S3.SS2.p11.4.m4.1.1.2.3.2" xref="S3.SS2.p11.4.m4.1.1.2.3.2.cmml">N</mi><mo id="S3.SS2.p11.4.m4.1.1.2.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p11.4.m4.1.1.2.3.1.cmml">Ã—</mo><mi id="S3.SS2.p11.4.m4.1.1.2.3.3" xref="S3.SS2.p11.4.m4.1.1.2.3.3.cmml">d</mi></mrow></msup><mo id="S3.SS2.p11.4.m4.1.1.1" stretchy="false" xref="S3.SS2.p11.4.m4.1.1.1.cmml">â†’</mo><msup id="S3.SS2.p11.4.m4.1.1.3" xref="S3.SS2.p11.4.m4.1.1.3.cmml"><mi id="S3.SS2.p11.4.m4.1.1.3.2" xref="S3.SS2.p11.4.m4.1.1.3.2.cmml">â„</mi><mi id="S3.SS2.p11.4.m4.1.1.3.3" xref="S3.SS2.p11.4.m4.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.4.m4.1b"><apply id="S3.SS2.p11.4.m4.1.1.cmml" xref="S3.SS2.p11.4.m4.1.1"><ci id="S3.SS2.p11.4.m4.1.1.1.cmml" xref="S3.SS2.p11.4.m4.1.1.1">â†’</ci><apply id="S3.SS2.p11.4.m4.1.1.2.cmml" xref="S3.SS2.p11.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p11.4.m4.1.1.2.1.cmml" xref="S3.SS2.p11.4.m4.1.1.2">superscript</csymbol><ci id="S3.SS2.p11.4.m4.1.1.2.2.cmml" xref="S3.SS2.p11.4.m4.1.1.2.2">â„</ci><apply id="S3.SS2.p11.4.m4.1.1.2.3.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3"><times id="S3.SS2.p11.4.m4.1.1.2.3.1.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3.1"></times><ci id="S3.SS2.p11.4.m4.1.1.2.3.2.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3.2">ğ‘</ci><ci id="S3.SS2.p11.4.m4.1.1.2.3.3.cmml" xref="S3.SS2.p11.4.m4.1.1.2.3.3">ğ‘‘</ci></apply></apply><apply id="S3.SS2.p11.4.m4.1.1.3.cmml" xref="S3.SS2.p11.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p11.4.m4.1.1.3.1.cmml" xref="S3.SS2.p11.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p11.4.m4.1.1.3.2.cmml" xref="S3.SS2.p11.4.m4.1.1.3.2">â„</ci><ci id="S3.SS2.p11.4.m4.1.1.3.3.cmml" xref="S3.SS2.p11.4.m4.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.4.m4.1c">\mathbb{R}^{N\times d}\rightarrow\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.4.m4.1d">blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_d end_POSTSUPERSCRIPT â†’ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.p11.5.m5.1"><semantics id="S3.SS2.p11.5.m5.1a"><mi id="S3.SS2.p11.5.m5.1.1" xref="S3.SS2.p11.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p11.5.m5.1b"><ci id="S3.SS2.p11.5.m5.1.1.cmml" xref="S3.SS2.p11.5.m5.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p11.5.m5.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p11.5.m5.1d">italic_d</annotation></semantics></math> is the shape of embedding output by CLAP). Finally, we calculate the cosine similarity between each audio embedding and all text embedding for all the labels for ZSAC.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental Setup</span>
</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">ReCLAP Training Datasets.</span> We train ReCLAP from scratch on a collection of multiple datasets including Sound-VECapsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib19" title="">19</a>]</cite> and CompA-660kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>. Detailed statistics about each dataset are provided on our GitHub. Our dataset has <math alttext="\approx" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><approx id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">â‰ˆ</annotation></semantics></math>2.3M audio-caption pairs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Evaluation Datasets.</span> For ZSAC, we adopt an evaluation setup similar to prior worksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> and employ AudioSetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib10" title="">10</a>]</cite>, ESC-50Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib11" title="">11</a>]</cite>, FSD50kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib20" title="">20</a>]</cite>, NSynthÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib21" title="">21</a>]</cite>, TUT-UrbanÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib22" title="">22</a>]</cite>, UrbanSound8KÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib23" title="">23</a>]</cite> and VGGSoundÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib24" title="">24</a>]</cite>. We evaluate for accuracy on multi-class and mAP for multi-label.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.2"><span class="ltx_text ltx_font_bold" id="S4.p3.2.1">Model Architecture and Hyper-parameters.</span> We follow the same model architecture as CompA-CLAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite> with a T5Â <sub class="ltx_sub" id="S4.p3.2.2">large</sub> text encoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib25" title="">25</a>]</cite> and HTSATÂ <sub class="ltx_sub" id="S4.p3.2.3">base</sub> audio encoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib26" title="">26</a>]</cite>. We train ReCLAP with a learning rate of 5e-4 and an effective batch size (BS) of 256. This BS is smaller than that in the literature, but we do so due to computational constraints. We employed <math alttext="k" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><mi id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">italic_k</annotation></semantics></math>=4 for caption and <math alttext="N" class="ltx_Math" display="inline" id="S4.p3.2.m2.1"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.1d">italic_N</annotation></semantics></math> = 2 for prompt augmentation.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span><span class="ltx_text" id="S4.T2.2.1" style="font-size:90%;">Performance comparison of ReCLAP with baselines on Zero-shot Audio classification benchmarks. ReCLAP outperforms baselines by 0.6%-54.8%.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.3" style="width:650.4pt;height:329.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(58.8pt,-29.8pt) scale(1.22076225264085,1.22076225264085) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt ltx_border_tt" colspan="2" id="S4.T2.3.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.2">ESC-50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.3">US8K</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.4">VGGSound</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.5">FSD50K</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.6">TUT</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.7">AudioSet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S4.T2.3.1.1.1.8">NSynth</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.1.2.1.1" rowspan="7"><span class="ltx_text" id="S4.T2.3.1.2.1.1.1">w/o Prompt Aug.</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.1.2.1.2">Wav2CLIP</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.3">41.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.4">40.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.5">10.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.6">3.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.7">28.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.8">5.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.2.1.9">5.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.3.2.1">AudioClip</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.2">69.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.3">65.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.4">9.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.5">6.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.6">29.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.7">3.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.3.2.8">6.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.4.3.1">CLAP</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.2">82.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.3">73.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.4">16.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.5">14.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.6">29.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.7">5.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.3.8">9.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.5.4.1">LAION-CLAP (repro.)</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.2">88.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.3">74.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.4">21.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.5">22.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.6">58.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.7">20.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4.8">11.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.6.5.1">CoLLAT</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.2">84.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.3">77.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.5">19.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.6">29.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.7">9.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5.8">-</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.7.6.1">CompA-CLAP</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.2">86.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.3">88.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.4">21.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.5">19.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.6">56.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.7">21.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6.8">11.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.8.7.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.1.1" style="background-color:#F2F2F2;">CLAP-2.3M</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.2.1" style="background-color:#F2F2F2;">88.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.3.1" style="background-color:#F2F2F2;">90.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.4.1" style="background-color:#F2F2F2;">24.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.5.1" style="background-color:#F2F2F2;">30.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.6.1" style="background-color:#F2F2F2;">61.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.7.1" style="background-color:#F2F2F2;">21.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.8.7.8.1" style="background-color:#F2F2F2;">11.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.9.8.1">
<span class="ltx_ERROR undefined" id="S4.T2.3.1.9.8.1.1">\cdashline</span>2-9</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.9.8.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.2.1" style="background-color:#F2F2F2;">ReCLAP</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.3.1" style="background-color:#F2F2F2;">90.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.4.1" style="background-color:#F2F2F2;">94.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.5.1" style="background-color:#F2F2F2;">24.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.6.1" style="background-color:#F2F2F2;">27.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.7.1" style="background-color:#F2F2F2;">63.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.8.1" style="background-color:#F2F2F2;">23.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8.9" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.9.8.9.1" style="background-color:#F2F2F2;">11.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T2.3.1.10.9.1" rowspan="5"><span class="ltx_text" id="S4.T2.3.1.10.9.1.1">w/ Prompt Aug.</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T2.3.1.10.9.2">CLAP</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.3">83.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.4">74.5</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.5">16.4</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.6">14.9</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.7">33.7</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.8">6.2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.10.9.9">10.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.11.10.1">LAION-CLAP (repro.)</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.2">89.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.3">76.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.4">23.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.5">24.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.6">61.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.7">21.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10.8">12.4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.12.11.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.1.1" style="background-color:#F2F2F2;">CLAP-2.3M</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.2.1" style="background-color:#F2F2F2;">89.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.3.1" style="background-color:#F2F2F2;">91.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.4.1" style="background-color:#F2F2F2;">25.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.5" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.12.11.5.1" style="background-color:#F2F2F2;">37.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.6.1" style="background-color:#F2F2F2;">63.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.7.1" style="background-color:#F2F2F2;">23.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.12.11.8.1" style="background-color:#F2F2F2;">13.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.13.12.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.1.1" style="background-color:#F2F2F2;">ReCLAP-660k</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.2" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.2.1" style="background-color:#F2F2F2;">89.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.3" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.3.1" style="background-color:#F2F2F2;">79.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.4" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.4.1" style="background-color:#F2F2F2;">25.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.5.1" style="background-color:#F2F2F2;">28.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.6" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.6.1" style="background-color:#F2F2F2;">60.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.7" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.7.1" style="background-color:#F2F2F2;">22.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.13.12.8" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.13.12.8.1" style="background-color:#F2F2F2;">13.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.1.14.13.1" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.14.13.1.1" style="background-color:#F2F2F2;">ReCLAP w/ only desc.</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.2" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.2.1" style="background-color:#F2F2F2;">89.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.3" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.3.1" style="background-color:#F2F2F2;">92.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.4" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.4.1" style="background-color:#F2F2F2;">26.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.5" style="background-color:#F2F2F2;"><span class="ltx_text" id="S4.T2.3.1.14.13.5.1" style="background-color:#F2F2F2;">37.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.6" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.6.1" style="background-color:#F2F2F2;">65.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.7" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.7.1" style="background-color:#F2F2F2;">25.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.14.13.8" style="background-color:#F2F2F2;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T2.3.1.14.13.8.1" style="background-color:#F2F2F2;">14.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T2.3.1.15.14.1">
<span class="ltx_ERROR undefined" id="S4.T2.3.1.15.14.1.1">\cdashline</span>2-9</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T2.3.1.15.14.2" style="background-color:#D9D9D9;"><span class="ltx_text" id="S4.T2.3.1.15.14.2.1" style="background-color:#D9D9D9;">ReCLAP</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.3" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.3.1" style="background-color:#D9D9D9;">92.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.4" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.4.1" style="background-color:#D9D9D9;">95.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.5" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.5.1" style="background-color:#D9D9D9;">29.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.6" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.6.1" style="background-color:#D9D9D9;">40.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.7" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.7.1" style="background-color:#D9D9D9;">67.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.8" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.8.1" style="background-color:#D9D9D9;">26.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.15.14.9" style="background-color:#D9D9D9;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.15.14.9.1" style="background-color:#D9D9D9;">14.7</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.p4.1.1">Baselines.</span> We use the following baselines for comparison: MMT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib27" title="">27</a>]</cite>, ML-ACTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib28" title="">28</a>]</cite>, CLAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib1" title="">1</a>]</cite>, CompA-CLAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>, LAION-CLAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib13" title="">13</a>]</cite> and LAION-CLAPÂ <span class="ltx_text ltx_font_italic" id="S4.p4.1.2">(ours)</span> (reproduced with BS=256 and excluding non-open-source datasets). For ZSAC, we compare with all the baselines mentioned earlier as well as Wav2CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib29" title="">29</a>]</cite>, AudioClipÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib30" title="">30</a>]</cite>, CoLLATÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib7" title="">7</a>]</cite> and ReCLAP w/ only desc. where we only employ <math alttext="t" class="ltx_Math" display="inline" id="S4.p4.1.m1.1"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.p4.1.m1.1d">italic_t</annotation></semantics></math> acoustic properties as prompts and donâ€™t generate captions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p5">
<p class="ltx_p" id="S4.p5.2"><span class="ltx_text ltx_font_bold" id="S4.p5.2.1">Ablations.</span> We perform several ablations to prove the effectiveness of our approach. <span class="ltx_text ltx_font_bold" id="S4.p5.2.2">For multi-modal retrieval:</span> (i) ReCLAP-660k: ReCLAP trained with caption augmentations on 660k pairs from Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>; (ii) CLAP-2.3M.: CLAP trained on our 2.3M audio-caption dataset (without caption augmentations). <span class="ltx_text ltx_font_bold" id="S4.p5.2.3">For ZSAC:</span> For ZSAC we add another ablation which is: ReCLAP w/ only desc: ZSAC with ReCLAP with only the <math alttext="t" class="ltx_Math" display="inline" id="S4.p5.1.m1.1"><semantics id="S4.p5.1.m1.1a"><mi id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><ci id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.p5.1.m1.1d">italic_t</annotation></semantics></math> descriptions as prompts from the prompt augmentation stage and do not generate the <math alttext="N" class="ltx_Math" display="inline" id="S4.p5.2.m2.1"><semantics id="S4.p5.2.m2.1a"><mi id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b"><ci id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.p5.2.m2.1d">italic_N</annotation></semantics></math> diverse scenario prompts.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S3.T1" title="TABLE I â€£ III-B Prompt Augmentation for ZSAC â€£ III Methodology â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">I</span></a> compares ReCLAP to prior works on AudioCaps and Clotho for text-to-audio and audio-to-text retrieval, showing SOTA performance in most cases. ReCLAP-660k, trained on the same data as CompA-CLAP, surpasses it on all metrics, and similar results are seen for CLAP-2.3M vs. ReCLAP. This demonstrates that ReCLAPâ€™s improvements are not due to dataset size alone. Inspired by Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#bib.bib2" title="">2</a>]</cite>, we argue that current benchmarks do not fully capture ReCLAPâ€™s capabilities in free-form T-A and A-T retrieval.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S4.T2" title="TABLE II â€£ IV Experimental Setup â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">II</span></a> compares our prompt augmentation method (â€œw/ Prompt Augâ€) with standard template-based prompting (â€œw/o Prompt Augâ€). Prompt augmentation consistently outperforms baselines, with gains of 0.6%-54.8%. ReCLAP shows a 0.9%-17.5% improvement with prompt augmentation. In contrast, CLAP and LAION-CLAP show limited gains, indicating they donâ€™t interpret sound descriptions as effectively as ReCLAP. This highlights the importance of caption augmentation training as a prior step.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Result Analysis</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S6.F2" title="Figure 2 â€£ VI Result Analysis â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates how ReCLAP and prompt augmentation increase the number of correct predictions for 4 labels from different datasets on ZSAC. As we can see, training CLAP on caption augmentation on the same dataset (CLAP-2.3M vs ReCLAP) improves retrieval of the correct label, which is further boosted by prompt augmentation.</p>
</div>
<figure class="ltx_figure" id="S6.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="S6.F2.g1" src="x2.png" width="300"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text" id="S6.F2.2.1" style="font-size:90%;">Comparison of accurately classified instances for 4 labels.</span></figcaption>
</figure>
<figure class="ltx_table" id="S6.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span><span class="ltx_text" id="S6.T3.2.1" style="font-size:90%;">Examples of ambiguous labels where prompt augmentations provide additional context.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S6.T3.3" style="width:433.6pt;height:183.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(25.5pt,-10.8pt) scale(1.13323389690788,1.13323389690788) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T3.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T3.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S6.T3.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T3.3.1.1.1.1.1">Label</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_tt" id="S6.T3.3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T3.3.1.1.1.2.1">Prompt Augmentation</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.3.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.2.1.1">metro station (TUT)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.2.1.2">A metallic rhapsody performed by the tireless locomotives,</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.3.2">
<td class="ltx_td" id="S6.T3.3.1.3.2.1"></td>
<td class="ltx_td ltx_align_left" id="S6.T3.3.1.3.2.2">with a recurring refrain from the stationâ€™s vocal spirit.</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.4.3.1">airport (TUT)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.4.3.2">A chorus of engines hums persistently, interspersed with the</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.5.4">
<td class="ltx_td" id="S6.T3.3.1.5.4.1"></td>
<td class="ltx_td ltx_align_left" id="S6.T3.3.1.5.4.2">murmur of voices and authoritative announcements.</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.6.5.1">organ (NSynth)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.6.5.2">The organ unfurled a tapestry of majestic harmonies, filling</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.7.6">
<td class="ltx_td" id="S6.T3.3.1.7.6.1"></td>
<td class="ltx_td ltx_align_left" id="S6.T3.3.1.7.6.2">the cathedral with its thunderous hymn.</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.8.7.1">writing (FSD50K)</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T3.3.1.8.7.2">In the hush of the library, the rhythmic scratch of pen on</td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.9.8">
<td class="ltx_td ltx_border_bb" id="S6.T3.3.1.9.8.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T3.3.1.9.8.2">paper becomes a soft dance of intellect and ink.</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">For example, the sound of an "organ" could refer to either a human organ or a musical instrument. By adding useful contextual information, prompt augmentations assist in clarifying such ambiguities, leading to more accurate retrievals.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Hyper-parameter Tuning</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.4">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S7.T4" title="TABLE IV â€£ VII Hyper-parameter Tuning â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">IV</span></a> compares performance across <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.1.m1.1"><semantics id="S7.p1.1.m1.1a"><mi id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><ci id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.1.m1.1d">italic_N</annotation></semantics></math>={1,2,3,4,5} to show the effect of the number of custom prompts <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.2.m2.1"><semantics id="S7.p1.2.m2.1a"><mi id="S7.p1.2.m2.1.1" xref="S7.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.2.m2.1b"><ci id="S7.p1.2.m2.1.1.cmml" xref="S7.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.2.m2.1d">italic_N</annotation></semantics></math> on the final ZSAC performance. As we see, the optimal performance is achieved at <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.3.m3.1"><semantics id="S7.p1.3.m3.1a"><mi id="S7.p1.3.m3.1.1" xref="S7.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.3.m3.1b"><ci id="S7.p1.3.m3.1.1.cmml" xref="S7.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.3.m3.1d">italic_N</annotation></semantics></math>=2, and model performance decreases with an increase in <math alttext="N" class="ltx_Math" display="inline" id="S7.p1.4.m4.1"><semantics id="S7.p1.4.m4.1a"><mi id="S7.p1.4.m4.1.1" xref="S7.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.p1.4.m4.1b"><ci id="S7.p1.4.m4.1.1.cmml" xref="S7.p1.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.p1.4.m4.1d">italic_N</annotation></semantics></math>. This decline is hypothesized to be due to the introduction of more noise into the process with each additional caption.</p>
</div>
<figure class="ltx_table" id="S7.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span><span class="ltx_text" id="S7.T4.2.1" style="font-size:90%;">Impact of <math alttext="N" class="ltx_Math" display="inline" id="S7.T4.2.1.m1.1"><semantics id="S7.T4.2.1.m1.1b"><mi id="S7.T4.2.1.m1.1.1" xref="S7.T4.2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.T4.2.1.m1.1c"><ci id="S7.T4.2.1.m1.1.1.cmml" xref="S7.T4.2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.2.1.m1.1d">N</annotation><annotation encoding="application/x-llamapun" id="S7.T4.2.1.m1.1e">italic_N</annotation></semantics></math> on ZSAC with ReCLAP.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T4.3" style="width:325.2pt;height:56.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(59.3pt,-10.3pt) scale(1.57425286235649,1.57425286235649) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T4.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S7.T4.3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S7.T4.3.1.1.1"><math alttext="N" class="ltx_Math" display="inline" id="S7.T4.3.1.1.1.m1.1"><semantics id="S7.T4.3.1.1.1.m1.1a"><mi id="S7.T4.3.1.1.1.m1.1.1" xref="S7.T4.3.1.1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.T4.3.1.1.1.m1.1b"><ci id="S7.T4.3.1.1.1.m1.1.1.cmml" xref="S7.T4.3.1.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.3.1.1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S7.T4.3.1.1.1.m1.1d">italic_N</annotation></semantics></math></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.2">1</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.3">2</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.4">3</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.5">4</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T4.3.1.1.6">5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T4.3.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S7.T4.3.1.2.1.1">Score</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.2">48.56</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S7.T4.3.1.2.1.3.1">52.22</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S7.T4.3.1.2.1.4.1">49.37</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.5">47.24</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_b ltx_border_t" id="S7.T4.3.1.2.1.6">44.35</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Additionally, TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.09213v1#S7.T5" title="TABLE V â€£ VII Hyper-parameter Tuning â€£ ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds"><span class="ltx_text ltx_ref_tag">V</span></a> shows the effect of probability <math alttext="p" class="ltx_Math" display="inline" id="S7.p2.1.m1.1"><semantics id="S7.p2.1.m1.1a"><mi id="S7.p2.1.m1.1.1" xref="S7.p2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.p2.1.m1.1b"><ci id="S7.p2.1.m1.1.1.cmml" xref="S7.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p2.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S7.p2.1.m1.1d">italic_p</annotation></semantics></math> on the final ZSAC performance.</p>
</div>
<figure class="ltx_table" id="S7.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE V: </span><span class="ltx_text" id="S7.T5.2.1" style="font-size:90%;">Impact of <math alttext="p" class="ltx_Math" display="inline" id="S7.T5.2.1.m1.1"><semantics id="S7.T5.2.1.m1.1b"><mi id="S7.T5.2.1.m1.1.1" xref="S7.T5.2.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.T5.2.1.m1.1c"><ci id="S7.T5.2.1.m1.1.1.cmml" xref="S7.T5.2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.2.1.m1.1d">p</annotation><annotation encoding="application/x-llamapun" id="S7.T5.2.1.m1.1e">italic_p</annotation></semantics></math> on ZSAC with ReCLAP.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T5.3" style="width:325.2pt;height:65.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(73.7pt,-14.9pt) scale(1.82904540884783,1.82904540884783) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T5.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S7.T5.3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S7.T5.3.1.1.1"><math alttext="p" class="ltx_Math" display="inline" id="S7.T5.3.1.1.1.m1.1"><semantics id="S7.T5.3.1.1.1.m1.1a"><mi id="S7.T5.3.1.1.1.m1.1.1" xref="S7.T5.3.1.1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.T5.3.1.1.1.m1.1b"><ci id="S7.T5.3.1.1.1.m1.1.1.cmml" xref="S7.T5.3.1.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.3.1.1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S7.T5.3.1.1.1.m1.1d">italic_p</annotation></semantics></math></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.2">0.2</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.3">0.4</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.4">0.6</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T5.3.1.1.5">0.8</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T5.3.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S7.T5.3.1.2.1.1">Score</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.2">47.16</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S7.T5.3.1.2.1.3.1">52.22</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S7.T5.3.1.2.1.4.1">48.29</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="S7.T5.3.1.2.1.5">45.64</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span class="ltx_text ltx_font_smallcaps" id="S8.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">In this paper, we propose to improve ZSAC by interpreting sounds using their descriptive features. To achieve this, we first propose ReCLAP, a CLAP model trained using additional caption augmentations that improve CLAPâ€™s understanding of sounds in the wild. Next, we propose to improve ZSAC with prompt augmentation, where we move beyond standard hand-written prompts and generate custom prompts for each category in the dataset. Our proposed method improves ZSAC over our baselines by significant margins.</p>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IX </span><span class="ltx_text ltx_font_smallcaps" id="S9.1.1">Limitations and Future Work</span>
</h2>
<div class="ltx_para" id="S9.p1">
<ol class="ltx_enumerate" id="S9.I1">
<li class="ltx_item" id="S9.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S9.I1.i1.p1">
<p class="ltx_p" id="S9.I1.i1.p1.1">LLM-generated augmentations may result in errors or repetitive captions, which require substantial human oversight. Future work will explore methods to improve quality control.</p>
</div>
</li>
<li class="ltx_item" id="S9.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S9.I1.i2.p1">
<p class="ltx_p" id="S9.I1.i2.p1.1">Synthetic augmentations from LLMs may introduce biases into models. Future efforts will focus on mitigating these biases.</p>
</div>
</li>
<li class="ltx_item" id="S9.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S9.I1.i3.p1">
<p class="ltx_p" id="S9.I1.i3.p1.1">Representations from ReCLAP can be employed to improve a range of tasks, including audio generation and understanding. Future work includes exploring these tasks.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Benjamin Elizalde, Soham Deshmukh, Mahmoud AlÂ Ismail, and Huaming Wang,

</span>
<span class="ltx_bibblock">â€œClap learning audio concepts from natural language supervision,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2023, pp. 1â€“5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Sreyan Ghosh, Ashish Seth, Sonal Kumar, Utkarsh Tyagi, Chandra KiranÂ Reddy Evuru, Ramaneswaran S, SÂ Sakshi, Oriol Nieto, Ramani Duraiswami, and Dinesh Manocha,

</span>
<span class="ltx_bibblock">â€œCompa: Addressing the gap in compositional reasoning in audio-language models,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Soham Deshmukh, Benjamin Elizalde, Rita Singh, and Huaming Wang,

</span>
<span class="ltx_bibblock">â€œPengi: An audio language model for audio tasks,â€ 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Zhifeng Kong, Arushi Goel, Rohan Badlani, Wei Ping, Rafael Valle, and Bryan Catanzaro,

</span>
<span class="ltx_bibblock">â€œAudio flamingo: A novel audio language model with few-shot learning and dialogue abilities,â€ 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Sreyan Ghosh, Sonal Kumar, Chandra KiranÂ Reddy Evuru, Ramani Duraiswami, and Dinesh Manocha,

</span>
<span class="ltx_bibblock">â€œRecap: Retrieval-augmented audio captioning,â€ 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Haohe Liu, Zehua Chen, YiÂ Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and MarkÂ D Plumbley,

</span>
<span class="ltx_bibblock">â€œAudioldm: Text-to-audio generation with latent diffusion models,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2301.12503</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Amila Silva, Spencer Whitehead, Chris Lengerich, and HughÂ James Leather,

</span>
<span class="ltx_bibblock">â€œCoLLAT: On adding fine-grained audio understanding to language models using token-level locked-language tuning,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Thirty-seventh Conference on Neural Information Processing Systems</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, etÂ al.,

</span>
<span class="ltx_bibblock">â€œLearning transferable visual models from natural language supervision,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">International conference on machine learning</span>. PMLR, 2021, pp. 8748â€“8763.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Tiago Tavares, Fabio Ayres, Zhepei Wang, and Paris Smaragdis,

</span>
<span class="ltx_bibblock">â€œOn class separability pitfalls in audio-text contrastive zero-shot learning,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2408.13068</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
JortÂ F Gemmeke, DanielÂ PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, RÂ Channing Moore, Manoj Plakal, and Marvin Ritter,

</span>
<span class="ltx_bibblock">â€œAudio set: An ontology and human-labeled dataset for audio events,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span>. IEEE, 2017, pp. 776â€“780.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
KarolÂ J. Piczak,

</span>
<span class="ltx_bibblock">â€œESC: Dataset for Environmental Sound Classification,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 23rd Annual ACM Conference on Multimedia</span>. pp. 1015â€“1018, ACM Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Il-Young Jeong and Jeongsoo Park,

</span>
<span class="ltx_bibblock">â€œCochlscene: Acquisition of acoustic scene data using crowdsourcing,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">2022 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</span>. IEEE, 2022, pp. 17â€“21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Yusong Wu*, KeÂ Chen*, Tianyu Zhang*, Yuchen Hui*, Taylor Berg-Kirkpatrick, and Shlomo Dubnov,

</span>
<span class="ltx_bibblock">â€œLarge-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Deepanway Ghosal, Navonil Majumder, Ambuj Mehrish, and Soujanya Poria,

</span>
<span class="ltx_bibblock">â€œText-to-audio generation using instruction tuned llm and latent diffusion model,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2304.13731</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Rongjie Huang, Jiawei Huang, Dongchao Yang, YiÂ Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao,

</span>
<span class="ltx_bibblock">â€œMake-an-audio: Text-to-audio generation with prompt-enhanced diffusion models,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2301.12661</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Andrea Agostinelli, TimoÂ I. Denk, ZalÃ¡n Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco Tagliasacchi, Matt Sharifi, Neil Zeghidour, and Christian Frank,

</span>
<span class="ltx_bibblock">â€œMusiclm: Generating music from text,â€ 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Yuan Gong, Hongyin Luo, AlexanderÂ H. Liu, Leonid Karlinsky, and JamesÂ R. Glass,

</span>
<span class="ltx_bibblock">â€œListen, think, and understand,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Hugo Touvron etÂ al.,

</span>
<span class="ltx_bibblock">â€œLlama 2: Open foundation and fine-tuned chat models,â€ 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
YiÂ Yuan, Dongya Jia, Xiaobin Zhuang, Yuanzhe Chen, Zhengxi Liu, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xubo Liu, MarkÂ D Plumbley, etÂ al.,

</span>
<span class="ltx_bibblock">â€œImproving audio generation with visual enhanced caption,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2407.04416</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Eduardo Fonseca, Xavier Favory, Jordi Pons, Frederic Font, and Xavier Serra,

</span>
<span class="ltx_bibblock">â€œFsd50k: An open dataset of human-labeled sound events,â€ 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Jesse Engel, Cinjon Resnick, Adam Roberts, Sander Dieleman, Mohammad Norouzi, Douglas Eck, and Karen Simonyan,

</span>
<span class="ltx_bibblock">â€œNeural audio synthesis of musical notes with wavenet autoencoders,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">International Conference on Machine Learning</span>. PMLR, 2017, pp. 1068â€“1077.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Annamaria Mesaros, Toni Heittola, and Tuomas Virtanen,

</span>
<span class="ltx_bibblock">â€œA multi-device dataset for urban acoustic scene classification,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:1807.09840</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Justin Salamon and JuanÂ Pablo Bello,

</span>
<span class="ltx_bibblock">â€œDeep convolutional neural networks and data augmentation for environmental sound classification,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">IEEE Signal processing letters</span>, vol. 24, no. 3, pp. 279â€“283, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Honglie Chen, Weidi Xie, Andrea Vedaldi, and Andrew Zisserman,

</span>
<span class="ltx_bibblock">â€œVggsound: A large-scale audio-visual dataset,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and PeterÂ J. Liu,

</span>
<span class="ltx_bibblock">â€œExploring the limits of transfer learning with a unified text-to-text transformer,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Journal of Machine Learning Research</span>, vol. 21, no. 140, pp. 1â€“67, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
KeÂ Chen, Xingjian Du, Bilei Zhu, Zejun Ma, Taylor Berg-Kirkpatrick, and Shlomo Dubnov,

</span>
<span class="ltx_bibblock">â€œHts-at: A hierarchical token-semantic audio transformer for sound classification and detection,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">ICASSP 2022</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Andreea-Maria Oncescu, AÂ Koepke, JoaoÂ F Henriques, Zeynep Akata, and Samuel Albanie,

</span>
<span class="ltx_bibblock">â€œAudio retrieval with natural language queries,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2105.02192</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Xinhao Mei, Xubo Liu, Jianyuan Sun, MarkÂ D Plumbley, and Wenwu Wang,

</span>
<span class="ltx_bibblock">â€œOn metric learning for audio-text cross-modal retrieval,â€

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2203.15537</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ho-Hsiang Wu, Prem Seetharaman, Kundan Kumar, and JuanÂ Pablo Bello,

</span>
<span class="ltx_bibblock">â€œWav2clip: Learning robust audio representations from clip,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">ICASSP 2022</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Andrey Guzhov, Federico Raue, JÃ¶rn Hees, and Andreas Dengel,

</span>
<span class="ltx_bibblock">â€œAudioclip: Extending clip to image, text and audio,â€

</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">ICASSP 2022</span>, 2022.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 13 21:52:14 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
