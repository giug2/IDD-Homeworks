<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2007.04422] IQ-VQA: Intelligent Visual Question Answering</title><meta property="og:description" content="Even though there has been tremendous progress in the field of Visual Question Answering, models today still tend to be inconsistent and brittle. To this end, we propose a model-independent cyclic framework which incre…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="IQ-VQA: Intelligent Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="IQ-VQA: Intelligent Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2007.04422">

<!--Generated on Sat Mar  2 11:00:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">IQ-VQA: Intelligent Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vatsal Goel
</span><span class="ltx_author_notes">Equal Contribution</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohit Chandak<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ashish Anand
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Prithwijit Guha
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Indian Institute of Technology, Guwahati
<br class="ltx_break"><span id="id8.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{vatsal29, mohit, anand.ashish, pguha}@iitg.ac.in</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Even though there has been tremendous progress in the field of Visual Question Answering, models today still tend to be inconsistent and brittle. To this end, we propose a model-independent cyclic framework which increases consistency and robustness of any VQA architecture. We train our models to answer the original question, generate an implication based on the answer and then also learn to answer the generated implication correctly. As a part of the cyclic framework, we propose a novel implication generator which can generate implied questions from any question-answer pair. As a baseline for future works on consistency, we provide a new human annotated VQA-Implications dataset. The dataset consists of <span id="id9.id1.1" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>30k questions containing implications of 3 types - Logical Equivalence, Necessary Condition and Mutual Exclusion - made from the VQA v2.0 validation dataset. We show that our framework improves consistency of VQA models by <span id="id9.id1.2" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>15% on the rule-based dataset, <span id="id9.id1.3" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>7% on VQA-Implications dataset and robustness by <span id="id9.id1.4" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>2%, without degrading their performance. In addition, we also quantitatively show improvement in attention maps which highlights better multi-modal understanding of vision and language.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Visual Question Answering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> task requires an AI system to answer natural language questions on a contextual image. Ideally, this system should be equipped with the ability to extract useful information (with reference to the question) by looking at the image. To answer these questions correctly, the system should not only identify the color, size, or shape of objects, but may also require general knowledge and reasoning abilities which makes the task more challenging.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> have pointed out strong language priors present in the VQA dataset. This could result in false impression of good performance by many state of the art models, without them actually understanding the image. For instance, answering any question starting with “What sport is” by “tennis” results in 41% accuracy. Moreover, citing the ‘visual priming bias’ present in the VQA dataset, questions starting with “Do you see a ..” result in ”yes” 87% of the time.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.04422/assets/images/cons.jpg" id="S1.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="135" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Input image</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<table id="S1.F1.sf2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.F1.sf2.1.1.1" class="ltx_tr">
<th id="S1.F1.sf2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S1.F1.sf2.1.1.1.1.1" class="ltx_text ltx_font_bold">Original</span></th>
<th id="S1.F1.sf2.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">How many sailboats are there?</th>
<th id="S1.F1.sf2.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.F1.sf2.1.2.1" class="ltx_tr">
<td id="S1.F1.sf2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.F1.sf2.1.2.1.1.1" class="ltx_text ltx_font_bold">Logeq</span></td>
<td id="S1.F1.sf2.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">Is there 1 sailboat?</td>
<td id="S1.F1.sf2.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S1.F1.sf2.1.2.1.3.1" class="ltx_text" style="color:#FF0000;">no</span></td>
</tr>
<tr id="S1.F1.sf2.1.3.2" class="ltx_tr">
<td id="S1.F1.sf2.1.3.2.1" class="ltx_td ltx_align_left"><span id="S1.F1.sf2.1.3.2.1.1" class="ltx_text ltx_font_bold">Mutex</span></td>
<td id="S1.F1.sf2.1.3.2.2" class="ltx_td ltx_align_right">Are there 2 sailboats?</td>
<td id="S1.F1.sf2.1.3.2.3" class="ltx_td ltx_align_right"><span id="S1.F1.sf2.1.3.2.3.1" class="ltx_text" style="color:#FF0000;">yes</span></td>
</tr>
<tr id="S1.F1.sf2.1.4.3" class="ltx_tr">
<td id="S1.F1.sf2.1.4.3.1" class="ltx_td ltx_align_left"><span id="S1.F1.sf2.1.4.3.1.1" class="ltx_text ltx_font_bold">Nec</span></td>
<td id="S1.F1.sf2.1.4.3.2" class="ltx_td ltx_align_right">Are there any sailboats?</td>
<td id="S1.F1.sf2.1.4.3.3" class="ltx_td ltx_align_right"><span id="S1.F1.sf2.1.4.3.3.1" class="ltx_text" style="color:#FF0000;">no</span></td>
</tr>
<tr id="S1.F1.sf2.1.5.4" class="ltx_tr">
<td id="S1.F1.sf2.1.5.4.1" class="ltx_td ltx_align_left"><span id="S1.F1.sf2.1.5.4.1.1" class="ltx_text ltx_font_bold">Rep</span></td>
<td id="S1.F1.sf2.1.5.4.2" class="ltx_td ltx_align_right">What is the number of sailboats?</td>
<td id="S1.F1.sf2.1.5.4.3" class="ltx_td ltx_align_right"><span id="S1.F1.sf2.1.5.4.3.1" class="ltx_text" style="color:#FF0000;">2</span></td>
</tr>
<tr id="S1.F1.sf2.1.6.5" class="ltx_tr">
<td id="S1.F1.sf2.1.6.5.1" class="ltx_td ltx_align_left"><span id="S1.F1.sf2.1.6.5.1.1" class="ltx_text ltx_font_bold">Rep</span></td>
<td id="S1.F1.sf2.1.6.5.2" class="ltx_td ltx_align_right">How many sailboats can you see?</td>
<td id="S1.F1.sf2.1.6.5.3" class="ltx_td ltx_align_right"><span id="S1.F1.sf2.1.6.5.3.1" class="ltx_text" style="color:#FF0000;">2</span></td>
</tr>
<tr id="S1.F1.sf2.1.7.6" class="ltx_tr">
<td id="S1.F1.sf2.1.7.6.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S1.F1.sf2.1.7.6.1.1" class="ltx_text ltx_font_bold">Rep</span></td>
<td id="S1.F1.sf2.1.7.6.2" class="ltx_td ltx_align_right ltx_border_bb">How many sailboats do you see?</td>
<td id="S1.F1.sf2.1.7.6.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S1.F1.sf2.1.7.6.3.1" class="ltx_text" style="color:#FF0000;">2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Implications and Rephrasings answered incorrectly</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S1.F1.2.1" class="ltx_text ltx_font_bold">An example of inconsistent and brittle nature of VQA models</span>. Even though the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> correctly answers the original question, it fails to answer any of the 3 generated implications and rephrasings correctly.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Many recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> have shown that despite having high accuracy on questions present in the dataset, these models perform poorly when rephrased or implied questions are asked and hence are not intelligent enough to be deployed in the real world. Fig <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the inconsistent and brittle nature of VQA models. Despite answering the original question correctly, the model fails to answer rephrased and implied questions related to the original question. This shows that models learn from language biases in the dataset to some extent, rather than correctly understanding the context of the image.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.7" class="ltx_p">Throughout the paper, <span id="S1.p4.7.1" class="ltx_text ltx_font_bold">Implications</span> are defined as questions <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="Q_{imp}" display="inline"><semantics id="S1.p4.1.m1.1a"><msub id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml"><mi id="S1.p4.1.m1.1.1.2" xref="S1.p4.1.m1.1.1.2.cmml">Q</mi><mrow id="S1.p4.1.m1.1.1.3" xref="S1.p4.1.m1.1.1.3.cmml"><mi id="S1.p4.1.m1.1.1.3.2" xref="S1.p4.1.m1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S1.p4.1.m1.1.1.3.1" xref="S1.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S1.p4.1.m1.1.1.3.3" xref="S1.p4.1.m1.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S1.p4.1.m1.1.1.3.1a" xref="S1.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S1.p4.1.m1.1.1.3.4" xref="S1.p4.1.m1.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><apply id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p4.1.m1.1.1.1.cmml" xref="S1.p4.1.m1.1.1">subscript</csymbol><ci id="S1.p4.1.m1.1.1.2.cmml" xref="S1.p4.1.m1.1.1.2">𝑄</ci><apply id="S1.p4.1.m1.1.1.3.cmml" xref="S1.p4.1.m1.1.1.3"><times id="S1.p4.1.m1.1.1.3.1.cmml" xref="S1.p4.1.m1.1.1.3.1"></times><ci id="S1.p4.1.m1.1.1.3.2.cmml" xref="S1.p4.1.m1.1.1.3.2">𝑖</ci><ci id="S1.p4.1.m1.1.1.3.3.cmml" xref="S1.p4.1.m1.1.1.3.3">𝑚</ci><ci id="S1.p4.1.m1.1.1.3.4.cmml" xref="S1.p4.1.m1.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">Q_{imp}</annotation></semantics></math> which can be answered by knowing the original question <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S1.p4.2.m2.1a"><mi id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><ci id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">Q</annotation></semantics></math> and answer <math id="S1.p4.3.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S1.p4.3.m3.1a"><mi id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><ci id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">A</annotation></semantics></math> without the knowledge of the context i.e. image <math id="S1.p4.4.m4.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S1.p4.4.m4.1a"><mi id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.1b"><ci id="S1.p4.4.m4.1.1.cmml" xref="S1.p4.4.m4.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m4.1c">I</annotation></semantics></math>. We categorize these implications into 3 types - logical equivalence, necessary condition and mutual exclusion - as introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Fig <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows these 3 categories for a QA pair. <span id="S1.p4.7.2" class="ltx_text ltx_font_bold">Consistency</span> is the percentage of implications answered correctly, given that the original question is answered correctly. <span id="S1.p4.7.3" class="ltx_text ltx_font_bold">Rephrasings</span> <math id="S1.p4.5.m5.1" class="ltx_Math" alttext="Q_{R}" display="inline"><semantics id="S1.p4.5.m5.1a"><msub id="S1.p4.5.m5.1.1" xref="S1.p4.5.m5.1.1.cmml"><mi id="S1.p4.5.m5.1.1.2" xref="S1.p4.5.m5.1.1.2.cmml">Q</mi><mi id="S1.p4.5.m5.1.1.3" xref="S1.p4.5.m5.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.5.m5.1b"><apply id="S1.p4.5.m5.1.1.cmml" xref="S1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S1.p4.5.m5.1.1.1.cmml" xref="S1.p4.5.m5.1.1">subscript</csymbol><ci id="S1.p4.5.m5.1.1.2.cmml" xref="S1.p4.5.m5.1.1.2">𝑄</ci><ci id="S1.p4.5.m5.1.1.3.cmml" xref="S1.p4.5.m5.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.5.m5.1c">Q_{R}</annotation></semantics></math> are linguistic variations on original question <math id="S1.p4.6.m6.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S1.p4.6.m6.1a"><mi id="S1.p4.6.m6.1.1" xref="S1.p4.6.m6.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S1.p4.6.m6.1b"><ci id="S1.p4.6.m6.1.1.cmml" xref="S1.p4.6.m6.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.6.m6.1c">Q</annotation></semantics></math> keeping the answer <math id="S1.p4.7.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S1.p4.7.m7.1a"><mi id="S1.p4.7.m7.1.1" xref="S1.p4.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S1.p4.7.m7.1b"><ci id="S1.p4.7.m7.1.1.cmml" xref="S1.p4.7.m7.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.7.m7.1c">A</annotation></semantics></math> exactly same, as introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. <span id="S1.p4.7.4" class="ltx_text ltx_font_bold">Robustness</span> is defined as the accuracy on rephrasings, calculated only on correctly answered original questions.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We believe that any model can be taught to better understand the content of the image by enforcing intelligence through consistency and robustness among the predicted answers. In this paper, we present and demonstrate a cyclic training scheme to solve the above mentioned problem of intelligence. Our framework is model independent and can be integrated with any VQA architecture. The framework consists of a generic VQA module and our implication generation module tailored especially for this task.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Our framework ensures intelligent behaviour of VQA models while answering different questions on the same image. This is achieved in two steps: Implication generator module introduces linguistic variations in the original question based on the answer predicted by the VQA model. Then, the model is again asked to answer this on-the-fly generated question so that it remains consistent with the previously predicted answer. Thus, the VQA architecture is collectively trained to answer questions and their implications correctly. We calculate the consistency of different state of the art models and show that our framework significantly improves consistency and robustness without harming the performance of the VQA model.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">We observe that there is no benchmark for consistency, which perhaps is the reason for limited development in this area. Hence, to promote robust and consistent VQA models in the future we collect a human annotated dataset of around 30k questions on the original VQA v2.0 validation dataset.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Dataset and code will be made publicly available.</span></span></span></p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">In later sections, we demonstrate the quality of these generated questions. We provide a baseline of our implication generator module for future works to compare with. We also perform a comparative study of the attention maps of models trained with our framework to those of baselines. We provide a qualitative and quantitative analysis and observe significant improvement in the quality of these attention maps. This proves that by learning on these variations, our framework not only improves the consistency and robustness of any generic VQA model but also achieves a stronger multi modal understanding of vision and language.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">To summarize, our main contributions in this paper are as follows -</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a model independent cyclic framework which improves consistency and robustness of any given VQA architecture without degrading the architecture’s original validation accuracy.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose a novel implication generator module, which can generate implications <math id="S1.I1.i2.p1.1.m1.2" class="ltx_Math" alttext="G:(Q,A)\longrightarrow Q_{imp}" display="inline"><semantics id="S1.I1.i2.p1.1.m1.2a"><mrow id="S1.I1.i2.p1.1.m1.2.3" xref="S1.I1.i2.p1.1.m1.2.3.cmml"><mi id="S1.I1.i2.p1.1.m1.2.3.2" xref="S1.I1.i2.p1.1.m1.2.3.2.cmml">G</mi><mo lspace="0.278em" rspace="0.278em" id="S1.I1.i2.p1.1.m1.2.3.1" xref="S1.I1.i2.p1.1.m1.2.3.1.cmml">:</mo><mrow id="S1.I1.i2.p1.1.m1.2.3.3" xref="S1.I1.i2.p1.1.m1.2.3.3.cmml"><mrow id="S1.I1.i2.p1.1.m1.2.3.3.2.2" xref="S1.I1.i2.p1.1.m1.2.3.3.2.1.cmml"><mo stretchy="false" id="S1.I1.i2.p1.1.m1.2.3.3.2.2.1" xref="S1.I1.i2.p1.1.m1.2.3.3.2.1.cmml">(</mo><mi id="S1.I1.i2.p1.1.m1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.cmml">Q</mi><mo id="S1.I1.i2.p1.1.m1.2.3.3.2.2.2" xref="S1.I1.i2.p1.1.m1.2.3.3.2.1.cmml">,</mo><mi id="S1.I1.i2.p1.1.m1.2.2" xref="S1.I1.i2.p1.1.m1.2.2.cmml">A</mi><mo stretchy="false" id="S1.I1.i2.p1.1.m1.2.3.3.2.2.3" xref="S1.I1.i2.p1.1.m1.2.3.3.2.1.cmml">)</mo></mrow><mo stretchy="false" id="S1.I1.i2.p1.1.m1.2.3.3.1" xref="S1.I1.i2.p1.1.m1.2.3.3.1.cmml">⟶</mo><msub id="S1.I1.i2.p1.1.m1.2.3.3.3" xref="S1.I1.i2.p1.1.m1.2.3.3.3.cmml"><mi id="S1.I1.i2.p1.1.m1.2.3.3.3.2" xref="S1.I1.i2.p1.1.m1.2.3.3.3.2.cmml">Q</mi><mrow id="S1.I1.i2.p1.1.m1.2.3.3.3.3" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.cmml"><mi id="S1.I1.i2.p1.1.m1.2.3.3.3.3.2" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S1.I1.i2.p1.1.m1.2.3.3.3.3.1" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.1.cmml">​</mo><mi id="S1.I1.i2.p1.1.m1.2.3.3.3.3.3" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S1.I1.i2.p1.1.m1.2.3.3.3.3.1a" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.1.cmml">​</mo><mi id="S1.I1.i2.p1.1.m1.2.3.3.3.3.4" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.4.cmml">p</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.1.m1.2b"><apply id="S1.I1.i2.p1.1.m1.2.3.cmml" xref="S1.I1.i2.p1.1.m1.2.3"><ci id="S1.I1.i2.p1.1.m1.2.3.1.cmml" xref="S1.I1.i2.p1.1.m1.2.3.1">:</ci><ci id="S1.I1.i2.p1.1.m1.2.3.2.cmml" xref="S1.I1.i2.p1.1.m1.2.3.2">𝐺</ci><apply id="S1.I1.i2.p1.1.m1.2.3.3.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3"><ci id="S1.I1.i2.p1.1.m1.2.3.3.1.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.1">⟶</ci><interval closure="open" id="S1.I1.i2.p1.1.m1.2.3.3.2.1.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.2.2"><ci id="S1.I1.i2.p1.1.m1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1">𝑄</ci><ci id="S1.I1.i2.p1.1.m1.2.2.cmml" xref="S1.I1.i2.p1.1.m1.2.2">𝐴</ci></interval><apply id="S1.I1.i2.p1.1.m1.2.3.3.3.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3"><csymbol cd="ambiguous" id="S1.I1.i2.p1.1.m1.2.3.3.3.1.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3">subscript</csymbol><ci id="S1.I1.i2.p1.1.m1.2.3.3.3.2.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3.2">𝑄</ci><apply id="S1.I1.i2.p1.1.m1.2.3.3.3.3.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3"><times id="S1.I1.i2.p1.1.m1.2.3.3.3.3.1.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.1"></times><ci id="S1.I1.i2.p1.1.m1.2.3.3.3.3.2.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.2">𝑖</ci><ci id="S1.I1.i2.p1.1.m1.2.3.3.3.3.3.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.3">𝑚</ci><ci id="S1.I1.i2.p1.1.m1.2.3.3.3.3.4.cmml" xref="S1.I1.i2.p1.1.m1.2.3.3.3.3.4">𝑝</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.1.m1.2c">G:(Q,A)\longrightarrow Q_{imp}</annotation></semantics></math>, for any given question answer pair.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">For future evaluation of consistency, we provide a new VQA-Implication dataset. The dataset consists of <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>30k questions containing implications of 3 types - Logical Equivalence, Necessary Condition and Mutual Exclusion.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.04422/assets/x1.jpg" id="S1.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="87" height="67" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Input image example</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<table id="S1.F2.sf2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.F2.sf2.1.1.1" class="ltx_tr">
<th id="S1.F2.sf2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S1.F2.sf2.1.1.1.1.1" class="ltx_text ltx_font_bold">Original</span></th>
<th id="S1.F2.sf2.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">How many people?</th>
<th id="S1.F2.sf2.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">4</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.F2.sf2.1.2.1" class="ltx_tr">
<th id="S1.F2.sf2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S1.F2.sf2.1.2.1.1.1" class="ltx_text ltx_font_bold">Logeq</span></th>
<td id="S1.F2.sf2.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">Are there 4 people?</td>
<td id="S1.F2.sf2.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">yes</td>
</tr>
<tr id="S1.F2.sf2.1.3.2" class="ltx_tr">
<th id="S1.F2.sf2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S1.F2.sf2.1.3.2.1.1" class="ltx_text ltx_font_bold">Mutex</span></th>
<td id="S1.F2.sf2.1.3.2.2" class="ltx_td ltx_align_right">Are there 5 people?</td>
<td id="S1.F2.sf2.1.3.2.3" class="ltx_td ltx_align_right">no</td>
</tr>
<tr id="S1.F2.sf2.1.4.3" class="ltx_tr">
<th id="S1.F2.sf2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S1.F2.sf2.1.4.3.1.1" class="ltx_text ltx_font_bold">Nec</span></th>
<td id="S1.F2.sf2.1.4.3.2" class="ltx_td ltx_align_right ltx_border_bb">Are there any people?</td>
<td id="S1.F2.sf2.1.4.3.3" class="ltx_td ltx_align_right ltx_border_bb">yes</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Generated implication example</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S1.F2.2.1" class="ltx_text ltx_font_bold">An example of the rule-based implication dataset</span>. Note that the implications can be answered without looking at the image.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Ever since Visual Question Answering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> was introduced, numerous models have been proposed to combine techniques from computer vision and natural language processing using techniques such as CNNs and LSTMs. Some of the best models using complex attention mechanisms include <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. The current state of the art is LXMERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, which uses a transformer network for self and cross attention between vision and language modalities.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.3" class="ltx_p">Analysis of the VQA v1 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> showed the presence of language priors in the dataset. Models were reportedly exploiting these priors as a shortcut for answering questions instead of understanding the image. To tackle this problem, VQA 2.0 was released which created complementary pairs in order to counter these priors. More specifically, for every image, question and answer triplet <math id="S2.p2.1.m1.3" class="ltx_Math" alttext="(I,Q,A)" display="inline"><semantics id="S2.p2.1.m1.3a"><mrow id="S2.p2.1.m1.3.4.2" xref="S2.p2.1.m1.3.4.1.cmml"><mo stretchy="false" id="S2.p2.1.m1.3.4.2.1" xref="S2.p2.1.m1.3.4.1.cmml">(</mo><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">I</mi><mo id="S2.p2.1.m1.3.4.2.2" xref="S2.p2.1.m1.3.4.1.cmml">,</mo><mi id="S2.p2.1.m1.2.2" xref="S2.p2.1.m1.2.2.cmml">Q</mi><mo id="S2.p2.1.m1.3.4.2.3" xref="S2.p2.1.m1.3.4.1.cmml">,</mo><mi id="S2.p2.1.m1.3.3" xref="S2.p2.1.m1.3.3.cmml">A</mi><mo stretchy="false" id="S2.p2.1.m1.3.4.2.4" xref="S2.p2.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.3b"><vector id="S2.p2.1.m1.3.4.1.cmml" xref="S2.p2.1.m1.3.4.2"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝐼</ci><ci id="S2.p2.1.m1.2.2.cmml" xref="S2.p2.1.m1.2.2">𝑄</ci><ci id="S2.p2.1.m1.3.3.cmml" xref="S2.p2.1.m1.3.3">𝐴</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.3c">(I,Q,A)</annotation></semantics></math>, a complimentary image <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="I^{c}" display="inline"><semantics id="S2.p2.2.m2.1a"><msup id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml"><mi id="S2.p2.2.m2.1.1.2" xref="S2.p2.2.m2.1.1.2.cmml">I</mi><mi id="S2.p2.2.m2.1.1.3" xref="S2.p2.2.m2.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><apply id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p2.2.m2.1.1.1.cmml" xref="S2.p2.2.m2.1.1">superscript</csymbol><ci id="S2.p2.2.m2.1.1.2.cmml" xref="S2.p2.2.m2.1.1.2">𝐼</ci><ci id="S2.p2.2.m2.1.1.3.cmml" xref="S2.p2.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">I^{c}</annotation></semantics></math> and answer <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="A^{c}" display="inline"><semantics id="S2.p2.3.m3.1a"><msup id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml"><mi id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml">A</mi><mi id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1">superscript</csymbol><ci id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2">𝐴</ci><ci id="S2.p2.3.m3.1.1.3.cmml" xref="S2.p2.3.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">A^{c}</annotation></semantics></math> were created. However, investigations in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> found that even after these ramifications priors continue to exist and exploited by VQA models.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> in VQA have introduced novel benchmarks such as robustness and consistency of models as a step towards limiting the false sense of progress in VQA with just accuracy and proposing models with better multi-modal understanding.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Consistency:</span> Inconsistency in QA models on the VQA and SQUAD dataset was first studied in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. They show how even the best VQA models are inconsistent in their answers. For example, given a question ”How many birds are in the picture?”, the model correctly answers ”3”. But upon asking ”Are there 3 birds in the picture?”, the same model incorrectly answers ”No”. This shows that models lack high level language and vision capabilities and could still be exploiting biases present in the dataset. They proposed evaluating consistency of these models and a simple data augmenting technique for improvement. However, augmentation limits the scope of implied questions to the added dataset. We in-turn propose a generative model based solution without this limitation.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">More recent work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> tackles inconsistency among binary i.e. ”yes/no” questions. They argue that despite answering original question correctly, VQA models performs poorly on logical composition of these questions. Another work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, focuses on improving consistency of models on reasoning questions. Unlike <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, these works provide model based solution but they target only a specific category of questions such as reasoning or binary questions. Unlike these, we show that our approach works better on the entire VQA v2.0 dataset rather than a small subset of it.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.6" class="ltx_p">Authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> previously attempted to improve consistency on the entire VQA v2.0 dataset. However, their concept of Entailed questions, generated from the Visual Genome <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> dataset, is quite different to our Implications. We believe that if the model is able to answer a question correctly, it should also be able to answer its implications correctly, which implies consistent behavior. But in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, given a question <math id="S2.p6.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p6.1.m1.1a"><mi id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><ci id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">Q</annotation></semantics></math> as ”Has he worn sneaker?” and answer ”yes”, an entailed question <math id="S2.p6.2.m2.1" class="ltx_Math" alttext="Q^{\prime}" display="inline"><semantics id="S2.p6.2.m2.1a"><msup id="S2.p6.2.m2.1.1" xref="S2.p6.2.m2.1.1.cmml"><mi id="S2.p6.2.m2.1.1.2" xref="S2.p6.2.m2.1.1.2.cmml">Q</mi><mo id="S2.p6.2.m2.1.1.3" xref="S2.p6.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p6.2.m2.1b"><apply id="S2.p6.2.m2.1.1.cmml" xref="S2.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p6.2.m2.1.1.1.cmml" xref="S2.p6.2.m2.1.1">superscript</csymbol><ci id="S2.p6.2.m2.1.1.2.cmml" xref="S2.p6.2.m2.1.1.2">𝑄</ci><ci id="S2.p6.2.m2.1.1.3.cmml" xref="S2.p6.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.2.m2.1c">Q^{\prime}</annotation></semantics></math> is ”Where is this photo?” with answer ”street”. Clearly <math id="S2.p6.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p6.3.m3.1a"><mi id="S2.p6.3.m3.1.1" xref="S2.p6.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p6.3.m3.1b"><ci id="S2.p6.3.m3.1.1.cmml" xref="S2.p6.3.m3.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.3.m3.1c">Q</annotation></semantics></math> and <math id="S2.p6.4.m4.1" class="ltx_Math" alttext="Q^{\prime}" display="inline"><semantics id="S2.p6.4.m4.1a"><msup id="S2.p6.4.m4.1.1" xref="S2.p6.4.m4.1.1.cmml"><mi id="S2.p6.4.m4.1.1.2" xref="S2.p6.4.m4.1.1.2.cmml">Q</mi><mo id="S2.p6.4.m4.1.1.3" xref="S2.p6.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p6.4.m4.1b"><apply id="S2.p6.4.m4.1.1.cmml" xref="S2.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p6.4.m4.1.1.1.cmml" xref="S2.p6.4.m4.1.1">superscript</csymbol><ci id="S2.p6.4.m4.1.1.2.cmml" xref="S2.p6.4.m4.1.1.2">𝑄</ci><ci id="S2.p6.4.m4.1.1.3.cmml" xref="S2.p6.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.4.m4.1c">Q^{\prime}</annotation></semantics></math> have no direct relation and as per our definition of consistency, answering <math id="S2.p6.5.m5.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p6.5.m5.1a"><mi id="S2.p6.5.m5.1.1" xref="S2.p6.5.m5.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p6.5.m5.1b"><ci id="S2.p6.5.m5.1.1.cmml" xref="S2.p6.5.m5.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.5.m5.1c">Q</annotation></semantics></math> and <math id="S2.p6.6.m6.1" class="ltx_Math" alttext="Q^{\prime}" display="inline"><semantics id="S2.p6.6.m6.1a"><msup id="S2.p6.6.m6.1.1" xref="S2.p6.6.m6.1.1.cmml"><mi id="S2.p6.6.m6.1.1.2" xref="S2.p6.6.m6.1.1.2.cmml">Q</mi><mo id="S2.p6.6.m6.1.1.3" xref="S2.p6.6.m6.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p6.6.m6.1b"><apply id="S2.p6.6.m6.1.1.cmml" xref="S2.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p6.6.m6.1.1.1.cmml" xref="S2.p6.6.m6.1.1">superscript</csymbol><ci id="S2.p6.6.m6.1.1.2.cmml" xref="S2.p6.6.m6.1.1.2">𝑄</ci><ci id="S2.p6.6.m6.1.1.3.cmml" xref="S2.p6.6.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.6.m6.1c">Q^{\prime}</annotation></semantics></math> correctly does not exhibit consistent behavior.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p"><span id="S2.p7.1.1" class="ltx_text ltx_font_bold">Robustness:</span> To decrease strong language priors, a number of works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> have introduced balanced datasets in context of robustness. The concept of robustness as a measure of performance on linguistic variations in the questions known as rephrasings was first introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. However, they used a ’consensus score’ metric whereas we use a metric similar to consistency for evaluation, to provide uniformity. To motivate future works in this field, they provide a VQA-Rephrasings dataset which we use to evaluate robustness of our models.</p>
</div>
<figure id="S2.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/model_diag.png" id="S2.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="473" height="110" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F3.sf1.1" class="ltx_p ltx_figure_panel ltx_align_center"><span id="S2.F3.sf1.1.1" class="ltx_text ltx_phantom"><span style="visibility:hidden"><img src="/html/2007.04422/assets/images/qg_diag.png" id="S2.F3.sf1.1.1.g1" class="ltx_graphics ltx_img_square" width="185" height="185" alt="Refer to caption"></span></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2007.04422/assets/images/qg_diag.png" id="S2.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="185" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S2.F3.20.1" class="ltx_text ltx_font_bold"> Proposed Model Architecture</span> (a) Abstract representation of our cyclic framework. Given an input image <math id="S2.F3.10.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S2.F3.10.m1.1b"><mi id="S2.F3.10.m1.1.1" xref="S2.F3.10.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S2.F3.10.m1.1c"><ci id="S2.F3.10.m1.1.1.cmml" xref="S2.F3.10.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.10.m1.1d">I</annotation></semantics></math> and question <math id="S2.F3.11.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.F3.11.m2.1b"><mi id="S2.F3.11.m2.1.1" xref="S2.F3.11.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.F3.11.m2.1c"><ci id="S2.F3.11.m2.1.1.cmml" xref="S2.F3.11.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.11.m2.1d">Q</annotation></semantics></math>, a VQA model predicts answer <math id="S2.F3.12.m3.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S2.F3.12.m3.1b"><msup id="S2.F3.12.m3.1.1" xref="S2.F3.12.m3.1.1.cmml"><mi id="S2.F3.12.m3.1.1.2" xref="S2.F3.12.m3.1.1.2.cmml">A</mi><mo id="S2.F3.12.m3.1.1.3" xref="S2.F3.12.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.F3.12.m3.1c"><apply id="S2.F3.12.m3.1.1.cmml" xref="S2.F3.12.m3.1.1"><csymbol cd="ambiguous" id="S2.F3.12.m3.1.1.1.cmml" xref="S2.F3.12.m3.1.1">superscript</csymbol><ci id="S2.F3.12.m3.1.1.2.cmml" xref="S2.F3.12.m3.1.1.2">𝐴</ci><ci id="S2.F3.12.m3.1.1.3.cmml" xref="S2.F3.12.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.12.m3.1d">A^{\prime}</annotation></semantics></math>. Then our proposed Implication generator transforms the original question <math id="S2.F3.13.m4.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.F3.13.m4.1b"><mi id="S2.F3.13.m4.1.1" xref="S2.F3.13.m4.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.F3.13.m4.1c"><ci id="S2.F3.13.m4.1.1.cmml" xref="S2.F3.13.m4.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.13.m4.1d">Q</annotation></semantics></math> to <math id="S2.F3.14.m5.1" class="ltx_Math" alttext="Q_{imp}" display="inline"><semantics id="S2.F3.14.m5.1b"><msub id="S2.F3.14.m5.1.1" xref="S2.F3.14.m5.1.1.cmml"><mi id="S2.F3.14.m5.1.1.2" xref="S2.F3.14.m5.1.1.2.cmml">Q</mi><mrow id="S2.F3.14.m5.1.1.3" xref="S2.F3.14.m5.1.1.3.cmml"><mi id="S2.F3.14.m5.1.1.3.2" xref="S2.F3.14.m5.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.F3.14.m5.1.1.3.1" xref="S2.F3.14.m5.1.1.3.1.cmml">​</mo><mi id="S2.F3.14.m5.1.1.3.3" xref="S2.F3.14.m5.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.F3.14.m5.1.1.3.1b" xref="S2.F3.14.m5.1.1.3.1.cmml">​</mo><mi id="S2.F3.14.m5.1.1.3.4" xref="S2.F3.14.m5.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.F3.14.m5.1c"><apply id="S2.F3.14.m5.1.1.cmml" xref="S2.F3.14.m5.1.1"><csymbol cd="ambiguous" id="S2.F3.14.m5.1.1.1.cmml" xref="S2.F3.14.m5.1.1">subscript</csymbol><ci id="S2.F3.14.m5.1.1.2.cmml" xref="S2.F3.14.m5.1.1.2">𝑄</ci><apply id="S2.F3.14.m5.1.1.3.cmml" xref="S2.F3.14.m5.1.1.3"><times id="S2.F3.14.m5.1.1.3.1.cmml" xref="S2.F3.14.m5.1.1.3.1"></times><ci id="S2.F3.14.m5.1.1.3.2.cmml" xref="S2.F3.14.m5.1.1.3.2">𝑖</ci><ci id="S2.F3.14.m5.1.1.3.3.cmml" xref="S2.F3.14.m5.1.1.3.3">𝑚</ci><ci id="S2.F3.14.m5.1.1.3.4.cmml" xref="S2.F3.14.m5.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.14.m5.1d">Q_{imp}</annotation></semantics></math> using <math id="S2.F3.15.m6.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S2.F3.15.m6.1b"><msup id="S2.F3.15.m6.1.1" xref="S2.F3.15.m6.1.1.cmml"><mi id="S2.F3.15.m6.1.1.2" xref="S2.F3.15.m6.1.1.2.cmml">A</mi><mo id="S2.F3.15.m6.1.1.3" xref="S2.F3.15.m6.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.F3.15.m6.1c"><apply id="S2.F3.15.m6.1.1.cmml" xref="S2.F3.15.m6.1.1"><csymbol cd="ambiguous" id="S2.F3.15.m6.1.1.1.cmml" xref="S2.F3.15.m6.1.1">superscript</csymbol><ci id="S2.F3.15.m6.1.1.2.cmml" xref="S2.F3.15.m6.1.1.2">𝐴</ci><ci id="S2.F3.15.m6.1.1.3.cmml" xref="S2.F3.15.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.15.m6.1d">A^{\prime}</annotation></semantics></math> and a control knob. This generated implication (and image) is passed to the VQA model to obtain answer <math id="S2.F3.16.m7.1" class="ltx_Math" alttext="A_{imp}" display="inline"><semantics id="S2.F3.16.m7.1b"><msub id="S2.F3.16.m7.1.1" xref="S2.F3.16.m7.1.1.cmml"><mi id="S2.F3.16.m7.1.1.2" xref="S2.F3.16.m7.1.1.2.cmml">A</mi><mrow id="S2.F3.16.m7.1.1.3" xref="S2.F3.16.m7.1.1.3.cmml"><mi id="S2.F3.16.m7.1.1.3.2" xref="S2.F3.16.m7.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.F3.16.m7.1.1.3.1" xref="S2.F3.16.m7.1.1.3.1.cmml">​</mo><mi id="S2.F3.16.m7.1.1.3.3" xref="S2.F3.16.m7.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.F3.16.m7.1.1.3.1b" xref="S2.F3.16.m7.1.1.3.1.cmml">​</mo><mi id="S2.F3.16.m7.1.1.3.4" xref="S2.F3.16.m7.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.F3.16.m7.1c"><apply id="S2.F3.16.m7.1.1.cmml" xref="S2.F3.16.m7.1.1"><csymbol cd="ambiguous" id="S2.F3.16.m7.1.1.1.cmml" xref="S2.F3.16.m7.1.1">subscript</csymbol><ci id="S2.F3.16.m7.1.1.2.cmml" xref="S2.F3.16.m7.1.1.2">𝐴</ci><apply id="S2.F3.16.m7.1.1.3.cmml" xref="S2.F3.16.m7.1.1.3"><times id="S2.F3.16.m7.1.1.3.1.cmml" xref="S2.F3.16.m7.1.1.3.1"></times><ci id="S2.F3.16.m7.1.1.3.2.cmml" xref="S2.F3.16.m7.1.1.3.2">𝑖</ci><ci id="S2.F3.16.m7.1.1.3.3.cmml" xref="S2.F3.16.m7.1.1.3.3">𝑚</ci><ci id="S2.F3.16.m7.1.1.3.4.cmml" xref="S2.F3.16.m7.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.16.m7.1d">A_{imp}</annotation></semantics></math>. (b) Detailed architecture of our implication generator. The predicted answer <math id="S2.F3.17.m8.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S2.F3.17.m8.1b"><msup id="S2.F3.17.m8.1.1" xref="S2.F3.17.m8.1.1.cmml"><mi id="S2.F3.17.m8.1.1.2" xref="S2.F3.17.m8.1.1.2.cmml">A</mi><mo id="S2.F3.17.m8.1.1.3" xref="S2.F3.17.m8.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.F3.17.m8.1c"><apply id="S2.F3.17.m8.1.1.cmml" xref="S2.F3.17.m8.1.1"><csymbol cd="ambiguous" id="S2.F3.17.m8.1.1.1.cmml" xref="S2.F3.17.m8.1.1">superscript</csymbol><ci id="S2.F3.17.m8.1.1.2.cmml" xref="S2.F3.17.m8.1.1.2">𝐴</ci><ci id="S2.F3.17.m8.1.1.3.cmml" xref="S2.F3.17.m8.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.17.m8.1d">A^{\prime}</annotation></semantics></math> and control knob are encoded to a latent space using respective encoders. They are then summed up along with question embedding and fed to a LSTM to generate implication <math id="S2.F3.18.m9.1" class="ltx_Math" alttext="Q_{imp}" display="inline"><semantics id="S2.F3.18.m9.1b"><msub id="S2.F3.18.m9.1.1" xref="S2.F3.18.m9.1.1.cmml"><mi id="S2.F3.18.m9.1.1.2" xref="S2.F3.18.m9.1.1.2.cmml">Q</mi><mrow id="S2.F3.18.m9.1.1.3" xref="S2.F3.18.m9.1.1.3.cmml"><mi id="S2.F3.18.m9.1.1.3.2" xref="S2.F3.18.m9.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.F3.18.m9.1.1.3.1" xref="S2.F3.18.m9.1.1.3.1.cmml">​</mo><mi id="S2.F3.18.m9.1.1.3.3" xref="S2.F3.18.m9.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.F3.18.m9.1.1.3.1b" xref="S2.F3.18.m9.1.1.3.1.cmml">​</mo><mi id="S2.F3.18.m9.1.1.3.4" xref="S2.F3.18.m9.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.F3.18.m9.1c"><apply id="S2.F3.18.m9.1.1.cmml" xref="S2.F3.18.m9.1.1"><csymbol cd="ambiguous" id="S2.F3.18.m9.1.1.1.cmml" xref="S2.F3.18.m9.1.1">subscript</csymbol><ci id="S2.F3.18.m9.1.1.2.cmml" xref="S2.F3.18.m9.1.1.2">𝑄</ci><apply id="S2.F3.18.m9.1.1.3.cmml" xref="S2.F3.18.m9.1.1.3"><times id="S2.F3.18.m9.1.1.3.1.cmml" xref="S2.F3.18.m9.1.1.3.1"></times><ci id="S2.F3.18.m9.1.1.3.2.cmml" xref="S2.F3.18.m9.1.1.3.2">𝑖</ci><ci id="S2.F3.18.m9.1.1.3.3.cmml" xref="S2.F3.18.m9.1.1.3.3">𝑚</ci><ci id="S2.F3.18.m9.1.1.3.4.cmml" xref="S2.F3.18.m9.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.18.m9.1d">Q_{imp}</annotation></semantics></math>.</figcaption>
</figure>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p"><span id="S2.p8.1.1" class="ltx_text ltx_font_bold">Question Generation:</span> There has been a thorough study of Natural Language generation in NLP, such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> extracts keywords from knowledge graphs and then formulate question generation from these keywords as Seq2Seq translation problem. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> tackles the question generation problem from Reinforcement Learning point of view. They consider generator as an actor trying to maximise BLEU score as it’s reward function. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> propose a Transformer based Seq2Seq pretraining model which beats the current state of the art in many summarization and question generation tasks. To the best of our knowledge, we are the first ones to propose an implication generator module to improve consistency of any VQA architecture.</p>
</div>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.1" class="ltx_p"><span id="S2.p9.1.1" class="ltx_text ltx_font_bold">Cyclic Framework:</span> Cyclic training for singular modality has been used in the past for tasks such as motion tracking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and text-based question answering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. For multi-modal tasks such as VQA, cyclic training was first introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. They used a Visual Question Generator (VQG) module to generate rephrasings of the original question and then trained their VQA module on those rephrasings in a cyclic manner. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, our framework is also model-independent and can be used for any VQA architecture. However, their aim was to make VQA models more robust to linguistic variations through rephrasings. Our aim, through our approach, is to make the models more accurate to not just rephrasings like in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, but also on implications.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Approach</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We use the rule-based approach in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to generate implications on entire VQA v2.0 dataset, referred to as the rule-based implication dataset. This rule-based method is unable to create all 3 implications for every QA pair, especially on yes/no type questions. Due to these restrictions by this approach, the rule-based implication dataset contains implications from about 60% of the original dataset. Moreover, all generated implications are of ’yes/no’ type, this serves as a strong prior for our implication generator module. Additional details about the rule-based implication dataset can be found in Section <a href="#S4" title="4 Experiments Setup ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Implication Generator Module</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.9" class="ltx_p">The role of this module is to generate implications of a given QA pair. This can be formulated as a transformation <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="G:(Q,A)\longrightarrow Q_{imp}" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3" xref="S3.SS1.p1.1.m1.2.3.cmml"><mi id="S3.SS1.p1.1.m1.2.3.2" xref="S3.SS1.p1.1.m1.2.3.2.cmml">G</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.1.m1.2.3.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">:</mo><mrow id="S3.SS1.p1.1.m1.2.3.3" xref="S3.SS1.p1.1.m1.2.3.3.cmml"><mrow id="S3.SS1.p1.1.m1.2.3.3.2.2" xref="S3.SS1.p1.1.m1.2.3.3.2.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.2.1" xref="S3.SS1.p1.1.m1.2.3.3.2.1.cmml">(</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">Q</mi><mo id="S3.SS1.p1.1.m1.2.3.3.2.2.2" xref="S3.SS1.p1.1.m1.2.3.3.2.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">A</mi><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.2.2.3" xref="S3.SS1.p1.1.m1.2.3.3.2.1.cmml">)</mo></mrow><mo stretchy="false" id="S3.SS1.p1.1.m1.2.3.3.1" xref="S3.SS1.p1.1.m1.2.3.3.1.cmml">⟶</mo><msub id="S3.SS1.p1.1.m1.2.3.3.3" xref="S3.SS1.p1.1.m1.2.3.3.3.cmml"><mi id="S3.SS1.p1.1.m1.2.3.3.3.2" xref="S3.SS1.p1.1.m1.2.3.3.3.2.cmml">Q</mi><mrow id="S3.SS1.p1.1.m1.2.3.3.3.3" xref="S3.SS1.p1.1.m1.2.3.3.3.3.cmml"><mi id="S3.SS1.p1.1.m1.2.3.3.3.3.2" xref="S3.SS1.p1.1.m1.2.3.3.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.2.3.3.3.3.1" xref="S3.SS1.p1.1.m1.2.3.3.3.3.1.cmml">​</mo><mi id="S3.SS1.p1.1.m1.2.3.3.3.3.3" xref="S3.SS1.p1.1.m1.2.3.3.3.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.2.3.3.3.3.1a" xref="S3.SS1.p1.1.m1.2.3.3.3.3.1.cmml">​</mo><mi id="S3.SS1.p1.1.m1.2.3.3.3.3.4" xref="S3.SS1.p1.1.m1.2.3.3.3.3.4.cmml">p</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.3"><ci id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.1">:</ci><ci id="S3.SS1.p1.1.m1.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.3.2">𝐺</ci><apply id="S3.SS1.p1.1.m1.2.3.3.cmml" xref="S3.SS1.p1.1.m1.2.3.3"><ci id="S3.SS1.p1.1.m1.2.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.1">⟶</ci><interval closure="open" id="S3.SS1.p1.1.m1.2.3.3.2.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.2.2"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑄</ci><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">𝐴</ci></interval><apply id="S3.SS1.p1.1.m1.2.3.3.3.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.3.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.3.3.3.2.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3.2">𝑄</ci><apply id="S3.SS1.p1.1.m1.2.3.3.3.3.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3.3"><times id="S3.SS1.p1.1.m1.2.3.3.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3.3.1"></times><ci id="S3.SS1.p1.1.m1.2.3.3.3.3.2.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3.3.2">𝑖</ci><ci id="S3.SS1.p1.1.m1.2.3.3.3.3.3.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3.3.3">𝑚</ci><ci id="S3.SS1.p1.1.m1.2.3.3.3.3.4.cmml" xref="S3.SS1.p1.1.m1.2.3.3.3.3.4">𝑝</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">G:(Q,A)\longrightarrow Q_{imp}</annotation></semantics></math> where <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="Q_{imp}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">Q</mi><mrow id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.1.1.3.1" xref="S3.SS1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.1.1.3.1a" xref="S3.SS1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.2.m2.1.1.3.4" xref="S3.SS1.p1.2.m2.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝑄</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><times id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">𝑖</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">𝑚</ci><ci id="S3.SS1.p1.2.m2.1.1.3.4.cmml" xref="S3.SS1.p1.2.m2.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">Q_{imp}</annotation></semantics></math> is the generated implication. In the VQA setting, this QA pair is provided by the VQA model. Any generic VQA model takes <math id="S3.SS1.p1.3.m3.2" class="ltx_Math" alttext="(Q,I)" display="inline"><semantics id="S3.SS1.p1.3.m3.2a"><mrow id="S3.SS1.p1.3.m3.2.3.2" xref="S3.SS1.p1.3.m3.2.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.3.m3.2.3.2.1" xref="S3.SS1.p1.3.m3.2.3.1.cmml">(</mo><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">Q</mi><mo id="S3.SS1.p1.3.m3.2.3.2.2" xref="S3.SS1.p1.3.m3.2.3.1.cmml">,</mo><mi id="S3.SS1.p1.3.m3.2.2" xref="S3.SS1.p1.3.m3.2.2.cmml">I</mi><mo stretchy="false" id="S3.SS1.p1.3.m3.2.3.2.3" xref="S3.SS1.p1.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.2b"><interval closure="open" id="S3.SS1.p1.3.m3.2.3.1.cmml" xref="S3.SS1.p1.3.m3.2.3.2"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑄</ci><ci id="S3.SS1.p1.3.m3.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2">𝐼</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.2c">(Q,I)</annotation></semantics></math> to predict <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msup id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">A</mi><mo id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝐴</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">A^{\prime}</annotation></semantics></math> where <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">Q</annotation></semantics></math> is the original question, <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">I</annotation></semantics></math> is the image and <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><msup id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">A</mi><mo id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">𝐴</ci><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">A^{\prime}</annotation></semantics></math> is the predicted answer. Our implication generator takes as input, the learned question encoding of the original question <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">Q</annotation></semantics></math>, the predicted answer scores <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><msup id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">A</mi><mo id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">superscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">𝐴</ci><ci id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">A^{\prime}</annotation></semantics></math> and a control knob (as one hot vector) to select between the three implication categories.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The implication generation module consists of three linear encoders that transform question encoding obtained from VQA model, the predicted answer scores, and the knob to lower dimensional feature vectors. These three inputs are then added together, and passed through a single layered LSTM with hidden size of 1024. This LSTM is trained to generate implications and optimized by minimizing the negative log likelihood with corresponding ground truth implication from the rule-based implication dataset. One thing to note is that we use answers scores over the entire vocabulary instead of a particular answer label, which increases performance on questions with more than one possible correct answer. Also, this provides a distribution over the entire set of answers which is a slightly rich and dense signal to learn from.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S3.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S3.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Val acc</span></th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" colspan="4"><span id="S3.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Consistency(rule-based)</span></th>
<th id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S3.T1.1.1.1.4.1" class="ltx_text">
<span id="S3.T1.1.1.1.4.1.1" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:56.9pt;">
<span id="S3.T1.1.1.1.4.1.1.1" class="ltx_p"><span id="S3.T1.1.1.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Consistency</span></span>
<span id="S3.T1.1.1.1.4.1.1.2" class="ltx_p ltx_align_center"><span id="S3.T1.1.1.1.4.1.1.2.1" class="ltx_text ltx_font_bold">(VQA-Imp)</span></span>
</span></span></th>
<th id="S3.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S3.T1.1.1.1.5.1" class="ltx_text ltx_font_bold">Robustness</span></th>
</tr>
<tr id="S3.T1.1.2.2" class="ltx_tr">
<td id="S3.T1.1.2.2.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">Logeq</td>
<td id="S3.T1.1.2.2.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">Nec</td>
<td id="S3.T1.1.2.2.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">Mutex</td>
<td id="S3.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">Overall</td>
</tr>
<tr id="S3.T1.1.3.3" class="ltx_tr">
<th id="S3.T1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">BUTD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</th>
<th id="S3.T1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">63.62</th>
<th id="S3.T1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">64.3</th>
<th id="S3.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">71.1</th>
<th id="S3.T1.1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">59.8</th>
<th id="S3.T1.1.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">65.3</th>
<th id="S3.T1.1.3.3.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">67.14</th>
<th id="S3.T1.1.3.3.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">79.21</th>
</tr>
<tr id="S3.T1.1.4.4" class="ltx_tr">
<th id="S3.T1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">BUTD + IQ</th>
<th id="S3.T1.1.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">63.57</th>
<td id="S3.T1.1.4.4.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.4.4.3.1" class="ltx_text ltx_font_bold">88.5</span></td>
<td id="S3.T1.1.4.4.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.4.4.4.1" class="ltx_text ltx_font_bold">96.7</span></td>
<td id="S3.T1.1.4.4.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.4.4.5.1" class="ltx_text ltx_font_bold">77.0</span></td>
<td id="S3.T1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.4.4.6.1" class="ltx_text ltx_font_bold">88.1</span></td>
<td id="S3.T1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.4.4.7.1" class="ltx_text ltx_font_bold">74.38</span></td>
<td id="S3.T1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.4.4.8.1" class="ltx_text ltx_font_bold">80.77</span></td>
</tr>
<tr id="S3.T1.1.5.5" class="ltx_tr">
<th id="S3.T1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<th id="S3.T1.1.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">65.37</th>
<th id="S3.T1.1.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">67.1</th>
<th id="S3.T1.1.5.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">77.6</th>
<th id="S3.T1.1.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">61.1</th>
<th id="S3.T1.1.5.5.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">69.0</th>
<th id="S3.T1.1.5.5.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">66.57</th>
<th id="S3.T1.1.5.5.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">79.93</th>
</tr>
<tr id="S3.T1.1.6.6" class="ltx_tr">
<th id="S3.T1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">BAN + IQ</th>
<th id="S3.T1.1.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">65.28</th>
<td id="S3.T1.1.6.6.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.6.6.3.1" class="ltx_text ltx_font_bold">89.3</span></td>
<td id="S3.T1.1.6.6.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.6.6.4.1" class="ltx_text ltx_font_bold">97.9</span></td>
<td id="S3.T1.1.6.6.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.6.6.5.1" class="ltx_text ltx_font_bold">79.8</span></td>
<td id="S3.T1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.6.6.6.1" class="ltx_text ltx_font_bold">89.6</span></td>
<td id="S3.T1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.6.6.7.1" class="ltx_text ltx_font_bold">74.61</span></td>
<td id="S3.T1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.6.6.8.1" class="ltx_text ltx_font_bold">81.62</span></td>
</tr>
<tr id="S3.T1.1.7.7" class="ltx_tr">
<th id="S3.T1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">Pythia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
</th>
<th id="S3.T1.1.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">64.70</th>
<th id="S3.T1.1.7.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">69.7</th>
<th id="S3.T1.1.7.7.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">76.4</th>
<th id="S3.T1.1.7.7.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">67.7</th>
<th id="S3.T1.1.7.7.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">70.0</th>
<th id="S3.T1.1.7.7.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">70.89</th>
<th id="S3.T1.1.7.7.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">79.31</th>
</tr>
<tr id="S3.T1.1.8.8" class="ltx_tr">
<th id="S3.T1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">Pythia + IQ</th>
<th id="S3.T1.1.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">65.60</th>
<td id="S3.T1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.8.8.3.1" class="ltx_text ltx_font_bold">88.7</span></td>
<td id="S3.T1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.8.8.4.1" class="ltx_text ltx_font_bold">97.6</span></td>
<td id="S3.T1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.8.8.5.1" class="ltx_text ltx_font_bold">79.0</span></td>
<td id="S3.T1.1.8.8.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.8.8.6.1" class="ltx_text ltx_font_bold">88.7</span></td>
<td id="S3.T1.1.8.8.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.8.8.7.1" class="ltx_text ltx_font_bold">76.55</span></td>
<td id="S3.T1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.1.8.8.8.1" class="ltx_text ltx_font_bold">82.40</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S3.T1.3.1" class="ltx_text ltx_font_bold">Consistency and robustness performance on rule-based validation, VQA-Implications and VQA-Rephrasings dataset.</span> Consistency and robustness are defined as percentage of correctly answered implications and rephrasings respectively, generated only on correctly answered original questions. All the models trained with our approach outperform their respective baselines in all categories, keeping the validation accuracy almost same.</figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">The implication generator module - by generating implications - introduces stronger linguistic variations than rephrasings as proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Thus we believe that by learning on these implications, models trained with our approach should also perform better on rephrasings thus leading to improvement in robustness, in addition to consistency.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Knob Mechanism</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Instead of using an implied answer selected randomly from <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="(yes,no)" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.2.2" xref="S3.SS2.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p1.1.m1.2.2.2.3" xref="S3.SS2.p1.1.m1.2.2.3.cmml">(</mo><mrow id="S3.SS2.p1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.1.1.2.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS2.p1.1.m1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.1.1.1.1.1a" xref="S3.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS2.p1.1.m1.1.1.1.1.4" xref="S3.SS2.p1.1.m1.1.1.1.1.4.cmml">s</mi></mrow><mo id="S3.SS2.p1.1.m1.2.2.2.4" xref="S3.SS2.p1.1.m1.2.2.3.cmml">,</mo><mrow id="S3.SS2.p1.1.m1.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS2.p1.1.m1.2.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.2.2.2.2.1" xref="S3.SS2.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S3.SS2.p1.1.m1.2.2.2.2.3" xref="S3.SS2.p1.1.m1.2.2.2.2.3.cmml">o</mi></mrow><mo stretchy="false" id="S3.SS2.p1.1.m1.2.2.2.5" xref="S3.SS2.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><interval closure="open" id="S3.SS2.p1.1.m1.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2"><apply id="S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.1"></times><ci id="S3.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2">𝑦</ci><ci id="S3.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3">𝑒</ci><ci id="S3.SS2.p1.1.m1.1.1.1.1.4.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.4">𝑠</ci></apply><apply id="S3.SS2.p1.1.m1.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2"><times id="S3.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.1"></times><ci id="S3.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2">𝑛</ci><ci id="S3.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.3">𝑜</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">(yes,no)</annotation></semantics></math> as input to the implication generator module, we use a three way knob to switch between logical equivalence, necessary condition and mutual exclusion. This helps the model to have better control over the generated implications. In our training dataset, implications from two categories - logical equivalence and necessary condition have ’yes’ as the correct answer. While training the implication generator using implied answer, we noted that model tends to generate necessary implications when provided ’yes’ as the implied answer. We believe that generating a necessary condition is easier as compared to logical equivalence and without having any control signal, model might learn to generate necessary implications all the time. Hence, we provide this control signal in the form of a one hot vector between the three implication categories.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Cyclic Framework</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.4" class="ltx_p">To integrate our implication generator module with any VQA module, we use a cyclic framework. The confidence score over answers generated by the VQA module is used by the implication generator module. The implications are then passed as question to the VQA module, along with the image <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">I</annotation></semantics></math> to give implied answer <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="A_{imp}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">A</mi><mrow id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.1.3.1" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.1.3.1a" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.2.m2.1.1.3.4" xref="S3.SS3.p1.2.m2.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝐴</ci><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><times id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3.1"></times><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">𝑖</ci><ci id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">𝑚</ci><ci id="S3.SS3.p1.2.m2.1.1.3.4.cmml" xref="S3.SS3.p1.2.m2.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">A_{imp}</annotation></semantics></math>. This enables the VQA module to learn on these implications and improve its consistency. Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, We incorporate gating mechanism and late activation in our cyclic architecture. So, instead of passing all implied questions, we filter out undesirable implications which have cosine similarity less than threshold <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="T_{sim}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><msub id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">T</mi><mrow id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml"><mi id="S3.SS3.p1.3.m3.1.1.3.2" xref="S3.SS3.p1.3.m3.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.3.m3.1.1.3.1" xref="S3.SS3.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.3.m3.1.1.3.3" xref="S3.SS3.p1.3.m3.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.3.m3.1.1.3.1a" xref="S3.SS3.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.3.m3.1.1.3.4" xref="S3.SS3.p1.3.m3.1.1.3.4.cmml">m</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">𝑇</ci><apply id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3"><times id="S3.SS3.p1.3.m3.1.1.3.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3.1"></times><ci id="S3.SS3.p1.3.m3.1.1.3.2.cmml" xref="S3.SS3.p1.3.m3.1.1.3.2">𝑠</ci><ci id="S3.SS3.p1.3.m3.1.1.3.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3">𝑖</ci><ci id="S3.SS3.p1.3.m3.1.1.3.4.cmml" xref="S3.SS3.p1.3.m3.1.1.3.4">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">T_{sim}</annotation></semantics></math> with the ground truth implication. Also, as part of the late activation scheme, we disable cyclic training before <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="A_{iter}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><msub id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">A</mi><mrow id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.3.1" xref="S3.SS3.p1.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.3.1a" xref="S3.SS3.p1.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.3.4" xref="S3.SS3.p1.4.m4.1.1.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.3.1b" xref="S3.SS3.p1.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.3.5" xref="S3.SS3.p1.4.m4.1.1.3.5.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">𝐴</ci><apply id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3"><times id="S3.SS3.p1.4.m4.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.3.1"></times><ci id="S3.SS3.p1.4.m4.1.1.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.3.2">𝑖</ci><ci id="S3.SS3.p1.4.m4.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3.3">𝑡</ci><ci id="S3.SS3.p1.4.m4.1.1.3.4.cmml" xref="S3.SS3.p1.4.m4.1.1.3.4">𝑒</ci><ci id="S3.SS3.p1.4.m4.1.1.3.5.cmml" xref="S3.SS3.p1.4.m4.1.1.3.5">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">A_{iter}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.13" class="ltx_p">We use three loss functions in our architecture, namely VQA loss <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="L_{vqa}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">L</mi><mrow id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1a" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.1.m1.1.1.3.4" xref="S3.SS3.p2.1.m1.1.1.3.4.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝐿</ci><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><times id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1"></times><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">𝑣</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3">𝑞</ci><ci id="S3.SS3.p2.1.m1.1.1.3.4.cmml" xref="S3.SS3.p2.1.m1.1.1.3.4">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">L_{vqa}</annotation></semantics></math>, question loss <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="L_{Q}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">L</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">𝐿</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">L_{Q}</annotation></semantics></math> and implication loss <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="L_{imp}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">L</mi><mrow id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.2" xref="S3.SS3.p2.3.m3.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.3.m3.1.1.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1a" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.3.m3.1.1.3.4" xref="S3.SS3.p2.3.m3.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">𝐿</ci><apply id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3"><times id="S3.SS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3.1"></times><ci id="S3.SS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.2">𝑖</ci><ci id="S3.SS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3">𝑚</ci><ci id="S3.SS3.p2.3.m3.1.1.3.4.cmml" xref="S3.SS3.p2.3.m3.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">L_{imp}</annotation></semantics></math>. <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="L_{vqa}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><msub id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">L</mi><mrow id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml"><mi id="S3.SS3.p2.4.m4.1.1.3.2" xref="S3.SS3.p2.4.m4.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.1.1.3.1" xref="S3.SS3.p2.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.1.1.3.3" xref="S3.SS3.p2.4.m4.1.1.3.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.1.1.3.1a" xref="S3.SS3.p2.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.1.1.3.4" xref="S3.SS3.p2.4.m4.1.1.3.4.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">𝐿</ci><apply id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3"><times id="S3.SS3.p2.4.m4.1.1.3.1.cmml" xref="S3.SS3.p2.4.m4.1.1.3.1"></times><ci id="S3.SS3.p2.4.m4.1.1.3.2.cmml" xref="S3.SS3.p2.4.m4.1.1.3.2">𝑣</ci><ci id="S3.SS3.p2.4.m4.1.1.3.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3.3">𝑞</ci><ci id="S3.SS3.p2.4.m4.1.1.3.4.cmml" xref="S3.SS3.p2.4.m4.1.1.3.4">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">L_{vqa}</annotation></semantics></math> is the standard binary cross-entropy (BCE) loss between predicted answer <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="A^{\prime}" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><msup id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">A</mi><mo id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">𝐴</ci><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">A^{\prime}</annotation></semantics></math> and ground truth <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="A^{gt}" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><msup id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">A</mi><mrow id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml"><mi id="S3.SS3.p2.6.m6.1.1.3.2" xref="S3.SS3.p2.6.m6.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.6.m6.1.1.3.1" xref="S3.SS3.p2.6.m6.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.6.m6.1.1.3.3" xref="S3.SS3.p2.6.m6.1.1.3.3.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">superscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">𝐴</ci><apply id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3"><times id="S3.SS3.p2.6.m6.1.1.3.1.cmml" xref="S3.SS3.p2.6.m6.1.1.3.1"></times><ci id="S3.SS3.p2.6.m6.1.1.3.2.cmml" xref="S3.SS3.p2.6.m6.1.1.3.2">𝑔</ci><ci id="S3.SS3.p2.6.m6.1.1.3.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">A^{gt}</annotation></semantics></math>. <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="L_{Q}" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><msub id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml"><mi id="S3.SS3.p2.7.m7.1.1.2" xref="S3.SS3.p2.7.m7.1.1.2.cmml">L</mi><mi id="S3.SS3.p2.7.m7.1.1.3" xref="S3.SS3.p2.7.m7.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><apply id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m7.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p2.7.m7.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2">𝐿</ci><ci id="S3.SS3.p2.7.m7.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">L_{Q}</annotation></semantics></math> is the negative log likelihood loss between generated implication <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="Q_{imp}" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><msub id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.2" xref="S3.SS3.p2.8.m8.1.1.2.cmml">Q</mi><mrow id="S3.SS3.p2.8.m8.1.1.3" xref="S3.SS3.p2.8.m8.1.1.3.cmml"><mi id="S3.SS3.p2.8.m8.1.1.3.2" xref="S3.SS3.p2.8.m8.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.1.1.3.1" xref="S3.SS3.p2.8.m8.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.8.m8.1.1.3.3" xref="S3.SS3.p2.8.m8.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.1.1.3.1a" xref="S3.SS3.p2.8.m8.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.8.m8.1.1.3.4" xref="S3.SS3.p2.8.m8.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><apply id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m8.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1.2">𝑄</ci><apply id="S3.SS3.p2.8.m8.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3"><times id="S3.SS3.p2.8.m8.1.1.3.1.cmml" xref="S3.SS3.p2.8.m8.1.1.3.1"></times><ci id="S3.SS3.p2.8.m8.1.1.3.2.cmml" xref="S3.SS3.p2.8.m8.1.1.3.2">𝑖</ci><ci id="S3.SS3.p2.8.m8.1.1.3.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3.3">𝑚</ci><ci id="S3.SS3.p2.8.m8.1.1.3.4.cmml" xref="S3.SS3.p2.8.m8.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">Q_{imp}</annotation></semantics></math> and ground truth implication <math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="Q_{imp}^{gt}" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><msubsup id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2.2" xref="S3.SS3.p2.9.m9.1.1.2.2.cmml">Q</mi><mrow id="S3.SS3.p2.9.m9.1.1.2.3" xref="S3.SS3.p2.9.m9.1.1.2.3.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2.3.2" xref="S3.SS3.p2.9.m9.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.9.m9.1.1.2.3.1" xref="S3.SS3.p2.9.m9.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p2.9.m9.1.1.2.3.3" xref="S3.SS3.p2.9.m9.1.1.2.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.9.m9.1.1.2.3.1a" xref="S3.SS3.p2.9.m9.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p2.9.m9.1.1.2.3.4" xref="S3.SS3.p2.9.m9.1.1.2.3.4.cmml">p</mi></mrow><mrow id="S3.SS3.p2.9.m9.1.1.3" xref="S3.SS3.p2.9.m9.1.1.3.cmml"><mi id="S3.SS3.p2.9.m9.1.1.3.2" xref="S3.SS3.p2.9.m9.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.9.m9.1.1.3.1" xref="S3.SS3.p2.9.m9.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.9.m9.1.1.3.3" xref="S3.SS3.p2.9.m9.1.1.3.3.cmml">t</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><apply id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1">superscript</csymbol><apply id="S3.SS3.p2.9.m9.1.1.2.cmml" xref="S3.SS3.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.2.1.cmml" xref="S3.SS3.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS3.p2.9.m9.1.1.2.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2.2">𝑄</ci><apply id="S3.SS3.p2.9.m9.1.1.2.3.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3"><times id="S3.SS3.p2.9.m9.1.1.2.3.1.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3.1"></times><ci id="S3.SS3.p2.9.m9.1.1.2.3.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3.2">𝑖</ci><ci id="S3.SS3.p2.9.m9.1.1.2.3.3.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3.3">𝑚</ci><ci id="S3.SS3.p2.9.m9.1.1.2.3.4.cmml" xref="S3.SS3.p2.9.m9.1.1.2.3.4">𝑝</ci></apply></apply><apply id="S3.SS3.p2.9.m9.1.1.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3"><times id="S3.SS3.p2.9.m9.1.1.3.1.cmml" xref="S3.SS3.p2.9.m9.1.1.3.1"></times><ci id="S3.SS3.p2.9.m9.1.1.3.2.cmml" xref="S3.SS3.p2.9.m9.1.1.3.2">𝑔</ci><ci id="S3.SS3.p2.9.m9.1.1.3.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">Q_{imp}^{gt}</annotation></semantics></math>. <math id="S3.SS3.p2.10.m10.1" class="ltx_Math" alttext="L_{imp}" display="inline"><semantics id="S3.SS3.p2.10.m10.1a"><msub id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml"><mi id="S3.SS3.p2.10.m10.1.1.2" xref="S3.SS3.p2.10.m10.1.1.2.cmml">L</mi><mrow id="S3.SS3.p2.10.m10.1.1.3" xref="S3.SS3.p2.10.m10.1.1.3.cmml"><mi id="S3.SS3.p2.10.m10.1.1.3.2" xref="S3.SS3.p2.10.m10.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.10.m10.1.1.3.1" xref="S3.SS3.p2.10.m10.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.10.m10.1.1.3.3" xref="S3.SS3.p2.10.m10.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.10.m10.1.1.3.1a" xref="S3.SS3.p2.10.m10.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.10.m10.1.1.3.4" xref="S3.SS3.p2.10.m10.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><apply id="S3.SS3.p2.10.m10.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.2">𝐿</ci><apply id="S3.SS3.p2.10.m10.1.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3"><times id="S3.SS3.p2.10.m10.1.1.3.1.cmml" xref="S3.SS3.p2.10.m10.1.1.3.1"></times><ci id="S3.SS3.p2.10.m10.1.1.3.2.cmml" xref="S3.SS3.p2.10.m10.1.1.3.2">𝑖</ci><ci id="S3.SS3.p2.10.m10.1.1.3.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3.3">𝑚</ci><ci id="S3.SS3.p2.10.m10.1.1.3.4.cmml" xref="S3.SS3.p2.10.m10.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">L_{imp}</annotation></semantics></math> is also the BCE loss between <math id="S3.SS3.p2.11.m11.1" class="ltx_Math" alttext="A_{imp}" display="inline"><semantics id="S3.SS3.p2.11.m11.1a"><msub id="S3.SS3.p2.11.m11.1.1" xref="S3.SS3.p2.11.m11.1.1.cmml"><mi id="S3.SS3.p2.11.m11.1.1.2" xref="S3.SS3.p2.11.m11.1.1.2.cmml">A</mi><mrow id="S3.SS3.p2.11.m11.1.1.3" xref="S3.SS3.p2.11.m11.1.1.3.cmml"><mi id="S3.SS3.p2.11.m11.1.1.3.2" xref="S3.SS3.p2.11.m11.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.11.m11.1.1.3.1" xref="S3.SS3.p2.11.m11.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.11.m11.1.1.3.3" xref="S3.SS3.p2.11.m11.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.11.m11.1.1.3.1a" xref="S3.SS3.p2.11.m11.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.11.m11.1.1.3.4" xref="S3.SS3.p2.11.m11.1.1.3.4.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.11.m11.1b"><apply id="S3.SS3.p2.11.m11.1.1.cmml" xref="S3.SS3.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.11.m11.1.1.1.cmml" xref="S3.SS3.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS3.p2.11.m11.1.1.2.cmml" xref="S3.SS3.p2.11.m11.1.1.2">𝐴</ci><apply id="S3.SS3.p2.11.m11.1.1.3.cmml" xref="S3.SS3.p2.11.m11.1.1.3"><times id="S3.SS3.p2.11.m11.1.1.3.1.cmml" xref="S3.SS3.p2.11.m11.1.1.3.1"></times><ci id="S3.SS3.p2.11.m11.1.1.3.2.cmml" xref="S3.SS3.p2.11.m11.1.1.3.2">𝑖</ci><ci id="S3.SS3.p2.11.m11.1.1.3.3.cmml" xref="S3.SS3.p2.11.m11.1.1.3.3">𝑚</ci><ci id="S3.SS3.p2.11.m11.1.1.3.4.cmml" xref="S3.SS3.p2.11.m11.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.11.m11.1c">A_{imp}</annotation></semantics></math> and <math id="S3.SS3.p2.12.m12.1" class="ltx_Math" alttext="A_{imp}^{gt}" display="inline"><semantics id="S3.SS3.p2.12.m12.1a"><msubsup id="S3.SS3.p2.12.m12.1.1" xref="S3.SS3.p2.12.m12.1.1.cmml"><mi id="S3.SS3.p2.12.m12.1.1.2.2" xref="S3.SS3.p2.12.m12.1.1.2.2.cmml">A</mi><mrow id="S3.SS3.p2.12.m12.1.1.2.3" xref="S3.SS3.p2.12.m12.1.1.2.3.cmml"><mi id="S3.SS3.p2.12.m12.1.1.2.3.2" xref="S3.SS3.p2.12.m12.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.12.m12.1.1.2.3.1" xref="S3.SS3.p2.12.m12.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p2.12.m12.1.1.2.3.3" xref="S3.SS3.p2.12.m12.1.1.2.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.12.m12.1.1.2.3.1a" xref="S3.SS3.p2.12.m12.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p2.12.m12.1.1.2.3.4" xref="S3.SS3.p2.12.m12.1.1.2.3.4.cmml">p</mi></mrow><mrow id="S3.SS3.p2.12.m12.1.1.3" xref="S3.SS3.p2.12.m12.1.1.3.cmml"><mi id="S3.SS3.p2.12.m12.1.1.3.2" xref="S3.SS3.p2.12.m12.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.12.m12.1.1.3.1" xref="S3.SS3.p2.12.m12.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.12.m12.1.1.3.3" xref="S3.SS3.p2.12.m12.1.1.3.3.cmml">t</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.12.m12.1b"><apply id="S3.SS3.p2.12.m12.1.1.cmml" xref="S3.SS3.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.12.m12.1.1.1.cmml" xref="S3.SS3.p2.12.m12.1.1">superscript</csymbol><apply id="S3.SS3.p2.12.m12.1.1.2.cmml" xref="S3.SS3.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.12.m12.1.1.2.1.cmml" xref="S3.SS3.p2.12.m12.1.1">subscript</csymbol><ci id="S3.SS3.p2.12.m12.1.1.2.2.cmml" xref="S3.SS3.p2.12.m12.1.1.2.2">𝐴</ci><apply id="S3.SS3.p2.12.m12.1.1.2.3.cmml" xref="S3.SS3.p2.12.m12.1.1.2.3"><times id="S3.SS3.p2.12.m12.1.1.2.3.1.cmml" xref="S3.SS3.p2.12.m12.1.1.2.3.1"></times><ci id="S3.SS3.p2.12.m12.1.1.2.3.2.cmml" xref="S3.SS3.p2.12.m12.1.1.2.3.2">𝑖</ci><ci id="S3.SS3.p2.12.m12.1.1.2.3.3.cmml" xref="S3.SS3.p2.12.m12.1.1.2.3.3">𝑚</ci><ci id="S3.SS3.p2.12.m12.1.1.2.3.4.cmml" xref="S3.SS3.p2.12.m12.1.1.2.3.4">𝑝</ci></apply></apply><apply id="S3.SS3.p2.12.m12.1.1.3.cmml" xref="S3.SS3.p2.12.m12.1.1.3"><times id="S3.SS3.p2.12.m12.1.1.3.1.cmml" xref="S3.SS3.p2.12.m12.1.1.3.1"></times><ci id="S3.SS3.p2.12.m12.1.1.3.2.cmml" xref="S3.SS3.p2.12.m12.1.1.3.2">𝑔</ci><ci id="S3.SS3.p2.12.m12.1.1.3.3.cmml" xref="S3.SS3.p2.12.m12.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.12.m12.1c">A_{imp}^{gt}</annotation></semantics></math>. Combining the three losses with their respective weights, we get total loss <math id="S3.SS3.p2.13.m13.1" class="ltx_Math" alttext="L_{tot}" display="inline"><semantics id="S3.SS3.p2.13.m13.1a"><msub id="S3.SS3.p2.13.m13.1.1" xref="S3.SS3.p2.13.m13.1.1.cmml"><mi id="S3.SS3.p2.13.m13.1.1.2" xref="S3.SS3.p2.13.m13.1.1.2.cmml">L</mi><mrow id="S3.SS3.p2.13.m13.1.1.3" xref="S3.SS3.p2.13.m13.1.1.3.cmml"><mi id="S3.SS3.p2.13.m13.1.1.3.2" xref="S3.SS3.p2.13.m13.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.13.m13.1.1.3.1" xref="S3.SS3.p2.13.m13.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.13.m13.1.1.3.3" xref="S3.SS3.p2.13.m13.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.13.m13.1.1.3.1a" xref="S3.SS3.p2.13.m13.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p2.13.m13.1.1.3.4" xref="S3.SS3.p2.13.m13.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.13.m13.1b"><apply id="S3.SS3.p2.13.m13.1.1.cmml" xref="S3.SS3.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.13.m13.1.1.1.cmml" xref="S3.SS3.p2.13.m13.1.1">subscript</csymbol><ci id="S3.SS3.p2.13.m13.1.1.2.cmml" xref="S3.SS3.p2.13.m13.1.1.2">𝐿</ci><apply id="S3.SS3.p2.13.m13.1.1.3.cmml" xref="S3.SS3.p2.13.m13.1.1.3"><times id="S3.SS3.p2.13.m13.1.1.3.1.cmml" xref="S3.SS3.p2.13.m13.1.1.3.1"></times><ci id="S3.SS3.p2.13.m13.1.1.3.2.cmml" xref="S3.SS3.p2.13.m13.1.1.3.2">𝑡</ci><ci id="S3.SS3.p2.13.m13.1.1.3.3.cmml" xref="S3.SS3.p2.13.m13.1.1.3.3">𝑜</ci><ci id="S3.SS3.p2.13.m13.1.1.3.4.cmml" xref="S3.SS3.p2.13.m13.1.1.3.4">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.13.m13.1c">L_{tot}</annotation></semantics></math> as:</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.50" class="ltx_Math" alttext="L_{tot}=L_{vqa}(A^{\prime},A^{gt})+\lambda_{Q}L_{Q}(Q_{imp},Q_{imp}^{gt})\\
+\lambda_{imp}L_{imp}(A_{imp},A_{imp}^{gt})" display="block"><semantics id="S3.E1.m1.50a"><mtable displaystyle="true" rowspacing="0pt" id="S3.E1.m1.50.50.12" xref="S3.E1.m1.44.44.6.cmml"><mtr id="S3.E1.m1.50.50.12a" xref="S3.E1.m1.44.44.6.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.50.50.12b" xref="S3.E1.m1.44.44.6.cmml"><mrow id="S3.E1.m1.48.48.10.42.29.29" xref="S3.E1.m1.44.44.6.cmml"><msub id="S3.E1.m1.48.48.10.42.29.29.30" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">L</mi><mrow id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.2.2.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.2.2.2.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.2.1.1a" xref="S3.E1.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E1.m1.2.2.2.2.2.2.1.4" xref="S3.E1.m1.2.2.2.2.2.2.1.4.cmml">t</mi></mrow></msub><mo id="S3.E1.m1.3.3.3.3.3.3" xref="S3.E1.m1.3.3.3.3.3.3.cmml">=</mo><mrow id="S3.E1.m1.48.48.10.42.29.29.29" xref="S3.E1.m1.44.44.6.cmml"><mrow id="S3.E1.m1.46.46.8.40.27.27.27.2" xref="S3.E1.m1.44.44.6.cmml"><msub id="S3.E1.m1.46.46.8.40.27.27.27.2.4" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.4.4.4.4.4.4" xref="S3.E1.m1.4.4.4.4.4.4.cmml">L</mi><mrow id="S3.E1.m1.5.5.5.5.5.5.1" xref="S3.E1.m1.5.5.5.5.5.5.1.cmml"><mi id="S3.E1.m1.5.5.5.5.5.5.1.2" xref="S3.E1.m1.5.5.5.5.5.5.1.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.5.5.5.1.1" xref="S3.E1.m1.5.5.5.5.5.5.1.1.cmml">​</mo><mi id="S3.E1.m1.5.5.5.5.5.5.1.3" xref="S3.E1.m1.5.5.5.5.5.5.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.5.5.5.1.1a" xref="S3.E1.m1.5.5.5.5.5.5.1.1.cmml">​</mo><mi id="S3.E1.m1.5.5.5.5.5.5.1.4" xref="S3.E1.m1.5.5.5.5.5.5.1.4.cmml">a</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.46.46.8.40.27.27.27.2.3" xref="S3.E1.m1.44.44.6.cmml">​</mo><mrow id="S3.E1.m1.46.46.8.40.27.27.27.2.2.2" xref="S3.E1.m1.44.44.6.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.6.6.6.6" xref="S3.E1.m1.44.44.6.cmml">(</mo><msup id="S3.E1.m1.45.45.7.39.26.26.26.1.1.1.1" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.7.7.7.7.7.7" xref="S3.E1.m1.7.7.7.7.7.7.cmml">A</mi><mo id="S3.E1.m1.8.8.8.8.8.8.1" xref="S3.E1.m1.8.8.8.8.8.8.1.cmml">′</mo></msup><mo id="S3.E1.m1.9.9.9.9.9.9" xref="S3.E1.m1.44.44.6.cmml">,</mo><msup id="S3.E1.m1.46.46.8.40.27.27.27.2.2.2.2" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.10.10.10.10.10.10" xref="S3.E1.m1.10.10.10.10.10.10.cmml">A</mi><mrow id="S3.E1.m1.11.11.11.11.11.11.1" xref="S3.E1.m1.11.11.11.11.11.11.1.cmml"><mi id="S3.E1.m1.11.11.11.11.11.11.1.2" xref="S3.E1.m1.11.11.11.11.11.11.1.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.11.11.11.11.11.11.1.1" xref="S3.E1.m1.11.11.11.11.11.11.1.1.cmml">​</mo><mi id="S3.E1.m1.11.11.11.11.11.11.1.3" xref="S3.E1.m1.11.11.11.11.11.11.1.3.cmml">t</mi></mrow></msup><mo stretchy="false" id="S3.E1.m1.12.12.12.12.12.12" xref="S3.E1.m1.44.44.6.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.13.13.13.13.13.13" xref="S3.E1.m1.13.13.13.13.13.13.cmml">+</mo><mrow id="S3.E1.m1.48.48.10.42.29.29.29.4" xref="S3.E1.m1.44.44.6.cmml"><msub id="S3.E1.m1.48.48.10.42.29.29.29.4.4" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.14.14.14.14.14.14" xref="S3.E1.m1.14.14.14.14.14.14.cmml">λ</mi><mi id="S3.E1.m1.15.15.15.15.15.15.1" xref="S3.E1.m1.15.15.15.15.15.15.1.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.48.48.10.42.29.29.29.4.3" xref="S3.E1.m1.44.44.6.cmml">​</mo><msub id="S3.E1.m1.48.48.10.42.29.29.29.4.5" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.16.16.16.16.16.16" xref="S3.E1.m1.16.16.16.16.16.16.cmml">L</mi><mi id="S3.E1.m1.17.17.17.17.17.17.1" xref="S3.E1.m1.17.17.17.17.17.17.1.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.48.48.10.42.29.29.29.4.3a" xref="S3.E1.m1.44.44.6.cmml">​</mo><mrow id="S3.E1.m1.48.48.10.42.29.29.29.4.2.2" xref="S3.E1.m1.44.44.6.cmml"><mo stretchy="false" id="S3.E1.m1.18.18.18.18.18.18" xref="S3.E1.m1.44.44.6.cmml">(</mo><msub id="S3.E1.m1.47.47.9.41.28.28.28.3.1.1.1" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.19.19.19.19.19.19" xref="S3.E1.m1.19.19.19.19.19.19.cmml">Q</mi><mrow id="S3.E1.m1.20.20.20.20.20.20.1" xref="S3.E1.m1.20.20.20.20.20.20.1.cmml"><mi id="S3.E1.m1.20.20.20.20.20.20.1.2" xref="S3.E1.m1.20.20.20.20.20.20.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.20.20.20.20.20.20.1.1" xref="S3.E1.m1.20.20.20.20.20.20.1.1.cmml">​</mo><mi id="S3.E1.m1.20.20.20.20.20.20.1.3" xref="S3.E1.m1.20.20.20.20.20.20.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.20.20.20.20.20.20.1.1a" xref="S3.E1.m1.20.20.20.20.20.20.1.1.cmml">​</mo><mi id="S3.E1.m1.20.20.20.20.20.20.1.4" xref="S3.E1.m1.20.20.20.20.20.20.1.4.cmml">p</mi></mrow></msub><mo id="S3.E1.m1.21.21.21.21.21.21" xref="S3.E1.m1.44.44.6.cmml">,</mo><msubsup id="S3.E1.m1.48.48.10.42.29.29.29.4.2.2.2" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.22.22.22.22.22.22" xref="S3.E1.m1.22.22.22.22.22.22.cmml">Q</mi><mrow id="S3.E1.m1.23.23.23.23.23.23.1" xref="S3.E1.m1.23.23.23.23.23.23.1.cmml"><mi id="S3.E1.m1.23.23.23.23.23.23.1.2" xref="S3.E1.m1.23.23.23.23.23.23.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.23.23.23.23.23.23.1.1" xref="S3.E1.m1.23.23.23.23.23.23.1.1.cmml">​</mo><mi id="S3.E1.m1.23.23.23.23.23.23.1.3" xref="S3.E1.m1.23.23.23.23.23.23.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.23.23.23.23.23.23.1.1a" xref="S3.E1.m1.23.23.23.23.23.23.1.1.cmml">​</mo><mi id="S3.E1.m1.23.23.23.23.23.23.1.4" xref="S3.E1.m1.23.23.23.23.23.23.1.4.cmml">p</mi></mrow><mrow id="S3.E1.m1.24.24.24.24.24.24.1" xref="S3.E1.m1.24.24.24.24.24.24.1.cmml"><mi id="S3.E1.m1.24.24.24.24.24.24.1.2" xref="S3.E1.m1.24.24.24.24.24.24.1.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.24.24.24.24.24.24.1.1" xref="S3.E1.m1.24.24.24.24.24.24.1.1.cmml">​</mo><mi id="S3.E1.m1.24.24.24.24.24.24.1.3" xref="S3.E1.m1.24.24.24.24.24.24.1.3.cmml">t</mi></mrow></msubsup><mo stretchy="false" id="S3.E1.m1.25.25.25.25.25.25" xref="S3.E1.m1.44.44.6.cmml">)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr id="S3.E1.m1.50.50.12c" xref="S3.E1.m1.44.44.6.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E1.m1.50.50.12d" xref="S3.E1.m1.44.44.6.cmml"><mrow id="S3.E1.m1.50.50.12.44.15.15" xref="S3.E1.m1.44.44.6.cmml"><mo id="S3.E1.m1.50.50.12.44.15.15a" xref="S3.E1.m1.44.44.6.cmml">+</mo><mrow id="S3.E1.m1.50.50.12.44.15.15.15" xref="S3.E1.m1.44.44.6.cmml"><msub id="S3.E1.m1.50.50.12.44.15.15.15.4" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.27.27.27.2.2.2" xref="S3.E1.m1.27.27.27.2.2.2.cmml">λ</mi><mrow id="S3.E1.m1.28.28.28.3.3.3.1" xref="S3.E1.m1.28.28.28.3.3.3.1.cmml"><mi id="S3.E1.m1.28.28.28.3.3.3.1.2" xref="S3.E1.m1.28.28.28.3.3.3.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.28.28.28.3.3.3.1.1" xref="S3.E1.m1.28.28.28.3.3.3.1.1.cmml">​</mo><mi id="S3.E1.m1.28.28.28.3.3.3.1.3" xref="S3.E1.m1.28.28.28.3.3.3.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.28.28.28.3.3.3.1.1a" xref="S3.E1.m1.28.28.28.3.3.3.1.1.cmml">​</mo><mi id="S3.E1.m1.28.28.28.3.3.3.1.4" xref="S3.E1.m1.28.28.28.3.3.3.1.4.cmml">p</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.50.50.12.44.15.15.15.3" xref="S3.E1.m1.44.44.6.cmml">​</mo><msub id="S3.E1.m1.50.50.12.44.15.15.15.5" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.29.29.29.4.4.4" xref="S3.E1.m1.29.29.29.4.4.4.cmml">L</mi><mrow id="S3.E1.m1.30.30.30.5.5.5.1" xref="S3.E1.m1.30.30.30.5.5.5.1.cmml"><mi id="S3.E1.m1.30.30.30.5.5.5.1.2" xref="S3.E1.m1.30.30.30.5.5.5.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.30.30.30.5.5.5.1.1" xref="S3.E1.m1.30.30.30.5.5.5.1.1.cmml">​</mo><mi id="S3.E1.m1.30.30.30.5.5.5.1.3" xref="S3.E1.m1.30.30.30.5.5.5.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.30.30.30.5.5.5.1.1a" xref="S3.E1.m1.30.30.30.5.5.5.1.1.cmml">​</mo><mi id="S3.E1.m1.30.30.30.5.5.5.1.4" xref="S3.E1.m1.30.30.30.5.5.5.1.4.cmml">p</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.50.50.12.44.15.15.15.3a" xref="S3.E1.m1.44.44.6.cmml">​</mo><mrow id="S3.E1.m1.50.50.12.44.15.15.15.2.2" xref="S3.E1.m1.44.44.6.cmml"><mo stretchy="false" id="S3.E1.m1.31.31.31.6.6.6" xref="S3.E1.m1.44.44.6.cmml">(</mo><msub id="S3.E1.m1.49.49.11.43.14.14.14.1.1.1" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.32.32.32.7.7.7" xref="S3.E1.m1.32.32.32.7.7.7.cmml">A</mi><mrow id="S3.E1.m1.33.33.33.8.8.8.1" xref="S3.E1.m1.33.33.33.8.8.8.1.cmml"><mi id="S3.E1.m1.33.33.33.8.8.8.1.2" xref="S3.E1.m1.33.33.33.8.8.8.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.33.33.33.8.8.8.1.1" xref="S3.E1.m1.33.33.33.8.8.8.1.1.cmml">​</mo><mi id="S3.E1.m1.33.33.33.8.8.8.1.3" xref="S3.E1.m1.33.33.33.8.8.8.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.33.33.33.8.8.8.1.1a" xref="S3.E1.m1.33.33.33.8.8.8.1.1.cmml">​</mo><mi id="S3.E1.m1.33.33.33.8.8.8.1.4" xref="S3.E1.m1.33.33.33.8.8.8.1.4.cmml">p</mi></mrow></msub><mo id="S3.E1.m1.34.34.34.9.9.9" xref="S3.E1.m1.44.44.6.cmml">,</mo><msubsup id="S3.E1.m1.50.50.12.44.15.15.15.2.2.2" xref="S3.E1.m1.44.44.6.cmml"><mi id="S3.E1.m1.35.35.35.10.10.10" xref="S3.E1.m1.35.35.35.10.10.10.cmml">A</mi><mrow id="S3.E1.m1.36.36.36.11.11.11.1" xref="S3.E1.m1.36.36.36.11.11.11.1.cmml"><mi id="S3.E1.m1.36.36.36.11.11.11.1.2" xref="S3.E1.m1.36.36.36.11.11.11.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.36.36.36.11.11.11.1.1" xref="S3.E1.m1.36.36.36.11.11.11.1.1.cmml">​</mo><mi id="S3.E1.m1.36.36.36.11.11.11.1.3" xref="S3.E1.m1.36.36.36.11.11.11.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.36.36.36.11.11.11.1.1a" xref="S3.E1.m1.36.36.36.11.11.11.1.1.cmml">​</mo><mi id="S3.E1.m1.36.36.36.11.11.11.1.4" xref="S3.E1.m1.36.36.36.11.11.11.1.4.cmml">p</mi></mrow><mrow id="S3.E1.m1.37.37.37.12.12.12.1" xref="S3.E1.m1.37.37.37.12.12.12.1.cmml"><mi id="S3.E1.m1.37.37.37.12.12.12.1.2" xref="S3.E1.m1.37.37.37.12.12.12.1.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.37.37.37.12.12.12.1.1" xref="S3.E1.m1.37.37.37.12.12.12.1.1.cmml">​</mo><mi id="S3.E1.m1.37.37.37.12.12.12.1.3" xref="S3.E1.m1.37.37.37.12.12.12.1.3.cmml">t</mi></mrow></msubsup><mo stretchy="false" id="S3.E1.m1.38.38.38.13.13.13" xref="S3.E1.m1.44.44.6.cmml">)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E1.m1.50b"><apply id="S3.E1.m1.44.44.6.cmml" xref="S3.E1.m1.50.50.12"><eq id="S3.E1.m1.3.3.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3.3.3"></eq><apply id="S3.E1.m1.44.44.6.8.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.44.44.6.8.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">𝐿</ci><apply id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1"><times id="S3.E1.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1"></times><ci id="S3.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.2">𝑡</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.3">𝑜</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.4.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.4">𝑡</ci></apply></apply><apply id="S3.E1.m1.44.44.6.6.cmml" xref="S3.E1.m1.50.50.12"><plus id="S3.E1.m1.13.13.13.13.13.13.cmml" xref="S3.E1.m1.13.13.13.13.13.13"></plus><apply id="S3.E1.m1.40.40.2.2.2.cmml" xref="S3.E1.m1.50.50.12"><times id="S3.E1.m1.40.40.2.2.2.3.cmml" xref="S3.E1.m1.50.50.12"></times><apply id="S3.E1.m1.40.40.2.2.2.4.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.40.40.2.2.2.4.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.4.4.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4.4.4">𝐿</ci><apply id="S3.E1.m1.5.5.5.5.5.5.1.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1"><times id="S3.E1.m1.5.5.5.5.5.5.1.1.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1"></times><ci id="S3.E1.m1.5.5.5.5.5.5.1.2.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.2">𝑣</ci><ci id="S3.E1.m1.5.5.5.5.5.5.1.3.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.3">𝑞</ci><ci id="S3.E1.m1.5.5.5.5.5.5.1.4.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.4">𝑎</ci></apply></apply><interval closure="open" id="S3.E1.m1.40.40.2.2.2.2.3.cmml" xref="S3.E1.m1.50.50.12"><apply id="S3.E1.m1.39.39.1.1.1.1.1.1.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.39.39.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.50.50.12">superscript</csymbol><ci id="S3.E1.m1.7.7.7.7.7.7.cmml" xref="S3.E1.m1.7.7.7.7.7.7">𝐴</ci><ci id="S3.E1.m1.8.8.8.8.8.8.1.cmml" xref="S3.E1.m1.8.8.8.8.8.8.1">′</ci></apply><apply id="S3.E1.m1.40.40.2.2.2.2.2.2.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.40.40.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.50.50.12">superscript</csymbol><ci id="S3.E1.m1.10.10.10.10.10.10.cmml" xref="S3.E1.m1.10.10.10.10.10.10">𝐴</ci><apply id="S3.E1.m1.11.11.11.11.11.11.1.cmml" xref="S3.E1.m1.11.11.11.11.11.11.1"><times id="S3.E1.m1.11.11.11.11.11.11.1.1.cmml" xref="S3.E1.m1.11.11.11.11.11.11.1.1"></times><ci id="S3.E1.m1.11.11.11.11.11.11.1.2.cmml" xref="S3.E1.m1.11.11.11.11.11.11.1.2">𝑔</ci><ci id="S3.E1.m1.11.11.11.11.11.11.1.3.cmml" xref="S3.E1.m1.11.11.11.11.11.11.1.3">𝑡</ci></apply></apply></interval></apply><apply id="S3.E1.m1.42.42.4.4.4.cmml" xref="S3.E1.m1.50.50.12"><times id="S3.E1.m1.42.42.4.4.4.3.cmml" xref="S3.E1.m1.50.50.12"></times><apply id="S3.E1.m1.42.42.4.4.4.4.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.42.42.4.4.4.4.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.14.14.14.14.14.14.cmml" xref="S3.E1.m1.14.14.14.14.14.14">𝜆</ci><ci id="S3.E1.m1.15.15.15.15.15.15.1.cmml" xref="S3.E1.m1.15.15.15.15.15.15.1">𝑄</ci></apply><apply id="S3.E1.m1.42.42.4.4.4.5.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.42.42.4.4.4.5.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.16.16.16.16.16.16.cmml" xref="S3.E1.m1.16.16.16.16.16.16">𝐿</ci><ci id="S3.E1.m1.17.17.17.17.17.17.1.cmml" xref="S3.E1.m1.17.17.17.17.17.17.1">𝑄</ci></apply><interval closure="open" id="S3.E1.m1.42.42.4.4.4.2.3.cmml" xref="S3.E1.m1.50.50.12"><apply id="S3.E1.m1.41.41.3.3.3.1.1.1.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.41.41.3.3.3.1.1.1.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.19.19.19.19.19.19.cmml" xref="S3.E1.m1.19.19.19.19.19.19">𝑄</ci><apply id="S3.E1.m1.20.20.20.20.20.20.1.cmml" xref="S3.E1.m1.20.20.20.20.20.20.1"><times id="S3.E1.m1.20.20.20.20.20.20.1.1.cmml" xref="S3.E1.m1.20.20.20.20.20.20.1.1"></times><ci id="S3.E1.m1.20.20.20.20.20.20.1.2.cmml" xref="S3.E1.m1.20.20.20.20.20.20.1.2">𝑖</ci><ci id="S3.E1.m1.20.20.20.20.20.20.1.3.cmml" xref="S3.E1.m1.20.20.20.20.20.20.1.3">𝑚</ci><ci id="S3.E1.m1.20.20.20.20.20.20.1.4.cmml" xref="S3.E1.m1.20.20.20.20.20.20.1.4">𝑝</ci></apply></apply><apply id="S3.E1.m1.42.42.4.4.4.2.2.2.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.42.42.4.4.4.2.2.2.1.cmml" xref="S3.E1.m1.50.50.12">superscript</csymbol><apply id="S3.E1.m1.42.42.4.4.4.2.2.2.2.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.42.42.4.4.4.2.2.2.2.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.22.22.22.22.22.22.cmml" xref="S3.E1.m1.22.22.22.22.22.22">𝑄</ci><apply id="S3.E1.m1.23.23.23.23.23.23.1.cmml" xref="S3.E1.m1.23.23.23.23.23.23.1"><times id="S3.E1.m1.23.23.23.23.23.23.1.1.cmml" xref="S3.E1.m1.23.23.23.23.23.23.1.1"></times><ci id="S3.E1.m1.23.23.23.23.23.23.1.2.cmml" xref="S3.E1.m1.23.23.23.23.23.23.1.2">𝑖</ci><ci id="S3.E1.m1.23.23.23.23.23.23.1.3.cmml" xref="S3.E1.m1.23.23.23.23.23.23.1.3">𝑚</ci><ci id="S3.E1.m1.23.23.23.23.23.23.1.4.cmml" xref="S3.E1.m1.23.23.23.23.23.23.1.4">𝑝</ci></apply></apply><apply id="S3.E1.m1.24.24.24.24.24.24.1.cmml" xref="S3.E1.m1.24.24.24.24.24.24.1"><times id="S3.E1.m1.24.24.24.24.24.24.1.1.cmml" xref="S3.E1.m1.24.24.24.24.24.24.1.1"></times><ci id="S3.E1.m1.24.24.24.24.24.24.1.2.cmml" xref="S3.E1.m1.24.24.24.24.24.24.1.2">𝑔</ci><ci id="S3.E1.m1.24.24.24.24.24.24.1.3.cmml" xref="S3.E1.m1.24.24.24.24.24.24.1.3">𝑡</ci></apply></apply></interval></apply><apply id="S3.E1.m1.44.44.6.6.6.cmml" xref="S3.E1.m1.50.50.12"><times id="S3.E1.m1.44.44.6.6.6.3.cmml" xref="S3.E1.m1.50.50.12"></times><apply id="S3.E1.m1.44.44.6.6.6.4.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.44.44.6.6.6.4.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.27.27.27.2.2.2.cmml" xref="S3.E1.m1.27.27.27.2.2.2">𝜆</ci><apply id="S3.E1.m1.28.28.28.3.3.3.1.cmml" xref="S3.E1.m1.28.28.28.3.3.3.1"><times id="S3.E1.m1.28.28.28.3.3.3.1.1.cmml" xref="S3.E1.m1.28.28.28.3.3.3.1.1"></times><ci id="S3.E1.m1.28.28.28.3.3.3.1.2.cmml" xref="S3.E1.m1.28.28.28.3.3.3.1.2">𝑖</ci><ci id="S3.E1.m1.28.28.28.3.3.3.1.3.cmml" xref="S3.E1.m1.28.28.28.3.3.3.1.3">𝑚</ci><ci id="S3.E1.m1.28.28.28.3.3.3.1.4.cmml" xref="S3.E1.m1.28.28.28.3.3.3.1.4">𝑝</ci></apply></apply><apply id="S3.E1.m1.44.44.6.6.6.5.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.44.44.6.6.6.5.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.29.29.29.4.4.4.cmml" xref="S3.E1.m1.29.29.29.4.4.4">𝐿</ci><apply id="S3.E1.m1.30.30.30.5.5.5.1.cmml" xref="S3.E1.m1.30.30.30.5.5.5.1"><times id="S3.E1.m1.30.30.30.5.5.5.1.1.cmml" xref="S3.E1.m1.30.30.30.5.5.5.1.1"></times><ci id="S3.E1.m1.30.30.30.5.5.5.1.2.cmml" xref="S3.E1.m1.30.30.30.5.5.5.1.2">𝑖</ci><ci id="S3.E1.m1.30.30.30.5.5.5.1.3.cmml" xref="S3.E1.m1.30.30.30.5.5.5.1.3">𝑚</ci><ci id="S3.E1.m1.30.30.30.5.5.5.1.4.cmml" xref="S3.E1.m1.30.30.30.5.5.5.1.4">𝑝</ci></apply></apply><interval closure="open" id="S3.E1.m1.44.44.6.6.6.2.3.cmml" xref="S3.E1.m1.50.50.12"><apply id="S3.E1.m1.43.43.5.5.5.1.1.1.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.43.43.5.5.5.1.1.1.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.32.32.32.7.7.7.cmml" xref="S3.E1.m1.32.32.32.7.7.7">𝐴</ci><apply id="S3.E1.m1.33.33.33.8.8.8.1.cmml" xref="S3.E1.m1.33.33.33.8.8.8.1"><times id="S3.E1.m1.33.33.33.8.8.8.1.1.cmml" xref="S3.E1.m1.33.33.33.8.8.8.1.1"></times><ci id="S3.E1.m1.33.33.33.8.8.8.1.2.cmml" xref="S3.E1.m1.33.33.33.8.8.8.1.2">𝑖</ci><ci id="S3.E1.m1.33.33.33.8.8.8.1.3.cmml" xref="S3.E1.m1.33.33.33.8.8.8.1.3">𝑚</ci><ci id="S3.E1.m1.33.33.33.8.8.8.1.4.cmml" xref="S3.E1.m1.33.33.33.8.8.8.1.4">𝑝</ci></apply></apply><apply id="S3.E1.m1.44.44.6.6.6.2.2.2.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.44.44.6.6.6.2.2.2.1.cmml" xref="S3.E1.m1.50.50.12">superscript</csymbol><apply id="S3.E1.m1.44.44.6.6.6.2.2.2.2.cmml" xref="S3.E1.m1.50.50.12"><csymbol cd="ambiguous" id="S3.E1.m1.44.44.6.6.6.2.2.2.2.1.cmml" xref="S3.E1.m1.50.50.12">subscript</csymbol><ci id="S3.E1.m1.35.35.35.10.10.10.cmml" xref="S3.E1.m1.35.35.35.10.10.10">𝐴</ci><apply id="S3.E1.m1.36.36.36.11.11.11.1.cmml" xref="S3.E1.m1.36.36.36.11.11.11.1"><times id="S3.E1.m1.36.36.36.11.11.11.1.1.cmml" xref="S3.E1.m1.36.36.36.11.11.11.1.1"></times><ci id="S3.E1.m1.36.36.36.11.11.11.1.2.cmml" xref="S3.E1.m1.36.36.36.11.11.11.1.2">𝑖</ci><ci id="S3.E1.m1.36.36.36.11.11.11.1.3.cmml" xref="S3.E1.m1.36.36.36.11.11.11.1.3">𝑚</ci><ci id="S3.E1.m1.36.36.36.11.11.11.1.4.cmml" xref="S3.E1.m1.36.36.36.11.11.11.1.4">𝑝</ci></apply></apply><apply id="S3.E1.m1.37.37.37.12.12.12.1.cmml" xref="S3.E1.m1.37.37.37.12.12.12.1"><times id="S3.E1.m1.37.37.37.12.12.12.1.1.cmml" xref="S3.E1.m1.37.37.37.12.12.12.1.1"></times><ci id="S3.E1.m1.37.37.37.12.12.12.1.2.cmml" xref="S3.E1.m1.37.37.37.12.12.12.1.2">𝑔</ci><ci id="S3.E1.m1.37.37.37.12.12.12.1.3.cmml" xref="S3.E1.m1.37.37.37.12.12.12.1.3">𝑡</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.50c">L_{tot}=L_{vqa}(A^{\prime},A^{gt})+\lambda_{Q}L_{Q}(Q_{imp},Q_{imp}^{gt})\\
+\lambda_{imp}L_{imp}(A_{imp},A_{imp}^{gt})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/main_att.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="685" height="284" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/main_att_2.png" id="S3.F4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="685" height="291" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S3.F4.2.1" class="ltx_text ltx_font_bold">Qualitative comparison of attention maps for Pythia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> and Pythia + IQ</span>. Top 2 rows represent implications and bottom 2 rows represent rephrasings. As evident from the figure, Pythia does not attend to relevant regions, whereas upon using our approach, the attention maps are much more focused on relevant regions.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments Setup</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We use the VQA v2.0 dataset for training and evaluating our model’s VQA performance. The VQA v2.0 training split consists of 443,757 questions on 82,783 images and the validation split contains 214,354 questions over 40,504 images.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">To train and evaluate our implication generator module and consistency, we use the implication dataset made by the rule-based approach in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. This dataset consists of 531,091 implied questions in training split and 255,682 questions for the validation split.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">We also evaluate our model’s consistency performance on human annotated VQA-Implications dataset which consists of 30,963 questions. For this dataset, we randomly select 10,500 questions from the VQA v2.0 validation set and create 3 implications (logeq, nec and mutex) per question.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">For robustness evaluation, we use the VQA-Rephrasings dataset provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. The dataset consists of 121,512 questions by making 3 rephrasings from 40,504 questions on the VQA v2.0 validation set.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>VQA Models</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In order to show the model independent behaviour of our proposed method, we evaluate intelligence of three VQA models: BUTD, BAN, Pythia. We use the open-source implementation of these models for training and evaluation. These models are trained with hyperparameters proposed in respective papers.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">BUTD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></span> uses bottom up attention mechanism from pretrained Faster-RCNN features on the images. Visual Genome <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> dataset is used to pretrain and extract top-K objects in the images during the preprocessing step. This model won the annual VQA challenge in 2017. For training BUTD, we used the fixed top-36 objects RCNN features for every image. Their model achieves 63.62% accuracy on the VQA v2.0 validation split.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite></span> uses bilinear model to reduce the computational cost of learning attention distributions, whereby different attention maps are built for each modality. Further, low-rank bilinear pooling extracts the joint representations for each pair of channels. BAN achieves 65.37% accuracy on the VQA v2.0 validation split.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Pythia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite></span> extracts image features from detectron also pretrained over visual genome. It also uses Resnet-152 features and ensembling over 30 models, but we didn’t use these techniques in our study. Glove embeddings are used for question and its implications. Pythia was the winning entry of 2018 VQA challenge and achieves 64.70% accuracy on the VQA v2.0 validation split.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Implementation details</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.6" class="ltx_p">For the gating mechanism and late activation, <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="T_{sim}=0.9" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><msub id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2.2" xref="S4.SS3.p1.1.m1.1.1.2.2.cmml">T</mi><mrow id="S4.SS3.p1.1.m1.1.1.2.3" xref="S4.SS3.p1.1.m1.1.1.2.3.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2.3.2" xref="S4.SS3.p1.1.m1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.1.1.2.3.1" xref="S4.SS3.p1.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.1.m1.1.1.2.3.3" xref="S4.SS3.p1.1.m1.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.1.1.2.3.1a" xref="S4.SS3.p1.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.1.m1.1.1.2.3.4" xref="S4.SS3.p1.1.m1.1.1.2.3.4.cmml">m</mi></mrow></msub><mo id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><eq id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></eq><apply id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.2.1.cmml" xref="S4.SS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2.2">𝑇</ci><apply id="S4.SS3.p1.1.m1.1.1.2.3.cmml" xref="S4.SS3.p1.1.m1.1.1.2.3"><times id="S4.SS3.p1.1.m1.1.1.2.3.1.cmml" xref="S4.SS3.p1.1.m1.1.1.2.3.1"></times><ci id="S4.SS3.p1.1.m1.1.1.2.3.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2.3.2">𝑠</ci><ci id="S4.SS3.p1.1.m1.1.1.2.3.3.cmml" xref="S4.SS3.p1.1.m1.1.1.2.3.3">𝑖</ci><ci id="S4.SS3.p1.1.m1.1.1.2.3.4.cmml" xref="S4.SS3.p1.1.m1.1.1.2.3.4">𝑚</ci></apply></apply><cn type="float" id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">T_{sim}=0.9</annotation></semantics></math> and <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="A_{iter}=5500" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><msub id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2.2" xref="S4.SS3.p1.2.m2.1.1.2.2.cmml">A</mi><mrow id="S4.SS3.p1.2.m2.1.1.2.3" xref="S4.SS3.p1.2.m2.1.1.2.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2.3.2" xref="S4.SS3.p1.2.m2.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.2.3.1" xref="S4.SS3.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.2.m2.1.1.2.3.3" xref="S4.SS3.p1.2.m2.1.1.2.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.2.3.1a" xref="S4.SS3.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.2.m2.1.1.2.3.4" xref="S4.SS3.p1.2.m2.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.2.3.1b" xref="S4.SS3.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.2.m2.1.1.2.3.5" xref="S4.SS3.p1.2.m2.1.1.2.3.5.cmml">r</mi></mrow></msub><mo id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">5500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><eq id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></eq><apply id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.2.1.cmml" xref="S4.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.2.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2.2">𝐴</ci><apply id="S4.SS3.p1.2.m2.1.1.2.3.cmml" xref="S4.SS3.p1.2.m2.1.1.2.3"><times id="S4.SS3.p1.2.m2.1.1.2.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.2.3.1"></times><ci id="S4.SS3.p1.2.m2.1.1.2.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2.3.2">𝑖</ci><ci id="S4.SS3.p1.2.m2.1.1.2.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.2.3.3">𝑡</ci><ci id="S4.SS3.p1.2.m2.1.1.2.3.4.cmml" xref="S4.SS3.p1.2.m2.1.1.2.3.4">𝑒</ci><ci id="S4.SS3.p1.2.m2.1.1.2.3.5.cmml" xref="S4.SS3.p1.2.m2.1.1.2.3.5">𝑟</ci></apply></apply><cn type="integer" id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">5500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">A_{iter}=5500</annotation></semantics></math> for Pythia and <math id="S4.SS3.p1.3.m3.2" class="ltx_Math" alttext="A_{iter}=10,000" display="inline"><semantics id="S4.SS3.p1.3.m3.2a"><mrow id="S4.SS3.p1.3.m3.2.3" xref="S4.SS3.p1.3.m3.2.3.cmml"><msub id="S4.SS3.p1.3.m3.2.3.2" xref="S4.SS3.p1.3.m3.2.3.2.cmml"><mi id="S4.SS3.p1.3.m3.2.3.2.2" xref="S4.SS3.p1.3.m3.2.3.2.2.cmml">A</mi><mrow id="S4.SS3.p1.3.m3.2.3.2.3" xref="S4.SS3.p1.3.m3.2.3.2.3.cmml"><mi id="S4.SS3.p1.3.m3.2.3.2.3.2" xref="S4.SS3.p1.3.m3.2.3.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.2.3.2.3.1" xref="S4.SS3.p1.3.m3.2.3.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.2.3.2.3.3" xref="S4.SS3.p1.3.m3.2.3.2.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.2.3.2.3.1a" xref="S4.SS3.p1.3.m3.2.3.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.2.3.2.3.4" xref="S4.SS3.p1.3.m3.2.3.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.2.3.2.3.1b" xref="S4.SS3.p1.3.m3.2.3.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.2.3.2.3.5" xref="S4.SS3.p1.3.m3.2.3.2.3.5.cmml">r</mi></mrow></msub><mo id="S4.SS3.p1.3.m3.2.3.1" xref="S4.SS3.p1.3.m3.2.3.1.cmml">=</mo><mrow id="S4.SS3.p1.3.m3.2.3.3.2" xref="S4.SS3.p1.3.m3.2.3.3.1.cmml"><mn id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">10</mn><mo id="S4.SS3.p1.3.m3.2.3.3.2.1" xref="S4.SS3.p1.3.m3.2.3.3.1.cmml">,</mo><mn id="S4.SS3.p1.3.m3.2.2" xref="S4.SS3.p1.3.m3.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.2b"><apply id="S4.SS3.p1.3.m3.2.3.cmml" xref="S4.SS3.p1.3.m3.2.3"><eq id="S4.SS3.p1.3.m3.2.3.1.cmml" xref="S4.SS3.p1.3.m3.2.3.1"></eq><apply id="S4.SS3.p1.3.m3.2.3.2.cmml" xref="S4.SS3.p1.3.m3.2.3.2"><csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.2.3.2.1.cmml" xref="S4.SS3.p1.3.m3.2.3.2">subscript</csymbol><ci id="S4.SS3.p1.3.m3.2.3.2.2.cmml" xref="S4.SS3.p1.3.m3.2.3.2.2">𝐴</ci><apply id="S4.SS3.p1.3.m3.2.3.2.3.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3"><times id="S4.SS3.p1.3.m3.2.3.2.3.1.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.1"></times><ci id="S4.SS3.p1.3.m3.2.3.2.3.2.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.2">𝑖</ci><ci id="S4.SS3.p1.3.m3.2.3.2.3.3.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.3">𝑡</ci><ci id="S4.SS3.p1.3.m3.2.3.2.3.4.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.4">𝑒</ci><ci id="S4.SS3.p1.3.m3.2.3.2.3.5.cmml" xref="S4.SS3.p1.3.m3.2.3.2.3.5">𝑟</ci></apply></apply><list id="S4.SS3.p1.3.m3.2.3.3.1.cmml" xref="S4.SS3.p1.3.m3.2.3.3.2"><cn type="integer" id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">10</cn><cn type="integer" id="S4.SS3.p1.3.m3.2.2.cmml" xref="S4.SS3.p1.3.m3.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.2c">A_{iter}=10,000</annotation></semantics></math> for BAN and BUTD. The LSTM hidden state size for implication generator module is 1024 and Glove embeddings are used of <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="dim=300" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mrow id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml"><mi id="S4.SS3.p1.4.m4.1.1.2.2" xref="S4.SS3.p1.4.m4.1.1.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.4.m4.1.1.2.1" xref="S4.SS3.p1.4.m4.1.1.2.1.cmml">​</mo><mi id="S4.SS3.p1.4.m4.1.1.2.3" xref="S4.SS3.p1.4.m4.1.1.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.4.m4.1.1.2.1a" xref="S4.SS3.p1.4.m4.1.1.2.1.cmml">​</mo><mi id="S4.SS3.p1.4.m4.1.1.2.4" xref="S4.SS3.p1.4.m4.1.1.2.4.cmml">m</mi></mrow><mo id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml">300</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><eq id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></eq><apply id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2"><times id="S4.SS3.p1.4.m4.1.1.2.1.cmml" xref="S4.SS3.p1.4.m4.1.1.2.1"></times><ci id="S4.SS3.p1.4.m4.1.1.2.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2.2">𝑑</ci><ci id="S4.SS3.p1.4.m4.1.1.2.3.cmml" xref="S4.SS3.p1.4.m4.1.1.2.3">𝑖</ci><ci id="S4.SS3.p1.4.m4.1.1.2.4.cmml" xref="S4.SS3.p1.4.m4.1.1.2.4">𝑚</ci></apply><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3">300</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">dim=300</annotation></semantics></math>. The weights for the losses are kept as <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="\lambda_{Q}=0.5" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><mrow id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><msub id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml"><mi id="S4.SS3.p1.5.m5.1.1.2.2" xref="S4.SS3.p1.5.m5.1.1.2.2.cmml">λ</mi><mi id="S4.SS3.p1.5.m5.1.1.2.3" xref="S4.SS3.p1.5.m5.1.1.2.3.cmml">Q</mi></msub><mo id="S4.SS3.p1.5.m5.1.1.1" xref="S4.SS3.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><eq id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1"></eq><apply id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.2.1.cmml" xref="S4.SS3.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.5.m5.1.1.2.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2.2">𝜆</ci><ci id="S4.SS3.p1.5.m5.1.1.2.3.cmml" xref="S4.SS3.p1.5.m5.1.1.2.3">𝑄</ci></apply><cn type="float" id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">\lambda_{Q}=0.5</annotation></semantics></math> and <math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="\lambda_{imp}=1.5" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><mrow id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml"><msub id="S4.SS3.p1.6.m6.1.1.2" xref="S4.SS3.p1.6.m6.1.1.2.cmml"><mi id="S4.SS3.p1.6.m6.1.1.2.2" xref="S4.SS3.p1.6.m6.1.1.2.2.cmml">λ</mi><mrow id="S4.SS3.p1.6.m6.1.1.2.3" xref="S4.SS3.p1.6.m6.1.1.2.3.cmml"><mi id="S4.SS3.p1.6.m6.1.1.2.3.2" xref="S4.SS3.p1.6.m6.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.6.m6.1.1.2.3.1" xref="S4.SS3.p1.6.m6.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.6.m6.1.1.2.3.3" xref="S4.SS3.p1.6.m6.1.1.2.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.6.m6.1.1.2.3.1a" xref="S4.SS3.p1.6.m6.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.6.m6.1.1.2.3.4" xref="S4.SS3.p1.6.m6.1.1.2.3.4.cmml">p</mi></mrow></msub><mo id="S4.SS3.p1.6.m6.1.1.1" xref="S4.SS3.p1.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.6.m6.1.1.3" xref="S4.SS3.p1.6.m6.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><apply id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1"><eq id="S4.SS3.p1.6.m6.1.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1.1"></eq><apply id="S4.SS3.p1.6.m6.1.1.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.6.m6.1.1.2.1.cmml" xref="S4.SS3.p1.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.6.m6.1.1.2.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2.2">𝜆</ci><apply id="S4.SS3.p1.6.m6.1.1.2.3.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3"><times id="S4.SS3.p1.6.m6.1.1.2.3.1.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.1"></times><ci id="S4.SS3.p1.6.m6.1.1.2.3.2.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.2">𝑖</ci><ci id="S4.SS3.p1.6.m6.1.1.2.3.3.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.3">𝑚</ci><ci id="S4.SS3.p1.6.m6.1.1.2.3.4.cmml" xref="S4.SS3.p1.6.m6.1.1.2.3.4">𝑝</ci></apply></apply><cn type="float" id="S4.SS3.p1.6.m6.1.1.3.cmml" xref="S4.SS3.p1.6.m6.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">\lambda_{imp}=1.5</annotation></semantics></math>. All models are trained on training split and evaluated on validation split of VQA v2.0 dataset.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results and Analysis</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Consistency performance</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">As defined in Section <a href="#S1" title="1 Introduction ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, consistency of any VQA model is its ability to answer the implications of a question correctly, if it correctly answers the original question. Implications are generated on the correctly answered questions from validation VQA v2.0 dataset, and consistency score is calculated as the fraction of correct predictions to total implications. These generated implications are binary yes/no questions, and hence randomly answering them would give about 50% consistency score.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">As seen in Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Implication Generator Module ‣ 3 Approach ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> All the 3 models achieve an average consistency score of <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>70%. i.e. they fail 30% of the times on implications of correctly predicted questions. Intuitively, Nec-implication serves as the neccessary condition which the models should know in order to answer the question. For eg: In order to answer ”How many birds are there?”, they should understand if ”Are there any birds in the picture?” Consistency score of <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>75% Nec-implication shows the lack of image understanding in these models. Using our approach, the three models achieve <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_typewriter" style="position:relative; bottom:-2.2pt;">~</span>97% on Nec-implication.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">BLEU-1</span></th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">BLEU-2</span></th>
<th id="S5.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">BLEU-3</span></th>
<th id="S5.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.5.1" class="ltx_text ltx_font_bold">BLEU-4</span></th>
<th id="S5.T2.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.6.1" class="ltx_text ltx_font_bold">ROUGE-L</span></th>
<th id="S5.T2.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.7.1" class="ltx_text ltx_font_bold">METEOR</span></th>
<th id="S5.T2.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.1.1.8.1" class="ltx_text ltx_font_bold">CIDEr</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.2.1" class="ltx_tr">
<th id="S5.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Pythia + IQ</th>
<td id="S5.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.627</td>
<td id="S5.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.520</td>
<td id="S5.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.443</td>
<td id="S5.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.381</td>
<td id="S5.T2.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.632</td>
<td id="S5.T2.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.288</td>
<td id="S5.T2.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.343</td>
</tr>
<tr id="S5.T2.1.3.2" class="ltx_tr">
<th id="S5.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Pythia + IQ + Knob</th>
<td id="S5.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.3.2.2.1" class="ltx_text ltx_font_bold">0.785</span></td>
<td id="S5.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.3.2.3.1" class="ltx_text ltx_font_bold">0.715</span></td>
<td id="S5.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.3.2.4.1" class="ltx_text ltx_font_bold">0.647</span></td>
<td id="S5.T2.1.3.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.3.2.5.1" class="ltx_text ltx_font_bold">0.581</span></td>
<td id="S5.T2.1.3.2.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.3.2.6.1" class="ltx_text ltx_font_bold">0.795</span></td>
<td id="S5.T2.1.3.2.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.3.2.7.1" class="ltx_text ltx_font_bold">0.409</span></td>
<td id="S5.T2.1.3.2.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S5.T2.1.3.2.8.1" class="ltx_text ltx_font_bold">5.263</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S5.T2.3.1" class="ltx_text ltx_font_bold">Implication generation performance on rule-based Implication validation dataset.</span> Note that using the knob mechanism instead of an implied answer gives significant improvement.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Robustness Performance</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We evaluate our framework’s robustness performance on the VQA-Rephrasings dataset introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Robustness is evaluated only on correctly answered original questions. Note that just like the models in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, we also do not train our models on the VQA-Rephrasings dataset. The results in Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Implication Generator Module ‣ 3 Approach ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> show that models trained using our approach are more robust compared to baseline. This is consistent with the hypotheses that our models learn to improve on a stronger linguistic variation than rephrasings by learning on implications and hence improvement in robustness is expected.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Attention Map Analysis</h3>

<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.2.2.3.1" class="ltx_tr">
<th id="S5.T3.2.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S5.T3.2.2.3.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S5.T3.2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.3.1.2.1" class="ltx_text ltx_font_bold">Logeq</span></td>
<td id="S5.T3.2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.3.1.3.1" class="ltx_text ltx_font_bold">Rephrasing</span></td>
</tr>
<tr id="S5.T3.2.2.2" class="ltx_tr">
<td id="S5.T3.1.1.1.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">(<math id="S5.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\times 10^{-4}" display="inline"><semantics id="S5.T3.1.1.1.1.1.m1.1a"><mrow id="S5.T3.1.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.1.m1.1.1.cmml"><mi id="S5.T3.1.1.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.1.1.m1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S5.T3.1.1.1.1.1.m1.1.1.1" xref="S5.T3.1.1.1.1.1.m1.1.1.1.cmml">×</mo><msup id="S5.T3.1.1.1.1.1.m1.1.1.3" xref="S5.T3.1.1.1.1.1.m1.1.1.3.cmml"><mn id="S5.T3.1.1.1.1.1.m1.1.1.3.2" xref="S5.T3.1.1.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.T3.1.1.1.1.1.m1.1.1.3.3" xref="S5.T3.1.1.1.1.1.m1.1.1.3.3.cmml"><mo id="S5.T3.1.1.1.1.1.m1.1.1.3.3a" xref="S5.T3.1.1.1.1.1.m1.1.1.3.3.cmml">−</mo><mn id="S5.T3.1.1.1.1.1.m1.1.1.3.3.2" xref="S5.T3.1.1.1.1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1"><times id="S5.T3.1.1.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.1"></times><csymbol cd="latexml" id="S5.T3.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.2">absent</csymbol><apply id="S5.T3.1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.1.1.1.1.1.m1.1.1.3.1.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.T3.1.1.1.1.1.m1.1.1.3.2.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.3.2">10</cn><apply id="S5.T3.1.1.1.1.1.m1.1.1.3.3.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.3.3"><minus id="S5.T3.1.1.1.1.1.m1.1.1.3.3.1.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.3.3"></minus><cn type="integer" id="S5.T3.1.1.1.1.1.m1.1.1.3.3.2.cmml" xref="S5.T3.1.1.1.1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.1.m1.1c">\times 10^{-4}</annotation></semantics></math>)</span></td>
<td id="S5.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.2.2.1" class="ltx_text ltx_font_bold">(<math id="S5.T3.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\times 10^{-4}" display="inline"><semantics id="S5.T3.2.2.2.2.1.m1.1a"><mrow id="S5.T3.2.2.2.2.1.m1.1.1" xref="S5.T3.2.2.2.2.1.m1.1.1.cmml"><mi id="S5.T3.2.2.2.2.1.m1.1.1.2" xref="S5.T3.2.2.2.2.1.m1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S5.T3.2.2.2.2.1.m1.1.1.1" xref="S5.T3.2.2.2.2.1.m1.1.1.1.cmml">×</mo><msup id="S5.T3.2.2.2.2.1.m1.1.1.3" xref="S5.T3.2.2.2.2.1.m1.1.1.3.cmml"><mn id="S5.T3.2.2.2.2.1.m1.1.1.3.2" xref="S5.T3.2.2.2.2.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.T3.2.2.2.2.1.m1.1.1.3.3" xref="S5.T3.2.2.2.2.1.m1.1.1.3.3.cmml"><mo id="S5.T3.2.2.2.2.1.m1.1.1.3.3a" xref="S5.T3.2.2.2.2.1.m1.1.1.3.3.cmml">−</mo><mn id="S5.T3.2.2.2.2.1.m1.1.1.3.3.2" xref="S5.T3.2.2.2.2.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.1.m1.1b"><apply id="S5.T3.2.2.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1"><times id="S5.T3.2.2.2.2.1.m1.1.1.1.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.1"></times><csymbol cd="latexml" id="S5.T3.2.2.2.2.1.m1.1.1.2.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.2">absent</csymbol><apply id="S5.T3.2.2.2.2.1.m1.1.1.3.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.2.2.2.2.1.m1.1.1.3.1.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.T3.2.2.2.2.1.m1.1.1.3.2.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.3.2">10</cn><apply id="S5.T3.2.2.2.2.1.m1.1.1.3.3.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.3.3"><minus id="S5.T3.2.2.2.2.1.m1.1.1.3.3.1.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.3.3"></minus><cn type="integer" id="S5.T3.2.2.2.2.1.m1.1.1.3.3.2.cmml" xref="S5.T3.2.2.2.2.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.1.m1.1c">\times 10^{-4}</annotation></semantics></math>)</span></td>
</tr>
<tr id="S5.T3.2.2.4.2" class="ltx_tr">
<th id="S5.T3.2.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">BUTD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</th>
<td id="S5.T3.2.2.4.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">31.72</td>
<td id="S5.T3.2.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">15.51</td>
</tr>
<tr id="S5.T3.2.2.5.3" class="ltx_tr">
<th id="S5.T3.2.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">BUTD + IQ <span id="S5.T3.2.2.5.3.1.1" class="ltx_text" style="font-size:90%;">(ours)</span>
</th>
<td id="S5.T3.2.2.5.3.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.5.3.2.1" class="ltx_text ltx_font_bold">26.73</span></td>
<td id="S5.T3.2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.5.3.3.1" class="ltx_text ltx_font_bold">13.88</span></td>
</tr>
<tr id="S5.T3.2.2.6.4" class="ltx_tr">
<th id="S5.T3.2.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<td id="S5.T3.2.2.6.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">8.09</td>
<td id="S5.T3.2.2.6.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">5.03</td>
</tr>
<tr id="S5.T3.2.2.7.5" class="ltx_tr">
<th id="S5.T3.2.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">BAN + IQ <span id="S5.T3.2.2.7.5.1.1" class="ltx_text" style="font-size:90%;">(ours)</span>
</th>
<td id="S5.T3.2.2.7.5.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.7.5.2.1" class="ltx_text ltx_font_bold">5.41</span></td>
<td id="S5.T3.2.2.7.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.7.5.3.1" class="ltx_text ltx_font_bold">3.64</span></td>
</tr>
<tr id="S5.T3.2.2.8.6" class="ltx_tr">
<th id="S5.T3.2.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">Pythia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
</th>
<td id="S5.T3.2.2.8.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">11.41</td>
<td id="S5.T3.2.2.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">5.40</td>
</tr>
<tr id="S5.T3.2.2.9.7" class="ltx_tr">
<th id="S5.T3.2.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">Pythia + IQ <span id="S5.T3.2.2.9.7.1.1" class="ltx_text" style="font-size:90%;">(ours)</span>
</th>
<td id="S5.T3.2.2.9.7.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.9.7.2.1" class="ltx_text ltx_font_bold">5.83</span></td>
<td id="S5.T3.2.2.9.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.9.7.3.1" class="ltx_text ltx_font_bold">3.37</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S5.T3.4.1" class="ltx_text ltx_font_bold">Attention map analysis.</span> Logeq (Rephrasing) denotes the mean Euclidean distance between attention maps of original question and Logeq (Rephrasing). Models trained with our approach produce better results highlighting stronger multi-modal understanding.</figcaption>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">As a qualitative analysis, we compare the attention maps of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> with our approach. As we can see in Fig <a href="#S3.F4" title="Figure 4 ‣ 3.3 Cyclic Framework ‣ 3 Approach ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the attention maps generated by our approach are significantly better than those of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> for both implications and rephrasings.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">To ensure appropriate visual grounding, we believe that the model should look at same regions as original question for logically equivalent and rephrased questions. As a quantitative comparison, we compute the mean Euclidean distance between attention weights for logically equivalent (Logeq) and rephrased questions with their respective original question. Table <a href="#S5.T3" title="Table 3 ‣ 5.3 Attention Map Analysis ‣ 5 Results and Analysis ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows that models trained with our approach tend to focus on same regions to answer the original question, its rephrasing and its logical equivalent counterpart. These analysis show that multi-modal understanding of vision and language is enhanced using our approach.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Data Augmentation</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">Since we are using an extra dataset (rule-based implications) in addition to VQA v2.0 to train our models, we also compare our models’ consistency with models finetuned using data augmentation. Table <a href="#S5.T4" title="Table 4 ‣ 5.4 Data Augmentation ‣ 5 Results and Analysis ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> summarizes these results. Better performance of our models on the human annotated VQA-Implications dataset shows that models trained with our approach generalize better and hence would do better than data augmentation in the outside world.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T4.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_rule" style="width:0.0pt;height:15.0pt;background:black;display:inline-block;"></span><span id="S5.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span>
</th>
<td id="S5.T4.1.1.1.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;">
<span id="S5.T4.1.1.1.2.1" class="ltx_ERROR undefined">\pbox</span>20cm<span id="S5.T4.1.1.1.2.2" class="ltx_text ltx_font_bold">Consistency</span>
</td>
<td id="S5.T4.1.1.1.3" class="ltx_td ltx_border_t" style="padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T4.1.2.2" class="ltx_tr">
<th id="S5.T4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.2.2.1.1" class="ltx_text ltx_font_bold">(rule-based)</span></th>
<td id="S5.T4.1.2.2.2" class="ltx_td ltx_align_right" style="padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;">
<span id="S5.T4.1.2.2.2.1" class="ltx_ERROR undefined">\pbox</span>20cm<span id="S5.T4.1.2.2.2.2" class="ltx_text ltx_font_bold">Consistency</span>
</td>
<td id="S5.T4.1.2.2.3" class="ltx_td" style="padding-bottom:0.0pt;padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T4.1.3.3" class="ltx_tr">
<th id="S5.T4.1.3.3.1" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.3.3.1.1" class="ltx_text ltx_font_bold">(VQA-Imp)</span></th>
<td id="S5.T4.1.3.3.2" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T4.1.3.3.3" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T4.1.4.4" class="ltx_tr">
<th id="S5.T4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">BUTD + DA</th>
<td id="S5.T4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.4.4.2.1" class="ltx_text ltx_font_bold">93.1</span></td>
<td id="S5.T4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">74.24</td>
</tr>
<tr id="S5.T4.1.5.5" class="ltx_tr">
<th id="S5.T4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">BUTD + IQ <span id="S5.T4.1.5.5.1.1" class="ltx_text" style="font-size:90%;">(ours)</span>
</th>
<td id="S5.T4.1.5.5.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">88.1</td>
<td id="S5.T4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.5.5.3.1" class="ltx_text ltx_font_bold">74.38</span></td>
</tr>
<tr id="S5.T4.1.6.6" class="ltx_tr">
<th id="S5.T4.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">BAN + DA</th>
<td id="S5.T4.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">87.6</td>
<td id="S5.T4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">74.33</td>
</tr>
<tr id="S5.T4.1.7.7" class="ltx_tr">
<th id="S5.T4.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">BAN + IQ <span id="S5.T4.1.7.7.1.1" class="ltx_text" style="font-size:90%;">(ours)</span>
</th>
<td id="S5.T4.1.7.7.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.7.7.2.1" class="ltx_text ltx_font_bold">89.6</span></td>
<td id="S5.T4.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.7.7.3.1" class="ltx_text ltx_font_bold">74.61</span></td>
</tr>
<tr id="S5.T4.1.8.8" class="ltx_tr">
<th id="S5.T4.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">Pythia + DA</th>
<td id="S5.T4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.8.8.2.1" class="ltx_text ltx_font_bold">89.7</span></td>
<td id="S5.T4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">76.19</td>
</tr>
<tr id="S5.T4.1.9.9" class="ltx_tr">
<th id="S5.T4.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l" style="padding-top:1pt;padding-bottom:1pt;">Pythia + IQ <span id="S5.T4.1.9.9.1.1" class="ltx_text" style="font-size:90%;">(ours)</span>
</th>
<td id="S5.T4.1.9.9.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1pt;padding-bottom:1pt;">88.7</td>
<td id="S5.T4.1.9.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.9.9.3.1" class="ltx_text ltx_font_bold">76.55</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S5.T4.3.1" class="ltx_text ltx_font_bold">Consistency comparison of data augmentation vs our approach.</span> VQA-Imp denotes our VQA-Implications dataset and DA stands for models finetuned on rule-based training implications. Even though our models lack on rule-based dataset, they consistently outperform their respective baselines on the VQA-Implication dataset.</figcaption>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Implication Generator Performance</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">We train our implication generator on the rule-based training dataset and evaluate our module on rule-based validation split. We use common question generator metrics such as BLEU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, ROUGE-L <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, METEOR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and CIDEr <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> scores for evaluation. We also demonstrate the importance of using the knob mechanism instead of an implied answer as input to the module. Table <a href="#S5.T2" title="Table 2 ‣ 5.1 Consistency performance ‣ 5 Results and Analysis ‣ IQ-VQA: Intelligent Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the results of the implication generator module.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Works</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Our contributions in this paper are three fold. First, we propose a model-independent cyclic training scheme for improving consistency and robustness of VQA models without degrading their performance. Second, a novel implication generator module for making implications using the question answer pair and a knob mechanism. Third, a new annotated VQA-Implications dataset as an evaluation baseline for future works in consistency.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Our implication generator being trained on rule-based implications dataset, has its own limitations. Firstly, the implications are restricted to 3 types - Logical Equivalence, Necessary Condition and Mutual Exclusion and all implications are limited to ’yes/no’ type. We believe that learning on implications not restricted to these limitations should lead to better performance. Furthermore, the rule-based implications come from a fixed distribution and are not as diverse as human annotated implications would be. This limitation can also be quantitatively seen by observing the difference between models’ performance on rule-based and human annotated implications.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We would like to thank Manish Borthakur, Aditi Jain and Udita Mittal from Indian Institute of Technology, Delhi for annotating the VQA-Implications dataset.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
A. Agrawal, D. Batra, D. Parikh, and A. Kembhavi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Don’t Just Assume; Look and Answer: Overcoming Priors for Visual
Question Answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 4971–4980, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
Gould, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Bottom-Up and Top-Down Attention for Image Captioning and Visual
Question Answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, June 2018.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
C. Lawrence Zitnick, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">VQA: Visual Question Answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision (ICCV)</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Michael Denkowski and Alon Lavie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Meteor Universal: Language Specific Translation Evaluation for Any
Target Language.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the EACL 2014 Workshop on Statistical Machine
Translation</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Tejas Gokhale, Pratyay Banerjee, Chitta Baral, and Yezhou Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">VQA-LOL: Visual Question Answering under the Lens of Logic, 2020.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Making the V in VQA Matter: Elevating the Role of Image
Understanding in Visual Question Answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Bilinear Attention Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems 31</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages
1571–1581, 2018.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Visual genome: Connecting language and vision using crowdsourced
dense image annotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International journal of computer vision</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 123(1):32–73, 2017.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Vishwajeet Kumar, Ganesh Ramakrishnan, and Yuan-Fang Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Putting the horse before the cart: A generator-evaluator framework
for question generation from text.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 23rd Conference on Computational Natural
Language Learning (CoNLL)</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, pages 812–821, 2019.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
Radu Soricut.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">ALBERT: A Lite BERT for Self-supervised Learning of Language
Representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Chin-Yew Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">ROUGE: A Package for Automatic Evaluation of Summaries.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Text Summarization Branches Out</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 74–81, Barcelona,
Spain, July 2004. Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Varun Manjunatha, Nirat Saini, and Larry S. Davis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Explicit Bias Discovery in Visual Question Answering Models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">BLEU: A Method for Automatic Evaluation of Machine Translation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 40th Annual Meeting on Association for
Computational Linguistics</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, ACL ’02, page 311–318, USA, 2002. Association
for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Arijit Ray, Karan Sikka, Ajay Divakaran, Stefan Lee, and Giedrius Burachas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Sunny and Dark Outside?! Improving Answer Consistency in VQA through
Entailed Question Generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 5863–5868, 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Sathish Reddy, Dinesh Raghu, Mitesh M. Khapra, and Sachindra Joshi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Generating Natural Language Question-Answer Pairs from a Knowledge
Graph Using a RNN Based Question Generation Model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 15th Conference of the European Chapter
of the Association for Computational Linguistics: Volume 1, Long Papers</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">,
pages 376–385, Valencia, Spain, Apr. 2017. Association for Computational
Linguistics.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Marco Tulio Ribeiro, Carlos Guestrin, and Sameer Singh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Are Red Roses Red? Evaluating Consistency of Question-Answering
Models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 6174–6184, Florence, Italy, July 2019.
Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Ramprasaath R Selvaraju, Purva Tendulkar, Devi Parikh, Eric Horvitz,
Marco Tulio Ribeiro, Besmira Nushi, and Ece Kamar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">SQuINTing at VQA Models: Introspecting VQA Models With
Sub-Questions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 10003–10011, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Meet Shah, Xinlei Chen, Marcus Rohrbach, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Cycle-Consistency for Robust Visual Question Answering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Narayanan Sundaram, Thomas Brox, and Kurt Keutzer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Dense Point Trajectories by GPU-Accelerated Large Displacement
Optical Flow.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 11th European Conference on Computer
Vision: Part I</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, ECCV’10, page 438–451, Berlin, Heidelberg, 2010.
Springer-Verlag.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Hao Tan and Mohit Bansal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">LXMERT: Learning Cross-Modality Encoder Representations from
Transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Duyu Tang, Nan Duan, Zhao Yan, Zhirui Zhang, Yibo Sun, Shujie Liu, Yuanhua Lv,
and Ming Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Learning to Collaborate for Question Answering and Asking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 1564–1574, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Ramakrishna Vedantam, C. Lawrence Zitnick, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">CIDEr: Consensus-Based Image Description Evaluation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, June 2015.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei
Zhang, and Ming Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">ProphetNet: Predicting Future N-gram for Sequence-to-Sequence
Pre-training, 2020.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Yu Jiang, Vivek Natarajan, Xinlei Chen, Marcus Rohrbach, Dhruv Batra, and
Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Pythia v0.1: the Winning Entry to the VQA Challenge 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1807.09956</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Peng Zhang, Yash Goyal, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Yin and yang: Balancing and answering binary visual questions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 5014–5022, 2016.
</span>
</span>
</li>
</ul>
</section>
<figure id="id3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/att_1.png" id="id1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="568" height="296" alt="[Uncaptioned image]"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/att_2.png" id="id2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="568" height="296" alt="[Uncaptioned image]"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/att_5.png" id="id3.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="568" height="290" alt="[Uncaptioned image]"></div>
</div>
</figure>
<figure id="Sx1.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/att_3.png" id="Sx1.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="568" height="296" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/images/att_4.png" id="Sx1.F5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="568" height="296" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Attention map comparisons of Pythia <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> vs the same model trained with our approach.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="id7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x2.jpg" id="id4.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="348" height="108" alt="[Uncaptioned image]"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x3.jpg" id="id5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="332" height="89" alt="[Uncaptioned image]"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x4.jpg" id="id6.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="364" height="87" alt="[Uncaptioned image]"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x5.jpg" id="id7.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="340" height="85" alt="[Uncaptioned image]"></div>
</div>
</figure>
<figure id="Sx1.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x6.jpg" id="Sx1.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="338" height="106" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x7.jpg" id="Sx1.F6.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="352" height="83" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x8.jpg" id="Sx1.F6.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="358" height="89" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2007.04422/assets/x9.jpg" id="Sx1.F6.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="326" height="90" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="Sx1.F6.2.1" class="ltx_text ltx_font_bold">Implications generated by our module.</span> As seen in the examples, the module can replace the answer value in Logical Equivalence type sometimes. Also, for numbered questions having answer ’0’ and ’yes/no’ questions, the module fails to generate correct implications due to limitations of the rule-based dataset.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2007.04421" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2007.04422" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2007.04422">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2007.04422" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2007.04423" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 11:00:25 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
