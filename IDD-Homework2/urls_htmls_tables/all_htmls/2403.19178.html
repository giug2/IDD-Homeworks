<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.19178] Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning</title><meta property="og:description" content="While centralized servers pose a risk of being a single point of failure, decentralized approaches like blockchain offer a compelling solution by implementing a consensus mechanism among multiple entities. Merging dist…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.19178">

<!--Generated on Fri Apr  5 13:38:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  %\date{Received:␣date␣/␣Accepted:␣date} .-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated learning Decentralization Blockchain Security Privacy">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">∎


</p>
</div>
<span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
<span id="footnotex12" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> Corresponding author. 
<br class="ltx_break"><span id="footnotex13" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">4</span></span></span></span> Equal contribution. 
<br class="ltx_break"><span id="footnotex14" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">5</span></span></span></span> Hithink RoyalFlush Information Network Co. Ltd., Hangzhou, China.
<br class="ltx_break"><span id="footnotex15" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">6</span></span></span></span> Information Science and Electrical Engineering Department, Kyushu University, Fukuoka, Japan.
<br class="ltx_break"><span id="footnotex16" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">7</span></span></span></span> Baidu Inc., Beijing, China.
<br class="ltx_break"><span id="footnotex17" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span> Unicom Digital Tech., Beijing, China.
<br class="ltx_break"><span id="footnotex18" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">9</span></span></span></span> Boston Consulting Group, Beijing, China.
</span></span></span>
<h1 class="ltx_title ltx_title_document">Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ji Liu<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span><span id="footnotex2" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">4</span></span></span></span><span id="footnotex3" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">5</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Chunlu Chen<span id="footnotex4" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">4</span></span></span></span><span id="footnotex5" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">6</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yu Li<span id="footnotex6" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">7</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Lin Sun<span id="footnotex7" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yulun Song<span id="footnotex8" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jingbo Zhou<span id="footnotex9" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">7</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Bo Jing<span id="footnotex10" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">7</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Dejing Dou<span id="footnotex11" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">9</span></span></span></span>
</span></span>
</div>
<div class="ltx_dates">(Accepted: March 28, 2024)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text" style="color:#000000;">While centralized servers pose a risk of being a single point of failure, decentralized approaches like blockchain offer a compelling solution by implementing a consensus mechanism among multiple entities. Merging distributed computing with cryptographic techniques, decentralized technologies introduce a novel computing paradigm. Blockchain ensures secure, transparent, and tamper-proof data management by validating and recording transactions via consensus across network nodes. Federated Learning (FL), as a distributed machine learning framework, enables participants to collaboratively train models while safeguarding data privacy by avoiding direct raw data exchange. Despite the growing interest in decentralized methods, their application in FL remains underexplored. This paper presents a thorough investigation into Blockchain-based FL (BCFL), spotlighting the synergy between blockchain’s security features and FL’s privacy-preserving model training capabilities.</span>
First, we present the taxonomy of BCFL from three aspects, including decentralized, separate networks, and reputation-based architectures.
Then, we summarize the general architecture of BCFL systems, providing a comprehensive perspective on FL architectures informed by blockchain.
Afterward, we analyze the application of BCFL in healthcare, IoT, and other privacy-sensitive areas.
Finally, we identify future research directions of BCFL.

</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Federated learning Decentralization Blockchain Security Privacy
</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">{textblock*}</span>
<p id="p2.2" class="ltx_p">8cm(3cm,15cm) <span id="p2.2.1" class="ltx_text" style="font-size:207%;">To appear in KAIS</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Blockchain is an innovative technology, which fundamentally reshapes transactions and interplays with various entities such as institutions and governments, and verifies authenticity processes. Initially devised for the digital currency Bitcoin, the capabilities of blockchain transcend its initial purpose, providing support for a diverse range of applications, from Peer-to-Peer (P2P) payment services to the management of supply chains. Essentially, a blockchain functions like a traditional ledger, documenting transactions that involve the transfer of money, goods, or secure data. Its structure, making it virtually impossible to alter data without detection by other users, enhances its security. This characteristic shifts verification systems from centralized to decentralized, where the consensus of multiple users facilitates the validation process.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The mechanics of blockchain involve the aggregation and organization of data into blocks, subsequently fortifying these blocks through cryptography. At the core of blockchain security lies a hash function, a cryptographic algorithm that solidifies the connections between blocks. This hash function generates a unique character string for each block, intricately interwoven into the succeeding block, forming a secure chain. Any endeavors to tamper with a previously established block disrupt this chain of hashes, resulting in a mismatch and exposing the attempted modification. The adaptability of blockchain extends beyond tracking commercial transactions; it can effectively store and safeguard sensitive information. Despite its vast potential, this technology is still in its infancy and must overcome various obstacles before achieving widespread adoption. Nevertheless, blockchain signifies a revolutionary shift in how entities and individuals engage, presenting a straightforward and secure mechanism to establish trust for virtually any transaction type.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated Learning (FL) has been a very hot topic in recent years. First, as people pay more attention to data privacy, more and more users are unwilling to share their private data. In addition, various countries have also introduced corresponding laws and regulations to restrict the behavior of data collectors, such as the Cybersecurity Law of the People’s Republic (CLPR) of China <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib105" title="" class="ltx_ref">CCL </a></cite>, the General Data Protection Regulation (GDPR) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib85" title="" class="ltx_ref">GDPR </a></cite>, the California Consumer Privacy Act (CCPA) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">CCPA </a></cite>, and the Consumer Privacy Bill of Rights (CPBR) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib26" title="" class="ltx_ref">Gaff2014 </a></cite>, Internet companies need to be further responsible for user data.FL is a machine learning technique in which people train algorithms on multiple distributed edge devices or servers with local data samples. This approach differs significantly from traditional centralized machine learning techniques, which upload all local datasets to a single server, while more classic decentralized approaches typically assume that the local data samples are all the same Distribution. The emergence of FL protects the privacy of user data to a certain extent, and achieves the effect of “available and invisible” <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib62" title="" class="ltx_ref">liu2022distributed </a></cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The fusion of blockchain and FL amalgamates the most advantageous features of both technologies, yielding a resilient and efficient system characterized by heightened data privacy and security. The decentralized nature of blockchain ensures equitable rights for all network nodes, mitigating the risks associated with centralized systems and protecting against data breaches. Its immutable and traceable nature provides inherent data integrity, deterring malicious manipulation and fostering trust among participants. Integrating blockchain into FL promotes a secure and privacy-preserving distributed learning environment, where sensitive data remains on edge devices while ensuring system security and stability. This symbiotic relationship between blockchain and FL paves the way for the development of robust and reliable decentralized machine learning systems, with broad applications in various domains.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Currently, there are numerous researchers exploring BlockChain-based FL (BCFL) architectures. A comprehensive review <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib6" title="" class="ltx_ref">berdik2021survey </a></cite> emphasizes the potential and complexities of blockchain as a service within today’s information systems, while highlighting the implications of blockchain in various industries. The integration of blockchain with cloud and edge computing paradigms is underscored as being of paramount importance.
The review <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib95" title="" class="ltx_ref">qammar2023securing </a></cite> explores blockchain’s potential to enhance FL by eliminating the need for centralized servers, thus solving problems like private information disclosure and high communication costs.
The concept of BCFL is dissected in a study <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib49" title="" class="ltx_ref">li2022blockchain </a></cite>, with a focus on the unique challenges, structural design, platforms, incentive mechanisms, and applications it presents. A decentralized approach to FL, involving the use of Swarm Learning (SL), is meticulously explored in another investigation <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib29" title="" class="ltx_ref">han2022demystifying </a></cite>. Here, a permissioned blockchain is introduced to ensure secure member onboarding and dynamic leader election, thereby facilitating highly decentralized deep learning.
A blockchain-based solution aimed at enhancing accountability and fairness in FL systems is presented in a different study <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib68" title="" class="ltx_ref">lo2021blockchain </a></cite>. This approach includes a smart contract-based data-model provenance registry and a weighted fair data sampler algorithm. The introduction of SPDL, a decentralized learning scheme integrating blockchain, Byzantine Fault-Tolerant (BFT) consensus, BFT Gradients Aggregation Rule (GAR), and differential privacy, is discussed in another work <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib121" title="" class="ltx_ref">xu2022spdl </a></cite>. This method ensures efficient machine learning while safeguarding data privacy, Byzantine fault tolerance, transparency, and traceability.
Lastly, the Blockchain Assisted Decentralized Federated Learning (BLADE-FL) framework <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib75" title="" class="ltx_ref">ma2020federated </a></cite> is brought forward as a fully decentralized framework, wherein both training and mining responsibilities are assigned to full nodes.
<span id="S1.p5.1.1" class="ltx_text" style="color:#000000;">Numerous studies have explored the architectures of BCFL, shedding light on its potential benefits and inherent challenges. Diverging from earlier efforts that have investigated distinct aspects of BCFL, our paper’s value is in amalgamating these diverse methodologies. We aim to offer a unified, exhaustive analysis of BCFL systems. This synthesis not only illuminates the current landscape of BCFL but also lays the groundwork for future advancements in this area. By developing a generic BCFL system architecture that encompasses essential components such as the infrastructure, network, communication, algorithms, blockchain consensus, and application layers, we provide a foundational framework for both evaluating existing FL systems and guiding the development of forthcoming BCFL solutions. Our comprehensive approach aims to catalyze innovation within BCFL by addressing gaps in existing research and proposing new directions for exploration.</span>
In this paper, we conduct an extensive analysis of BCFL systems. The essence of our work lies in synthesizing existing methodologies and outlining future research directions. A significant contribution of this research is the development of a generic BCFL system architecture. This architecture, structured into key layers including infrastructure, network, communication, algorithms, blockchain consensus, and application, serves as both an evaluative tool for existing FL systems and a foundational guide for the development of future BCFL systems. Moreover, we delve into the diverse applications of BCFL across various sectors, highlighting its versatility and potential for innovation. Our study aims to provide a comprehensive perspective on BCFL systems, while providing the basis for future research in the field of BCFL systems.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The rest of the manuscript is organized as follows. In Section <a href="#S2" title="2 An Overview of Blockchain and Federated Learning ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we introduce the basic concepts of blockchain and FL and discuss their relationship. In Section <a href="#S3" title="3 Blockchain-based Federated Learning: A Taxonomy and Review ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we provide detailed information on the architecture of FL systems, including the infrastructure layer, network layer, communication layer, algorithm layer, Blockchain consensus, and application layer. In addition, we discuss the current state of research and challenges related to each topic. Finally, section <a href="#S4" title="4 Challenges and Open Research Directions ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and section <a href="#S5" title="5 Conclusion ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> discuss the future directions and concludes.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>An Overview of Blockchain and Federated Learning</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we introduce the basic concepts of blockchain and FL. Then, we discuss the privacy preserving in FL. And the necessity of integrating blockchain and FL.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Blockchain and Distributed System</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text" style="color:#000000;">Distributed systems are networks of computers or nodes that work together to form a unified system, characterized by decentralization, consensus, fault tolerance, and scalability.</span> Decentralization distributes control and decision-making across various nodes, thereby bolstering fault tolerance, scalability, and resilience. Consensus mechanisms protect the system by ensuring that all nodes consistently concur on the state of the system, even under adverse conditions such as failure or malicious actions. Fault tolerance denotes the ability of a distributed system to handle the malfunction of an individual node or component without compromising the functionality of the entire system. This resilience is achieved through strategies such as redundancy, replication, and comprehensive error-handling mechanisms. Scalability refers to the system’s capability to horizontally scale by incorporating additional nodes to accommodate increasing workloads and expanding user bases.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2403.19178/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="234" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Blockchain Network and Transaction Blocks.</span></figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Blockchain is a special distributed ledger technology that ensures a secure <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref">kolb2020core </a>; <a href="#bib.bib39" title="" class="ltx_ref">kalodner2020blocksci </a></cite>, immutable record of transactions or data. Blockchain functions on top of a distributed system and incorporates principles such as cryptography, transparency and immutability, consensus mechanisms, smart contracts, and trust and security, as shown in Figure <a href="#S2.F1" title="Figure 1 ‣ 2.1 Blockchain and Distributed System ‣ 2 An Overview of Blockchain and Federated Learning ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Blockchain employs cryptography to safeguard the integrity and security of data, authenticate transactions, and shield information stored on the blockchain through hash functions, digital signatures, and encryption <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib59" title="" class="ltx_ref">liang2020secure </a></cite>. Each transaction recorded on the blockchain is transparent, visible to all network participants, and virtually indelible once added to the blockchain - assuring immutability and traceability. Through a consensus mechanism, blockchain facilitates agreement among distributed nodes on the validity and sequencing of transactions <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib28" title="" class="ltx_ref">garay2020sok </a>; <a href="#bib.bib114" title="" class="ltx_ref">wang2019survey </a></cite>. Supported by most blockchain platforms, smart contracts are self-executing agreements with predefined rules inscribed on the blockchain. These smart contracts autonomously carry out transactions and enforce mutually agreed terms, thereby negating the need for intermediaries. Blockchain technology bolsters trust by eliminating central institutions or intermediaries and makes it challenging for malign actors to tamper with data, courtesy of its distributed features and cryptographic security measures <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib73" title="" class="ltx_ref">lugan2019secure </a>; <a href="#bib.bib17" title="" class="ltx_ref">chen2018machine </a></cite>. In addition, researchers have focused on improving the throughput of blockchain systems <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib92" title="" class="ltx_ref">peng2020falcondb </a></cite>. A method involving the construction of a blockchain system with multiple subchains is outlined in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib126" title="" class="ltx_ref">yu2020ohie </a></cite>. This system facilitates simultaneous mining operations across all subchains, thereby ensuring security, liveliness, and high throughput in the blockchain protocol.
In another approach, the Red Belly Blockchain Consensus (RBBC) is introduced <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib21" title="" class="ltx_ref">crain2021red </a></cite>. This consensus protocol aims to bolster security and achieve high throughput, particularly in scenarios involving a large number of consensus nodes.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">The blockchain system is fundamentally a distributed system, and the core challenges of distributed systems revolve around consistency and consensus. Within distributed systems, the terms synchronous and asynchronous carry specific implications. Synchronization entails that each node in the system has an upper limit on clock error, and message transmission must be completed within a specified time; otherwise, it is deemed a failure. Simultaneously, the processing time for each node to handle the message is predetermined. In synchronous systems, the identification of lost messages is relatively straightforward. On the other hand, asynchronous signifies that each node in the system may have a significant clock difference, and the time taken to process a message at each point can vary arbitrarily, making it challenging to determine where a message has not received a response.
In general, blockchain technology is mainly divided into two types: permissionless, exemplified by Bitcoin, and permissioned, with Fabric being a prominent example. In permissionless systems, users can access the network and blocks anonymously without registration. The network is open for anyone to join or exit freely. The public chain is a decentralized blockchain, ensuring transaction security and immutability through cryptographic (asymmetric encryption) algorithms and establishing mutual trust in a network environment with consensus mechanisms. Common consensus mechanisms in public chains include Proof of Work (POW) and Proof of Stake (POS). In contrast, in permissioned blockchains, the prevalent consensus protocols are Kafka, Raft, and PBFT.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Blockchain’s versatility is demonstrated through its applications in sectors like healthcare, where it enhances security, privacy, and interoperability in Electronic Health Record (EHR) systems <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib103" title="" class="ltx_ref">shi2020applications </a></cite>. Additionally, blockchain has been studied in the context of cloud computing, addressing security and privacy challenges when outsourcing computational tasks to cloud service providers <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib101" title="" class="ltx_ref">shan2018practical </a></cite>.
Additionally, Unmanned Aerial Vehicles (UAVs) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib93" title="" class="ltx_ref">pokhrel2021blockchain </a></cite>, smart city <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib23" title="" class="ltx_ref">esposito2021blockchain </a></cite>, cloud computing <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib27" title="" class="ltx_ref">gai2020blockchain </a></cite>,edge computing <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib120" title="" class="ltx_ref">xiong2018mobile </a></cite>, Internet of Vehicles (IoV) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib41" title="" class="ltx_ref">kang2019toward </a></cite>, these examples demonstrate the broad range of applications for blockchain technology and its ability to address diverse challenges across different industries.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Privacy Preserving in Federated Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">With the development of database technology and network technology, all kinds of industries have accumulated a large amount of useful data. How to extract valuable knowledge for decision-making from these data has become a top priority. Positioned as a potent data analysis tool, data mining excels in uncovering latent patterns and regularities within data, presenting findings in the form of rules, clusters, decision trees, dependency networks, or other knowledge representations. These insights find applications in diverse areas such as business decision-making, scientific research, and medical investigations.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">FL initializes model parameters for all clients via a central server, as shown in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.2 Privacy Preserving in Federated Learning ‣ 2 An Overview of Blockchain and Federated Learning ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The client trains the local model with the initialized model parameters and shares the parameters trained by the local model to the central server. The central server aggregates the parameters of the local model and sends the updated model and parameters to each client. Repeat the above steps until the model converges.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2403.19178/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Federated Learning architecture and its applications.</span></figcaption>
</figure>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">FL is divided into centralized FL and decentralized FL according to the network topology. According to data availability, it can be divided into cross silo FL and cross device FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib53" title="" class="ltx_ref">li2021survey </a></cite>. In different data partition scenarios, FL can be divided into horizontal FL, vertical FL and federated transfer learning. Among them, the optimization algorithms of FL include fedavg, smc-avg, fedprox etc.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Data Heterogeneity:</span> Data heterogeneity is a significant challenge in FL due to the decentralized nature of the approach. In FL, data is distributed across multiple devices or entities, each with its unique characteristics, formats, and representations. Firstly, feature heterogeneity arises when participating devices have different sets of features or attributes available for training, making the aggregation and alignment of models challenging. Secondly, data distribution heterogeneity occurs due to variations in user populations, geographical locations, or data collection practices among participating devices, potentially introducing biases into the trained model. Lastly, data format heterogeneity poses challenges in FL as data from different sources or platforms may have varying formats, representations, or structures.</p>
</div>
<div id="S2.I1.i1.p2" class="ltx_para">
<p id="S2.I1.i1.p2.1" class="ltx_p"><span id="S2.I1.i1.p2.1.1" class="ltx_text" style="color:#000000;">To address these heterogeneity challenges, researchers employ various techniques <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib124" title="" class="ltx_ref">ye2023heterogeneous </a></cite>, including model architecture adjustments and feature engineering to harmonize feature spaces across devices. They utilize meta-learning and domain adaptation to manage data distribution variations and explore models with intermediate representations or multi-format designs for data format heterogeneity. These strategies facilitate effective data use in federated learning, enhancing model robustness and efficiency across diverse environments.</span></p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Privacy and Security:</span>
FL is a decentralized approach to machine learning where multiple devices or entities collaboratively train a shared model without sharing their raw data. While FL offers numerous advantages, such as preserving data privacy and reducing communication costs, it also raises important privacy concerns <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib125" title="" class="ltx_ref">yin2021comprehensive </a></cite>.</p>
</div>
<div id="S2.I1.i2.p2" class="ltx_para">
<ul id="S2.I1.i2.I1" class="ltx_itemize">
<li id="S2.I1.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i2.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Data Leakage:</span> During the training process, models are shared among participating devices or entities. There is a risk of unintentional data leakage if the models contain sensitive information about the training data. Adversaries could potentially reconstruct or infer sensitive data from the shared models.</p>
</div>
</li>
<li id="S2.I1.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i2.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Membership Inference Attacks:</span> In a membership inference attack, adversaries aim to determine whether a specific data point was part of the training dataset. By analyzing the model’s responses to queries, adversaries can infer the presence or absence of particular data points, potentially revealing sensitive information about individuals.</p>
</div>
</li>
<li id="S2.I1.i2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i2.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Model Poisoning Attacks:</span> In a model poisoning attack, adversaries inject malicious data or manipulate their local updates to poison the shared model. This can lead to the model incorporating biased or incorrect information, compromising the privacy of other participants’ data.</p>
</div>
</li>
</ul>
</div>
<div id="S2.I1.i2.p3" class="ltx_para">
<p id="S2.I1.i2.p3.1" class="ltx_p"><span id="S2.I1.i2.p3.1.1" class="ltx_text" style="color:#000000;">To mitigate these threats, techniques such as Differential Privacy (DP), which adds noise to the data or model updates to obscure individual contributions, and Homomorphic Encryption (HE), allowing computations on encrypted data, are applied. These methods ensure that FL remains resilient against attacks while maintaining data privacy and model integrity.</span>
The focus of many research endeavors has been on bolstering security and enhancing privacy protection within the realm of FL. For instance, a scalable production system has been outlined in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">bonawitz2019towards </a></cite>, which is tailored for the mobile device domain, tackling challenges related to device availability, unreliable connections, cross-device coordination, and limited resources.
A different framework is introduced in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib54" title="" class="ltx_ref">li2021ditto </a></cite>, which employs regularization terms to amplify the fairness and robustness of personalized FL. In <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib109" title="" class="ltx_ref">truex2019hybrid </a></cite>, differential privacy and homomorphic encryption have been incorporated into FL, aiming to diminish privacy noise and enhance model accuracy via secure multi-party computation.
The TrustFL scheme <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib134" title="" class="ltx_ref">zhang2020enabling </a></cite> leverages Trusted Execution Environments (TEE) to secure the trustworthy execution of training tasks, offering high-confidence guarantees while preserving efficiency. These various methodologies collectively contribute to enhancing the security and privacy of FL.
Secure model aggregation and performance optimization also emerge as crucial areas of research. A distributed framework enabling joint association and resource allocation is discussed in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib44" title="" class="ltx_ref">khan2021dispersed </a></cite>, paving the way for multiple groups to learn a global model. In addition, a model-contrastive FL framework is proposed <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib52" title="" class="ltx_ref">li2021model </a></cite>, which improves local training performance by accounting for the similarity of model representations.
The framework proposed in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib89" title="" class="ltx_ref">pandey2020crowdsourcing </a></cite> coordinates multiple mobile clients via an MEC server for parameter aggregation and global model updates. Finally, a Bayesian nonparametric neural network framework for FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib127" title="" class="ltx_ref">yurochkin2019bayesian </a></cite>, where the global model is constructed using the Probabilistic Federated Neural Matching (PFNM) method to tackle communication issues. Each of these approaches contributes uniquely to the secure model aggregation and performance optimization in FL.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Traceability and Accountability:</span>
Traceability and accountability are critical considerations in FL to ensure transparency, integrity, and responsible use of data.</p>
</div>
<div id="S2.I1.i3.p2" class="ltx_para">
<ul id="S2.I1.i3.I1" class="ltx_itemize">
<li id="S2.I1.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i3.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i3.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i3.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Traceability</span> involves model auditing, which tracks and audits the models trained in FL by recording metadata such as model architecture, hyperparameters, and data sources. Data provenance is another aspect of traceability, enabling the tracking of the origin and history of the data used for training, ensuring authenticity, and assessing potential biases. These traceability measures enhance transparency and build trust among participants.</p>
</div>
</li>
<li id="S2.I1.i3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I1.i3.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S2.I1.i3.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i3.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Accountability</span> in FL encompasses participant accountability, where participants are expected to adhere to agreed-upon protocols, privacy measures, and security practices. Participants should be held accountable for their actions to maintain the integrity of the FL process. Moreover, maintaining security and trust in FL systems requires participants to implement appropriate security measures, protect data confidentiality, and prevent unauthorized access or malicious activities.</p>
</div>
</li>
</ul>
</div>
<div id="S2.I1.i3.p3" class="ltx_para">
<p id="S2.I1.i3.p3.1" class="ltx_p">However, traceability and accountability in FL face several challenges. The decentralized structure of FL introduces complexity in coordinating and establishing consensus on traceability standards and accountability mechanisms across multiple participants. Ensuring traceability and accountability while preserving privacy adds another layer of complexity, as privacy-preserving techniques must balance providing traceability information while protecting sensitive participant data. Additionally, data fragmentation caused by the distribution of data across different participants, poses challenges in tracing the origin and lineage of data.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>The Necessity of Integrating Blockchain and Federated Learning</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Combining blockchain and FL has the potential to offer several advantages and address key challenges in both domains:</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Incentive Mechanisms:</span> The cryptocurrency or token system native to blockchain can facilitate the establishment of incentive mechanisms for participants in FL. In traditional FL, due to economic rationality, many clients are reluctant to share their valuable data. By rewarding data contributors, model validators, and other participants with tokens, blockchain can incentivize active participation, data sharing, and model improvement <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib67" title="" class="ltx_ref">liu2020fedcoin </a></cite>.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Enhanced Data Privacy and Security:</span> The decentralized and immutable nature of blockchain offers a secure and transparent framework for data sharing and storage. The traditional FL framework heavily relies on a single central server and may fall apart if such a server behaves maliciously. At the same time, the existing design is vulnerable to the malicious clients that might upload poisonous models to attack the FL network. <span id="S2.I2.i2.p1.1.2" class="ltx_text" style="color:#000000;">Incorporating the cryptographic methods of blockchain into Federated Learning (FL) significantly bolsters data privacy and security. Blockchain’s decentralized and immutable nature ensures that data remains encrypted and anonymous, safeguarding against the vulnerabilities of centralized servers and malicious model uploads by clients. By leveraging blockchain, FL can achieve a transparent framework for data sharing and storage, enabling participants to validate the integrity and authenticity of shared models without exposing sensitive information <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib81" title="" class="ltx_ref">moudoud2021towards </a>; <a href="#bib.bib42" title="" class="ltx_ref">kang2020reliable </a>; <a href="#bib.bib58" title="" class="ltx_ref">li2021local </a></cite>. This integration enhances trust and reliability within the FL ecosystem.</span></p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Trust and Transparency:</span> The transparency and auditability inherent in blockchain can tackle trust issues in FL. It enables participants to track the history and provenance of data, models, and computations. This transparency fosters trust among participants, as they can verify the fairness and reliability of the FL process <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib122" title="" class="ltx_ref">yang2023explainable </a></cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">The application of Blockchain in FL is exemplified by various frameworks and systems designed to enhance privacy, accuracy, and trust:</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p">BML-ES <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib107" title="" class="ltx_ref">tian2021blockchain </a></cite>: A blockchain-centric machine learning framework for Industrial Internet of Things (IIoT) edge services, utilizing smart contracts for aggregation strategies and employing the SM2 public key cryptosystem to secure privacy and improve model accuracy.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p">TrustFed <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib111" title="" class="ltx_ref">ur2021trustfed </a></cite>: Integrates blockchain in cross-device FL systems to prevent model poisoning, ensure fair training, and maintain the reputation of participants. Smart contracts are used to manage reputations and exclude malicious actors, ensuring a dependable training environment.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p">State Channels for Trust Supervision <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib130" title="" class="ltx_ref">zhang2021federated </a></cite>: A mechanism that uses blockchain and FL to create a trusted environment for distributed data sharing. It employs state channels to establish secure sandboxes for FL tasks, ensuring integrity and supervision throughout the process.</p>
</div>
</li>
<li id="S2.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i4.p1" class="ltx_para">
<p id="S2.I3.i4.p1.1" class="ltx_p">Proof of Federated Training (PoFT) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref">chakraborty2022proof </a></cite>: A framework enabling verifiable model training across blockchain networks, enhancing transparency and trust in the collaborative training process.</p>
</div>
</li>
<li id="S2.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i5.p1" class="ltx_para">
<p id="S2.I3.i5.p1.1" class="ltx_p">Decentralized Model Training and Gradient Aggregation <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib137" title="" class="ltx_ref">zhao2021blockchain </a></cite>: Proposes a blockchain-based architecture for secure model training and introduces a gradient aggregation method aimed at enhancing model accuracy, privacy, and performance.</p>
</div>
</li>
<li id="S2.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I3.i6.p1" class="ltx_para">
<p id="S2.I3.i6.p1.1" class="ltx_p">Blockchain-in-the-loop FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib80" title="" class="ltx_ref">mothukuri2021fabricfl </a></cite>: Merges traditional FL with Hyperledger Fabric, incorporating gamification to enhance participation and efficiency.</p>
</div>
</li>
</ul>
<p id="S2.SS3.p2.2" class="ltx_p"><span id="S2.SS3.p2.2.1" class="ltx_text" style="color:#000000;">Smart contracts within these systems play a pivotal role in ensuring fairness and dependability by automating enforcement of agreements and conditions without the need for intermediaries. This automation ensures that all parties adhere to the predefined rules, significantly reducing the risk of biased or malicious behavior. As a result, smart contracts contribute to creating a transparent, secure, and trustworthy environment for FL, facilitating its application in diverse fields such as smart cities <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib139" title="" class="ltx_ref">zheng2022applications </a></cite>, vehicular communication networking <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib94" title="" class="ltx_ref">pokhrel2020decentralized </a></cite>, edge FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib32" title="" class="ltx_ref">hu2021blockchainB </a></cite>, precision medicine <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib118" title="" class="ltx_ref">warnat2021swarm </a>; <a href="#bib.bib116" title="" class="ltx_ref">wang2021blockchain </a></cite>, thereby enhancing privacy, security, and trust in FL ecosystems <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib88" title="" class="ltx_ref">Ouyang2023Artificial </a></cite>.</span></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Blockchain-based Federated Learning: A Taxonomy and Review</h2>

<figure id="S3.F3" class="ltx_figure"><img src="/html/2403.19178/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Blockchain-based Federated Learning Architecture.</span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">From the architecture of the FL in figure <a href="#S2.F2" title="Figure 2 ‣ 2.2 Privacy Preserving in Federated Learning ‣ 2 An Overview of Blockchain and Federated Learning ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we can realize that the aggregator server suffers from the single point of failure. However, with the adaptation of blockchain technology into FL, some security assumptions for FL need to be declared in advance. First, aggregator may behave dishonestly or external attacks could influence the FL result. Therefore, numerous works have been done by combining blockchain and FL technology in order to prevent malicious or honest-but-curious aggregator <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref">chen2018machine </a></cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Usually, the architecture of this kind of BCFL is shown as figure <a href="#S3.F3" title="Figure 3 ‣ 3 Blockchain-based Federated Learning: A Taxonomy and Review ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. From a bottom-up perspective, the overall architecture is divided into five layers. The bottom layer of the architecture is infrastructure layer which contains various kind of storage and computation resource. We will discuss and a taxonomy will be provided in section 3.1. Section 3.2 will discuss the network layer of blockchain based FL, which mainly includes P2P, random leader election etc. There are mainly two ways in communication layer which contains message and RPC protocol. In the algorithm layer, privacy preserving methods and incentive mechanism are provided in this layer. Then the upmost layer is related application. Besides, the blockchain consensus plays a vital role in the whole architecture.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Architectures of Blockchain-based Federated Learning</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text" style="color:#000000;">BCFL Systems are categorized into three distinct architectures based on their operational dynamics <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib116" title="" class="ltx_ref">wang2021blockchain </a>; <a href="#bib.bib141" title="" class="ltx_ref">zhu2023blockchain </a></cite>: fully coupled, where clients double as both training and blockchain nodes, offering decentralization but requiring high device performance; flexibly coupled, which separates blockchain and FL operations to ease network communication, achieved through committee selection or smart contracts; and loosely coupled, prioritizing reputation to gauge participant reliability, focusing mainly on model update validation and reputation management on the ledger.</span></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Infrastructure Layer</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text" style="color:#000000;">The BCFL architecture incorporates FL into blockchain in two primary configurations: the L1 and L2 layer architectures. The L1 layer directly integrates FL with blockchain, offering a decentralized, P2P framework where peers join freely, supported by consensus mechanisms for system reliability <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib102" title="" class="ltx_ref">shayan2020biscotti </a></cite>. The L2 layer, alternatively, builds FL atop blockchain nodes, emphasizing layered data processing and model training <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib7" title="" class="ltx_ref">bhattacharya2019bindaas </a></cite>.</span></p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text" style="color:#000000;">At its core, the BCFL infrastructure unites data storage and computational resources. It adopts a decentralized storage model, with privacy ensured through advanced cryptographic methods like SMPC and homomorphic encryption. These technologies facilitate secure, private data sharing and model aggregation, while blockchain’s auditability improves transparency and trust. Computational demands are met locally, utilizing Central Processing Unit (CPUs), GPUs <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref">2012cuda </a></cite>, and Tensor Processing Units (TPUs) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib38" title="" class="ltx_ref">2017tpu </a></cite>. The system addresses device heterogeneity <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib14" title="" class="ltx_ref">che2022federated </a></cite> and computational limits through lightweight architectures, model compression <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib35" title="" class="ltx_ref">jia2023efficient </a></cite>, and federated distillation, optimizing performance and resource allocation across varied devices.</span></p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Network Layer</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The network structure of blockchain inherits the general topology structure of computer communication network, and can be divided into three categories: centralized network, multi-centralized network and decentralized network as shown in figure <a href="#S3.F4" title="Figure 4 ‣ 3.3 Network Layer ‣ 3 Blockchain-based Federated Learning: A Taxonomy and Review ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text" style="color:#000000;">Centralized Networks: In a centralized network setup as shown in figure <a href="#S3.F4" title="Figure 4 ‣ 3.3 Network Layer ‣ 3 Blockchain-based Federated Learning: A Taxonomy and Review ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(a), all communications and transactions are routed through a central node. This structure, often seen in permissioned blockchain systems, can offer streamlined efficiency and quicker consensus due to the singular control point. However, it also presents a significant security risk; the central node becomes a prime target for attacks, potentially compromising the entire network’s integrity and privacy. For BCFL, this setup could limit the system’s resilience and increase vulnerability to data breaches and single points of failure.</span></p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text" style="color:#000000;">Multi-Centralized Networks: Multi-centralized networks as shown in figure <a href="#S3.F4" title="Figure 4 ‣ 3.3 Network Layer ‣ 3 Blockchain-based Federated Learning: A Taxonomy and Review ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(b), or federated blockchains, introduce several central nodes instead of just one. This setup is typically employed to balance control among multiple organizations or parties, enhancing collaboration while still maintaining a level of centralized governance. While this structure improves security and reduces the risk associated with a single point of failure, it may still face challenges in achieving the same level of decentralization and resistance to censorship or collusion as fully decentralized networks. For BCFL systems, multi-centralized networks can offer improved security and operational efficiency but may still encounter scalability limits and centralized control issues.</span></p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text" style="color:#000000;">Decentralized Networks: Decentralized networks as shown in figure <a href="#S3.F4" title="Figure 4 ‣ 3.3 Network Layer ‣ 3 Blockchain-based Federated Learning: A Taxonomy and Review ‣ Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(c), epitomized by permissionless blockchains like Bitcoin and Ethereum, distribute data verification and transaction processing across a wide array of nodes. This P2P network structure ensures no single point of control or failure, significantly enhancing security and data integrity. Each node operates with equal status, creating a robust system resistant to censorship, tampering, and attacks. For BCFL, decentralized networks provide a secure and transparent environment for data sharing and model training, although they may face challenges in terms of scalability and consensus speed due to the distributed nature of decision-making.</span></p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text" style="color:#000000;">In summary, the choice of network setup in BCFL systems profoundly impacts their performance and security. Centralized networks may offer operational efficiency but pose higher security risks. Multi-centralized networks provide a balance with improved security but still retain some centralized control aspects. Decentralized networks, while offering the highest level of security and data integrity, might struggle with scalability and slower consensus mechanisms.</span></p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.19178/assets/figures/centralized.png" id="S3.F4.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="523" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">centralized</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.19178/assets/figures/multi-centralized.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="476" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">multi-centralized</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.19178/assets/figures/decentralized.png" id="S3.F4.sf3.g1" class="ltx_graphics ltx_img_square" width="598" height="593" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F4.sf3.3.2" class="ltx_text" style="font-size:90%;">decentralized</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">
Blockchain network structure categories
</span></figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Communication Layer</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The communication layer plays a pivotal role in BCFL systems, orchestrating data transfer and message exchanges among participants to facilitate the collaborative learning process. It is tasked with transmitting model updates, aggregated results, and coordination directives efficiently and securely across the network of devices or servers engaged in FL.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">The communication layer employs various protocols and mechanisms to ensure efficient and secure data exchange.</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">Encryption Techniques: Advanced encryption methods are utilized to encrypt data before transmission, safeguarding against unauthorized access and ensuring that data privacy is maintained.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">Network Protocols: Reliable and efficient network protocols are employed to manage the delivery of messages. These protocols are designed to ensure that data packets reach their intended destinations reliably and in order, even in the face of network disruptions or congestion.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p">Synchronization Mechanisms: Given the distributed nature of BCFL systems, synchronization mechanisms are crucial for coordinating communication among participants <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib66" title="" class="ltx_ref">liu2023distributed </a></cite>. These mechanisms ensure that model updates are shared in a timely manner and help in managing the asynchronous nature of data transmissions, aligning the updates from various participants.</p>
</div>
</li>
<li id="S3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i4.p1" class="ltx_para">
<p id="S3.I2.i4.p1.1" class="ltx_p">Decentralized Communication Frameworks: Employing decentralized frameworks, such as peer-to-peer (P2P) networks or blockchain, facilitates direct communication between participants, eliminating the need for centralized intermediaries. This approach not only enhances the system’s resilience and decentralization but also reduces potential bottlenecks and points of failure. For example, the Blockchain Assisted Decentralized FL (BLADE-FL) framework is proposed in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib75" title="" class="ltx_ref">ma2020federated </a></cite>. This fully decentralized framework assigns responsibility for both training and mining to full nodes. These frameworks can enhance the decentralization and resilience of the FL system.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text" style="color:#000000;">However, BCFL systems face significant challenges such as latency and limited bandwidth, which are addressed through data compression techniques, to minimize the size of data transmissions and enhance exchange speeds. Adaptive network routing and congestion control algorithms optimize data flows, reducing latency and improving communication efficiency. Additionally, batch processing and caching are employed to lower the frequency and volume of data transfers, mitigating the impact of network constraints. These strategies ensure the communication layer in BCFL systems facilitates secure, efficient, and resilient data exchange, overcoming the hurdles of distributed learning environments and promoting seamless collaboration among network participants.</span></p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Algorithm Layer</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">In the algorithm layer of BCFL, there are four key aspects to consider: Aggregation algorithms, security algorithms, optimization algorithms, and incentive algorithms.</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p"><span id="S3.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Aggregation Algorithms:</span> These algorithms primarily address how to effectively aggregate local models from different participants to form a global model. The most common algorithm is FedAvg <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib77" title="" class="ltx_ref">mcmahan2017communication </a></cite>, where participants upload the weights of their local models to the blockchain network in each round of training. The global model is then acquired by calculating the average of these weights through smart contracts. Additionally, there are more sophisticated aggregation algorithms, such as FedProx <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib55" title="" class="ltx_ref">li2020federated </a></cite>, SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib43" title="" class="ltx_ref">karimireddy2020scaffold </a></cite>, FedPD <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib135" title="" class="ltx_ref">Zhang2020FedPD </a></cite>, and FedBN <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib56" title="" class="ltx_ref">li2021fedbn </a></cite>.
In addition, by constructing an asynchronous FL system <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib61" title="" class="ltx_ref">liu2023aedfl </a>; <a href="#bib.bib63" title="" class="ltx_ref">liu2023fedasmu </a></cite>, it is possible to address the security challenges posed by centralized models, achieving privacy, fault tolerance, and reliable data sharing <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib113" title="" class="ltx_ref">wang2022asynchronous </a></cite>. Based on this architecture, a FL asynchronous aggregation protocol based on permissioned blockchain is proposed that can effectively alleviate the synchronous FL algorithm <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib13" title="" class="ltx_ref">che2023federated </a>; <a href="#bib.bib64" title="" class="ltx_ref">liu2022multi </a>; <a href="#bib.bib37" title="" class="ltx_ref">jin2022accelerated </a>; <a href="#bib.bib140" title="" class="ltx_ref">zhou2022efficient </a></cite> by integrating the learned model into the blockchain and performing two-order aggregation calculations.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p"><span id="S3.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Security Algorithms:</span> These algorithms are dedicated to conducting model training and aggregation while preserving the privacy of the participants. The most common methods employ encryption technologies like homomorphic encryption and secure multi-party computation to ensure the weights of the participants’ models are not leaked during the upload and aggregation process. Some methods leverage characteristics of blockchain, such as decentralization and immutability, to enhance the system’s resistance against attacks.</p>
</div>
<div id="S3.I3.i2.p2" class="ltx_para">
<ul id="S3.I3.i2.I1" class="ltx_itemize">
<li id="S3.I3.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i2.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I3.i2.I1.i1.p1" class="ltx_para">
<p id="S3.I3.i2.I1.i1.p1.1" class="ltx_p"><span id="S3.I3.i2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Secure Multi-Party Computation (SMPC):</span>
Secure Multi-Party Computation (SMPC) is a computational model for protecting data privacy, allowing multiple parties to compute without disclosing their private data. In SMPC, each party holds a portion of private data, and computations can be performed on encrypted data to maintain privacy.</p>
</div>
<div id="S3.I3.i2.I1.i1.p2" class="ltx_para">
<p id="S3.I3.i2.I1.i1.p2.1" class="ltx_p">In SMPC, parties communicate and interact via protocols, collectively calculating the final result without having to directly expose their private data. SMPC often involves the use of encryption techniques, cryptographic protocols, and distributed algorithms to ensure data privacy and security. During computation, parties can use technologies such as homomorphic encryption, secret sharing, zero-knowledge proofs, and secure multi-party computation to ensure the security of the computation process and results.</p>
</div>
</li>
<li id="S3.I3.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i2.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I3.i2.I1.i2.p1" class="ltx_para">
<p id="S3.I3.i2.I1.i2.p1.1" class="ltx_p"><span id="S3.I3.i2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Homomorphic Encryption (HE):</span>
HE is an encryption algorithm that satisfies the properties of homomorphic operations on ciphertexts. That is, after the data undergoes homomorphic encryption, a specific calculation is performed on the ciphertext, and the result of the ciphertext calculation, after corresponding homomorphic decryption, is equivalent to the same calculation performed directly on the plaintext data. This realizes a state of "computable but invisible" for the data. By using homomorphic encryption technology, computations can be carried out on ciphertexts without the need for a key, which not only reduces communication costs but also balances the computational costs among all parties.</p>
</div>
</li>
<li id="S3.I3.i2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i2.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I3.i2.I1.i3.p1" class="ltx_para">
<p id="S3.I3.i2.I1.i3.p1.1" class="ltx_p"><span id="S3.I3.i2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Differential Privacy (DP):</span>
Differential privacy is a technology that protects the underlying user privacy information in data by adding disruptive noise. The principle ensures that even if an attacker has mastered all other information except for one piece, they still cannot infer that piece of information. The most common method is to add noise conforming to a certain distribution to the result, randomizing the query result. The main issue to address in differential privacy is data utility. Since it is necessary to incorporate randomness into the query result, it could potentially lead to a decrease in data usability <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib58" title="" class="ltx_ref">li2021local </a></cite>.</p>
</div>
</li>
<li id="S3.I3.i2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i2.I1.i4.1.1.1" class="ltx_text ltx_font_bold">–</span></span> </li>
</ul>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p"><span id="S3.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Optimization Algorithms:</span> These algorithms aim to optimize the performance of FL, such as reducing the number of training rounds, communication overhead, and enhancing model accuracy. The most common methods include gradient compression and gradient pruning to reduce communication overhead. Other techniques utilize asynchronous and local updates to decrease the number of training rounds.</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p id="S3.I3.i4.p1.1" class="ltx_p"><span id="S3.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">Incentive Algorithms:</span> These algorithms consider how to motivate participants to join in FL and distribute incentives fairly. Although FL has shown great advantages in enabling collaborative learning while protecting data privacy, it still faces an open challenge of incentivizing people to join the FL by contributing their computation power and data. A Deep Reinforcement Learning (DRL) based incentive mechanism as a solution addresses unique challenges of unshared information and contribution evaluation difficulties in FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib129" title="" class="ltx_ref">zhan2020learning </a></cite>. Efficiency of this mechanism is demonstrated via numerical experiments, compared with baseline approaches.
On the other hand, cross-disciplinary areas such as economics and game theory are also discussed in the context of designing incentive mechanisms for FL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib110" title="" class="ltx_ref">tu2022incentive </a></cite>.
The paper elucidates various economic and game models, aiming to understand the motivations behind their use in FL incentive mechanism design. It provides detailed reviews, analyses, and comparisons of different economic and game theoretic approaches for designing a variety of FL incentive mechanisms.</p>
</div>
<div id="S3.I3.i4.p2" class="ltx_para">
<ul id="S3.I3.i4.I1" class="ltx_itemize">
<li id="S3.I3.i4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i4.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I3.i4.I1.i1.p1" class="ltx_para">
<p id="S3.I3.i4.I1.i1.p1.1" class="ltx_p"><span id="S3.I3.i4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Reputation based FL:</span>
To address existing issues in federated learning, such as redundant transmissions, network congestion, as well as security and privacy concerns, reputation-based approaches have been proposed. Typically, reputation-based methods involve measuring the reliability of participants by designing a security mechanism. The blockchain-based reputation system <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib138" title="" class="ltx_ref">zhao2020mobile </a></cite>, which increments the reputation value of clients contributing correct and useful model parameters and decrements for those uploading malicious parameters, influencing client selection for subsequent training rounds. A reputation mechanism framework RepBFL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref">chen2021repbfl </a></cite>, merging blockchain and FL for applications in the Internet of Vehicles (IoV). By leveraging blockchain, it ensures shared data protection and the selection of high-reputation nodes for FL, alongside evaluating the reliability of vehicles in IoV. The approach presented in <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib133" title="" class="ltx_ref">zhang2021blockchain </a></cite> employs a reputation-based evaluation using model quality parameters and blockchain to gauge worker reliability and maintain reputation values. In <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib74" title="" class="ltx_ref">lyu2020collaborative </a></cite>, research on collaborative fairness in FL leads to the development of a collaborative fair FL framework, CFFL. This introduces a reputation mechanism based on empirical individual model performance, mediating participant rewards to maintain fairness across communication rounds. Lastly, <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib40" title="" class="ltx_ref">kang2019incentive </a></cite> regards reputation as a metric quantifying the reliability and trustworthiness of mobile devices. Its multi-weight subjective logic model is employed for reputation calculation, with consortium blockchain technology securing reputation storage in a decentralized manner. Notably, the reputation calculation involves the task requester selecting eligible worker candidates based on resource information. The reputation value of candidate workers is then computed based on direct reputation feedback from interaction history and indirect reputation feedback from other task requesters, all of which is stored and managed on an open-access reputation blockchain.</p>
</div>
</li>
<li id="S3.I3.i4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i4.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I3.i4.I1.i2.p1" class="ltx_para">
<p id="S3.I3.i4.I1.i2.p1.1" class="ltx_p"><span id="S3.I3.i4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Payment based FL:</span>
FedCoin <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib67" title="" class="ltx_ref">liu2020fedcoin </a></cite> employs Shapley Values (SVs) for a feasible SV-based profit distribution that equitably mirrors contributions to the global FL model. Here, the blockchain consensus entities deploy the Shapley Proof-of-Stake protocol (PoSap) for the calculation of SVs and creation of new blocks.
Constructing an FL protocol on a public blockchain network can resolve the challenges related to monitoring worker behavior and guaranteeing protocol adherence <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib108" title="" class="ltx_ref">toyoda2020blockchain </a></cite>. This protocol embeds competition into BCFL, rewarding only those workers whose contributions are valuable and naturally discouraging deviation from the protocol. The mobile-crowd FL system <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib36" title="" class="ltx_ref">jiang2022reward </a></cite> incentivizes mobile devices to train accurate models by offering rewards based on individual contributions. A Stackelberg game models interactions between the server and devices, and two reward policies, namely, the size-based and accuracy-based policies, are compared under different definitions of individual contribution.
In addition, the challenge of transparently assessing contributions from different data owners in a cross-silo horizontal federated learning setup is tackled by quantifying data owners’ SV-based contributions with adjustable precision, safeguarding their privacy <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib76" title="" class="ltx_ref">ma2021transparent </a></cite>.</p>
</div>
</li>
<li id="S3.I3.i4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i4.I1.i3.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I3.i4.I1.i3.p1" class="ltx_para">
<p id="S3.I3.i4.I1.i3.p1.1" class="ltx_p"><span id="S3.I3.i4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">DeepChain:</span>
DeepChain <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib119" title="" class="ltx_ref">weng2019deepchain </a></cite> is a collaborative framework for training deep learning models with joint participation from clients. It guarantees data confidentiality, computational verifiability, and offers incentives to participants. The incentive mechanism in DeepChain is orchestrated around timeout checks and monetary penalties, fostering fairness among participants. It takes punitive measures in scenarios where participants fail to meet deadlines or inaccurately execute functions, by imposing monetary penalties, confiscating the pre-deposited funds from dishonest participants and redistributing them among honest ones.</p>
</div>
</li>
<li id="S3.I3.i4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I3.i4.I1.i4.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I3.i4.I1.i4.p1" class="ltx_para">
<p id="S3.I3.i4.I1.i4.p1.1" class="ltx_p"><span id="S3.I3.i4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Mechanism Design:</span>
Designing a mechanism is the objective for achieving effective incentives. The survey <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib128" title="" class="ltx_ref">zeng2021comprehensive </a></cite> meticulously explores incentive mechanisms for federated learning. It compiles existing incentive mechanisms and categorizes them based on key techniques, such as the Stackelberg game, auction, contract theory, Shapley value, reinforcement learning, and blockchain.
Furthermore, to address the challenges posed by malicious participants in large-scale collaborations, Refiner is proposed <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib136" title="" class="ltx_ref">zhang2021refiner </a></cite>. The system resides on the Ethereum public blockchain platform and operates an incentive mechanism rewarding participants based on the volume of their training data and the performance of local updates. For dealing with malicious actors, Refiner deploys a committee of randomly selected validators. These validators penalize unscrupulous participants by denying rewards and eliminating corrupt updates from the global model.</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">In BCFL, there is a need to craft an effective incentive mechanism that stimulates active participation among participants and recognizes their contributions. In addition, privacy-preserving methods should be employed to protect data privacy of participants throughout the FL process. Subsequently, its training process should be optimized for the system to achieve the best performance. By addressing the above issues, BCFL systems can motivate participants while ensuring data privacy and security.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Blockchain Consensus</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">In the context of FL system implementation, consensus pertains to the agreement or protocol employed by participants to synchronize their models and collectively make decisions. Consensus algorithms, such as PoW or PoS, are commonly utilized in blockchain-based systems to establish agreement among distributed participants. These algorithms ensure that all participants agree on the validity of model updates and prevent malicious actors from tampering with the system.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p id="S3.SS6.p2.1" class="ltx_p">The consensus mechanism is to complete the verification and confirmation of transactions in a very short period of time through the voting of special nodes. If nodes with disparate interests can reach a consensus on a transaction, it implies a broader network consensus. With the evolution of blockchain technology, the term consensus mechanism has become widely recognized, and various innovative consensus mechanisms continue to emerge.</p>
</div>
<div id="S3.SS6.p3" class="ltx_para">
<p id="S3.SS6.p3.1" class="ltx_p">Consensus holds paramount importance in blockchain technology as it safeguards the integrity, security, and immutability of the distributed ledger. Numerous consensus algorithms are employed in blockchain networks, each characterized by its unique attributes and trade-offs.</p>
</div>
<div id="S3.SS6.p4" class="ltx_para">
<ul id="S3.I4" class="ltx_itemize">
<li id="S3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i1.p1" class="ltx_para">
<p id="S3.I4.i1.p1.1" class="ltx_p"><span id="S3.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">Proof of Work (PoW):</span>
Bitcoin uses the PoW(Proof of Work) workload proof mechanism, and later Ethereum is the PoW and PoS(Proof of Stake) consensus mechanism. PoW is the equivalent of figuring out a difficult math problem that gets harder over time. Although PoW is a consensus mechanism recognized by everyone, computing consumes a lot of energy and may indirectly affect carbon emissions and the environment.
BCFL <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib97" title="" class="ltx_ref">qu2020decentralized </a></cite>, a distributed hash table for efficient block generation is introduced. This solution employs a proof-of-work consensus mechanism to ensure consistency in the global model.
LearningChain <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref">chen2018machine </a></cite>, a decentralized federated system leveraging a Byzantine fault-tolerant aggregation algorithm known as l-nearest aggression. The system is based on the PoW consensus, where the leader is selected through competition and the l-nearest algorithm is used to aggregate the gradient.
Swarm Learning (SL) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib118" title="" class="ltx_ref">warnat2021swarm </a></cite> a decentralized machine learning approach combining edge computing and blockchain-based P2P networking. With Swarm Learning, data and parameters are kept at the edge, thereby eliminating the need for a central coordinator.</p>
</div>
</li>
<li id="S3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i2.p1" class="ltx_para">
<p id="S3.I4.i2.p1.1" class="ltx_p"><span id="S3.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">Proof of Stake (PoS):</span>
PoS is seen as a more environmentally friendly alternative to PoW. Instead of miners competing to solve problems, validators are chosen to create new blocks based on the amount of cryptocurrency they hold and are willing to "stake" as collateral.</p>
</div>
</li>
<li id="S3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i3.p1" class="ltx_para">
<p id="S3.I4.i3.p1.1" class="ltx_p"><span id="S3.I4.i3.p1.1.1" class="ltx_text ltx_font_bold">Delegated Proof of Stake (DPoS):</span>
In DPoS, stakeholders elect a certain number of delegates who validate transactions and create blocks. This method is designed to be more democratic and efficient than traditional PoS.</p>
</div>
</li>
<li id="S3.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i4.p1" class="ltx_para">
<p id="S3.I4.i4.p1.1" class="ltx_p"><span id="S3.I4.i4.p1.1.1" class="ltx_text ltx_font_bold">Proof of Training Quality (PoQ):</span>
The existing consensus mechanisms, such as Proof of Work (PoW), consume significant computational and communication resources or have limited additional contributions to data sharing. To address this problem, <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib69" title="" class="ltx_ref">lu2019blockchain </a></cite> proposes a consensus mechanism called PoQ has been proposesd that combines FL with differential privacy. PoQ integrates data model training with the consensus process, replacing the meaningless computational work of finding random numbers in PoW with the authentication of model parameter accuracy.</p>
</div>
</li>
<li id="S3.I4.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i5.p1" class="ltx_para">
<p id="S3.I4.i5.p1.1" class="ltx_p"><span id="S3.I4.i5.p1.1.1" class="ltx_text ltx_font_bold">Byzantine Fault Tolerance (BFT):</span>
This consensus mechanism aims to withstand ’Byzantine’ faults, where components may fail and there is imperfect information on whether a component is failed or not. There are several BFT, such as Practical Byzantine Fault Tolerance (PBFT) used in Hyperledger Fabric <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib3" title="" class="ltx_ref">2018hyperledger </a>; <a href="#bib.bib106" title="" class="ltx_ref">sun2021permissioned </a>; <a href="#bib.bib18" title="" class="ltx_ref">chen2020methodology </a></cite>, and the Federated Byzantine Agreement (FBA) used in Stellar <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib78" title="" class="ltx_ref">mittal2021Stellar </a></cite>.</p>
</div>
</li>
<li id="S3.I4.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i6.p1" class="ltx_para">
<p id="S3.I4.i6.p1.1" class="ltx_p"><span id="S3.I4.i6.p1.1.1" class="ltx_text ltx_font_bold">Proof of Federation (PoF):</span>
Biscotti <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib102" title="" class="ltx_ref">shayan2020biscotti </a></cite>, which combines PoF with consistent hashing and Verifiable Random Functions (VRF) to select critical roles for peer nodes. These roles aid in coordinating the privacy and security of model updates. To prevent peers from poisoning the model through Multi-Krum defense, Biscotti employs differentiated private noise to provide privacy. It also utilizes Shamir secret sharing for secure aggregation. However, when all nodes participate in the consensus, the computational load is too large <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib100" title="" class="ltx_ref">ramanan2020baffle </a></cite>.</p>
</div>
</li>
<li id="S3.I4.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i7.p1" class="ltx_para">
<p id="S3.I4.i7.p1.1" class="ltx_p"><span id="S3.I4.i7.p1.1.1" class="ltx_text ltx_font_bold">RAFT:</span>
RAFT is a consensus algorithm used in some permissioned blockchain networks. It elects a leader among a group of nodes, and the leader is responsible for proposing and validating blocks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">kim2021improved </a></cite>. Raft focuses on simplicity and fault tolerance and is designed to be easier to understand and implement than other consensus algorithms.</p>
</div>
</li>
<li id="S3.I4.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i8.p1" class="ltx_para">
<p id="S3.I4.i8.p1.1" class="ltx_p"><span id="S3.I4.i8.p1.1.1" class="ltx_text ltx_font_bold">Proof of Federated Training:</span>
Proof of Federated Training (PoFT) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib12" title="" class="ltx_ref">chakraborty2022proof </a></cite>, is a framework for enabling verifiable model training across multiple blockchain networks. It addresses issues such as power consumption/resource wastage in POW and data privacy in blockchain <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib96" title="" class="ltx_ref">qu2021proof </a></cite>.
In addition, Proof of FL (PoFL) is also employed in vehicular networks, where vehicles compete to become miners by adhering to the FL consensus proof within the blockchain network <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib4" title="" class="ltx_ref">ayaz2021blockchain </a></cite>. Additionally, IPFS and PoFL are utilized to ensure decentralized federated learning security for connected autonomous vehicles <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib30" title="" class="ltx_ref">he2021bift </a></cite>.</p>
</div>
</li>
<li id="S3.I4.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i9.p1" class="ltx_para">
<p id="S3.I4.i9.p1.1" class="ltx_p"><span id="S3.I4.i9.p1.1.1" class="ltx_text ltx_font_bold">Committee Consensus:</span>
The Blockchain-based FL framework with Committee consensus (BFLC) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib57" title="" class="ltx_ref">li2020blockchain </a></cite>, utilizes blockchain for global model storage and local model update exchange, eliminating the need for a centralized server <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib65" title="" class="ltx_ref">liu2023heterps </a></cite>. Additionally, an innovative committee consensus mechanism is introduced to reduce the computational load and mitigate malicious attacks.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS6.p5" class="ltx_para">
<p id="S3.SS6.p5.1" class="ltx_p">These consensus algorithms all have their strengths and weaknesses and are suited to different use-cases. Selecting the right consensus mechanism is vital for the security, scalability, and efficiency of the blockchain network.
These are some commonly used blockchain consensus algorithms. However, the selection of a consensus algorithm is influenced by factors such as the desired degree of decentralization, security, scalability, and the specific needs of the blockchain network.</p>
</div>
</section>
<section id="S3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Application Layer</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p id="S3.SS7.p1.1" class="ltx_p">FL has various applications across different domains where services based on this technology can be provided.</p>
</div>
<div id="S3.SS7.p2" class="ltx_para">
<ul id="S3.I5" class="ltx_itemize">
<li id="S3.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i1.p1" class="ltx_para">
<p id="S3.I5.i1.p1.1" class="ltx_p"><span id="S3.I5.i1.p1.1.1" class="ltx_text ltx_font_bold">Internet of Vehicles:</span>
Vehicles are increasingly becoming data generation sources. Data such as GPS location, speed, and road conditions can contribute to better traffic management, route planning, and accident prevention. However, this data is also sensitive <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib5" title="" class="ltx_ref">bai2022internet </a></cite>. BCFL enables aggregation of data from multiple vehicles to train models without sharing the raw data <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib94" title="" class="ltx_ref">pokhrel2020decentralized </a>; <a href="#bib.bib11" title="" class="ltx_ref">chai2020hierarchical </a>; <a href="#bib.bib16" title="" class="ltx_ref">chen2021bdfl </a>; <a href="#bib.bib87" title="" class="ltx_ref">otoum2020blockchain </a>; <a href="#bib.bib15" title="" class="ltx_ref">chen2021repbfl </a>; <a href="#bib.bib50" title="" class="ltx_ref">li2022fedhisyn </a></cite>. Moreover, blockchain can also be used to maintain a tamper-proof record of vehicle interactions and transactions in the network <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib2" title="" class="ltx_ref">aloqaily2021energy </a>; <a href="#bib.bib70" title="" class="ltx_ref">lu2020blockchain </a></cite>.</p>
</div>
</li>
<li id="S3.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i2.p1" class="ltx_para">
<p id="S3.I5.i2.p1.1" class="ltx_p"><span id="S3.I5.i2.p1.1.1" class="ltx_text ltx_font_bold">Resource allocation:</span>
In large distributed systems, effective resource allocation is critical to maximize efficiency <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib117" title="" class="ltx_ref">wang2022incentive </a></cite>. By applying FL on top of a blockchain network, resources can be allocated dynamically based on the learning from the network usage patterns <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib51" title="" class="ltx_ref">li2021blockchain </a></cite>. In essence, integrating blockchain with FL not only fortifies privacy and reliability but also provides a platform for efficient resource allocation and utilization <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">deng2021flex </a></cite>.</p>
</div>
</li>
<li id="S3.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i3.p1" class="ltx_para">
<p id="S3.I5.i3.p1.1" class="ltx_p"><span id="S3.I5.i3.p1.1.1" class="ltx_text ltx_font_bold">Edge computing:</span> BCFL has great potential for applications in edge computing. It provides a secure mechanism for data sharing, resource collaboration and sharing, model updates and upgrades, as well as guarantees for interference resistance and fault tolerance <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref">liu2021blockchain </a>; <a href="#bib.bib70" title="" class="ltx_ref">lu2020blockchain </a>; <a href="#bib.bib84" title="" class="ltx_ref">nguyen2022latency </a>; <a href="#bib.bib83" title="" class="ltx_ref">nguyen2021federated </a>; <a href="#bib.bib97" title="" class="ltx_ref">qu2020decentralized </a></cite>. By leveraging the computing resources and data of edge devices, BCFL enables intelligent applications to perform inference and decision-making tasks efficiently and securely <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib98" title="" class="ltx_ref">rahmadika2021blockchain </a>; <a href="#bib.bib72" title="" class="ltx_ref">lu2020low </a>; <a href="#bib.bib71" title="" class="ltx_ref">lu2020communication </a></cite>. It addresses challenges such as data privacy, resource constraints, and unstable environments commonly encountered in edge computing <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib112" title="" class="ltx_ref">wan2022privacy </a>; <a href="#bib.bib31" title="" class="ltx_ref">hu2021blockchain </a></cite>. This approach offers a novel solution for the development and expansion of edge computing scenarios. It has been extensively researched and applied in the Mobile phones scenario, and it is believed that it will provide solutions for the development and expansion of more edge computing scenarios in the future <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib24" title="" class="ltx_ref">fan2022mobile </a>; <a href="#bib.bib25" title="" class="ltx_ref">feng2021two </a>; <a href="#bib.bib31" title="" class="ltx_ref">hu2021blockchain </a>; <a href="#bib.bib32" title="" class="ltx_ref">hu2021blockchainB </a>; <a href="#bib.bib47" title="" class="ltx_ref">kong2021achieving </a></cite>.</p>
</div>
</li>
<li id="S3.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i4.p1" class="ltx_para">
<p id="S3.I5.i4.p1.1" class="ltx_p"><span id="S3.I5.i4.p1.1.1" class="ltx_text ltx_font_bold">Healthcare:</span> In healthcare, patient data is sensitive but can be extremely useful for detecting diseases <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib48" title="" class="ltx_ref">kumar2021blockchain </a>; <a href="#bib.bib91" title="" class="ltx_ref">passerat2019blockchain </a>; <a href="#bib.bib79" title="" class="ltx_ref">mohammed2023energy </a></cite> and improving treatment <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib99" title="" class="ltx_ref">rahman2020secure </a>; <a href="#bib.bib82" title="" class="ltx_ref">myrzashova2023blockchain </a></cite>. BCFL allows healthcare institutions to collaborate and learn from a vast amount of patient data without compromising patient privacy <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib90" title="" class="ltx_ref">passerat2020blockchain </a>; <a href="#bib.bib1" title="" class="ltx_ref">aich2022protecting </a>; <a href="#bib.bib132" title="" class="ltx_ref">zhang2021blockchain2 </a></cite>. In addition, blockchain can provide traceability of data and computations, increasing the trust in the learned models <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib115" title="" class="ltx_ref">wang2021blockchainMedical </a></cite>.</p>
</div>
</li>
<li id="S3.I5.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i5.p1" class="ltx_para">
<p id="S3.I5.i5.p1.1" class="ltx_p"><span id="S3.I5.i5.p1.1.1" class="ltx_text ltx_font_bold">Energy:</span> The integration of blockchain with FL presents a transformative approach for diverse energy applications. BCFL can be used to optimize grid operations, facilitates P2P energy trading and sharing across microgrids <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">bouachir2022federatedgrids </a></cite>. Moreover, in the context of the Industrial Internet of Things (IIoT), BCFL can address security and privacy concerns associated with credit data sharing in wireless networks <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib123" title="" class="ltx_ref">yang2022privacy </a>; <a href="#bib.bib86" title="" class="ltx_ref">otoum2022federated </a>; <a href="#bib.bib34" title="" class="ltx_ref">issa2023blockchain </a>; <a href="#bib.bib33" title="" class="ltx_ref">Huang2023Distance </a>; <a href="#bib.bib104" title="" class="ltx_ref">singh2023fusionfedblock </a></cite>. It is also being applied for blade icing detection in wind energy turbines, a rapidly growing sector of renewable energy <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib19" title="" class="ltx_ref">cheng2022blockchain </a></cite>.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Challenges and Open Research Directions</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The amalgamation of blockchain with FL combines the advantages of both realms, establishing a system that prioritizes data privacy and security. Nevertheless, this integration presents its own array of challenges. In this section, we outline these challenges and propose potential research directions.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Data Security and Privacy Protection</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In a landscape where FL with blockchain, the paramount concern becomes ensuring the security and privacy of data. Effectively managing sensitive information, such as medical records or personal identities, within a networked environment is a challenge. An in-depth exploration of cryptographic techniques to handle such data without exposing its true content is essential. Future research should delve into new cryptographic solutions tailored to this integrated system.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model Efficiency and Performance Optimization</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Efficient computation for distributed data and models is a fundamental requirement of FL. The core challenges in this domain involve devising algorithms that reduce computational complexity, minimize communication overhead, and enhance the efficiency of model training and inference. Future research endeavors should concentrate on fine-tuning distributed optimization methods, integrating advanced compression strategies <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib131" title="" class="ltx_ref">zhang2022fedduap </a></cite> to alleviate communication burdens, and exploring hardware enhancements for enhanced computational efficiency. An investigation into hybrid models, amalgamating centralized and decentralized training methods, also holds considerable promise.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Scalability</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text" style="color:#000000;">As blockchain and FL converge towards creating secure, private data management frameworks, scalability emerges as a crucial bottleneck, particularly as the systems scale and demand increases. The integration of off-chain calculations, sidechains, and layer-2 technologies like state channels or Plasma represents a forward-thinking approach to overcoming these challenges. Off-chain calculations offload intensive tasks, reducing main blockchain load, while sidechains manage transactions separately to decrease congestion. Layer-2 technologies, such as state channels or Plasma, facilitate fast transactions atop the existing blockchain, maintaining security. These approaches, leveraging blockchain’s and FL’s core principles, aim to cultivate scalable, secure, and decentralized learning ecosystems.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As a decentralized and immutable technology, blockchain enables an egalitarian platform for all network participants, mitigates data breaches, and fosters trustworthiness. The combination of FL with blockchain creates a robust learning ecosystem prioritizing data security and user privacy. In this paper, we conduct a thorough exploration of such integrations, providing a comprehensive perspective on FL architectures informed by blockchain. We aim to offer clear insights for researchers and practitioners in this burgeoning field by examining the foundational elements of both realms and highlighting their synergies. We are optimistic that the challenges and research pathways outlined herein will guide the next wave of innovations in decentralized machine learning frameworks.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Satyabrata Aich, Nday Kabulo Sinai, Saurabh Kumar, Mohammed Ali, Yu Ran Choi,
Moon-IL Joo, and Hee-Cheol Kim.

</span>
<span class="ltx_bibblock">Protecting personal healthcare record using blockchain &amp; federated
learning technologies.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">2022 24th International Conference on Advanced Communication
Technology (ICACT)</span>, pages 109–112. IEEE, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Moayad Aloqaily, Ismaeel Al Ridhawi, and Mohsen Guizani.

</span>
<span class="ltx_bibblock">Energy-aware blockchain and federated learning-supported vehicular
networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Intelligent Transportation Systems</span>, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Elli Androulaki, Artem Barger, Vita Bortnikov, Christian Cachin, Konstantinos
Christidis, Angelo De Caro, David Enyeart, Christopher Ferris, Gennady
Laventman, Yacov Manevich, et al.

</span>
<span class="ltx_bibblock">Hyperledger fabric: a distributed operating system for permissioned
blockchains.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proceedings of the thirteenth EuroSys conference</span>, pages
1–15, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Ferheen Ayaz, Zhengguo Sheng, Daxin Tian, and Yong LIANG Guan.

</span>
<span class="ltx_bibblock">A blockchain based federated learning for message dissemination in
vehicular networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Vehicular Technology</span>, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Jian Bai, Zhuo Zhang, and Bingshen Shen.

</span>
<span class="ltx_bibblock">Internet of vehicles security situation awareness based on intrusion
detection protection systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Journal of Computational Methods in Sciences and Engineering</span>,
22(1):189–195, 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
David Berdik, Safa Otoum, Nikolas Schmidt, Dylan Porter, and Yaser Jararweh.

</span>
<span class="ltx_bibblock">A survey on blockchain for information systems management and
security.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Information Processing &amp; Management</span>, 58(1):102397, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Pronaya Bhattacharya, Sudeep Tanwar, Umesh Bodkhe, Sudhanshu Tyagi, and Neeraj
Kumar.

</span>
<span class="ltx_bibblock">Bindaas: Blockchain-based deep-learning as-a-service in healthcare
4.0 applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">IEEE transactions on network science and engineering</span>,
8(2):1242–1255, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečnỳ, Stefano
Mazzocchi, Brendan McMahan, et al.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine Learning and Systems</span>, 1:374–388, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Ouns Bouachir, Moayad Aloqaily, Öznur Özkasap, and Faizan Ali.

</span>
<span class="ltx_bibblock">Federatedgrids: Federated learning and blockchain-assisted p2p energy
sharing.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Green Communications and Networking</span>, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
California State Legislature, USA.

</span>
<span class="ltx_bibblock">California consumer privacy act home page.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.caprivacy.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.caprivacy.org/</a>.

</span>
<span class="ltx_bibblock">Online; accessed 14/02/2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Haoye Chai, Supeng Leng, Yijin Chen, and Ke Zhang.

</span>
<span class="ltx_bibblock">A hierarchical blockchain-enabled federated learning algorithm for
knowledge sharing in internet of vehicles.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Intelligent Transportation Systems</span>,
22(7):3975–3986, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Sarthak Chakraborty and Sandip Chakraborty.

</span>
<span class="ltx_bibblock">Proof of federated training: Accountable cross-network model training
and inference.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2204.06919</span>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Tianshi Che, Ji Liu, Yang Zhou, Jiaxiang Ren, Jiwen Zhou, Victor S Sheng,
Huaiyu Dai, and Dejing Dou.

</span>
<span class="ltx_bibblock">Federated learning of large language models with parameter-efficient
prompt tuning and adaptive optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Empirical Methods in Natural Language Processing (EMNLP)</span>,
pages 1–18, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Tianshi Che, Zijie Zhang, Yang Zhou, Xin Zhao, Ji Liu, Zhe Jiang, Da Yan,
Ruoming Jin, and Dejing Dou.

</span>
<span class="ltx_bibblock">Federated fingerprint learning with heterogeneous architectures.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">IEEE Int. Conf. on Data Mining (ICDM)</span>, pages 31–40. IEEE,
2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Haoyu Chen, Naiyue Chen, He Liu, Honglei Zhang, Jiabo Xu, Huaping Chen, and
Yidong Li.

</span>
<span class="ltx_bibblock">Repbfl: Reputation based blockchain-enabled federated learning
framework for data sharing in internet of vehicles.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">International Conference on Parallel and Distributed
Computing: Applications and Technologies</span>, pages 536–547. Springer, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Jin-Hua Chen, Min-Rong Chen, Guo-Qiang Zeng, and Jia-Si Weng.

</span>
<span class="ltx_bibblock">Bdfl: a byzantine-fault-tolerance decentralized federated learning
method for autonomous vehicle.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Vehicular Technology</span>, 70(9):8639–8652,
2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Xuhui Chen, Jinlong Ji, Changqing Luo, Weixian Liao, and Pan Li.

</span>
<span class="ltx_bibblock">When machine learning meets blockchain: A decentralized,
privacy-preserving and secure design.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">2018 IEEE international conference on big data (big data)</span>,
pages 1178–1187. IEEE, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
YiTong Chen, Qian Chen, and YuXiang Xie.

</span>
<span class="ltx_bibblock">A methodology for high-efficient federated-learning with consortium
blockchain.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">2020 IEEE 4th Conference on Energy Internet and Energy System
Integration (EI2)</span>, pages 3090–3095. IEEE, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Xu Cheng, Weiwei Tian, Fan Shi, Meng Zhao, Shengyong Chen, and Hao Wang.

</span>
<span class="ltx_bibblock">A blockchain-empowered cluster-based federated learning model for
blade icing estimation on iot-enabled wind turbine.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Shane Cook.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">CUDA programming: a developer’s guide to parallel computing with
GPUs</span>.

</span>
<span class="ltx_bibblock">Newnes, 2012.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Tyler Crain, Christopher Natoli, and Vincent Gramoli.

</span>
<span class="ltx_bibblock">Red belly: A secure, fair and scalable open blockchain.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">2021 IEEE Symposium on Security and Privacy (SP)</span>, pages
466–483. IEEE, 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Yang Deng, Tao Han, and Ning Zhang.

</span>
<span class="ltx_bibblock">Flex: Trading edge computing resources for federated learning via
blockchain.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">IEEE INFOCOM 2021-IEEE Conference on Computer Communications
Workshops (INFOCOM WKSHPS)</span>, pages 1–2. IEEE, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Christian Esposito, Massimo Ficco, and Brij Bhooshan Gupta.

</span>
<span class="ltx_bibblock">Blockchain-based authentication and authorization for smart city
applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Information Processing &amp; Management</span>, 58(2):102468, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Sizheng Fan, Hongbo Zhang, Zehua Wang, and Wei Cai.

</span>
<span class="ltx_bibblock">Mobile devices strategies in blockchain-based federated learning: A
dynamic game perspective.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Network Science and Engineering</span>, 2022.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Lei Feng, Zhixiang Yang, Shaoyong Guo, Xuesong Qiu, Wenjing Li, and Peng Yu.

</span>
<span class="ltx_bibblock">Two-layered blockchain architecture for federated learning over
mobile edge network.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">IEEE Network</span>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
B. M. Gaff, H. E. Sussman, and J. Geetter.

</span>
<span class="ltx_bibblock">Privacy and big data.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Computer</span>, 47(6):7–9, 2014.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Keke Gai, Jinnan Guo, Liehuang Zhu, and Shui Yu.

</span>
<span class="ltx_bibblock">Blockchain meets cloud computing: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</span>, 22(3):2009–2030,
2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Juan Garay and Aggelos Kiayias.

</span>
<span class="ltx_bibblock">Sok: A consensus taxonomy in the blockchain era.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Cryptographers’ track at the RSA conference</span>, pages
284–318. Springer, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Jialiang Han, Yun Ma, Yudong Han, Ying Zhang, and Gang Huang.

</span>
<span class="ltx_bibblock">Demystifying swarm learning: A new paradigm of blockchain-based
decentralized federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2201.05286</span>, 2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Ying He, Ke Huang, Guangzheng Zhang, F Richard Yu, Jianyong Chen, and Jianqiang
Li.

</span>
<span class="ltx_bibblock">Bift: A blockchain-based federated learning system for connected and
autonomous vehicles.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Qin Hu, Zhilin Wang, Minghui Xu, and Xiuzhen Cheng.

</span>
<span class="ltx_bibblock">Blockchain and federated edge learning for privacy-preserving mobile
crowdsensing.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Shili Hu, Jiangfeng Li, Chenxi Zhang, Qinpei Zhao, and Wei Ye.

</span>
<span class="ltx_bibblock">The blockchain-based edge computing framework for privacy-preserving
federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">IEEE Int. Conf. on Blockchain (Blockchain)</span>, pages 566–571,
2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Xiaoge Huang, Yuhang Wu, Chengchao Liang, Qianbin Chen, and Jie Zhang.

</span>
<span class="ltx_bibblock">Distance-aware hierarchical federated learning in blockchain-enabled
edge computing network.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 10(21):19163–19176, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Wael Issa, Nour Moustafa, Benjamin Turnbull, Nasrin Sohrabi, and Zahir Tari.

</span>
<span class="ltx_bibblock">Blockchain-based federated learning for securing internet of things:
A comprehensive survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys</span>, 55(9):1–43, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Juncheng Jia, Ji Liu, Chendi Zhou, Hao Tian, Mianxiong Dong, and Dejing Dou.

</span>
<span class="ltx_bibblock">Efficient asynchronous federated learning with sparsification and
quantization.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Concurrency and Computation: Practice and Experience</span>, page
e8002, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Suhan Jiang and Jie Wu.

</span>
<span class="ltx_bibblock">A reward response game in the blockchain-powered federated learning
system.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">International Journal of Parallel, Emergent and Distributed
Systems</span>, 37(1):68–90, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Jiayin Jin, Jiaxiang Ren, Yang Zhou, Lingjuan Lyu, Ji Liu, and Dejing Dou.

</span>
<span class="ltx_bibblock">Accelerated federated learning with decoupled adaptive optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Int. Conf. on Machine Learning (ICML)</span>, pages 10298–10322.
PMLR, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal,
Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al.

</span>
<span class="ltx_bibblock">In-datacenter performance analysis of a tensor processing unit.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Int. Symposium on Computer Architecture (ISCA)</span>, pages
1–12, 2017.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Harry Kalodner, Malte Möser, Kevin Lee, Steven Goldfeder, Martin Plattner,
Alishah Chator, and Arvind Narayanan.

</span>
<span class="ltx_bibblock"><math id="bib.bib39.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib39.1.m1.1a"><mo stretchy="false" id="bib.bib39.1.m1.1.1" xref="bib.bib39.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib39.1.m1.1b"><ci id="bib.bib39.1.m1.1.1.cmml" xref="bib.bib39.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib39.1.m1.1c">\{</annotation></semantics></math>BlockSci<math id="bib.bib39.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib39.2.m2.1a"><mo stretchy="false" id="bib.bib39.2.m2.1.1" xref="bib.bib39.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib39.2.m2.1b"><ci id="bib.bib39.2.m2.1.1.cmml" xref="bib.bib39.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib39.2.m2.1c">\}</annotation></semantics></math>: Design and applications of a blockchain analysis
platform.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.3.1" class="ltx_text ltx_font_italic">29th USENIX Security Symposium (USENIX Security 20)</span>, pages
2721–2738, 2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Jiawen Kang, Zehui Xiong, Dusit Niyato, Shengli Xie, and Junshan Zhang.

</span>
<span class="ltx_bibblock">Incentive mechanism for reliable federated learning: A joint
optimization approach to combining reputation and contract theory.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 6(6):10700–10714, 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Jiawen Kang, Zehui Xiong, Dusit Niyato, Dongdong Ye, Dong In Kim, and Jun Zhao.

</span>
<span class="ltx_bibblock">Toward secure blockchain-enabled internet of vehicles: Optimizing
consensus management using reputation and contract theory.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Vehicular Technology</span>, 68(3):2906–2920,
2019.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Jiawen Kang, Zehui Xiong, Dusit Niyato, Yuze Zou, Yang Zhang, and Mohsen
Guizani.

</span>
<span class="ltx_bibblock">Reliable federated learning for mobile networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">IEEE Wireless Communications</span>, 27(2):72–80, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
Stich, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Latif U Khan, Walid Saad, Zhu Han, and Choong Seon Hong.

</span>
<span class="ltx_bibblock">Dispersed federated learning: Vision, taxonomy, and future
directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">IEEE Wireless Communications</span>, 28(5):192–198, 2021.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Donghee Kim, Inshil Doh, and Kijoon Chae.

</span>
<span class="ltx_bibblock">Improved raft algorithm exploiting federated learning for private
blockchain performance enhancement.

</span>
<span class="ltx_bibblock">In <span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">2021 International Conference on Information Networking
(ICOIN)</span>, pages 828–832. IEEE, 2021.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
John Kolb, Moustafa AbdelBaky, Randy H Katz, and David E Culler.

</span>
<span class="ltx_bibblock">Core concepts, challenges, and future directions in blockchain: A
centralized tutorial.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys (CSUR)</span>, 53(1):1–39, 2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Qinglei Kong, Feng Yin, Yue Xiao, Beibei Li, Xuejia Yang, and Shuguang Cui.

</span>
<span class="ltx_bibblock">Achieving blockchain-based privacy-preserving location proofs under
federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">ICC 2021-IEEE International Conference on Communications</span>,
pages 1–6. IEEE, 2021.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Rajesh Kumar, Abdullah Aman Khan, Jay Kumar, Noorbakhsh Amiri Golilarz, Simin
Zhang, Yang Ting, Chengyu Zheng, Wenyong Wang, et al.

</span>
<span class="ltx_bibblock">Blockchain-federated-learning and deep learning models for covid-19
detection using ct imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">IEEE Sensors Journal</span>, 21(14):16301–16314, 2021.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Dun Li, Dezhi Han, Tien-Hsiung Weng, Zibin Zheng, Hongzhi Li, Han Liu,
Arcangelo Castiglione, and Kuan-Ching Li.

</span>
<span class="ltx_bibblock">Blockchain for federated learning toward secure distributed machine
learning systems: a systemic survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">Soft Computing</span>, 26(9):4423–4440, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Guanghao Li, Yue Hu, Miao Zhang, Ji Liu, Quanjun Yin, Yong Peng, and Dejing
Dou.

</span>
<span class="ltx_bibblock">Fedhisyn: A hierarchical synchronous federated learning framework for
resource and data heterogeneity.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">Int. Conf. on Parallel Processing (ICPP)</span>, pages 1–11,
2022.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Jun Li, Yumeng Shao, Kang Wei, Ming Ding, Chuan Ma, Long Shi, Zhu Han, and
Vincent Poor.

</span>
<span class="ltx_bibblock">Blockchain assisted decentralized federated learning (blade-fl):
Performance analysis and resource allocation.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</span>, 2021.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Qinbin Li, Bingsheng He, and Dawn Song.

</span>
<span class="ltx_bibblock">Model-contrastive federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 10713–10722, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu Liu, and
Bingsheng He.

</span>
<span class="ltx_bibblock">A survey on federated learning systems: vision, hype and reality for
data privacy and protection.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</span>, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith.

</span>
<span class="ltx_bibblock">Ditto: Fair and robust federated learning through personalization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
6357–6368. PMLR, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Proceedings of Machine learning and systems</span>, 2:429–450, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, and Qi Dou.

</span>
<span class="ltx_bibblock">Fedbn: Federated learning on non-iid features via local batch
normalization.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.07623</span>, 2021.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Yuzheng Li, Chuan Chen, Nan Liu, Huawei Huang, Zibin Zheng, and Qiang Yan.

</span>
<span class="ltx_bibblock">A blockchain-based decentralized federated learning framework with
committee consensus.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">IEEE Network</span>, 35(1):234–241, 2020.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Zhidu Li, Yujie Zhou, Dapeng Wu, and Ruyan Wang.

</span>
<span class="ltx_bibblock">Local model update for blockchain enabled federated learning:
Approach and analysis.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">IEEE Int. Conf. on Blockchain (Blockchain)</span>, pages 113–121,
2021.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Wei Liang, Yongkai Fan, Kuan-Ching Li, Dafang Zhang, and Jean-Luc Gaudiot.

</span>
<span class="ltx_bibblock">Secure data storage and recovery in industrial blockchain network
environments.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 16(10):6543–6552,
2020.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Hong Liu, Shuaipeng Zhang, Pengfei Zhang, Xinqiang Zhou, Xuebin Shao, Geguang
Pu, and Yan Zhang.

</span>
<span class="ltx_bibblock">Blockchain and federated learning for collaborative intrusion
detection in vehicular edge computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Vehicular Technology</span>, 70(6):6073–6084,
2021.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Ji Liu, Tianshi Che, Yang Zhou, Ruoming Jin, Huaiyu Dai, Dejing Dou, and
Patrick Valduriez.

</span>
<span class="ltx_bibblock">Aedfl: efficient asynchronous decentralized federated learning with
heterogeneous devices.

</span>
<span class="ltx_bibblock">In <span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">SIAM Conference on Data Mining</span>, pages 1–15, 2023.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Ji Liu, Jizhou Huang, Yang Zhou, Xuhong Li, Shilei Ji, Haoyi Xiong, and Dejing
Dou.

</span>
<span class="ltx_bibblock">From distributed machine learning to federated learning: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Knowledge and Information Systems</span>, 64(4):885–917, 2022.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Ji Liu, Juncheng Jia, Tianshi Che, Chao Huo, Jiaxiang Ren, Yang Zhou, Huaiyu
Dai, and Dejing Dou.

</span>
<span class="ltx_bibblock">Fedasmu: Efficient asynchronous federated learning with dynamic
staleness-aware model update.

</span>
<span class="ltx_bibblock">In <span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">AAAI</span>, pages 1–18, 2023.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Ji Liu, Juncheng Jia, Beichen Ma, Chendi Zhou, Jingbo Zhou, Yang Zhou, Huaiyu
Dai, and Dejing Dou.

</span>
<span class="ltx_bibblock">Multi-job intelligent scheduling with cross-device federated
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</span>,
34(2):535–551, 2022.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Ji Liu, Zhihua Wu, Danlei Feng, Minxu Zhang, Xinxuan Wu, Xuefeng Yao, Dianhai
Yu, Yanjun Ma, Feng Zhao, and Dejing Dou.

</span>
<span class="ltx_bibblock">Heterps: Distributed deep learning with reinforcement learning based
scheduling in heterogeneous environments.

</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Future Generation Computer Systems</span>, 2023.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Ji Liu, Xuehai Zhou, Lei Mo, Shilei Ji, Yuan Liao, Zheng Li, Qin Gu, and Dejing
Dou.

</span>
<span class="ltx_bibblock">Distributed and deep vertical federated learning with big data.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">Concurrency and Computation: Practice and Experience</span>, page
e7697, 2023.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Yuan Liu, Zhengpeng Ai, Shuai Sun, Shuangfeng Zhang, Zelei Liu, and Han Yu.

</span>
<span class="ltx_bibblock">Fedcoin: A peer-to-peer payment system for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">Federated Learning</span>, pages 125–138. Springer, 2020.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Sin Kit Lo, Yue Liu, Qinghua Lu, Chen Wang, Xiwei Xu, Hye-Young Paik, and
Liming Zhu.

</span>
<span class="ltx_bibblock">Blockchain-based trustworthy federated learning architecture.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2108.06912</span>, 2021.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Yunlong Lu, Xiaohong Huang, Yueyue Dai, Sabita Maharjan, and Yan Zhang.

</span>
<span class="ltx_bibblock">Blockchain and federated learning for privacy-preserved data sharing
in industrial iot.

</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 16(6):4177–4186,
2019.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan Zhang.

</span>
<span class="ltx_bibblock">Blockchain empowered asynchronous federated learning for secure data
sharing in internet of vehicles.

</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Vehicular Technology</span>, 69(4):4298–4311,
2020.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan Zhang.

</span>
<span class="ltx_bibblock">Communication-efficient federated learning and permissioned
blockchain for digital twin edge networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 8(4):2276–2288, 2020.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan Zhang.

</span>
<span class="ltx_bibblock">Low-latency federated learning and blockchain for edge association in
digital twin empowered 6g networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 17(7):5098–5107,
2020.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Sébastien Lugan, Paul Desbordes, Eliott Brion, Luis Xavier Ramos Tormo,
Axel Legay, and Benoît Macq.

</span>
<span class="ltx_bibblock">Secure architectures implementing trusted coalitions for blockchained
distributed learning (tclearn).

</span>
<span class="ltx_bibblock"><span id="bib.bib73.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 7:181789–181799, 2019.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Xinyi Xu, Qian Wang, and Han Yu.

</span>
<span class="ltx_bibblock">Collaborative fairness in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">Federated Learning</span>, pages 189–204. Springer, 2020.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Chuan Ma, Jun Li, Ming Ding, Long Shi, Taotao Wang, Zhu Han, and H Vincent
Poor.

</span>
<span class="ltx_bibblock">When federated learning meets blockchain: A new distributed learning
paradigm.

</span>
<span class="ltx_bibblock"><span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.09338</span>, 2020.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Shuaicheng Ma, Yang Cao, and Li Xiong.

</span>
<span class="ltx_bibblock">Transparent contribution evaluation for secure federated learning on
blockchain.

</span>
<span class="ltx_bibblock">In <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">2021 IEEE 37th International Conference on Data Engineering
Workshops (ICDEW)</span>, pages 88–91. IEEE, 2021.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pages 1273–1282.
PMLR, 2017.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Nitin Mittal, Srishty Pal, Anjali Joshi, Ashish Sharma, Sandeep Tayal, and
Yogesh Sharma.

</span>
<span class="ltx_bibblock">Comparative analysis of various platforms of blockchain.

</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">Smart and Sustainable Intelligent Systems</span>, pages 323–340,
2021.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Mazin Abed Mohammed, Abdullah Lakhan, Karrar Hameed Abdulkareem, Dilovan Asaad
Zebari, Jan Nedoma, Radek Martinek, Seifedine Kadry, and Begonya
Garcia-Zapirain.

</span>
<span class="ltx_bibblock">Energy-efficient distributed federated learning offloading and
scheduling healthcare system in blockchain based networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">Internet of Things</span>, 22:100815, 2023.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Viraaji Mothukuri, Reza M Parizi, Seyedamin Pouriyeh, Ali Dehghantanha, and
Kim-Kwang Raymond Choo.

</span>
<span class="ltx_bibblock">Fabricfl: Blockchain-in-the-loop federated learning for trusted
decentralized systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">IEEE Systems Journal</span>, 2021.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Hajar Moudoud, Soumaya Cherkaoui, and Lyes Khoukhi.

</span>
<span class="ltx_bibblock">Towards a secure and reliable federated learning using blockchain.

</span>
<span class="ltx_bibblock">In <span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">IEEE Global Communications Conf. (GLOBECOM)</span>, pages 1–6,
2021.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Raushan Myrzashova, Saeed Hamood Alsamhi, Alexey V Shvetsov, Ammar Hawbani, and
Xi Wei.

</span>
<span class="ltx_bibblock">Blockchain meets federated learning in healthcare: A systematic
review with challenges and opportunities.

</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2023.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Dinh C Nguyen, Ming Ding, Quoc-Viet Pham, Pubudu N Pathirana, Long Bao Le,
Aruna Seneviratne, Jun Li, Dusit Niyato, and H Vincent Poor.

</span>
<span class="ltx_bibblock">Federated learning meets blockchain in edge computing: Opportunities
and challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2021.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Dinh C Nguyen, Seyyedali Hosseinalipour, David J Love, Pubudu N Pathirana, and
Christopher G Brinton.

</span>
<span class="ltx_bibblock">Latency optimization for blockchain-empowered federated learning in
multi-server edge computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2203.09670</span>, 2022.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Official Journal of the European Union.

</span>
<span class="ltx_bibblock">General data protection regulation.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679</a>,
2016.

</span>
<span class="ltx_bibblock">Online; accessed 12/02/2021.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Safa Otoum, Ismaeel Al Ridhawi, and Hussein Mouftah.

</span>
<span class="ltx_bibblock">A federated learning and blockchain-enabled sustainable energy-trade
at the edge: A framework for industry 4.0.

</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2022.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Safa Otoum, Ismaeel Al Ridhawi, and Hussein T Mouftah.

</span>
<span class="ltx_bibblock">Blockchain-supported federated learning for trustworthy vehicular
networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib87.1.1" class="ltx_text ltx_font_italic">GLOBECOM 2020-2020 IEEE Global Communications Conference</span>,
pages 1–6. IEEE, 2020.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Liwei Ouyang, Fei-Yue Wang, Yonglin Tian, Xiaofeng Jia, Hongwei Qi, and
Ge Wang.

</span>
<span class="ltx_bibblock">Artificial identification: A novel privacy framework for federated
learning based on blockchain.

</span>
<span class="ltx_bibblock"><span id="bib.bib88.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Computational Social Systems</span>,
10(6):3576–3585, 2023.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Shashi Raj Pandey, Nguyen H Tran, Mehdi Bennis, Yan Kyaw Tun, Aunas Manzoor,
and Choong Seon Hong.

</span>
<span class="ltx_bibblock">A crowdsourcing framework for on-device federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib89.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Wireless Communications</span>, 19(5):3241–3256,
2020.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Jonathan Passerat-Palmbach, Tyler Farnan, Mike McCoy, Justin D Harris, Sean T
Manion, Heather Leigh Flannery, and Bill Gleim.

</span>
<span class="ltx_bibblock">Blockchain-orchestrated machine learning for privacy preserving
federated learning in electronic health data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib90.1.1" class="ltx_text ltx_font_italic">IEEE Int. Conf. on Blockchain (Blockchain)</span>, pages 550–555,
2020.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Jonathan Passerat-Palmbach, Tyler Farnan, Robert Miller, Marielle S Gross,
Heather Leigh Flannery, and Bill Gleim.

</span>
<span class="ltx_bibblock">A blockchain-orchestrated federated learning architecture for
healthcare consortia.

</span>
<span class="ltx_bibblock"><span id="bib.bib91.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1910.12603</span>, 2019.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Yanqing Peng, Min Du, Feifei Li, Raymond Cheng, and Dawn Song.

</span>
<span class="ltx_bibblock">Falcondb: Blockchain-based collaborative database.

</span>
<span class="ltx_bibblock">In <span id="bib.bib92.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2020 ACM SIGMOD International Conference
on Management of Data</span>, pages 637–652, 2020.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Shiva Raj Pokhrel.

</span>
<span class="ltx_bibblock">Blockchain brings trust to collaborative drones and leo satellites:
an intelligent decentralized learning in the space.

</span>
<span class="ltx_bibblock"><span id="bib.bib93.1.1" class="ltx_text ltx_font_italic">IEEE sensors journal</span>, 21(22):25331–25339, 2021.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Shiva Raj Pokhrel and Jinho Choi.

</span>
<span class="ltx_bibblock">A decentralized federated learning approach for connected autonomous
vehicles.

</span>
<span class="ltx_bibblock">In <span id="bib.bib94.1.1" class="ltx_text ltx_font_italic">2020 IEEE Wireless Communications and Networking Conference
Workshops (WCNCW)</span>, pages 1–6. IEEE, 2020.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Attia Qammar, Ahmad Karim, Huansheng Ning, and Jianguo Ding.

</span>
<span class="ltx_bibblock">Securing federated learning with blockchain: a systematic literature
review.

</span>
<span class="ltx_bibblock"><span id="bib.bib95.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence Review</span>, 56(5):3951–3985, 2023.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Xidi Qu, Shengling Wang, Qin Hu, and Xiuzhen Cheng.

</span>
<span class="ltx_bibblock">Proof of federated learning: A novel energy-recycling consensus
algorithm.

</span>
<span class="ltx_bibblock"><span id="bib.bib96.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</span>,
32(8):2074–2085, 2021.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Youyang Qu, Longxiang Gao, Tom H Luan, Yong Xiang, Shui Yu, Bai Li, and Gavin
Zheng.

</span>
<span class="ltx_bibblock">Decentralized privacy using blockchain-enabled federated learning in
fog computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib97.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 7(6):5171–5183, 2020.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Sandi Rahmadika, Muhammad Firdaus, Seolah Jang, and Kyung-Hyune Rhee.

</span>
<span class="ltx_bibblock">Blockchain-enabled 5g edge networks and beyond: an intelligent
cross-silo federated learning approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib98.1.1" class="ltx_text ltx_font_italic">Security and Communication Networks</span>, 2021, 2021.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Mohamed Abdur Rahman, M Shamim Hossain, Mohammad Saiful Islam, Nabil A Alrajeh,
and Ghulam Muhammad.

</span>
<span class="ltx_bibblock">Secure and provenance enhanced internet of health things framework: A
blockchain managed federated learning approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib99.1.1" class="ltx_text ltx_font_italic">Ieee Access</span>, 8:205071–205087, 2020.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Paritosh Ramanan and Kiyoshi Nakayama.

</span>
<span class="ltx_bibblock">Baffle: Blockchain based aggregator free federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib100.1.1" class="ltx_text ltx_font_italic">IEEE Int. Conf. on Blockchain (Blockchain)</span>, pages 72–81.
IEEE, 2020.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Zihao Shan, Kui Ren, Marina Blanton, and Cong Wang.

</span>
<span class="ltx_bibblock">Practical secure computation outsourcing: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib101.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys (CSUR)</span>, 51(2):1–40, 2018.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
Muhammad Shayan, Clement Fung, Chris JM Yoon, and Ivan Beschastnikh.

</span>
<span class="ltx_bibblock">Biscotti: A blockchain system for private and secure federated
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib102.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</span>,
32(7):1513–1525, 2020.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Shuyun Shi, Debiao He, Li Li, Neeraj Kumar, Muhammad Khurram Khan, and
Kim-Kwang Raymond Choo.

</span>
<span class="ltx_bibblock">Applications of blockchain in ensuring the security and privacy of
electronic health record systems: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib103.1.1" class="ltx_text ltx_font_italic">Computers &amp; security</span>, 97:101966, 2020.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Sushil Kumar Singh, Laurence T Yang, and Jong Hyuk Park.

</span>
<span class="ltx_bibblock">Fusionfedblock: Fusion of blockchain and federated learning to
preserve privacy in industry 5.0.

</span>
<span class="ltx_bibblock"><span id="bib.bib104.1.1" class="ltx_text ltx_font_italic">Information Fusion</span>, 90:233–240, 2023.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Standing Committee of the National People’s Congress.

</span>
<span class="ltx_bibblock">Cybersecurity law of the people’s republic of china.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.newamerica.org/cybersecurity-initiative/digichina/blog/translation-cybersecurity-law-peoples-republic-china/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.newamerica.org/cybersecurity-initiative/digichina/blog/translation-cybersecurity-law-peoples-republic-china/</a>.

</span>
<span class="ltx_bibblock">Online; accessed 22/02/2021.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
Jin Sun, Ying Wu, Shangping Wang, Yixue Fu, and Xiao Chang.

</span>
<span class="ltx_bibblock">Permissioned blockchain frame for secure federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib106.1.1" class="ltx_text ltx_font_italic">IEEE Communications Letters</span>, 26(1):13–17, 2021.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
Youliang Tian, Ta Li, Jinbo Xiong, Md Zakirul Alam Bhuiyan, Jianfeng Ma, and
Changgen Peng.

</span>
<span class="ltx_bibblock">A blockchain-based machine learning framework for edge services in
iiot.

</span>
<span class="ltx_bibblock"><span id="bib.bib107.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 18(3):1918–1929,
2021.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
Kentaroh Toyoda, Jun Zhao, Allan Neng Sheng Zhang, and P Takis Mathiopoulos.

</span>
<span class="ltx_bibblock">Blockchain-enabled federated learning with mechanism design.

</span>
<span class="ltx_bibblock"><span id="bib.bib108.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 8:219744–219756, 2020.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
Stacey Truex, Nathalie Baracaldo, Ali Anwar, Thomas Steinke, Heiko Ludwig, Rui
Zhang, and Yi Zhou.

</span>
<span class="ltx_bibblock">A hybrid approach to privacy-preserving federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib109.1.1" class="ltx_text ltx_font_italic">Proceedings of the 12th ACM workshop on artificial
intelligence and security</span>, pages 1–11, 2019.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
Xuezhen Tu, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Yang Zhang, and Juan Li.

</span>
<span class="ltx_bibblock">Incentive mechanisms for federated learning: From economic and game
theoretic perspective.

</span>
<span class="ltx_bibblock"><span id="bib.bib110.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Cognitive Communications and Networking</span>,
2022.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
Muhammad Habib ur Rehman, Ahmed Mukhtar Dirir, Khaled Salah, Ernesto Damiani,
and Davor Svetinovic.

</span>
<span class="ltx_bibblock">Trustfed: a framework for fair and trustworthy cross-device federated
learning in iiot.

</span>
<span class="ltx_bibblock"><span id="bib.bib111.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 17(12):8485–8494,
2021.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
Yichen Wan, Youyang Qu, Longxiang Gao, and Yong Xiang.

</span>
<span class="ltx_bibblock">Privacy-preserving blockchain-enabled federated learning for
b5g-driven edge computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib112.1.1" class="ltx_text ltx_font_italic">Computer Networks</span>, 204:108671, 2022.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Rong Wang and Wei-Tek Tsai.

</span>
<span class="ltx_bibblock">Asynchronous federated learning system based on permissioned
blockchains.

</span>
<span class="ltx_bibblock"><span id="bib.bib113.1.1" class="ltx_text ltx_font_italic">Sensors</span>, 22(4):1672, 2022.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
Wenbo Wang, Dinh Thai Hoang, Peizhao Hu, Zehui Xiong, Dusit Niyato, Ping Wang,
Yonggang Wen, and Dong In Kim.

</span>
<span class="ltx_bibblock">A survey on consensus mechanisms and mining strategy management in
blockchain networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib114.1.1" class="ltx_text ltx_font_italic">Ieee Access</span>, 7:22328–22370, 2019.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
Zexin Wang, Biwei Yan, and Yan Yao.

</span>
<span class="ltx_bibblock">Blockchain empowered federated learning for medical data sharing
model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib115.1.1" class="ltx_text ltx_font_italic">International Conference on Wireless Algorithms, Systems, and
Applications</span>, pages 537–544. Springer, 2021.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
Zhilin Wang and Qin Hu.

</span>
<span class="ltx_bibblock">Blockchain-based federated learning: A comprehensive survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib116.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2110.02182</span>, 2021.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
Zhilin Wang, Qin Hu, Ruinian Li, Minghui Xu, and Zehui Xiong.

</span>
<span class="ltx_bibblock">Incentive mechanism design for joint resource allocation in
blockchain-based federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib117.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2202.10938</span>, 2022.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Stefanie Warnat-Herresthal, Hartmut Schultze, Krishnaprasad Lingadahalli
Shastry, Sathyanarayanan Manamohan, Saikat Mukherjee, Vishesh Garg, Ravi
Sarveswara, Kristian Händler, Peter Pickkers, N Ahmad Aziz, et al.

</span>
<span class="ltx_bibblock">Swarm learning for decentralized and confidential clinical machine
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib118.1.1" class="ltx_text ltx_font_italic">Nature</span>, 594(7862):265–270, 2021.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
Jiasi Weng, Jian Weng, Jilian Zhang, Ming Li, Yue Zhang, and Weiqi Luo.

</span>
<span class="ltx_bibblock">Deepchain: Auditable and privacy-preserving deep learning with
blockchain-based incentive.

</span>
<span class="ltx_bibblock"><span id="bib.bib119.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</span>,
18(5):2438–2455, 2019.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
Zehui Xiong, Yang Zhang, Dusit Niyato, Ping Wang, and Zhu Han.

</span>
<span class="ltx_bibblock">When mobile blockchain meets edge computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib120.1.1" class="ltx_text ltx_font_italic">IEEE Communications Magazine</span>, 56(8):33–39, 2018.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
Minghui Xu, Zongrui Zou, Ye Cheng, Qin Hu, Dongxiao Yu, and Xiuzhen Cheng.

</span>
<span class="ltx_bibblock">Spdl: Blockchain-secured and privacy-preserving decentralized
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib121.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2201.01989</span>, 2022.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
Fan Yang, Mohammad Zoynul Abedin, and Petr Hajek.

</span>
<span class="ltx_bibblock">An explainable federated learning and blockchain-based secure credit
modeling method.

</span>
<span class="ltx_bibblock"><span id="bib.bib122.1.1" class="ltx_text ltx_font_italic">European Journal of Operational Research</span>, 2023.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
Fan Yang, Yanan Qiao, Mohammad Zoynul Abedin, and Cheng Huang.

</span>
<span class="ltx_bibblock">Privacy-preserved credit data sharing integrating blockchain and
federated learning for industrial 4.0.

</span>
<span class="ltx_bibblock"><span id="bib.bib123.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Industrial Informatics</span>, 2022.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
Mang Ye, Xiuwen Fang, Bo Du, Pong C Yuen, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Heterogeneous federated learning: State-of-the-art and research
challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib124.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys</span>, 56(3):1–44, 2023.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
Xuefei Yin, Yanming Zhu, and Jiankun Hu.

</span>
<span class="ltx_bibblock">A comprehensive survey of privacy-preserving federated learning: A
taxonomy, review, and future directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib125.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys (CSUR)</span>, 54(6):1–36, 2021.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
Haifeng Yu, Ivica Nikolić, Ruomu Hou, and Prateek Saxena.

</span>
<span class="ltx_bibblock">Ohie: Blockchain scaling made simple.

</span>
<span class="ltx_bibblock">In <span id="bib.bib126.1.1" class="ltx_text ltx_font_italic">2020 IEEE Symposium on Security and Privacy (SP)</span>, pages
90–105. IEEE, 2020.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia
Hoang, and Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Bayesian nonparametric federated learning of neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib127.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
7252–7261. PMLR, 2019.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
Rongfei Zeng, Chao Zeng, Xingwei Wang, Bo Li, and Xiaowen Chu.

</span>
<span class="ltx_bibblock">A comprehensive survey of incentive mechanism for federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib128.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.15406</span>, 2021.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
Yufeng Zhan, Peng Li, Zhihao Qu, Deze Zeng, and Song Guo.

</span>
<span class="ltx_bibblock">A learning-based incentive mechanism for federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib129.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 7(7):6360–6368, 2020.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
Fan Zhang, Shaoyong Guo, Xuesong Qiu, Siya Xu, Feng Qi, and Zhili Wang.

</span>
<span class="ltx_bibblock">Federated learning meets blockchain: State channel based distributed
data sharing trust supervision mechanism.

</span>
<span class="ltx_bibblock"><span id="bib.bib130.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 2021.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
Hong Zhang, Ji Liu, Juncheng Jia, Yang Zhou, Huaiyu Dai, and Dejing Dou.

</span>
<span class="ltx_bibblock">Fedduap: Federated learning with dynamic update and adaptive pruning
using shared data on the server.

</span>
<span class="ltx_bibblock">In <span id="bib.bib131.1.1" class="ltx_text ltx_font_italic">Int. Joint Conf. on Artificial Intelligence (IJCAI)</span>, 2022.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
Huiru Zhang, Guangshun Li, Yue Zhang, Keke Gai, and Meikang Qiu.

</span>
<span class="ltx_bibblock">Blockchain-based privacy-preserving medical data sharing scheme using
federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib132.1.1" class="ltx_text ltx_font_italic">International Conference on Knowledge Science, Engineering
and Management</span>, pages 634–646. Springer, 2021.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
Qinnan Zhang, Qingyang Ding, Jianming Zhu, and Dandan Li.

</span>
<span class="ltx_bibblock">Blockchain empowered reliable federated learning by worker selection:
A trustworthy reputation evaluation method.

</span>
<span class="ltx_bibblock">In <span id="bib.bib133.1.1" class="ltx_text ltx_font_italic">2021 IEEE Wireless Communications and Networking Conference
Workshops (WCNCW)</span>, pages 1–6. IEEE, 2021.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
Xiaoli Zhang, Fengting Li, Zeyu Zhang, Qi Li, Cong Wang, and Jianping Wu.

</span>
<span class="ltx_bibblock">Enabling execution assurance of federated learning at untrusted
participants.

</span>
<span class="ltx_bibblock">In <span id="bib.bib134.1.1" class="ltx_text ltx_font_italic">IEEE INFOCOM 2020-IEEE Conference on Computer
Communications</span>, pages 1877–1886. IEEE, 2020.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
Xinwei Zhang, Mingyi Hong, SairajV. Dhople, Wotao Yin, and Yang Liu.

</span>
<span class="ltx_bibblock">Fedpd: A federated learning framework with optimal rates and
adaptivity to non-iid data.

</span>
<span class="ltx_bibblock"><span id="bib.bib135.1.1" class="ltx_text ltx_font_italic">arXiv: Learning</span>, 2020.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
Zhebin Zhang, Dajie Dong, Yuhang Ma, Yilong Ying, Dawei Jiang, Ke Chen, Lidan
Shou, and Gang Chen.

</span>
<span class="ltx_bibblock">Refiner: a reliable incentive-driven federated learning system
powered by blockchain.

</span>
<span class="ltx_bibblock"><span id="bib.bib136.1.1" class="ltx_text ltx_font_italic">Proceedings of the VLDB Endowment</span>, 14(12):2659–2662, 2021.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
Jian Zhao, Xin Wu, Yan Zhang, Yu Wu, and Zhi Wang.

</span>
<span class="ltx_bibblock">A blockchain based decentralized gradient aggregation design for
federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib137.1.1" class="ltx_text ltx_font_italic">International Conference on Artificial Neural Networks</span>,
pages 359–371. Springer, 2021.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
Yang Zhao, Jun Zhao, Linshan Jiang, Rui Tan, and Dusit Niyato.

</span>
<span class="ltx_bibblock">Mobile edge computing, blockchain and reputation-based crowdsourcing
iot federated learning: A secure, decentralized and privacy-preserving
system.

</span>
<span class="ltx_bibblock"><span id="bib.bib138.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1906.10893</span>, 2020.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
Zhaohua Zheng, Yize Zhou, Yilong Sun, Zhang Wang, Boyi Liu, and Keqiu Li.

</span>
<span class="ltx_bibblock">Applications of federated learning in smart cities: recent advances,
taxonomy, and open challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib139.1.1" class="ltx_text ltx_font_italic">Connection Science</span>, 34(1):1–28, 2022.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
Chendi Zhou, Ji Liu, Juncheng Jia, Jingbo Zhou, Yang Zhou, Huaiyu Dai, and
Dejing Dou.

</span>
<span class="ltx_bibblock">Efficient device scheduling with multi-job federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib140.1.1" class="ltx_text ltx_font_italic">AAAI Conf. on Artificial Intelligence</span>, volume 36, pages
9971–9979, 2022.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
Juncen Zhu, Jiannong Cao, Divya Saxena, Shan Jiang, and Houda Ferradi.

</span>
<span class="ltx_bibblock">Blockchain-empowered federated learning: Challenges, solutions, and
future directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib141.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys</span>, 55(11):1–31, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.19177" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.19178" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.19178">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.19178" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.19179" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 13:38:18 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
