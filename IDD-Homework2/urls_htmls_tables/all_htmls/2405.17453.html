<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.17453] Semi-Federated Learning for Internet of Intelligence</title><meta property="og:description" content="One key vision of intelligent Internet of Things (IoT) is to provide connected intelligence for a large number of application scenarios, such as self-driving cars, industrial manufacturing, and smart city.
However, exi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Semi-Federated Learning for Internet of Intelligence">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Semi-Federated Learning for Internet of Intelligence">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.17453">

<!--Generated on Wed Jun  5 15:57:38 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Semi-Federated Learning for Internet of Intelligence</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wanli Ni
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
and Zhaohui Yang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span><span class="ltx_author_notes">Wanli Ni is with the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China (e-mail: niwanli@tsinghua.edu.cn).Zhaohui Yang is with the College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310058, China (e-mail: yang_zhaohui@zju.edu.cn).
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">One key vision of intelligent Internet of Things (IoT) is to provide connected intelligence for a large number of application scenarios, such as self-driving cars, industrial manufacturing, and smart city.
However, existing centralized or federated learning paradigms have difficulties in coordinating heterogeneous resources in distributed IoT environments.
In this article, we introduce a semi-federated learning (<span id="id1.id1.1" class="ltx_text ltx_font_typewriter">SemiFL</span>) framework to tackle the challenges of data and device heterogeneity in massive IoT networks.
In SemiFL, only users with sufficient computing resources are selected for local model training, while the remaining users only transmit raw data to the base station for remote computing.
By doing so, <span id="id1.id1.2" class="ltx_text ltx_font_typewriter">SemiFL</span> incorporates conventional centralized and federated learning paradigms into a harmonized framework that allows all devices to participate in the global model training regardless of their computational capabilities and data distributions.
Furthermore, we propose a next-generation multiple access scheme by seamlessly integrating communication and computation over the air.
This achieves the concurrent transmission of raw data and model parameters in a spectrum-efficient manner.
With their abilities to change channels and charge devices, two emerging techniques, reconfigurable intelligent surface and wireless energy transfer, are merged with our <span id="id1.id1.3" class="ltx_text ltx_font_typewriter">SemiFL</span> framework to enhance its performance in bandwidth- and energy-limited IoT networks, respectively.
Simulation results are presented to demonstrate the superiority of our <span id="id1.id1.4" class="ltx_text ltx_font_typewriter">SemiFL</span> for achieving edge intelligence among computing-heterogeneous IoT devices.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Machine learning (ML) empowers numerous intelligent services for future Internet of Things (IoT) networks, such as smart factories, auto-driving cars, and metaverse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
The ubiquitous connectivity of massive IoT devices (e.g., sensors, cameras, and smart watches) has the potential to create a pervasive environment for collecting multi-modal data in real time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
The tremendous amount of data sensed by thousands of IoT devices can be exploited by ML models to distill knowledge for smart decision-making.
Although the traditional centralized learning (CL) paradigm has exhibited outstanding performance in many IoT scenarios, transmitting a huge amount of raw data from edge devices to the base station (BS) may cause an extremely high communication overhead <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
Furthermore, raw data collected by IoT devices often contains private information exposing user’s behavior and habits, so sending them over wireless networks causes security concerns in privacy-sensitive scenarios.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To protect user privacy while improving communication efficiency, federated learning (FL) is proposed to allow edge devices to collaboratively train a shared model while keeping their datasets at local <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
However, FL requires all local devices to have sufficient computing resources for conducting on-device learning.
In addition, as data generation is usually personalized, the non-independent and identically distributed (non-IID) datasets between different devices significantly affect FL performance in terms of training speed and prediction accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
<span id="S1.p2.1.1" class="ltx_text ltx_font_italic">These challenges raise two fundamental questions:
1) How to adapt FL to computing-heterogeneous IoT networks?
2) How to design advanced signal processing techniques for the Internet of intelligence?</span></p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparing the proposed SemiFL with CL, FL, and on-device learning paradigms.</figcaption>
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.1.1" class="ltx_tr" style="background-color:#BFBFBF;">
<td id="S1.T1.1.1.1" class="ltx_td ltx_nopad ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding:2.5pt 8.0pt;"><svg version="1.1" height="21.76" width="116.54" overflow="visible"><g transform="translate(0,21.76) scale(1,-1)"><path d="M 0,21.76 116.54,0" stroke="#000000" stroke-width="0.4"></path><g class="ltx_svg_fog" transform="translate(0,0)"><g transform="translate(0,9.46) scale(1, -1)"><foreignObject width="39.63" height="9.46" overflow="visible">
<span id="S1.T1.1.1.1.pic1.1.1" class="ltx_inline-block" style="background-color:#BFBFBF;">
<span id="S1.T1.1.1.1.pic1.1.1.1" class="ltx_inline-block ltx_align_left">
<span id="S1.T1.1.1.1.pic1.1.1.1.1" class="ltx_p"><span id="S1.T1.1.1.1.pic1.1.1.1.1.1" class="ltx_text ltx_font_bold">Metric</span></span>
</span>
</span></foreignObject></g></g><g class="ltx_svg_fog" transform="translate(58.27,9.46)"><g transform="translate(0,12.3) scale(1, -1)"><foreignObject width="58.27" height="12.3" overflow="visible">
<span id="S1.T1.1.1.1.pic1.2.1" class="ltx_inline-block" style="background-color:#BFBFBF;">
<span id="S1.T1.1.1.1.pic1.2.1.1" class="ltx_inline-block ltx_align_right">
<span id="S1.T1.1.1.1.pic1.2.1.1.1" class="ltx_p"><span id="S1.T1.1.1.1.pic1.2.1.1.1.1" class="ltx_text ltx_font_bold">Paradigm</span></span>
</span>
</span></foreignObject></g></g></g></svg></td>
<td id="S1.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.1.2.1" class="ltx_text ltx_font_bold" style="background-color:#BFBFBF;">CL<span id="S1.T1.1.1.2.1.1" class="ltx_text ltx_font_medium"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite></span></span></td>
<td id="S1.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#BFBFBF;">On-device Learning<span id="S1.T1.1.1.3.1.1" class="ltx_text ltx_font_medium"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></span></span></td>
<td id="S1.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.1.4.1" class="ltx_text ltx_font_bold" style="background-color:#BFBFBF;">FL<span id="S1.T1.1.1.4.1.1" class="ltx_text ltx_font_medium"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite></span></span></td>
<td id="S1.T1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.1.5.1" class="ltx_text ltx_font_bold" style="background-color:#BFBFBF;">SemiFL</span></td>
</tr>
<tr id="S1.T1.1.2" class="ltx_tr">
<td id="S1.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding:2.5pt 8.0pt;">Upload data type</td>
<td id="S1.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 8.0pt;">Raw data</td>
<td id="S1.T1.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 8.0pt;">No Communication</td>
<td id="S1.T1.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 8.0pt;">Weight/Gradient</td>
<td id="S1.T1.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 8.0pt;">Hybrid</td>
</tr>
<tr id="S1.T1.1.3" class="ltx_tr" style="background-color:#E6E6FF;">
<td id="S1.T1.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.3.1.1" class="ltx_text" style="background-color:#E6E6FF;">Communication overhead</span></td>
<td id="S1.T1.1.3.2" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.3.2.1" class="ltx_text" style="background-color:#E6E6FF;">High</span></td>
<td id="S1.T1.1.3.3" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.3.3.1" class="ltx_text" style="background-color:#E6E6FF;">None</span></td>
<td id="S1.T1.1.3.4" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.3.4.1" class="ltx_text" style="background-color:#E6E6FF;">Low</span></td>
<td id="S1.T1.1.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.3.5.1" class="ltx_text" style="background-color:#E6E6FF;">Middle</span></td>
</tr>
<tr id="S1.T1.1.4" class="ltx_tr" style="background-color:#F5F5FF;">
<td id="S1.T1.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.4.1.1" class="ltx_text" style="background-color:#F5F5FF;">Model training</span></td>
<td id="S1.T1.1.4.2" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.4.2.1" class="ltx_text" style="background-color:#F5F5FF;">Remote</span></td>
<td id="S1.T1.1.4.3" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.4.3.1" class="ltx_text" style="background-color:#F5F5FF;">Local</span></td>
<td id="S1.T1.1.4.4" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.4.4.1" class="ltx_text" style="background-color:#F5F5FF;">Local</span></td>
<td id="S1.T1.1.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.4.5.1" class="ltx_text" style="background-color:#F5F5FF;">Collaborative</span></td>
</tr>
<tr id="S1.T1.1.5" class="ltx_tr" style="background-color:#E6E6FF;">
<td id="S1.T1.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.5.1.1" class="ltx_text" style="background-color:#E6E6FF;">Learning accuracy</span></td>
<td id="S1.T1.1.5.2" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.5.2.1" class="ltx_text" style="background-color:#E6E6FF;">High</span></td>
<td id="S1.T1.1.5.3" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.5.3.1" class="ltx_text" style="background-color:#E6E6FF;">Low</span></td>
<td id="S1.T1.1.5.4" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.5.4.1" class="ltx_text" style="background-color:#E6E6FF;">Middle</span></td>
<td id="S1.T1.1.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.5.5.1" class="ltx_text" style="background-color:#E6E6FF;">High</span></td>
</tr>
<tr id="S1.T1.1.6" class="ltx_tr" style="background-color:#F5F5FF;">
<td id="S1.T1.1.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.6.1.1" class="ltx_text" style="background-color:#F5F5FF;">Privacy protection</span></td>
<td id="S1.T1.1.6.2" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.6.2.1" class="ltx_text" style="background-color:#F5F5FF;">Low</span></td>
<td id="S1.T1.1.6.3" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.6.3.1" class="ltx_text" style="background-color:#F5F5FF;">High</span></td>
<td id="S1.T1.1.6.4" class="ltx_td ltx_align_center" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.6.4.1" class="ltx_text" style="background-color:#F5F5FF;">High</span></td>
<td id="S1.T1.1.6.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.6.5.1" class="ltx_text" style="background-color:#F5F5FF;">Middle</span></td>
</tr>
<tr id="S1.T1.1.7" class="ltx_tr" style="background-color:#E6E6FF;">
<td id="S1.T1.1.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.7.1.1" class="ltx_text" style="background-color:#E6E6FF;">Computation utilization</span></td>
<td id="S1.T1.1.7.2" class="ltx_td ltx_align_center ltx_border_b" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.7.2.1" class="ltx_text" style="background-color:#E6E6FF;">Middle</span></td>
<td id="S1.T1.1.7.3" class="ltx_td ltx_align_center ltx_border_b" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.7.3.1" class="ltx_text" style="background-color:#E6E6FF;">Low</span></td>
<td id="S1.T1.1.7.4" class="ltx_td ltx_align_center ltx_border_b" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.7.4.1" class="ltx_text" style="background-color:#E6E6FF;">Middle</span></td>
<td id="S1.T1.1.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding:2.5pt 8.0pt;"><span id="S1.T1.1.7.5.1" class="ltx_text" style="background-color:#E6E6FF;">High</span></td>
</tr>
</table>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this article, we discuss the advantages and drawbacks of typical ML paradigms (including CL, FL, and on-device learning), and argue that all of them face challenges hampering their success in practical IoT networks with data and device heterogeneity.
Especially for those low-end sensors having very few computing resources, they cannot do local model training, even though they collect large amounts of data.
To overcome these challenges, we propose a semi-federated learning (SemiFL) framework, where devices with sufficient computing resources (referred to as FL users) train models locally, while the remaining devices (referred to as CL users) upload their datasets to the base station (BS) for remote computation on their behalf.
Compared to typical ML paradigms with either fully centralized or fully local computing, such a two-tier computing framework is beneficial to boost resource utilization at the wireless edge.
The detailed comparisons of CL, FL and SemiFL frameworks are illustrated in Table <a href="#S1.T1" title="TABLE I ‣ I Introduction ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.
The main contributions of this article are summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose SemiFL integrating both CL and FL paradigms into a unified framework.
Geo-distributed resources (e.g., computing and storage) can be utilized more smartly by flexibly designating devices as different participants according to their computational capabilities.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">To alleviate the radio scarcity and meet the transmission requirements of SemiFL, we propose a learning-centric communication scheme, called next-generation multiple access (NGMA), by merging non-orthogonal multiple access (NOMA) with over-the-air computation (AirComp).
The joint design of communication and computation enables all users to concurrently transmit raw data and model parameters over shared channels.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">To achieve collaborative model training in energy-constrained networks with battery-limited IoT devices, we advocate a simultaneous wireless information and power transfer (SWIPT)-enabled SemiFL framework.
Additionally, we suggest a reconfigurable intelligent surface (RIS)-aided SemiFL to combat unfavorable signal propagation in wireless networks.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Typical ML Paradigms</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Depending on where the ML model training is performed, typical ML paradigms can be roughly classified into three categories: CL, FL, and on-device learning, as shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II Typical ML Paradigms ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2405.17453/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="336" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The first row illustrates three typical ML paradigms: CL, on-device learning, and FL. The second row demonstrates three common uplink transmission schemes for wireless FL, including orthogonal multiple access (OMA), NOMA, and AirComp.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">CL Paradigm</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Due to its excellent performance in most ML tasks, CL is often deployed in the cloud-based system that has rich datasets and powerful computing capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
However, CL may entail three key problems when implemented in IoT networks.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">High communication overhead:</span>
To support accurate environment perception and agile network control, a large number of sensors should be deployed in the field to collect real-time and multi-modal data with high resolution, which makes the data samples gathered at local devices large in size/quantity.
Therefore, the communication overhead is extremely high for the uplink wireless transmission when considering the limited bandwidth available at the network edge.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Privacy and security risk:</span>
Since the transmitted samples may contain privacy-sensitive information such as user preferences, habits or behaviors, there is a risk of information leakage.
This is especially worrisome when the signal propagation environment is untrusted due to the presence of eavesdroppers.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">Inference and execution delay:</span>
During the inference stage, inputs need to be uploaded to the BS for inference, and then outputs will be fed back to local devices.
The delay caused by uplink and downlink transmissions impairs the freshness of input data and output results, thus degrading the inference and execution efficiency of IoT devices.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">On-device Learning</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Owing to the self-learning setting, on-device learning has several promising advantages, including having no communication cost and protecting user privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Moreover, edge devices can infer on new samples directly, without the involvement of the BS, thus being capable of responding to tasks/events quickly.
However, implementing on-device learning among IoT devices still faces many issues.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Insufficient computing resources:</span>
While large-scale ML models have better performance in complex tasks, they also require a lot of computation/storage resources to conduct model training.
Due to the lack of powerful CPU/GPU, it is difficult for most IoT devices to complete local computation in a short period, which hampers the real-time model update.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Limited local datasets:</span>
Local training samples available on each device may be insufficient to train large-scale models like traditional CL.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_bold">Constrained energy supply:</span>
Due to their restricted costs, many devices are usually equipped with low-capacity batteries, which makes their operational lifetime very limited.
Moreover, once the device is deployed, it is hard and expensive to recharge or replace the battery.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">FL Paradigm</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Compared to on-device learning, FL achieves better performance while maintaining the advantages of privacy protection, fast response, and scalability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
However, FL also faces several challenges.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">Non-IID and unbalanced dataset:</span>
Considering the user-behavior difference, the data distributions among edge devices are likely to be statistically heterogeneous.
Furthermore, some IoT devices may be in a stable environment where data is generated slowly, while others may be in a fluctuating one.
These situations may result in varying dataset sizes at different devices, namely, unbalanced datasets.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p"><span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_bold">Heterogeneous computing capability:</span>
Every participating device in FL is required to have sufficient computational resources to conduct local learning.
But, in practice, some IoT devices do not have sufficient computing capabilities due to their inherent hardware implementation.
If we discard these computing-limited devices, then the performance of FL will be compromised, due to the loss of a large amount of training samples collected by these low-end devices.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p"><span id="S2.SS3.p4.1.1" class="ltx_text ltx_font_bold">Limited radio resources:</span>
Although transmitting model parameters is much more communication-efficient than sending raw data, FL requires a large number of communication rounds before achieving convergence.
Hence, the frequent information exchange between the BS and local devices still results in heavy traffic at the bandwidth-limited network edge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
In the second row of Fig. <a href="#S2.F1" title="Figure 1 ‣ II Typical ML Paradigms ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we summarize the commonly used uplink communication schemes for FL in wireless networks, including OMA, NOMA, and AirComp.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Proposed SemiFL Framework</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we propose a SemiFL framework by allowing all devices to participate in the learning process regardless of their computational capabilities and data distributions.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F2.sf1.1" class="ltx_block ltx_minipage ltx_align_top" style="width:195.1pt;">
<img src="/html/2405.17453/assets/x2.png" id="S3.F2.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="246" height="198" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Illustration of a generalized SemiFL framework. Some users upload raw data to the BS for model computation, while others update model gradients to the BS for global aggregation.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F2.sf2.1" class="ltx_block ltx_minipage ltx_align_top" style="width:195.1pt;">
<img src="/html/2405.17453/assets/x3.png" id="S3.F2.sf2.1.g1" class="ltx_graphics ltx_img_square" width="246" height="267" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>The learning process of SemiFL. The edge platform consists of a BS and a parameter server. The black dashed lines (blue solid lines) denote downlink (uplink) communications between the edge platform and IoT devices. The purple block indicates the data collection process. The blue (grey) blocks represent the local (global) computation processes.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The proposed SemiFL framework and its learning process.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">SemiFL Framework</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">A generalized SemiFL framework is illustrated in Fig. <a href="#S3.F2.sf1" title="In Figure 2 ‣ III Proposed SemiFL Framework ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2a</span></a>, where there are two groups of local devices, called CL users and FL users.
Specifically, devices with limited computational resources are designated as CL users to send their raw data to the edge platform, while the remaining devices are assigned as FL users to upload their model parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Note that even if the data distributions of these CL users are non-IID and unbalanced, the BS can approximately reconstruct an IID dataset by gathering the data from multiple CL users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
In the SemiFL, the datasets collected from CL users are used to train a CL model, while the models received from FL users are aggregated into a FL model.
Next, the trained CL model and the aggregated FL model are fused into one global model which is then distributed to all IoT devices for knowledge sharing.
Note that SemiFL having two computing layers can make full use of the computation and storage resources available at the network edge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Learning Process of SemiFL</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Unlike conventional CL and FL, the BS in SemiFL needs to schedule the data-uploading CL users and the gradient-updating FL users simultaneously for collaborative ML model training.
As illustrated in Fig. <a href="#S3.F2.sf2" title="In Figure 2 ‣ III Proposed SemiFL Framework ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2b</span></a>, there are six main steps in each communication round of SemiFL.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Step 1:</span>
At the beginning of each communication round, the BS requests the status information of all IoT devices.
Then, these devices send back their status information, e.g., communication, computation, and storage.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Step 2:</span>
According to their computational capabilities, all IoT devices are designated as communication-centric CL users (purple) or computation-centric FL users (blue).
Afterwards, the classification results are sent back to all the devices.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Step 3:</span>
All FL users need to compute their models on-device by using their local datasets, while these CL users are responsible for collecting data samples.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p"><span id="S3.SS2.p5.1.1" class="ltx_text ltx_font_bold">Step 4:</span>
The datasets collected by CL users and the model parameters computed by FL users are uploaded to the BS for further processing.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p"><span id="S3.SS2.p6.1.1" class="ltx_text ltx_font_bold">Step 5:</span>
Using the datasets gathered from CL users, the BS trains a CL model in a centralized manner, and then aggregates it with the FL model to obtain a global model.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p"><span id="S3.SS2.p7.1.1" class="ltx_text ltx_font_bold">Step 6:</span>
At the end of each communication round, the BS broadcasts the global model to all local devices.
The above steps are repeated until the stop criterion is reached.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">SemiFL Relying on NGMA</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we first propose an NGMA scheme for satisfying the uplink transmission requirement of SemiFL in the bandwidth-limited IoT network.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2405.17453/assets/x4.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="500" height="393" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Schematic diagram of the proposed NGMA-based SemiFL framework and its transceiver design.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">NGMA Scheme</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The bandwidth of existing IoT networks is often very limited.
To solve the conflict between the communication-centric CL users and the computation-centric FL users, we propose an NGMA scheme to enable the learning-centric uplink transmission for these computing-heterogeneous users in SemiFL. As shown in Fig. <a href="#S4.F3" title="Figure 3 ‣ IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, our NGMA scheme integrates NOMA-based data transmission and AirComp-based gradient aggregation into a unified framework by fully exploiting the superposition property of wireless channels.
By simultaneously serving CL and FL users over the shared channel, the distributed datasets and model gradients from the two sets of users can be gathered in a spectrum-efficient manner.
Due to the concurrent transmission, an efficient interference management technique should be adopted in this <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">joint-communication-and-computation</span> scheme to improve the throughput of CL users while reducing the computation distortion of FL users.
Recalling the basic principle of successive interference cancellation (SIC), the user having strongest channel condition can be decoded first, and then its signal is removed from the received superposition signal to obtain the composite signal composed of weaker users, and so on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
This perfectly matches the signal processing needs of SemiFL, where the signal of each CL user is expected to be decoded individually, while the signal of FL users should be superposed synthetically.
As a result, we adopt SIC at the BS side to separate the superimposition signal received from the two sets of users having different transmission goals.
To obtain the desired signal, we apply receive beamforming at the receiver side to arrange CL users to be strong users having large values of effective channel coefficients, while arranging FL users to be weak users having small values <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
Then, the individual signals of all strong CL users are decoded one by one, and subsequently removed from the superimposition signal to obtain the aggregated signal of weak FL users.
Such a signal processing process can exactly meet the uplink transmission requirements of SemiFL.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">NGMA-Based SemiFL</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Fig. <a href="#S4.F3" title="Figure 3 ‣ IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the model training process of NGMA-based SemiFL framework in one communication round (i.e., Steps 3-6 depicted in Section <a href="#S3.SS2" title="III-B Learning Process of SemiFL ‣ III Proposed SemiFL Framework ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>).
The bottom half of Fig. <a href="#S4.F3" title="Figure 3 ‣ IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> provides the signal processing process and the corresponding transceiver design.
Specifically, during the uplink transmission, local datasets of CL users are first encoded as communication symbols and local gradients of FL users are pre-processed as computation symbols.
Then, these information symbols of all users are transmitted concurrently over the shared wireless channel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
As stated in Section <a href="#S4.SS1" title="IV-A NGMA Scheme ‣ IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>, the BS first applies SIC to decode the individual dataset of CL users for global training.
After removing the signal of CL users, the weighted sum of local gradients can be obtained by carefully designing the transmit and receive strategies.
At last, the global model is updated by the gradient information obtained from both CL and FL users.
To gain insight into the learning behavior of SemiFL, the exact expressions of the convergence performance are derived in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> for characterizing the impacts of learning rates and wireless communications.
The theoretical results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> show that the SemiFL is able to converge sub-linearly, but there exists a non-vanishing error floor even if the communication round approaches infinity.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F4.sf1.1" class="ltx_block ltx_minipage ltx_align_top" style="width:390.3pt;">
<img src="/html/2405.17453/assets/x5.png" id="S4.F4.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="500" height="299" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>An illustration of the SWIPT-enabled SemiFL system.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F4.sf2.1" class="ltx_block ltx_minipage ltx_align_top" style="width:390.3pt;">
<img src="/html/2405.17453/assets/x6.png" id="S4.F4.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="217" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>An illustration of the STAR-RIS-aided SemiFL system.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Integrating SemiFL with emerging SWIPT and STAR-RIS techniques, respectively.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">SemiFL in Unfavorable Scenarios</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we integrate SemiFL with SWIPT and simultaneously transmitting and reflecting RIS (STAR-RIS) to tackle the issues raised by unfavorable scenarios, such as battery-limited devices and weak signal coverage.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">SWIPT-Enabled SemiFL</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">In remote rural areas, a large number of IoT monitoring devices are battery-limited.
For these devices with low battery capacity, the maintenance cost is relatively high.
As a result, the battery issue of IoT devices deserves the same attention as the concerns about communication efficiency.
To overcome the energy scarcity problem in IoT networks, one promising approach is to provide the energy harvesting capability to these battery-limited devices, which allows them to continually acquire radio frequency energy from the associated BS.
In this light, the combination of SemiFL and energy harvesting is able to guarantee the virtually perpetual operation of battery-limited IoT devices, as long as their hardware works well.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">In order to get rid of the energy storage limitation faced by IoT devices, we advocate a SWIPT-enabled SemiFL framework by allowing the BS to transfer wireless energy to these battery-limited devices in a stable and controllable manner.
As shown in Fig. <a href="#S4.F4.sf1" title="In Figure 4 ‣ IV-B NGMA-Based SemiFL ‣ IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4a</span></a>, the main process of SWIPT-enabled SemiFL follows the <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_italic">harvest-then-learn</span> protocol <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
Specifically, in the first time slot, both wireless information (i.e., global model parameters) and power are conveyed to all devices simultaneously over the same frequency band.
After harvesting sufficient energy from the BS, these IoT devices start to collect data samples and conduct local learning in the second time slot.
Next, the newly sensed data of CL users and the updated model parameters of FL users are sent to the BS in the third time slot.
Finally, the decoded CL datasets are used to improve the prediction accuracy of the aggregated FL model in the fourth time slot.
One may notice that the details of the above last three time slots are the same as that of Steps 3-5 mentioned in Section <a href="#S3.SS2" title="III-B Learning Process of SemiFL ‣ III Proposed SemiFL Framework ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>.
Hence, the similar introduction of the uplink transmission is omitted here for brevity.
Despite the advantages brought by energy harvesting (e.g., self-sustainability and flexibility), it also causes several new problems if we expect to build a high-performance SWIPT-enabled SemiFL system.
For example, the hardware design of IoT devices should be modified to comprise both information decoding and energy harvesting modules.
In addition, the rate-energy tradeoff between information and power should be balanced carefully by optimizing the power splitting ratio at IoT devices.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">STAR-RIS-Aided SemiFL</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Due to the blockage, wireless networks may encounter coverage holes
Additionally, as stated in Section <a href="#S4.SS1" title="IV-A NGMA Scheme ‣ IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>, the proposed NGMA scheme needs to coordinate the concurrent transmission of CL and FL users by arranging their decoding order determined by the channel condition.
However, the traditional wireless environment is considered to be fixed and cannot be flexibly modified on demand, but only compensated by the design of complex transceivers.
At present, an innovative concept of RIS has been conceived to treat the wireless environment as a controllable optimization variable.
It improves the coverage area of the existing network and can be used to overcome the unfavorable link blocking problem.
In order to further enhance the learning performance of SemiFL with the aid of a dual-functional metasurface, we propose a STAR-RIS-aided SemiFL framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
This framework is capable of improving the communication efficiency of CL users and reducing the aggregation distortion of FL users by leveraging the STAR-RIS to mitigate interference and to align channel.
As shown in Fig. <a href="#S4.F4.sf2" title="In Figure 4 ‣ IV-B NGMA-Based SemiFL ‣ IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4b</span></a>, the STAR-RIS is deployed in proximity to local users to relay their signals to the BS by establishing extra communication links.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Compared to the pure SemiFL in Section <a href="#S4" title="IV SemiFL Relying on NGMA ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> where only the transmission and reception schemes can be optimized, the STAR-RIS-aided SemiFL framework has the following merits.
First, the introduced STAR-RIS can be leveraged to change the channel quality of individual users constructively or destructively by adjusting the reflection/refraction coefficients as well as its deployment location <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
This enables a more flexible decoding order design for CL users who use NOMA to upload local datasets.
Second, the STAR-RIS introduces new degrees of freedom that can be further utilized to match the desired weighted sum of input parameters, thus reducing the aggregation distortion of FL users who use AirComp to update local models.
Third, the STAR-RIS is compatible with existing systems, and it can be easily integrated into heterogeneous IoT networks, yet without the need of extra time slots or new protocol design.
Therefore, the learning process and transceiver design of the STAR-RIS-aided SemiFL framework are the same as that of the pure one, in addition to taking into account the optimization of the STAR-RIS configuration.
Our experimental results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> showed that the spectral efficiency of SemiFL can be significantly improved by the STAR-RIS at a low energy cost.</p>
</div>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S5.F5.sf1.1" class="ltx_block ltx_minipage ltx_align_top" style="width:216.8pt;">
<img src="/html/2405.17453/assets/x7.png" id="S5.F5.sf1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="284" height="213" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Training loss vs. the number of communication rounds</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S5.F5.sf2.1" class="ltx_block ltx_minipage ltx_align_top" style="width:216.8pt;">
<img src="/html/2405.17453/assets/x8.png" id="S5.F5.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="284" height="213" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Test accuracy vs. the number of communication rounds</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Learning performance of training a CNN on the MNIST dataset: (a) training loss, and (b) test accuracy.</figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Simulation Results</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">To demonstrate the effectiveness of our proposed SemiFL frameworks, we compare our SemiFL schemes with three benchmarks:
1) Conventional CL: all users send their datasets to the BS for centralized training;
2) AirComp-based FL: all users conduct local learning and upload their model gradients using AirComp;
3) Fixed beamforming: the transceiver design remains the same over different communication rounds.
In Fig. <a href="#S5.F5" title="Figure 5 ‣ V-B STAR-RIS-Aided SemiFL ‣ V SemiFL in Unfavorable Scenarios ‣ Semi-Federated Learning for Internet of Intelligence" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we show the SemiFL performance on the classification task using MNIST dataset.
From this figure, we can observe that the STAR-RIS-aided SemiFL approaches the conventional CL scheme having ideal model updates, and our SemiFL frameworks outperform the AirComp-based FL and fixed beamforming schemes.
First, this reveals that the FL performance can be further improved by using the raw data uploaded by these computing-limited CL users.
Second, this demonstrates that dynamically adjusting the transceiver design is beneficial to significantly alleviate the negative effect of noisy fading channels on the achievable learning performance.
Moreover, we notice that the STAR-RIS-aided SemiFL is able to achieve higher test accuracy than the counterpart without RIS.
This is mainly because the STAR-RIS not only helps to improve the overall throughput of NOMA-based CL users, but also contributes to reducing the aggregation error of AirComp-based FL users.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this article, a SemiFL framework has been proposed by integrating the conventional CL and FL into a harmonized framework, in which all IoT devices are allowed to collaboratively train a shared model even in the presence of low-computing devices and non-IID datasets.
Through reaping the merits of existing ML paradigms, our SemiFL framework achieves lower training loss and better prediction accuracy than FL, while having less communication cost than CL.
Additionally, a learning-centric NGMA uplink transmission scheme has been designed to meet SemiFL requirements of data uploading and model aggregation in a spectrum-efficient manner.
Furthermore, the STAR-RIS and the SWIPT have been incorporated with SemiFL to further tackle the challenging issues faced by intelligent IoT networks, such as operational stability, limited bandwidth, and constrained battery capacity.
Experimental results showed that our SemiFL framework is a competitive solution for the realization of pervasive intelligence at the wireless edge.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M. Chen, U. Challita, W. Saad <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Artificial neural networks-based
machine learning for wireless networks: A tutorial,” <em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">IEEE Commun.
Surveys Tut.</em>, vol. 21, no. 4, pp. 3039–3071, Fourthquarter 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Q. Zhou, Z. Qu, S. Guo <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “On-device learning systems for edge
intelligence: A software and hardware synergy perspective,” <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">IEEE
Internet Things J.</em>, vol. 8, no. 15, pp. 11 916–11 934, Aug. 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
K. Yang, Y. Shi, Y. Zhou <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated machine learning for
intelligent IoT via reconfigurable intelligent surface,” <em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic">IEEE
Netw.</em>, vol. 34, no. 5, pp. 16–22, Sept. 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
W. Ni, Y. Liu, Z. Yang <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning in multi-RIS-aided
systems,” <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, vol. 9, no. 12, pp. 9608–9624,
Jun. 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
G. Zhu, D. Liu, Y. Du <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Toward an intelligent edge: Wireless
communication meets machine learning,” <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">IEEE Commun. Mag.</em>, vol. 58,
no. 1, pp. 19–25, Jan. 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T. Gafni, N. Shlezinger, K. Cohen <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning: A signal
processing perspective,” <em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">IEEE Signal Process. Mag.</em>, vol. 39, no. 3,
pp. 14–41, May 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
X. Cao, G. Zhu, J. Xu <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Optimized power control design for
over-the-air federated edge learning,” <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">IEEE J. Sel. Areas Commun.</em>,
vol. 40, no. 1, pp. 342–358, Jan. 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
D. Gündüz, D. B. Kurka, M. Jankowski <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Communicate to learn at
the edge,” <em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">IEEE Commun. Mag.</em>, vol. 58, no. 12, pp. 14–19, Dec. 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
W. Ni, J. Zheng, and H. Tian, “Semi-federated learning for collaborative
intelligence in massive IoT networks,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>,
vol. 10, no. 13, pp. 11 942–11 943, Jul. 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
N. Yoshida, T. Nishio, M. Morikura <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Hybrid-FL for wireless
networks: Cooperative learning mechanism using non-IID data,” in
<em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE ICC</em>, Dublin, Ireland, Jun. 2020, pp. 1–7.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J. Zheng, W. Ni, H. Tian <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Semi-federated learning: Convergence
analysis and optimization of a hybrid learning framework,” <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">IEEE Trans.
Wireless Commun.</em>, vol. 22, no. 12, pp. 9438–9456, Dec. 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
W. Ni, Y. Liu, Z. Yang <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Integrating over-the-air federated
learning and non-orthogonal multiple access: What role can RIS play?”
<em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol. 21, no. 12, pp. 10 083–10 099,
Dec. 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Han, W. Ni, and L. Li, “Semi-federated learning for connected intelligence
with computing-heterogeneous devices,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, early
access, 2024.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
W. Ni, Y. Liu, Y. C. Eldar <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “STAR-RIS integrated
non-orthogonal multiple access and over-the-air federated learning:
Framework, analysis, and optimization,” <em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>,
vol. 9, no. 18, pp. 17 136–17 156, Sept. 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
X. Zhang, H. Tian, W. Ni <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep reinforcement learning for
energy efficiency maximization in swipt-based over-the-air federated
learning,” <em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on Green Communications and Networking</em>,
vol. 8, no. 1, pp. 525–541, Mar. 2024.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.17452" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.17453" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.17453">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.17453" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.17454" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 15:57:38 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
