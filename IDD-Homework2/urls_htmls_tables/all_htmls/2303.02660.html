<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.02660] SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data</title><meta property="og:description" content="Recently, significant progress has been made in face presentation attack detection (PAD), which aims to secure face recognition systems against presentation attacks, owing to the availability of several face PAD datase‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.02660">

<!--Generated on Thu Feb 29 20:45:19 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Meiling Fang<sup id="id6.6.id1" class="ltx_sup"><span id="id6.6.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Marco Huber<sup id="id7.7.id2" class="ltx_sup"><span id="id7.7.id2.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Naser Damer<sup id="id8.8.id3" class="ltx_sup"><span id="id8.8.id3.1" class="ltx_text ltx_font_italic">1,2</span></sup> 
<br class="ltx_break"><sup id="id9.9.id4" class="ltx_sup"><span id="id9.9.id4.1" class="ltx_text ltx_font_italic">1</span></sup>Fraunhofer Institute for Computer Graphics Research IGD,
Darmstadt, Germany
<br class="ltx_break"><sup id="id10.10.id5" class="ltx_sup"><span id="id10.10.id5.1" class="ltx_text ltx_font_italic">2</span></sup>Department of Computer Science, TU Darmstadt,
Darmstadt, Germany
<br class="ltx_break">Email: meiling.fang@igd.fraunhofer.de
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">Recently, significant progress has been made in face presentation attack detection (PAD), which aims to secure face recognition systems against presentation attacks, owing to the availability of several face PAD datasets. However, all available datasets are based on privacy and legally-sensitive authentic biometric data with a limited number of subjects.
To target these legal and technical challenges, this work presents the first synthetic-based face PAD dataset, named SynthASpoof, as a large-scale PAD development dataset.
The bona fide samples in SynthASpoof are synthetically generated and the attack samples are collected by presenting such synthetic data to capture systems in a real attack scenario.
The experimental results demonstrate the feasibility of using SynthASpoof for the development of face PAD.
Moreover, we boost the performance of such a solution by incorporating the domain generalization tool MixStyle into the PAD solutions.
Additionally, we showed the viability of using synthetic data as a supplement to enrich the diversity of limited authentic training data and consistently enhance PAD performances. The SynthASpoof dataset, containing 25,000 bona fide and 78,800 attack samples, the implementation, and the pre-trained weights are made publicly available <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/meilfang/SynthASpoof.git" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/meilfang/SynthASpoof.git</a></span></span></span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Due to its outstanding performance, face recognition has been widely used in various aspects of our daily lives, such as access control, phone unlocking, and mobile payments. However, face recognition is vulnerable to presentation attacks (PAs) including print attacks, video replay attacks, and 3D mask attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Therefore, face presentation attack detection (PAD), referring to the process of identifying whether a face presented to the system is a bona fide (live) or PA (spoof), is essential to secure face recognition from PAs.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">With the advancements in deep learning technology, face PAD algorithms have made great progress. One of the main contributors to this advance is the face PAD datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
However, these datasets utilized for developing data-driven PAD solutions are built on authentic biometric data, which might raise ethical and legal challenges.
This concern has recently been discussed in both the face recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and face morphing attack detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> communities. Given the legal privacy regulations, the collection, use, share, and maintenance of face data for biometric processing is extremely challenging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. For example, several large-scale face recognition datasets, such as VGGFace2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, MS-Celeb-1M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and MegaFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, were withdrawn by their creators with privacy and proper subjects consent issues being the main drive.
One of the main candidate solutions for this issue is the use of synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. This has been very recently and successfully proposed for the training of face recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and morphing attack detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, among other processes such as model quantization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Synthetic data for PAD development has, besides the privacy and legal motivations, a major advantage when it comes to scale and diversity.
While most existing face PAD datasets are of a small-scale with a limited number of subjects, creating a synthetic-based PAD development data enables to produce a large-scale dataset in terms of both, the number of samples and the number of different faces.
</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Motivated by the legal and ethical challenges in using, sharing, and collecting authentic biometric data along with the limitation in the scale and diversity in existing datasets, this work poses the question of ‚Äùcan synthetic data be used for the development of face PAD?‚Äù.
This is based on our assumption that learning to detect the differences between bona fide and attack samples of a synthetic origin can be used to detect these differences between authentic bona fide and attacks, and thus perform PAD.
Towards that, we introduce <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">the first privacy-friendly synthetic-based face PAD (Anti-Spoofing) dataset, SynthASpoof</span>, consisting of 25,000 bona fide and 78,800 attack samples.
The bona fide samples are created by using StyleGAN2-ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, while the attack samples are collected by presenting these synthetic samples as printed/replayed attacks to varied capture sensors.
Samples of the SynthASpoof are shown in Fig. <a href="#S3.F1" title="Figure 1 ‚Ä£ 3 SynthASpoof Dataset ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Based on the SynthASpoof dataset, we then conduct extensive experiments to <span id="S1.p3.1.2" class="ltx_text ltx_font_bold">explore the feasibility of using synthetic data for the development of face PADs</span>. Subsequently, we propose to <span id="S1.p3.1.3" class="ltx_text ltx_font_bold">adapt MixStyle <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> to enhance the generalizability of models trained on SynthASpoof</span>. Furthermore, we <span id="S1.p3.1.4" class="ltx_text ltx_font_bold">successfully propose supplementing the authentic training data with the synthetic SynthASpoof to achieve even higher PAD performances</span>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<figure id="S2.T1" class="ltx_table">
<div id="S2.T1.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:447.2pt;height:107pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-115.0pt,27.5pt) scale(0.660409228898734,0.660409228898734) ;">
<table id="S2.T1.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.2.2.3.1" class="ltx_tr">
<th id="S2.T1.2.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Dataset</th>
<th id="S2.T1.2.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Year</th>
<th id="S2.T1.2.2.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"># Bona fide/attack</th>
<th id="S2.T1.2.2.3.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"># Sub</th>
<th id="S2.T1.2.2.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Attack types</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.2.2.4.1" class="ltx_tr">
<td id="S2.T1.2.2.4.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">CASIA-FASD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
<td id="S2.T1.2.2.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">2012</td>
<td id="S2.T1.2.2.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">150 / 450 (V)</td>
<td id="S2.T1.2.2.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">50</td>
<td id="S2.T1.2.2.4.1.5" class="ltx_td ltx_align_center ltx_border_tt">1 Print, 1 Replay</td>
</tr>
<tr id="S2.T1.2.2.5.2" class="ltx_tr">
<td id="S2.T1.2.2.5.2.1" class="ltx_td ltx_align_center ltx_border_r">Replay-Attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S2.T1.2.2.5.2.2" class="ltx_td ltx_align_center ltx_border_r">2012</td>
<td id="S2.T1.2.2.5.2.3" class="ltx_td ltx_align_center ltx_border_r">200 / 1,000 (V)</td>
<td id="S2.T1.2.2.5.2.4" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S2.T1.2.2.5.2.5" class="ltx_td ltx_align_center">1 Print, 2 Replay</td>
</tr>
<tr id="S2.T1.2.2.6.3" class="ltx_tr">
<td id="S2.T1.2.2.6.3.1" class="ltx_td ltx_align_center ltx_border_r">MSU-MFSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>
</td>
<td id="S2.T1.2.2.6.3.2" class="ltx_td ltx_align_center ltx_border_r">2015</td>
<td id="S2.T1.2.2.6.3.3" class="ltx_td ltx_align_center ltx_border_r">70 / 210 (V)</td>
<td id="S2.T1.2.2.6.3.4" class="ltx_td ltx_align_center ltx_border_r">35</td>
<td id="S2.T1.2.2.6.3.5" class="ltx_td ltx_align_center">1 Print, 2 Replay</td>
</tr>
<tr id="S2.T1.2.2.7.4" class="ltx_tr">
<td id="S2.T1.2.2.7.4.1" class="ltx_td ltx_align_center ltx_border_r">OULU-NPU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</td>
<td id="S2.T1.2.2.7.4.2" class="ltx_td ltx_align_center ltx_border_r">2017</td>
<td id="S2.T1.2.2.7.4.3" class="ltx_td ltx_align_center ltx_border_r">1,980 / 3,960 (V)</td>
<td id="S2.T1.2.2.7.4.4" class="ltx_td ltx_align_center ltx_border_r">55</td>
<td id="S2.T1.2.2.7.4.5" class="ltx_td ltx_align_center">2 Print,2 Replay</td>
</tr>
<tr id="S2.T1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">SiW-M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>
</td>
<td id="S2.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">2019</td>
<td id="S2.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">660 / 968 (V)</td>
<td id="S2.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r">493<sup id="S2.T1.1.1.1.1.1" class="ltx_sup">‚àó</sup>
</td>
<td id="S2.T1.1.1.1.5" class="ltx_td ltx_align_center">1 Print, 1 Replay, 5 3D Mask, 3 Make Up, 3 Partial</td>
</tr>
<tr id="S2.T1.2.2.2" class="ltx_tr">
<td id="S2.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r">CelebA-Spoof <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>
</td>
<td id="S2.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r">2020</td>
<td id="S2.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r">184,407 / 377,168(I)</td>
<td id="S2.T1.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r">10,177<sup id="S2.T1.2.2.2.1.1" class="ltx_sup">‚àó</sup>
</td>
<td id="S2.T1.2.2.2.5" class="ltx_td ltx_align_center">3 Print, 3 Replay, 1 3D, 3 Paper Cut</td>
</tr>
<tr id="S2.T1.2.2.8.5" class="ltx_tr">
<td id="S2.T1.2.2.8.5.1" class="ltx_td ltx_align_center ltx_border_r">PADISI-Face <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S2.T1.2.2.8.5.2" class="ltx_td ltx_align_center ltx_border_r">2021</td>
<td id="S2.T1.2.2.8.5.3" class="ltx_td ltx_align_center ltx_border_r">1,105 / 924 (V)</td>
<td id="S2.T1.2.2.8.5.4" class="ltx_td ltx_align_center ltx_border_r">360</td>
<td id="S2.T1.2.2.8.5.5" class="ltx_td ltx_align_center">1 Print, 4 Mask, 1 Makeup, 1 Tattoo, 2 Partial</td>
</tr>
<tr id="S2.T1.2.2.9.6" class="ltx_tr">
<td id="S2.T1.2.2.9.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">SynthASpoof</td>
<td id="S2.T1.2.2.9.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">2023</td>
<td id="S2.T1.2.2.9.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">25,000 / 78,800 (I&amp;V)</td>
<td id="S2.T1.2.2.9.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">25,000</td>
<td id="S2.T1.2.2.9.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">1 Print, 3 Replay</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.5.2" class="ltx_text" style="font-size:90%;">Summary of the public face PAD datasets. V and I are shorthand for video and image, respectively. Subject number with ‚Äô*‚Äô denotes the subjects are partially or all from the web. Note the limited scale of most datasets and the fact that the larger ones are based on web-collected images.</span></figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In the last decade, many face PAD datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> have been collected and made available to support the development of PAD algorithms. The face PAD datasets can be broadly categorized into four groups based on the type of attacks and sensors: multi-modal 3D attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, multi-modal 2D attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, single-modal 3D attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, and single-modal 2D attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Multi-modal datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> used multiple sensors in addition to visible cameras, such as depth and infrared cameras, providing more options for face PAD solutions. However, such datasets have limitations in real-world deployment due to the cost of sensors and computation resources. 3D attacks are more realistic than traditional 2D attacks. The HiFiMask <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> dataset is the largest and most recent 3D face mask PAD dataset, collected from 75 subjects and including three mask attacks. However, HiFiMask dataset has a limited number of subjects and mask materials due to the higher cost of 3D mask creation compared to 2D attacks. Most 2D face PAD datasets (as seen in Table <a href="#S2.T1" title="Table 1 ‚Ä£ 2 Related Work ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) are outdated due to their acquisition equipment and have limited numbers of subjects and samples, leading to a potential over-fitting risk.
SiW-M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, PADISI-Face <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, and CelebA-Spoof <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> are relatively up-to-date and large-scale datasets, where CelebA-Spoof and part of the SiW-M dataset were collected from the web. Many of the existing face PAD datasets have ethical and legal issues that limit their public availability and raise concerns about sharing and reusing biometric information of individuals, driving some researches to keep their developed datasets private <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. For example, SiW-M is currently inaccessible. In addition to privacy issues, CelebA-spoof has several limitations: 1) numerous label noise, 2) low quality attack samples, which contradict the fact that attackers commonly use highly sophisticated artifacts to maximize their impersonation success probability, and 3) no consent of all involved individuals.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Overall, existing face PAD datasets have two primary limitations. First, the collection, use, and share of such data pose ethical and legal challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Second, the scale of the existing face PAD datasets may not be sufficient to develop over-parameterized deep learning based PAD solutions.
This highlights the need for face PAD development datasets that prioritize the privacy of individuals, the shareability of data in the research community, and the reproducibility and continuity of face PAD research.
To address these concerns, we propose the use of synthetic data for the development of face PAD. Our synthetic SynthASpoof data contains of 25,000 bona fide samples and 78,800 attack samples (details in Section <a href="#S3" title="3 SynthASpoof Dataset ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>SynthASpoof Dataset</h2>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2303.02660/assets/x1.png" id="S3.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="424" height="376" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.4.2" class="ltx_text" style="font-size:90%;">Samples of the SynthASpoof dataset. The left column shows bona fide samples. The second to last column show different attack samples collected from the corresponding bona fide images. In the case of replay attacks, three sensors (webcam, Samsung phone, and iPad) were used to capture the attacks displayed on different screens. </span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Despite the significance of publicly available datasets in promoting the progress of face PAD and being valuable sources for the research community, legal, ethical and privacy concerns, as well as the limited size and diversity of the datasets pose challenges to the development of generalized PAD solutions.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">This section introduces our SynthASpoof dataset (samples are shown in Fig. <a href="#S3.F1" title="Figure 1 ‚Ä£ 3 SynthASpoof Dataset ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), which is the first synthetic-based face PAD dataset. The dataset is built based on the image synthesis and selection procedure presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
To follow realistic attack scenarios appearing in authentic data attacks, the attack samples are created based on the synthetic bona fide data by presenting printed and replayed images to capture sensors.
This aims at fulfilling our assumption that the difference between authentic bona fide and authentic-based attacks induced by the attack process can also be induced by the same attack process using synthetic data. Thus, learning to detect this difference on synthetic data will enable detecting it in authentic-based attacks.
</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">Bona Fide Samples:</span>
First, 125,000 images were created by using the StyleGAN2-ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> trained on Flickr-Faces-HQ dataset (FFHQ) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. The pretrained model produced a synthetic face data for each latent vector that was randomly non-repeatedly generated based on Gaussian noise.
These images were then filtered automatically by using the CR-FIQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> face image utility assessment approach, where extreme non-frontal poses and largely occluded images were mostly removed by removing the images with the lowest utility score. This helps simulate the real log-in face recognition scenario that is commonly targeted by PAs.
Finally, SynthASpoof contains 25,000 bona fide samples.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.2" class="ltx_p"><span id="S3.p4.2.1" class="ltx_text ltx_font_bold">Attack Samples:</span> SynthASpoof contains two attack types, print and replay attacks.
For the print attacks 3,800 videos of distinct synthetic subjects were captured using a Samsung Galaxy Tablet S6.
For the more challenging replay attack, we introduce diverse display and capture setups.
First, attacks displayed on a MacBook Air 2020 screen were captured using both a Samsung Galaxy A71 and an iPad Pro 10.5 (both with a resolution of <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="1920\times 1080" display="inline"><semantics id="S3.p4.1.m1.1a"><mrow id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mn id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">1920</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p4.1.m1.1.1.1" xref="S3.p4.1.m1.1.1.1.cmml">√ó</mo><mn id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml">1080</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><times id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1.1"></times><cn type="integer" id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">1920</cn><cn type="integer" id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3">1080</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">1920\times 1080</annotation></semantics></math>).
Additionally, attacks displayed on a Dell UltraSharp 24 display were captured using a Creative Labs webcam with a resolution of <math id="S3.p4.2.m2.1" class="ltx_Math" alttext="720\times 480" display="inline"><semantics id="S3.p4.2.m2.1a"><mrow id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml"><mn id="S3.p4.2.m2.1.1.2" xref="S3.p4.2.m2.1.1.2.cmml">720</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p4.2.m2.1.1.1" xref="S3.p4.2.m2.1.1.1.cmml">√ó</mo><mn id="S3.p4.2.m2.1.1.3" xref="S3.p4.2.m2.1.1.3.cmml">480</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><apply id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1"><times id="S3.p4.2.m2.1.1.1.cmml" xref="S3.p4.2.m2.1.1.1"></times><cn type="integer" id="S3.p4.2.m2.1.1.2.cmml" xref="S3.p4.2.m2.1.1.2">720</cn><cn type="integer" id="S3.p4.2.m2.1.1.3.cmml" xref="S3.p4.2.m2.1.1.3">480</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">720\times 480</annotation></semantics></math>.
All the 25,000 images were used as an attack on each setup resulting in a total of 75,000 replay attack clips.
All attack captures (print and replay) were cropped so that they do not include any region outside of the displayed attack image (e.g. screen border).
All captured attacks are videos with a duration ranging from 3 to 5 seconds, from each of these videos the single frame in the middle of the video is also extracted as a single image attack used in our training.
Both, the videos and the images of the SynthaSpoof dataset are publicly released and can be used to develop PAD solutions based on synthetic data.
</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Comparing to existing face PAD datasets, the proposed SynthASpoof dataset provides three advantages: <span id="S3.p5.1.1" class="ltx_text ltx_font_bold">1) Privacy-friendly:</span> SynthASpoof is the first synthetic face PAD dataset which relaxes the pure dependence on the legally and ethically challenging use of authentic development data. <span id="S3.p5.1.2" class="ltx_text ltx_font_bold">2) Large-scale and high-quality samples</span>:
As discussed in Section <a href="#S2" title="2 Related Work ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, most existing datasets are of small scale, the only relatively larger and diverse dataset is the CelebA-Spoof <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. However, some of its bona fide samples might be falsely annotated and many of the attack samples exhibit severe distortion and low quality, as they were collected from the web (which is a orivacy issue by itself) without proper control or post-processing checks.
In contrast, the bona fide samples in SynthASpoof were checked by face image quality control and the attack samples were collected in a controlled manner to reflect the fact that attackers usually use highly sophisticated artifacts to maximize their success in impersonation. <span id="S3.p5.1.3" class="ltx_text ltx_font_bold">3) Extensibility:</span> researchers can build subsequent synthetic-based face PAD datasets by increasing the diversity of attack types.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>PAD Solutions</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To assess the suitability of using SynthASpoof for the development of face PAD, we adopt two of the commonly used face PAD backbones, ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and PixBis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. The selection of these two backbones was based on their wide use, representing two common supervision strategies in face PAD, and reported good performance in previous studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Base Presentation Attack Detectors</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.3" class="ltx_p"><span id="S4.SS1.p1.3.1" class="ltx_text ltx_font_bold">ResNet</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> is one of the most popular backbone architectures used in face PAD algorithm design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. We report the results of a model trained from scratch based on the ResNet-18 model architecture. A cross-entropy loss function is used in the training phase and formulated as follows:</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.2" class="ltx_Math" alttext="\mathcal{L}_{CE}=-[y\cdot\log p+(1-y)\cdot\log(1-p)]," display="block"><semantics id="S4.E1.m1.2a"><mrow id="S4.E1.m1.2.2.1" xref="S4.E1.m1.2.2.1.1.cmml"><mrow id="S4.E1.m1.2.2.1.1" xref="S4.E1.m1.2.2.1.1.cmml"><msub id="S4.E1.m1.2.2.1.1.3" xref="S4.E1.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.2.2.1.1.3.2" xref="S4.E1.m1.2.2.1.1.3.2.cmml">‚Ñí</mi><mrow id="S4.E1.m1.2.2.1.1.3.3" xref="S4.E1.m1.2.2.1.1.3.3.cmml"><mi id="S4.E1.m1.2.2.1.1.3.3.2" xref="S4.E1.m1.2.2.1.1.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.1.1.3.3.1" xref="S4.E1.m1.2.2.1.1.3.3.1.cmml">‚Äã</mo><mi id="S4.E1.m1.2.2.1.1.3.3.3" xref="S4.E1.m1.2.2.1.1.3.3.3.cmml">E</mi></mrow></msub><mo id="S4.E1.m1.2.2.1.1.2" xref="S4.E1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E1.m1.2.2.1.1.1" xref="S4.E1.m1.2.2.1.1.1.cmml"><mo id="S4.E1.m1.2.2.1.1.1a" xref="S4.E1.m1.2.2.1.1.1.cmml">‚àí</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E1.m1.2.2.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.2.1.cmml">[</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.4" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.cmml"><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.4.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.2.cmml">y</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.2.2.1.1.1.1.1.1.4.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.1.cmml">‚ãÖ</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.4.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.cmml"><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.1.cmml">log</mi><mo lspace="0.167em" id="S4.E1.m1.2.2.1.1.1.1.1.1.4.3a" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.cmml">‚Å°</mo><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.2.cmml">p</mi></mrow></mrow><mo id="S4.E1.m1.2.2.1.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.3.cmml">+</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.cmml"><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">‚àí</mo><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo rspace="0.055em" stretchy="false" id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.E1.m1.2.2.1.1.1.1.1.1.2.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml">‚ãÖ</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml"><mi id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">log</mi><mo id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1a" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">‚Å°</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml"><mo stretchy="false" id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">(</mo><mrow id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.cmml"><mn id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2.cmml">1</mn><mo id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1.cmml">‚àí</mo><mi id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.cmml">p</mi></mrow><mo stretchy="false" id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S4.E1.m1.2.2.1.1.1.1.1.3" xref="S4.E1.m1.2.2.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S4.E1.m1.2.2.1.2" xref="S4.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.2b"><apply id="S4.E1.m1.2.2.1.1.cmml" xref="S4.E1.m1.2.2.1"><eq id="S4.E1.m1.2.2.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.2"></eq><apply id="S4.E1.m1.2.2.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.1.1.3.1.cmml" xref="S4.E1.m1.2.2.1.1.3">subscript</csymbol><ci id="S4.E1.m1.2.2.1.1.3.2.cmml" xref="S4.E1.m1.2.2.1.1.3.2">‚Ñí</ci><apply id="S4.E1.m1.2.2.1.1.3.3.cmml" xref="S4.E1.m1.2.2.1.1.3.3"><times id="S4.E1.m1.2.2.1.1.3.3.1.cmml" xref="S4.E1.m1.2.2.1.1.3.3.1"></times><ci id="S4.E1.m1.2.2.1.1.3.3.2.cmml" xref="S4.E1.m1.2.2.1.1.3.3.2">ùê∂</ci><ci id="S4.E1.m1.2.2.1.1.3.3.3.cmml" xref="S4.E1.m1.2.2.1.1.3.3.3">ùê∏</ci></apply></apply><apply id="S4.E1.m1.2.2.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1"><minus id="S4.E1.m1.2.2.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1"></minus><apply id="S4.E1.m1.2.2.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S4.E1.m1.2.2.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1"><plus id="S4.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.3"></plus><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4"><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.4.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.1">‚ãÖ</ci><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.4.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.2">ùë¶</ci><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.3"><log id="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.1"></log><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.4.3.2">ùëù</ci></apply></apply><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2"><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.3">‚ãÖ</ci><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1"><minus id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">ùë¶</ci></apply><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1"><log id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"></log><apply id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1"><minus id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.1"></minus><cn type="integer" id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.2">1</cn><ci id="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3.cmml" xref="S4.E1.m1.2.2.1.1.1.1.1.1.2.2.1.1.1.3">ùëù</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.2c">\mathcal{L}_{CE}=-[y\cdot\log p+(1-y)\cdot\log(1-p)],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p1.2" class="ltx_p">where <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ùë¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">y</annotation></semantics></math> is the ground truth (1 for bona fide and 0 for attack in our case) and <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">p</annotation></semantics></math> is the predicted score.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p"><span id="S4.SS1.p2.3.1" class="ltx_text ltx_font_bold">PixBis</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> employs a binary supervisory strategy at pixel-level to simplify the problem and obviate the need for a computationally intensive synthesis of depth maps. Two dense blocks of DenseNet121 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> are utilized as the model backbone and a combination of two binary cross-entropy loss functions is used to train the model for both pixel-wise and binary output.
The combined loss equation for the training of all models is formed as:</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.1" class="ltx_Math" alttext="\mathcal{L}_{PixBis}=\mathcal{L}_{CE}^{pixel-wise}+\mathcal{L}_{CE}^{binary}." display="block"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><msub id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.2.2" xref="S4.E2.m1.1.1.1.1.2.2.cmml">‚Ñí</mi><mrow id="S4.E2.m1.1.1.1.1.2.3" xref="S4.E2.m1.1.1.1.1.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.2.3.2" xref="S4.E2.m1.1.1.1.1.2.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.2.3.1" xref="S4.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.2.3.3" xref="S4.E2.m1.1.1.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.2.3.1a" xref="S4.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.2.3.4" xref="S4.E2.m1.1.1.1.1.2.3.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.2.3.1b" xref="S4.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.2.3.5" xref="S4.E2.m1.1.1.1.1.2.3.5.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.2.3.1c" xref="S4.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.2.3.6" xref="S4.E2.m1.1.1.1.1.2.3.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.2.3.1d" xref="S4.E2.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.2.3.7" xref="S4.E2.m1.1.1.1.1.2.3.7.cmml">s</mi></mrow></msub><mo id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.3.cmml"><msubsup id="S4.E2.m1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.3.2.2.2" xref="S4.E2.m1.1.1.1.1.3.2.2.2.cmml">‚Ñí</mi><mrow id="S4.E2.m1.1.1.1.1.3.2.2.3" xref="S4.E2.m1.1.1.1.1.3.2.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.2.2.3.2" xref="S4.E2.m1.1.1.1.1.3.2.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.2.3.1" xref="S4.E2.m1.1.1.1.1.3.2.2.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.2.3.3" xref="S4.E2.m1.1.1.1.1.3.2.2.3.3.cmml">E</mi></mrow><mrow id="S4.E2.m1.1.1.1.1.3.2.3" xref="S4.E2.m1.1.1.1.1.3.2.3.cmml"><mrow id="S4.E2.m1.1.1.1.1.3.2.3.2" xref="S4.E2.m1.1.1.1.1.3.2.3.2.cmml"><mi id="S4.E2.m1.1.1.1.1.3.2.3.2.2" xref="S4.E2.m1.1.1.1.1.3.2.3.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.3.2.1" xref="S4.E2.m1.1.1.1.1.3.2.3.2.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.3.2.3" xref="S4.E2.m1.1.1.1.1.3.2.3.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.3.2.1a" xref="S4.E2.m1.1.1.1.1.3.2.3.2.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.3.2.4" xref="S4.E2.m1.1.1.1.1.3.2.3.2.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.3.2.1b" xref="S4.E2.m1.1.1.1.1.3.2.3.2.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.3.2.5" xref="S4.E2.m1.1.1.1.1.3.2.3.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.3.2.1c" xref="S4.E2.m1.1.1.1.1.3.2.3.2.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.3.2.6" xref="S4.E2.m1.1.1.1.1.3.2.3.2.6.cmml">l</mi></mrow><mo id="S4.E2.m1.1.1.1.1.3.2.3.1" xref="S4.E2.m1.1.1.1.1.3.2.3.1.cmml">‚àí</mo><mrow id="S4.E2.m1.1.1.1.1.3.2.3.3" xref="S4.E2.m1.1.1.1.1.3.2.3.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.2.3.3.2" xref="S4.E2.m1.1.1.1.1.3.2.3.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.3.3.1" xref="S4.E2.m1.1.1.1.1.3.2.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.3.3.3" xref="S4.E2.m1.1.1.1.1.3.2.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.3.3.1a" xref="S4.E2.m1.1.1.1.1.3.2.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.3.3.4" xref="S4.E2.m1.1.1.1.1.3.2.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.2.3.3.1b" xref="S4.E2.m1.1.1.1.1.3.2.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.2.3.3.5" xref="S4.E2.m1.1.1.1.1.3.2.3.3.5.cmml">e</mi></mrow></mrow></msubsup><mo id="S4.E2.m1.1.1.1.1.3.1" xref="S4.E2.m1.1.1.1.1.3.1.cmml">+</mo><msubsup id="S4.E2.m1.1.1.1.1.3.3" xref="S4.E2.m1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.3.3.2.2" xref="S4.E2.m1.1.1.1.1.3.3.2.2.cmml">‚Ñí</mi><mrow id="S4.E2.m1.1.1.1.1.3.3.2.3" xref="S4.E2.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.3.2.3.2" xref="S4.E2.m1.1.1.1.1.3.3.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.3.2.3.1" xref="S4.E2.m1.1.1.1.1.3.3.2.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.3.2.3.3" xref="S4.E2.m1.1.1.1.1.3.3.2.3.3.cmml">E</mi></mrow><mrow id="S4.E2.m1.1.1.1.1.3.3.3" xref="S4.E2.m1.1.1.1.1.3.3.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.3.3.2" xref="S4.E2.m1.1.1.1.1.3.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.3.3.1" xref="S4.E2.m1.1.1.1.1.3.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.3.3.3" xref="S4.E2.m1.1.1.1.1.3.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.3.3.1a" xref="S4.E2.m1.1.1.1.1.3.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.3.3.4" xref="S4.E2.m1.1.1.1.1.3.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.3.3.1b" xref="S4.E2.m1.1.1.1.1.3.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.3.3.5" xref="S4.E2.m1.1.1.1.1.3.3.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.3.3.1c" xref="S4.E2.m1.1.1.1.1.3.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.3.3.6" xref="S4.E2.m1.1.1.1.1.3.3.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.3.3.3.1d" xref="S4.E2.m1.1.1.1.1.3.3.3.1.cmml">‚Äã</mo><mi id="S4.E2.m1.1.1.1.1.3.3.3.7" xref="S4.E2.m1.1.1.1.1.3.3.3.7.cmml">y</mi></mrow></msubsup></mrow></mrow><mo lspace="0em" id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><eq id="S4.E2.m1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1"></eq><apply id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.1.1.1.1.2.2">‚Ñí</ci><apply id="S4.E2.m1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.2.3"><times id="S4.E2.m1.1.1.1.1.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.2.3.1"></times><ci id="S4.E2.m1.1.1.1.1.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.2.3.2">ùëÉ</ci><ci id="S4.E2.m1.1.1.1.1.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.2.3.3">ùëñ</ci><ci id="S4.E2.m1.1.1.1.1.2.3.4.cmml" xref="S4.E2.m1.1.1.1.1.2.3.4">ùë•</ci><ci id="S4.E2.m1.1.1.1.1.2.3.5.cmml" xref="S4.E2.m1.1.1.1.1.2.3.5">ùêµ</ci><ci id="S4.E2.m1.1.1.1.1.2.3.6.cmml" xref="S4.E2.m1.1.1.1.1.2.3.6">ùëñ</ci><ci id="S4.E2.m1.1.1.1.1.2.3.7.cmml" xref="S4.E2.m1.1.1.1.1.2.3.7">ùë†</ci></apply></apply><apply id="S4.E2.m1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.3"><plus id="S4.E2.m1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.1"></plus><apply id="S4.E2.m1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.2.1.cmml" xref="S4.E2.m1.1.1.1.1.3.2">superscript</csymbol><apply id="S4.E2.m1.1.1.1.1.3.2.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.2.2.1.cmml" xref="S4.E2.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.3.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2.2.2">‚Ñí</ci><apply id="S4.E2.m1.1.1.1.1.3.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.2.3"><times id="S4.E2.m1.1.1.1.1.3.2.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.2.2.3.1"></times><ci id="S4.E2.m1.1.1.1.1.3.2.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2.2.3.2">ùê∂</ci><ci id="S4.E2.m1.1.1.1.1.3.2.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.2.3.3">ùê∏</ci></apply></apply><apply id="S4.E2.m1.1.1.1.1.3.2.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3"><minus id="S4.E2.m1.1.1.1.1.3.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.1"></minus><apply id="S4.E2.m1.1.1.1.1.3.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2"><times id="S4.E2.m1.1.1.1.1.3.2.3.2.1.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2.1"></times><ci id="S4.E2.m1.1.1.1.1.3.2.3.2.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2.2">ùëù</ci><ci id="S4.E2.m1.1.1.1.1.3.2.3.2.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2.3">ùëñ</ci><ci id="S4.E2.m1.1.1.1.1.3.2.3.2.4.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2.4">ùë•</ci><ci id="S4.E2.m1.1.1.1.1.3.2.3.2.5.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2.5">ùëí</ci><ci id="S4.E2.m1.1.1.1.1.3.2.3.2.6.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.2.6">ùëô</ci></apply><apply id="S4.E2.m1.1.1.1.1.3.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.3"><times id="S4.E2.m1.1.1.1.1.3.2.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.3.1"></times><ci id="S4.E2.m1.1.1.1.1.3.2.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.3.2">ùë§</ci><ci id="S4.E2.m1.1.1.1.1.3.2.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.3.3">ùëñ</ci><ci id="S4.E2.m1.1.1.1.1.3.2.3.3.4.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.3.4">ùë†</ci><ci id="S4.E2.m1.1.1.1.1.3.2.3.3.5.cmml" xref="S4.E2.m1.1.1.1.1.3.2.3.3.5">ùëí</ci></apply></apply></apply><apply id="S4.E2.m1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3">superscript</csymbol><apply id="S4.E2.m1.1.1.1.1.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2.2">‚Ñí</ci><apply id="S4.E2.m1.1.1.1.1.3.3.2.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2.3"><times id="S4.E2.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2.3.1"></times><ci id="S4.E2.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2.3.2">ùê∂</ci><ci id="S4.E2.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2.3.3">ùê∏</ci></apply></apply><apply id="S4.E2.m1.1.1.1.1.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3"><times id="S4.E2.m1.1.1.1.1.3.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.1"></times><ci id="S4.E2.m1.1.1.1.1.3.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.2">ùëè</ci><ci id="S4.E2.m1.1.1.1.1.3.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.3">ùëñ</ci><ci id="S4.E2.m1.1.1.1.1.3.3.3.4.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.4">ùëõ</ci><ci id="S4.E2.m1.1.1.1.1.3.3.3.5.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.5">ùëé</ci><ci id="S4.E2.m1.1.1.1.1.3.3.3.6.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.6">ùëü</ci><ci id="S4.E2.m1.1.1.1.1.3.3.3.7.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.7">ùë¶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\mathcal{L}_{PixBis}=\mathcal{L}_{CE}^{pixel-wise}+\mathcal{L}_{CE}^{binary}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.2" class="ltx_p">where <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{CE}^{pixel-wise}" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><msubsup id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.1.m1.1.1.2.2" xref="S4.SS1.p2.1.m1.1.1.2.2.cmml">‚Ñí</mi><mrow id="S4.SS1.p2.1.m1.1.1.2.3" xref="S4.SS1.p2.1.m1.1.1.2.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2.3.2" xref="S4.SS1.p2.1.m1.1.1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.2.3.1" xref="S4.SS1.p2.1.m1.1.1.2.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.2.3.3" xref="S4.SS1.p2.1.m1.1.1.2.3.3.cmml">E</mi></mrow><mrow id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml"><mrow id="S4.SS1.p2.1.m1.1.1.3.2" xref="S4.SS1.p2.1.m1.1.1.3.2.cmml"><mi id="S4.SS1.p2.1.m1.1.1.3.2.2" xref="S4.SS1.p2.1.m1.1.1.3.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.2.1" xref="S4.SS1.p2.1.m1.1.1.3.2.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.3.2.3" xref="S4.SS1.p2.1.m1.1.1.3.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.2.1a" xref="S4.SS1.p2.1.m1.1.1.3.2.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.3.2.4" xref="S4.SS1.p2.1.m1.1.1.3.2.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.2.1b" xref="S4.SS1.p2.1.m1.1.1.3.2.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.3.2.5" xref="S4.SS1.p2.1.m1.1.1.3.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.2.1c" xref="S4.SS1.p2.1.m1.1.1.3.2.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.3.2.6" xref="S4.SS1.p2.1.m1.1.1.3.2.6.cmml">l</mi></mrow><mo id="S4.SS1.p2.1.m1.1.1.3.1" xref="S4.SS1.p2.1.m1.1.1.3.1.cmml">‚àí</mo><mrow id="S4.SS1.p2.1.m1.1.1.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.cmml"><mi id="S4.SS1.p2.1.m1.1.1.3.3.2" xref="S4.SS1.p2.1.m1.1.1.3.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.3.1" xref="S4.SS1.p2.1.m1.1.1.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.3.3.3" xref="S4.SS1.p2.1.m1.1.1.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.3.1a" xref="S4.SS1.p2.1.m1.1.1.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.3.3.4" xref="S4.SS1.p2.1.m1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.1.m1.1.1.3.3.1b" xref="S4.SS1.p2.1.m1.1.1.3.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.1.m1.1.1.3.3.5" xref="S4.SS1.p2.1.m1.1.1.3.3.5.cmml">e</mi></mrow></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">superscript</csymbol><apply id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.2.1.cmml" xref="S4.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2.2">‚Ñí</ci><apply id="S4.SS1.p2.1.m1.1.1.2.3.cmml" xref="S4.SS1.p2.1.m1.1.1.2.3"><times id="S4.SS1.p2.1.m1.1.1.2.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.2.3.1"></times><ci id="S4.SS1.p2.1.m1.1.1.2.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2.3.2">ùê∂</ci><ci id="S4.SS1.p2.1.m1.1.1.2.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.2.3.3">ùê∏</ci></apply></apply><apply id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3"><minus id="S4.SS1.p2.1.m1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3.1"></minus><apply id="S4.SS1.p2.1.m1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2"><times id="S4.SS1.p2.1.m1.1.1.3.2.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2.1"></times><ci id="S4.SS1.p2.1.m1.1.1.3.2.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2.2">ùëù</ci><ci id="S4.SS1.p2.1.m1.1.1.3.2.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2.3">ùëñ</ci><ci id="S4.SS1.p2.1.m1.1.1.3.2.4.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2.4">ùë•</ci><ci id="S4.SS1.p2.1.m1.1.1.3.2.5.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2.5">ùëí</ci><ci id="S4.SS1.p2.1.m1.1.1.3.2.6.cmml" xref="S4.SS1.p2.1.m1.1.1.3.2.6">ùëô</ci></apply><apply id="S4.SS1.p2.1.m1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3"><times id="S4.SS1.p2.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.1"></times><ci id="S4.SS1.p2.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.2">ùë§</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.3">ùëñ</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.4.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.4">ùë†</ci><ci id="S4.SS1.p2.1.m1.1.1.3.3.5.cmml" xref="S4.SS1.p2.1.m1.1.1.3.3.5">ùëí</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\mathcal{L}_{CE}^{pixel-wise}</annotation></semantics></math> refers to the loss based on the pixel-wise output and <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{CE}^{binary}" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><msubsup id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p2.2.m2.1.1.2.2" xref="S4.SS1.p2.2.m2.1.1.2.2.cmml">‚Ñí</mi><mrow id="S4.SS1.p2.2.m2.1.1.2.3" xref="S4.SS1.p2.2.m2.1.1.2.3.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2.3.2" xref="S4.SS1.p2.2.m2.1.1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.2.3.1" xref="S4.SS1.p2.2.m2.1.1.2.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.2.m2.1.1.2.3.3" xref="S4.SS1.p2.2.m2.1.1.2.3.3.cmml">E</mi></mrow><mrow id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml"><mi id="S4.SS1.p2.2.m2.1.1.3.2" xref="S4.SS1.p2.2.m2.1.1.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.3.1" xref="S4.SS1.p2.2.m2.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.2.m2.1.1.3.3" xref="S4.SS1.p2.2.m2.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.3.1a" xref="S4.SS1.p2.2.m2.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.2.m2.1.1.3.4" xref="S4.SS1.p2.2.m2.1.1.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.3.1b" xref="S4.SS1.p2.2.m2.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.2.m2.1.1.3.5" xref="S4.SS1.p2.2.m2.1.1.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.3.1c" xref="S4.SS1.p2.2.m2.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.2.m2.1.1.3.6" xref="S4.SS1.p2.2.m2.1.1.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p2.2.m2.1.1.3.1d" xref="S4.SS1.p2.2.m2.1.1.3.1.cmml">‚Äã</mo><mi id="S4.SS1.p2.2.m2.1.1.3.7" xref="S4.SS1.p2.2.m2.1.1.3.7.cmml">y</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">superscript</csymbol><apply id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.2.1.cmml" xref="S4.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.2.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2.2">‚Ñí</ci><apply id="S4.SS1.p2.2.m2.1.1.2.3.cmml" xref="S4.SS1.p2.2.m2.1.1.2.3"><times id="S4.SS1.p2.2.m2.1.1.2.3.1.cmml" xref="S4.SS1.p2.2.m2.1.1.2.3.1"></times><ci id="S4.SS1.p2.2.m2.1.1.2.3.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2.3.2">ùê∂</ci><ci id="S4.SS1.p2.2.m2.1.1.2.3.3.cmml" xref="S4.SS1.p2.2.m2.1.1.2.3.3">ùê∏</ci></apply></apply><apply id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3"><times id="S4.SS1.p2.2.m2.1.1.3.1.cmml" xref="S4.SS1.p2.2.m2.1.1.3.1"></times><ci id="S4.SS1.p2.2.m2.1.1.3.2.cmml" xref="S4.SS1.p2.2.m2.1.1.3.2">ùëè</ci><ci id="S4.SS1.p2.2.m2.1.1.3.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3.3">ùëñ</ci><ci id="S4.SS1.p2.2.m2.1.1.3.4.cmml" xref="S4.SS1.p2.2.m2.1.1.3.4">ùëõ</ci><ci id="S4.SS1.p2.2.m2.1.1.3.5.cmml" xref="S4.SS1.p2.2.m2.1.1.3.5">ùëé</ci><ci id="S4.SS1.p2.2.m2.1.1.3.6.cmml" xref="S4.SS1.p2.2.m2.1.1.3.6">ùëü</ci><ci id="S4.SS1.p2.2.m2.1.1.3.7.cmml" xref="S4.SS1.p2.2.m2.1.1.3.7">ùë¶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\mathcal{L}_{CE}^{binary}</annotation></semantics></math> refers to the loss based on the binary output.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>MixStyle</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Recent studies in synthetic-based face recognition revealed a domain gap between synthetic and authentic face images through the examination of the performance divergence between face recognition models trained on synthetic and authentic data. This performance gap has also been observed in our work, as will be detailed in Section <a href="#S6.SS1" title="6.1 SynthASpoof PAD ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>. To narrow the domain gap between synthetic and authentic face PAD data, we adapt a recently proposed domain generalization method, MixStyle <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. MixStyle mixes the feature statistics of two samples to synthesize novel domains inspired by the observation that the feature statistics encode style/domain-related information. To adapt the face PAD model from synthetic data to authentic data, we utilized the labeled synthetic SynthASpoof and unlabeled authentic face PAD data to perform MixStyle within a mini-batch and with a controlled probability during the training process.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.5" class="ltx_p">Mathematically, the MixStyle adapted in our case can be formulated as follows:</p>
<table id="S4.E3" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E3X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E3X.2.1.1.m1.3" class="ltx_Math" alttext="\displaystyle\gamma=\lambda\sigma(x_{s})+(1-\lambda)\sigma(x_{a})" display="inline"><semantics id="S4.E3X.2.1.1.m1.3a"><mrow id="S4.E3X.2.1.1.m1.3.3" xref="S4.E3X.2.1.1.m1.3.3.cmml"><mi id="S4.E3X.2.1.1.m1.3.3.5" xref="S4.E3X.2.1.1.m1.3.3.5.cmml">Œ≥</mi><mo id="S4.E3X.2.1.1.m1.3.3.4" xref="S4.E3X.2.1.1.m1.3.3.4.cmml">=</mo><mrow id="S4.E3X.2.1.1.m1.3.3.3" xref="S4.E3X.2.1.1.m1.3.3.3.cmml"><mrow id="S4.E3X.2.1.1.m1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.3.cmml">Œª</mi><mo lspace="0em" rspace="0em" id="S4.E3X.2.1.1.m1.1.1.1.1.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.cmml">‚Äã</mo><mi id="S4.E3X.2.1.1.m1.1.1.1.1.4" xref="S4.E3X.2.1.1.m1.1.1.1.1.4.cmml">œÉ</mi><mo lspace="0em" rspace="0em" id="S4.E3X.2.1.1.m1.1.1.1.1.2a" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S4.E3X.2.1.1.m1.1.1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml">s</mi></msub><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E3X.2.1.1.m1.3.3.3.4" xref="S4.E3X.2.1.1.m1.3.3.3.4.cmml">+</mo><mrow id="S4.E3X.2.1.1.m1.3.3.3.3" xref="S4.E3X.2.1.1.m1.3.3.3.3.cmml"><mrow id="S4.E3X.2.1.1.m1.2.2.2.2.1.1" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.cmml"><mn id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml">1</mn><mo id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.cmml">‚àí</mo><mi id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.3.cmml">Œª</mi></mrow><mo stretchy="false" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E3X.2.1.1.m1.3.3.3.3.3" xref="S4.E3X.2.1.1.m1.3.3.3.3.3.cmml">‚Äã</mo><mi id="S4.E3X.2.1.1.m1.3.3.3.3.4" xref="S4.E3X.2.1.1.m1.3.3.3.3.4.cmml">œÉ</mi><mo lspace="0em" rspace="0em" id="S4.E3X.2.1.1.m1.3.3.3.3.3a" xref="S4.E3X.2.1.1.m1.3.3.3.3.3.cmml">‚Äã</mo><mrow id="S4.E3X.2.1.1.m1.3.3.3.3.2.1" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.cmml"><mo stretchy="false" id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.2" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.cmml">(</mo><msub id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.cmml"><mi id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.2" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.2.cmml">x</mi><mi id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.3" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.3.cmml">a</mi></msub><mo stretchy="false" id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.3" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3X.2.1.1.m1.3b"><apply id="S4.E3X.2.1.1.m1.3.3.cmml" xref="S4.E3X.2.1.1.m1.3.3"><eq id="S4.E3X.2.1.1.m1.3.3.4.cmml" xref="S4.E3X.2.1.1.m1.3.3.4"></eq><ci id="S4.E3X.2.1.1.m1.3.3.5.cmml" xref="S4.E3X.2.1.1.m1.3.3.5">ùõæ</ci><apply id="S4.E3X.2.1.1.m1.3.3.3.cmml" xref="S4.E3X.2.1.1.m1.3.3.3"><plus id="S4.E3X.2.1.1.m1.3.3.3.4.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.4"></plus><apply id="S4.E3X.2.1.1.m1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1"><times id="S4.E3X.2.1.1.m1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2"></times><ci id="S4.E3X.2.1.1.m1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.3">ùúÜ</ci><ci id="S4.E3X.2.1.1.m1.1.1.1.1.4.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.4">ùúé</ci><apply id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2">ùë•</ci><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.3">ùë†</ci></apply></apply><apply id="S4.E3X.2.1.1.m1.3.3.3.3.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.3"><times id="S4.E3X.2.1.1.m1.3.3.3.3.3.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.3.3"></times><apply id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1"><minus id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1"></minus><cn type="integer" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2">1</cn><ci id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.3">ùúÜ</ci></apply><ci id="S4.E3X.2.1.1.m1.3.3.3.3.4.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.3.4">ùúé</ci><apply id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1">subscript</csymbol><ci id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.2">ùë•</ci><ci id="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.3.3.3.3.2.1.1.3">ùëé</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3X.2.1.1.m1.3c">\displaystyle\gamma=\lambda\sigma(x_{s})+(1-\lambda)\sigma(x_{a})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(3)</span></td>
</tr>
<tr id="S4.E3Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E3Xa.2.1.1.m1.3" class="ltx_Math" alttext="\displaystyle\beta=\lambda\mu(x_{s})+(1-\lambda)\mu(x_{a})" display="inline"><semantics id="S4.E3Xa.2.1.1.m1.3a"><mrow id="S4.E3Xa.2.1.1.m1.3.3" xref="S4.E3Xa.2.1.1.m1.3.3.cmml"><mi id="S4.E3Xa.2.1.1.m1.3.3.5" xref="S4.E3Xa.2.1.1.m1.3.3.5.cmml">Œ≤</mi><mo id="S4.E3Xa.2.1.1.m1.3.3.4" xref="S4.E3Xa.2.1.1.m1.3.3.4.cmml">=</mo><mrow id="S4.E3Xa.2.1.1.m1.3.3.3" xref="S4.E3Xa.2.1.1.m1.3.3.3.cmml"><mrow id="S4.E3Xa.2.1.1.m1.1.1.1.1" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.cmml"><mi id="S4.E3Xa.2.1.1.m1.1.1.1.1.3" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.3.cmml">Œª</mi><mo lspace="0em" rspace="0em" id="S4.E3Xa.2.1.1.m1.1.1.1.1.2" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.2.cmml">‚Äã</mo><mi id="S4.E3Xa.2.1.1.m1.1.1.1.1.4" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.4.cmml">Œº</mi><mo lspace="0em" rspace="0em" id="S4.E3Xa.2.1.1.m1.1.1.1.1.2a" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.2" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.3.cmml">s</mi></msub><mo stretchy="false" id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.3" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E3Xa.2.1.1.m1.3.3.3.4" xref="S4.E3Xa.2.1.1.m1.3.3.3.4.cmml">+</mo><mrow id="S4.E3Xa.2.1.1.m1.3.3.3.3" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.cmml"><mrow id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.2" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.cmml"><mn id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.2" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.2.cmml">1</mn><mo id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.1" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.1.cmml">‚àí</mo><mi id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.3" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.3.cmml">Œª</mi></mrow><mo stretchy="false" id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.3" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E3Xa.2.1.1.m1.3.3.3.3.3" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.3.cmml">‚Äã</mo><mi id="S4.E3Xa.2.1.1.m1.3.3.3.3.4" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.4.cmml">Œº</mi><mo lspace="0em" rspace="0em" id="S4.E3Xa.2.1.1.m1.3.3.3.3.3a" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.3.cmml">‚Äã</mo><mrow id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.cmml"><mo stretchy="false" id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.2" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.cmml">(</mo><msub id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.cmml"><mi id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.2" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.2.cmml">x</mi><mi id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.3" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.3.cmml">a</mi></msub><mo stretchy="false" id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.3" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3Xa.2.1.1.m1.3b"><apply id="S4.E3Xa.2.1.1.m1.3.3.cmml" xref="S4.E3Xa.2.1.1.m1.3.3"><eq id="S4.E3Xa.2.1.1.m1.3.3.4.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.4"></eq><ci id="S4.E3Xa.2.1.1.m1.3.3.5.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.5">ùõΩ</ci><apply id="S4.E3Xa.2.1.1.m1.3.3.3.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3"><plus id="S4.E3Xa.2.1.1.m1.3.3.3.4.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.4"></plus><apply id="S4.E3Xa.2.1.1.m1.1.1.1.1.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1"><times id="S4.E3Xa.2.1.1.m1.1.1.1.1.2.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.2"></times><ci id="S4.E3Xa.2.1.1.m1.1.1.1.1.3.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.3">ùúÜ</ci><ci id="S4.E3Xa.2.1.1.m1.1.1.1.1.4.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.4">ùúá</ci><apply id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.2">ùë•</ci><ci id="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3Xa.2.1.1.m1.1.1.1.1.1.1.1.3">ùë†</ci></apply></apply><apply id="S4.E3Xa.2.1.1.m1.3.3.3.3.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.3"><times id="S4.E3Xa.2.1.1.m1.3.3.3.3.3.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.3"></times><apply id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.cmml" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1"><minus id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.1.cmml" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.1"></minus><cn type="integer" id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.2.cmml" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.2">1</cn><ci id="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.3.cmml" xref="S4.E3Xa.2.1.1.m1.2.2.2.2.1.1.1.3">ùúÜ</ci></apply><ci id="S4.E3Xa.2.1.1.m1.3.3.3.3.4.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.4">ùúá</ci><apply id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1"><csymbol cd="ambiguous" id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.1.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1">subscript</csymbol><ci id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.2.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.2">ùë•</ci><ci id="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.3.cmml" xref="S4.E3Xa.2.1.1.m1.3.3.3.3.2.1.1.3">ùëé</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3Xa.2.1.1.m1.3c">\displaystyle\beta=\lambda\mu(x_{s})+(1-\lambda)\mu(x_{a})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S4.SS2.p2.4" class="ltx_p">Where <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="x_{s}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">x</mi><mi id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">ùë•</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">x_{s}</annotation></semantics></math> and <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="x_{a}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">x</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">ùë•</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">ùëé</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">x_{a}</annotation></semantics></math> refer to synthetic and authentic face PAD data, respectively. <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="\lambda\in\mathbb{R}^{B}" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mrow id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mi id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">Œª</mi><mo id="S4.SS2.p2.3.m3.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.cmml">‚àà</mo><msup id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml"><mi id="S4.SS2.p2.3.m3.1.1.3.2" xref="S4.SS2.p2.3.m3.1.1.3.2.cmml">‚Ñù</mi><mi id="S4.SS2.p2.3.m3.1.1.3.3" xref="S4.SS2.p2.3.m3.1.1.3.3.cmml">B</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><in id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1"></in><ci id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">ùúÜ</ci><apply id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.1.1.3.1.cmml" xref="S4.SS2.p2.3.m3.1.1.3">superscript</csymbol><ci id="S4.SS2.p2.3.m3.1.1.3.2.cmml" xref="S4.SS2.p2.3.m3.1.1.3.2">‚Ñù</ci><ci id="S4.SS2.p2.3.m3.1.1.3.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3.3">ùêµ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">\lambda\in\mathbb{R}^{B}</annotation></semantics></math> are weights sampled from the Beta distribution.
The final mixed feature statistic is applied to the styled normalized synthetic face PAD data <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="x_{s}" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><msub id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mi id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">x</mi><mi id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">ùë•</ci><ci id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3">ùë†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">x_{s}</annotation></semantics></math> as:</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.3" class="ltx_Math" alttext="MixStyle(x_{s})=\gamma\frac{x_{s}-\mu(x_{s})}{\sigma(x_{s})}+\beta" display="block"><semantics id="S4.E4.m1.3a"><mrow id="S4.E4.m1.3.3" xref="S4.E4.m1.3.3.cmml"><mrow id="S4.E4.m1.3.3.1" xref="S4.E4.m1.3.3.1.cmml"><mi id="S4.E4.m1.3.3.1.3" xref="S4.E4.m1.3.3.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mi id="S4.E4.m1.3.3.1.4" xref="S4.E4.m1.3.3.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2a" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mi id="S4.E4.m1.3.3.1.5" xref="S4.E4.m1.3.3.1.5.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2b" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mi id="S4.E4.m1.3.3.1.6" xref="S4.E4.m1.3.3.1.6.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2c" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mi id="S4.E4.m1.3.3.1.7" xref="S4.E4.m1.3.3.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2d" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mi id="S4.E4.m1.3.3.1.8" xref="S4.E4.m1.3.3.1.8.cmml">y</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2e" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mi id="S4.E4.m1.3.3.1.9" xref="S4.E4.m1.3.3.1.9.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2f" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mi id="S4.E4.m1.3.3.1.10" xref="S4.E4.m1.3.3.1.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.2g" xref="S4.E4.m1.3.3.1.2.cmml">‚Äã</mo><mrow id="S4.E4.m1.3.3.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.cmml">(</mo><msub id="S4.E4.m1.3.3.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.cmml"><mi id="S4.E4.m1.3.3.1.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.2.cmml">x</mi><mi id="S4.E4.m1.3.3.1.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.3.cmml">s</mi></msub><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.3.3.2" xref="S4.E4.m1.3.3.2.cmml">=</mo><mrow id="S4.E4.m1.3.3.3" xref="S4.E4.m1.3.3.3.cmml"><mrow id="S4.E4.m1.3.3.3.2" xref="S4.E4.m1.3.3.3.2.cmml"><mi id="S4.E4.m1.3.3.3.2.2" xref="S4.E4.m1.3.3.3.2.2.cmml">Œ≥</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.3.2.1" xref="S4.E4.m1.3.3.3.2.1.cmml">‚Äã</mo><mfrac id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml"><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml"><msub id="S4.E4.m1.1.1.1.3" xref="S4.E4.m1.1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.3.2.cmml">x</mi><mi id="S4.E4.m1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.3.3.cmml">s</mi></msub><mo id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.2.cmml">‚àí</mo><mrow id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.cmml">Œº</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S4.E4.m1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.3.cmml">s</mi></msub><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S4.E4.m1.2.2.2" xref="S4.E4.m1.2.2.2.cmml"><mi id="S4.E4.m1.2.2.2.3" xref="S4.E4.m1.2.2.2.3.cmml">œÉ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.2.2" xref="S4.E4.m1.2.2.2.2.cmml">‚Äã</mo><mrow id="S4.E4.m1.2.2.2.1.1" xref="S4.E4.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.2.2.2.1.1.2" xref="S4.E4.m1.2.2.2.1.1.1.cmml">(</mo><msub id="S4.E4.m1.2.2.2.1.1.1" xref="S4.E4.m1.2.2.2.1.1.1.cmml"><mi id="S4.E4.m1.2.2.2.1.1.1.2" xref="S4.E4.m1.2.2.2.1.1.1.2.cmml">x</mi><mi id="S4.E4.m1.2.2.2.1.1.1.3" xref="S4.E4.m1.2.2.2.1.1.1.3.cmml">s</mi></msub><mo stretchy="false" id="S4.E4.m1.2.2.2.1.1.3" xref="S4.E4.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S4.E4.m1.3.3.3.1" xref="S4.E4.m1.3.3.3.1.cmml">+</mo><mi id="S4.E4.m1.3.3.3.3" xref="S4.E4.m1.3.3.3.3.cmml">Œ≤</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.3b"><apply id="S4.E4.m1.3.3.cmml" xref="S4.E4.m1.3.3"><eq id="S4.E4.m1.3.3.2.cmml" xref="S4.E4.m1.3.3.2"></eq><apply id="S4.E4.m1.3.3.1.cmml" xref="S4.E4.m1.3.3.1"><times id="S4.E4.m1.3.3.1.2.cmml" xref="S4.E4.m1.3.3.1.2"></times><ci id="S4.E4.m1.3.3.1.3.cmml" xref="S4.E4.m1.3.3.1.3">ùëÄ</ci><ci id="S4.E4.m1.3.3.1.4.cmml" xref="S4.E4.m1.3.3.1.4">ùëñ</ci><ci id="S4.E4.m1.3.3.1.5.cmml" xref="S4.E4.m1.3.3.1.5">ùë•</ci><ci id="S4.E4.m1.3.3.1.6.cmml" xref="S4.E4.m1.3.3.1.6">ùëÜ</ci><ci id="S4.E4.m1.3.3.1.7.cmml" xref="S4.E4.m1.3.3.1.7">ùë°</ci><ci id="S4.E4.m1.3.3.1.8.cmml" xref="S4.E4.m1.3.3.1.8">ùë¶</ci><ci id="S4.E4.m1.3.3.1.9.cmml" xref="S4.E4.m1.3.3.1.9">ùëô</ci><ci id="S4.E4.m1.3.3.1.10.cmml" xref="S4.E4.m1.3.3.1.10">ùëí</ci><apply id="S4.E4.m1.3.3.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.1.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1">subscript</csymbol><ci id="S4.E4.m1.3.3.1.1.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.2">ùë•</ci><ci id="S4.E4.m1.3.3.1.1.1.1.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.3">ùë†</ci></apply></apply><apply id="S4.E4.m1.3.3.3.cmml" xref="S4.E4.m1.3.3.3"><plus id="S4.E4.m1.3.3.3.1.cmml" xref="S4.E4.m1.3.3.3.1"></plus><apply id="S4.E4.m1.3.3.3.2.cmml" xref="S4.E4.m1.3.3.3.2"><times id="S4.E4.m1.3.3.3.2.1.cmml" xref="S4.E4.m1.3.3.3.2.1"></times><ci id="S4.E4.m1.3.3.3.2.2.cmml" xref="S4.E4.m1.3.3.3.2.2">ùõæ</ci><apply id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"><divide id="S4.E4.m1.2.2.3.cmml" xref="S4.E4.m1.2.2"></divide><apply id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><minus id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.2"></minus><apply id="S4.E4.m1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.3.2">ùë•</ci><ci id="S4.E4.m1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.3.3">ùë†</ci></apply><apply id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2"></times><ci id="S4.E4.m1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3">ùúá</ci><apply id="S4.E4.m1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2">ùë•</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3">ùë†</ci></apply></apply></apply><apply id="S4.E4.m1.2.2.2.cmml" xref="S4.E4.m1.2.2.2"><times id="S4.E4.m1.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2"></times><ci id="S4.E4.m1.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.3">ùúé</ci><apply id="S4.E4.m1.2.2.2.1.1.1.cmml" xref="S4.E4.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.1.1.1.1.cmml" xref="S4.E4.m1.2.2.2.1.1">subscript</csymbol><ci id="S4.E4.m1.2.2.2.1.1.1.2.cmml" xref="S4.E4.m1.2.2.2.1.1.1.2">ùë•</ci><ci id="S4.E4.m1.2.2.2.1.1.1.3.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3">ùë†</ci></apply></apply></apply></apply><ci id="S4.E4.m1.3.3.3.3.cmml" xref="S4.E4.m1.3.3.3.3">ùõΩ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.3c">MixStyle(x_{s})=\gamma\frac{x_{s}-\mu(x_{s})}{\sigma(x_{s})}+\beta</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p2.6" class="ltx_p">It is important to note that: 1) The loss is calculated only on the synthetic face PAD data output when conducting the domain adaptation experiment in Section <a href="#S6.SS3" title="6.3 Effect of MixStyle ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>.
2) In Section <a href="#S6.SS4" title="6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.4</span></a>, the face PAD model is trained on a combination of the SynthASpoof and an authentic face PAD dataset to address the problem of limited training data. MixStyle is used there to reduce the difference between the synthetic and authentic training data, which is demonstrated later by the performance on unseen authentic data. 3) MixStyle is removed during the inference process, and thus does not require additional computational overhead while using the PAD.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">In our experiment, MixStyle is inserted after the first and second ResNet blocks and after the first dense block of the PixBis model, based on the fact that features at higher layers have a stronger correlation with class labels as opposed to the domain information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3>

<figure id="S5.F2" class="ltx_figure"><img src="/html/2303.02660/assets/x2.png" id="S5.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="189" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S5.F2.4.2" class="ltx_text" style="font-size:90%;">Samples of four authentic face PAD datasets. Images with green bounding box are bona fide, while others are attack samples.</span></figcaption>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">To assess the feasibility of using SynthASpoof to develop face PAD, the performance of models trained on SynthASpoofis evaluated on four authentic face PAD benchmarks: MSU-MFSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> (denoted as M), CASIA-MFSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> (denoted as C), Idiap Replay-Attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> (denoted as I), and OULU-NPU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> (denoted as O). The data samples are shown in Fig. <a href="#S5.F2" title="Figure 2 ‚Ä£ 5.1 Datasets ‚Ä£ 5 Experiments ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">MSU-MFSD</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> dataset consists of 440 videos captured from 35 subjects using two different resolutions of cameras. The dataset contains two types of attacks, printed photo attacks and replay attacks.
The <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_bold">CASIA-MFSD</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> dataset is comprised of 600 videos from 50 subjects and includes three types of attacks: warped photo attack, cut photo attack, and video replay attack.
The <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_bold">Idiap Replay-Attack</span> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> contains 300 videos from 50 subjects captured under various sensors and illumination conditions. The dataset includes two attack types: print attacks and replay attacks.
The <span id="S5.SS1.p2.1.4" class="ltx_text ltx_font_bold">Oulu-NPU</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> is a mobile face PAD dataset designed for assessing the generalizability of PAD methods in a realistic mobile scenario. OULU-NPU consists of 5940 video clips from 55 subjects using six different mobile phones.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The performance of models trained on synthetic and authentic face PAD data is analyzed over these datasets. As SynthASpoof database is specifically created for the purpose of training face PAD models, the entire dataset is used in the training phase. The trained models are then further tested on other authentic face PAD datasets.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Implementation Setup</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> and to make up for the relatively smaller size of the authentic datasets, 25 frames (per video) were sampled evenly across the duration of each video in the four authentic face PAD datasets, while only one frame was considered from each video in the SynthASpoof database as detailed in Sec. <a href="#S3" title="3 SynthASpoof Dataset ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Tab. <a href="#S2.T1" title="Table 1 ‚Ä£ 2 Related Work ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
The faces were then detected and cropped using the MTCNN method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and resized to <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="224\times 224\times 3" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.1.1.1a" xref="S5.SS2.p1.1.m1.1.1.1.cmml">√ó</mo><mn id="S5.SS2.p1.1.m1.1.1.4" xref="S5.SS2.p1.1.m1.1.1.4.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">224</cn><cn type="integer" id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">224</cn><cn type="integer" id="S5.SS2.p1.1.m1.1.1.4.cmml" xref="S5.SS2.p1.1.m1.1.1.4">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">224\times 224\times 3</annotation></semantics></math> pixels, following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.
During training, a weighted sampling was performed to insure a bona fide-attack ratio of 1:1.
The Stochastic Gradient Descent (SGD) optimizer with a momentum of 0.9 and weight decay of 5e-4, and an exponential learning scheduler with a gamma of 0.998 was applied in all training processes.
The initial learning rate for training the ResNet and PixBis models on the SynthASpoof database was set to 0.01. The batch size in the training phase was 128 and the training epoch was set to 70.
Conventional data augmentation techniques: horizontal flipping, scaling and rotating, random gamma adjustment, RGB shifting, and color gittering, were used. The effects of these techniques are explored in Section <a href="#S6.SS2" title="6.2 Effect of Cropping and Data Augmentation ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>.
In the testing phase, a final PAD decision score of a video is a fused score (mean-rule fusion) of all frames, following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Evaluation Metrics</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Following existing cross-domain face PAD methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, we report the Half Total Error Rate (HTER), which is the mean of Bona fide Presentation Classification Error Rate (BPCER) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and Attack Presentation Classification Error Rate (APCER) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and Area under the Receiver Operating Characteristic (ROC) Curve (AUC) value for cross-dataset face PAD evaluation. Additionally, ROC curves are illustrated, where the x-axis is APCER and the y-axis is 1-BPCER.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We first explore if the synthetic data can be used to develop PAD solutions.
We further compare the performance between models trained on the synthetic and the authentic data and tested on different authentic face PAD datasets.
Then, we investigate the effect of cropping and data augmentation on PAD performance.
Furthermore, we prove the sanity of adapting MixStyle to enhance the performance of PAD models trained on synthetic data.
We also explore the usability of SynthASpoof as supplementary training data to enhance the diversity of authentic training data. Finally, a visual analysis and a final discussion is presetned.
</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>SynthASpoof PAD</h3>

<figure id="S6.T2" class="ltx_table">
<div id="S6.T2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:486.9pt;height:68pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-78.6pt,11.0pt) scale(0.755853050680961,0.755853050680961) ;">
<table id="S6.T2.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T2.2.1.1.1" class="ltx_tr">
<th id="S6.T2.2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Method</th>
<th id="S6.T2.2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Training data</th>
<th id="S6.T2.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">C ‚Üí I</th>
<th id="S6.T2.2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">C ‚Üí M</th>
<th id="S6.T2.2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">C ‚Üí O</th>
<th id="S6.T2.2.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">I ‚Üí C</th>
<th id="S6.T2.2.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">I ‚Üí M</th>
<th id="S6.T2.2.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">I ‚Üí O</th>
<th id="S6.T2.2.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">M ‚Üí C</th>
<th id="S6.T2.2.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">M ‚Üí I</th>
<th id="S6.T2.2.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">M ‚Üí O</th>
<th id="S6.T2.2.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">O ‚Üí M</th>
<th id="S6.T2.2.1.1.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">O ‚Üí C</th>
<th id="S6.T2.2.1.1.1.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">O ‚Üí I</th>
<th id="S6.T2.2.1.1.1.15" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Average</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T2.2.1.2.1" class="ltx_tr">
<td id="S6.T2.2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S6.T2.2.1.2.1.1.1" class="ltx_text">ResNet</span></td>
<td id="S6.T2.2.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Authentic</td>
<td id="S6.T2.2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">38.85</td>
<td id="S6.T2.2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">18.10</td>
<td id="S6.T2.2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.94</td>
<td id="S6.T2.2.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">42.22</td>
<td id="S6.T2.2.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">18.81</td>
<td id="S6.T2.2.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.42</td>
<td id="S6.T2.2.1.2.1.9" class="ltx_td ltx_align_center ltx_border_t">27.11</td>
<td id="S6.T2.2.1.2.1.10" class="ltx_td ltx_align_center ltx_border_t">16.30</td>
<td id="S6.T2.2.1.2.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30.49</td>
<td id="S6.T2.2.1.2.1.12" class="ltx_td ltx_align_center ltx_border_t">15.71</td>
<td id="S6.T2.2.1.2.1.13" class="ltx_td ltx_align_center ltx_border_t">23.11</td>
<td id="S6.T2.2.1.2.1.14" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">23.10</td>
<td id="S6.T2.2.1.2.1.15" class="ltx_td ltx_align_center ltx_border_t">25.01 ¬± 8.74</td>
</tr>
<tr id="S6.T2.2.1.3.2" class="ltx_tr">
<td id="S6.T2.2.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r">SynthASpoof</td>
<td id="S6.T2.2.1.3.2.2" class="ltx_td ltx_align_center">8.90</td>
<td id="S6.T2.2.1.3.2.3" class="ltx_td ltx_align_center">25.48</td>
<td id="S6.T2.2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">34.23</td>
<td id="S6.T2.2.1.3.2.5" class="ltx_td ltx_align_center">39.22</td>
<td id="S6.T2.2.1.3.2.6" class="ltx_td ltx_align_center">25.48</td>
<td id="S6.T2.2.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r">34.23</td>
<td id="S6.T2.2.1.3.2.8" class="ltx_td ltx_align_center">39.22</td>
<td id="S6.T2.2.1.3.2.9" class="ltx_td ltx_align_center">8.90</td>
<td id="S6.T2.2.1.3.2.10" class="ltx_td ltx_align_center ltx_border_r">34.23</td>
<td id="S6.T2.2.1.3.2.11" class="ltx_td ltx_align_center">25.48</td>
<td id="S6.T2.2.1.3.2.12" class="ltx_td ltx_align_center">39.22</td>
<td id="S6.T2.2.1.3.2.13" class="ltx_td ltx_align_center ltx_border_rr">8.90</td>
<td id="S6.T2.2.1.3.2.14" class="ltx_td ltx_align_center">26.96 ¬± 12.04</td>
</tr>
<tr id="S6.T2.2.1.4.3" class="ltx_tr">
<td id="S6.T2.2.1.4.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" rowspan="2"><span id="S6.T2.2.1.4.3.1.1" class="ltx_text">PixBis</span></td>
<td id="S6.T2.2.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Authentic</td>
<td id="S6.T2.2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">25.05</td>
<td id="S6.T2.2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">11.19</td>
<td id="S6.T2.2.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.72</td>
<td id="S6.T2.2.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t">34.22</td>
<td id="S6.T2.2.1.4.3.7" class="ltx_td ltx_align_center ltx_border_t">21.67</td>
<td id="S6.T2.2.1.4.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.57</td>
<td id="S6.T2.2.1.4.3.9" class="ltx_td ltx_align_center ltx_border_t">39.11</td>
<td id="S6.T2.2.1.4.3.10" class="ltx_td ltx_align_center ltx_border_t">13.65</td>
<td id="S6.T2.2.1.4.3.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.58</td>
<td id="S6.T2.2.1.4.3.12" class="ltx_td ltx_align_center ltx_border_t">15.00</td>
<td id="S6.T2.2.1.4.3.13" class="ltx_td ltx_align_center ltx_border_t">28.11</td>
<td id="S6.T2.2.1.4.3.14" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">21.80</td>
<td id="S6.T2.2.1.4.3.15" class="ltx_td ltx_align_center ltx_border_t">24.97 ¬± 9.27</td>
</tr>
<tr id="S6.T2.2.1.5.4" class="ltx_tr">
<td id="S6.T2.2.1.5.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">SynthASpoof</td>
<td id="S6.T2.2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b">7.50</td>
<td id="S6.T2.2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b">38.33</td>
<td id="S6.T2.2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">38.70</td>
<td id="S6.T2.2.1.5.4.5" class="ltx_td ltx_align_center ltx_border_b">38.44</td>
<td id="S6.T2.2.1.5.4.6" class="ltx_td ltx_align_center ltx_border_b">38.33</td>
<td id="S6.T2.2.1.5.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">38.70</td>
<td id="S6.T2.2.1.5.4.8" class="ltx_td ltx_align_center ltx_border_b">38.44</td>
<td id="S6.T2.2.1.5.4.9" class="ltx_td ltx_align_center ltx_border_b">7.50</td>
<td id="S6.T2.2.1.5.4.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">38.70</td>
<td id="S6.T2.2.1.5.4.11" class="ltx_td ltx_align_center ltx_border_b">38.33</td>
<td id="S6.T2.2.1.5.4.12" class="ltx_td ltx_align_center ltx_border_b">38.44</td>
<td id="S6.T2.2.1.5.4.13" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr">7.50</td>
<td id="S6.T2.2.1.5.4.14" class="ltx_td ltx_align_center ltx_border_b">30.73 ¬± 14.01</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S6.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S6.T2.4.2" class="ltx_text" style="font-size:90%;">The comparison results of models trained on SynthAspoof and authentic datasets, presented as HTER (%). Models trained on SynthASpoof dataset achieve comparable performances to models trained on authentic datasets in many cases, indicating the usability of SynthASpoof for the development of face PAD.</span></figcaption>
</figure>
<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">To study the feasibility of using SynthASpoof for developing face PAD solutions, we train the models on our SynthASpoof dataset and test on the different authentic datasets from real-world scenarios.
We also train the models on the authentic data by following the cross-dataset (the evaluation data is unknown) evaluation protocols in recent face PAD works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">In these works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, one face PAD dataset is used for the training and the remaining three datasets are separately used as testing data. Therefore, we conduct experiments upon the following 12 scenarios: C ‚Üí I, C ‚Üí M, C ‚Üí O, I ‚Üí C, I ‚Üí M, I ‚Üí O, M ‚Üí C, M ‚Üí I, M ‚Üí O, O ‚Üí M, O ‚Üí I, and O ‚Üí C.
Two face PAD models, ResNet-18 and PixBis, are trained following these 12 protocols to evaluate the real-world scenarios. The results are shown in Tab. <a href="#S6.T2" title="Table 2 ‚Ä£ 6.1 SynthASpoof PAD ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
In general, training on SynthASpoof dataset obtains comparable results to the training on authentic data. For example, the average HTER values of ResNet trained on the authentic data and the synthetic data are 25.01% and 26.96%, respectively.
When testing on M, C, and O, the models trained on authentic data achieved better performance than the models trained on synthetic data. The possible reason of this observation is that there is a domain gap between the trained synthetic and the tested authentic images.
When testing on I, models trained on the SynthASpoof obtain significantly better results than models trained on authentic data, because the SynthASpoof dataset includes a diverse range of replay attacks (more than print ones), enabling the model to generalize well on the Idiap ReplayAttack , which mainly consist of replay attacks. This result indicate the applicability of our SynthASpoof dataset for face PAD.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">We also visualize the feature distribution using t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> on the most challenging case, CASIA, and the best-performing dataset, Idiap ReplayAttack. As shown in Fig. <a href="#S6.F4" title="Figure 4 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (a) and (c), we have the following observations: 1) Different attack types are clustered separately (represented by different shades of blue), indicating potentially poor generalization on unseen attacks, as evidenced by the results on the CASIA dataset. 2) There is a clear distance between the SynthASpoof and the authentic datasets (represented by different shapes), implying the domain gap between synthetic and authentic data.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.1" class="ltx_p">Both quantitative and qualitative results demonstrate the high viability of using SynthASpoof for the development of face PAD algorithms, especially when containing the same type of PA. The observable distance between the synthetic and authentic data will be reduced later in Section <a href="#S6.SS3" title="6.3 Effect of MixStyle ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a> when incorporating MixStyle.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Effect of Cropping and Data Augmentation</h3>

<figure id="S6.T3" class="ltx_table">
<div id="S6.T3.10" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:491.9pt;height:63.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-102.5pt,13.2pt) scale(0.705920927206944,0.705920927206944) ;">
<table id="S6.T3.10.10" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T3.10.10.11.1" class="ltx_tr">
<th id="S6.T3.10.10.11.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="S6.T3.10.10.11.1.1.1" class="ltx_text">Margin</span></th>
<th id="S6.T3.10.10.11.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S6.T3.10.10.11.1.2.1" class="ltx_text">Aug</span></th>
<td id="S6.T3.10.10.11.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">M</td>
<td id="S6.T3.10.10.11.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">C</td>
<td id="S6.T3.10.10.11.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">I</td>
<td id="S6.T3.10.10.11.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">O</td>
<td id="S6.T3.10.10.11.1.7" class="ltx_td ltx_align_center ltx_border_t" colspan="2">Average</td>
</tr>
<tr id="S6.T3.10.10.10" class="ltx_tr">
<td id="S6.T3.1.1.1.1" class="ltx_td ltx_align_center">HTER(%) <math id="S6.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T3.1.1.1.1.m1.1.1" xref="S6.T3.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T3.1.1.1.1.m1.1b"><ci id="S6.T3.1.1.1.1.m1.1.1.cmml" xref="S6.T3.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r">AUC(%) <math id="S6.T3.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.2.2.2.2.m1.1a"><mo stretchy="false" id="S6.T3.2.2.2.2.m1.1.1" xref="S6.T3.2.2.2.2.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.2.2.m1.1b"><ci id="S6.T3.2.2.2.2.m1.1.1.cmml" xref="S6.T3.2.2.2.2.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T3.3.3.3.3" class="ltx_td ltx_align_center">HTER(%) <math id="S6.T3.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.3.3.3.3.m1.1a"><mo stretchy="false" id="S6.T3.3.3.3.3.m1.1.1" xref="S6.T3.3.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T3.3.3.3.3.m1.1b"><ci id="S6.T3.3.3.3.3.m1.1.1.cmml" xref="S6.T3.3.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T3.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r">AUC(%) <math id="S6.T3.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.4.4.4.4.m1.1a"><mo stretchy="false" id="S6.T3.4.4.4.4.m1.1.1" xref="S6.T3.4.4.4.4.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T3.4.4.4.4.m1.1b"><ci id="S6.T3.4.4.4.4.m1.1.1.cmml" xref="S6.T3.4.4.4.4.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T3.5.5.5.5" class="ltx_td ltx_align_center">HTER(%) <math id="S6.T3.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.5.5.5.5.m1.1a"><mo stretchy="false" id="S6.T3.5.5.5.5.m1.1.1" xref="S6.T3.5.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T3.5.5.5.5.m1.1b"><ci id="S6.T3.5.5.5.5.m1.1.1.cmml" xref="S6.T3.5.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T3.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r">AUC(%) <math id="S6.T3.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.6.6.6.6.m1.1a"><mo stretchy="false" id="S6.T3.6.6.6.6.m1.1.1" xref="S6.T3.6.6.6.6.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T3.6.6.6.6.m1.1b"><ci id="S6.T3.6.6.6.6.m1.1.1.cmml" xref="S6.T3.6.6.6.6.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T3.7.7.7.7" class="ltx_td ltx_align_center">HTER(%) <math id="S6.T3.7.7.7.7.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.7.7.7.7.m1.1a"><mo stretchy="false" id="S6.T3.7.7.7.7.m1.1.1" xref="S6.T3.7.7.7.7.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T3.7.7.7.7.m1.1b"><ci id="S6.T3.7.7.7.7.m1.1.1.cmml" xref="S6.T3.7.7.7.7.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.7.7.7.7.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T3.8.8.8.8" class="ltx_td ltx_align_center ltx_border_r">AUC(%) <math id="S6.T3.8.8.8.8.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.8.8.8.8.m1.1a"><mo stretchy="false" id="S6.T3.8.8.8.8.m1.1.1" xref="S6.T3.8.8.8.8.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T3.8.8.8.8.m1.1b"><ci id="S6.T3.8.8.8.8.m1.1.1.cmml" xref="S6.T3.8.8.8.8.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.8.8.8.8.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S6.T3.9.9.9.9" class="ltx_td ltx_align_center">HTER(%) <math id="S6.T3.9.9.9.9.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.9.9.9.9.m1.1a"><mo stretchy="false" id="S6.T3.9.9.9.9.m1.1.1" xref="S6.T3.9.9.9.9.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T3.9.9.9.9.m1.1b"><ci id="S6.T3.9.9.9.9.m1.1.1.cmml" xref="S6.T3.9.9.9.9.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.9.9.9.9.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S6.T3.10.10.10.10" class="ltx_td ltx_align_center">AUC(%) <math id="S6.T3.10.10.10.10.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.10.10.10.10.m1.1a"><mo stretchy="false" id="S6.T3.10.10.10.10.m1.1.1" xref="S6.T3.10.10.10.10.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T3.10.10.10.10.m1.1b"><ci id="S6.T3.10.10.10.10.m1.1.1.cmml" xref="S6.T3.10.10.10.10.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.10.10.10.10.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S6.T3.10.10.12.2" class="ltx_tr">
<th id="S6.T3.10.10.12.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">0%</th>
<th id="S6.T3.10.10.12.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">w/o</th>
<td id="S6.T3.10.10.12.2.3" class="ltx_td ltx_align_center ltx_border_t">21.43</td>
<td id="S6.T3.10.10.12.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79.96</td>
<td id="S6.T3.10.10.12.2.5" class="ltx_td ltx_align_center ltx_border_t">42.00</td>
<td id="S6.T3.10.10.12.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.33</td>
<td id="S6.T3.10.10.12.2.7" class="ltx_td ltx_align_center ltx_border_t">15.90</td>
<td id="S6.T3.10.10.12.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.36</td>
<td id="S6.T3.10.10.12.2.9" class="ltx_td ltx_align_center ltx_border_t">36.33</td>
<td id="S6.T3.10.10.12.2.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.27</td>
<td id="S6.T3.10.10.12.2.11" class="ltx_td ltx_align_center ltx_border_t">28.92</td>
<td id="S6.T3.10.10.12.2.12" class="ltx_td ltx_align_center ltx_border_t">72.73</td>
</tr>
<tr id="S6.T3.10.10.13.3" class="ltx_tr">
<th id="S6.T3.10.10.13.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">0%</th>
<th id="S6.T3.10.10.13.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">w/</th>
<td id="S6.T3.10.10.13.3.3" class="ltx_td ltx_align_center ltx_border_t">24.52</td>
<td id="S6.T3.10.10.13.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">82.22</td>
<td id="S6.T3.10.10.13.3.5" class="ltx_td ltx_align_center ltx_border_t">39.22</td>
<td id="S6.T3.10.10.13.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.00</td>
<td id="S6.T3.10.10.13.3.7" class="ltx_td ltx_align_center ltx_border_t">8.90</td>
<td id="S6.T3.10.10.13.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.96</td>
<td id="S6.T3.10.10.13.3.9" class="ltx_td ltx_align_center ltx_border_t">30.91</td>
<td id="S6.T3.10.10.13.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.03</td>
<td id="S6.T3.10.10.13.3.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.10.10.13.3.11.1" class="ltx_text ltx_font_bold">25.89</span></td>
<td id="S6.T3.10.10.13.3.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.10.10.13.3.12.1" class="ltx_text ltx_font_bold">78.80</span></td>
</tr>
<tr id="S6.T3.10.10.14.4" class="ltx_tr">
<th id="S6.T3.10.10.14.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t">5%</th>
<th id="S6.T3.10.10.14.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">w/</th>
<td id="S6.T3.10.10.14.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">24.29</td>
<td id="S6.T3.10.10.14.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">79.18</td>
<td id="S6.T3.10.10.14.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">47.00</td>
<td id="S6.T3.10.10.14.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">52.33</td>
<td id="S6.T3.10.10.14.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">11.45</td>
<td id="S6.T3.10.10.14.4.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">94.99</td>
<td id="S6.T3.10.10.14.4.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">35.77</td>
<td id="S6.T3.10.10.14.4.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">67.98</td>
<td id="S6.T3.10.10.14.4.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">29.63</td>
<td id="S6.T3.10.10.14.4.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">73.62</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T3.12.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S6.T3.13.2" class="ltx_text" style="font-size:90%;">The impact of margin extension of face bounding box (extracted from MTCNN) and the effect of using data augmentation by training models on synthetic data and testing separately on four authentic face PAD datasets (M, C, I, and O). The results show that models trained on face images without bounding box extension outperformed models trained on slightly extended face regions. Moreover, applying data augmentation resulted in a better generalized model.</span></figcaption>
</figure>
<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">We explore the impact of data augmentation and adding a margin to the face crop by conducting experiments on the synthetic (training) and the authentic data (test). The results are shown in Tab. <a href="#S6.T3" title="Table 3 ‚Ä£ 6.2 Effect of Cropping and Data Augmentation ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
We use the following data augmentation <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The used augmentation library: Albumentation - <a target="_blank" href="https://albumentations.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://albumentations.ai/</a></span></span></span> techniques: horizontal flipping, scaling and rotation with a limit of 0.1%, random gamma adjustment within a gamma range from 80 to 180, RGB shifting with a limit of 20, and color jittering with a limit of 0.1%.
As shown in Tab. <a href="#S6.T3" title="Table 3 ‚Ä£ 6.2 Effect of Cropping and Data Augmentation ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, using a combined augmentation operation obtains a significant average performance improvement, decreasing the average HTER values from 28.92% to 25.89%.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">As previous work have shown that the consideration area beyond the face is beneficial for PAD performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we argue that this enhancement might be related to properties of specific limited dataset and might not generalize well on unknown data, therefore we study the inclusion of such an area. We compare the results between cropping face region without extension and with 5% extension of bounding box extracted from MTCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. The results in Tab. <a href="#S6.T3" title="Table 3 ‚Ä£ 6.2 Effect of Cropping and Data Augmentation ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> indicate that cropping faces with extension leads to a lower PAD performance on unknown datasets.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">As a result, in the following experiments, all models are trained on the cropped faces without bounding box extension and using data augmentation to enhance the PAD generalizability.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Effect of MixStyle</h3>

<figure id="S6.T4" class="ltx_table">
<div id="S6.T4.10" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:491.9pt;height:76.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-100.1pt,15.6pt) scale(0.710823134032852,0.710823134032852) ;">
<table id="S6.T4.10.10" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T4.10.10.11.1" class="ltx_tr">
<th id="S6.T4.10.10.11.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S6.T4.10.10.11.1.1.1" class="ltx_text">Method</span></th>
<th id="S6.T4.10.10.11.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">M</th>
<th id="S6.T4.10.10.11.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">C</th>
<th id="S6.T4.10.10.11.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">I</th>
<th id="S6.T4.10.10.11.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">O</th>
<th id="S6.T4.10.10.11.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2">Average</th>
</tr>
<tr id="S6.T4.10.10.10" class="ltx_tr">
<th id="S6.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">HTER(%) <math id="S6.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T4.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T4.1.1.1.1.m1.1.1" xref="S6.T4.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T4.1.1.1.1.m1.1b"><ci id="S6.T4.1.1.1.1.m1.1.1.cmml" xref="S6.T4.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S6.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">AUC(%) <math id="S6.T4.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.2.2.2.2.m1.1a"><mo stretchy="false" id="S6.T4.2.2.2.2.m1.1.1" xref="S6.T4.2.2.2.2.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T4.2.2.2.2.m1.1b"><ci id="S6.T4.2.2.2.2.m1.1.1.cmml" xref="S6.T4.2.2.2.2.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S6.T4.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">HTER(%) <math id="S6.T4.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T4.3.3.3.3.m1.1a"><mo stretchy="false" id="S6.T4.3.3.3.3.m1.1.1" xref="S6.T4.3.3.3.3.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T4.3.3.3.3.m1.1b"><ci id="S6.T4.3.3.3.3.m1.1.1.cmml" xref="S6.T4.3.3.3.3.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S6.T4.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">AUC(%) <math id="S6.T4.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.4.4.4.4.m1.1a"><mo stretchy="false" id="S6.T4.4.4.4.4.m1.1.1" xref="S6.T4.4.4.4.4.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T4.4.4.4.4.m1.1b"><ci id="S6.T4.4.4.4.4.m1.1.1.cmml" xref="S6.T4.4.4.4.4.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S6.T4.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">HTER(%) <math id="S6.T4.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T4.5.5.5.5.m1.1a"><mo stretchy="false" id="S6.T4.5.5.5.5.m1.1.1" xref="S6.T4.5.5.5.5.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T4.5.5.5.5.m1.1b"><ci id="S6.T4.5.5.5.5.m1.1.1.cmml" xref="S6.T4.5.5.5.5.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S6.T4.6.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">AUC(%) <math id="S6.T4.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.6.6.6.6.m1.1a"><mo stretchy="false" id="S6.T4.6.6.6.6.m1.1.1" xref="S6.T4.6.6.6.6.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T4.6.6.6.6.m1.1b"><ci id="S6.T4.6.6.6.6.m1.1.1.cmml" xref="S6.T4.6.6.6.6.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S6.T4.7.7.7.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">HTER(%) <math id="S6.T4.7.7.7.7.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T4.7.7.7.7.m1.1a"><mo stretchy="false" id="S6.T4.7.7.7.7.m1.1.1" xref="S6.T4.7.7.7.7.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T4.7.7.7.7.m1.1b"><ci id="S6.T4.7.7.7.7.m1.1.1.cmml" xref="S6.T4.7.7.7.7.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.7.7.7.7.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S6.T4.8.8.8.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">AUC(%) <math id="S6.T4.8.8.8.8.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.8.8.8.8.m1.1a"><mo stretchy="false" id="S6.T4.8.8.8.8.m1.1.1" xref="S6.T4.8.8.8.8.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T4.8.8.8.8.m1.1b"><ci id="S6.T4.8.8.8.8.m1.1.1.cmml" xref="S6.T4.8.8.8.8.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.8.8.8.8.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S6.T4.9.9.9.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">HTER(%) <math id="S6.T4.9.9.9.9.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T4.9.9.9.9.m1.1a"><mo stretchy="false" id="S6.T4.9.9.9.9.m1.1.1" xref="S6.T4.9.9.9.9.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S6.T4.9.9.9.9.m1.1b"><ci id="S6.T4.9.9.9.9.m1.1.1.cmml" xref="S6.T4.9.9.9.9.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.9.9.9.9.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S6.T4.10.10.10.10" class="ltx_td ltx_align_center ltx_th ltx_th_column">AUC(%) <math id="S6.T4.10.10.10.10.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.10.10.10.10.m1.1a"><mo stretchy="false" id="S6.T4.10.10.10.10.m1.1.1" xref="S6.T4.10.10.10.10.m1.1.1.cmml">‚Üë</mo><annotation-xml encoding="MathML-Content" id="S6.T4.10.10.10.10.m1.1b"><ci id="S6.T4.10.10.10.10.m1.1.1.cmml" xref="S6.T4.10.10.10.10.m1.1.1">‚Üë</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.10.10.10.10.m1.1c">\uparrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T4.10.10.12.1" class="ltx_tr">
<th id="S6.T4.10.10.12.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">ResNet</th>
<td id="S6.T4.10.10.12.1.2" class="ltx_td ltx_align_center ltx_border_t">25.48</td>
<td id="S6.T4.10.10.12.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79.54</td>
<td id="S6.T4.10.10.12.1.4" class="ltx_td ltx_align_center ltx_border_t">39.22</td>
<td id="S6.T4.10.10.12.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.00</td>
<td id="S6.T4.10.10.12.1.6" class="ltx_td ltx_align_center ltx_border_t">8.90</td>
<td id="S6.T4.10.10.12.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.96</td>
<td id="S6.T4.10.10.12.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.10.10.12.1.8.1" class="ltx_text ltx_font_bold">34.23</span></td>
<td id="S6.T4.10.10.12.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T4.10.10.12.1.9.1" class="ltx_text ltx_font_bold">71.48</span></td>
<td id="S6.T4.10.10.12.1.10" class="ltx_td ltx_align_center ltx_border_t">26.96</td>
<td id="S6.T4.10.10.12.1.11" class="ltx_td ltx_align_center ltx_border_t">77.50</td>
</tr>
<tr id="S6.T4.10.10.13.2" class="ltx_tr">
<th id="S6.T4.10.10.13.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">¬†¬†‚ÄÉ+MixStyle</th>
<td id="S6.T4.10.10.13.2.2" class="ltx_td ltx_align_center"><span id="S6.T4.10.10.13.2.2.1" class="ltx_text ltx_font_bold">21.43</span></td>
<td id="S6.T4.10.10.13.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T4.10.10.13.2.3.1" class="ltx_text ltx_font_bold">81.97</span></td>
<td id="S6.T4.10.10.13.2.4" class="ltx_td ltx_align_center"><span id="S6.T4.10.10.13.2.4.1" class="ltx_text ltx_font_bold">22.78</span></td>
<td id="S6.T4.10.10.13.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T4.10.10.13.2.5.1" class="ltx_text ltx_font_bold">83.66</span></td>
<td id="S6.T4.10.10.13.2.6" class="ltx_td ltx_align_center"><span id="S6.T4.10.10.13.2.6.1" class="ltx_text ltx_font_bold">6.70</span></td>
<td id="S6.T4.10.10.13.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T4.10.10.13.2.7.1" class="ltx_text ltx_font_bold">98.30</span></td>
<td id="S6.T4.10.10.13.2.8" class="ltx_td ltx_align_center">36.07</td>
<td id="S6.T4.10.10.13.2.9" class="ltx_td ltx_align_center ltx_border_r">69.52</td>
<td id="S6.T4.10.10.13.2.10" class="ltx_td ltx_align_center"><span id="S6.T4.10.10.13.2.10.1" class="ltx_text ltx_font_bold">21.75</span></td>
<td id="S6.T4.10.10.13.2.11" class="ltx_td ltx_align_center"><span id="S6.T4.10.10.13.2.11.1" class="ltx_text ltx_font_bold">83.36</span></td>
</tr>
<tr id="S6.T4.10.10.14.3" class="ltx_tr">
<th id="S6.T4.10.10.14.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">PixBis</th>
<td id="S6.T4.10.10.14.3.2" class="ltx_td ltx_align_center ltx_border_t">38.33</td>
<td id="S6.T4.10.10.14.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.87</td>
<td id="S6.T4.10.10.14.3.4" class="ltx_td ltx_align_center ltx_border_t">38.44</td>
<td id="S6.T4.10.10.14.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.79</td>
<td id="S6.T4.10.10.14.3.6" class="ltx_td ltx_align_center ltx_border_t">7.50</td>
<td id="S6.T4.10.10.14.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.88</td>
<td id="S6.T4.10.10.14.3.8" class="ltx_td ltx_align_center ltx_border_t">35.77</td>
<td id="S6.T4.10.10.14.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.50</td>
<td id="S6.T4.10.10.14.3.10" class="ltx_td ltx_align_center ltx_border_t">30.74</td>
<td id="S6.T4.10.10.14.3.11" class="ltx_td ltx_align_center ltx_border_t">72.26</td>
</tr>
<tr id="S6.T4.10.10.15.4" class="ltx_tr">
<th id="S6.T4.10.10.15.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">¬†¬†‚ÄÉ+MixStyle</th>
<td id="S6.T4.10.10.15.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T4.10.10.15.4.2.1" class="ltx_text ltx_font_bold">30.48</span></td>
<td id="S6.T4.10.10.15.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T4.10.10.15.4.3.1" class="ltx_text ltx_font_bold">70.38</span></td>
<td id="S6.T4.10.10.15.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T4.10.10.15.4.4.1" class="ltx_text ltx_font_bold">32.00</span></td>
<td id="S6.T4.10.10.15.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T4.10.10.15.4.5.1" class="ltx_text ltx_font_bold">69.36</span></td>
<td id="S6.T4.10.10.15.4.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T4.10.10.15.4.6.1" class="ltx_text ltx_font_bold">6.10</span></td>
<td id="S6.T4.10.10.15.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T4.10.10.15.4.7.1" class="ltx_text ltx_font_bold">98.29</span></td>
<td id="S6.T4.10.10.15.4.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T4.10.10.15.4.8.1" class="ltx_text ltx_font_bold">34.46</span></td>
<td id="S6.T4.10.10.15.4.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T4.10.10.15.4.9.1" class="ltx_text ltx_font_bold">67.71</span></td>
<td id="S6.T4.10.10.15.4.10" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T4.10.10.15.4.10.1" class="ltx_text ltx_font_bold">25.76</span></td>
<td id="S6.T4.10.10.15.4.11" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T4.10.10.15.4.11.1" class="ltx_text ltx_font_bold">76.44</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T4.12.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S6.T4.13.2" class="ltx_text" style="font-size:90%;">The ablation study of MixStyle for adapting models from the synthetic domain to authentic domain. Note that the target domain (authentic face PAD) is used in the training process for MixStyle without labels. The bold number indicates the best performance for each method, pointing out that the usage of MixStyle resulted in an enhanced PAD performance in general.</span></figcaption>
</figure>
<figure id="S6.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.02660/assets/x3.png" id="S6.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="351" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S6.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">ResNet</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2303.02660/assets/x4.png" id="S6.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="351" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S6.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">PixBis</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S6.F3.3.2" class="ltx_text" style="font-size:90%;">ROC curves of ResNet (a) and PixBis (b) trained on SynthASpoof dataset and tested on four authentic face PAD datasets (M, C, I, and O). The light colors represent the baseline model and the heavy colors indicate the models trained with the help of MixStyle, mostly leading to better performance (higher curves).</span></figcaption>
</figure>
<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">As discussed in Sec. <a href="#S6.SS1" title="6.1 SynthASpoof PAD ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a> and showed in Fig. <a href="#S6.F4" title="Figure 4 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, there is a distance between the training synthetic and the testing authentic samples.
Motivated by this, MixStyle <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> is adapted to transfer the domain-related information from the authentic data to the synthetic data. In the training process, the authentic face PAD dataset is used without label only for calculating feature statistics, i.e., the loss is only computed based on the synthetic data.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">Tab. <a href="#S6.T4" title="Table 4 ‚Ä£ 6.3 Effect of MixStyle ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that applying MixStyle leads to better model generalizability in most cases. The average HTER values on four testing authentic face PAD datasets decreased from 26.96% to 21.75% by ResNet and from 30.74% to 25.76% by PixBis, while the AUC values increased from 77.50% to 83.36% by ResNet and from 72.26% to 76.44% by PixBis. The ROC curves shown in Fig. <a href="#S6.F3" title="Figure 3 ‚Ä£ 6.3 Effect of MixStyle ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrate the consistent observation for the baseline model and the model with MixStyle.</p>
</div>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">To provide a more detailed understanding of the benefit of MixStyle, we visualize the feature space by ResNet models on our most challenging dataset CAISA and the best performed dataset Idiap ReplayAttack in Fig. <a href="#S6.F4" title="Figure 4 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We have the following observations: 1) Features of different types of synthetic attacks (different blue squares) are clustered more closely by applying MixStyle than baseline models, as well as for bona fide, indicating a better generalizability on unknown attack types. 2) Features of authentic data are clustered more closely within the same class of data by applying MixStyle than baseline models. 3) The distance between features of synthetic (‚óº) and authentic data (‚úñ) is visually reduced by using MixStyle.</p>
</div>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p">The quantitative and visual results discussed above demonstrate that MixStyle helps to enhance the PAD performance of models trained on the synthetic data.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Effect of a supplementing Authentic Data with SynthASpoof</h3>

<figure id="S6.T5" class="ltx_table">
<div id="S6.T5.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:486.9pt;height:138.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-136.1pt,38.7pt) scale(0.641488176713748,0.641488176713748) ;">
<table id="S6.T5.2.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T5.2.1.1.1" class="ltx_tr">
<td id="S6.T5.2.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Method</td>
<td id="S6.T5.2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">C ‚Üí I</td>
<td id="S6.T5.2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">C ‚Üí M</td>
<td id="S6.T5.2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">C ‚Üí O</td>
<td id="S6.T5.2.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">I ‚Üí C</td>
<td id="S6.T5.2.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">I ‚Üí M</td>
<td id="S6.T5.2.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">I ‚Üí O</td>
<td id="S6.T5.2.1.1.1.8" class="ltx_td ltx_align_center ltx_border_t">M ‚Üí C</td>
<td id="S6.T5.2.1.1.1.9" class="ltx_td ltx_align_center ltx_border_t">M ‚Üí I</td>
<td id="S6.T5.2.1.1.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">M ‚Üí O</td>
<td id="S6.T5.2.1.1.1.11" class="ltx_td ltx_align_center ltx_border_t">O ‚Üí M</td>
<td id="S6.T5.2.1.1.1.12" class="ltx_td ltx_align_center ltx_border_t">O ‚Üí C</td>
<td id="S6.T5.2.1.1.1.13" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">O ‚Üí I</td>
<td id="S6.T5.2.1.1.1.14" class="ltx_td ltx_align_center ltx_border_t">Average</td>
</tr>
<tr id="S6.T5.2.1.2.2" class="ltx_tr">
<td id="S6.T5.2.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Binary CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="S6.T5.2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">45.80</td>
<td id="S6.T5.2.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">25.60</td>
<td id="S6.T5.2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.40</td>
<td id="S6.T5.2.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">44.40</td>
<td id="S6.T5.2.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">48.60</td>
<td id="S6.T5.2.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">45.40</td>
<td id="S6.T5.2.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t">50.10</td>
<td id="S6.T5.2.1.2.2.9" class="ltx_td ltx_align_center ltx_border_t">49.90</td>
<td id="S6.T5.2.1.2.2.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.40</td>
<td id="S6.T5.2.1.2.2.11" class="ltx_td ltx_align_center ltx_border_t">30.20</td>
<td id="S6.T5.2.1.2.2.12" class="ltx_td ltx_align_center ltx_border_t">41.20</td>
<td id="S6.T5.2.1.2.2.13" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">47.40</td>
<td id="S6.T5.2.1.2.2.14" class="ltx_td ltx_align_center ltx_border_t">41.37 ¬± 8.42</td>
</tr>
<tr id="S6.T5.2.1.3.3" class="ltx_tr">
<td id="S6.T5.2.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r">ADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S6.T5.2.1.3.3.2" class="ltx_td ltx_align_center">17.50</td>
<td id="S6.T5.2.1.3.3.3" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.3.3.3.1" class="ltx_text ltx_font_italic">9.30</span></td>
<td id="S6.T5.2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r">29.10</td>
<td id="S6.T5.2.1.3.3.5" class="ltx_td ltx_align_center">41.60</td>
<td id="S6.T5.2.1.3.3.6" class="ltx_td ltx_align_center">30.50</td>
<td id="S6.T5.2.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r">39.60</td>
<td id="S6.T5.2.1.3.3.8" class="ltx_td ltx_align_center">17.70</td>
<td id="S6.T5.2.1.3.3.9" class="ltx_td ltx_align_center">5.10</td>
<td id="S6.T5.2.1.3.3.10" class="ltx_td ltx_align_center ltx_border_r">31.20</td>
<td id="S6.T5.2.1.3.3.11" class="ltx_td ltx_align_center">31.50</td>
<td id="S6.T5.2.1.3.3.12" class="ltx_td ltx_align_center">19.80</td>
<td id="S6.T5.2.1.3.3.13" class="ltx_td ltx_align_center ltx_border_rr">26.80</td>
<td id="S6.T5.2.1.3.3.14" class="ltx_td ltx_align_center">24.98 ¬± 11.28</td>
</tr>
<tr id="S6.T5.2.1.4.4" class="ltx_tr">
<td id="S6.T5.2.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r">DR-MD-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</td>
<td id="S6.T5.2.1.4.4.2" class="ltx_td ltx_align_center">26.10</td>
<td id="S6.T5.2.1.4.4.3" class="ltx_td ltx_align_center">20.20</td>
<td id="S6.T5.2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">24.70</td>
<td id="S6.T5.2.1.4.4.5" class="ltx_td ltx_align_center">39.20</td>
<td id="S6.T5.2.1.4.4.6" class="ltx_td ltx_align_center">23.20</td>
<td id="S6.T5.2.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">33.60</td>
<td id="S6.T5.2.1.4.4.8" class="ltx_td ltx_align_center">34.30</td>
<td id="S6.T5.2.1.4.4.9" class="ltx_td ltx_align_center">8.70</td>
<td id="S6.T5.2.1.4.4.10" class="ltx_td ltx_align_center ltx_border_r">31.70</td>
<td id="S6.T5.2.1.4.4.11" class="ltx_td ltx_align_center">22.00</td>
<td id="S6.T5.2.1.4.4.12" class="ltx_td ltx_align_center">21.80</td>
<td id="S6.T5.2.1.4.4.13" class="ltx_td ltx_align_center ltx_border_rr">27.60</td>
<td id="S6.T5.2.1.4.4.14" class="ltx_td ltx_align_center">26.09 ¬± 8.05</td>
</tr>
<tr id="S6.T5.2.1.5.5" class="ltx_tr">
<td id="S6.T5.2.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r">DR-UDA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S6.T5.2.1.5.5.2" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.5.5.2.1" class="ltx_text ltx_font_italic">15.60</span></td>
<td id="S6.T5.2.1.5.5.3" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.5.5.3.1" class="ltx_text ltx_font_bold">9.00</span></td>
<td id="S6.T5.2.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">28.70</td>
<td id="S6.T5.2.1.5.5.5" class="ltx_td ltx_align_center">34.20</td>
<td id="S6.T5.2.1.5.5.6" class="ltx_td ltx_align_center">29.00</td>
<td id="S6.T5.2.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r">38.50</td>
<td id="S6.T5.2.1.5.5.8" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.5.5.8.1" class="ltx_text ltx_font_italic">16.80</span></td>
<td id="S6.T5.2.1.5.5.9" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.5.5.9.1" class="ltx_text ltx_font_bold">3.00</span></td>
<td id="S6.T5.2.1.5.5.10" class="ltx_td ltx_align_center ltx_border_r">30.20</td>
<td id="S6.T5.2.1.5.5.11" class="ltx_td ltx_align_center">27.40</td>
<td id="S6.T5.2.1.5.5.12" class="ltx_td ltx_align_center">19.50</td>
<td id="S6.T5.2.1.5.5.13" class="ltx_td ltx_align_center ltx_border_rr">25.40</td>
<td id="S6.T5.2.1.5.5.14" class="ltx_td ltx_align_center">23.11 ¬± 10.50</td>
</tr>
<tr id="S6.T5.2.1.6.6" class="ltx_tr">
<td id="S6.T5.2.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r">SDFANet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="S6.T5.2.1.6.6.2" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.6.6.2.1" class="ltx_text ltx_font_bold">15.50</span></td>
<td id="S6.T5.2.1.6.6.3" class="ltx_td ltx_align_center">12.14</td>
<td id="S6.T5.2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T5.2.1.6.6.4.1" class="ltx_text ltx_font_italic">17.08</span></td>
<td id="S6.T5.2.1.6.6.5" class="ltx_td ltx_align_center">46.11</td>
<td id="S6.T5.2.1.6.6.6" class="ltx_td ltx_align_center">24.29</td>
<td id="S6.T5.2.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r">41.56</td>
<td id="S6.T5.2.1.6.6.8" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.6.6.8.1" class="ltx_text ltx_font_bold">13.33</span></td>
<td id="S6.T5.2.1.6.6.9" class="ltx_td ltx_align_center">11.36</td>
<td id="S6.T5.2.1.6.6.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T5.2.1.6.6.10.1" class="ltx_text ltx_font_bold">18.92</span></td>
<td id="S6.T5.2.1.6.6.11" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.6.6.11.1" class="ltx_text ltx_font_bold">11.67</span></td>
<td id="S6.T5.2.1.6.6.12" class="ltx_td ltx_align_center">19.33</td>
<td id="S6.T5.2.1.6.6.13" class="ltx_td ltx_align_center ltx_border_rr">18.71</td>
<td id="S6.T5.2.1.6.6.14" class="ltx_td ltx_align_center">20.83 ¬± 11.44</td>
</tr>
<tr id="S6.T5.2.1.7.7" class="ltx_tr">
<td id="S6.T5.2.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">ResNet</td>
<td id="S6.T5.2.1.7.7.2" class="ltx_td ltx_align_center ltx_border_t">38.85</td>
<td id="S6.T5.2.1.7.7.3" class="ltx_td ltx_align_center ltx_border_t">18.10</td>
<td id="S6.T5.2.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.94</td>
<td id="S6.T5.2.1.7.7.5" class="ltx_td ltx_align_center ltx_border_t">42.22</td>
<td id="S6.T5.2.1.7.7.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T5.2.1.7.7.6.1" class="ltx_text ltx_font_italic">18.81</span></td>
<td id="S6.T5.2.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.42</td>
<td id="S6.T5.2.1.7.7.8" class="ltx_td ltx_align_center ltx_border_t">27.11</td>
<td id="S6.T5.2.1.7.7.9" class="ltx_td ltx_align_center ltx_border_t">16.30</td>
<td id="S6.T5.2.1.7.7.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30.49</td>
<td id="S6.T5.2.1.7.7.11" class="ltx_td ltx_align_center ltx_border_t">15.71</td>
<td id="S6.T5.2.1.7.7.12" class="ltx_td ltx_align_center ltx_border_t">23.11</td>
<td id="S6.T5.2.1.7.7.13" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">23.10</td>
<td id="S6.T5.2.1.7.7.14" class="ltx_td ltx_align_center ltx_border_t">25.01 ¬± 8.74</td>
</tr>
<tr id="S6.T5.2.1.8.8" class="ltx_tr">
<td id="S6.T5.2.1.8.8.1" class="ltx_td ltx_align_left ltx_border_r">+ SynthASpoof</td>
<td id="S6.T5.2.1.8.8.2" class="ltx_td ltx_align_center">36.80</td>
<td id="S6.T5.2.1.8.8.3" class="ltx_td ltx_align_center">13.10</td>
<td id="S6.T5.2.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">20.88</td>
<td id="S6.T5.2.1.8.8.5" class="ltx_td ltx_align_center">33.33</td>
<td id="S6.T5.2.1.8.8.6" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.8.8.6.1" class="ltx_text ltx_font_italic">18.81</span></td>
<td id="S6.T5.2.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r">31.65</td>
<td id="S6.T5.2.1.8.8.8" class="ltx_td ltx_align_center">28.67</td>
<td id="S6.T5.2.1.8.8.9" class="ltx_td ltx_align_center">11.85</td>
<td id="S6.T5.2.1.8.8.10" class="ltx_td ltx_align_center ltx_border_r">26.53</td>
<td id="S6.T5.2.1.8.8.11" class="ltx_td ltx_align_center">19.05</td>
<td id="S6.T5.2.1.8.8.12" class="ltx_td ltx_align_center">20.44</td>
<td id="S6.T5.2.1.8.8.13" class="ltx_td ltx_align_center ltx_border_rr">18.95</td>
<td id="S6.T5.2.1.8.8.14" class="ltx_td ltx_align_center">23.34 ¬± 7.97</td>
</tr>
<tr id="S6.T5.2.1.9.9" class="ltx_tr">
<td id="S6.T5.2.1.9.9.1" class="ltx_td ltx_align_left ltx_border_r">+SynthASpoof + MixStyle</td>
<td id="S6.T5.2.1.9.9.2" class="ltx_td ltx_align_center">22.50</td>
<td id="S6.T5.2.1.9.9.3" class="ltx_td ltx_align_center">12.86</td>
<td id="S6.T5.2.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">19.49</td>
<td id="S6.T5.2.1.9.9.5" class="ltx_td ltx_align_center">28.56</td>
<td id="S6.T5.2.1.9.9.6" class="ltx_td ltx_align_center">19.52</td>
<td id="S6.T5.2.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T5.2.1.9.9.7.1" class="ltx_text ltx_font_italic">26.96</span></td>
<td id="S6.T5.2.1.9.9.8" class="ltx_td ltx_align_center">17.44</td>
<td id="S6.T5.2.1.9.9.9" class="ltx_td ltx_align_center">11.10</td>
<td id="S6.T5.2.1.9.9.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T5.2.1.9.9.10.1" class="ltx_text ltx_font_italic">20.95</span></td>
<td id="S6.T5.2.1.9.9.11" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.9.9.11.1" class="ltx_text ltx_font_italic">14.76</span></td>
<td id="S6.T5.2.1.9.9.12" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.9.9.12.1" class="ltx_text ltx_font_bold">18.67</span></td>
<td id="S6.T5.2.1.9.9.13" class="ltx_td ltx_align_center ltx_border_rr">22.15</td>
<td id="S6.T5.2.1.9.9.14" class="ltx_td ltx_align_center">
<span id="S6.T5.2.1.9.9.14.1" class="ltx_text ltx_font_italic">19.58</span> ¬± <span id="S6.T5.2.1.9.9.14.2" class="ltx_text ltx_font_bold">5.20</span>
</td>
</tr>
<tr id="S6.T5.2.1.10.10" class="ltx_tr">
<td id="S6.T5.2.1.10.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">PixBis</td>
<td id="S6.T5.2.1.10.10.2" class="ltx_td ltx_align_center ltx_border_t">25.05</td>
<td id="S6.T5.2.1.10.10.3" class="ltx_td ltx_align_center ltx_border_t">11.19</td>
<td id="S6.T5.2.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.72</td>
<td id="S6.T5.2.1.10.10.5" class="ltx_td ltx_align_center ltx_border_t">34.22</td>
<td id="S6.T5.2.1.10.10.6" class="ltx_td ltx_align_center ltx_border_t">21.67</td>
<td id="S6.T5.2.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.57</td>
<td id="S6.T5.2.1.10.10.8" class="ltx_td ltx_align_center ltx_border_t">39.11</td>
<td id="S6.T5.2.1.10.10.9" class="ltx_td ltx_align_center ltx_border_t">13.65</td>
<td id="S6.T5.2.1.10.10.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.58</td>
<td id="S6.T5.2.1.10.10.11" class="ltx_td ltx_align_center ltx_border_t">15.00</td>
<td id="S6.T5.2.1.10.10.12" class="ltx_td ltx_align_center ltx_border_t">28.11</td>
<td id="S6.T5.2.1.10.10.13" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">21.80</td>
<td id="S6.T5.2.1.10.10.14" class="ltx_td ltx_align_center ltx_border_t">24.97 ¬± 9.27</td>
</tr>
<tr id="S6.T5.2.1.11.11" class="ltx_tr">
<td id="S6.T5.2.1.11.11.1" class="ltx_td ltx_align_left ltx_border_r">+ SynthASpoof</td>
<td id="S6.T5.2.1.11.11.2" class="ltx_td ltx_align_center">20.15</td>
<td id="S6.T5.2.1.11.11.3" class="ltx_td ltx_align_center">24.05</td>
<td id="S6.T5.2.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">26.55</td>
<td id="S6.T5.2.1.11.11.5" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.11.11.5.1" class="ltx_text ltx_font_italic">27.67</span></td>
<td id="S6.T5.2.1.11.11.6" class="ltx_td ltx_align_center">23.10</td>
<td id="S6.T5.2.1.11.11.7" class="ltx_td ltx_align_center ltx_border_r">32.41</td>
<td id="S6.T5.2.1.11.11.8" class="ltx_td ltx_align_center">26.56</td>
<td id="S6.T5.2.1.11.11.9" class="ltx_td ltx_align_center">8.10</td>
<td id="S6.T5.2.1.11.11.10" class="ltx_td ltx_align_center ltx_border_r">28.18</td>
<td id="S6.T5.2.1.11.11.11" class="ltx_td ltx_align_center">15.95</td>
<td id="S6.T5.2.1.11.11.12" class="ltx_td ltx_align_center"><span id="S6.T5.2.1.11.11.12.1" class="ltx_text ltx_font_italic">19.00</span></td>
<td id="S6.T5.2.1.11.11.13" class="ltx_td ltx_align_center ltx_border_rr"><span id="S6.T5.2.1.11.11.13.1" class="ltx_text ltx_font_italic">16.50</span></td>
<td id="S6.T5.2.1.11.11.14" class="ltx_td ltx_align_center">22.35 ¬± <span id="S6.T5.2.1.11.11.14.1" class="ltx_text ltx_font_italic">6.72</span>
</td>
</tr>
<tr id="S6.T5.2.1.12.12" class="ltx_tr">
<td id="S6.T5.2.1.12.12.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">+SynthASpoof + MixStyle</td>
<td id="S6.T5.2.1.12.12.2" class="ltx_td ltx_align_center ltx_border_b">22.02</td>
<td id="S6.T5.2.1.12.12.3" class="ltx_td ltx_align_center ltx_border_b">11.19</td>
<td id="S6.T5.2.1.12.12.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T5.2.1.12.12.4.1" class="ltx_text ltx_font_bold">16.48</span></td>
<td id="S6.T5.2.1.12.12.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T5.2.1.12.12.5.1" class="ltx_text ltx_font_bold">23.00</span></td>
<td id="S6.T5.2.1.12.12.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T5.2.1.12.12.6.1" class="ltx_text ltx_font_bold">14.05</span></td>
<td id="S6.T5.2.1.12.12.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S6.T5.2.1.12.12.7.1" class="ltx_text ltx_font_bold">23.74</span></td>
<td id="S6.T5.2.1.12.12.8" class="ltx_td ltx_align_center ltx_border_b">36.56</td>
<td id="S6.T5.2.1.12.12.9" class="ltx_td ltx_align_center ltx_border_b"><span id="S6.T5.2.1.12.12.9.1" class="ltx_text ltx_font_italic">4.05</span></td>
<td id="S6.T5.2.1.12.12.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">28.71</td>
<td id="S6.T5.2.1.12.12.11" class="ltx_td ltx_align_center ltx_border_b">15.71</td>
<td id="S6.T5.2.1.12.12.12" class="ltx_td ltx_align_center ltx_border_b">21.44</td>
<td id="S6.T5.2.1.12.12.13" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S6.T5.2.1.12.12.13.1" class="ltx_text ltx_font_bold">12.95</span></td>
<td id="S6.T5.2.1.12.12.14" class="ltx_td ltx_align_center ltx_border_b">
<span id="S6.T5.2.1.12.12.14.1" class="ltx_text ltx_font_bold">19.16</span> ¬± 8.63</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S6.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S6.T5.4.2" class="ltx_text" style="font-size:90%;">The results of PAD models trained on a combined training dataset, presented as HTER (%). Combining SynthASpoof data and the authentic PAD images boost the generalizability of PAD models. Moreover, incorporating MixStyle into the training process leads to even a better generalized PAD models. In comparison to existing works, supplementing the authentic data with SynthASpoof and using MixStyle leads to comparable results and an average performance that goes beyond the latest PAD solutions.
</span></figcaption>
</figure>
<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">As models trained on limited data can easily over-fit the training data and thereby generalize poorly to other domains, we investigate the effect of using the SynthASpoof dataset as a supplementary training data to enhance the diversity of authentic training data.
<span id="S6.SS4.p1.1.1" class="ltx_text ltx_font_italic">+ SynthASpoof</span> in Tab. <a href="#S6.T5" title="Table 5 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> refers to that the SynthASpoof is combined with the authentic data in the training process.</p>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.1" class="ltx_p">As shown in Tab. <a href="#S6.T5" title="Table 5 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, including synthetic data in the training process improves the generalizability of the PAD models. For example, the average HTER value of ResNet decreases from 25.01% to 23.34%, and of PixBis decreases from 24.97% to 22.35%. These results suggest that adding the SynthASpoof dataset increases the diversity of training samples and thus leads to better representation learning.
Despite the overall improvement, the inclusion of synthetic data did not improve performance in all scenarios. A performance degradation is observed in five out of 12 scenarios when training the ResNet model and in four cases with the PixBis model. This might be caused by the distance between synthetic and authentic face data as we discussed in Sec. <a href="#S6.SS1" title="6.1 SynthASpoof PAD ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>. Therefore, we also utilized MixStyle in a combined training process, aiming to narrow the domain gap between the synthetic and authentic data, just as we did in Sec. <a href="#S6.SS3" title="6.3 Effect of MixStyle ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a> but with the PAD training here including authentic data.It can be seen that the model trained with MixStyle generalizes better on unseen test data than the one trained without MixStyle, e.g., the average HTER value of ResNet decreases from 23.34% to 19.58% and of PixBis decreases from 22.35% to 19.16% with the help of MixStyle. With MixStyle, suplementing the authentic data with SynthASpoof improved the PAD performance in 10 out 12 experimental setups for the ResNet-based PAD.</p>
</div>
<div id="S6.SS4.p3" class="ltx_para">
<p id="S6.SS4.p3.1" class="ltx_p">In summary, incorporating the SynthASpoof dataset seems to diversify the training data, alleviating the overfitting issue caused by limited training data. Furthermore, MixStyle narrows the domain gap between synthetic and authentic data, leading to improved model generalizability.</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2303.02660/assets/tsne_2.png" id="S6.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S6.F4.4.2" class="ltx_text" style="font-size:90%;">Visualization of the feature distribution by using t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> for the training on synthetic (‚óº) and test on authentic face PAD (‚úñ) samples, including the most challenging dataset CASIA in our case and the best performing dataset Idiap ReplayAttack.
The bona fide samples in both datasets are illustrated by green, while different attack types in the SynthASpoof dataset and attacks in the authentic dataset are represented in various shades of blue. Fig. (a) and (c) demonstrate a clear distance between different attack in the SynthASpoof dataset and a distance between synthetic and authentic data for both classes, bona fides and attack. Fig. (b) and (c) indicate that MixStyle helps to reduce the distance between the synthetic and the authetic data, i.e., samples within the same class are clustered more closely. </span></figcaption>
</figure>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Visualization and Analysis</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">We visualized the feature distribution learned by ResNet without MixStyle and with MixStyle in Fig. <a href="#S6.F4" title="Figure 4 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> by considering the most challenging case, SynthASpoof ‚Üí CASIA, and the best performing case SynthASpoof ‚Üí Idiap ReplayAttack (both with results presented in Tab. <a href="#S6.T4" title="Table 4 ‚Ä£ 6.3 Effect of MixStyle ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). To avoid the possible overlapping region and obtain a clear observation, we randomly select 500 samples from each dataset and illustrate their distribution by using t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Comparing Fig. <a href="#S6.F4" title="Figure 4 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (a) and (b), and (c) and (d), we found that samples obtained by the model with MixStyle are clustered more closely than baseline models, indicating the effectiveness of MixStyle. Furthermore, applying MixStyle results in a clearer decision boundary given the perspective of the discriminative capability.</p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.6 </span>Discussion</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p">A extensive experiments successfully demonstrated the feasibility of using the SynthASpoof dataset for the development of face PAD solutions by training as a stand-alone dataset and serving as a supplement to increasing the diversity of limited training data.
Although the goal of this work is not to achieve state-of-the-art PAD performances, a comparison to recent major works using the same experimental protocol is presented in Tab. <a href="#S6.T5" title="Table 5 ‚Ä£ 6.4 Effect of a supplementing Authentic Data with SynthASpoof ‚Ä£ 6 Results ‚Ä£ SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
This comparison shows that our PAD trained with the supplement of SynthASpoof and with MixStyle actually outperforms these works in many experimental settings, even leading to a better overall (average) performance.
Due to its privacy-friendly characteristic, the SynthASpoof dataset is made publicly available to the research community. Therefore, SynthASpoof can be extended by collecting more attack data to increase the diversity of attacks (printing, screen and capture devices).
Moreover, researchers can build PAD datasets to tackle research problems, e.g., the PAD fairness issue <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> by ensuring a demographically-diverse training data.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">To address the ethical and legal challenges associated with the usage, reuse, and sharing of authentic biometric data and motivated by the need for large-scale and diverse PAD development datasets, this work introduced the first privacy-friendly and synthetic-based dataset, SynthASpoof. The dataset consists of 25,000 bona fide and 78,000 presentation attack samples, which is made publicly available for the research community. We successfully proved the usability of the SynthASpoof dataset for the development of face PADs.
We also showed that SynthASpoof enhanced the generalizability of PAD models by enriching the diversity of the limited authentic data. Furthermore, MixStyle helped to decrease the distance between the synthetic and authentic data, resulting in a more robust and generalized presentation attack detector.</p>
</div>
<section id="S7.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Acknowledgment:</h4>

<div id="S7.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S7.SS0.SSS0.Px1.p1.1" class="ltx_p">This research work has been funded by the German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research and the Arts within their joint support of the National Research Center for Applied Cybersecurity ATHENE.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Zinelabdine Boulkenafet, Jukka Komulainen, Lei Li, Xiaoyi Feng, and Abdenour
Hadid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">OULU-NPU: A mobile face presentation attack database with
real-world variations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">FG</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 612‚Äì618. IEEE Computer Society, 2017.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Fadi Boutros, Naser Damer, and Arjan Kuijper.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Quantface: Towards lightweight face recognition by synthetic data
low-bit quantization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">26th International Conference on Pattern Recognition, ICPR
2022, Montreal, QC, Canada, August 21-25, 2022</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 855‚Äì862. IEEE,
2022.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Fadi Boutros, Meiling Fang, Marcel Klemt, Biying Fu, and Naser Damer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">CR-FIQA: face image quality assessment by learning sample relative
classifiability.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, abs/2112.06592, 2021.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Fadi Boutros, Marco Huber, Patrick Siebke, Tim Rieber, and Naser Damer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Sface: Privacy-friendly and accurate face recognition using synthetic
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IJCB</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 1‚Äì11. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Fadi Boutros, Marcel Klemt, Meiling Fang, Arjan Kuijper, and Naser Damer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Unsupervised face recognition using unlabeled synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">17th IEEE International Conference on Automatic Face and
Gesture Recognition, FG 2023, Waikoloa Beach, HI, USA, January 5-8, 2023</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">,
pages 1‚Äì8. IEEE, 2023.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Qiong Cao, Li Shen, Weidi Xie, Omkar¬†M. Parkhi, and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Vggface2: A dataset for recognising faces across pose and age.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">FG</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 67‚Äì74. IEEE Computer Society, 2018.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Ivana Chingovska, Andr√© Anjos, and S√©bastien Marcel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">On the effectiveness of local binary patterns in face anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">BIOSIG</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, volume P-196 of </span><span id="bib.bib7.6.4" class="ltx_text ltx_font_italic" style="font-size:90%;">LNI</span><span id="bib.bib7.7.5" class="ltx_text" style="font-size:90%;">, pages 1‚Äì7. GI,
2012.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
C√©sar Augusto Fontanillo L√≥pez and Abdullah Elbi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">On synthetic data: a brief introduction for data protection law
dummies, 2022.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Naser Damer, C√©sar Augusto¬†Fontanillo L√≥pez, Meiling Fang,
No√©mie Spiller, Minh¬†Vu Pham, and Fadi Boutros.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Privacy-friendly synthetic data for the development of face morphing
attack detectors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition Workshops, CVPR Workshops 2022, New Orleans, LA, USA, June
19-20, 2022</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, pages 1605‚Äì1616. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Meiling Fang, Hamza Ali, Arjan Kuijper, and Naser Damer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Patchswap: Boosting the generalizability of face presentation attack
detection by identity-aware patch swapping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Joint Conference on Biometrics, IJCB
2022, Abu Dhabi, United Arab Emirates, October 10-13, 2022</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, pages 1‚Äì10.
IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Meiling Fang, Fadi Boutros, and Naser Damer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Unsupervised face morphing attack detection via self-paced anomaly
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Joint Conference on Biometrics, IJCB
2022, Abu Dhabi, United Arab Emirates, October 10-13, 2022</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 1‚Äì11.
IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Meiling Fang, Fadi Boutros, Arjan Kuijper, and Naser Damer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Partial attack supervision and regional weighted inference for masked
face presentation attack detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">16th IEEE International Conference on Automatic Face and
Gesture Recognition, FG 2021, Jodhpur, India, December 15-18, 2021</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages
1‚Äì8. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Meiling Fang, Naser Damer, Florian Kirchbuchner, and Arjan Kuijper.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Learnable multi-level frequency decomposition and hierarchical
attention mechanism for generalized face presentation attack detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Winter Conference on Applications of Computer
Vision, WACV 2022, Waikoloa, HI, USA, January 3-8, 2022</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 1131‚Äì1140.
IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Meiling Fang, Naser Damer, Florian Kirchbuchner, and Arjan Kuijper.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Real masks and spoof faces: On the masked face presentation attack
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Pattern Recognit.</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 123:108398, 2022.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Meiling Fang, Wufei Yang, Arjan Kuijper, Vitomir Struc, and Naser Damer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Fairness in face presentation attack detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, abs/2209.09035, 2022.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Anjith George and S√©bastien Marcel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Deep pixel-wise binary supervision for face presentation attack
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICB</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 1‚Äì8. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Anjith George, Zohreh Mostaani, David Geissenbuhler, Olegs Nikisins,
Andr√© Anjos, and S√©bastien Marcel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Biometric face presentation attack detection with multi-channel
convolutional neural network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. Inf. Forensics Secur.</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">, 15:42‚Äì55, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, and Jianfeng Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Ms-celeb-1m: A dataset and benchmark for large-scale face
recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV (3)</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, volume 9907 of </span><span id="bib.bib18.6.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Lecture Notes in Computer
Science</span><span id="bib.bib18.7.5" class="ltx_text" style="font-size:90%;">, pages 87‚Äì102. Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages 770‚Äì778. IEEE Computer Society, 2016.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Gao Huang, Zhuang Liu, Laurens van¬†der Maaten, and Kilian¬†Q. Weinberger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Densely connected convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages
2261‚Äì2269. IEEE Computer Society, 2017.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Marco Huber, Fadi Boutros, Anh¬†Thi Luu, Kiran¬†B. Raja, Raghavendra Ramachandra,
Naser Damer, Pedro¬†C. Neto, Tiago Gon√ßalves, Ana¬†F. Sequeira, Jaime¬†S.
Cardoso, Jo√£o Tremo√ßo, Miguel Louren√ßo, Sergio Serra,
Eduardo Cerme√±o, Marija Ivanovska, Borut Batagelj, Andrej Kronovsek,
Peter Peer, and Vitomir Struc.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">SYN-MAD 2022: Competition on face morphing attack detection based
on privacy-aware synthetic training data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IJCB</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 1‚Äì10. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
International Organization for Standardization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">ISO/IEC DIS 30107-3:2016: Information Technology ‚Äì Biometric
presentation attack detection ‚Äì P. 3: Testing and reporting, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and
Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Training generative adversarial networks with limited data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Tero Karras, Samuli Laine, and Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">A style-based generator architecture for generative adversarial
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, pages 4401‚Äì4410. Computer Vision Foundation /
IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Ira Kemelmacher-Shlizerman, Steven¬†M. Seitz, Daniel Miller, and Evan
Brossard.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">The megaface benchmark: 1 million faces for recognition at scale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 4873‚Äì4882. IEEE Computer Society, 2016.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Haoliang Li, Sinno¬†Jialin Pan, Shiqi Wang, and Alex¬†C. Kot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Domain generalization with adversarial feature learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 5400‚Äì5409. IEEE Computer Society, 2018.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Ajian Liu, Chenxu Zhao, Zitong Yu, Jun Wan, Anyang Su, Xing Liu, Zichang Tan,
Sergio Escalera, Junliang Xing, Yanyan Liang, Guodong Guo, Zhen Lei, Stan¬†Z.
Li, and Du Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Contrastive context-aware learning for 3d high-fidelity mask face
presentation attack detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. Inf. Forensics Secur.</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 17:2497‚Äì2507, 2022.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Yaojie Liu, Joel Stehouwer, Amin Jourabloo, and Xiaoming Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Deep tree learning for zero-shot face anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition,
CVPR 2019, Long Beach, CA, USA, June 16-20, 2019</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages 4680‚Äì4689.
Computer Vision Foundation / IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Pedro¬†C. Neto, Ana¬†F. Sequeira, and Jaime¬†S. Cardoso.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Myope models - are face presentation attack detection models
short-sighted?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Winter Conference on Applications of Computer
Vision Workshops, WACV - Workshops, Waikoloa, HI, USA, January 4-8, 2022</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">,
pages 390‚Äì399. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Haibo Qiu, Baosheng Yu, Dihong Gong, Zhifeng Li, Wei Liu, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Synface: Face recognition with synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 10860‚Äì10870. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Mohammad Rostami, Leonidas Spinoulas, Mohamed¬†E. Hussein, Joe Mathai, and Wael
Abd-Almageed.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Detection and continual learning of novel face presentation attacks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 14831‚Äì14840. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Rui Shao, Xiangyuan Lan, Jiawei Li, and Pong¬†C. Yuen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Multi-adversarial discriminative deep domain generalization for face
presentation attack detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, pages 10023‚Äì10031. Computer Vision Foundation /
IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Rui Shao, Xiangyuan Lan, and Pong¬†C. Yuen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Regularized fine-grained meta face anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 11974‚Äì11981. AAAI Press, 2020.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Laurens van¬†der Maaten and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Visualizing data using t-sne.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Machine Learning Research</span><span id="bib.bib34.4.2" class="ltx_text" style="font-size:90%;">, 9(86):2579‚Äì2605, 2008.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Guoqing Wang, Hu Han, Shiguang Shan, and Xilin Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Improving cross-database face presentation attack detection via
adversarial domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICB</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 1‚Äì8. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Guoqing Wang, Hu Han, Shiguang Shan, and Xilin Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Cross-domain face presentation attack detection via multi-domain
disentangled representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages 6677‚Äì6686. Computer Vision Foundation /
IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Guoqing Wang, Hu Han, Shiguang Shan, and Xilin Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Unsupervised adversarial domain adaptation for cross-domain face
presentation attack detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. Inf. Forensics Secur.</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, 16:56‚Äì69, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Di Wen, Hu Han, and Anil¬†K. Jain.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Face spoof detection with image distortion analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. Inf. Forensics Secur.</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, 10(4):746‚Äì761, 2015.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Jianwei Yang, Zhen Lei, and Stan¬†Z. Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Learn convolutional neural network for face anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">, abs/1408.5601, 2014.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Zitong Yu, Xiaobai Li, Jingang Shi, Zhaoqiang Xia, and Guoying Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Revisiting pixel-wise supervision for face anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. Biom. Behav. Identity Sci.</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, 3(3):285‚Äì295, 2021.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Joint face detection and alignment using multitask cascaded
convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Signal Proc. Lett.</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, 23(10):1499‚Äì1503, 2016.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Shifeng Zhang, Xiaobo Wang, Ajian Liu, Chenxu Zhao, Jun Wan, Sergio Escalera,
Hailin Shi, Zezheng Wang, and Stan¬†Z. Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">A dataset and benchmark for large-scale multi-modal face
anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, pages 919‚Äì928. Computer Vision Foundation / IEEE,
2019.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Yuanhan Zhang, Zhenfei Yin, Yidong Li, Guojun Yin, Junjie Yan, Jing Shao, and
Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Celeba-spoof: Large-scale face anti-spoofing dataset with rich
annotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision - ECCV 2020 - 16th European Conference,
Glasgow, UK, August 23-28, 2020, Proceedings, Part XII</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, volume 12357 of
</span><span id="bib.bib43.6.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Lecture Notes in Computer Science</span><span id="bib.bib43.7.5" class="ltx_text" style="font-size:90%;">, pages 70‚Äì85. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Zhiwei Zhang, Junjie Yan, Sifei Liu, Zhen Lei, Dong Yi, and Stan¬†Z. Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">A face antispoofing database with diverse attacks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICB</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, pages 26‚Äì31. IEEE, 2012.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Domain generalization with mixstyle.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">. OpenReview.net, 2021.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Lifang Zhou, Jun Luo, Xinbo Gao, Weisheng Li, Bangjun Lei, and Jiaxu Leng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Selective domain-invariant feature alignment network for face
anti-spoofing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. Inf. Forensics Secur.</span><span id="bib.bib46.4.2" class="ltx_text" style="font-size:90%;">, 16:5352‚Äì5365, 2021.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.02659" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.02660" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.02660">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.02660" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.02661" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 20:45:19 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
