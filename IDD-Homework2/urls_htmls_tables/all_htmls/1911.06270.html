<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1911.06270] Federated Learning for Healthcare Informatics</title><meta property="og:description" content="With the rapid development of computer software and hardware technologies, more and more healthcare data are becoming readily available from clinical institutions, patients, insurance companies and pharmaceutical indusâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for Healthcare Informatics">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for Healthcare Informatics">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1911.06270">

<!--Generated on Sun Mar 17 09:46:19 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on Received: date / Accepted: date.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated Learnin Healthcare Privacy">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">âˆ</p>
</div>
<span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>J. Xu, C. Su and F. Wang<sup id="id1.1" class="ltx_sup">âˆ—</sup> </span></span></span><span id="id1a" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, New York, USA 
<br class="ltx_break"><span id="id1a.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>few2001@med.cornell.edu</span></span></span> </span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>B. S. Glicksberg </span></span></span><span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>Institute for Digital Health, Icahn School of Medicine at Mount Sinai, New York, New York, USA
</span></span></span><span id="id4" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">institutetext: </span>P. Walker </span></span></span><span id="id5" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">institutetext: </span>U.S. Department of Defense Joint Artificial Intelligence Center, Washington, D.C., USA
</span></span></span><span id="id6" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">institutetext: </span>J. Bian </span></span></span><span id="id7" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">institutetext: </span>Department of Health Outcomes and Biomedical Informatics, College of Medicine. University of Florida, Gainesville, Florida, USA.
</span></span></span>
<h1 class="ltx_title ltx_title_document">Federated Learning for Healthcare Informatics</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jie Xu
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Benjamin S. Glicksberg
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chang Su
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Peter Walker
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiang Bian
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fei Wang<sup id="id3.2.id1" class="ltx_sup">âˆ—</sup>
</span></span>
</div>
<div class="ltx_dates">(Received: date / Accepted: date)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">With the rapid development of computer software and hardware technologies, more and more healthcare data are becoming readily available from clinical institutions, patients, insurance companies and pharmaceutical industries, among others. This access provides an unprecedented opportunity for data science technologies to derive data-driven insights and improve the quality of care delivery. Healthcare data, however, are usually fragmented and private making it difficult to generate robust results across populations. For example, different hospitals own the electronic health records (EHR) of different patient populations and these records are difficult to share across hospitals because of their sensitive nature. This creates a big barrier for developing effective analytical approaches that are generalizable, which need diverse, â€œbig data". Federated learning, a mechanism of training a shared global model with a central server while keeping all the sensitive data in local institutions where the data belong, provides great promise to connect the fragmented healthcare data sources with privacy-preservation. The goal of this survey is to provide a review for federated learning technologies, particularly within the biomedical space. In particular, we summarize the general solutions to the statistical challenges, system challenges and privacy issues in federated learning, and point out the implications and potentials in healthcare.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Federated Learnin Healthcare Privacy
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The recent years have witnessed a surge of interest related to healthcare data analytics, due to the fact that more and more such data are becoming readily available from various sources including clinical institutions, patient individuals, insurance companies and pharmaceutical industries, among others. This provides an unprecedented opportunity for the development of computational techniques to dig data-driven insights for improving the quality of care delivery <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib93" title="" class="ltx_ref">wang2019ai </a>; <a href="#bib.bib64" title="" class="ltx_ref">miotto2018deep </a></cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Healthcare data are typically fragmented because of the complicated nature of the healthcare system and processes. For example, different hospitals may be able to access the clinical records of their own patient populations only. These records are highly sensitive with protected health information (PHI) of individuals. Rigorous regulations, such as the Health Insurance Portability and Accountability Act (HIPAA) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib26" title="" class="ltx_ref">gostin2001national </a></cite>, have been developed to regulate the process of accessing and analyzing such data. This creates a big challenge for modern data mining and machine learning (ML) technologies, such as deep learning <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib53" title="" class="ltx_ref">lecun2015deep </a></cite>, which typically requires a large amount of training data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated learning is a paradigm with a recent surge in popularity as it holds great promise on learning with fragmented sensitive data. Instead of aggregating data from different places all together, or relying on the traditional discovery then replication design, it enables training a shared global model with a central server while keeping the data in local institutions where the they originate.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The term â€œfederated learning" is not new. In 1976, Patrick Hill, a philosophy professor, first developed the Federated Learning Community (FLC) to bring people together to jointly learn, which helped students overcome the anonymity and isolation in large research universitiesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref">hill1985rationale </a></cite>. Subsequently, there were several efforts aiming at building federations of learning content and content repositories
Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib75" title="" class="ltx_ref">rehak2005model </a>; <a href="#bib.bib66" title="" class="ltx_ref">mukherjee2005system </a>; <a href="#bib.bib5" title="" class="ltx_ref">barcelos2011agent </a></cite>. In 2005, Rehak <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib75" title="" class="ltx_ref">rehak2005model </a></cite> developed a reference model describing how to establish an interoperable repository infrastructure by creating federations of repositories, where the metadata are collected from the contributing repositories into a central registry provided with a single point of discovery and access. The ultimate goal of this model is to enable learning from diverse content repositories. These practices in federated learning community or federated search service have provided effective references for the development of federated learning algorithms.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Federated learning holds great promises on healthcare data analytics. For both provider (e.g., building a model for predicting the hospital readmission risk with patient Electronic Health Records (EHR) <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib63" title="" class="ltx_ref">min2019predictive </a></cite>) and consumer (patient) based applications (e.g., screening atrial fibrillation with electrocardiograms captured by smartwatch <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib71" title="" class="ltx_ref">perez2019large </a></cite>), the sensitive patient data can stay either in local institutions or with individual consumers without going out during the federated model learning process, which effectively protects the patient privacy. The goal of this paper is to review the setup of federated learning, discuss the general solutions and challenges, as well as envision its applications in healthcare.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In this review, after a formal overview of federated learning, we summarize the main challenges and recent progress in this field. Then we illustrate the potential of federated learning methods in healthcare by describing the successful recent research. At last, we discuss the main opportunities and open questions for future applications in healthcare.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/1911.06270/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Schematic of the federated learning framework.<span id="S1.F1.4.2.1" class="ltx_text ltx_font_medium"> The model is trained in a distributed manner: The institutions periodically communicate the local updates with a central server to learn a global model. The central server aggregates the updates and sends back the parameters of the updated global model.</span></span></figcaption>
</figure>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p"><span id="S1.p7.1.1" class="ltx_text ltx_font_bold">Difference with Existing Reviews</span> There has been a few review articles on federated learning recently. For example, Yang <em id="S1.p7.1.2" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib97" title="" class="ltx_ref">Yang:2019:FML:3306498.3298981 </a></cite> wrote the early federated learning survey summarizing the general privacy-preserving techniques that can be applied to federated learning. Some researchers surveyed sub-problems of federated learning, <em id="S1.p7.1.3" class="ltx_emph ltx_font_italic">e.g.,</em> personalization techniquesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib51" title="" class="ltx_ref">kulkarni2020survey </a></cite>, semi-supervised learning algorithmsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib41" title="" class="ltx_ref">jin2020survey </a></cite>, threat modelsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib60" title="" class="ltx_ref">lyu2020threats </a></cite>, mobile edge networksÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib58" title="" class="ltx_ref">lim2019federated </a></cite>. Kairouz <em id="S1.p7.1.4" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib43" title="" class="ltx_ref">kairouz2019advances </a></cite> discussed recent advances and presented an extensive collection of open problems and challenges. LiÂ <em id="S1.p7.1.5" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib55" title="" class="ltx_ref">li2019federated </a></cite> conducted the review on federated learning from a system viewpoint. Different from those reviews, this paper provided the potential of federated learning to be applied in healthcare. We summarized the general solution to the challenges in federated learning scenario and surveyed a set of representative federated learning methods for healthcare. In the last part of this review, we outlined some directions or open questions in federated learning for healthcare. An early version of this paper is available on arXiv <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib95" title="" class="ltx_ref">xu2019federated </a></cite>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Federated Learning</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.5" class="ltx_p">Federated learning is a problem of training a high-quality shared global model with a central server from decentralized data scattered among large number of different clients (Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Federated Learning for Healthcare Informatics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
Mathematically, assume there are <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">K</annotation></semantics></math> activated clients where the data reside in (a client could be a mobile phone, a wearable device, or a clinical institution data warehouse, <em id="S2.p1.5.1" class="ltx_emph ltx_font_italic">etc</em>). Let <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{k}" display="inline"><semantics id="S2.p1.2.m2.1a"><msub id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">ğ’Ÿ</ci><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\mathcal{D}_{k}</annotation></semantics></math> denote the data distribution associated to client <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p1.3.m3.1a"><mi id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">k</annotation></semantics></math> and <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="S2.p1.4.m4.1a"><msub id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">n</mi><mi id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">ğ‘›</ci><ci id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">n_{k}</annotation></semantics></math> the number of samples available from that client. <math id="S2.p1.5.m5.1" class="ltx_Math" alttext="n=\sum_{k=1}^{K}n_{k}" display="inline"><semantics id="S2.p1.5.m5.1a"><mrow id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><mi id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml">n</mi><mo rspace="0.111em" id="S2.p1.5.m5.1.1.1" xref="S2.p1.5.m5.1.1.1.cmml">=</mo><mrow id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml"><msubsup id="S2.p1.5.m5.1.1.3.1" xref="S2.p1.5.m5.1.1.3.1.cmml"><mo id="S2.p1.5.m5.1.1.3.1.2.2" xref="S2.p1.5.m5.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="S2.p1.5.m5.1.1.3.1.2.3" xref="S2.p1.5.m5.1.1.3.1.2.3.cmml"><mi id="S2.p1.5.m5.1.1.3.1.2.3.2" xref="S2.p1.5.m5.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.p1.5.m5.1.1.3.1.2.3.1" xref="S2.p1.5.m5.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.p1.5.m5.1.1.3.1.2.3.3" xref="S2.p1.5.m5.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.p1.5.m5.1.1.3.1.3" xref="S2.p1.5.m5.1.1.3.1.3.cmml">K</mi></msubsup><msub id="S2.p1.5.m5.1.1.3.2" xref="S2.p1.5.m5.1.1.3.2.cmml"><mi id="S2.p1.5.m5.1.1.3.2.2" xref="S2.p1.5.m5.1.1.3.2.2.cmml">n</mi><mi id="S2.p1.5.m5.1.1.3.2.3" xref="S2.p1.5.m5.1.1.3.2.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><eq id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1"></eq><ci id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2">ğ‘›</ci><apply id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3"><apply id="S2.p1.5.m5.1.1.3.1.cmml" xref="S2.p1.5.m5.1.1.3.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.3.1.1.cmml" xref="S2.p1.5.m5.1.1.3.1">superscript</csymbol><apply id="S2.p1.5.m5.1.1.3.1.2.cmml" xref="S2.p1.5.m5.1.1.3.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.3.1.2.1.cmml" xref="S2.p1.5.m5.1.1.3.1">subscript</csymbol><sum id="S2.p1.5.m5.1.1.3.1.2.2.cmml" xref="S2.p1.5.m5.1.1.3.1.2.2"></sum><apply id="S2.p1.5.m5.1.1.3.1.2.3.cmml" xref="S2.p1.5.m5.1.1.3.1.2.3"><eq id="S2.p1.5.m5.1.1.3.1.2.3.1.cmml" xref="S2.p1.5.m5.1.1.3.1.2.3.1"></eq><ci id="S2.p1.5.m5.1.1.3.1.2.3.2.cmml" xref="S2.p1.5.m5.1.1.3.1.2.3.2">ğ‘˜</ci><cn type="integer" id="S2.p1.5.m5.1.1.3.1.2.3.3.cmml" xref="S2.p1.5.m5.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.p1.5.m5.1.1.3.1.3.cmml" xref="S2.p1.5.m5.1.1.3.1.3">ğ¾</ci></apply><apply id="S2.p1.5.m5.1.1.3.2.cmml" xref="S2.p1.5.m5.1.1.3.2"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.3.2.1.cmml" xref="S2.p1.5.m5.1.1.3.2">subscript</csymbol><ci id="S2.p1.5.m5.1.1.3.2.2.cmml" xref="S2.p1.5.m5.1.1.3.2.2">ğ‘›</ci><ci id="S2.p1.5.m5.1.1.3.2.3.cmml" xref="S2.p1.5.m5.1.1.3.2.3">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">n=\sum_{k=1}^{K}n_{k}</annotation></semantics></math> is the total sample size.
Federated learning problem boils down to solving a empirical risk minimization problem of the formÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib48" title="" class="ltx_ref">konevcny2015federated </a>; <a href="#bib.bib49" title="" class="ltx_ref">konevcny2016bfederated </a>; <a href="#bib.bib61" title="" class="ltx_ref">mcmahan2017communication </a></cite>:
<span id="S2.p1.5.2" class="ltx_text" style="font-size:90%;"></span></p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.6" class="ltx_Math" alttext="\min_{\mathbf{w}\in\mathbb{R}^{d}}F(\mathbf{w}):=\sum_{k=1}^{K}\frac{n_{k}}{n}F_{k}(\mathbf{w})\ \ \ \ \text{where}\ \ \ F_{k}(\mathbf{w}):=\frac{1}{n_{k}}\sum_{\mathbf{x}_{i}\in\mathcal{D}_{k}}f_{i}(\mathbf{w})," display="block"><semantics id="S2.E1.m1.6a"><mrow id="S2.E1.m1.6.6.1"><mrow id="S2.E1.m1.6.6.1.1.2" xref="S2.E1.m1.6.6.1.1.3.cmml"><mrow id="S2.E1.m1.6.6.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.cmml"><mrow id="S2.E1.m1.6.6.1.1.1.1.3" xref="S2.E1.m1.6.6.1.1.1.1.3.cmml"><mrow id="S2.E1.m1.6.6.1.1.1.1.3.2" xref="S2.E1.m1.6.6.1.1.1.1.3.2.cmml"><munder id="S2.E1.m1.6.6.1.1.1.1.3.2.1" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.3.2.1.2" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.2.cmml">min</mi><mrow id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.2" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.2.cmml">ğ°</mi><mo mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.1" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.1.cmml">âˆˆ</mo><msup id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.2" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.2.cmml">â„</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.3" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.3.cmml">d</mi></msup></mrow></munder><mo lspace="0.167em" id="S2.E1.m1.6.6.1.1.1.1.3.2a" xref="S2.E1.m1.6.6.1.1.1.1.3.2.cmml">â¡</mo><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.3.2.2" xref="S2.E1.m1.6.6.1.1.1.1.3.2.2.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.1.1.3.1" xref="S2.E1.m1.6.6.1.1.1.1.3.1.cmml">â€‹</mo><mrow id="S2.E1.m1.6.6.1.1.1.1.3.3.2" xref="S2.E1.m1.6.6.1.1.1.1.3.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.6.6.1.1.1.1.3.3.2.1" xref="S2.E1.m1.6.6.1.1.1.1.3.cmml">(</mo><mi mathsize="90%" id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">ğ°</mi><mo maxsize="90%" minsize="90%" rspace="0.278em" id="S2.E1.m1.6.6.1.1.1.1.3.3.2.2" xref="S2.E1.m1.6.6.1.1.1.1.3.cmml">)</mo></mrow></mrow><mo mathsize="90%" rspace="0.111em" id="S2.E1.m1.6.6.1.1.1.1.2" xref="S2.E1.m1.6.6.1.1.1.1.2.cmml">:=</mo><mrow id="S2.E1.m1.6.6.1.1.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.1.2.cmml"><mrow id="S2.E1.m1.6.6.1.1.1.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.cmml"><munderover id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2.cmml">k</mi><mo mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1.cmml">=</mo><mn mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.3.cmml">K</mi></munderover><mrow id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml"><mfrac id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.cmml"><msub id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml">n</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3.cmml">k</mi></msub><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.1" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><msub id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml">F</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.1a" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.4.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.4.2.1" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml">(</mo><mi mathsize="90%" id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">ğ°</mi><mo maxsize="90%" minsize="90%" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.4.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mspace width="1.8em" id="S2.E1.m1.6.6.1.1.1.1.1.1.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.cmml"></mspace><mtext mathsize="90%" id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5a.cmml">where</mtext></mrow></mrow><mspace width="1.35em" id="S2.E1.m1.6.6.1.1.2.3" xref="S2.E1.m1.6.6.1.1.3a.cmml"></mspace><mrow id="S2.E1.m1.6.6.1.1.2.2" xref="S2.E1.m1.6.6.1.1.2.2.cmml"><mrow id="S2.E1.m1.6.6.1.1.2.2.2" xref="S2.E1.m1.6.6.1.1.2.2.2.cmml"><msub id="S2.E1.m1.6.6.1.1.2.2.2.2" xref="S2.E1.m1.6.6.1.1.2.2.2.2.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.2.2.2" xref="S2.E1.m1.6.6.1.1.2.2.2.2.2.cmml">F</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.2.2.3" xref="S2.E1.m1.6.6.1.1.2.2.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.2.2.2.1" xref="S2.E1.m1.6.6.1.1.2.2.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.6.6.1.1.2.2.2.3.2" xref="S2.E1.m1.6.6.1.1.2.2.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.6.6.1.1.2.2.2.3.2.1" xref="S2.E1.m1.6.6.1.1.2.2.2.cmml">(</mo><mi mathsize="90%" id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">ğ°</mi><mo maxsize="90%" minsize="90%" rspace="0.278em" id="S2.E1.m1.6.6.1.1.2.2.2.3.2.2" xref="S2.E1.m1.6.6.1.1.2.2.2.cmml">)</mo></mrow></mrow><mo mathsize="90%" rspace="0.278em" id="S2.E1.m1.6.6.1.1.2.2.1" xref="S2.E1.m1.6.6.1.1.2.2.1.cmml">:=</mo><mrow id="S2.E1.m1.6.6.1.1.2.2.3" xref="S2.E1.m1.6.6.1.1.2.2.3.cmml"><mfrac id="S2.E1.m1.6.6.1.1.2.2.3.2" xref="S2.E1.m1.6.6.1.1.2.2.3.2.cmml"><mn mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.2.2" xref="S2.E1.m1.6.6.1.1.2.2.3.2.2.cmml">1</mn><msub id="S2.E1.m1.6.6.1.1.2.2.3.2.3" xref="S2.E1.m1.6.6.1.1.2.2.3.2.3.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.2.3.2" xref="S2.E1.m1.6.6.1.1.2.2.3.2.3.2.cmml">n</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.2.3.3" xref="S2.E1.m1.6.6.1.1.2.2.3.2.3.3.cmml">k</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.2.2.3.1" xref="S2.E1.m1.6.6.1.1.2.2.3.1.cmml">â€‹</mo><mrow id="S2.E1.m1.6.6.1.1.2.2.3.3" xref="S2.E1.m1.6.6.1.1.2.2.3.3.cmml"><munder id="S2.E1.m1.6.6.1.1.2.2.3.3.1" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.cmml"><msub id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.2.cmml">ğ±</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.3" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.3.cmml">i</mi></msub><mo mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.1" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.1.cmml">âˆˆ</mo><msub id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.2.cmml">ğ’Ÿ</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.3" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.3.cmml">k</mi></msub></mrow></munder><mrow id="S2.E1.m1.6.6.1.1.2.2.3.3.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.cmml"><msub id="S2.E1.m1.6.6.1.1.2.2.3.3.2.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.cmml"><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.2.cmml">f</mi><mi mathsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.3" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.2.2.3.3.2.1" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.6.6.1.1.2.2.3.3.2.3.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.2.3.2.1" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.cmml">(</mo><mi mathsize="90%" id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">ğ°</mi><mo maxsize="90%" minsize="90%" id="S2.E1.m1.6.6.1.1.2.2.3.3.2.3.2.2" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo mathsize="90%" id="S2.E1.m1.6.6.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.6b"><apply id="S2.E1.m1.6.6.1.1.3.cmml" xref="S2.E1.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.3a.cmml" xref="S2.E1.m1.6.6.1.1.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.6.6.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.6.6.1.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.2">assign</csymbol><apply id="S2.E1.m1.6.6.1.1.1.1.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3"><times id="S2.E1.m1.6.6.1.1.1.1.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.1"></times><apply id="S2.E1.m1.6.6.1.1.1.1.3.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2"><apply id="S2.E1.m1.6.6.1.1.1.1.3.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.3.2.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1">subscript</csymbol><min id="S2.E1.m1.6.6.1.1.1.1.3.2.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.2"></min><apply id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3"><in id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.1"></in><ci id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.2">ğ°</ci><apply id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3">superscript</csymbol><ci id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.2">â„</ci><ci id="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.1.3.3.3">ğ‘‘</ci></apply></apply></apply><ci id="S2.E1.m1.6.6.1.1.1.1.3.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2.2">ğ¹</ci></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ğ°</ci></apply><list id="S2.E1.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1"><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1"><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1">subscript</csymbol><sum id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.2"></sum><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3"><eq id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.1"></eq><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.2">ğ‘˜</ci><cn type="integer" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.1.3">ğ¾</ci></apply><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2"><times id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.1"></times><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2"><divide id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2"></divide><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.2">ğ‘›</ci><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.2.3">ğ‘˜</ci></apply><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.2.3">ğ‘›</ci></apply><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.2">ğ¹</ci><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.1.2.3.3">ğ‘˜</ci></apply><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">ğ°</ci></apply></apply><ci id="S2.E1.m1.5.5a.cmml" xref="S2.E1.m1.5.5"><mtext mathsize="90%" id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5">where</mtext></ci></list></apply><apply id="S2.E1.m1.6.6.1.1.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2"><csymbol cd="latexml" id="S2.E1.m1.6.6.1.1.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.1">assign</csymbol><apply id="S2.E1.m1.6.6.1.1.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.2"><times id="S2.E1.m1.6.6.1.1.2.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.2.1"></times><apply id="S2.E1.m1.6.6.1.1.2.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.2.2.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.2.2">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.2.2.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.2.2.2">ğ¹</ci><ci id="S2.E1.m1.6.6.1.1.2.2.2.2.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.2.2.3">ğ‘˜</ci></apply><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">ğ°</ci></apply><apply id="S2.E1.m1.6.6.1.1.2.2.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3"><times id="S2.E1.m1.6.6.1.1.2.2.3.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.1"></times><apply id="S2.E1.m1.6.6.1.1.2.2.3.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.2"><divide id="S2.E1.m1.6.6.1.1.2.2.3.2.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.2"></divide><cn type="integer" id="S2.E1.m1.6.6.1.1.2.2.3.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.2.2">1</cn><apply id="S2.E1.m1.6.6.1.1.2.2.3.2.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.2.2.3.2.3.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.2.3">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.2.2.3.2.3.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.2.3.2">ğ‘›</ci><ci id="S2.E1.m1.6.6.1.1.2.2.3.2.3.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.2.3.3">ğ‘˜</ci></apply></apply><apply id="S2.E1.m1.6.6.1.1.2.2.3.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3"><apply id="S2.E1.m1.6.6.1.1.2.2.3.3.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1">subscript</csymbol><sum id="S2.E1.m1.6.6.1.1.2.2.3.3.1.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.2"></sum><apply id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3"><in id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.1"></in><apply id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.2">ğ±</ci><ci id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.2.3">ğ‘–</ci></apply><apply id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.2">ğ’Ÿ</ci><ci id="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.1.3.3.3">ğ‘˜</ci></apply></apply></apply><apply id="S2.E1.m1.6.6.1.1.2.2.3.3.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2"><times id="S2.E1.m1.6.6.1.1.2.2.3.3.2.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.1"></times><apply id="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.2">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.2">ğ‘“</ci><ci id="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.3.cmml" xref="S2.E1.m1.6.6.1.1.2.2.3.3.2.2.3">ğ‘–</ci></apply><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">ğ°</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.6c">\min_{\mathbf{w}\in\mathbb{R}^{d}}F(\mathbf{w}):=\sum_{k=1}^{K}\frac{n_{k}}{n}F_{k}(\mathbf{w})\ \ \ \ \text{where}\ \ \ F_{k}(\mathbf{w}):=\frac{1}{n_{k}}\sum_{\mathbf{x}_{i}\in\mathcal{D}_{k}}f_{i}(\mathbf{w}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p1.6" class="ltx_p">where <math id="S2.p1.6.m1.1" class="ltx_Math" alttext="\mathbf{w}" display="inline"><semantics id="S2.p1.6.m1.1a"><mi id="S2.p1.6.m1.1.1" xref="S2.p1.6.m1.1.1.cmml">ğ°</mi><annotation-xml encoding="MathML-Content" id="S2.p1.6.m1.1b"><ci id="S2.p1.6.m1.1.1.cmml" xref="S2.p1.6.m1.1.1">ğ°</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m1.1c">\mathbf{w}</annotation></semantics></math> is the model parameter to be learned.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In particular, algorithms for federated learning face with a number of challengesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib87" title="" class="ltx_ref">smith2017federated </a>; <a href="#bib.bib12" title="" class="ltx_ref">caldas2018leaf </a></cite>, specifically:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.3" class="ltx_p"><span id="S2.I1.i1.p1.3.1" class="ltx_text ltx_font_bold">Statistical:</span> The data distribution among all clients differ greatly, <em id="S2.I1.i1.p1.3.2" class="ltx_emph ltx_font_italic">i.e.,</em> <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\forall k\neq\tilde{k}" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><mrow id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml"><mrow id="S2.I1.i1.p1.1.m1.1.1.2" xref="S2.I1.i1.p1.1.m1.1.1.2.cmml"><mo rspace="0.167em" id="S2.I1.i1.p1.1.m1.1.1.2.1" xref="S2.I1.i1.p1.1.m1.1.1.2.1.cmml">âˆ€</mo><mi id="S2.I1.i1.p1.1.m1.1.1.2.2" xref="S2.I1.i1.p1.1.m1.1.1.2.2.cmml">k</mi></mrow><mo id="S2.I1.i1.p1.1.m1.1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.1.cmml">â‰ </mo><mover accent="true" id="S2.I1.i1.p1.1.m1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.3.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.3.2" xref="S2.I1.i1.p1.1.m1.1.1.3.2.cmml">k</mi><mo id="S2.I1.i1.p1.1.m1.1.1.3.1" xref="S2.I1.i1.p1.1.m1.1.1.3.1.cmml">~</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><neq id="S2.I1.i1.p1.1.m1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1"></neq><apply id="S2.I1.i1.p1.1.m1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2"><csymbol cd="latexml" id="S2.I1.i1.p1.1.m1.1.1.2.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.1">for-all</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.2.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2.2">ğ‘˜</ci></apply><apply id="S2.I1.i1.p1.1.m1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3"><ci id="S2.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.1">~</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">\forall k\neq\tilde{k}</annotation></semantics></math>, we have <math id="S2.I1.i1.p1.2.m2.4" class="ltx_Math" alttext="\mathbb{E}_{\mathbf{x}_{i}\sim{\mathcal{D}_{k}}}[f_{i}(\mathbf{w};\mathbf{x}_{i})]\neq\mathbb{E}_{\mathbf{x}_{i}\sim\mathcal{D}_{\tilde{k}}}[f_{i}(\mathbf{w};\mathbf{x}_{i})]" display="inline"><semantics id="S2.I1.i1.p1.2.m2.4a"><mrow id="S2.I1.i1.p1.2.m2.4.4" xref="S2.I1.i1.p1.2.m2.4.4.cmml"><mrow id="S2.I1.i1.p1.2.m2.3.3.1" xref="S2.I1.i1.p1.2.m2.3.3.1.cmml"><msub id="S2.I1.i1.p1.2.m2.3.3.1.3" xref="S2.I1.i1.p1.2.m2.3.3.1.3.cmml"><mi id="S2.I1.i1.p1.2.m2.3.3.1.3.2" xref="S2.I1.i1.p1.2.m2.3.3.1.3.2.cmml">ğ”¼</mi><mrow id="S2.I1.i1.p1.2.m2.3.3.1.3.3" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.cmml"><msub id="S2.I1.i1.p1.2.m2.3.3.1.3.3.2" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.cmml"><mi id="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.2" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.2.cmml">ğ±</mi><mi id="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.3" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.3.cmml">i</mi></msub><mo id="S2.I1.i1.p1.2.m2.3.3.1.3.3.1" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.1.cmml">âˆ¼</mo><msub id="S2.I1.i1.p1.2.m2.3.3.1.3.3.3" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.2" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.2.cmml">ğ’Ÿ</mi><mi id="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.3" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.3.cmml">k</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.3.3.1.2" xref="S2.I1.i1.p1.2.m2.3.3.1.2.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.2.m2.3.3.1.1.1" xref="S2.I1.i1.p1.2.m2.3.3.1.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p1.2.m2.3.3.1.1.1.2" xref="S2.I1.i1.p1.2.m2.3.3.1.1.2.1.cmml">[</mo><mrow id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.cmml"><msub id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.cmml"><mi id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.2" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.2.cmml">f</mi><mi id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.3" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.2" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.2" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2.cmml">(</mo><mi id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml">ğ°</mi><mo id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.3" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2.cmml">;</mo><msub id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.2" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.2.cmml">ğ±</mi><mi id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.3" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.4" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.I1.i1.p1.2.m2.3.3.1.1.1.3" xref="S2.I1.i1.p1.2.m2.3.3.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.I1.i1.p1.2.m2.4.4.3" xref="S2.I1.i1.p1.2.m2.4.4.3.cmml">â‰ </mo><mrow id="S2.I1.i1.p1.2.m2.4.4.2" xref="S2.I1.i1.p1.2.m2.4.4.2.cmml"><msub id="S2.I1.i1.p1.2.m2.4.4.2.3" xref="S2.I1.i1.p1.2.m2.4.4.2.3.cmml"><mi id="S2.I1.i1.p1.2.m2.4.4.2.3.2" xref="S2.I1.i1.p1.2.m2.4.4.2.3.2.cmml">ğ”¼</mi><mrow id="S2.I1.i1.p1.2.m2.4.4.2.3.3" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.cmml"><msub id="S2.I1.i1.p1.2.m2.4.4.2.3.3.2" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.cmml"><mi id="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.2" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.2.cmml">ğ±</mi><mi id="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.3" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.3.cmml">i</mi></msub><mo id="S2.I1.i1.p1.2.m2.4.4.2.3.3.1" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.1.cmml">âˆ¼</mo><msub id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.2" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.2.cmml">ğ’Ÿ</mi><mover accent="true" id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.cmml"><mi id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.2" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.2.cmml">k</mi><mo id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.1" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.1.cmml">~</mo></mover></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.4.4.2.2" xref="S2.I1.i1.p1.2.m2.4.4.2.2.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.2.m2.4.4.2.1.1" xref="S2.I1.i1.p1.2.m2.4.4.2.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p1.2.m2.4.4.2.1.1.2" xref="S2.I1.i1.p1.2.m2.4.4.2.1.2.1.cmml">[</mo><mrow id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.cmml"><msub id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.cmml"><mi id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.2" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.2.cmml">f</mi><mi id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.3" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.2" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.2.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.2" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.2.cmml">(</mo><mi id="S2.I1.i1.p1.2.m2.2.2" xref="S2.I1.i1.p1.2.m2.2.2.cmml">ğ°</mi><mo id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.3" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.2.cmml">;</mo><msub id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.2" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.2.cmml">ğ±</mi><mi id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.3" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.4" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.I1.i1.p1.2.m2.4.4.2.1.1.3" xref="S2.I1.i1.p1.2.m2.4.4.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.4b"><apply id="S2.I1.i1.p1.2.m2.4.4.cmml" xref="S2.I1.i1.p1.2.m2.4.4"><neq id="S2.I1.i1.p1.2.m2.4.4.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.3"></neq><apply id="S2.I1.i1.p1.2.m2.3.3.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1"><times id="S2.I1.i1.p1.2.m2.3.3.1.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.2"></times><apply id="S2.I1.i1.p1.2.m2.3.3.1.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.3.3.1.3.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.3.3.1.3.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.2">ğ”¼</ci><apply id="S2.I1.i1.p1.2.m2.3.3.1.3.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3"><csymbol cd="latexml" id="S2.I1.i1.p1.2.m2.3.3.1.3.3.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.1">similar-to</csymbol><apply id="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.2"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.2">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.2">ğ±</ci><ci id="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.2.3">ğ‘–</ci></apply><apply id="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.3">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.2">ğ’Ÿ</ci><ci id="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.3.3.3.3">ğ‘˜</ci></apply></apply></apply><apply id="S2.I1.i1.p1.2.m2.3.3.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1"><csymbol cd="latexml" id="S2.I1.i1.p1.2.m2.3.3.1.1.2.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1"><times id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.2"></times><apply id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.2">ğ‘“</ci><ci id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.3.3">ğ‘–</ci></apply><list id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1"><ci id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">ğ°</ci><apply id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.2">ğ±</ci><ci id="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></list></apply></apply></apply><apply id="S2.I1.i1.p1.2.m2.4.4.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2"><times id="S2.I1.i1.p1.2.m2.4.4.2.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.2"></times><apply id="S2.I1.i1.p1.2.m2.4.4.2.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.4.4.2.3.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.4.4.2.3.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.2">ğ”¼</ci><apply id="S2.I1.i1.p1.2.m2.4.4.2.3.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3"><csymbol cd="latexml" id="S2.I1.i1.p1.2.m2.4.4.2.3.3.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.1">similar-to</csymbol><apply id="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.2"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.2">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.2">ğ±</ci><ci id="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.2.3">ğ‘–</ci></apply><apply id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.2">ğ’Ÿ</ci><apply id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3"><ci id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.1">~</ci><ci id="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.3.3.3.3.2">ğ‘˜</ci></apply></apply></apply></apply><apply id="S2.I1.i1.p1.2.m2.4.4.2.1.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1"><csymbol cd="latexml" id="S2.I1.i1.p1.2.m2.4.4.2.1.2.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.2">delimited-[]</csymbol><apply id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1"><times id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.2"></times><apply id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.2">ğ‘“</ci><ci id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.3.3">ğ‘–</ci></apply><list id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1"><ci id="S2.I1.i1.p1.2.m2.2.2.cmml" xref="S2.I1.i1.p1.2.m2.2.2">ğ°</ci><apply id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.2">ğ±</ci><ci id="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.4.4.2.1.1.1.1.1.1.3">ğ‘–</ci></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.4c">\mathbb{E}_{\mathbf{x}_{i}\sim{\mathcal{D}_{k}}}[f_{i}(\mathbf{w};\mathbf{x}_{i})]\neq\mathbb{E}_{\mathbf{x}_{i}\sim\mathcal{D}_{\tilde{k}}}[f_{i}(\mathbf{w};\mathbf{x}_{i})]</annotation></semantics></math>. It is such that any data points available locally are far from being a representative sample of the overall distribution, <em id="S2.I1.i1.p1.3.3" class="ltx_emph ltx_font_italic">i.e.,</em> <math id="S2.I1.i1.p1.3.m3.3" class="ltx_Math" alttext="\mathbb{E}_{\mathbf{x}_{i}\sim\mathcal{D}_{k}}[f_{i}(\mathbf{w};\mathbf{x}_{i})]\neq F(\mathbf{w})" display="inline"><semantics id="S2.I1.i1.p1.3.m3.3a"><mrow id="S2.I1.i1.p1.3.m3.3.3" xref="S2.I1.i1.p1.3.m3.3.3.cmml"><mrow id="S2.I1.i1.p1.3.m3.3.3.1" xref="S2.I1.i1.p1.3.m3.3.3.1.cmml"><msub id="S2.I1.i1.p1.3.m3.3.3.1.3" xref="S2.I1.i1.p1.3.m3.3.3.1.3.cmml"><mi id="S2.I1.i1.p1.3.m3.3.3.1.3.2" xref="S2.I1.i1.p1.3.m3.3.3.1.3.2.cmml">ğ”¼</mi><mrow id="S2.I1.i1.p1.3.m3.3.3.1.3.3" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.cmml"><msub id="S2.I1.i1.p1.3.m3.3.3.1.3.3.2" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.cmml"><mi id="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.2" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.2.cmml">ğ±</mi><mi id="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.3" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.3.cmml">i</mi></msub><mo id="S2.I1.i1.p1.3.m3.3.3.1.3.3.1" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.1.cmml">âˆ¼</mo><msub id="S2.I1.i1.p1.3.m3.3.3.1.3.3.3" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.2" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.2.cmml">ğ’Ÿ</mi><mi id="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.3" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.3.cmml">k</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.3.m3.3.3.1.2" xref="S2.I1.i1.p1.3.m3.3.3.1.2.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.3.m3.3.3.1.1.1" xref="S2.I1.i1.p1.3.m3.3.3.1.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p1.3.m3.3.3.1.1.1.2" xref="S2.I1.i1.p1.3.m3.3.3.1.1.2.1.cmml">[</mo><mrow id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.cmml"><msub id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.cmml"><mi id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.2" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.2.cmml">f</mi><mi id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.3" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.2" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.2" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.2.cmml">(</mo><mi id="S2.I1.i1.p1.3.m3.1.1" xref="S2.I1.i1.p1.3.m3.1.1.cmml">ğ°</mi><mo id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.3" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.2.cmml">;</mo><msub id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.cmml"><mi id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.2" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.2.cmml">ğ±</mi><mi id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.3" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.4" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.I1.i1.p1.3.m3.3.3.1.1.1.3" xref="S2.I1.i1.p1.3.m3.3.3.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.I1.i1.p1.3.m3.3.3.2" xref="S2.I1.i1.p1.3.m3.3.3.2.cmml">â‰ </mo><mrow id="S2.I1.i1.p1.3.m3.3.3.3" xref="S2.I1.i1.p1.3.m3.3.3.3.cmml"><mi id="S2.I1.i1.p1.3.m3.3.3.3.2" xref="S2.I1.i1.p1.3.m3.3.3.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.3.m3.3.3.3.1" xref="S2.I1.i1.p1.3.m3.3.3.3.1.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.3.m3.3.3.3.3.2" xref="S2.I1.i1.p1.3.m3.3.3.3.cmml"><mo stretchy="false" id="S2.I1.i1.p1.3.m3.3.3.3.3.2.1" xref="S2.I1.i1.p1.3.m3.3.3.3.cmml">(</mo><mi id="S2.I1.i1.p1.3.m3.2.2" xref="S2.I1.i1.p1.3.m3.2.2.cmml">ğ°</mi><mo stretchy="false" id="S2.I1.i1.p1.3.m3.3.3.3.3.2.2" xref="S2.I1.i1.p1.3.m3.3.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.3.m3.3b"><apply id="S2.I1.i1.p1.3.m3.3.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3"><neq id="S2.I1.i1.p1.3.m3.3.3.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.2"></neq><apply id="S2.I1.i1.p1.3.m3.3.3.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1"><times id="S2.I1.i1.p1.3.m3.3.3.1.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.2"></times><apply id="S2.I1.i1.p1.3.m3.3.3.1.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.3.3.1.3.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.3.3.1.3.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.2">ğ”¼</ci><apply id="S2.I1.i1.p1.3.m3.3.3.1.3.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3"><csymbol cd="latexml" id="S2.I1.i1.p1.3.m3.3.3.1.3.3.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.1">similar-to</csymbol><apply id="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.2"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.2">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.2">ğ±</ci><ci id="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.2.3">ğ‘–</ci></apply><apply id="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.3">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.2">ğ’Ÿ</ci><ci id="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.3.3.3.3">ğ‘˜</ci></apply></apply></apply><apply id="S2.I1.i1.p1.3.m3.3.3.1.1.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1"><csymbol cd="latexml" id="S2.I1.i1.p1.3.m3.3.3.1.1.2.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1"><times id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.2"></times><apply id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.2">ğ‘“</ci><ci id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.3.3">ğ‘–</ci></apply><list id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1"><ci id="S2.I1.i1.p1.3.m3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1">ğ°</ci><apply id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.2">ğ±</ci><ci id="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></list></apply></apply></apply><apply id="S2.I1.i1.p1.3.m3.3.3.3.cmml" xref="S2.I1.i1.p1.3.m3.3.3.3"><times id="S2.I1.i1.p1.3.m3.3.3.3.1.cmml" xref="S2.I1.i1.p1.3.m3.3.3.3.1"></times><ci id="S2.I1.i1.p1.3.m3.3.3.3.2.cmml" xref="S2.I1.i1.p1.3.m3.3.3.3.2">ğ¹</ci><ci id="S2.I1.i1.p1.3.m3.2.2.cmml" xref="S2.I1.i1.p1.3.m3.2.2">ğ°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.3.m3.3c">\mathbb{E}_{\mathbf{x}_{i}\sim\mathcal{D}_{k}}[f_{i}(\mathbf{w};\mathbf{x}_{i})]\neq F(\mathbf{w})</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.2" class="ltx_p"><span id="S2.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">Communication:</span> The number of clients <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">K</annotation></semantics></math> is large and can be much bigger than the average number of training sample stored in the activated clients, <em id="S2.I1.i2.p1.2.2" class="ltx_emph ltx_font_italic">i.e.,</em> <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="K\gg({n}/{K})" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><mrow id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml">K</mi><mo id="S2.I1.i2.p1.2.m2.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.2.cmml">â‰«</mo><mrow id="S2.I1.i2.p1.2.m2.1.1.1.1" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.i2.p1.2.m2.1.1.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.I1.i2.p1.2.m2.1.1.1.1.1" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.1.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.2.cmml">n</mi><mo id="S2.I1.i2.p1.2.m2.1.1.1.1.1.1" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.1.cmml">/</mo><mi id="S2.I1.i2.p1.2.m2.1.1.1.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.I1.i2.p1.2.m2.1.1.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><csymbol cd="latexml" id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2">much-greater-than</csymbol><ci id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3">ğ¾</ci><apply id="S2.I1.i2.p1.2.m2.1.1.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.1.1"><divide id="S2.I1.i2.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.1"></divide><ci id="S2.I1.i2.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.2">ğ‘›</ci><ci id="S2.I1.i2.p1.2.m2.1.1.1.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.1.1.1.3">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">K\gg({n}/{K})</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Privacy and Security:</span> Additional privacy protections are needed for unreliable participating clients. It is impossible to ensure none of the millions of clients are malicious.</p>
</div>
</li>
</ul>
<p id="S2.p2.2" class="ltx_p">Next, we will survey, in detail, the existing federated learning related works on handling such challenges.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Statistical Challenges of Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The naive way to solve the federated learning problem is through Federated Averaging (<span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">FedAvg</span>)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib61" title="" class="ltx_ref">mcmahan2017communication </a></cite>. It is demonstrated can work with certain non independent identical distribution (non-IID) data by requiring all the clients to share the same model.
However, <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">FedAvg</span> does not address the statistical challenge of strongly skewed data distributions. The performance of convolutional neural networks trained with <span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_italic">FedAvg</span> algorithm can reduce significantly due to the weight divergenceÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib98" title="" class="ltx_ref">zhao2018federated </a></cite>.
Existing research on dealing with the statistical challenge of federated learning can be grouped into two fields, <em id="S2.SS1.p1.1.4" class="ltx_emph ltx_font_italic">i.e.,</em> consensus solution and pluralistic solution.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Consensus Solution</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.2" class="ltx_p">Most centralized models are trained on the aggregated training samples obtained from the samples drawn from the local clientsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib87" title="" class="ltx_ref">smith2017federated </a>; <a href="#bib.bib98" title="" class="ltx_ref">zhao2018federated </a></cite>. Intrinsically, the centralized model is trained to minimize the loss with respect to the uniform distributionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib65" title="" class="ltx_ref">pmlr-v97-mohri19a </a></cite>: <math id="S2.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\bar{\mathcal{D}}=\sum_{k=1}^{K}\frac{n_{k}}{n}\mathcal{D}_{k}" display="inline"><semantics id="S2.SS1.SSS1.p1.1.m1.1a"><mrow id="S2.SS1.SSS1.p1.1.m1.1.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.cmml"><mover accent="true" id="S2.SS1.SSS1.p1.1.m1.1.1.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS1.p1.1.m1.1.1.2.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.2.2.cmml">ğ’Ÿ</mi><mo id="S2.SS1.SSS1.p1.1.m1.1.1.2.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.2.1.cmml">Â¯</mo></mover><mo rspace="0.111em" id="S2.SS1.SSS1.p1.1.m1.1.1.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S2.SS1.SSS1.p1.1.m1.1.1.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.cmml"><msubsup id="S2.SS1.SSS1.p1.1.m1.1.1.3.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.cmml"><mo id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.cmml"><mi id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.3.cmml">K</mi></msubsup><mrow id="S2.SS1.SSS1.p1.1.m1.1.1.3.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.cmml"><mfrac id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.cmml"><msub id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.cmml"><mi id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.1.cmml">â€‹</mo><msub id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.2.cmml">ğ’Ÿ</mi><mi id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.3.cmml">k</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.1.m1.1b"><apply id="S2.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1"><eq id="S2.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.1"></eq><apply id="S2.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.2"><ci id="S2.SS1.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.2.1">Â¯</ci><ci id="S2.SS1.SSS1.p1.1.m1.1.1.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.2.2">ğ’Ÿ</ci></apply><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3"><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1">superscript</csymbol><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1">subscript</csymbol><sum id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.2"></sum><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3"><eq id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.1"></eq><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.2">ğ‘˜</ci><cn type="integer" id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.1.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.1.3">ğ¾</ci></apply><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2"><times id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.1"></times><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2"><divide id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2"></divide><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.2">ğ‘›</ci><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.2.3">ğ‘˜</ci></apply><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.2.3">ğ‘›</ci></apply><apply id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.2">ğ’Ÿ</ci><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.2.3.3">ğ‘˜</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.1.m1.1c">\bar{\mathcal{D}}=\sum_{k=1}^{K}\frac{n_{k}}{n}\mathcal{D}_{k}</annotation></semantics></math>, where <math id="S2.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\bar{\mathcal{D}}" display="inline"><semantics id="S2.SS1.SSS1.p1.2.m2.1a"><mover accent="true" id="S2.SS1.SSS1.p1.2.m2.1.1" xref="S2.SS1.SSS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS1.p1.2.m2.1.1.2" xref="S2.SS1.SSS1.p1.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mo id="S2.SS1.SSS1.p1.2.m2.1.1.1" xref="S2.SS1.SSS1.p1.2.m2.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.2.m2.1b"><apply id="S2.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1"><ci id="S2.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1.1">Â¯</ci><ci id="S2.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1.2">ğ’Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.2.m2.1c">\bar{\mathcal{D}}</annotation></semantics></math> is the target data distribution for the learning model. However, this specific uniform distribution is not an adequate solution in most scenarios.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.p2.1" class="ltx_p">To address this issue, the recent proposed solution is to model the target distribution or force the data adapt to the uniform distributionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib98" title="" class="ltx_ref">zhao2018federated </a>; <a href="#bib.bib65" title="" class="ltx_ref">pmlr-v97-mohri19a </a></cite>. Specifically, Mohri <em id="S2.SS1.SSS1.p2.1.1" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib65" title="" class="ltx_ref">pmlr-v97-mohri19a </a></cite> proposed a minimax optimization scheme, <em id="S2.SS1.SSS1.p2.1.2" class="ltx_emph ltx_font_italic">i.e.,</em> agnostic federated learning (AFL), where the centralized model is optimized for any possible target distribution formed by a mixture of the client distributions. This method has only been applied at small scales. Compared to AFL, Li <em id="S2.SS1.SSS1.p2.1.3" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib56" title="" class="ltx_ref">li2019fair </a></cite> proposed <math id="S2.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.SS1.SSS1.p2.1.m1.1a"><mi id="S2.SS1.SSS1.p2.1.m1.1.1" xref="S2.SS1.SSS1.p2.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.1.m1.1b"><ci id="S2.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.1.m1.1c">q</annotation></semantics></math>-Fair Federated Learning (<span id="S2.SS1.SSS1.p2.1.4" class="ltx_text ltx_font_italic">q-FFL</span>), assigning higher weight to devices with poor performance, so that the distribution of accuracy in the network reduces in variance. They empirically demonstrate the improved flexibility and scalability of <span id="S2.SS1.SSS1.p2.1.5" class="ltx_text ltx_font_italic">q-FFL</span> compared to AFL.</p>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p id="S2.SS1.SSS1.p3.1" class="ltx_p">Another commonly used method is globally sharing a small portion of data between all the clientsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib98" title="" class="ltx_ref">zhao2018federated </a>; <a href="#bib.bib67" title="" class="ltx_ref">nishio2018client </a></cite>. The shared subset is required containing a uniform distribution over classes from the central server to the clients. In addition to handle non-IID issue, sharing information of a small portion of trusted instances and noise patterns can guide the local agents to select compact training subset, while the clients learn to add changes to selected data samples, in order to improve the test performance of the global modelÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib30" title="" class="ltx_ref">han2019robust </a></cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Pluralistic Solution</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.2" class="ltx_p">Generally, it is difficult to find a consensus solution <math id="S2.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{w}" display="inline"><semantics id="S2.SS1.SSS2.p1.1.m1.1a"><mi id="S2.SS1.SSS2.p1.1.m1.1.1" xref="S2.SS1.SSS2.p1.1.m1.1.1.cmml">ğ°</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.1.m1.1b"><ci id="S2.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1">ğ°</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.1.m1.1c">\mathbf{w}</annotation></semantics></math> that is good for all components <math id="S2.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{i}" display="inline"><semantics id="S2.SS1.SSS2.p1.2.m2.1a"><msub id="S2.SS1.SSS2.p1.2.m2.1.1" xref="S2.SS1.SSS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS2.p1.2.m2.1.1.2" xref="S2.SS1.SSS2.p1.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mi id="S2.SS1.SSS2.p1.2.m2.1.1.3" xref="S2.SS1.SSS2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.2.m2.1b"><apply id="S2.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.2">ğ’Ÿ</ci><ci id="S2.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.2.m2.1c">\mathcal{D}_{i}</annotation></semantics></math>. Instead of wastefully insisting on a consensus solution, many researchers choose to embracing this heterogeneity.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p">Multi-task learning (MTL) is a natural way to deal with the data drawn from different distributions. It directly captures relationships amongst non-IID and unbalanced data by leveraging the relatedness between them in comparison to learn a single global model. In order to do this, it is necessary to target a particular way in which tasks are related, <em id="S2.SS1.SSS2.p2.1.1" class="ltx_emph ltx_font_italic">e.g.</em> sharing sparsity, sharing low-rank structure, graph-based relatedness and so forth. Recently, Smith <em id="S2.SS1.SSS2.p2.1.2" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib87" title="" class="ltx_ref">smith2017federated </a></cite> empirically demonstrated this point on real-world federated datasets and proposed a novel method <span id="S2.SS1.SSS2.p2.1.3" class="ltx_text ltx_font_italic">MOCHA</span> to solve a general convex MTL problem with handling the system challenges at the same time.
Later, Corinzia <em id="S2.SS1.SSS2.p2.1.4" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib17" title="" class="ltx_ref">corinzia2019variational </a></cite> introduced <span id="S2.SS1.SSS2.p2.1.5" class="ltx_text ltx_font_italic">VIRTUAL</span>, an algorithm for federated multi-task learning with non-convex models. They consider the federation of central server and clients as a Bayesian network and perform training using approximated variational inference. This work bridges the frameworks of federated and transfer/continuous learning.</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p id="S2.SS1.SSS2.p3.1" class="ltx_p">The success of multi-task learning rests on whether the chosen relatedness assumptions hold. Compared to this, pluralism can be a critical tool for dealing with heterogeneous data without any additional or even low-order terms that depend on the relatedness as in MTLÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">eichner2019semi </a></cite>. Eichner <em id="S2.SS1.SSS2.p3.1.1" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib22" title="" class="ltx_ref">eichner2019semi </a></cite> considered training in the presence of block-cyclic data, and showed that a remarkably simple pluralistic approach can entirely resolve the source of data heterogeneity. When the component distributions are actually different, pluralism can outperform the â€œidealâ€ IID baseline.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/1911.06270/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="406" height="232" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.7.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.8.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Communication efficient federated learning methods.<span id="S2.F2.8.2.1" class="ltx_text ltx_font_medium"> Existing research on improving communication efficiency can be categorized into </span>a<span id="S2.F2.8.2.2" class="ltx_text ltx_font_medium"> model compression, </span>b<span id="S2.F2.8.2.3" class="ltx_text ltx_font_medium"> clients selection, </span>c<span id="S2.F2.8.2.4" class="ltx_text ltx_font_medium"> updates reducing and </span>d<span id="S2.F2.8.2.5" class="ltx_text ltx_font_medium"> peer-to-peer learning.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Communication Efficiency of Federated Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.3" class="ltx_p">In federated learning setting, training data remain distributed over a large number of clients each with unreliable and relatively slow network connections. Naively for synchronous protocol in federated learningÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib87" title="" class="ltx_ref">smith2017federated </a>; <a href="#bib.bib50" title="" class="ltx_ref">konevcny2016afederated </a></cite>, the total number of bits that required during uplink (clinets <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="\to" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mo stretchy="false" id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\to</annotation></semantics></math> server) and downlink (server <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="\to" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mo stretchy="false" id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\to</annotation></semantics></math> clients) communication by each of the <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mi id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">K</annotation></semantics></math> clients during training are given by</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.3" class="ltx_Math" alttext="\mathcal{B}^{up/down}\in\mathcal{O}(U\times\underbrace{|\mathbf{w}|\times(H(\triangle\mathbf{w}^{up/down})+\beta)}_{\text{update size}})" display="block"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml"><msup id="S2.E2.m1.3.3.3" xref="S2.E2.m1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.3.2" xref="S2.E2.m1.3.3.3.2.cmml">â„¬</mi><mrow id="S2.E2.m1.3.3.3.3" xref="S2.E2.m1.3.3.3.3.cmml"><mrow id="S2.E2.m1.3.3.3.3.2" xref="S2.E2.m1.3.3.3.3.2.cmml"><mrow id="S2.E2.m1.3.3.3.3.2.2" xref="S2.E2.m1.3.3.3.3.2.2.cmml"><mi id="S2.E2.m1.3.3.3.3.2.2.2" xref="S2.E2.m1.3.3.3.3.2.2.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.3.3.2.2.1" xref="S2.E2.m1.3.3.3.3.2.2.1.cmml">â€‹</mo><mi id="S2.E2.m1.3.3.3.3.2.2.3" xref="S2.E2.m1.3.3.3.3.2.2.3.cmml">p</mi></mrow><mo id="S2.E2.m1.3.3.3.3.2.1" xref="S2.E2.m1.3.3.3.3.2.1.cmml">/</mo><mi id="S2.E2.m1.3.3.3.3.2.3" xref="S2.E2.m1.3.3.3.3.2.3.cmml">d</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.3.3.1" xref="S2.E2.m1.3.3.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.3.3.3.3.3" xref="S2.E2.m1.3.3.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.3.3.1a" xref="S2.E2.m1.3.3.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.3.3.3.3.4" xref="S2.E2.m1.3.3.3.3.4.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.3.3.1b" xref="S2.E2.m1.3.3.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.3.3.3.3.5" xref="S2.E2.m1.3.3.3.3.5.cmml">n</mi></mrow></msup><mo id="S2.E2.m1.3.3.2" xref="S2.E2.m1.3.3.2.cmml">âˆˆ</mo><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.1.3" xref="S2.E2.m1.3.3.1.3.cmml">ğ’ª</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.2" xref="S2.E2.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.3.3.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.2.cmml">U</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E2.m1.3.3.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml">Ã—</mo><munder id="S2.E2.m1.3.3.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.3.cmml"><munder accentunder="true" id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml"><mrow id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml"><mrow id="S2.E2.m1.2.2.2.4.2" xref="S2.E2.m1.2.2.2.4.1.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.2.4.2.1" xref="S2.E2.m1.2.2.2.4.1.1.cmml">|</mo><mi id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">ğ°</mi><mo rspace="0.055em" stretchy="false" id="S2.E2.m1.2.2.2.4.2.2" xref="S2.E2.m1.2.2.2.4.1.1.cmml">|</mo></mrow><mo rspace="0.222em" id="S2.E2.m1.2.2.2.3" xref="S2.E2.m1.2.2.2.3.cmml">Ã—</mo><mrow id="S2.E2.m1.2.2.2.2.1" xref="S2.E2.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.2.2.1.2" xref="S2.E2.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S2.E2.m1.2.2.2.2.1.1" xref="S2.E2.m1.2.2.2.2.1.1.cmml"><mrow id="S2.E2.m1.2.2.2.2.1.1.1" xref="S2.E2.m1.2.2.2.2.1.1.1.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.1.3.cmml">H</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.2.1.1.1.2" xref="S2.E2.m1.2.2.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.2.2.2.2.1.1.1.1.1" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.2" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.2" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.2.cmml">â–³</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.1" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.1.cmml">â€‹</mo><msup id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.2" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.2.cmml">ğ°</mi><mrow id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.cmml"><mrow id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.cmml"><mrow id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.2" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.1" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.1.cmml">â€‹</mo><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.3" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.3.cmml">p</mi></mrow><mo id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.1" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.1.cmml">/</mo><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.3" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.3.cmml">d</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.3" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1a" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.4" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.4.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1b" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.5" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.5.cmml">n</mi></mrow></msup></mrow><mo stretchy="false" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.2.2.2.2.1.1.2" xref="S2.E2.m1.2.2.2.2.1.1.2.cmml">+</mo><mi id="S2.E2.m1.2.2.2.2.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.3.cmml">Î²</mi></mrow><mo stretchy="false" id="S2.E2.m1.2.2.2.2.1.3" xref="S2.E2.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.2.2.3" xref="S2.E2.m1.2.2.3.cmml">âŸ</mo></munder><mtext id="S2.E2.m1.3.3.1.1.1.1.3.2" xref="S2.E2.m1.3.3.1.1.1.1.3.2a.cmml">update size</mtext></munder></mrow><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3"><in id="S2.E2.m1.3.3.2.cmml" xref="S2.E2.m1.3.3.2"></in><apply id="S2.E2.m1.3.3.3.cmml" xref="S2.E2.m1.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.3.1.cmml" xref="S2.E2.m1.3.3.3">superscript</csymbol><ci id="S2.E2.m1.3.3.3.2.cmml" xref="S2.E2.m1.3.3.3.2">â„¬</ci><apply id="S2.E2.m1.3.3.3.3.cmml" xref="S2.E2.m1.3.3.3.3"><times id="S2.E2.m1.3.3.3.3.1.cmml" xref="S2.E2.m1.3.3.3.3.1"></times><apply id="S2.E2.m1.3.3.3.3.2.cmml" xref="S2.E2.m1.3.3.3.3.2"><divide id="S2.E2.m1.3.3.3.3.2.1.cmml" xref="S2.E2.m1.3.3.3.3.2.1"></divide><apply id="S2.E2.m1.3.3.3.3.2.2.cmml" xref="S2.E2.m1.3.3.3.3.2.2"><times id="S2.E2.m1.3.3.3.3.2.2.1.cmml" xref="S2.E2.m1.3.3.3.3.2.2.1"></times><ci id="S2.E2.m1.3.3.3.3.2.2.2.cmml" xref="S2.E2.m1.3.3.3.3.2.2.2">ğ‘¢</ci><ci id="S2.E2.m1.3.3.3.3.2.2.3.cmml" xref="S2.E2.m1.3.3.3.3.2.2.3">ğ‘</ci></apply><ci id="S2.E2.m1.3.3.3.3.2.3.cmml" xref="S2.E2.m1.3.3.3.3.2.3">ğ‘‘</ci></apply><ci id="S2.E2.m1.3.3.3.3.3.cmml" xref="S2.E2.m1.3.3.3.3.3">ğ‘œ</ci><ci id="S2.E2.m1.3.3.3.3.4.cmml" xref="S2.E2.m1.3.3.3.3.4">ğ‘¤</ci><ci id="S2.E2.m1.3.3.3.3.5.cmml" xref="S2.E2.m1.3.3.3.3.5">ğ‘›</ci></apply></apply><apply id="S2.E2.m1.3.3.1.cmml" xref="S2.E2.m1.3.3.1"><times id="S2.E2.m1.3.3.1.2.cmml" xref="S2.E2.m1.3.3.1.2"></times><ci id="S2.E2.m1.3.3.1.3.cmml" xref="S2.E2.m1.3.3.1.3">ğ’ª</ci><apply id="S2.E2.m1.3.3.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1"><times id="S2.E2.m1.3.3.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1"></times><ci id="S2.E2.m1.3.3.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.2">ğ‘ˆ</ci><apply id="S2.E2.m1.3.3.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.3">subscript</csymbol><apply id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2"><ci id="S2.E2.m1.2.2.3.cmml" xref="S2.E2.m1.2.2.3">âŸ</ci><apply id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"><times id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.3"></times><apply id="S2.E2.m1.2.2.2.4.1.cmml" xref="S2.E2.m1.2.2.2.4.2"><abs id="S2.E2.m1.2.2.2.4.1.1.cmml" xref="S2.E2.m1.2.2.2.4.2.1"></abs><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">ğ°</ci></apply><apply id="S2.E2.m1.2.2.2.2.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1"><plus id="S2.E2.m1.2.2.2.2.1.1.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2"></plus><apply id="S2.E2.m1.2.2.2.2.1.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1"><times id="S2.E2.m1.2.2.2.2.1.1.1.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.2"></times><ci id="S2.E2.m1.2.2.2.2.1.1.1.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.3">ğ»</ci><apply id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1"><times id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.1"></times><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.2">â–³</ci><apply id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3">superscript</csymbol><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.2">ğ°</ci><apply id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3"><times id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.1"></times><apply id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2"><divide id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.1"></divide><apply id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2"><times id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.1"></times><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.2">ğ‘¢</ci><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.2.3">ğ‘</ci></apply><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.2.3">ğ‘‘</ci></apply><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.3">ğ‘œ</ci><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.4.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.4">ğ‘¤</ci><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.5.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.3.3.5">ğ‘›</ci></apply></apply></apply></apply><ci id="S2.E2.m1.2.2.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3">ğ›½</ci></apply></apply></apply><ci id="S2.E2.m1.3.3.1.1.1.1.3.2a.cmml" xref="S2.E2.m1.3.3.1.1.1.1.3.2"><mtext mathsize="70%" id="S2.E2.m1.3.3.1.1.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.3.2">update size</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">\mathcal{B}^{up/down}\in\mathcal{O}(U\times\underbrace{|\mathbf{w}|\times(H(\triangle\mathbf{w}^{up/down})+\beta)}_{\text{update size}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p1.9" class="ltx_p">where <math id="S2.SS2.p1.4.m1.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S2.SS2.p1.4.m1.1a"><mi id="S2.SS2.p1.4.m1.1.1" xref="S2.SS2.p1.4.m1.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m1.1b"><ci id="S2.SS2.p1.4.m1.1.1.cmml" xref="S2.SS2.p1.4.m1.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m1.1c">U</annotation></semantics></math> is the total number of updates performed by each client, <math id="S2.SS2.p1.5.m2.1" class="ltx_Math" alttext="|\mathbf{w}|" display="inline"><semantics id="S2.SS2.p1.5.m2.1a"><mrow id="S2.SS2.p1.5.m2.1.2.2" xref="S2.SS2.p1.5.m2.1.2.1.cmml"><mo stretchy="false" id="S2.SS2.p1.5.m2.1.2.2.1" xref="S2.SS2.p1.5.m2.1.2.1.1.cmml">|</mo><mi id="S2.SS2.p1.5.m2.1.1" xref="S2.SS2.p1.5.m2.1.1.cmml">ğ°</mi><mo stretchy="false" id="S2.SS2.p1.5.m2.1.2.2.2" xref="S2.SS2.p1.5.m2.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m2.1b"><apply id="S2.SS2.p1.5.m2.1.2.1.cmml" xref="S2.SS2.p1.5.m2.1.2.2"><abs id="S2.SS2.p1.5.m2.1.2.1.1.cmml" xref="S2.SS2.p1.5.m2.1.2.2.1"></abs><ci id="S2.SS2.p1.5.m2.1.1.cmml" xref="S2.SS2.p1.5.m2.1.1">ğ°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m2.1c">|\mathbf{w}|</annotation></semantics></math> is the size of the model and <math id="S2.SS2.p1.6.m3.1" class="ltx_Math" alttext="H(\triangle\mathbf{w}^{up/down})" display="inline"><semantics id="S2.SS2.p1.6.m3.1a"><mrow id="S2.SS2.p1.6.m3.1.1" xref="S2.SS2.p1.6.m3.1.1.cmml"><mi id="S2.SS2.p1.6.m3.1.1.3" xref="S2.SS2.p1.6.m3.1.1.3.cmml">H</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m3.1.1.2" xref="S2.SS2.p1.6.m3.1.1.2.cmml">â€‹</mo><mrow id="S2.SS2.p1.6.m3.1.1.1.1" xref="S2.SS2.p1.6.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.p1.6.m3.1.1.1.1.2" xref="S2.SS2.p1.6.m3.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p1.6.m3.1.1.1.1.1" xref="S2.SS2.p1.6.m3.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.SS2.p1.6.m3.1.1.1.1.1.2" xref="S2.SS2.p1.6.m3.1.1.1.1.1.2.cmml">â–³</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m3.1.1.1.1.1.1" xref="S2.SS2.p1.6.m3.1.1.1.1.1.1.cmml">â€‹</mo><msup id="S2.SS2.p1.6.m3.1.1.1.1.1.3" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.cmml"><mi id="S2.SS2.p1.6.m3.1.1.1.1.1.3.2" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.2.cmml">ğ°</mi><mrow id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.cmml"><mrow id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.cmml"><mrow id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.cmml"><mi id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.2" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.1" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.1.cmml">â€‹</mo><mi id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.3" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.3.cmml">p</mi></mrow><mo id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.1" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.1.cmml">/</mo><mi id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.3" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.3.cmml">d</mi></mrow><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.3" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1a" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.4" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.4.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1b" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.5" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.5.cmml">n</mi></mrow></msup></mrow><mo stretchy="false" id="S2.SS2.p1.6.m3.1.1.1.1.3" xref="S2.SS2.p1.6.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m3.1b"><apply id="S2.SS2.p1.6.m3.1.1.cmml" xref="S2.SS2.p1.6.m3.1.1"><times id="S2.SS2.p1.6.m3.1.1.2.cmml" xref="S2.SS2.p1.6.m3.1.1.2"></times><ci id="S2.SS2.p1.6.m3.1.1.3.cmml" xref="S2.SS2.p1.6.m3.1.1.3">ğ»</ci><apply id="S2.SS2.p1.6.m3.1.1.1.1.1.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1"><times id="S2.SS2.p1.6.m3.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.1"></times><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.2">â–³</ci><apply id="S2.SS2.p1.6.m3.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m3.1.1.1.1.1.3.1.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3">superscript</csymbol><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.3.2.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.2">ğ°</ci><apply id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3"><times id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.1"></times><apply id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2"><divide id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.1.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.1"></divide><apply id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2"><times id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.1.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.1"></times><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.2.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.2">ğ‘¢</ci><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.3.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.2.3">ğ‘</ci></apply><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.3.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.2.3">ğ‘‘</ci></apply><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.3.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.3">ğ‘œ</ci><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.4.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.4">ğ‘¤</ci><ci id="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.5.cmml" xref="S2.SS2.p1.6.m3.1.1.1.1.1.3.3.5">ğ‘›</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m3.1c">H(\triangle\mathbf{w}^{up/down})</annotation></semantics></math> is the entropy of the weight updates exchanged during transmitting process. <math id="S2.SS2.p1.7.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.SS2.p1.7.m4.1a"><mi id="S2.SS2.p1.7.m4.1.1" xref="S2.SS2.p1.7.m4.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m4.1b"><ci id="S2.SS2.p1.7.m4.1.1.cmml" xref="S2.SS2.p1.7.m4.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m4.1c">\beta</annotation></semantics></math> is the difference between the true update size and the minimal update size (which is given by the entropy)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib81" title="" class="ltx_ref">sattler2019robust </a></cite>.
Apparently, we can consider three ways to reduce the communication cost: a) reduce the number of clients <math id="S2.SS2.p1.8.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS2.p1.8.m5.1a"><mi id="S2.SS2.p1.8.m5.1.1" xref="S2.SS2.p1.8.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.8.m5.1b"><ci id="S2.SS2.p1.8.m5.1.1.cmml" xref="S2.SS2.p1.8.m5.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.8.m5.1c">K</annotation></semantics></math>, b) reduce the update size, c) reduce the number of updates <math id="S2.SS2.p1.9.m6.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S2.SS2.p1.9.m6.1a"><mi id="S2.SS2.p1.9.m6.1.1" xref="S2.SS2.p1.9.m6.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.9.m6.1b"><ci id="S2.SS2.p1.9.m6.1.1.cmml" xref="S2.SS2.p1.9.m6.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.9.m6.1c">U</annotation></semantics></math>. Starting at these three points, we can organize existing research on communication-efficient federated learning into four groups, <em id="S2.SS2.p1.9.1" class="ltx_emph ltx_font_italic">i.e.,</em> model compression, clients selection, updates reducing and peer-to-peer learning (Fig.Â <a href="#S2.F2" title="Figure 2 â€£ 2.1.2 Pluralistic Solution â€£ 2.1 Statistical Challenges of Federated Learning â€£ 2 Federated Learning â€£ Federated Learning for Healthcare Informatics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Client Selection.</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">The most natural and rough way for reducing communicationn cost is to restrict the participated clients or choose a fraction of parameters to be updated at each round. Shokri <em id="S2.SS2.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib84" title="" class="ltx_ref">shokri2015privacy </a></cite> use the selective stochastic gradient descent protocol, where the selection can be completely random or only the parameters whose current values are farther away from their local optima are selected, <em id="S2.SS2.SSS1.p1.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, those that have a larger gradient.
Nishio <em id="S2.SS2.SSS1.p1.1.3" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib67" title="" class="ltx_ref">nishio2018client </a></cite> proposed a new protocol referred to as <span id="S2.SS2.SSS1.p1.1.4" class="ltx_text ltx_font_italic">FedCS</span>, where the central server manage the resources of heterogeneous clients and determine which clients should participate the current training task by analyzing the resource information of each client, such as wireless channel states, computational capacities and the size of data resources relevant to the current task.
Here, the server should decide how much data, energy and CPU resources used by the mobile devices such that the energy consumption, training latency, and bandwidth cost are minimized while meeting requirements of the training tasks. AnhÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib4" title="" class="ltx_ref">anh2019efficient </a></cite> thus propose to use the Deep Q-LearningÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib91" title="" class="ltx_ref">van2016deep </a></cite> technique that enables the server to find the optimal data and energy management for the mobile devices participating in the mobile crowd-machine learning through federated learning without any prior knowledge of network dynamics.</p>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Model Compression</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">The goal of model compression is to compress the server-to-client exchanges to reduce uplink/downlink communication cost. The first way is through structured updates, where the update is directly learned from a restricted space parameterized using a smaller number of variables, <em id="S2.SS2.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em> sparse, low-rankÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref">konevcny2016afederated </a></cite>, or more specifically, pruning the least useful connections in a networkÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib29" title="" class="ltx_ref">han2015deep </a>; <a href="#bib.bib100" title="" class="ltx_ref">zhu2019multi </a></cite>, weight quantizationÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib15" title="" class="ltx_ref">chen2019communication </a>; <a href="#bib.bib81" title="" class="ltx_ref">sattler2019robust </a></cite>, and model distillationÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib35" title="" class="ltx_ref">hinton2015distilling </a></cite>.
The second way is lossy compression, where a full model update is first learned and then compressed using a combination of quantization, random rotations, and subsampling before sending it to the serverÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib50" title="" class="ltx_ref">konevcny2016afederated </a>; <a href="#bib.bib2" title="" class="ltx_ref">agarwal2018cpsgd </a></cite>.
Then the server decodes the updates before doing the aggregation.</p>
</div>
<div id="S2.SS2.SSS2.p2" class="ltx_para">
<p id="S2.SS2.SSS2.p2.1" class="ltx_p">Federated dropout, in which each client, instead of locally training an update to the whole global model, trains an update to a smaller sub-modelÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib11" title="" class="ltx_ref">caldas2018expanding </a></cite>. These sub-models are subsets of the global model and, as such, the computed local updates have a natural interpretation as updates to the larger global model.
Federated dropout not only reduces the downlink communication but also reduces the size of uplink updates. Moreover, the local computational costs is correspondingly reduced since the local training procedure dealing with parameters with smaller dimensions.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/1911.06270/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="135" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.5.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S2.F3.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Privacy-preserving schemes.<span id="S2.F3.6.2.1" class="ltx_text ltx_font_medium"> </span>a<span id="S2.F3.6.2.2" class="ltx_text ltx_font_medium"> Secure multi-party computation. In security sharing, security values (blue and yellow pie) are split into any number of shares that are distributed among the computing nodes. During the computation, no computation node is able to recover the original value nor learn anything about the output (green pie). Any nodes can combine their shares to reconstruct the original value. </span>b<span id="S2.F3.6.2.3" class="ltx_text ltx_font_medium"> Differential privacy. It guarantees that anyone seeing the result of a differentially private analysis will make the same inference (Answer 1 and Answer 2 are nearly indistinguishable). </span></span></figcaption>
</figure>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>Updates Reduction</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.1" class="ltx_p">Kamp <em id="S2.SS2.SSS3.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib44" title="" class="ltx_ref">kamp2018efficient </a></cite> proposed to average models dynamically depending on the utility of the communication, which leads to a reduction of communication by an order of magnitude compared to periodically communicating state-of-the-art approaches. This facet is well suited for massively distributed systems with limited communication infrastructure.
Bui <em id="S2.SS2.SSS3.p1.1.2" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib10" title="" class="ltx_ref">bui2018partitioned </a></cite> improved federated learning for Bayesian neural networks using partitioned variational inference, where the client can decide to upload the parameters back to the central server after multiple passes through its data, after one local epoch, or after just one mini-batch.
Guha <em id="S2.SS2.SSS3.p1.1.3" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib28" title="" class="ltx_ref">guha2018oneshot </a></cite> focused on techniques for one-shot federated learning, in which they learn a global model from data in the network using only a single round of communication between the devices and the central server.
Besides above works, RenÂ <em id="S2.SS2.SSS3.p1.1.4" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib76" title="" class="ltx_ref">ren2019accelerating </a></cite> theoretically analyzed the detailed expression of the learning efficiency in the CPU scenario and formulate a training acceleration problem under both communication and learning resource budget. Reinforcement learning and round robin learning are widely used to manage the communication and computation resourcesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib4" title="" class="ltx_ref">anh2019efficient </a>; <a href="#bib.bib94" title="" class="ltx_ref">wang2018edge </a>; <a href="#bib.bib101" title="" class="ltx_ref">zhuo2019federated </a>; <a href="#bib.bib38" title="" class="ltx_ref">ickin2019privacy </a></cite>.</p>
</div>
</section>
<section id="S2.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.4 </span>Peer-to-Peer Learning</h4>

<div id="S2.SS2.SSS4.p1" class="ltx_para">
<p id="S2.SS2.SSS4.p1.1" class="ltx_p">In federated learning, a central server is required to coordinate the training process of the global model.
However, the communication cost to the central server may be not affordable since a large number of clients are usually involved.
Also, many practical peer-to-peer networks are usually dynamic, and it is not possible to regularly access a fixed central server. Moreover, because of the dependence on central server, all clients are required to agree on one trusted central body, and whose failure would interrupt the training process for all clients. Therefore, some researches began to study fully decentralized framework where the central server is not requiredÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib83" title="" class="ltx_ref">shayan2018biscotti </a>; <a href="#bib.bib77" title="" class="ltx_ref">roy2019braintorrent </a>; <a href="#bib.bib52" title="" class="ltx_ref">lalitha2019peer </a>; <a href="#bib.bib33" title="" class="ltx_ref">he2019central </a></cite>. The local clients are distributed over the graph/network where they only communicate with their one-hop neighbors. Each client updates its local belief based on own data, then aggregates information from the one-hop neighbors.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Privacy and Security</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.2" class="ltx_p">In federated learning, we usually assume the number of participated clients (<em id="S2.SS3.p1.2.1" class="ltx_emph ltx_font_italic">e.g.</em>, phones, cars, clinical institutionsâ€¦) is large, potentially in the thousands or millions. It is impossible to ensure none of the clients are malicious. The setting of federated learning, where the model is trained locally without revealing the input data or the modelâ€™s output to any clients, prevents direct leakage while training or using the model. However, the clients may infer some information about another clientâ€™s private dataset given the execution of <math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="f(\mathbf{w})" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><mrow id="S2.SS3.p1.1.m1.1.2" xref="S2.SS3.p1.1.m1.1.2.cmml"><mi id="S2.SS3.p1.1.m1.1.2.2" xref="S2.SS3.p1.1.m1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.1.m1.1.2.1" xref="S2.SS3.p1.1.m1.1.2.1.cmml">â€‹</mo><mrow id="S2.SS3.p1.1.m1.1.2.3.2" xref="S2.SS3.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S2.SS3.p1.1.m1.1.2.3.2.1" xref="S2.SS3.p1.1.m1.1.2.cmml">(</mo><mi id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">ğ°</mi><mo stretchy="false" id="S2.SS3.p1.1.m1.1.2.3.2.2" xref="S2.SS3.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.2"><times id="S2.SS3.p1.1.m1.1.2.1.cmml" xref="S2.SS3.p1.1.m1.1.2.1"></times><ci id="S2.SS3.p1.1.m1.1.2.2.cmml" xref="S2.SS3.p1.1.m1.1.2.2">ğ‘“</ci><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">ğ°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">f(\mathbf{w})</annotation></semantics></math>, or over the shared predictive model <math id="S2.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{w}" display="inline"><semantics id="S2.SS3.p1.2.m2.1a"><mi id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">ğ°</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><ci id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">ğ°</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">\mathbf{w}</annotation></semantics></math>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib90" title="" class="ltx_ref">truex2018hybrid </a></cite>.
To this end, there have been many efforts focus on privacy either from an individual point of view or multiparty views, especially in social media field which significantly exacerbated multiparty privacy (MP) conflictsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib89" title="" class="ltx_ref">thomas2010unfriendly </a>; <a href="#bib.bib88" title="" class="ltx_ref">such2018multiparty </a></cite>.</p>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Secure Multi-Party Computation</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">Secure multi-party computation (SMC) has a natural application to federated learning scenarios, where each individual client use a combination of cryptographic techniques and oblivious transfer to jointly compute a function of their private dataÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib70" title="" class="ltx_ref">pathak2010multiparty </a>; <a href="#bib.bib7" title="" class="ltx_ref">bonawitz2017practical </a></cite>.
Homomorphic encryption is a public key system, where any party can encrypt its data with a known public key and perform calculations with data encrypted by others with the same public keyÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib23" title="" class="ltx_ref">fontaine2007survey </a></cite>. Due to its success in cloud computing, it comes naturally into this realm, and it has certainly been used in many federated learning researchesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib32" title="" class="ltx_ref">hardy2017private </a>; <a href="#bib.bib13" title="" class="ltx_ref">Chai2019Secure </a></cite>.</p>
</div>
<div id="S2.SS3.SSS1.p2" class="ltx_para">
<p id="S2.SS3.SSS1.p2.1" class="ltx_p">Although SMC guarantees that none of the parties share anything with each other or with any third party, it can not prevent an adversary from learning some individual information, <em id="S2.SS3.SSS1.p2.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, which clientsâ€™ absence might change the decision boundary of a classifier, etc. Moreover, SMC protocols are usually computationally expensive even for the simplest problems, requiring iterated encryption/decryption and repeated communication between participants about some of the encrypted resultsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib70" title="" class="ltx_ref">pathak2010multiparty </a></cite>.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">Summary of recent work on federated learning for healthcare</span></figcaption>
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.4.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_border_t">Problem</td>
<td id="S2.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_border_t">ML Method</td>
<td id="S2.T1.4.1.1.3" class="ltx_td ltx_align_left ltx_border_t"># Hospital</td>
<td id="S2.T1.4.1.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">Data</td>
</tr>
<tr id="S2.T1.4.2.2" class="ltx_tr">
<td id="S2.T1.4.2.2.1" class="ltx_td ltx_align_left ltx_border_t">Patient Similarity LearningÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib54" title="" class="ltx_ref">lee2018privacy </a></cite>
</td>
<td id="S2.T1.4.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Hashing</td>
<td id="S2.T1.4.2.2.3" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="S2.T1.4.2.2.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">
<span id="S2.T1.4.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.2.2.4.1.1" class="ltx_p">MIMIC-IIIÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib42" title="" class="ltx_ref">johnson2016mimic </a></cite></span>
</span>
</td>
</tr>
<tr id="S2.T1.4.3.3" class="ltx_tr">
<td id="S2.T1.4.3.3.1" class="ltx_td ltx_align_left">Patient Similarity LearningÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib96" title="" class="ltx_ref">xu2020federated </a></cite>
</td>
<td id="S2.T1.4.3.3.2" class="ltx_td ltx_align_center">Hashing</td>
<td id="S2.T1.4.3.3.3" class="ltx_td ltx_align_center">20</td>
<td id="S2.T1.4.3.3.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.3.3.4.1.1" class="ltx_p">MIMIC-III</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.4.4" class="ltx_tr">
<td id="S2.T1.4.4.4.1" class="ltx_td ltx_align_left">PhenotypingÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib47" title="" class="ltx_ref">kim2017federated </a></cite>
</td>
<td id="S2.T1.4.4.4.2" class="ltx_td ltx_align_center">*TF</td>
<td id="S2.T1.4.4.4.3" class="ltx_td ltx_align_center">1-5</td>
<td id="S2.T1.4.4.4.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.4.4.1.1" class="ltx_p">MIMIC-III, UCSDÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib92" title="" class="ltx_ref">wah2011caltech </a></cite></span>
</span>
</td>
</tr>
<tr id="S2.T1.4.5.5" class="ltx_tr">
<td id="S2.T1.4.5.5.1" class="ltx_td ltx_align_left">PhenotypingÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib59" title="" class="ltx_ref">liu2019two </a></cite>
</td>
<td id="S2.T1.4.5.5.2" class="ltx_td ltx_align_center">NLP</td>
<td id="S2.T1.4.5.5.3" class="ltx_td ltx_align_center">10</td>
<td id="S2.T1.4.5.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.5.5.4.1.1" class="ltx_p">MIMIC-III</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.6.6" class="ltx_tr">
<td id="S2.T1.4.6.6.1" class="ltx_td ltx_align_left">Representation LearningÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib85" title="" class="ltx_ref">silva2018federated </a></cite>
</td>
<td id="S2.T1.4.6.6.2" class="ltx_td ltx_align_center">PCA</td>
<td id="S2.T1.4.6.6.3" class="ltx_td ltx_align_center">10-100</td>
<td id="S2.T1.4.6.6.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.6.6.4.1.1" class="ltx_p">ADNI, UK Biobank, PPMI, MIRIAD</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.7.7" class="ltx_tr">
<td id="S2.T1.4.7.7.1" class="ltx_td ltx_align_left">Mortality PredictionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib37" title="" class="ltx_ref">huang2019patient </a></cite>
</td>
<td id="S2.T1.4.7.7.2" class="ltx_td ltx_align_center">Autoencoder</td>
<td id="S2.T1.4.7.7.3" class="ltx_td ltx_align_center">5-50</td>
<td id="S2.T1.4.7.7.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.7.7.4.1.1" class="ltx_p">eICU Collaborative Research DatabaseÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib73" title="" class="ltx_ref">pollard2018eicu </a></cite></span>
</span>
</td>
</tr>
<tr id="S2.T1.4.8.8" class="ltx_tr">
<td id="S2.T1.4.8.8.1" class="ltx_td ltx_align_left">Hospitalizations PredictionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">brisimi2018federated </a></cite>
</td>
<td id="S2.T1.4.8.8.2" class="ltx_td ltx_align_center">SVM</td>
<td id="S2.T1.4.8.8.3" class="ltx_td ltx_align_center">5, 10</td>
<td id="S2.T1.4.8.8.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.8.8.4.1.1" class="ltx_p">Boston Medical Center</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.9.9" class="ltx_tr">
<td id="S2.T1.4.9.9.1" class="ltx_td ltx_align_left">Preterm-birth PredictionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">boughorbel2019federated </a></cite>
</td>
<td id="S2.T1.4.9.9.2" class="ltx_td ltx_align_center">RNN</td>
<td id="S2.T1.4.9.9.3" class="ltx_td ltx_align_center">50</td>
<td id="S2.T1.4.9.9.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.9.9.4.1.1" class="ltx_p">Cerner Health Facts</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.10.10" class="ltx_tr">
<td id="S2.T1.4.10.10.1" class="ltx_td ltx_align_left">Mortality PredictionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib72" title="" class="ltx_ref">pfohl2019federated </a></cite>
</td>
<td id="S2.T1.4.10.10.2" class="ltx_td ltx_align_center">LR, NN</td>
<td id="S2.T1.4.10.10.3" class="ltx_td ltx_align_center">31</td>
<td id="S2.T1.4.10.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.10.10.4.1.1" class="ltx_p">eICU Collaborative Research Database</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.11.11" class="ltx_tr">
<td id="S2.T1.4.11.11.1" class="ltx_td ltx_align_left">Mortality PredictionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib82" title="" class="ltx_ref">sharma2019preserving </a></cite>
</td>
<td id="S2.T1.4.11.11.2" class="ltx_td ltx_align_center">LR, MLP</td>
<td id="S2.T1.4.11.11.3" class="ltx_td ltx_align_center">2</td>
<td id="S2.T1.4.11.11.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S2.T1.4.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.11.11.4.1.1" class="ltx_p">MIMIC-III</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.12.12" class="ltx_tr">
<td id="S2.T1.4.12.12.1" class="ltx_td ltx_align_left ltx_border_t" colspan="4">*TF: Tensor Factorization, MLP: Multi-layer Perceptron</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S2.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Differential Privacy</h4>

<div id="S2.SS3.SSS2.p1" class="ltx_para">
<p id="S2.SS3.SSS2.p1.1" class="ltx_p">Differential privacy (DP)Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib20" title="" class="ltx_ref">dwork2006our </a></cite> is an alternative theoretical model for protecting the privacy of individual data, which has been widely applied to many areas, not only traditional algorithms, <em id="S2.SS3.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em> boostingÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib21" title="" class="ltx_ref">dwork2010boosting </a></cite>, principal component analysisÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib14" title="" class="ltx_ref">chaudhuri2013near </a></cite>, support vector machineÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib78" title="" class="ltx_ref">rubinstein2009learning </a></cite>, but also deep learning researchÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">abadi2016deep </a>; <a href="#bib.bib62" title="" class="ltx_ref">mcmahan2017learning </a></cite>. It ensures that the addition or removal does not substantially affect the outcome of any analysis, and is thus also widely studied in federated learning research to prevent the indirect leakageÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib84" title="" class="ltx_ref">shokri2015privacy </a>; <a href="#bib.bib62" title="" class="ltx_ref">mcmahan2017learning </a>; <a href="#bib.bib1" title="" class="ltx_ref">abadi2016deep </a></cite>. However, DP only protects users from data leakage to a certain extent, and may reduce performance in prediction accuracy because it is a lossy methodÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">cheng2019secureboost </a></cite>.
Thus, some researchers combine DP with SMC to reduce the growth of noise injection as the number of parties increases without sacrificing privacy while preserving provable privacy guarantees, protecting against extraction attacks and collusion threatsÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib16" title="" class="ltx_ref">cheng2019secureboost </a>; <a href="#bib.bib90" title="" class="ltx_ref">truex2018hybrid </a></cite>.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Applications</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Federated learning has been incorporated and utilized in many domains. This widespread adoption is due in part by the fact that it enables a collaborative modeling mechanism that allows for efficient ML all while ensuring data privacy and legal compliance between multiple parties or multiple computing nodes. Some promising examples that highlight these capabilities are virtual keyboard predictionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib31" title="" class="ltx_ref">hard2018federated </a>; <a href="#bib.bib62" title="" class="ltx_ref">mcmahan2017learning </a></cite>, smart retailÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib99" title="" class="ltx_ref">zhao2019mobile </a></cite>, financeÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib97" title="" class="ltx_ref">Yang:2019:FML:3306498.3298981 </a></cite>, vehicle-to-vehicle communicationÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib80" title="" class="ltx_ref">samarakoon2018federated </a></cite>. In this section, we focus primarily on applications within the healthcare space, but also discuss promising applications in other domains since some principles can be applied to healthcare.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Healthcare</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">EHRs have emerged as a crucial source of real world healthcare data that has been used for an amalgamation of important biomedical researchÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib24" title="" class="ltx_ref">glicksberg2018next </a>; <a href="#bib.bib39" title="" class="ltx_ref">jensen2012mining </a></cite>, including for machine learning researchÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib64" title="" class="ltx_ref">miotto2018deep </a></cite>. While providing a huge amount of patient data for analysis, EHRs contain systemic and random biases overall and specific to hospitals that limit the generalizability of results. For example, Obermeyer <em id="S3.SS1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em>Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib68" title="" class="ltx_ref">obermeyer2019dissecting </a></cite> found that a commonly used algorithm to determine enrollment in specific health programs were biased against African Americans, assigning the same level of risk to healthier Caucasian patients. These improperly calibrated algorithms can arise due to a variety of reasons, such as differences in underlying access to care or low representation in training data. It is clear that one way to alleviate the risk for such biased algorithms is the ability to learn from EHR data that is more representative of the global population and which goes beyond a single hospital or site. Unfortunately, due to a myriad of reasons such as discrepant data schemes and privacy concerns, it is unlikely that data will eve be connected together in a single database to learn from all at once. The creation and utility of standardized common data models, such as OMOPÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib36" title="" class="ltx_ref">hripcsak2015observational </a></cite>, allow for more wide-spread replication analyses but it does not overcome the limitations of joint data access. As such, it is imperative that alternative strategies emerge for learning from multiple EHR data sources that go beyond the common discovery-replication framework. Federated learning might be the tool to enable large-scale representative ML of EHR data and we discuss many studies which demonstrate this fact below.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Federated learning is a viable method to connect EHR data from medical institutions, allowing them to share their experiences, and not their data, with a guarantee of privacy Â <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">boughorbel2019federated </a>; <a href="#bib.bib27" title="" class="ltx_ref">gruendner2019ketos </a>; <a href="#bib.bib74" title="" class="ltx_ref">raja2014modern </a>; <a href="#bib.bib19" title="" class="ltx_ref">duan2020learning </a>; <a href="#bib.bib57" title="" class="ltx_ref">li2019distributed </a>; <a href="#bib.bib37" title="" class="ltx_ref">huang2019patient </a></cite>. In these scenarios, the performance of ML model will be significantly improved by the iterative improvements of learning from large and diverse medical data sets.
There have been some tasks were studied in federated learning setting in healthcare, <em id="S3.SS1.p2.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, patient similarity learningÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib54" title="" class="ltx_ref">lee2018privacy </a></cite>, patient representation learning, phenotypingÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib47" title="" class="ltx_ref">kim2017federated </a>; <a href="#bib.bib59" title="" class="ltx_ref">liu2019two </a></cite>, predictive modelingÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">brisimi2018federated </a>; <a href="#bib.bib37" title="" class="ltx_ref">huang2019patient </a>; <a href="#bib.bib82" title="" class="ltx_ref">sharma2019preserving </a></cite>, <em id="S3.SS1.p2.1.2" class="ltx_emph ltx_font_italic">etc</em>.
Summary of these work is listed in TableÂ <a href="#S2.T1" title="Table 1 â€£ 2.3.1 Secure Multi-Party Computation â€£ 2.3 Privacy and Security â€£ 2 Federated Learning â€£ Federated Learning for Healthcare Informatics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Others</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">An important application of federated learning is for natural language processing (NLP) tasks. When Google first proposed federated learning concept in 2016, the application scenario is Gboard - a virtual keyboard of Google for touchscreen mobile devices with support for more than 600 language varietiesÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib31" title="" class="ltx_ref">hard2018federated </a>; <a href="#bib.bib62" title="" class="ltx_ref">mcmahan2017learning </a></cite>. Indeed, as users increasingly turn to mobile devices, fast mobile input methods with auto-correction, word completion, and next-word prediction features are becoming more and more important. For these NLP tasks, especially next-word prediction, typed text in mobile apps are usually better than the data from scanned books or speech-to-text in terms of aiding typing on a mobile keyboard. However, these language data often contain sensitive information, <em id="S3.SS2.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, passwords, search queries, or text messages with personal information. Therefore, federated learning has a promising application in NLP like virtual keyboard predictionÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib31" title="" class="ltx_ref">hard2018federated </a>; <a href="#bib.bib62" title="" class="ltx_ref">mcmahan2017learning </a>; <a href="#bib.bib6" title="" class="ltx_ref">bonawitz2019towards </a></cite>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.3.2" class="ltx_text" style="font-size:90%;">Popular tools for federated learning research</span></figcaption>
<table id="S3.T2.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.4.1.1" class="ltx_tr">
<th id="S3.T2.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Project Name</th>
<th id="S3.T2.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Developer</th>
<th id="S3.T2.4.1.1.3" class="ltx_td ltx_align_center ltx_align_middle ltx_th ltx_th_column ltx_border_t">Description</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.4.2.1" class="ltx_tr">
<td id="S3.T2.4.2.1.1" class="ltx_td ltx_align_center ltx_border_t">PySyftÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib79" title="" class="ltx_ref">ryffel2018generic </a></cite>
</td>
<td id="S3.T2.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t">OpenMined</td>
<td id="S3.T2.4.2.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.2pt;">
<span id="S3.T2.4.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.2.1.3.1.1" class="ltx_p">It decouples private data from model training using federated learning, DP and MPC within PyTorch. TensorFlow bindings is also availableÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib69" title="" class="ltx_ref">pysyft2019 </a></cite>.</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.3.2" class="ltx_tr">
<td id="S3.T2.4.3.2.1" class="ltx_td ltx_align_center ltx_border_t">TFFÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib25" title="" class="ltx_ref">tff2019 </a></cite>
</td>
<td id="S3.T2.4.3.2.2" class="ltx_td ltx_align_center ltx_border_t">Google</td>
<td id="S3.T2.4.3.2.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.2pt;">
<span id="S3.T2.4.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.3.2.3.1.1" class="ltx_p">With TFF, TensorFlow provides users with a flexible and open framework through which they can simulate distributed computing locally.</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.4.3" class="ltx_tr">
<td id="S3.T2.4.4.3.1" class="ltx_td ltx_align_center ltx_border_t">FATEÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib3" title="" class="ltx_ref">fate2019 </a></cite>
</td>
<td id="S3.T2.4.4.3.2" class="ltx_td ltx_align_center ltx_border_t">Webank</td>
<td id="S3.T2.4.4.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.2pt;">
<span id="S3.T2.4.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.3.3.1.1" class="ltx_p">FATE support the Federated AI ecosystem, where a secure computing protocol is implemented based on homomorphic encryption and MPC.</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.5.4" class="ltx_tr">
<td id="S3.T2.4.5.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">Tensor/IOÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib18" title="" class="ltx_ref">tensorio2019 </a></cite>
</td>
<td id="S3.T2.4.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">Dow <em id="S3.T2.4.5.4.2.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S3.T2.4.5.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_t" style="width:199.2pt;">
<span id="S3.T2.4.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.5.4.3.1.1" class="ltx_p">Tensor/IO is a lightweight cross-platform library for on-device machine learning, bringing the power of TensorFlow and TensorFlow Lite to iOS, Android, and React native applications.</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Other applications include smart retailÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib99" title="" class="ltx_ref">zhao2019mobile </a></cite>, financeÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib46" title="" class="ltx_ref">kawa2019credit </a></cite> and so on. Specifically, smart retail aims to use machine learning technology to provide personalized services to customers based on data like user purchasing power and product characteristics for product recommendation and sales services. In terms of financial applications, Tencentâ€™s WeBank
leverages federated learning technologies for credit risk management, where several Banks could jointly generate a comprehensive credit score for a customer without sharing his or her dataÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib97" title="" class="ltx_ref">Yang:2019:FML:3306498.3298981 </a></cite>.
With the growth and development of federated learning, there are many companies or research teams that have carried out various tools oriented to scientific research and product development. Popular ones are listed in TableÂ <a href="#S3.T2" title="Table 2 â€£ 3.2 Others â€£ 3 Applications â€£ Federated Learning for Healthcare Informatics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusions and Open Questions</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this survey, we review the current progress on federated learning including, but not limited to healthcare field. We summarize the general solutions to the various challenges in federated learning and hope to provide a useful resource for researchers to refer. Besides the summarized general issues in federated learning setting, we list some probably encountered directions or open questions when federated learning is applied in healthcare area in the following.</p>
</div>
<div id="S4.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Data Quality</span>.
Federated learning has the potential to connect all the isolated medical institutions, hospitals or devices to make them share their experiences with privacy guarantee. However, most health systems suffer from data clutter and efficiency problems. The quality of data collected from multiple sources is uneven and there is no uniform data standard. The analyzed results are apparently worthless when dirty data are accidentally used as samples. The ability to strategically leverage medical data is critical. Therefore, how to clean, correct and complete data and accordingly ensure data quality is a key to improve the machine learning model weather we are dealing with federated learning scenario or not.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Incorporating Expert Knowledge</span>.
In 2016, IBM introduced Watson for Oncology, a tool that uses the natural language processing system to summarize patientsâ€™ electronic health records and search the powerful database behind it to advise doctors on treatments. Unfortunately, some oncologists say they trust their judgment more than Watson tells them what needs to be doneÂ <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>http://news.moore.ren/industry/158978.htm</span></span></span>. Therefore, hopefully doctors will be involved in the training process. Since every data set collected here cannot be of high quality, so it will be very helpful if the standards of evidence-based machine is introduced, doctors will also see the diagnostic criteria of artificial intelligence. If wrong, doctors will give further guidance to artificial intelligence to improve the accuracy of machine learning model during training process."</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Incentive Mechanisms</span>.
With the internet of things and the variety of third party portals, a growing number of smartphone healthcare apps are compatible with wearable devices. In addition to data accumulated in hospitals or medical centers, another type of data that is of great value is coming from wearable devices not only to the researchers, but more importantly for the owners. However, during federated model training process, the clients suffer from considerable overhead in communication and computation.
Without well-designed incentives, self-interested mobile or other wearable devices will be reluctant to participate in federal learning tasks, which will hinder the adoption of federated learningÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib45" title="" class="ltx_ref">kang2019incentive </a></cite>. How to design an efficient incentive mechanism to attract devices with high-quality data to join federated learning is another important problem.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Personalization</span>.
Wearable devices are more focus on public health, which means helping people who are already healthy to improve their health, such as helping them exercise, practice meditation and improve their sleep quality. How to assist patients to carry out scientifically designed personalized health management, correct the functional pathological state by examining indicators, and interrupt the pathological change process are very important. Reasonable chronic disease management can avoid emergency visits and hospitalization and reduce the number of visits. Cost and labor savings. Although there are some general work about federated learning personalizationÂ <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib86" title="" class="ltx_ref">sim2019investigation </a>; <a href="#bib.bib40" title="" class="ltx_ref">jiang2019improving </a></cite>, for healthcare informatics, how to combining the medical domain knowledge and make the global model be personalized for every medical institutions or wearable devices is another open question.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p"><span id="S4.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Model Precision</span>.
Federated tries to make isolated institutions or devices share their experiences, and the performance of machine learning model will be significantly improved by the formed large medical dataset. However, the prediction task is currently restricted and relatively simple. Medical treatment itself is a very professional and accurate field. Medical devices in hospitals have incomparable advantages over wearable devices. And the models of Doc.ai could predict the phenome collection of oneâ€™s biometric data based on its selfie, such as height, weight, age, sex and BMI<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://doc.ai/blog/do-you-know-how-valuable-your-medical-da/</span></span></span>. How to improve the prediction model to predict future health conditions is definitely worth exploring.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
The work is supported by ONR N00014-18-1-2585 and NSF 1750326.

</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Conflict of interest</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The authors declare that they have no conflict of interest.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
Abadi, M., Chu, A., Goodfellow, I., McMahan, H.B., Mironov, I., Talwar, K.,
Zhang, L.: Deep learning with differential privacy.

</span>
<span class="ltx_bibblock">In: Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security, pp. 308â€“318. ACM (2016)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
Agarwal, N., Suresh, A.T., Yu, F.X.X., Kumar, S., McMahan, B.: cpsgd:
Communication-efficient and differentially-private distributed sgd.

</span>
<span class="ltx_bibblock">In: Advances in Neural Information Processing Systems, pp. 7564â€“7575
(2018)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
AI, W.: Federated ai technology enabler.

</span>
<span class="ltx_bibblock">https://www.fedai.org/cn/ (2019)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
Anh, T.T., Luong, N.C., Niyato, D., Kim, D.I., Wang, L.C.: Efficient training
management for mobile crowd-machine learning: A deep reinforcement learning
approach.

</span>
<span class="ltx_bibblock">IEEE Wireless Communications Letters (2019)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
Barcelos, C., Gluz, J., Vicari, R.: An agent-based federated learning object
search service.

</span>
<span class="ltx_bibblock">Interdisciplinary journal of e-learning and learning objects
<span id="bib.bib5.1.1" class="ltx_text ltx_font_bold">7</span>(1), 37â€“54 (2011)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V.,
Kiddon, C., Konecny, J., Mazzocchi, S., McMahan, H.B., etÂ al.: Towards
federated learning at scale: System design.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1902.01046 (2019)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.B., Patel, S.,
Ramage, D., Segal, A., Seth, K.: Practical secure aggregation for
privacy-preserving machine learning.

</span>
<span class="ltx_bibblock">In: Proceedings of the 2017 ACM SIGSAC Conference on Computer and
Communications Security, pp. 1175â€“1191. ACM (2017)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
Boughorbel, S., Jarray, F., Venugopal, N., Moosa, S., Elhadi, H., Makhlouf, M.:
Federated uncertainty-aware learning for distributed hospital ehr data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1910.12191 (2019)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
Brisimi, T.S., Chen, R., Mela, T., Olshevsky, A., Paschalidis, I.C., Shi, W.:
Federated learning of predictive models from federated electronic health
records.

</span>
<span class="ltx_bibblock">International journal of medical informatics <span id="bib.bib9.1.1" class="ltx_text ltx_font_bold">112</span>, 59â€“67
(2018)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
Bui, T.D., Nguyen, C.V., Swaroop, S., Turner, R.E.: Partitioned variational
inference: A unified framework encompassing federated and continual learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1811.11206 (2018)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(11)</span>
<span class="ltx_bibblock">
Caldas, S., KoneÄny, J., McMahan, H.B., Talwalkar, A.: Expanding the
reach of federated learning by reducing client resource requirements.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1812.07210 (2018)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(12)</span>
<span class="ltx_bibblock">
Caldas, S., Wu, P., Li, T., KoneÄná»³, J., McMahan, H.B., Smith, V.,
Talwalkar, A.: Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1812.01097 (2018)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(13)</span>
<span class="ltx_bibblock">
Chai, D., Wang, L., Chen, K., Yang, Q.: Secure federated matrix factorization
(2019)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(14)</span>
<span class="ltx_bibblock">
Chaudhuri, K., Sarwate, A.D., Sinha, K.: A near-optimal algorithm for
differentially-private principal components.

</span>
<span class="ltx_bibblock">The Journal of Machine Learning Research <span id="bib.bib14.1.1" class="ltx_text ltx_font_bold">14</span>(1), 2905â€“2943
(2013)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(15)</span>
<span class="ltx_bibblock">
Chen, Y., Sun, X., Jin, Y.: Communication-efficient federated deep learning
with asynchronous model update and temporally weighted aggregation.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1903.07424 (2019)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
Cheng, K., Fan, T., Jin, Y., Liu, Y., Chen, T., Yang, Q.: Secureboost: A
lossless federated learning framework.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1901.08755 (2019)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(17)</span>
<span class="ltx_bibblock">
Corinzia, L., Buhmann, J.M.: Variational federated multi-task learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1906.06268 (2019)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
doc.ai: Declarative, on-device machine learning for ios, android, and react
native.

</span>
<span class="ltx_bibblock">https://github.com/doc-ai/tensorio (2019)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(19)</span>
<span class="ltx_bibblock">
Duan, R., Boland, M.R., Liu, Z., Liu, Y., Chang, H.H., Xu, H., Chu, H., Schmid,
C.H., Forrest, C.B., Holmes, J.H., etÂ al.: Learning from electronic health
records across multiple sites: A communication-efficient and
privacy-preserving distributed algorithm.

</span>
<span class="ltx_bibblock">Journal of the American Medical Informatics Association
<span id="bib.bib19.1.1" class="ltx_text ltx_font_bold">27</span>(3), 376â€“385 (2020)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
Dwork, C., Kenthapadi, K., McSherry, F., Mironov, I., Naor, M.: Our data,
ourselves: Privacy via distributed noise generation.

</span>
<span class="ltx_bibblock">In: Annual International Conference on the Theory and Applications of
Cryptographic Techniques, pp. 486â€“503. Springer (2006)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
Dwork, C., Rothblum, G.N., Vadhan, S.: Boosting and differential privacy.

</span>
<span class="ltx_bibblock">In: 2010 IEEE 51st Annual Symposium on Foundations of Computer
Science, pp. 51â€“60. IEEE (2010)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(22)</span>
<span class="ltx_bibblock">
Eichner, H., Koren, T., McMahan, H.B., Srebro, N., Talwar, K.: Semi-cyclic
stochastic gradient descent.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1904.10120 (2019)

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(23)</span>
<span class="ltx_bibblock">
Fontaine, C., Galand, F.: A survey of homomorphic encryption for
nonspecialists.

</span>
<span class="ltx_bibblock">EURASIP Journal on Information Security <span id="bib.bib23.1.1" class="ltx_text ltx_font_bold">2007</span>, 15 (2007)

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(24)</span>
<span class="ltx_bibblock">
Glicksberg, B.S., Johnson, K.W., Dudley, J.T.: The next generation of precision
medicine: observational studies, electronic health records, biobanks and
continuous monitoring.

</span>
<span class="ltx_bibblock">Human molecular genetics <span id="bib.bib24.1.1" class="ltx_text ltx_font_bold">27</span>(R1), R56â€“R62 (2018)

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(25)</span>
<span class="ltx_bibblock">
Google: Tensorflow federated.

</span>
<span class="ltx_bibblock">https://www.tensorflow.org/federated (2019)

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(26)</span>
<span class="ltx_bibblock">
Gostin, L.O.: National health information privacy: regulations under the health
insurance portability and accountability act.

</span>
<span class="ltx_bibblock">JAMA <span id="bib.bib26.1.1" class="ltx_text ltx_font_bold">285</span>(23), 3015â€“3021 (2001)

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(27)</span>
<span class="ltx_bibblock">
Gruendner, J., Schwachhofer, T., Sippl, P., Wolf, N., Erpenbeck, M., Gulden,
C., Kapsner, L.A., Zierk, J., Mate, S., StÃ¼rzl, M., etÂ al.: Ketos:
Clinical decision support and machine learning as a serviceâ€“a training and
deployment platform based on docker, omop-cdm, and fhir web services.

</span>
<span class="ltx_bibblock">PloS one <span id="bib.bib27.1.1" class="ltx_text ltx_font_bold">14</span>(10) (2019)

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(28)</span>
<span class="ltx_bibblock">
Guha, N., Talwalkar, A., Smith, V.: One-shot federated learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1902.11175 (2019)

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(29)</span>
<span class="ltx_bibblock">
Han, S., Mao, H., Dally, W.J.: Deep compression: Compressing deep neural
networks with pruning, trained quantization and huffman coding.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1510.00149 (2015)

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(30)</span>
<span class="ltx_bibblock">
Han, Y., Zhang, X.: Robust federated training via collaborative machine
teaching using trusted instances.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1905.02941 (2019)

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(31)</span>
<span class="ltx_bibblock">
Hard, A., Rao, K., Mathews, R., Beaufays, F., Augenstein, S., Eichner, H.,
Kiddon, C., Ramage, D.: Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1811.03604 (2018)

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(32)</span>
<span class="ltx_bibblock">
Hardy, S., Henecka, W., Ivey-Law, H., Nock, R., Patrini, G., Smith, G., Thorne,
B.: Private federated learning on vertically partitioned data via entity
resolution and additively homomorphic encryption.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1711.10677 (2017)

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(33)</span>
<span class="ltx_bibblock">
He, C., Tan, C., Tang, H., Qiu, S., Liu, J.: Central server free federated
learning over single-sided trust social networks.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1910.04956 (2019)

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(34)</span>
<span class="ltx_bibblock">
Hill, P.: The rationale for learning communities and learning community models.
(1985)

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(35)</span>
<span class="ltx_bibblock">
Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural
network.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1503.02531 (2015)

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(36)</span>
<span class="ltx_bibblock">
Hripcsak, G., Duke, J.D., Shah, N.H., Reich, C.G., Huser, V., Schuemie, M.J.,
Suchard, M.A., Park, R.W., Wong, I.C.K., Rijnbeek, P.R., etÂ al.:
Observational health data sciences and informatics (ohdsi): opportunities for
observational researchers.

</span>
<span class="ltx_bibblock">Studies in health technology and informatics <span id="bib.bib36.1.1" class="ltx_text ltx_font_bold">216</span>, 574 (2015)

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(37)</span>
<span class="ltx_bibblock">
Huang, L., Liu, D.: Patient clustering improves efficiency of federated machine
learning to predict mortality and hospital stay time using distributed
electronic medical records.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1903.09296 (2019)

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(38)</span>
<span class="ltx_bibblock">
Ickin, S., Vandikas, K., Fiedler, M.: Privacy preserving qoe modeling using
collaborative learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1906.09248 (2019)

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(39)</span>
<span class="ltx_bibblock">
Jensen, P.B., Jensen, L.J., Brunak, S.: Mining electronic health records:
towards better research applications and clinical care.

</span>
<span class="ltx_bibblock">Nature Reviews Genetics <span id="bib.bib39.1.1" class="ltx_text ltx_font_bold">13</span>(6), 395â€“405 (2012)

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(40)</span>
<span class="ltx_bibblock">
Jiang, Y., KoneÄná»³, J., Rush, K., Kannan, S.: Improving federated
learning personalization via model agnostic meta learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1909.12488v1 (2019)

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(41)</span>
<span class="ltx_bibblock">
Jin, Y., Wei, X., Liu, Y., Yang, Q.: A survey towards federated semi-supervised
learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2002.11545 (2020)

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(42)</span>
<span class="ltx_bibblock">
Johnson, A.E., Pollard, T.J., Shen, L., Li-wei, H.L., Feng, M., Ghassemi, M.,
Moody, B., Szolovits, P., Celi, L.A., Mark, R.G.: Mimic-iii, a freely
accessible critical care database.

</span>
<span class="ltx_bibblock">Scientific data <span id="bib.bib42.1.1" class="ltx_text ltx_font_bold">3</span>, 160035 (2016)

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(43)</span>
<span class="ltx_bibblock">
Kairouz, P., McMahan, H.B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A.N.,
Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., etÂ al.: Advances and
open problems in federated learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1912.04977 (2019)

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(44)</span>
<span class="ltx_bibblock">
Kamp, M., Adilova, L., Sicking, J., HÃ¼ger, F., Schlicht, P., Wirtz, T.,
Wrobel, S.: Efficient decentralized deep learning by dynamic model averaging.

</span>
<span class="ltx_bibblock">In: Joint European Conference on Machine Learning and Knowledge
Discovery in Databases, pp. 393â€“409. Springer (2018)

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(45)</span>
<span class="ltx_bibblock">
Kang, J., Xiong, Z., Niyato, D., Yu, H., Liang, Y.C., Kim, D.I.: Incentive
design for efficient federated learning in mobile networks: A contract theory
approach.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1905.07479 (2019)

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(46)</span>
<span class="ltx_bibblock">
Kawa, D., Punyani, S., Nayak, P., Karkera, A., Jyotinagar, V.: Credit risk
assessment from combined bank records using federated learning (2019)

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(47)</span>
<span class="ltx_bibblock">
Kim, Y., Sun, J., Yu, H., Jiang, X.: Federated tensor factorization for
computational phenotyping.

</span>
<span class="ltx_bibblock">In: Proceedings of the 23rd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 887â€“895. ACM (2017)

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(48)</span>
<span class="ltx_bibblock">
KoneÄná»³, J., McMahan, B., Ramage, D.: Federated optimization:
Distributed optimization beyond the datacenter.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1511.03575 (2015)

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(49)</span>
<span class="ltx_bibblock">
KoneÄná»³, J., McMahan, H.B., Ramage, D., RichtÃ¡rik, P.: Federated
optimization: Distributed machine learning for on-device intelligence.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1610.02527 (2016)

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(50)</span>
<span class="ltx_bibblock">
KoneÄná»³, J., McMahan, H.B., Yu, F.X., RichtÃ¡rik, P., Suresh,
A.T., Bacon, D.: Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1610.05492 (2016)

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(51)</span>
<span class="ltx_bibblock">
Kulkarni, V., Kulkarni, M., Pant, A.: Survey of personalization techniques for
federated learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2003.08673 (2020)

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(52)</span>
<span class="ltx_bibblock">
Lalitha, A., Kilinc, O.C., Javidi, T., Koushanfar, F.: Peer-to-peer federated
learning on graphs.

</span>
<span class="ltx_bibblock">rXiv preprint arXiv:1901.11173 (2019)

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(53)</span>
<span class="ltx_bibblock">
LeCun, Y., Bengio, Y., Hinton, G.: Deep learning.

</span>
<span class="ltx_bibblock">nature <span id="bib.bib53.1.1" class="ltx_text ltx_font_bold">521</span>(7553), 436â€“444 (2015)

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(54)</span>
<span class="ltx_bibblock">
Lee, J., Sun, J., Wang, F., Wang, S., Jun, C.H., Jiang, X.: Privacy-preserving
patient similarity learning in a federated environment: development and
analysis.

</span>
<span class="ltx_bibblock">JMIR medical informatics <span id="bib.bib54.1.1" class="ltx_text ltx_font_bold">6</span>(2), e20 (2018)

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(55)</span>
<span class="ltx_bibblock">
Li, T., Sahu, A.K., Zaheer, M., Sanjabi, M., Talwalkar, A., Smith1, V.:
Federated optimization for heterogeneous networks.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1812.06127 (2019)

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(56)</span>
<span class="ltx_bibblock">
Li, T., Sanjabi, M., Smith, V.: Fair resource allocation in federated learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1905.10497 (2019)

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(57)</span>
<span class="ltx_bibblock">
Li, Z., Roberts, K., Jiang, X., Long, Q.: Distributed learning from multiple
ehr databases: Contextual embedding models for medical events.

</span>
<span class="ltx_bibblock">Journal of biomedical informatics <span id="bib.bib57.1.1" class="ltx_text ltx_font_bold">92</span>, 103138 (2019)

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(58)</span>
<span class="ltx_bibblock">
Lim, W.Y.B., Luong, N.C., Hoang, D.T., Jiao, Y., Liang, Y.C., Yang, Q., Niyato,
D., Miao, C.: Federated learning in mobile edge networks: A comprehensive
survey.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1909.11875 (2019)

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(59)</span>
<span class="ltx_bibblock">
Liu, D., Dligach, D., Miller, T.: Two-stage federated phenotyping and patient
representation learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1908.05596 (2019)

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(60)</span>
<span class="ltx_bibblock">
Lyu, L., Yu, H., Yang, Q.: Threats to federated learning: A survey.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2003.02133 (2020)

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(61)</span>
<span class="ltx_bibblock">
McMahan, B., Moore, E., Ramage, D., Hampson, S., yÂ Arcas, B.A.:
Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In: Artificial Intelligence and Statistics, pp. 1273â€“1282 (2017)

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(62)</span>
<span class="ltx_bibblock">
McMahan, H.B., Ramage, D., Talwar, K., Zhang, L.: Learning differentially
private recurrent language models.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1710.06963 (2017)

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(63)</span>
<span class="ltx_bibblock">
Min, X., Yu, B., Wang, F.: Predictive modeling of the hospital readmission risk
from patientsâ€™ claims data using machine learning: A case study on copd.

</span>
<span class="ltx_bibblock">Scientific reports <span id="bib.bib63.1.1" class="ltx_text ltx_font_bold">9</span>(1), 2362 (2019)

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(64)</span>
<span class="ltx_bibblock">
Miotto, R., Wang, F., Wang, S., Jiang, X., Dudley, J.T.: Deep learning for
healthcare: review, opportunities and challenges.

</span>
<span class="ltx_bibblock">Briefings in bioinformatics <span id="bib.bib64.1.1" class="ltx_text ltx_font_bold">19</span>(6), 1236â€“1246 (2018)

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(65)</span>
<span class="ltx_bibblock">
Mohri, M., Sivek, G., Suresh, A.T.: Agnostic federated learning.

</span>
<span class="ltx_bibblock">In: K.Â Chaudhuri, R.Â Salakhutdinov (eds.) Proceedings of the 36th
International Conference on Machine Learning, <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine
Learning Research</em>, vol.Â 97, pp. 4615â€“4625. PMLR, Long Beach, California,
USA (2019)

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(66)</span>
<span class="ltx_bibblock">
Mukherjee, R., Jaffe, H.: System and method for dynamic context-sensitive
federated search of multiple information repositories (2005).

</span>
<span class="ltx_bibblock">US Patent App. 10/743,196

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(67)</span>
<span class="ltx_bibblock">
Nishio, T., Yonetani, R.: Client selection for federated learning with
heterogeneous resources in mobile edge.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1804.08333 (2018)

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(68)</span>
<span class="ltx_bibblock">
Obermeyer, Z., Powers, B., Vogeli, C., Mullainathan, S.: Dissecting racial bias
in an algorithm used to manage the health of populations.

</span>
<span class="ltx_bibblock">Science <span id="bib.bib68.1.1" class="ltx_text ltx_font_bold">366</span>(6464), 447â€“453 (2019)

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(69)</span>
<span class="ltx_bibblock">
OpenMined: Pysyft-tensorflow.

</span>
<span class="ltx_bibblock">https://github.com/OpenMined/PySyft-TensorFlow (2019)

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(70)</span>
<span class="ltx_bibblock">
Pathak, M., Rane, S., Raj, B.: Multiparty differential privacy via aggregation
of locally trained classifiers.

</span>
<span class="ltx_bibblock">In: Advances in Neural Information Processing Systems, pp. 1876â€“1884
(2010)

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(71)</span>
<span class="ltx_bibblock">
Perez, M.V., Mahaffey, K.W., Hedlin, H., Rumsfeld, J.S., Garcia, A., Ferris,
T., Balasubramanian, V., Russo, A.M., Rajmane, A., Cheung, L., etÂ al.:
Large-scale assessment of a smartwatch to identify atrial fibrillation.

</span>
<span class="ltx_bibblock">New England Journal of Medicine <span id="bib.bib71.1.1" class="ltx_text ltx_font_bold">381</span>(20), 1909â€“1917 (2019)

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(72)</span>
<span class="ltx_bibblock">
Pfohl, S.R., Dai, A.M., Heller, K.: Federated and differentially private
learning for electronic health records.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1911.05861 (2019)

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(73)</span>
<span class="ltx_bibblock">
Pollard, T.J., Johnson, A.E., Raffa, J.D., Celi, L.A., Mark, R.G., Badawi, O.:
The eicu collaborative research database, a freely available multi-center
database for critical care research.

</span>
<span class="ltx_bibblock">Scientific data <span id="bib.bib73.1.1" class="ltx_text ltx_font_bold">5</span>, 180178 (2018)

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(74)</span>
<span class="ltx_bibblock">
Raja, P.V., Sivasankar, E.: Modern framework for distributed healthcare data
analytics based on hadoop.

</span>
<span class="ltx_bibblock">In: Information and Communication Technology-EurAsia Conference, pp.
348â€“355. Springer (2014)

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(75)</span>
<span class="ltx_bibblock">
Rehak, D., Dodds, P., Lannom, L.: A model and infrastructure for federated
learning content repositories.

</span>
<span class="ltx_bibblock">In: Interoperability of Web-Based Educational Systems Workshop, vol.
143. Citeseer (2005)

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(76)</span>
<span class="ltx_bibblock">
Ren, J., Yu, G., Ding, G.: Accelerating dnn training in wireless federated edge
learning system.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1905.09712 (2019)

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(77)</span>
<span class="ltx_bibblock">
Roy, A.G., Siddiqui, S., PÃ¶lsterl, S., Navab, N., Wachinger, C.:
Braintorrent: A peer-to-peer environment for decentralized federated
learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1905.06731 (2019)

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(78)</span>
<span class="ltx_bibblock">
Rubinstein, B.I., Bartlett, P.L., Huang, L., Taft, N.: Learning in a large
function space: Privacy-preserving mechanisms for svm learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:0911.5708 (2009)

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(79)</span>
<span class="ltx_bibblock">
Ryffel, T., Trask, A., Dahl, M., Wagner, B., Mancuso, J., Rueckert, D.,
Passerat-Palmbach, J.: A generic framework for privacy preserving deep
learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1811.04017 (2018)

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(80)</span>
<span class="ltx_bibblock">
Samarakoon, S., Bennis, M., Saad, W., Debbah, M.: Federated learning for
ultra-reliable low-latency v2v communications.

</span>
<span class="ltx_bibblock">In: 2018 IEEE Global Communications Conference (GLOBECOM), pp. 1â€“7.
IEEE (2018)

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(81)</span>
<span class="ltx_bibblock">
Sattler, F., Wiedemann, S., MÃ¼ller, K.R., Samek, W.: Robust and
communication-efficient federated learning from non-iid data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1903.02891 (2019)

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(82)</span>
<span class="ltx_bibblock">
Sharma, P., Shamout, F.E., Clifton, D.A.: Preserving patient privacy while
training a predictive model of in-hospital mortality.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1912.00354 (2019)

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(83)</span>
<span class="ltx_bibblock">
Shayan, M., Fung, C., Yoon, C.J., Beschastnikh, I.: Biscotti: A ledger for
private and secure peer-to-peer machine learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1811.09904 (2018)

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(84)</span>
<span class="ltx_bibblock">
Shokri, R., Shmatikov, V.: Privacy-preserving deep learning.

</span>
<span class="ltx_bibblock">In: Proceedings of the 22nd ACM SIGSAC conference on computer and
communications security, pp. 1310â€“1321. ACM (2015)

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(85)</span>
<span class="ltx_bibblock">
Silva, S., Gutman, B., Romero, E., Thompson, P.M., Altmann, A., Lorenzi, M.:
Federated learning in distributed medical databases: Meta-analysis of
large-scale subcortical brain data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1810.08553 (2018)

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(86)</span>
<span class="ltx_bibblock">
Sim, K.C., Zadrazil, P., Beaufays, F.: An investigation into on-device
personalization of end-to-end automatic speech recognition models.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1909.06678 (2019)

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(87)</span>
<span class="ltx_bibblock">
Smith, V., Chiang, C.K., Sanjabi, M., Talwalkar, A.S.: Federated multi-task
learning.

</span>
<span class="ltx_bibblock">In: Advances in Neural Information Processing Systems, pp. 4424â€“4434
(2017)

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(88)</span>
<span class="ltx_bibblock">
Such, J.M., Criado, N.: Multiparty privacy in social media.

</span>
<span class="ltx_bibblock">Commun. ACM <span id="bib.bib88.1.1" class="ltx_text ltx_font_bold">61</span>(8), 74â€“81 (2018)

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(89)</span>
<span class="ltx_bibblock">
Thomas, K., Grier, C., Nicol, D.M.: unfriendly: Multi-party privacy risks in
social networks.

</span>
<span class="ltx_bibblock">In: International Symposium on Privacy Enhancing Technologies
Symposium, pp. 236â€“252. Springer (2010)

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(90)</span>
<span class="ltx_bibblock">
Truex, S., Baracaldo, N., Anwar, A., Steinke, T., Ludwig, H., Zhang, R.: A
hybrid approach to privacy-preserving federated learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1812.03224 (2018)

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(91)</span>
<span class="ltx_bibblock">
VanÂ Hasselt, H., Guez, A., Silver, D.: Deep reinforcement learning with double
q-learning.

</span>
<span class="ltx_bibblock">In: Thirtieth AAAI conference on artificial intelligence (2016)

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(92)</span>
<span class="ltx_bibblock">
Wah, C., Branson, S., Welinder, P., Perona, P., Belongie, S.: The caltech-ucsd
birds-200-2011 dataset (2011)

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(93)</span>
<span class="ltx_bibblock">
Wang, F., Preininger, A.: Ai in health: State of the art, challenges, and
future directions.

</span>
<span class="ltx_bibblock">Yearbook of medical informatics <span id="bib.bib93.1.1" class="ltx_text ltx_font_bold">28</span>(01), 016â€“026 (2019)

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(94)</span>
<span class="ltx_bibblock">
Wang, X., Han, Y., Wang, C., Zhao, Q., Chen, X., Chen, M.: In-edge ai:
Intelligentizing mobile edge computing, caching and communication by
federated learning.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1809.07857 (2018)

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(95)</span>
<span class="ltx_bibblock">
Xu, J., Wang, F.: Federated learning for healthcare informatics.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1911.06270 (2019)

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(96)</span>
<span class="ltx_bibblock">
Xu, J., Xu, Z., Walker, P., Wang, F.: Federated patient hashing.

</span>
<span class="ltx_bibblock">In: AAAI, pp. 6486â€“6493 (2020)

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(97)</span>
<span class="ltx_bibblock">
Yang, Q., Liu, Y., Chen, T., Tong, Y.: Federated machine learning: Concept and
applications.

</span>
<span class="ltx_bibblock">ACM Trans. Intell. Syst. Technol. <span id="bib.bib97.1.1" class="ltx_text ltx_font_bold">10</span>(2), 12:1â€“12:19 (2019).

</span>
<span class="ltx_bibblock">DOIÂ 10.1145/3298981.

</span>
<span class="ltx_bibblock">URL http://doi.acm.org/10.1145/3298981

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(98)</span>
<span class="ltx_bibblock">
Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V.: Federated learning
with non-iid data.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1806.00582 (2018)

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(99)</span>
<span class="ltx_bibblock">
Zhao, Y., Zhao, J., Jiang, L., Tan, R., Niyato, D.: Mobile edge computing,
blockchain and reputation-based crowdsourcing iot federated learning: A
secure, decentralized and privacy-preserving system.

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1906.10893 (2019)

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(100)</span>
<span class="ltx_bibblock">
Zhu, H., Jin, Y.: Multi-objective evolutionary federated learning.

</span>
<span class="ltx_bibblock">IEEE transactions on neural networks and learning systems (2019)

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(101)</span>
<span class="ltx_bibblock">
Zhuo, H.H., Feng, W., Xu, Q., Yang, Q., Lin, Y.: Federated reinforcement
learning.

</span>
<span class="ltx_bibblock">rXiv preprint arXiv:1901.08277 (2019)

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1911.06269" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1911.06270" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1911.06270">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1911.06270" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1911.06271" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 17 09:46:19 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
