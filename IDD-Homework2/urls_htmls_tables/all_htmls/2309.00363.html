<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.00363] FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning</title><meta property="og:description" content="Large language models (LLMs) have demonstrated great capabilities in various natural language understanding and generation tasks.
Platforms such as Hugging Face facilitate access and utilization of the pre-trained LLMs…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.00363">

<!--Generated on Wed Feb 28 05:41:35 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FederatedScope-LLM: 
<br class="ltx_break">A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
​Weirui Kuang  , Bingchen Qian<sup id="id2.2.id1" class="ltx_sup">∗</sup>, Zitao Li, Daoyuan Chen, Dawei Gao, Xuchen Pan, Yuexiang Xie,
<br class="ltx_break"><span id="id3.3.id2" class="ltx_ERROR undefined">\AND</span> Yaliang Li  , Bolin Ding, Jingren Zhou
<br class="ltx_break">
<br class="ltx_break"> Alibaba Group
</span><span class="ltx_author_notes">Co-first authors.Corresponding author, email: yaliang.li@alibaba-inc.com</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Large language models (LLMs) have demonstrated great capabilities in various natural language understanding and generation tasks.
Platforms such as Hugging Face facilitate access and utilization of the pre-trained LLMs for different entities, ranging from computer science researchers to users with little machine learning background.
Different entities can further improve the performance of those LLMs on their specific downstream tasks by fine-tuning LLMs.
When several entities have similar interested tasks, but their local data cannot be shared directly because of privacy concerns regulations, federated learning (FL) is a mainstream solution to leverage the data of different entities.
Besides avoiding direct data sharing, FL can also achieve rigorous data privacy protection, model intelligent property protection, and model customization via composition with different techniques.
However, fine-tuning LLMs in federated learning settings still lacks adequate support from the existing FL frameworks because it has to deal with optimizing the consumption of significant communication and computational resources, various data preparation for different tasks, and distinct information protection demands.
This paper first discusses these challenges of federated fine-tuning LLMs in detail, and introduces
our implemented package <span id="id4.id1.1" class="ltx_text ltx_font_bold">F</span>ederated<span id="id4.id1.2" class="ltx_text ltx_font_bold">S</span>cope-<span id="id4.id1.3" class="ltx_text ltx_font_bold">LLM</span> (<span id="id4.id1.4" class="ltx_text ltx_font_smallcaps">FS-LLM</span>) as a main contribution, which consists of the following components:
(1) we build a complete end-to-end benchmarking pipeline, automizing the processes of dataset preprocessing, federated fine-tuning execution or simulation, and performance evaluation on federated LLM fine-tuning with different capability demonstration purposes;
(2) we provide comprehensive and off-the-shelf federated parameter-efficient fine-tuning (PEFT) algorithm implementations and versatile programming interfaces for future extension to enhance the capabilities of LLMs in FL scenarios with low communication and computation costs, even without accessing the full model (e.g., closed-source LLMs);
(3) we adopt several accelerating operators and resource-efficient operators for fine-tuning LLMs with limited resources and the flexible pluggable sub-routines for interdisciplinary study (e.g., LLMs in personalized FL).
We conduct extensive and reproducible experiments to validate the effectiveness of <span id="id4.id1.5" class="ltx_text ltx_font_smallcaps">FS-LLM</span> and benchmark advanced LLMs with state-of-the-art parameter-efficient fine-tuning algorithms in a federated setting, which also yields many valuable insights into federated fine-tuning LLMs for the research community.
To facilitate further research and adoption, we release <span id="id4.id1.6" class="ltx_text ltx_font_smallcaps">FS-LLM</span> at <a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/llm" title="" class="ltx_ref ltx_href">https://github.com/alibaba/FederatedScope/tree/llm</a>. <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We will continuously update the codebase and arXiv version.</span></span></span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Recent advances in large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a href="#bib.bib80" title="" class="ltx_ref">2023</a>; Brown et al., <a href="#bib.bib8" title="" class="ltx_ref">2020</a>; OpenAI, <a href="#bib.bib60" title="" class="ltx_ref">2023</a>; Zhang et al., <a href="#bib.bib92" title="" class="ltx_ref">2022</a>; Scao et al., <a href="#bib.bib74" title="" class="ltx_ref">2022</a>; Zeng et al., <a href="#bib.bib91" title="" class="ltx_ref">2023</a>; Chowdhery et al., <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite> have enabled a wide range of real-world applications across various domains, such as chatbots (i.e., ChatGPT<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://openai.com/blog/chatgpt</span></span></span>), writing assistants <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>; Ippolito et al., <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>, search engines (i.e., New Bing<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://www.bing.com/new</span></span></span>), tool/API retriever <cite class="ltx_cite ltx_citemacro_citep">(Qin et al., <a href="#bib.bib67" title="" class="ltx_ref">2023</a>; Patil et al., <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite> and multimodal systems <cite class="ltx_cite ltx_citemacro_citep">(Driess et al., <a href="#bib.bib26" title="" class="ltx_ref">2023</a>; Huang et al., <a href="#bib.bib34" title="" class="ltx_ref">2023</a>; Wu et al., <a href="#bib.bib85" title="" class="ltx_ref">2023</a>)</cite>.
Compared to previous pre-trained language models <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a href="#bib.bib24" title="" class="ltx_ref">2019</a>; Liu et al., <a href="#bib.bib52" title="" class="ltx_ref">2019</a>)</cite>, LLMs exhibit remarkable emergent abilities that have not been observed before <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a href="#bib.bib94" title="" class="ltx_ref">2023</a>)</cite>.
These emergent abilities of LLMs are the cores of the unprecedented proficiency and efficiency of AI systems built on top of them.
Consequently, both academic and industrial people have demonstrated a keen interest in investigating the potentialities of LLMs.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">When applying LLMs in practical applications, such as education, law, and medicine, fine-tuning LLMs with domain-specific data can be essential.
Fine-tuning can enrich LLMs with domain knowledge, enhance their specific ability, improve the fairness and reliability of the outputs, and prevent certain damage caused by hallucination <cite class="ltx_cite ltx_citemacro_citep">(Ji et al., <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite>.
However, fine-tuning LLMs entails a high demand for computational resources and a substantial amount of domain data that may not be sharable due to privacy concerns.
The former challenge can be addressed by recent works <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Li &amp; Liang, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>; Liu et al., <a href="#bib.bib50" title="" class="ltx_ref">2021a</a>; <a href="#bib.bib51" title="" class="ltx_ref">b</a>; Lester et al., <a href="#bib.bib45" title="" class="ltx_ref">2021</a>; Houlsby et al., <a href="#bib.bib32" title="" class="ltx_ref">2019</a>; Karimi Mahabadi et al., <a href="#bib.bib39" title="" class="ltx_ref">2021</a>; Pfeiffer et al., <a href="#bib.bib64" title="" class="ltx_ref">2020a</a>; <a href="#bib.bib66" title="" class="ltx_ref">c</a>)</cite>, which adapt pre-trained LLMs to specific domains by tuning modules with limited trainable parameters (denoted as <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">adapters</em>).
For the latter issue, one of the feasible solutions is federated learning (FL) <cite class="ltx_cite ltx_citemacro_citep">(Konečný et al., <a href="#bib.bib41" title="" class="ltx_ref">2016</a>; McMahan et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>; Yang et al., <a href="#bib.bib89" title="" class="ltx_ref">2019</a>)</cite>, a distributed learning paradigm that allows multiple entities to optimize a model collaboratively without directly sharing their data.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Although the existing FL frameworks <cite class="ltx_cite ltx_citemacro_citep">(Bonawitz et al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>; Ryffel et al., <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite> can usually support various machine learning models,
the development of federated fine-tuning on LLM is still in a premature stage because of the following <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">gaps</span> in existing work.
<span id="S1.p3.1.2" class="ltx_text ltx_font_bold">(i)</span> No existing FL package contains comprehensive and efficient implementations of LLM fine-tuning algorithms and a standardized benchmark for comparing the model performance, communication cost, and computation overhead when federated fine-tuning LLMs.
<span id="S1.p3.1.3" class="ltx_text ltx_font_bold">(ii)</span> Fine-tuning LLMs in FL is still computationally expensive on the client side, even with the parameter-efficient fine-tuning (PEFT) algorithms.
<span id="S1.p3.1.4" class="ltx_text ltx_font_bold">(iii)</span>
Because pre-trained LLMs are of great intelligent property value and may not belong to clients, it might be necessary to let clients conduct federated fine-tuning without accessing the full model (e.g., closed-source LLMs).
<span id="S1.p3.1.5" class="ltx_text ltx_font_bold">(iv)</span>
It is unclear whether the existing algorithms for solving advanced FL problems, such as personalized FL (pFL) <cite class="ltx_cite ltx_citemacro_citep">(Tan et al., <a href="#bib.bib78" title="" class="ltx_ref">2022</a>; Chen et al., <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite> and federated hyperparameter optimization (FedHPO) <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite>, are still effective with different federated fine-tuning algorithms for LLMs.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We aim to bridge the aforementioned gaps and further promote the study of fine-tuning LLMs in the context of federated learning. Thus, we build up a novel open-source package for fine-tuning LLMs via federated learning, called <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">F</span>ederated<span id="S1.p4.1.2" class="ltx_text ltx_font_bold">S</span>cope-<span id="S1.p4.1.3" class="ltx_text ltx_font_bold">LLM</span> (<span id="S1.p4.1.4" class="ltx_text ltx_font_smallcaps">FS-LLM</span>), on top of FederatedScope (FS) <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a href="#bib.bib88" title="" class="ltx_ref">2023</a>)</cite>.
Our contributions can be summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> packages a collection of diverse federated fine-tuning datasets from various domains with tunable levels of heterogeneity and a suite of corresponding evaluation tasks to form a complete pipeline to benchmark federated fine-tuning LLMs algorithms in FL scenarios.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> provides comprehensive federated fine-tuning algorithms for LLMs with low communication and computation costs and versatile programming interfaces, which support both scenarios where clients can or cannot access the full model.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> is equipped with an optimized federated fine-tuning training paradigm for LLMs towards customizable efficiency-boosting (e.g., memory consumption reduction and multi-GPU parallelism) and interdisciplinary research potentials (e.g., pFL and FedHPO).</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i4.p1.1" class="ltx_p">We perform extensive experiments based on <span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> and investigate the empirical performances of federated fine-tuned LLMs.
Based on our observations, we point out the challenges for federated fine-tuning LLMs and offer insights for future research in this emerging field.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2309.00363/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="401" height="297" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the architecture of <span id="S1.F1.5.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>, which consists of three main modules: <span id="S1.F1.6.2" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span>, <span id="S1.F1.7.3" class="ltx_text ltx_font_smallcaps">LLM-AlgZoo</span>, and <span id="S1.F1.8.4" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span>. As an example in the figure, we use the PEFT algorithms to fine-tune LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a href="#bib.bib80" title="" class="ltx_ref">2023</a>)</cite> in FL, with half-precision <cite class="ltx_cite ltx_citemacro_citep">(Micikevicius et al., <a href="#bib.bib56" title="" class="ltx_ref">2018</a>)</cite> training and offloading <cite class="ltx_cite ltx_citemacro_citep">(Ren et al., <a href="#bib.bib71" title="" class="ltx_ref">2021</a>)</cite> strategy and pFedMe <cite class="ltx_cite ltx_citemacro_citep">(T Dinh et al., <a href="#bib.bib77" title="" class="ltx_ref">2020</a>)</cite> algorithm. Under this learning paradigm, the clients can efficiently train on their local data with limited hardware resources, while the communication between the clients and the server only requires transmitting the adapter (which typically has very few parameters). This achieves high efficiency in both communication and computation. In the figure, Acc. stands for accelerating operator, Perf. stands for performance, Comm. stands for communication, Comp. stands for computation, and Fair. stands for fairness.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Overview</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">In Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we illustrate the overall architecture of <span id="S2.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> using a concrete example.
As mentioned above, <span id="S2.p1.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span> is built upon FS <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a href="#bib.bib88" title="" class="ltx_ref">2023</a>)</cite>, an easy-to-use platform that provides essential modules for constructing FL courses (e.g., communication modules, aggregation strategies, and training functionality interfaces), rich extended functionality, and plenty of instantiated FL algorithms.
On top of FS, we develop three enrichments to address the gaps mentioned in Section <a href="#S1" title="1 Introduction ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and facilitate fine-tuning LLMs in the federated setting: <span id="S2.p1.1.3" class="ltx_text ltx_font_bold ltx_font_smallcaps">LLM-Benchmarks</span>, <span id="S2.p1.1.4" class="ltx_text ltx_font_bold ltx_font_smallcaps">LLM-AlgZoo</span>, and <span id="S2.p1.1.5" class="ltx_text ltx_font_bold ltx_font_smallcaps">LLM-Trainer</span>.
With these new modules, <span id="S2.p1.1.6" class="ltx_text ltx_font_smallcaps">FS-LLM</span> supports end-to-end federated fine-tuning for LLMs, providing (1) data preparation for fine-tuning and evaluation, (2) several out-of-the-box popular fine-tuning algorithms and unified and flexible programming interfaces, (3) various accelerating and resource-efficient operators and flexible pluggable sub-routines for interdisciplinary study.
We present an overview in this section and give detailed descriptions of these modules in Section <a href="#S3" title="3 LLM-Benchmarks: A Complete Pipeline for Benchmarking ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S4" title="4 LLM-AlgZoo: A Collection of Fine-tuning Algorithms ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and <a href="#S5" title="5 LLM-Trainer: Training Operators and Paradigm ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, respectively.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">To consolidate the implementations and facilitate the FL research about LLMs, one of the critical steps is to construct a module with an end-to-end benchmarking pipeline, i.e., <span id="S2.p2.1.1" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span> in <span id="S2.p2.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span>.
We assemble various corpus datasets from different domains for fine-tuning and pair each of them with one specific relevant evaluation task to assess the performance of the fine-tuned LLMs on different domains.
For the datasets prepared for fine-tuning, we partition them according to their meta-information, formulating them into federated versions.
Meanwhile, <span id="S2.p2.1.3" class="ltx_text ltx_font_smallcaps">FS-LLM</span> offers <span id="S2.p2.1.4" class="ltx_text ltx_font_italic">Splitter</span> to split centralized datasets, enhancing the extensibility of the fine-tuning dataset for federated fine-tuning LLMs.
Furthermore, we provide a rich set of docker images where the runtime environment of the evaluation tasks has been prepared.
<span id="S2.p2.1.5" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span> enables users to conveniently compare the effectiveness of different fine-tuning algorithms in various FL scenarios.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">Another important and helpful component provided in <span id="S2.p3.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>, <span id="S2.p3.1.2" class="ltx_text ltx_font_smallcaps">LLM-AlgZoo</span>, includes a collection of fine-tuning algorithms tailored for FL.
As communication and computation resources of clients are usually limited in FL, we leverage and integrate several PEFT algorithms into the FL setting, such as LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, prefix-tuning <cite class="ltx_cite ltx_citemacro_citep">(Li &amp; Liang, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>)</cite>, P-tuning <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib51" title="" class="ltx_ref">2021b</a>)</cite>, and prompt tuning <cite class="ltx_cite ltx_citemacro_citep">(Lester et al., <a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite>.
Compared to full-parameter fine-tuning, these PEFT algorithms significantly reduce memory consumption, training time, and communication cost for fine-tuning LLMs.
Besides, motivated by the practical concerns on intelligent property protection of LLMs, we also integrate a privacy-preserving fine-tuning algorithm, offsite-tuning <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a href="#bib.bib87" title="" class="ltx_ref">2023</a>)</cite>, for the scenario where clients only tune small adapters based on a distilled model from a full LLM.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">Based on the fine-tuning algorithms mentioned above (i.e., the PEFT algorithms and offsite-tuning), <span id="S2.p4.1.1" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span> powers the FL fine-tuning process by adopting a hook-like training scheme.
Though these algorithms fine-tune a small number of parameters of LLMs, they can still be computationally expensive for some clients.
Therefore, <span id="S2.p4.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span> incorporates various accelerating operators and resource-efficient operators as hook-like functions, such as DeepSpeed’s ZeRO <cite class="ltx_cite ltx_citemacro_citep">(Rasley et al., <a href="#bib.bib70" title="" class="ltx_ref">2020</a>)</cite>, Pytorch’s data parallelism <cite class="ltx_cite ltx_citemacro_citep">(Paszke et al., <a href="#bib.bib61" title="" class="ltx_ref">2019</a>)</cite>, and model quantization <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib93" title="" class="ltx_ref">2019</a>)</cite>, to accelerate the local fine-tuning process and enable <span id="S2.p4.1.3" class="ltx_text ltx_font_smallcaps">FS-LLM</span> to work efficiently on consumer-level GPUs.
Besides, <span id="S2.p4.1.4" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span>, with the help of its customizable hook-like programming interfaces, can be quickly and seamlessly integrated with existing plug-ins in FS for interdisciplinary studies, such as pFL <cite class="ltx_cite ltx_citemacro_citep">(Tan et al., <a href="#bib.bib78" title="" class="ltx_ref">2022</a>)</cite> and FedHPO <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite>, which could be a promising direction for further research.
For meeting different hardware settings or research goals, <span id="S2.p4.1.5" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span> enables <span id="S2.p4.1.6" class="ltx_text ltx_font_smallcaps">FS-LLM</span> to fine-tune LLMs in simulated mode (single-machine FL for simulation, all clients in one machine), distributed mode (multi-machine FL, one client per machine), and clustered mode (multi-machine FL, one client per cluster).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span>: A Complete Pipeline for Benchmarking</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">As gap <span id="S3.p1.1.1" class="ltx_text ltx_font_bold">(i)</span> mentioned in Section <a href="#S1" title="1 Introduction ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, there has yet to be a consensus in the academic community or industry on how to fairly evaluate the LLM fine-tuning algorithms in FL and what baselines are to compare.
Therefore, we introduce <span id="S3.p1.1.2" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span>, the first convenient and fair module to evaluate federated LLM fine-tuning.
<span id="S3.p1.1.3" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span> covers a complete benchmarking pipeline, consisting of stages from the construction of fine-tuning datasets to the evaluation with a collection of tasks.
To facilitate replication and validation, we offer a series of look-up tables containing benchmark results for the fine-tuning datasets and their corresponding evaluation tasks.
Additionally, we containerize the runtime environment of the evaluation for conveniently benchmarking the performance of the federated fine-tuned LLMs.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Federated fine-tuning dataset construction</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">Unlike pre-training from scratch, fine-tuning LLMs is typically for adapting pre-trained LLMs to one specific domain, which can be very diverse, such as code generation and mathematical reasoning.
Additionally, as considered in existing FL literature, the local datasets held by individual clients can exhibit varying degrees of heterogeneity, even within the same domain.
For instance, although a set of clients share a common interest in fine-tuning an LLM for code generation, the code base of some clients may mainly consist of Jave, while the code bases of other clients may contain a substantial portion of Python.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p">To echo the diversity of target domains and the heterogeneity of data in real-world FL scenarios, we curate three fine-tuning datasets in <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span>. They cover a wide range of domains and exhibit realistic data distributions across different clients.
(1) <span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span> is built from CodeAlpaca <cite class="ltx_cite ltx_citemacro_citep">(Chaudhary, <a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite> to enhance LLMs’ code generation capability.
It simulates a <em id="S3.SS1.p2.1.3" class="ltx_emph ltx_font_italic">nine</em>-client FL scenario.
Each client’s dataset consists of coding exercises with answers limited to <em id="S3.SS1.p2.1.4" class="ltx_emph ltx_font_italic">one</em> specific programming language, such as Java or Python.
(2) <span id="S3.SS1.p2.1.5" class="ltx_text ltx_font_italic">Fed-Dolly</span> is for enhancing the capability of LLMs for generic language. We partition Databricks-dolly-15k <cite class="ltx_cite ltx_citemacro_citep">(Conover et al., <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> into <em id="S3.SS1.p2.1.6" class="ltx_emph ltx_font_italic">eight</em> clients’ local datasets.
Each client’s dataset consists of a series of high-quality human-generated question-response pairs but is limited to <em id="S3.SS1.p2.1.7" class="ltx_emph ltx_font_italic">one</em> specific NLP task, such as information extraction or QA.
(3) <span id="S3.SS1.p2.1.8" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span> is curated into <em id="S3.SS1.p2.1.9" class="ltx_emph ltx_font_italic">three</em> subsets from the train split in <span id="S3.SS1.p2.1.10" class="ltx_text ltx_font_italic">GSM8K</span> <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>, aiming to enhance the capability of LLMs for the chain of thought (CoT).
Each client’s dataset consists of grade school math questions randomly partitioned from the original dataset.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p">It is worth noting that, in addition to the built-in datasets mentioned above, we provide splitters for partitioning the centralized dataset into a federated version based on different meta-information or with different heterogeneity degrees among clients.
For example, users can apply different splitters to a centralized dataset, such as the uniform splitter, Dirichlet splitter, or meta-information splitter, to construct fine-tuning datasets that mirror the heterogeneity inherent in different FL scenarios.
We provide several built-in datasets for these splitters, such as <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_italic">Alpaca</span> <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite>, <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_italic">cleanedAlpaca</span> <cite class="ltx_cite ltx_citemacro_citep">(Ruebsamen, <a href="#bib.bib72" title="" class="ltx_ref">2023</a>)</cite>, etc.
For more details about the provided fine-tuning datasets, please refer to Appendix <a href="#A1.SS1" title="A.1 Fine-tuning Dataset description ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Federated fine-tuning dataset and its corresponding evaluation task.</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_top ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S3.T1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.1" class="ltx_p" style="width:93.9pt;">Fine-tuning Dataset</span>
</span>
</td>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.1.1" class="ltx_p" style="width:190.6pt;">Goal of Evaluation Task</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.2" class="ltx_tr">
<td id="S3.T1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.1.1.1" class="ltx_p" style="width:76.8pt;"><span id="S3.T1.1.2.1.1.1.1" class="ltx_text"></span> <span id="S3.T1.1.2.1.1.1.2" class="ltx_text">
<span id="S3.T1.1.2.1.1.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S3.T1.1.2.1.1.1.2.1.1" class="ltx_tr">
<span id="S3.T1.1.2.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T1.1.2.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span></span></span>
<span id="S3.T1.1.2.1.1.1.2.1.2" class="ltx_tr">
<span id="S3.T1.1.2.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">&amp;</span></span>
<span id="S3.T1.1.2.1.1.1.2.1.3" class="ltx_tr">
<span id="S3.T1.1.2.1.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T1.1.2.1.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">HumanEval</span></span></span>
</span></span><span id="S3.T1.1.2.1.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="S3.T1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.2.1.1" class="ltx_p" style="width:93.9pt;">Coding exercises with different programming languages</span>
</span>
</td>
<td id="S3.T1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.2.3.1.1" class="ltx_p" style="width:190.6pt;">How much can a federated fine-tuning algorithm improve the performance of an LLM with heterogeneous data on an in-domain task (coding)?</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.3" class="ltx_tr">
<td id="S3.T1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.1.1.1" class="ltx_p" style="width:76.8pt;"><span id="S3.T1.1.3.1.1.1.1" class="ltx_text"></span> <span id="S3.T1.1.3.1.1.1.2" class="ltx_text">
<span id="S3.T1.1.3.1.1.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S3.T1.1.3.1.1.1.2.1.1" class="ltx_tr">
<span id="S3.T1.1.3.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T1.1.3.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Fed-Dolly</span></span></span>
<span id="S3.T1.1.3.1.1.1.2.1.2" class="ltx_tr">
<span id="S3.T1.1.3.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">&amp;</span></span>
<span id="S3.T1.1.3.1.1.1.2.1.3" class="ltx_tr">
<span id="S3.T1.1.3.1.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T1.1.3.1.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">HELM</span></span></span>
</span></span><span id="S3.T1.1.3.1.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="S3.T1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.2.1.1" class="ltx_p" style="width:93.9pt;">Human-generated question-response pairs with different types</span>
</span>
</td>
<td id="S3.T1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.3.3.1.1" class="ltx_p" style="width:190.6pt;">How much can a federated fine-tuning algorithm improve the performance of an LLM with heterogeneous data on generic language capabilities?</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.4" class="ltx_tr">
<td id="S3.T1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.1.1.1" class="ltx_p" style="width:76.8pt;"><span id="S3.T1.1.4.1.1.1.1" class="ltx_text"></span> <span id="S3.T1.1.4.1.1.1.2" class="ltx_text">
<span id="S3.T1.1.4.1.1.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S3.T1.1.4.1.1.1.2.1.1" class="ltx_tr">
<span id="S3.T1.1.4.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T1.1.4.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span></span></span>
<span id="S3.T1.1.4.1.1.1.2.1.2" class="ltx_tr">
<span id="S3.T1.1.4.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">&amp;</span></span>
<span id="S3.T1.1.4.1.1.1.2.1.3" class="ltx_tr">
<span id="S3.T1.1.4.1.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="S3.T1.1.4.1.1.1.2.1.3.1.1" class="ltx_text ltx_font_italic">GSM8K-test</span></span></span>
</span></span><span id="S3.T1.1.4.1.1.1.3" class="ltx_text"></span></span>
</span>
</td>
<td id="S3.T1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.2.1.1" class="ltx_p" style="width:93.9pt;">Math questions with independent and homogeneous distribution</span>
</span>
</td>
<td id="S3.T1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S3.T1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.4.3.1.1" class="ltx_p" style="width:190.6pt;">How much can a federated fine-tuning algorithm improve the performance of an LLM with i.i.d. data on an in-domain task (CoT)?</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Federated LLM fine-tuning evaluation</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">LLMs are known to be very powerful, but it is challenging to evaluate their capabilities by a single metric.
To the best of our knowledge, there are no ready-to-use evaluation tools for assessing federated LLM fine-tuning (let alone with the personalized FL algorithms) in terms of accuracy and efficiency.
To fulfill such a gap, in <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span>, we provide a complete benchmarking pipeline to assess LLM fine-tuning in various FL scenarios.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p">We argue that fine-tuning should aim to enhance one of the two aspects of LLMs: either to improve their generic language capabilities or to improve their domain-specific capabilities for one particular downstream task.
Therefore, we curate three evaluation datasets from different subject areas, including
<span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_italic">HumanEval</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite> for the code generation, <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_italic">HELM</span> <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite> for the generic language capabilities,
and <span id="S3.SS2.p2.1.3" class="ltx_text ltx_font_italic">GSM8K-test</span> <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> (the test split in <span id="S3.SS2.p2.1.4" class="ltx_text ltx_font_italic">GSM8K</span>) for CoT.
Given that different datasets employ different default evaluation metrics, for simplicity, we introduce the term <em id="S3.SS2.p2.1.5" class="ltx_emph ltx_font_italic">evaluation score</em> as a unifying descriptor for the evaluated results obtained on these datasets with their metrics.
Specifically, the evaluation score represents Pass@1 score when using <span id="S3.SS2.p2.1.6" class="ltx_text ltx_font_italic">HumanEval</span>, a mixture of metric scores on 16 subtasks when evaluating on <span id="S3.SS2.p2.1.7" class="ltx_text ltx_font_italic">HELM<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">4</span></span><span id="footnote4.5" class="ltx_text ltx_font_upright">Because evaluation on 16 subtasks is time-consuming, we also curate a smaller </span><span id="footnote4.6" class="ltx_text">HELM-MINI</span><span id="footnote4.7" class="ltx_text ltx_font_upright"> with 4 subtasks but consistent performance with original </span><span id="footnote4.8" class="ltx_text">HELM</span><span id="footnote4.9" class="ltx_text ltx_font_upright"> for a brief evaluation. </span></span></span></span></span>, and accuracy when utilizing <span id="S3.SS2.p2.1.8" class="ltx_text ltx_font_italic">GSM8K-test</span>.
And more details can be found in Appendix <a href="#A1.SS2" title="A.2 Evaluation task description ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p">Then, we define evaluating an LLM on a specific dataset and generating the corresponding evaluation score as an <em id="S3.SS2.p3.1.1" class="ltx_emph ltx_font_italic">evaluation task</em>.
We combine each fine-tuning dataset mentioned in Section <a href="#S3.SS1" title="3.1 Federated fine-tuning dataset construction ‣ 3 LLM-Benchmarks: A Complete Pipeline for Benchmarking ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> with one specific evaluation task, which allows users to fairly assess the improvement of fine-tuned LLMs in FL.
The fine-tuning dataset, the corresponding evaluation task, and the goal of the evaluation task are listed in Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Federated fine-tuning dataset construction ‣ 3 LLM-Benchmarks: A Complete Pipeline for Benchmarking ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Note that there is generally a distribution shift between the fine-tuning and evaluation datasets, making it much more challenging than those in other domains of FL <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib9" title="" class="ltx_ref">2018</a>; Dong et al., <a href="#bib.bib25" title="" class="ltx_ref">2022</a>; Wang et al., <a href="#bib.bib81" title="" class="ltx_ref">2022</a>)</cite>.
To ensure the consistency of the evaluation results, we containerize the runtime environment of these evaluation tasks to docker images for conveniently assessing the performance of the federated LLM fine-tuning.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p">Last but not least, we also introduce a rich set of cost-related metrics to measure the efficiency of a federated fine-tuning process, including both computation costs (e.g., GPU usage, computation time, flops count) and communication costs (e.g., message size).
Along with evaluation scores, these metrics could give a comprehensive assessment of the federated fine-tuning process.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">LLM-AlgZoo</span>: A Collection of Fine-tuning Algorithms</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">In addition to the benchmarking module, <span id="S4.p1.1.1" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span>, we implement a set of popular fine-tuning algorithms in <span id="S4.p1.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span> and introduce them as <span id="S4.p1.1.3" class="ltx_text ltx_font_smallcaps">LLM-AlgZoo</span> in this section.
Aiming to fulfill the gaps <span id="S4.p1.1.4" class="ltx_text ltx_font_bold">(i)</span> and <span id="S4.p1.1.5" class="ltx_text ltx_font_bold">(ii)</span>, <span id="S4.p1.1.6" class="ltx_text ltx_font_smallcaps">LLM-AlgZoo</span> first includes a collection of PEFT algorithms to satisfy the constraints on the communication and computation costs in federated fine-tuning when all clients have access to the full model.
However, we also realize that there are cases where the LLM owner may not be willing to share the full model in the federated fine-tuning stage.
Thus, to fulfill gap <span id="S4.p1.1.7" class="ltx_text ltx_font_bold">(iii)</span>, we further adopt a fine-tuning algorithm that does not require full model access in the FL setting.
Notice that all these fine-tuning algorithms are implemented on a set of unified but flexible interfaces, which hides the underlying standard functionalities from algorithm implementors, such as coordinating communication in FL.
The same interfaces can support more diverse fine-tuning algorithms in future development if users follow the same programming paradigm as our implemented algorithms.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Reducing communication and computation costs with PEFT algorithms</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">Achieving communication and computation efficiencies are two major challenges for fine-tuning LLMs in FL.
The communication bottleneck arises from the limited bandwidth of the internet connection between the server and the clients.
This challenge becomes exacerbated when full-parameter fine-tuning LLMs in FL, as they require transmitting more parameters than previous pre-trained language models.
For example, full-parameter fine-tuning LLaMA-7B in FL requires 28GB of message transfer for one communication round from the client to the server. Assuming the network bandwidth is 100MBps, only model uploading and downloading will take about 75 minutes, which is intolerant, especially for clients with limited network bandwidth.
The computation efficiency is the other critical issue for federated fine-tuning LLMs.
For example, full-parameter fine-tuning LLaMA-7B requires about 28GB of GPU memory for the model.
In addition, the SGD optimizer and the gradients need another 92GB of GPU memory, leading to at least 112GB of GPU memory in total - this is unaffordable for most resource-limited entities.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p">We provide a set of implemented PEFT algorithms in <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> as solutions for our users to encounter these challenges, including LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, prefix-tuning <cite class="ltx_cite ltx_citemacro_citep">(Li &amp; Liang, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>)</cite>, P-tuning <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib51" title="" class="ltx_ref">2021b</a>)</cite>, and prompt tuning <cite class="ltx_cite ltx_citemacro_citep">(Lester et al., <a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite>.
These algorithms perform fine-tuning by only training (additional) modules with limited parameters, known as <em id="S4.SS1.p2.1.2" class="ltx_emph ltx_font_italic">adapters</em>, but keep other parameters frozen.
Compared to full-parameter fine-tuning in FL, clients only need to transmit the adapters in each communication round, which reduces the transmission time to tens of seconds or even seconds.
Meanwhile, PEFT algorithms reduce the computation cost and make local training more viable for resource-limited clients.
For example, if we only fine-tune the adapter of LLaMA-7B, the total GPU memory consumption will be a little more than 28GB, and the computation time will be less than that of full-parameter fine-tuning as well.
Thus, based on considerations of communication and computation costs, <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_smallcaps">LLM-AlgZoo</span> adopts PEFT algorithms and makes them considerably more viable for resource-limited entities when federated fine-tuning LLMs.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Federated fine-tuning without accessing full model</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">Many existing LLMs <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib59" title="" class="ltx_ref">2022</a>; <a href="#bib.bib60" title="" class="ltx_ref">2023</a>; Anthropic, <a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite> are closed-source for some reasons such as high training costs, preventing training data leakage, and maintaining commercial secrets.
However, in some commercial scenarios, downstream customers may not be satisfied with simply using APIs to perform inference on these all-around LLMs but also want to customize them more to their domain-specific data.
These domain-specific data are often private, limited, and incomplete, which leads to insufficient adaptation and generalization of LLMs to the customers’ needs.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">To satisfy such practical demand, we adapt a privacy-preserving fine-tuning algorithm, offsite-tuning <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a href="#bib.bib87" title="" class="ltx_ref">2023</a>)</cite>, to a federated version, and name it FedOT for short.
It sends a lossy compressed model with untrainable parameters to the clients as an emulator of the complete LLM at the beginning of FL.
During the FL, the clients fine-tune adapters with the frozen emulator and their domain-specific data.
FedOT safeguards both the intelligent property of the model providers and the data privacy of the clients, while leveraging the distributed data for adapting LLMs to specific domains.
This algorithm can be further integrated with the PEFT algorithms mentioned in Section <a href="#S4.SS1" title="4.1 Reducing communication and computation costs with PEFT algorithms ‣ 4 LLM-AlgZoo: A Collection of Fine-tuning Algorithms ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Extendability by unified interfaces for federated fine-tuning</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p">Notice that the aforementioned federated fine-tuning algorithms, regardless of whether the clients have access to the full model, are all implemented via a set of unified interfaces in <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>.
The interfaces compose a skeleton structure that can be customized to various FL applications.
The interfaces can be invoked with customized functions in different stages, handling the underlying communication and synchronization between the server and clients in FL.
Figure <a href="#S4.F2" title="Figure 2 ‣ 4.3 Extendability by unified interfaces for federated fine-tuning ‣ 4 LLM-AlgZoo: A Collection of Fine-tuning Algorithms ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates some unified interfaces used by fine-tuning algorithms in Section <a href="#S4.SS1" title="4.1 Reducing communication and computation costs with PEFT algorithms ‣ 4 LLM-AlgZoo: A Collection of Fine-tuning Algorithms ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> and <a href="#S4.SS2" title="4.2 Federated fine-tuning without accessing full model ‣ 4 LLM-AlgZoo: A Collection of Fine-tuning Algorithms ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.
The unified interfaces include but are not limited to the model pre-processing interface (arrow ①), initial model broadcast interface (arrow ②), shared parameter aggregation interface (arrow ③), and parameter re-distribution interface (arrow ④).
For closed-source LLMs, which are inaccessible to clients, the model providers can compress the LLM into an emulator by implementing a distillation function with the model pre-processing interface; for open-source LLMs, which are accessible, the pre-processing interface just returns the original LLM.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p">These unified but flexible interfaces are based on the event-driven architecture in FL <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a href="#bib.bib88" title="" class="ltx_ref">2023</a>)</cite>.
In the context of federated LLM fine-tuning, events are the exchanged information (e.g., local updated weights).
Each event has a corresponding handler, which is the actions triggered by it.
The event-driven architecture allows the entities of FL to program their behaviors and react to the events.
Thus, by designing message-handler pairs, users can extend and customize the federated fine-tuning algorithms easily because of the extensibility of <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2309.00363/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="198" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The unified interfaces for federated fine-tuning LLMs with or without accessing the full model.
When the LLM is not accessible to clients, different algorithms can be used to generate an emulator, including distillation, pruning, and quantization via ① LLM model pre-processing interface; if the LLM is accessible, ① just output the input by default.
The other three interfaces in the figure are ② initial model broadcast, ③ shared parameter aggregation, and ④ parameter re-distribution.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span>: Training Operators and Paradigm</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">Although PEFT algorithms can significantly reduce the computation cost, they may still be computationally expensive for some clients with limited resources.
To alleviate such concerns, we provide <span id="S5.p1.1.1" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span>, which is designed to further accelerate computation and save resources during the local training and message transmission stages in FL.
We implement a set of accelerating operators and resource-efficient operators to fulfill gap <span id="S5.p1.1.2" class="ltx_text ltx_font_bold">(ii)</span>.
Moreover, to meet different hardware settings or research goals,
<span id="S5.p1.1.3" class="ltx_text ltx_font_smallcaps">FS-LLM</span> supports simulated mode, distributed mode, and clustered mode.
For simulated mode, all clients run on a single machine to simulate the federated fine-tuning process.
For the distributed mode and clustered mode, each client runs on one or more machines and communicates with the server separately.
These modes share a consistent programming paradigm and behavior.
Meanwhile, we note that there are also advanced FL problems in federated fine-tuning LLMs, such as pFL <cite class="ltx_cite ltx_citemacro_citep">(Tan et al., <a href="#bib.bib78" title="" class="ltx_ref">2022</a>)</cite> and FedHPO <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite>.
Thus, to further fulfill gap <span id="S5.p1.1.4" class="ltx_text ltx_font_bold">(iv)</span>, we implement <span id="S5.p1.1.5" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span> as a collection of hook-like functions to support rich extensions, following the design principles of FS Trainer <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a href="#bib.bib88" title="" class="ltx_ref">2023</a>)</cite>.
These hook-like functions will be executed by some arranged pattern to fine-tune the adapter within the local client.
By adding, removing, or replacing hook-like functions, entities can conveniently customize local fine-tuning procedures and extend applicabilities.
<span id="S5.p1.1.6" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span> can be effortlessly compatible with implemented advanced FL algorithms for interdisciplinary research.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Training operators for acceleration and efficiency</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p">We introduce various accelerating operators and resource-efficient operators for fine-tuning LLMs in <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>.
These provided operators aim to optimize the federated fine-tuning process in terms of CPU/GPU memory consumption, multi-GPU parallel, and communication cost.
We describe the operators and show how they can be combined to achieve better compatibility and efficiency.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Mode-generic operators.</span>
We provide operators generalized to different modes in the local fine-tuning stage of <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span>.
We implement mixed-precision training and gradient accumulation operators in several hook-like functions to save GPU resources.
Furthermore, to accelerate the local fine-tuning process and enable multi-GPU parallelism, <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_smallcaps">FS-LLM</span> integrates Pytorch’s data parallel mechanism.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">Mode-specific operators.</span>
Besides the aforementioned generalized operators, we develop specialized operators that are tailored for each mode and aim to address the bottlenecks in each mode.
To be more specific, in the simulated mode, instantiating multiple clients on a single machine with several independent instantiated models causes a lot of memory consumption.
Therefore, we use a round-robin switching operator, which allows the clients to take turns using the frozen full model for fine-tuning the adapter and then aggregating the updated adapters.
Under this operator, when the number of clients grows, the memory consumption will only increase by an additional amount of the adapter.
This improvement makes it possible to conduct simulated FL experiments with a number of clients on one single machine.
For the distributed mode and clustered mode, we accelerate the communication between the server and the clients by one to two orders of magnitude by reducing the size of communication messages.
We apply different communication optimizations for different messages and introduce communication-efficient operators, including quantization operator, streaming operator, and compression operator.
Specifically, the quantization operator reduces the bit-width of the model parameters in the message to 16 or 8 bits; the streaming operator serializes the model parameters to eliminate the overhead of type conversion; the compression operator applies DEFLATE <cite class="ltx_cite ltx_citemacro_citep">(Deutsch, <a href="#bib.bib22" title="" class="ltx_ref">1996a</a>)</cite> or Gzip <cite class="ltx_cite ltx_citemacro_citep">(Deutsch, <a href="#bib.bib23" title="" class="ltx_ref">1996b</a>)</cite> algorithms to compress the messages.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.p4.1" class="ltx_p"><span id="S5.SS1.p4.1.1" class="ltx_text ltx_font_bold">Parallelization operators.</span>
Meanwhile, we also migrate the functionality of DeepSpeed as shown in Figure <a href="#S5.F3" title="Figure 3 ‣ 5.1 Training operators for acceleration and efficiency ‣ 5 LLM-Trainer: Training Operators and Paradigm ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, providing data parallelism with multi-GPU memory optimization and CPU offloading capabilities, further enhancing resource utilization.
Specifically, after launching the fine-tuning with DeepSpeed, we disable some modules (e.g., the logging module, the WandB module, and the file writing module) for the subprocess other than the Rank <math id="S5.SS1.p4.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S5.SS1.p4.1.m1.1a"><mn id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><cn type="integer" id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">0</cn></annotation-xml></semantics></math> process to avoid conflicts.
In addition, in distributed and clustered modes, each subprocess communicates independently with each other across the server and the clients, and only synchronizes with other subprocesses during the local fine-tuning process, ensuring consistent behavior across different modes.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2309.00363/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S5.F3.4.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> integrates DeepSpeed for federated fine-tuning in different hardware conditions. Rank <math id="S5.F3.2.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S5.F3.2.m1.1b"><mn id="S5.F3.2.m1.1.1" xref="S5.F3.2.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.F3.2.m1.1c"><cn type="integer" id="S5.F3.2.m1.1.1.cmml" xref="S5.F3.2.m1.1.1">0</cn></annotation-xml></semantics></math> indicates the main process for multi-GPU training, and some modules of other subprocesses are disabled (e.g., logging and saving checkpoints). Msg stands for messages transmitted between the server and the clients, which trigger the events to happen.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Training paradigm for extendability towards advanced FL tasks</h3>

<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p">Another design philosophy of <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">LLM-Trainer</span> is to support various extensions easily and integrate different hook-like functions with existing training paradigms seamlessly for FL interdisciplinary study.
A vanilla fine-tuning process involves three steps:
(1) preparing datasets and extracting them by batches, (2) iterating over the training datasets to update the model parameters, and (3) evaluating the performance of the fine-tuned model on validation datasets.
We implement fine-grained learning behaviors for advanced FL tasks at different points in the above steps with hook-like functions.
For instance, pFL <cite class="ltx_cite ltx_citemacro_citep">(Tan et al., <a href="#bib.bib78" title="" class="ltx_ref">2022</a>)</cite> and FedHPO <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite> are two advanced FL tasks that can significantly improve model performance in FL.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_bold">Adaptation of pFL with LLMs.</span>
FS <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a href="#bib.bib88" title="" class="ltx_ref">2023</a>)</cite> provides many implemented pFL plugins <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>, which can be integrated for federated fine-finetuning LLMs.
However, due to limited resources, it is unrealistic for the clients to maintain both global and local models at the same time for some pFL algorithms <cite class="ltx_cite ltx_citemacro_citep">(T Dinh et al., <a href="#bib.bib77" title="" class="ltx_ref">2020</a>; Li et al., <a href="#bib.bib46" title="" class="ltx_ref">2021</a>)</cite>, as it would consume a lot of memory.
Therefore, we optimize the implementation of these pFL algorithms by only using global and local adapters.
With such an implementation, by adding a pFL hook-like function, we can achieve the cooperation of any PEFT algorithms with the implemented pFL algorithms, which provides strong extensibility for federated fine-tuning LLMs in personalized settings.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.p3.1" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_bold">Adaptation of FedHPO with LLMs.</span>
Similarly, for FedHPO, we offer extensions for <span id="S5.SS2.p3.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span> with model-free HPO methods (e.g., random search <cite class="ltx_cite ltx_citemacro_citep">(Bergstra &amp; Bengio, <a href="#bib.bib4" title="" class="ltx_ref">2012</a>)</cite> and grid search), model-based HPO methods (e.g., Bayesian Optimization <cite class="ltx_cite ltx_citemacro_citep">(Shahriari et al., <a href="#bib.bib76" title="" class="ltx_ref">2015</a>)</cite>), multi-fidelity HPO method (e.g., Successive Halving Algorithm <cite class="ltx_cite ltx_citemacro_citep">(Jamieson &amp; Talwalkar, <a href="#bib.bib37" title="" class="ltx_ref">2016</a>)</cite>), and FedHPO methods (e.g., FTS <cite class="ltx_cite ltx_citemacro_citep">(Dai et al., <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> and FLoRA <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib95" title="" class="ltx_ref">2021</a>)</cite>).</p>
</div>
<div id="S5.SS2.p4" class="ltx_para ltx_noindent">
<p id="S5.SS2.p4.1" class="ltx_p">As our vision, the extensibility of <span id="S5.SS2.p4.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> to support the interdisciplinary study of LLMs and other FL scenarios dramatically expands the application scenarios of fine-tuning LLMs in FL and raises many new research opportunities, which we will discuss more details later in Section <a href="#S7" title="7 Discussions and Future Directions ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Experiments</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">In this section, we demonstrate the effectiveness of <span id="S6.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> by a set of comprehensive experiments with different algorithms and tasks.
We want to answer the following research questions:
(1) How effective and efficient is it to federated fine-tuning LLMs with PEFT algorithms (Section <a href="#S6.SS1" title="6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a> and <a href="#S6.SS2" title="6.2 Efficiency of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>)?
(2) How effective is it to federated fine-tune LLMs without accessing the full model (Section <a href="#S6.SS3" title="6.3 Fine-tuning LLMs without accessing the full model in FL ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>)?
(3) What insights can we obtain from the interdisciplinary capabilities of <span id="S6.p1.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span> in resolving pFL and FedHPO problems when federated fine-tuning LLMs (Section <a href="#S6.SS4" title="6.4 Personalized federated learning for LLMs ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.4</span></a> and <a href="#S6.SS5" title="6.5 Study of the FedHPO for LLMs ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.5</span></a>)?
We go through our experimental results and provide answers to the above questions.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Effectiveness of PEFT algorithms in <span id="S6.SS1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.p1.1" class="ltx_p">Firstly, we benchmark the performance of different PEFT algorithms in different application domains and scenarios.
As described in Section <a href="#S3" title="3 LLM-Benchmarks: A Complete Pipeline for Benchmarking ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we use three federated fine-tuning datasets to fine-tune LLMs and evaluate them with corresponding tasks: (i) federated fine-tuning with <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span> for code generation and evaluating with <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_italic">HumanEval</span>, (ii) federated fine-tuning with <span id="S6.SS1.p1.1.3" class="ltx_text ltx_font_italic">Fed-Dolly</span> for generic language capability and evaluating with <span id="S6.SS1.p1.1.4" class="ltx_text ltx_font_italic">HELM</span>, and (iii) federated fine-tuning with <span id="S6.SS1.p1.1.5" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span> for mathematical reasoning and evaluating with <span id="S6.SS1.p1.1.6" class="ltx_text ltx_font_italic">GSM8K-test</span>.
We conduct experiments in three scenarios: global (centralized fine-tuning), fed (federated fine-tuning), and local (separated fine-tuning).
To be more specific, the global scenario can be regarded as fine-tuning LLMs with one client who holds the whole fine-tuning dataset. Fed scenario means that clients federated fine-tune LLMs where each client holds a different fine-tuning dataset.
Local scenario means that each client independently fine-tunes LLMs with its own fine-tuning dataset.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS1.p2.1" class="ltx_p">All the experiments are conducted on the machines with the same hardware configuration: Nvidia A100 GPU (80GB) with Intel Xeon Platinum 8369B CPU and 512GB of RAM.
For all scenarios, we repeat the experiments three times with different random seeds.
We report the average evaluation score with its standard deviation.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS1.p3.4" class="ltx_p"><span id="S6.SS1.p3.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Benchmark federated fine-tuned LLaMA-7B.</span>
We use a widely adopted LLM, LLaMA-7B, with three PEFT algorithms <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>
We exclude prefix-tuning from our experiments, because its implementation in  <cite class="ltx_cite ltx_citemacro_cite">Mangrulkar et al. (<a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite> contains unresolved issues when we were preparing this package.
</span></span></span>, including LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, P-tuning <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib51" title="" class="ltx_ref">2021b</a>)</cite>, and prompt tuning <cite class="ltx_cite ltx_citemacro_citep">(Lester et al., <a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite>.
We employ FedAvg <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite> as the federated aggregation strategy.
To conduct the experiments uniformly and fairly, we fix the FL-specific hyperparameters and the hyperparameters that have a large impact on the computation cost for all experiments.
For example, we set the communication round to <math id="S6.SS1.p3.1.m1.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S6.SS1.p3.1.m1.1a"><mn id="S6.SS1.p3.1.m1.1.1" xref="S6.SS1.p3.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.1.m1.1b"><cn type="integer" id="S6.SS1.p3.1.m1.1.1.cmml" xref="S6.SS1.p3.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.1.m1.1c">500</annotation></semantics></math>, the local update step to <math id="S6.SS1.p3.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S6.SS1.p3.2.m2.1a"><mn id="S6.SS1.p3.2.m2.1.1" xref="S6.SS1.p3.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.2.m2.1b"><cn type="integer" id="S6.SS1.p3.2.m2.1.1.cmml" xref="S6.SS1.p3.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.2.m2.1c">30</annotation></semantics></math>, and the batch size to <math id="S6.SS1.p3.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S6.SS1.p3.3.m3.1a"><mn id="S6.SS1.p3.3.m3.1.1" xref="S6.SS1.p3.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.3.m3.1b"><cn type="integer" id="S6.SS1.p3.3.m3.1.1.cmml" xref="S6.SS1.p3.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.3.m3.1c">1</annotation></semantics></math>.
We perform a grid search for algorithm-specific and learning-related hyperparameters to obtain the optimal configuration.
For example, the search space of the learning rate is <math id="S6.SS1.p3.4.m4.6" class="ltx_Math" alttext="\{$1\text{\times}{10}^{-4}$,$3\text{\times}{10}^{-4}$,$5\text{\times}{10}^{-4}$,$1\text{\times}{10}^{-3}$,$3\text{\times}{10}^{-3}$,$5\text{\times}{10}^{-3}$\}" display="inline"><semantics id="S6.SS1.p3.4.m4.6a"><mrow id="S6.SS1.p3.4.m4.6.7.2" xref="S6.SS1.p3.4.m4.6.7.1.cmml"><mo stretchy="false" id="S6.SS1.p3.4.m4.6.7.2.1" xref="S6.SS1.p3.4.m4.6.7.1.cmml">{</mo><mrow id="S6.SS1.p3.4.m4.1.1.m1.3.3.3" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.1.1.m1.1.1.1.1.1.1.1" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml">1</mn><mtext id="S6.SS1.p3.4.m4.1.1.m1.2.2.2.2.2.2.2" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml">×</mtext><msup id="S6.SS1.p3.4.m4.1.1.m1.3.3.3.3.3.3.3" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.1.1.m1.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml">10</mn><mrow id="S6.SS1.p3.4.m4.1.1.m1.3.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml"><mo id="S6.SS1.p3.4.m4.1.1.m1.3.3.3.3.3.3.3.3.2a" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml">−</mo><mn id="S6.SS1.p3.4.m4.1.1.m1.3.3.3.3.3.3.3.3.2.2" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml">4</mn></mrow></msup></mrow><mo id="S6.SS1.p3.4.m4.6.7.2.2" xref="S6.SS1.p3.4.m4.6.7.1.cmml">,</mo><mrow id="S6.SS1.p3.4.m4.2.2.m1.3.3.3" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.2.2.m1.1.1.1.1.1.1.1" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml">3</mn><mtext id="S6.SS1.p3.4.m4.2.2.m1.2.2.2.2.2.2.2" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml">×</mtext><msup id="S6.SS1.p3.4.m4.2.2.m1.3.3.3.3.3.3.3" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.2.2.m1.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml">10</mn><mrow id="S6.SS1.p3.4.m4.2.2.m1.3.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml"><mo id="S6.SS1.p3.4.m4.2.2.m1.3.3.3.3.3.3.3.3.2a" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml">−</mo><mn id="S6.SS1.p3.4.m4.2.2.m1.3.3.3.3.3.3.3.3.2.2" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml">4</mn></mrow></msup></mrow><mo id="S6.SS1.p3.4.m4.6.7.2.3" xref="S6.SS1.p3.4.m4.6.7.1.cmml">,</mo><mrow id="S6.SS1.p3.4.m4.3.3.m1.3.3.3" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.3.3.m1.1.1.1.1.1.1.1" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml">5</mn><mtext id="S6.SS1.p3.4.m4.3.3.m1.2.2.2.2.2.2.2" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml">×</mtext><msup id="S6.SS1.p3.4.m4.3.3.m1.3.3.3.3.3.3.3" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.3.3.m1.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml">10</mn><mrow id="S6.SS1.p3.4.m4.3.3.m1.3.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml"><mo id="S6.SS1.p3.4.m4.3.3.m1.3.3.3.3.3.3.3.3.2a" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml">−</mo><mn id="S6.SS1.p3.4.m4.3.3.m1.3.3.3.3.3.3.3.3.2.2" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml">4</mn></mrow></msup></mrow><mo id="S6.SS1.p3.4.m4.6.7.2.4" xref="S6.SS1.p3.4.m4.6.7.1.cmml">,</mo><mrow id="S6.SS1.p3.4.m4.4.4.m1.3.3.3" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.4.4.m1.1.1.1.1.1.1.1" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml">1</mn><mtext id="S6.SS1.p3.4.m4.4.4.m1.2.2.2.2.2.2.2" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml">×</mtext><msup id="S6.SS1.p3.4.m4.4.4.m1.3.3.3.3.3.3.3" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.4.4.m1.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml">10</mn><mrow id="S6.SS1.p3.4.m4.4.4.m1.3.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml"><mo id="S6.SS1.p3.4.m4.4.4.m1.3.3.3.3.3.3.3.3.2a" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml">−</mo><mn id="S6.SS1.p3.4.m4.4.4.m1.3.3.3.3.3.3.3.3.2.2" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml">3</mn></mrow></msup></mrow><mo id="S6.SS1.p3.4.m4.6.7.2.5" xref="S6.SS1.p3.4.m4.6.7.1.cmml">,</mo><mrow id="S6.SS1.p3.4.m4.5.5.m1.3.3.3" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.5.5.m1.1.1.1.1.1.1.1" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml">3</mn><mtext id="S6.SS1.p3.4.m4.5.5.m1.2.2.2.2.2.2.2" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml">×</mtext><msup id="S6.SS1.p3.4.m4.5.5.m1.3.3.3.3.3.3.3" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.5.5.m1.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml">10</mn><mrow id="S6.SS1.p3.4.m4.5.5.m1.3.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml"><mo id="S6.SS1.p3.4.m4.5.5.m1.3.3.3.3.3.3.3.3.2a" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml">−</mo><mn id="S6.SS1.p3.4.m4.5.5.m1.3.3.3.3.3.3.3.3.2.2" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml">3</mn></mrow></msup></mrow><mo id="S6.SS1.p3.4.m4.6.7.2.6" xref="S6.SS1.p3.4.m4.6.7.1.cmml">,</mo><mrow id="S6.SS1.p3.4.m4.6.6.m1.3.3.3" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.6.6.m1.1.1.1.1.1.1.1" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml">5</mn><mtext id="S6.SS1.p3.4.m4.6.6.m1.2.2.2.2.2.2.2" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml">×</mtext><msup id="S6.SS1.p3.4.m4.6.6.m1.3.3.3.3.3.3.3" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml"><mn id="S6.SS1.p3.4.m4.6.6.m1.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml">10</mn><mrow id="S6.SS1.p3.4.m4.6.6.m1.3.3.3.3.3.3.3.3.2" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml"><mo id="S6.SS1.p3.4.m4.6.6.m1.3.3.3.3.3.3.3.3.2a" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml">−</mo><mn id="S6.SS1.p3.4.m4.6.6.m1.3.3.3.3.3.3.3.3.2.2" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml">3</mn></mrow></msup></mrow><mo stretchy="false" id="S6.SS1.p3.4.m4.6.7.2.7" xref="S6.SS1.p3.4.m4.6.7.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.4.m4.6b"><set id="S6.SS1.p3.4.m4.6.7.1.cmml" xref="S6.SS1.p3.4.m4.6.7.2"><csymbol cd="latexml" id="S6.SS1.p3.4.m4.1.1.m1.3.3.3.cmml" xref="S6.SS1.p3.4.m4.1.1.m1.3.3.3">1E-4</csymbol><csymbol cd="latexml" id="S6.SS1.p3.4.m4.2.2.m1.3.3.3.cmml" xref="S6.SS1.p3.4.m4.2.2.m1.3.3.3">3E-4</csymbol><csymbol cd="latexml" id="S6.SS1.p3.4.m4.3.3.m1.3.3.3.cmml" xref="S6.SS1.p3.4.m4.3.3.m1.3.3.3">5E-4</csymbol><csymbol cd="latexml" id="S6.SS1.p3.4.m4.4.4.m1.3.3.3.cmml" xref="S6.SS1.p3.4.m4.4.4.m1.3.3.3">1E-3</csymbol><csymbol cd="latexml" id="S6.SS1.p3.4.m4.5.5.m1.3.3.3.cmml" xref="S6.SS1.p3.4.m4.5.5.m1.3.3.3">3E-3</csymbol><csymbol cd="latexml" id="S6.SS1.p3.4.m4.6.6.m1.3.3.3.cmml" xref="S6.SS1.p3.4.m4.6.6.m1.3.3.3">5E-3</csymbol></set></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.4.m4.6c">\{$1\text{\times}{10}^{-4}$,$3\text{\times}{10}^{-4}$,$5\text{\times}{10}^{-4}$,$1\text{\times}{10}^{-3}$,$3\text{\times}{10}^{-3}$,$5\text{\times}{10}^{-3}$\}</annotation></semantics></math>.
Please refer to Appendix <a href="#A1.SS3" title="A.3 Detailed hyperparameters and results ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a> for more algorithm-specific hyperparameters corresponding to each PEFT algorithm.
Moreover, to further reduce the GPU memory consumption for efficiency, we employ the half-precision operator during fine-tuning.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance comparisons among different PEFT algorithms when fine-tuning LLaMA-7B in FL: Evaluation Scores(%) <math id="S6.T2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.2.m1.1b"><mo id="S6.T2.2.m1.1.1" xref="S6.T2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.2.m1.1c"><csymbol cd="latexml" id="S6.T2.2.m1.1.1.cmml" xref="S6.T2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.2.m1.1d">\pm</annotation></semantics></math> standard deviation(%).</figcaption>
<table id="S6.T2.29" class="ltx_tabular ltx_align_middle">
<tr id="S6.T2.29.28" class="ltx_tr">
<td id="S6.T2.29.28.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Algorithm</td>
<td id="S6.T2.29.28.2" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.29.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.29.28.2.1.1" class="ltx_p">Scenario</span>
</span>
</td>
<td id="S6.T2.29.28.3" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.29.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.29.28.3.1.1" class="ltx_p"><span id="S6.T2.29.28.3.1.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span></span>
</span>
</td>
<td id="S6.T2.29.28.4" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.29.28.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.29.28.4.1.1" class="ltx_p"><span id="S6.T2.29.28.4.1.1.1" class="ltx_text ltx_font_italic">Fed-Dolly</span></span>
</span>
</td>
<td id="S6.T2.29.28.5" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.29.28.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.29.28.5.1.1" class="ltx_p"><span id="S6.T2.29.28.5.1.1.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span></span>
</span>
</td>
</tr>
<tr id="S6.T2.5.3" class="ltx_tr">
<td id="S6.T2.5.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="S6.T2.5.3.4.1" class="ltx_text">LoRA</span></td>
<td id="S6.T2.5.3.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.5.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.5.3.5.1.1" class="ltx_p">Global</span>
</span>
</td>
<td id="S6.T2.3.1.1" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.3.1.1.1.1" class="ltx_p">13.54<math id="S6.T2.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.3.1.1.1.1.m1.1a"><mo id="S6.T2.3.1.1.1.1.m1.1.1" xref="S6.T2.3.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.3.1.1.1.1.m1.1.1.cmml" xref="S6.T2.3.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.3.1.1.1.1.m1.1c">\pm</annotation></semantics></math>0.24</span>
</span>
</td>
<td id="S6.T2.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.4.2.2.1.1" class="ltx_p">46.25<math id="S6.T2.4.2.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.4.2.2.1.1.m1.1a"><mo id="S6.T2.4.2.2.1.1.m1.1.1" xref="S6.T2.4.2.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.4.2.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.4.2.2.1.1.m1.1.1.cmml" xref="S6.T2.4.2.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.4.2.2.1.1.m1.1c">\pm</annotation></semantics></math>0.44</span>
</span>
</td>
<td id="S6.T2.5.3.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.5.3.3.1.1" class="ltx_p">14.81<math id="S6.T2.5.3.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.5.3.3.1.1.m1.1a"><mo id="S6.T2.5.3.3.1.1.m1.1.1" xref="S6.T2.5.3.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.5.3.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.5.3.3.1.1.m1.1.1.cmml" xref="S6.T2.5.3.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.5.3.3.1.1.m1.1c">\pm</annotation></semantics></math>1.04</span>
</span>
</td>
</tr>
<tr id="S6.T2.8.6" class="ltx_tr">
<td id="S6.T2.8.6.4" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.8.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.8.6.4.1.1" class="ltx_p">Fed</span>
</span>
</td>
<td id="S6.T2.6.4.1" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.6.4.1.1.1" class="ltx_p">13.29<math id="S6.T2.6.4.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.6.4.1.1.1.m1.1a"><mo id="S6.T2.6.4.1.1.1.m1.1.1" xref="S6.T2.6.4.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.6.4.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.6.4.1.1.1.m1.1.1.cmml" xref="S6.T2.6.4.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.6.4.1.1.1.m1.1c">\pm</annotation></semantics></math>0.10</span>
</span>
</td>
<td id="S6.T2.7.5.2" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.7.5.2.1.1" class="ltx_p">46.57<math id="S6.T2.7.5.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.7.5.2.1.1.m1.1a"><mo id="S6.T2.7.5.2.1.1.m1.1.1" xref="S6.T2.7.5.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.7.5.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.7.5.2.1.1.m1.1.1.cmml" xref="S6.T2.7.5.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.7.5.2.1.1.m1.1c">\pm</annotation></semantics></math>0.24</span>
</span>
</td>
<td id="S6.T2.8.6.3" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.8.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.8.6.3.1.1" class="ltx_p">14.25<math id="S6.T2.8.6.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.8.6.3.1.1.m1.1a"><mo id="S6.T2.8.6.3.1.1.m1.1.1" xref="S6.T2.8.6.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.8.6.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.8.6.3.1.1.m1.1.1.cmml" xref="S6.T2.8.6.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.8.6.3.1.1.m1.1c">\pm</annotation></semantics></math>1.37</span>
</span>
</td>
</tr>
<tr id="S6.T2.11.9" class="ltx_tr">
<td id="S6.T2.11.9.4" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.11.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.11.9.4.1.1" class="ltx_p">Local</span>
</span>
</td>
<td id="S6.T2.9.7.1" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.9.7.1.1.1" class="ltx_p">10.99<math id="S6.T2.9.7.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.9.7.1.1.1.m1.1a"><mo id="S6.T2.9.7.1.1.1.m1.1.1" xref="S6.T2.9.7.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.9.7.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.9.7.1.1.1.m1.1.1.cmml" xref="S6.T2.9.7.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.9.7.1.1.1.m1.1c">\pm</annotation></semantics></math>0.77</span>
</span>
</td>
<td id="S6.T2.10.8.2" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.10.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.10.8.2.1.1" class="ltx_p">43.98<math id="S6.T2.10.8.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.10.8.2.1.1.m1.1a"><mo id="S6.T2.10.8.2.1.1.m1.1.1" xref="S6.T2.10.8.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.10.8.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.10.8.2.1.1.m1.1.1.cmml" xref="S6.T2.10.8.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.10.8.2.1.1.m1.1c">\pm</annotation></semantics></math>1.38</span>
</span>
</td>
<td id="S6.T2.11.9.3" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.11.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.11.9.3.1.1" class="ltx_p">11.88<math id="S6.T2.11.9.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.11.9.3.1.1.m1.1a"><mo id="S6.T2.11.9.3.1.1.m1.1.1" xref="S6.T2.11.9.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.11.9.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.11.9.3.1.1.m1.1.1.cmml" xref="S6.T2.11.9.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.11.9.3.1.1.m1.1c">\pm</annotation></semantics></math>1.35</span>
</span>
</td>
</tr>
<tr id="S6.T2.14.12" class="ltx_tr">
<td id="S6.T2.14.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="S6.T2.14.12.4.1" class="ltx_text">P-tuning</span></td>
<td id="S6.T2.14.12.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.14.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.14.12.5.1.1" class="ltx_p">Global</span>
</span>
</td>
<td id="S6.T2.12.10.1" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.12.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.12.10.1.1.1" class="ltx_p">10.24<math id="S6.T2.12.10.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.12.10.1.1.1.m1.1a"><mo id="S6.T2.12.10.1.1.1.m1.1.1" xref="S6.T2.12.10.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.12.10.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.12.10.1.1.1.m1.1.1.cmml" xref="S6.T2.12.10.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.12.10.1.1.1.m1.1c">\pm</annotation></semantics></math>0.30</span>
</span>
</td>
<td id="S6.T2.13.11.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.13.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.13.11.2.1.1" class="ltx_p">41.29<math id="S6.T2.13.11.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.13.11.2.1.1.m1.1a"><mo id="S6.T2.13.11.2.1.1.m1.1.1" xref="S6.T2.13.11.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.13.11.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.13.11.2.1.1.m1.1.1.cmml" xref="S6.T2.13.11.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.13.11.2.1.1.m1.1c">\pm</annotation></semantics></math>0.01</span>
</span>
</td>
<td id="S6.T2.14.12.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.14.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.14.12.3.1.1" class="ltx_p">12.13<math id="S6.T2.14.12.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.14.12.3.1.1.m1.1a"><mo id="S6.T2.14.12.3.1.1.m1.1.1" xref="S6.T2.14.12.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.14.12.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.14.12.3.1.1.m1.1.1.cmml" xref="S6.T2.14.12.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.14.12.3.1.1.m1.1c">\pm</annotation></semantics></math>0.41</span>
</span>
</td>
</tr>
<tr id="S6.T2.17.15" class="ltx_tr">
<td id="S6.T2.17.15.4" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.17.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.17.15.4.1.1" class="ltx_p">Fed</span>
</span>
</td>
<td id="S6.T2.15.13.1" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.15.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.15.13.1.1.1" class="ltx_p">9.71<math id="S6.T2.15.13.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.15.13.1.1.1.m1.1a"><mo id="S6.T2.15.13.1.1.1.m1.1.1" xref="S6.T2.15.13.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.15.13.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.15.13.1.1.1.m1.1.1.cmml" xref="S6.T2.15.13.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.15.13.1.1.1.m1.1c">\pm</annotation></semantics></math>0.66</span>
</span>
</td>
<td id="S6.T2.16.14.2" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.16.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.16.14.2.1.1" class="ltx_p">41.50<math id="S6.T2.16.14.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.16.14.2.1.1.m1.1a"><mo id="S6.T2.16.14.2.1.1.m1.1.1" xref="S6.T2.16.14.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.16.14.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.16.14.2.1.1.m1.1.1.cmml" xref="S6.T2.16.14.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.16.14.2.1.1.m1.1c">\pm</annotation></semantics></math>0.32</span>
</span>
</td>
<td id="S6.T2.17.15.3" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.17.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.17.15.3.1.1" class="ltx_p">11.75<math id="S6.T2.17.15.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.17.15.3.1.1.m1.1a"><mo id="S6.T2.17.15.3.1.1.m1.1.1" xref="S6.T2.17.15.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.17.15.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.17.15.3.1.1.m1.1.1.cmml" xref="S6.T2.17.15.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.17.15.3.1.1.m1.1c">\pm</annotation></semantics></math>0.39</span>
</span>
</td>
</tr>
<tr id="S6.T2.20.18" class="ltx_tr">
<td id="S6.T2.20.18.4" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.20.18.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.20.18.4.1.1" class="ltx_p">Local</span>
</span>
</td>
<td id="S6.T2.18.16.1" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.18.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.18.16.1.1.1" class="ltx_p">7.78<math id="S6.T2.18.16.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.18.16.1.1.1.m1.1a"><mo id="S6.T2.18.16.1.1.1.m1.1.1" xref="S6.T2.18.16.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.18.16.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.18.16.1.1.1.m1.1.1.cmml" xref="S6.T2.18.16.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.18.16.1.1.1.m1.1c">\pm</annotation></semantics></math>2.27</span>
</span>
</td>
<td id="S6.T2.19.17.2" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.19.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.19.17.2.1.1" class="ltx_p">38.76<math id="S6.T2.19.17.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.19.17.2.1.1.m1.1a"><mo id="S6.T2.19.17.2.1.1.m1.1.1" xref="S6.T2.19.17.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.19.17.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.19.17.2.1.1.m1.1.1.cmml" xref="S6.T2.19.17.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.19.17.2.1.1.m1.1c">\pm</annotation></semantics></math>2.39</span>
</span>
</td>
<td id="S6.T2.20.18.3" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.20.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.20.18.3.1.1" class="ltx_p">11.42<math id="S6.T2.20.18.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.20.18.3.1.1.m1.1a"><mo id="S6.T2.20.18.3.1.1.m1.1.1" xref="S6.T2.20.18.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.20.18.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.20.18.3.1.1.m1.1.1.cmml" xref="S6.T2.20.18.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.20.18.3.1.1.m1.1c">\pm</annotation></semantics></math>0.96</span>
</span>
</td>
</tr>
<tr id="S6.T2.23.21" class="ltx_tr">
<td id="S6.T2.23.21.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="S6.T2.23.21.4.1" class="ltx_text">Prompt tuning</span></td>
<td id="S6.T2.23.21.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.23.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.23.21.5.1.1" class="ltx_p">Global</span>
</span>
</td>
<td id="S6.T2.21.19.1" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.21.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.21.19.1.1.1" class="ltx_p">9.80<math id="S6.T2.21.19.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.21.19.1.1.1.m1.1a"><mo id="S6.T2.21.19.1.1.1.m1.1.1" xref="S6.T2.21.19.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.21.19.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.21.19.1.1.1.m1.1.1.cmml" xref="S6.T2.21.19.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.21.19.1.1.1.m1.1c">\pm</annotation></semantics></math>1.79</span>
</span>
</td>
<td id="S6.T2.22.20.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.22.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.22.20.2.1.1" class="ltx_p">41.24<math id="S6.T2.22.20.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.22.20.2.1.1.m1.1a"><mo id="S6.T2.22.20.2.1.1.m1.1.1" xref="S6.T2.22.20.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.22.20.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.22.20.2.1.1.m1.1.1.cmml" xref="S6.T2.22.20.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.22.20.2.1.1.m1.1c">\pm</annotation></semantics></math>0.54</span>
</span>
</td>
<td id="S6.T2.23.21.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.23.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.23.21.3.1.1" class="ltx_p">9.75<math id="S6.T2.23.21.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.23.21.3.1.1.m1.1a"><mo id="S6.T2.23.21.3.1.1.m1.1.1" xref="S6.T2.23.21.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.23.21.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.23.21.3.1.1.m1.1.1.cmml" xref="S6.T2.23.21.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.23.21.3.1.1.m1.1c">\pm</annotation></semantics></math>1.49</span>
</span>
</td>
</tr>
<tr id="S6.T2.26.24" class="ltx_tr">
<td id="S6.T2.26.24.4" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.26.24.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.26.24.4.1.1" class="ltx_p">Fed</span>
</span>
</td>
<td id="S6.T2.24.22.1" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.24.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.24.22.1.1.1" class="ltx_p">9.63<math id="S6.T2.24.22.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.24.22.1.1.1.m1.1a"><mo id="S6.T2.24.22.1.1.1.m1.1.1" xref="S6.T2.24.22.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.24.22.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.24.22.1.1.1.m1.1.1.cmml" xref="S6.T2.24.22.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.24.22.1.1.1.m1.1c">\pm</annotation></semantics></math>0.36</span>
</span>
</td>
<td id="S6.T2.25.23.2" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.25.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.25.23.2.1.1" class="ltx_p">40.72<math id="S6.T2.25.23.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.25.23.2.1.1.m1.1a"><mo id="S6.T2.25.23.2.1.1.m1.1.1" xref="S6.T2.25.23.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.25.23.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.25.23.2.1.1.m1.1.1.cmml" xref="S6.T2.25.23.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.25.23.2.1.1.m1.1c">\pm</annotation></semantics></math>0.64</span>
</span>
</td>
<td id="S6.T2.26.24.3" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.26.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.26.24.3.1.1" class="ltx_p">9.86<math id="S6.T2.26.24.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.26.24.3.1.1.m1.1a"><mo id="S6.T2.26.24.3.1.1.m1.1.1" xref="S6.T2.26.24.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.26.24.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.26.24.3.1.1.m1.1.1.cmml" xref="S6.T2.26.24.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.26.24.3.1.1.m1.1c">\pm</annotation></semantics></math>0.59</span>
</span>
</td>
</tr>
<tr id="S6.T2.29.27" class="ltx_tr">
<td id="S6.T2.29.27.4" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.29.27.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.29.27.4.1.1" class="ltx_p">Local</span>
</span>
</td>
<td id="S6.T2.27.25.1" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.27.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.27.25.1.1.1" class="ltx_p">7.18<math id="S6.T2.27.25.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.27.25.1.1.1.m1.1a"><mo id="S6.T2.27.25.1.1.1.m1.1.1" xref="S6.T2.27.25.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.27.25.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.27.25.1.1.1.m1.1.1.cmml" xref="S6.T2.27.25.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.27.25.1.1.1.m1.1c">\pm</annotation></semantics></math>2.17</span>
</span>
</td>
<td id="S6.T2.28.26.2" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.28.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.28.26.2.1.1" class="ltx_p">37.65<math id="S6.T2.28.26.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.28.26.2.1.1.m1.1a"><mo id="S6.T2.28.26.2.1.1.m1.1.1" xref="S6.T2.28.26.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.28.26.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.28.26.2.1.1.m1.1.1.cmml" xref="S6.T2.28.26.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.28.26.2.1.1.m1.1c">\pm</annotation></semantics></math>6.12</span>
</span>
</td>
<td id="S6.T2.29.27.3" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T2.29.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T2.29.27.3.1.1" class="ltx_p">9.65<math id="S6.T2.29.27.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T2.29.27.3.1.1.m1.1a"><mo id="S6.T2.29.27.3.1.1.m1.1.1" xref="S6.T2.29.27.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T2.29.27.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T2.29.27.3.1.1.m1.1.1.cmml" xref="S6.T2.29.27.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.29.27.3.1.1.m1.1c">\pm</annotation></semantics></math>0.77</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S6.SS1.p4" class="ltx_para ltx_noindent">
<p id="S6.SS1.p4.1" class="ltx_p"><span id="S6.SS1.p4.1.1" class="ltx_text ltx_font_bold">Results and Analysis.</span>
Table <a href="#S6.T2" title="Table 2 ‣ 6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the comparisons among different PEFT algorithms for federated fine-tuned LLaMA-7B under different scenarios.
In summary, we can draw the following conclusions.
(1) All algorithms with federated fine-tuning can significantly outperform those under the local scenario, and they all show very competitive results against those under the global scenario.
This suggests that it is feasible and effective to federated fine-tuning LLMs with PEFT algorithms, which allows multiple entities to benefit from the collaborative training without directly sharing their private data.
(2) Among these PEFT algorithms, LoRA shows the most promising performance and beats the other two algorithms by a large margin in all three scenarios.
P-tuning and prompt tuning are two parameterized prompt algorithms that insert some learnable tokens into the model input to improve the performance of downstream tasks.
However, they are outperformed by LoRA, a low-rank adaptation algorithm that augments each layer of LLMs with two low-rank matrices to capture new domain-specific knowledge.
We conjecture that these parameterized prompt algorithms are limited by the knowledge encoded in the original LLM during the pre-training stage.
This indicates that LoRA is a suitable PEFT algorithm for federate fine-tuning LLMs in future research or realistic scenarios.</p>
</div>
<div id="S6.SS1.p5" class="ltx_para ltx_noindent">
<p id="S6.SS1.p5.1" class="ltx_p"><span id="S6.SS1.p5.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">How about federated fine-tuning previous-generation language models?</span>
As a comparison, we select the superior PEFT algorithm in Table <a href="#S6.T2" title="Table 2 ‣ 6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, to federated fine-tune a previous-generation language model, OPT-2.7B <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib92" title="" class="ltx_ref">2022</a>)</cite>, which has fewer parameters than LLaMA-7B.
Table <a href="#S6.T3" title="Table 3 ‣ 6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the evaluation results of OPT-2.7B on the <span id="S6.SS1.p5.1.2" class="ltx_text ltx_font_italic">HumanEval</span>, <span id="S6.SS1.p5.1.3" class="ltx_text ltx_font_italic">HELM</span> evaluations, and <span id="S6.SS1.p5.1.4" class="ltx_text ltx_font_italic">GSM8K-test</span>.</p>
</div>
<div id="S6.SS1.p6" class="ltx_para ltx_noindent">
<p id="S6.SS1.p6.1" class="ltx_p">Though the model performance of OPT-2.7B is improved with federated fine-tuning compared to those under the local scenario, it is not significant.
Moreover, OPT-2.7B fails in the evaluation of some subtasks in HELM due to the exceeded input length, which limits the scope of the application of the previous-generation language models with fewer parameters.
Comparing the performance of federated fine-tuned LLaMA-7B and OPT-2.7B in Figure <a href="#S6.F4" title="Figure 4 ‣ 6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we observe that the current-generation LLM with a larger scale has an obvious advantage over the previous-generation language model with a smaller scale on various evaluation tasks.
Thus, if the communication and computation costs are affordable, one should consider the larger scale of current-generation LLMs for more significant FL improvement and better absolute performance on downstream tasks.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance of federated fine-tuned previous-generation language model, OPT-2.7B, with LoRA: Evaluation Scores(%) <math id="S6.T3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.3.m1.1b"><mo id="S6.T3.3.m1.1.1" xref="S6.T3.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.3.m1.1c"><csymbol cd="latexml" id="S6.T3.3.m1.1.1.cmml" xref="S6.T3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.3.m1.1d">\pm</annotation></semantics></math> standard deviation(%). (<sup id="S6.T3.18.1" class="ltx_sup">∗</sup>OPT-2.7B fails on some subtasks in HELM due to the exceeded input length, and failed subtasks are excluded when calculating the final results.)</figcaption>
<table id="S6.T3.16" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.16.13" class="ltx_tr">
<td id="S6.T3.16.13.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Algorithm</td>
<td id="S6.T3.16.13.2" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.16.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.16.13.2.1.1" class="ltx_p">Scenario</span>
</span>
</td>
<td id="S6.T3.16.13.3" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.16.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.16.13.3.1.1" class="ltx_p"><span id="S6.T3.16.13.3.1.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span></span>
</span>
</td>
<td id="S6.T3.16.13.4" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.16.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.16.13.4.1.1" class="ltx_p"><span id="S6.T3.16.13.4.1.1.1" class="ltx_text ltx_font_italic">Fed-Dolly</span></span>
</span>
</td>
<td id="S6.T3.16.13.5" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.16.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.16.13.5.1.1" class="ltx_p"><span id="S6.T3.16.13.5.1.1.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span></span>
</span>
</td>
</tr>
<tr id="S6.T3.8.4" class="ltx_tr">
<td id="S6.T3.8.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="S6.T3.8.4.5.1" class="ltx_text">LoRA</span></td>
<td id="S6.T3.8.4.6" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.8.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.8.4.6.1.1" class="ltx_p">Global</span>
</span>
</td>
<td id="S6.T3.5.1.1" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.5.1.1.1.1" class="ltx_p">0.61<math id="S6.T3.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.5.1.1.1.1.m1.1a"><mo id="S6.T3.5.1.1.1.1.m1.1.1" xref="S6.T3.5.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.5.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.5.1.1.1.1.m1.1.1.cmml" xref="S6.T3.5.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.5.1.1.1.1.m1.1c">\pm</annotation></semantics></math>0.61</span>
</span>
</td>
<td id="S6.T3.7.3.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.7.3.3.2" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.7.3.3.2.2" class="ltx_p">25.90<math id="S6.T3.6.2.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.6.2.2.1.1.m1.1a"><mo id="S6.T3.6.2.2.1.1.m1.1.1" xref="S6.T3.6.2.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.6.2.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.6.2.2.1.1.m1.1.1.cmml" xref="S6.T3.6.2.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.6.2.2.1.1.m1.1c">\pm</annotation></semantics></math>0.40<sup id="S6.T3.7.3.3.2.2.1" class="ltx_sup">∗</sup></span>
</span>
</td>
<td id="S6.T3.8.4.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.8.4.4.1.1" class="ltx_p">2.92<math id="S6.T3.8.4.4.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.8.4.4.1.1.m1.1a"><mo id="S6.T3.8.4.4.1.1.m1.1.1" xref="S6.T3.8.4.4.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.8.4.4.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.8.4.4.1.1.m1.1.1.cmml" xref="S6.T3.8.4.4.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.8.4.4.1.1.m1.1c">\pm</annotation></semantics></math>0.11</span>
</span>
</td>
</tr>
<tr id="S6.T3.12.8" class="ltx_tr">
<td id="S6.T3.12.8.5" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.12.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.12.8.5.1.1" class="ltx_p">Fed</span>
</span>
</td>
<td id="S6.T3.9.5.1" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.9.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.9.5.1.1.1" class="ltx_p">0.43<math id="S6.T3.9.5.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.9.5.1.1.1.m1.1a"><mo id="S6.T3.9.5.1.1.1.m1.1.1" xref="S6.T3.9.5.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.9.5.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.9.5.1.1.1.m1.1.1.cmml" xref="S6.T3.9.5.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.9.5.1.1.1.m1.1c">\pm</annotation></semantics></math>0.07</span>
</span>
</td>
<td id="S6.T3.11.7.3" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.11.7.3.2" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.11.7.3.2.2" class="ltx_p">25.90<math id="S6.T3.10.6.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.10.6.2.1.1.m1.1a"><mo id="S6.T3.10.6.2.1.1.m1.1.1" xref="S6.T3.10.6.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.10.6.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.10.6.2.1.1.m1.1.1.cmml" xref="S6.T3.10.6.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.10.6.2.1.1.m1.1c">\pm</annotation></semantics></math>0.33<sup id="S6.T3.11.7.3.2.2.1" class="ltx_sup">∗</sup></span>
</span>
</td>
<td id="S6.T3.12.8.4" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.12.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.12.8.4.1.1" class="ltx_p">2.88<math id="S6.T3.12.8.4.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.12.8.4.1.1.m1.1a"><mo id="S6.T3.12.8.4.1.1.m1.1.1" xref="S6.T3.12.8.4.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.12.8.4.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.12.8.4.1.1.m1.1.1.cmml" xref="S6.T3.12.8.4.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.12.8.4.1.1.m1.1c">\pm</annotation></semantics></math>0.17</span>
</span>
</td>
</tr>
<tr id="S6.T3.16.12" class="ltx_tr">
<td id="S6.T3.16.12.5" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.16.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.16.12.5.1.1" class="ltx_p">Local</span>
</span>
</td>
<td id="S6.T3.13.9.1" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.13.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.13.9.1.1.1" class="ltx_p">0.25<math id="S6.T3.13.9.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.13.9.1.1.1.m1.1a"><mo id="S6.T3.13.9.1.1.1.m1.1.1" xref="S6.T3.13.9.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.13.9.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.13.9.1.1.1.m1.1.1.cmml" xref="S6.T3.13.9.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.13.9.1.1.1.m1.1c">\pm</annotation></semantics></math>0.25</span>
</span>
</td>
<td id="S6.T3.15.11.3" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.15.11.3.2" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.15.11.3.2.2" class="ltx_p">25.06<math id="S6.T3.14.10.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.14.10.2.1.1.m1.1a"><mo id="S6.T3.14.10.2.1.1.m1.1.1" xref="S6.T3.14.10.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.14.10.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.14.10.2.1.1.m1.1.1.cmml" xref="S6.T3.14.10.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.14.10.2.1.1.m1.1c">\pm</annotation></semantics></math>1.02<sup id="S6.T3.15.11.3.2.2.1" class="ltx_sup">∗</sup></span>
</span>
</td>
<td id="S6.T3.16.12.4" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T3.16.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T3.16.12.4.1.1" class="ltx_p">2.25<math id="S6.T3.16.12.4.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T3.16.12.4.1.1.m1.1a"><mo id="S6.T3.16.12.4.1.1.m1.1.1" xref="S6.T3.16.12.4.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T3.16.12.4.1.1.m1.1b"><csymbol cd="latexml" id="S6.T3.16.12.4.1.1.m1.1.1.cmml" xref="S6.T3.16.12.4.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.16.12.4.1.1.m1.1c">\pm</annotation></semantics></math>0.22</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2309.00363/assets/x4.png" id="S6.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="338" height="241" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Visualization of the performance comparison of fine-tuned LLaMA-7B and OPT-2.7B under federated and local scenarios. (The axes are scaled to highlight the differences.)</figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Efficiency of PEFT algorithms in <span id="S6.SS2.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.p1.1" class="ltx_p">In this section, we evaluate the efficiency of various PEFT algorithms in FL.
Among all the metrics, we focus on their GPU memory consumption, message size, and computation time in the federated fine-tuning process.
We note that the GPU memory consumption refers to the model only, excluding the input tokens and the optimizer state, because the input length varies greatly across data and affects the GPU memory consumption during fine-tuning LLMs.
For message size, we report the number of bytes of the serialized adapter parameters during one communication between the server and one client.
The computation time is defined as the time duration of one training step with a batch size of <math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mn id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><cn type="integer" id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">1</annotation></semantics></math>, from the start of forward propagation to the end of backward propagation.
We report the computation time on two types of hardware, both with 512GB of RAM: Nvidia A100 GPU (80GB) with Intel Xeon Platinum 8369B CPU and Nvidia V100 GPU (32GB) with Intel Xeon Platinum 8163 CPU.
For a fair comparison, we follow the same experimental settings as Section <a href="#S6.SS1" title="6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a> for all PEFT algorithms.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.1" class="ltx_p"><span id="S6.SS2.p2.1.1" class="ltx_text ltx_font_bold">Results and Analysis.</span>
As shown in Table <a href="#S6.T4" title="Table 4 ‣ 6.2 Efficiency of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we can first notice that (1) fine-tuning with different PEFT algorithms has negligible impact on the GPU memory consumption.
(2) However, there are large differences in the message sizes, which in turn lead to large variations in the transmission time.
For example, for a client with 100Mbps bandwidth, the transmission time (upload and download) per round ranges from about 0.01 seconds (with prompt tuning) to 40 seconds (with P-tuning) when using different PEFT algorithms.
(3) Moreover, from the table, we can observe that the computation time varies due to different GPUs, with almost a twofold difference.
Therefore, a more critical issue deserves attention: federated fine-tuning LLMs may suffer from more idle time due to the heterogeneity of computing resources among different clients.
Because this computation efficiency difference can be significant, the benefit of mitigating communication latency by sending messages asynchronously in multiple computational stages may diminish.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.p3.1" class="ltx_p">Therefore, there are two research directions for federated fine-tuning LLMs in efficiency: (1) how to leverage the idle time of computation-resource-rich clients while they wait for computation-resource-limited clients to complete local updates, and (2) how to optimize the utilization of the available bandwidth resources in computation-resource-limited clients during computation.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Efficiency comparisons among different PEFT algorithms when fine-tuning LLaMA-7B in FL.
(<sup id="S6.T4.11.1" class="ltx_sup">∗</sup>The GPU usage is subject to minor variations due to the differences in Cuda versions.)</figcaption>
<table id="S6.T4.9" class="ltx_tabular ltx_align_middle">
<tr id="S6.T4.9.8" class="ltx_tr">
<td id="S6.T4.9.8.1" class="ltx_td ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="S6.T4.9.8.2" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.9.8.2.1.1" class="ltx_p">LoRA</span>
</span>
</td>
<td id="S6.T4.9.8.3" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.9.8.3.1.1" class="ltx_p">P-tuning</span>
</span>
</td>
<td id="S6.T4.9.8.4" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.9.8.4.1.1" class="ltx_p">Prompt tuning</span>
</span>
</td>
</tr>
<tr id="S6.T4.3.1" class="ltx_tr">
<td id="S6.T4.3.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">GPU Usage<sup id="S6.T4.3.1.1.1" class="ltx_sup">∗</sup> (MB)</td>
<td id="S6.T4.3.1.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.2.1.1" class="ltx_p">13,450</span>
</span>
</td>
<td id="S6.T4.3.1.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.3.1.1" class="ltx_p">13,538</span>
</span>
</td>
<td id="S6.T4.3.1.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.3.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.3.1.4.1.1" class="ltx_p">13,442</span>
</span>
</td>
</tr>
<tr id="S6.T4.9.9" class="ltx_tr">
<td id="S6.T4.9.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Message Size (MB)</td>
<td id="S6.T4.9.9.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.9.9.2.1.1" class="ltx_p">21.40</span>
</span>
</td>
<td id="S6.T4.9.9.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.9.9.3.1.1" class="ltx_p">256.48</span>
</span>
</td>
<td id="S6.T4.9.9.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.9.9.4.1.1" class="ltx_p">0.17</span>
</span>
</td>
</tr>
<tr id="S6.T4.6.4" class="ltx_tr">
<td id="S6.T4.6.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Comp. Time on A100 (Sec.)</td>
<td id="S6.T4.4.2.1" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.4.2.1.1.1" class="ltx_p">0.16<math id="S6.T4.4.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T4.4.2.1.1.1.m1.1a"><mo id="S6.T4.4.2.1.1.1.m1.1.1" xref="S6.T4.4.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T4.4.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T4.4.2.1.1.1.m1.1.1.cmml" xref="S6.T4.4.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.4.2.1.1.1.m1.1c">\pm</annotation></semantics></math>0.02</span>
</span>
</td>
<td id="S6.T4.5.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.5.3.2.1.1" class="ltx_p">0.15<math id="S6.T4.5.3.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T4.5.3.2.1.1.m1.1a"><mo id="S6.T4.5.3.2.1.1.m1.1.1" xref="S6.T4.5.3.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T4.5.3.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T4.5.3.2.1.1.m1.1.1.cmml" xref="S6.T4.5.3.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.5.3.2.1.1.m1.1c">\pm</annotation></semantics></math>0.03</span>
</span>
</td>
<td id="S6.T4.6.4.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.6.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.6.4.3.1.1" class="ltx_p">0.15<math id="S6.T4.6.4.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T4.6.4.3.1.1.m1.1a"><mo id="S6.T4.6.4.3.1.1.m1.1.1" xref="S6.T4.6.4.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T4.6.4.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T4.6.4.3.1.1.m1.1.1.cmml" xref="S6.T4.6.4.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.6.4.3.1.1.m1.1c">\pm</annotation></semantics></math>0.04</span>
</span>
</td>
</tr>
<tr id="S6.T4.9.7" class="ltx_tr">
<td id="S6.T4.9.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Comp. Time on V100 (Sec.)</td>
<td id="S6.T4.7.5.1" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.7.5.1.1.1" class="ltx_p">0.33<math id="S6.T4.7.5.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T4.7.5.1.1.1.m1.1a"><mo id="S6.T4.7.5.1.1.1.m1.1.1" xref="S6.T4.7.5.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T4.7.5.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T4.7.5.1.1.1.m1.1.1.cmml" xref="S6.T4.7.5.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.7.5.1.1.1.m1.1c">\pm</annotation></semantics></math>0.07</span>
</span>
</td>
<td id="S6.T4.8.6.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.8.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.8.6.2.1.1" class="ltx_p">0.33<math id="S6.T4.8.6.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T4.8.6.2.1.1.m1.1a"><mo id="S6.T4.8.6.2.1.1.m1.1.1" xref="S6.T4.8.6.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T4.8.6.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T4.8.6.2.1.1.m1.1.1.cmml" xref="S6.T4.8.6.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.8.6.2.1.1.m1.1c">\pm</annotation></semantics></math>0.08</span>
</span>
</td>
<td id="S6.T4.9.7.3" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T4.9.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.9.7.3.1.1" class="ltx_p">0.33<math id="S6.T4.9.7.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T4.9.7.3.1.1.m1.1a"><mo id="S6.T4.9.7.3.1.1.m1.1.1" xref="S6.T4.9.7.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T4.9.7.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T4.9.7.3.1.1.m1.1.1.cmml" xref="S6.T4.9.7.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.9.7.3.1.1.m1.1c">\pm</annotation></semantics></math>0.10</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Fine-tuning LLMs without accessing the full model in FL</h3>

<div id="S6.SS3.p1" class="ltx_para ltx_noindent">
<p id="S6.SS3.p1.2" class="ltx_p">In this section, we investigate the performance of federated fine-tuning LLMs without accessing the full model. As mentioned in Section <a href="#S4.SS2" title="4.2 Federated fine-tuning without accessing full model ‣ 4 LLM-AlgZoo: A Collection of Fine-tuning Algorithms ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, we adapt a privacy-preserving fine-tuning algorithm, offsite-tuning <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a href="#bib.bib87" title="" class="ltx_ref">2023</a>)</cite>, to federated scenarios.
Specifically, we use the first and last two layers of LLaMA-7B as the adapter and compress the model as the emulator by dropping <math id="S6.SS3.p1.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.SS3.p1.1.m1.1a"><mrow id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml"><mn id="S6.SS3.p1.1.m1.1.1.2" xref="S6.SS3.p1.1.m1.1.1.2.cmml">20</mn><mo id="S6.SS3.p1.1.m1.1.1.1" xref="S6.SS3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><apply id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.SS3.p1.1.m1.1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p1.1.m1.1.1.2.cmml" xref="S6.SS3.p1.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">20\%</annotation></semantics></math> and <math id="S6.SS3.p1.2.m2.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S6.SS3.p1.2.m2.1a"><mrow id="S6.SS3.p1.2.m2.1.1" xref="S6.SS3.p1.2.m2.1.1.cmml"><mn id="S6.SS3.p1.2.m2.1.1.2" xref="S6.SS3.p1.2.m2.1.1.2.cmml">50</mn><mo id="S6.SS3.p1.2.m2.1.1.1" xref="S6.SS3.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.2.m2.1b"><apply id="S6.SS3.p1.2.m2.1.1.cmml" xref="S6.SS3.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.SS3.p1.2.m2.1.1.1.cmml" xref="S6.SS3.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p1.2.m2.1.1.2.cmml" xref="S6.SS3.p1.2.m2.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.2.m2.1c">50\%</annotation></semantics></math> of the remaining layers uniformly.
Then the server broadcasts both the adapter and emulator to all clients, and the clients only fine-tune the adapter with FedAvg.
We compare the performance of LLMs with fine-tuned adapters via federated offsite-tuning (denoted as FedOT) and corresponding local offsite-tuning (denoted as LocalOT).
Following Section <a href="#S6.SS1" title="6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>, we benchmark FedOT on <span id="S6.SS3.p1.2.1" class="ltx_text ltx_font_smallcaps">LLM-Benchmarks</span>.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para ltx_noindent">
<p id="S6.SS3.p2.3" class="ltx_p"><span id="S6.SS3.p2.3.1" class="ltx_text ltx_font_bold">Results and Analysis.</span>
We present the evaluation scores of FedOT and LocalOT in Table <a href="#S6.T5" title="Table 5 ‣ 6.3 Fine-tuning LLMs without accessing the full model in FL ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
We can have the following observations:
(1) Comparing FedOT and LocalOT, FL offers significant benefits for this privacy-preserving fine-tuning algorithm for federated fine-tuning LLMs without accessing the full model.
This demonstrates that FedOT can still enable multiple entities to benefit from collaborative training without sharing their private data directly when they cannot access the full model.
(2) When the dropping rate is <math id="S6.SS3.p2.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.SS3.p2.1.m1.1a"><mrow id="S6.SS3.p2.1.m1.1.1" xref="S6.SS3.p2.1.m1.1.1.cmml"><mn id="S6.SS3.p2.1.m1.1.1.2" xref="S6.SS3.p2.1.m1.1.1.2.cmml">20</mn><mo id="S6.SS3.p2.1.m1.1.1.1" xref="S6.SS3.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.1.m1.1b"><apply id="S6.SS3.p2.1.m1.1.1.cmml" xref="S6.SS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S6.SS3.p2.1.m1.1.1.1.cmml" xref="S6.SS3.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.1.m1.1.1.2.cmml" xref="S6.SS3.p2.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.1.m1.1c">20\%</annotation></semantics></math>, FedOT still achieves competitive performance compared to some of those PEFT algorithms, even though the clients cannot access the full model.
However, it should be noted that this is because the number of parameters of the adapter in FedOT is significantly larger than those in the PEFT algorithms.
FedOT sacrifices communication efficiency for model performance, making it effective in scenarios where clients cannot access the full model.
(3) On the other hand, the results show that when the dropping rate increases to <math id="S6.SS3.p2.2.m2.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S6.SS3.p2.2.m2.1a"><mrow id="S6.SS3.p2.2.m2.1.1" xref="S6.SS3.p2.2.m2.1.1.cmml"><mn id="S6.SS3.p2.2.m2.1.1.2" xref="S6.SS3.p2.2.m2.1.1.2.cmml">50</mn><mo id="S6.SS3.p2.2.m2.1.1.1" xref="S6.SS3.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.2.m2.1b"><apply id="S6.SS3.p2.2.m2.1.1.cmml" xref="S6.SS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S6.SS3.p2.2.m2.1.1.1.cmml" xref="S6.SS3.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.2.m2.1.1.2.cmml" xref="S6.SS3.p2.2.m2.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.2.m2.1c">50\%</annotation></semantics></math> from <math id="S6.SS3.p2.3.m3.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.SS3.p2.3.m3.1a"><mrow id="S6.SS3.p2.3.m3.1.1" xref="S6.SS3.p2.3.m3.1.1.cmml"><mn id="S6.SS3.p2.3.m3.1.1.2" xref="S6.SS3.p2.3.m3.1.1.2.cmml">20</mn><mo id="S6.SS3.p2.3.m3.1.1.1" xref="S6.SS3.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.3.m3.1b"><apply id="S6.SS3.p2.3.m3.1.1.cmml" xref="S6.SS3.p2.3.m3.1.1"><csymbol cd="latexml" id="S6.SS3.p2.3.m3.1.1.1.cmml" xref="S6.SS3.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.p2.3.m3.1.1.2.cmml" xref="S6.SS3.p2.3.m3.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.3.m3.1c">20\%</annotation></semantics></math>, the model loses a large amount of knowledge from the pre-training stage, almost fails to retain the capacity of the CoT and code generation, and hardly acquire new knowledge from the fine-tuning.
There is a trade-off between the compression rate and the performance of LLMs: increasing the compression rate enhances the privacy of LLMs but degrades their performance.
This indicates that how to compress LLMs while maintaining their generalization ability and model privacy is a promising research direction to explore.</p>
</div>
<figure id="S6.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance comparisons between different compression rates (dropping layers uniformly) when fine-tuning LLaMA-7B without accessing the full model under federated and local scenarios: Evaluation Scores(%) <math id="S6.T5.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.2.m1.1b"><mo id="S6.T5.2.m1.1.1" xref="S6.T5.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.2.m1.1c"><csymbol cd="latexml" id="S6.T5.2.m1.1.1.cmml" xref="S6.T5.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.2.m1.1d">\pm</annotation></semantics></math> standard deviation(%).</figcaption>
<table id="S6.T5.16" class="ltx_tabular ltx_align_middle">
<tr id="S6.T5.16.15" class="ltx_tr">
<td id="S6.T5.16.15.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Dropping Rate</td>
<td id="S6.T5.16.15.2" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.16.15.2.1.1" class="ltx_p">Scenario</span>
</span>
</td>
<td id="S6.T5.16.15.3" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.16.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.16.15.3.1.1" class="ltx_p"><span id="S6.T5.16.15.3.1.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span></span>
</span>
</td>
<td id="S6.T5.16.15.4" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.16.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.16.15.4.1.1" class="ltx_p"><span id="S6.T5.16.15.4.1.1.1" class="ltx_text ltx_font_italic">Fed-Dolly</span></span>
</span>
</td>
<td id="S6.T5.16.15.5" class="ltx_td ltx_align_justify ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.16.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.16.15.5.1.1" class="ltx_p"><span id="S6.T5.16.15.5.1.1.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span></span>
</span>
</td>
</tr>
<tr id="S6.T5.6.4" class="ltx_tr">
<td id="S6.T5.3.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S6.T5.3.1.1.1" class="ltx_text"><math id="S6.T5.3.1.1.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S6.T5.3.1.1.1.m1.1a"><mrow id="S6.T5.3.1.1.1.m1.1.1" xref="S6.T5.3.1.1.1.m1.1.1.cmml"><mn id="S6.T5.3.1.1.1.m1.1.1.2" xref="S6.T5.3.1.1.1.m1.1.1.2.cmml">20</mn><mo id="S6.T5.3.1.1.1.m1.1.1.1" xref="S6.T5.3.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.3.1.1.1.m1.1b"><apply id="S6.T5.3.1.1.1.m1.1.1.cmml" xref="S6.T5.3.1.1.1.m1.1.1"><csymbol cd="latexml" id="S6.T5.3.1.1.1.m1.1.1.1.cmml" xref="S6.T5.3.1.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.T5.3.1.1.1.m1.1.1.2.cmml" xref="S6.T5.3.1.1.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.3.1.1.1.m1.1c">20\%</annotation></semantics></math></span></td>
<td id="S6.T5.6.4.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.6.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.6.4.5.1.1" class="ltx_p">Fed</span>
</span>
</td>
<td id="S6.T5.4.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.4.2.2.1.1" class="ltx_p">7.14<math id="S6.T5.4.2.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.4.2.2.1.1.m1.1a"><mo id="S6.T5.4.2.2.1.1.m1.1.1" xref="S6.T5.4.2.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.4.2.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.4.2.2.1.1.m1.1.1.cmml" xref="S6.T5.4.2.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.4.2.2.1.1.m1.1c">\pm</annotation></semantics></math>2.75</span>
</span>
</td>
<td id="S6.T5.5.3.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.5.3.3.1.1" class="ltx_p">44.88<math id="S6.T5.5.3.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.5.3.3.1.1.m1.1a"><mo id="S6.T5.5.3.3.1.1.m1.1.1" xref="S6.T5.5.3.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.5.3.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.5.3.3.1.1.m1.1.1.cmml" xref="S6.T5.5.3.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.5.3.3.1.1.m1.1c">\pm</annotation></semantics></math>0.75</span>
</span>
</td>
<td id="S6.T5.6.4.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.6.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.6.4.4.1.1" class="ltx_p">9.02<math id="S6.T5.6.4.4.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.6.4.4.1.1.m1.1a"><mo id="S6.T5.6.4.4.1.1.m1.1.1" xref="S6.T5.6.4.4.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.6.4.4.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.6.4.4.1.1.m1.1.1.cmml" xref="S6.T5.6.4.4.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.6.4.4.1.1.m1.1c">\pm</annotation></semantics></math>0.71</span>
</span>
</td>
</tr>
<tr id="S6.T5.9.7" class="ltx_tr">
<td id="S6.T5.9.7.4" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.9.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.9.7.4.1.1" class="ltx_p">Local</span>
</span>
</td>
<td id="S6.T5.7.5.1" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.7.5.1.1.1" class="ltx_p">0.18<math id="S6.T5.7.5.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.7.5.1.1.1.m1.1a"><mo id="S6.T5.7.5.1.1.1.m1.1.1" xref="S6.T5.7.5.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.7.5.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.7.5.1.1.1.m1.1.1.cmml" xref="S6.T5.7.5.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.7.5.1.1.1.m1.1c">\pm</annotation></semantics></math>0.50</span>
</span>
</td>
<td id="S6.T5.8.6.2" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.8.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.8.6.2.1.1" class="ltx_p">38.45<math id="S6.T5.8.6.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.8.6.2.1.1.m1.1a"><mo id="S6.T5.8.6.2.1.1.m1.1.1" xref="S6.T5.8.6.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.8.6.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.8.6.2.1.1.m1.1.1.cmml" xref="S6.T5.8.6.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.8.6.2.1.1.m1.1c">\pm</annotation></semantics></math>9.57</span>
</span>
</td>
<td id="S6.T5.9.7.3" class="ltx_td ltx_align_justify" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.9.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.9.7.3.1.1" class="ltx_p">4.72<math id="S6.T5.9.7.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.9.7.3.1.1.m1.1a"><mo id="S6.T5.9.7.3.1.1.m1.1.1" xref="S6.T5.9.7.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.9.7.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.9.7.3.1.1.m1.1.1.cmml" xref="S6.T5.9.7.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.9.7.3.1.1.m1.1c">\pm</annotation></semantics></math>2.91</span>
</span>
</td>
</tr>
<tr id="S6.T5.13.11" class="ltx_tr">
<td id="S6.T5.10.8.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="S6.T5.10.8.1.1" class="ltx_text"><math id="S6.T5.10.8.1.1.m1.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S6.T5.10.8.1.1.m1.1a"><mrow id="S6.T5.10.8.1.1.m1.1.1" xref="S6.T5.10.8.1.1.m1.1.1.cmml"><mn id="S6.T5.10.8.1.1.m1.1.1.2" xref="S6.T5.10.8.1.1.m1.1.1.2.cmml">50</mn><mo id="S6.T5.10.8.1.1.m1.1.1.1" xref="S6.T5.10.8.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.10.8.1.1.m1.1b"><apply id="S6.T5.10.8.1.1.m1.1.1.cmml" xref="S6.T5.10.8.1.1.m1.1.1"><csymbol cd="latexml" id="S6.T5.10.8.1.1.m1.1.1.1.cmml" xref="S6.T5.10.8.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.T5.10.8.1.1.m1.1.1.2.cmml" xref="S6.T5.10.8.1.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.10.8.1.1.m1.1c">50\%</annotation></semantics></math></span></td>
<td id="S6.T5.13.11.5" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.13.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.13.11.5.1.1" class="ltx_p">Fed</span>
</span>
</td>
<td id="S6.T5.11.9.2" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.11.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.11.9.2.1.1" class="ltx_p">0.16<math id="S6.T5.11.9.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.11.9.2.1.1.m1.1a"><mo id="S6.T5.11.9.2.1.1.m1.1.1" xref="S6.T5.11.9.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.11.9.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.11.9.2.1.1.m1.1.1.cmml" xref="S6.T5.11.9.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.11.9.2.1.1.m1.1c">\pm</annotation></semantics></math>0.15</span>
</span>
</td>
<td id="S6.T5.12.10.3" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.12.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.12.10.3.1.1" class="ltx_p">37.01<math id="S6.T5.12.10.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.12.10.3.1.1.m1.1a"><mo id="S6.T5.12.10.3.1.1.m1.1.1" xref="S6.T5.12.10.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.12.10.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.12.10.3.1.1.m1.1.1.cmml" xref="S6.T5.12.10.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.12.10.3.1.1.m1.1c">\pm</annotation></semantics></math>2.34</span>
</span>
</td>
<td id="S6.T5.13.11.4" class="ltx_td ltx_align_justify ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.13.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.13.11.4.1.1" class="ltx_p">2.98<math id="S6.T5.13.11.4.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.13.11.4.1.1.m1.1a"><mo id="S6.T5.13.11.4.1.1.m1.1.1" xref="S6.T5.13.11.4.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.13.11.4.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.13.11.4.1.1.m1.1.1.cmml" xref="S6.T5.13.11.4.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.13.11.4.1.1.m1.1c">\pm</annotation></semantics></math>0.98</span>
</span>
</td>
</tr>
<tr id="S6.T5.16.14" class="ltx_tr">
<td id="S6.T5.16.14.4" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.16.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.16.14.4.1.1" class="ltx_p">Local</span>
</span>
</td>
<td id="S6.T5.14.12.1" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.14.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.14.12.1.1.1" class="ltx_p">0.00<math id="S6.T5.14.12.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.14.12.1.1.1.m1.1a"><mo id="S6.T5.14.12.1.1.1.m1.1.1" xref="S6.T5.14.12.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.14.12.1.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.14.12.1.1.1.m1.1.1.cmml" xref="S6.T5.14.12.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.14.12.1.1.1.m1.1c">\pm</annotation></semantics></math>0.00</span>
</span>
</td>
<td id="S6.T5.15.13.2" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.15.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.15.13.2.1.1" class="ltx_p">35.44<math id="S6.T5.15.13.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.15.13.2.1.1.m1.1a"><mo id="S6.T5.15.13.2.1.1.m1.1.1" xref="S6.T5.15.13.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.15.13.2.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.15.13.2.1.1.m1.1.1.cmml" xref="S6.T5.15.13.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.15.13.2.1.1.m1.1c">\pm</annotation></semantics></math>5.99</span>
</span>
</td>
<td id="S6.T5.16.14.3" class="ltx_td ltx_align_justify ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span id="S6.T5.16.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.16.14.3.1.1" class="ltx_p">1.82<math id="S6.T5.16.14.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S6.T5.16.14.3.1.1.m1.1a"><mo id="S6.T5.16.14.3.1.1.m1.1.1" xref="S6.T5.16.14.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S6.T5.16.14.3.1.1.m1.1b"><csymbol cd="latexml" id="S6.T5.16.14.3.1.1.m1.1.1.cmml" xref="S6.T5.16.14.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.16.14.3.1.1.m1.1c">\pm</annotation></semantics></math>1.29</span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Personalized federated learning for LLMs</h3>

<div id="S6.SS4.p1" class="ltx_para ltx_noindent">
<p id="S6.SS4.p1.1" class="ltx_p">To explore the potential of personalized federated learning algorithms <cite class="ltx_cite ltx_citemacro_citep">(Tan et al., <a href="#bib.bib78" title="" class="ltx_ref">2022</a>)</cite> for fine-tuning LLMs in FL, we compare pFedMe <cite class="ltx_cite ltx_citemacro_citep">(T Dinh et al., <a href="#bib.bib77" title="" class="ltx_ref">2020</a>)</cite> and FedAvg <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite> with LoRA in this subsection under different data heterogeneity.
To simulate different levels of data heterogeneity, we create variants of <span id="S6.SS4.p1.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span>.</p>
</div>
<div id="S6.SS4.p2" class="ltx_para ltx_noindent">
<p id="S6.SS4.p2.3" class="ltx_p">We use the programming language of the code samples as the label and split the fine-tuning dataset into nine clients by Latent Dirichlet Allocation (i.e., Dirichlet splitter).
We use four different values for <math id="S6.SS4.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.SS4.p2.1.m1.1a"><mi id="S6.SS4.p2.1.m1.1.1" xref="S6.SS4.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.1.m1.1b"><ci id="S6.SS4.p2.1.m1.1.1.cmml" xref="S6.SS4.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.1.m1.1c">\alpha</annotation></semantics></math> of the Dirichlet splitter from <math id="S6.SS4.p2.2.m2.1" class="ltx_Math" alttext="0.05" display="inline"><semantics id="S6.SS4.p2.2.m2.1a"><mn id="S6.SS4.p2.2.m2.1.1" xref="S6.SS4.p2.2.m2.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.2.m2.1b"><cn type="float" id="S6.SS4.p2.2.m2.1.1.cmml" xref="S6.SS4.p2.2.m2.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.2.m2.1c">0.05</annotation></semantics></math> to <math id="S6.SS4.p2.3.m3.1" class="ltx_Math" alttext="50.0" display="inline"><semantics id="S6.SS4.p2.3.m3.1a"><mn id="S6.SS4.p2.3.m3.1.1" xref="S6.SS4.p2.3.m3.1.1.cmml">50.0</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.3.m3.1b"><cn type="float" id="S6.SS4.p2.3.m3.1.1.cmml" xref="S6.SS4.p2.3.m3.1.1">50.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.3.m3.1c">50.0</annotation></semantics></math>.
Along with the original <span id="S6.SS4.p2.3.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span> dataset, we obtain five federated fine-tuning datasets with different heterogeneity.
Following Section <a href="#S6.SS1" title="6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>, we repeat each experiment three times with different random seeds.
The averaged evaluation scores (Pass@1 scores) with their standard deviation are reported.
We note that evaluation scores with pFedMe are obtained by benchmarking each personalized client individually and then computing their average scores.</p>
</div>
<div id="S6.SS4.p3" class="ltx_para ltx_noindent">
<p id="S6.SS4.p3.1" class="ltx_p"><span id="S6.SS4.p3.1.1" class="ltx_text ltx_font_bold">Results and Analysis.</span>
We present the performance of fine-tuning with LoRA using FedAvg and pFedMe in different data heterogeneities in Figure <a href="#S6.F5.sf1" title="In Figure 5 ‣ 6.4 Personalized federated learning for LLMs ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>, which shows the performance of fine-tuning with FedAvg gradually approaches that under the global scenario as data heterogeneity decreases.
However, pFedMe surprisingly does not outperform FedAvg under any data distribution, which shows different results with previous language models in pFL-bench <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>.
We analyze this phenomenon and find that:
(1) To improve efficiency, we use the half-precision operator to fine-tune LLMs in the experiment. However, this leads to a more pronounced precision loss for pFedMe than FedAvg, since pFedMe multiplies the update of the local model with respect to the global model by a small learning rate. This adversely impacts the performance of pFedMe.
(2) The use of acceleration operators for efficient LLM fine-tuning restricts the range of hyperparameter space in these pFL algorithms, affecting the upper bound of algorithm performance in the valid parameter space. For example, assuming the LLM performs better when the learning rate is <math id="S6.SS4.p3.1.m1.1" class="ltx_Math" alttext="0.00001" display="inline"><semantics id="S6.SS4.p3.1.m1.1a"><mn id="S6.SS4.p3.1.m1.1.1" xref="S6.SS4.p3.1.m1.1.1.cmml">0.00001</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p3.1.m1.1b"><cn type="float" id="S6.SS4.p3.1.m1.1.1.cmml" xref="S6.SS4.p3.1.m1.1.1">0.00001</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p3.1.m1.1c">0.00001</annotation></semantics></math>, but at this point, using half-precision or mixed-precision training for efficiency, the model can barely be updated due to the precision loss.</p>
</div>
<div id="S6.SS4.p4" class="ltx_para ltx_noindent">
<p id="S6.SS4.p4.1" class="ltx_p">Based on these observations, we believe how to ensure the compatibility of various efficient training operators and different pFL algorithms is still unclear and deserves more attention from the community.
Besides, sharing a common base LLM and only maintaining multiple versions of adapters may not be compatible with some existing pFL algorithms because pFL algorithms may introduce access conflicts.
For instance, when a penalty term is used to constrain the large updates of the local model, the computation to compute updates requires using both the global adapter with the base LLM and the local adapter with the base LLM in the same step.
Significantly, more memory cost is required to avoid the conflict by maintaining multiple copies of LLMs and their adapters.
Resolving this challenge may require new algorithm development or a new pFL computation pattern for future work.</p>
</div>
<figure id="S6.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2309.00363/assets/x5.png" id="S6.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>The comparison of performance with pFedMe and FedAvg over different data heterogeneity: the higher <math id="S6.F5.sf1.2.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S6.F5.sf1.2.m1.1b"><mi id="S6.F5.sf1.2.m1.1.1" xref="S6.F5.sf1.2.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S6.F5.sf1.2.m1.1c"><ci id="S6.F5.sf1.2.m1.1.1.cmml" xref="S6.F5.sf1.2.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.F5.sf1.2.m1.1d">\alpha</annotation></semantics></math>, the lower the data heterogeneity among clients. Global stands for fine-tuning LLMs under the global scenario, and Base stands for the original model, which is not fine-tuned.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2309.00363/assets/x6.png" id="S6.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="384" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>The landscape of the rank of the validation loss and the Pass@1 scores over all the hyperparameter combinations. The grey surface shows the distribution of the rank based on the Pass@1 scores, and the blue-red surface indicates the distribution of the rank based on the validation loss.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Fine-tuning LLMs in pFL (<span id="S6.F5.3.1" class="ltx_text ltx_font_bold">Left</span>) and FedHPO (<span id="S6.F5.4.2" class="ltx_text ltx_font_bold">Right</span>).</figcaption>
</figure>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Study of the FedHPO for LLMs</h3>

<div id="S6.SS5.p1" class="ltx_para ltx_noindent">
<p id="S6.SS5.p1.1" class="ltx_p">Since fine-tuning LLMs in FL is very costly, it is usually infeasible to perform full-fidelity hyperparameter optimization.
However, we observe that the performance of fine-tuned LLMs in FL is highly dependent on the choice of hyperparameters (see Appendix <a href="#A1.SS3" title="A.3 Detailed hyperparameters and results ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>).
Therefore, we investigate whether we can use low-fidelity FedHPO <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite> methods in this scenario.
We follow the experiment settings in Section <a href="#S6.SS1" title="6.1 Effectiveness of PEFT algorithms in FS-LLM ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a> and use LoRA to fine-tune LLaMA-7B on <span id="S6.SS5.p1.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span> yet with lower fidelity (i.e., fewer communication rounds).
We rank all the hyperparameter combinations searched by their validation loss in ascending order and evaluation scores in descending order separately.
We plot the two landscapes of the rank to explore the feasibility of using low-fidelity FedHPO methods when federated fine-tuning LLMs.</p>
</div>
<div id="S6.SS5.p2" class="ltx_para ltx_noindent">
<p id="S6.SS5.p2.1" class="ltx_p"><span id="S6.SS5.p2.1.1" class="ltx_text ltx_font_bold">Results and Analysis.</span>
Based on the results shown in Figure <a href="#S6.F5.sf2" title="In Figure 5 ‣ 6.4 Personalized federated learning for LLMs ‣ 6 Experiments ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>, we distill the following observations.
(1) We observe that the rank of the evaluation scores of the fine-tuned LLMs varies drastically and non-smoothly with respect to the hyperparameter changes.
This poses a great challenge for finding the optimal hyperparameters, as it requires a fine-grained and exhaustive search over the hyperparameter space.
(2) Moreover, we reveal a significant discrepancy between the ranks of validation loss and the ranks of final generalization performance in evaluation tasks during fine-tuning.
This implies that the validation loss may not reflect the generalization ability of the fine-tuned LLMs.</p>
</div>
<div id="S6.SS5.p3" class="ltx_para ltx_noindent">
<p id="S6.SS5.p3.1" class="ltx_p">In summary, we uncover two major challenges for fine-tuning LLMs in FedHPO: (1) the evaluation scores are highly sensitive and non-smooth to the hyperparameter changes, and (2) the validation loss may not be a reliable indicator of the generalization performance.
These challenges identify two promising yet unexplored research directions for future work on fine-tuning LLMs in FedHPO.
The first direction is to develop fine-grained but efficient FedHPO methods for finding the optimal hyperparameters on federated fine-tuning LLMs, which can avoid exhaustive searches over the hyperparameter space.
The second direction is to exploit concurrent exploration in FedHPO to evaluate the generalization ability of the client-side hyperparameters with low fidelity for each client during the FL process.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussions and Future Directions</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">This paper introduces a comprehensive and practical package for federated fine-tuning LLMs.
Our experimental results illustrate how our <span id="S7.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span> bridges the gaps between the universal FL framework and the need for fine-tuning LLMs under various FL settings.
More importantly, our benchmark results also provide positive guidance and insights for the research community regarding how to optimize the federated fine-tuning and what sub-problems in the field deserve more focus.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p">However, the results of this paper are limited by several factors.
(1) Due to the resource limit, all experiments use a batch size of <math id="S7.p2.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S7.p2.1.m1.1a"><mn id="S7.p2.1.m1.1.1" xref="S7.p2.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S7.p2.1.m1.1b"><cn type="integer" id="S7.p2.1.m1.1.1.cmml" xref="S7.p2.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p2.1.m1.1c">1</annotation></semantics></math>, but federated fine-tuning LLMs with larger batch sizes might perform better.
(2) We also find that designing different prompts (either in fine-tuning or evaluation) will impact the evaluation results. To ensure a fair evaluation and comparison, we use a fixed prompt, but more explorations are possible.</p>
</div>
<div id="S7.p3" class="ltx_para ltx_noindent">
<p id="S7.p3.1" class="ltx_p">Based on our observations and experiments, we outline some promising directions for future research in federated fine-tuning LLMs as follows.</p>
<ul id="S7.I1" class="ltx_itemize">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p">Designing computation-efficient fine-tuning algorithms for federated fine-tuning LLMs.
Even with PEFT algorithms, the computation cost is still too high for most resource-limited clients.
Reducing the computation cost can lower the barrier for more data holders and allow more entities to benefit from the federated fine-tuning LLMs.</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.1" class="ltx_p">Exploring more privacy-preserving fine-tuning algorithms without accessing the full model in FL.
FedOT suffers from a trade-off between model compression rate and model performance.
Addressing this issue would protect the sensitive information of LLMs in FL from exposing pre-training data and the valuable full model, which could be exploited by malicious entities for adversarial attacks or commercial gains while maintaining model performance in FL.</p>
</div>
</li>
<li id="S7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i3.p1" class="ltx_para">
<p id="S7.I1.i3.p1.1" class="ltx_p">Optimizing pFL algorithms to enable robust combination with various accelerating and resource-efficient operators.
If performance degradation due to low-precision training can be overcome, it would improve the personalized model performance when data are heterogeneous and computation resources are limited among clients.</p>
</div>
</li>
<li id="S7.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i4.p1" class="ltx_para">
<p id="S7.I1.i4.p1.1" class="ltx_p">Investigating low-fidelity FedHPO methods for fine-tuning LLMs in FL. Based on our experimental results, we find the inconsistency between validation loss and the generalization performance of LLMs.
Overcoming this inconsistency would help find optimal hyperparameters for federated fine-tuning LLMs with low cost, resulting in better generalization performance.</p>
</div>
</li>
<li id="S7.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S7.I1.i5.p1.1" class="ltx_p">Extending the federated LLM fine-tuning to cross-device setting.
As we have already observed the demand for federated fine-tuning LLMs in the cross-silo scenario, we also notice a similar need in the cross-device scenario <cite class="ltx_cite ltx_citemacro_citep">(Lai et al., <a href="#bib.bib43" title="" class="ltx_ref">2022</a>; Chen et al., <a href="#bib.bib12" title="" class="ltx_ref">2023</a>; Gao et al., <a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite>.
In the cross-device scenario, the clients are more numerous and heterogeneous, the computational resources are more limited, and the network conditions are more diverse.
How to federated fine-tune LLMs under the cross-device scenario is an urgent problem that needs to be solved.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusions</h2>

<div id="S8.p1" class="ltx_para ltx_noindent">
<p id="S8.p1.1" class="ltx_p">In this paper, we first identify gaps that need to be addressed between fine-tuning LLMs in federated settings and the existing universal FL frameworks.
To bridge these gaps, we introduce our open-source package, <span id="S8.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>, with rich functionalities and extensibilities, which supports federated fine-tuning LLMs under various FL scenarios.
We conduct extensive experiments to demonstrate the utility of our package and gain insights into how to fine-tune LLMs in FL settings.
Based on the findings from these experimental results, we outline some promising directions for future research in federated LLM fine-tuning to advance the FL and LLM community.
We have released <span id="S8.p1.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span> at <a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/llm" title="" class="ltx_ref ltx_href">https://github.com/alibaba/FederatedScope/tree/llm</a> for promoting further research.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alex et al. (2021)</span>
<span class="ltx_bibblock">
Neel Alex, Eli Lifland, Lewis Tunstall, Abhishek Thakur, Pegah Maham, C Jess
Riedel, Emmie Hine, Carolyn Ashurst, Paul Sedille, Alexis Carlier, et al.

</span>
<span class="ltx_bibblock">RAFT: A Real-World Few-Shot Text Classification Benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.14076</em>, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2023)</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">Introducing Claude, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bajaj et al. (2016)</span>
<span class="ltx_bibblock">
Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu,
Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al.

</span>
<span class="ltx_bibblock">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1611.09268</em>, 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergstra &amp; Bengio (2012)</span>
<span class="ltx_bibblock">
James Bergstra and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Random Search for Hyper-Parameter Optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Journal of machine learning research</em>, 13(2), 2012.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bi et al. (2023)</span>
<span class="ltx_bibblock">
Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi Tian.

</span>
<span class="ltx_bibblock">Accurate medium-range global weather forecasting with 3D neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 619:533 – 538, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al. (2019)</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konečnỳ, Stefano
Mazzocchi, Brendan McMahan, et al.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System design.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proc. of machine learning and systems (MLSys’19)</em>,
volume 1, pp.  374–388, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borkan et al. (2019)</span>
<span class="ltx_bibblock">
Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman.

</span>
<span class="ltx_bibblock">Nuanced Metrics for Measuring Unintended Bias with Real Data for
Text Classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Companion Proceedings of the World Wide Web Conference
(WWW’19)</em>, pp.  491–500, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et al.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’20)</em>, volume 33, pp.  1877–1901, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. (2018)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub
Konečnỳ, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.01097</em>, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhary (2023)</span>
<span class="ltx_bibblock">
Sahil Chaudhary.

</span>
<span class="ltx_bibblock">Code alpaca: An instruction-following llama model for code
generation.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/sahil280114/codealpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/sahil280114/codealpaca</a>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Daoyuan Chen, Dawei Gao, Weirui Kuang, Yaliang Li, and Bolin Ding.

</span>
<span class="ltx_bibblock">pFL-Bench: A Comprehensive Benchmark for Personalized Federated
Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’22)</em>, pp.  9344–9360, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Daoyuan Chen, Dawei Gao, Yuexiang Xie, Xuchen Pan, Zitao Li, Yaliang Li, Bolin
Ding, and Jingren Zhou.

</span>
<span class="ltx_bibblock">FS-Real: Towards Real-World Cross-Device Federated Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proc. of the ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD’23)</em>, pp.  3829–3841, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, et al.

</span>
<span class="ltx_bibblock">Evaluating Large Language Models Trained on Code.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv perprint arXiv:2107.03374</em>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2021)</span>
<span class="ltx_bibblock">
Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, Dimitrios
Papadopoulos, and Qiang Yang.

</span>
<span class="ltx_bibblock">Secureboost: A lossless federated learning framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, 36:87–98, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et al. (2018)</span>
<span class="ltx_bibblock">
Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy
Liang, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">QuAC: Question Answering in Context.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proc. of the Conference on Empirical Methods in Natural
Language Processing (EMNLP’18)</em>, pp.  2174–2184, 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et al. (2022)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, et al.

</span>
<span class="ltx_bibblock">PaLM: Scaling Language Modeling with Pathways.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.02311</em>, 2022.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al. (2019)</span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael
Collins, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BoolQ: Exploring the Surprising Difficulty of Natural Yes/No
Questions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proc. of the Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies
(NAACL’19)</em>, pp.  2924–2936, 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al. (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
Christopher Hesse, and John Schulman.

</span>
<span class="ltx_bibblock">Training Verifiers to Solve Math Word Problems.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.14168</em>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Computer (2023)</span>
<span class="ltx_bibblock">
Together Computer.

</span>
<span class="ltx_bibblock">RedPajama: An Open Source Recipe to Reproduce LLaMA training
dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/togethercomputer/RedPajama-Data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/togethercomputer/RedPajama-Data</a>, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conover et al. (2023)</span>
<span class="ltx_bibblock">
Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali
Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin.

</span>
<span class="ltx_bibblock">Free Dolly: Introducing the World’s First Truly Open
Instruction-Tuned LLM, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. (2020)</span>
<span class="ltx_bibblock">
Zhongxiang Dai, Bryan Kian Hsiang Low, and Patrick Jaillet.

</span>
<span class="ltx_bibblock">Federated Bayesian Optimization via Thompson Sampling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’20)</em>, volume 33, pp.  9687–9699, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deutsch (1996a)</span>
<span class="ltx_bibblock">
L. Peter Deutsch.

</span>
<span class="ltx_bibblock">DEFLATE Compressed Data Format Specification version 1.3.

</span>
<span class="ltx_bibblock">RFC 1951, Network Working Group, 1996a.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deutsch (1996b)</span>
<span class="ltx_bibblock">
L. Peter Deutsch.

</span>
<span class="ltx_bibblock">GZIP file format specification version 4.3.

</span>
<span class="ltx_bibblock">RFC 1952, Network Working Group, 1996b.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proc. of NAACL-HLT (NAACL-HLT’19)</em>, pp.  4171–4186, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2022)</span>
<span class="ltx_bibblock">
Chenhe Dong, Yuexiang Xie, Bolin Ding, Ying Shen, and Yaliang Li.

</span>
<span class="ltx_bibblock">Collaborating Heterogeneous Natural Language Processing Tasks via
Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.05789</em>, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Driess et al. (2023)</span>
<span class="ltx_bibblock">
Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery,
Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al.

</span>
<span class="ltx_bibblock">PaLM-E: An Embodied Multimodal Language Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.03378</em>, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al. (2021)</span>
<span class="ltx_bibblock">
Wenjing Fang, Derun Zhao, Jin Tan, Chaochao Chen, Chaofan Yu, Li Wang, Lei
Wang, Jun Zhou, and Benyu Zhang.

</span>
<span class="ltx_bibblock">Large-scale secure xgb for vertical federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proc. of the Conference on Information &amp; Knowledge
Management (CIKM’21)</em>, pp.  443–452, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Dawei Gao, Daoyuan Chen, Zitao Li, Yuexiang Xie, Xuchen Pan, Yaliang Li, Bolin
Ding, and Jingren Zhou.

</span>
<span class="ltx_bibblock">FS-Real: A Real-World Cross-Device Federated Learning Platform.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">PVLDB</em>, 16(12):4046–4049, 2023.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021a)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song,
and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Aligning AI With Shared Human Values.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Learning
Representations (ICLR’21)</em>, 2021a.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021b)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn
Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring Massive Multitask Language Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Learning
Representations (ICLR’21)</em>, 2021b.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hermann et al. (2015)</span>
<span class="ltx_bibblock">
Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will
Kay, Mustafa Suleyman, and Phil Blunsom.

</span>
<span class="ltx_bibblock">Teaching Machines to Read and Comprehend.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’15)</em>, volume 28, pp.  1693–1701, 2015.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Houlsby et al. (2019)</span>
<span class="ltx_bibblock">
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin
De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.

</span>
<span class="ltx_bibblock">Parameter-Efficient Transfer Learning for NLP.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Machine Learning
(ICML’21)</em>, pp.  2790–2799, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
Weizhu Chen, et al.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Learning
Representations (ICLR’22)</em>, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023)</span>
<span class="ltx_bibblock">
Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma,
Tengchao Lv, Lei Cui, Owais Khan Mohammed, Qiang Liu, et al.

</span>
<span class="ltx_bibblock">Language Is Not All You Need: Aligning Perception with Language
Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.14045</em>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Husain et al. (2019)</span>
<span class="ltx_bibblock">
Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc
Brockschmidt.

</span>
<span class="ltx_bibblock">CodeSearchNet Challenge: Evaluating the State of Semantic Code
Search.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.09436</em>, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ippolito et al. (2022)</span>
<span class="ltx_bibblock">
Daphne Ippolito, Ann Yuan, Andy Coenen, and Sehmon Burnam.

</span>
<span class="ltx_bibblock">Creative Writing with an AI-Powered Writing Assistant: Perspectives
from Professional Writers.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.05030</em>, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jamieson &amp; Talwalkar (2016)</span>
<span class="ltx_bibblock">
Kevin Jamieson and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">Non-stochastic Best Arm Identification and Hyperparameter
Optimization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proc. of the Artificial intelligence and statistics
(AISTATS’16)</em>, pp.  240–248, 2016.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al. (2023)</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
Ye Jin Bang, Andrea Madotto, and Pascale Fung.

</span>
<span class="ltx_bibblock">Survey of Hallucination in Natural Language Generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, 55:1–38, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimi Mahabadi et al. (2021)</span>
<span class="ltx_bibblock">
Rabeeh Karimi Mahabadi, James Henderson, and Sebastian Ruder.

</span>
<span class="ltx_bibblock">Compacter: Efficient Low-Rank Hypercomplex Adapter Layers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’21)</em>, volume 34, pp.  1022–1035, 2021.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kočiskỳ et al. (2018)</span>
<span class="ltx_bibblock">
Tomáš Kočiskỳ, Jonathan Schwarz, Phil Blunsom, Chris Dyer,
Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette.

</span>
<span class="ltx_bibblock">The NarrativeQA Reading Comprehension Challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
6:317–328, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečný et al. (2016)</span>
<span class="ltx_bibblock">
Jakub Konečný, H. Brendan McMahan, Daniel Ramage, and Peter
Richtárik.

</span>
<span class="ltx_bibblock">Federated Optimization: Distributed Machine Learning for On-Device
Intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.02527</em>, 2016.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
Kenton Lee, et al.

</span>
<span class="ltx_bibblock">Natural Questions: A Benchmark for Question Answering Research.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:453–466, 2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et al. (2022)</span>
<span class="ltx_bibblock">
Fan Lai, Yinwei Dai, Sanjay Singapuram, Jiachen Liu, Xiangfeng Zhu, Harsha
Madhyastha, and Mosharaf Chowdhury.

</span>
<span class="ltx_bibblock">FedScale: Benchmarking Model and System Performance of Federated
Learning at Scale.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Machine Learning
(ICML’22)</em>, volume 162, pp.  11814–11827, 2022.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2022)</span>
<span class="ltx_bibblock">
Mina Lee, Percy Liang, and Qian Yang.

</span>
<span class="ltx_bibblock">CoAuthor: Designing a Human-AI Collaborative Writing Dataset for
Exploring Language Model Capabilities.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proc. of the CHI Conference on Human Factors in Computing
Systems (CHI’22)</em>, 2022.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lester et al. (2021)</span>
<span class="ltx_bibblock">
Brian Lester, Rami Al-Rfou, and Noah Constant.

</span>
<span class="ltx_bibblock">The Power of Scale for Parameter-Efficient Prompt Tuning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proc. of the Conference on Empirical Methods in Natural
Language Processing (EMNLP’21)</em>, pp.  3045–3059, 2021.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2021)</span>
<span class="ltx_bibblock">
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith.

</span>
<span class="ltx_bibblock">Ditto: Fair and Robust Federated Learning Through Personalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Machine Learning
(ICML’21)</em>, volume 139, pp.  6357–6368, 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li &amp; Liang (2021)</span>
<span class="ltx_bibblock">
Xiang Lisa Li and Percy Liang.

</span>
<span class="ltx_bibblock">Prefix-Tuning: Optimizing Continuous Prompts for Generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proc. of the Annual Meeting of the Association for
Computational Linguistics and the International Joint Conference on Natural
Language Processing (ACL-IJCNLP’21)</em>, pp.  4582–4597, 2021.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2022)</span>
<span class="ltx_bibblock">
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu,
Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar,
et al.

</span>
<span class="ltx_bibblock">Holistic Evaluation of Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.09110</em>, 2022.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2021)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">TruthfulQA: Measuring How Models Mimic Human Falsehoods.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.07958</em>, 2021.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021a)</span>
<span class="ltx_bibblock">
Xiao Liu, Kaixuan Ji, Yicheng Fu, Zhengxiao Du, Zhilin Yang, and Jie Tang.

</span>
<span class="ltx_bibblock">P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning
Universally Across Scales and Tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.07602</em>, 2021a.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021b)</span>
<span class="ltx_bibblock">
Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and
Jie Tang.

</span>
<span class="ltx_bibblock">GPT Understands, Too.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.10385</em>, 2021b.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">RoBERTa: A Robustly Optimized BERT Pretraining Approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maas et al. (2011)</span>
<span class="ltx_bibblock">
Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and
Christopher Potts.

</span>
<span class="ltx_bibblock">Learning Word Vectors for Sentiment Analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proc. of the Annual Meeting of the Association for
Computational Linguistics: Human Language Technologies (AMACL’11)</em>, pp. 142–150, 2011.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mangrulkar et al. (2022)</span>
<span class="ltx_bibblock">
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, and Sayak
Paul.

</span>
<span class="ltx_bibblock">PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/huggingface/peft" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/peft</a>, 2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise
Agüera y Arcas.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from Decentralized
Data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proc. of the Artificial intelligence and statistics
(AISTATS’17)</em>, pp.  1273–1282, 2017.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Micikevicius et al. (2018)</span>
<span class="ltx_bibblock">
Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen,
David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh
Venkatesh, et al.

</span>
<span class="ltx_bibblock">Mixed Precision Training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Learning
Representations (ICLR’18)</em>, 2018.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mihaylov et al. (2018)</span>
<span class="ltx_bibblock">
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book
Question Answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1809.02789</em>, 2018.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narayan et al. (2018)</span>
<span class="ltx_bibblock">
Shashi Narayan, Shay B. Cohen, and Mirella Lapata.

</span>
<span class="ltx_bibblock">Don’t Give Me the Details, Just the Summary! Topic-Aware
Convolutional Neural Networks for Extreme Summarization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proc. of the Conference on Empirical Methods in Natural
Language Processing (EMNLP’18)</em>, pp.  1797–1807, 2018.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Introducing ChatGPT, 2022.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et al. (2019)</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al.

</span>
<span class="ltx_bibblock">PyTorch: An Imperative Style, High-Performance Deep Learning
Library.

</span>
<span class="ltx_bibblock">In <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’19)</em>, pp.  8024–8035, 2019.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patil et al. (2023)</span>
<span class="ltx_bibblock">
Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez.

</span>
<span class="ltx_bibblock">Gorilla: Large Language Model Connected with Massive APIs.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.15334</em>, 2023.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peters et al. (2018)</span>
<span class="ltx_bibblock">
Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
Kenton Lee, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Deep Contextualized Word Representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Proc. of North American Chapter of the Association for
Computational Linguistics (NAACL-HLT’18)</em>, pp.  2227–2237, 2018.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfeiffer et al. (2020a)</span>
<span class="ltx_bibblock">
Jonas Pfeiffer, Aishwarya Kamath, Andreas Rücklé, Kyunghyun Cho, and
Iryna Gurevych.

</span>
<span class="ltx_bibblock">AdapterFusion: Non-Destructive Task Composition for Transfer
Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.00247</em>, 2020a.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfeiffer et al. (2020b)</span>
<span class="ltx_bibblock">
Jonas Pfeiffer, Andreas Rücklé, Clifton Poth, Aishwarya Kamath, Ivan
Vulić, Sebastian Ruder, Kyunghyun Cho, and Iryna Gurevych.

</span>
<span class="ltx_bibblock">AdapterHub: A Framework for Adapting Transformers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Conference on Empirical Methods in
Natural Language Processing: Systems Demonstrations (EMNLP’20)</em>, pp. 46–54, 2020b.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfeiffer et al. (2020c)</span>
<span class="ltx_bibblock">
Jonas Pfeiffer, Ivan Vulić, Iryna Gurevych, and Sebastian Ruder.

</span>
<span class="ltx_bibblock">MAD-X: An Adapter-Based Framework for Multi-Task
Cross-Lingual Transfer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Proc. of the Conference on Empirical Methods in Natural
Language Processing (EMNLP’20)</em>, pp.  7654–7673, 2020c.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et al. (2023)</span>
<span class="ltx_bibblock">
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin,
Xin Cong, Xiangru Tang, Bill Qian, et al.

</span>
<span class="ltx_bibblock">ToolLLM: Facilitating Large Language Models to Master 16000+
Real-world APIs.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.16789</em>, 2023.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford &amp; Narasimhan (2018)</span>
<span class="ltx_bibblock">
Alec Radford and Karthik Narasimhan.

</span>
<span class="ltx_bibblock">Improving Language Understanding by Generative Pre-Training.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.

</span>
<span class="ltx_bibblock">Language Models are Unsupervised Multitask Learners.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasley et al. (2020)</span>
<span class="ltx_bibblock">
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.

</span>
<span class="ltx_bibblock">DeepSpeed: System Optimizations Enable Training Deep Learning Models
with Over 100 Billion Parameters.

</span>
<span class="ltx_bibblock">In <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Proc. of the ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD’20)</em>, pp.  3505–3506, 2020.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. (2021)</span>
<span class="ltx_bibblock">
Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase,
Shuangyang Yang, Minjia Zhang, Dong Li, and Yuxiong He.

</span>
<span class="ltx_bibblock">ZeRO-Offload: Democratizing Billion-Scale Model Training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Proc. of the USENIX Annual Technical Conference (USENIX
ATC’21)</em>, pp.  551–564, 2021.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruebsamen (2023)</span>
<span class="ltx_bibblock">
Gene Ruebsamen.

</span>
<span class="ltx_bibblock">Cleaned Alpaca Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/gururise/AlpacaDataCleaned" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/gururise/AlpacaDataCleaned</a>, 2023.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryffel et al. (2018)</span>
<span class="ltx_bibblock">
Théo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason V. Mancuso,
Daniel Rueckert, and Jonathan Passerat-Palmbach.

</span>
<span class="ltx_bibblock">A generic framework for privacy preserving deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.04017</em>, 2018.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et al. (2022)</span>
<span class="ltx_bibblock">
Teven Le Scao, Angela Fan, Christopher Akiki, et al.

</span>
<span class="ltx_bibblock">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.05100</em>, 2022.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">See et al. (2017)</span>
<span class="ltx_bibblock">
Abigail See, Peter J. Liu, and Christopher D. Manning.

</span>
<span class="ltx_bibblock">Get To The Point: Summarization with Pointer-Generator Networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">Proc. of the Annual Meeting of the Association for
Computational Linguistics (AMACL’17)</em>, pp.  1073–1083, 2017.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shahriari et al. (2015)</span>
<span class="ltx_bibblock">
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas.

</span>
<span class="ltx_bibblock">Taking the Human Out of the Loop: A Review of Bayesian
Optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 104(1):148–175,
2015.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">T Dinh et al. (2020)</span>
<span class="ltx_bibblock">
Canh T Dinh, Nguyen Tran, and Josh Nguyen.

</span>
<span class="ltx_bibblock">Personalized Federated Learning with Moreau Envelopes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’20)</em>, volume 33, pp.  21394–21405, 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. (2022)</span>
<span class="ltx_bibblock">
Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang.

</span>
<span class="ltx_bibblock">Towards Personalized Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>,
pp.  1–17, 2022.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford Alpaca: An Instruction-following LLaMA model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, et al.

</span>
<span class="ltx_bibblock">LLaMA: Open and Efficient Foundation Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Zhen Wang, Weirui Kuang, Yuexiang Xie, Liuyi Yao, Yaliang Li, Bolin Ding, and
Jingren Zhou.

</span>
<span class="ltx_bibblock">FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient
Package for Federated Graph Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">Proc. of the ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (KDD’22)</em>, 2022.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Zhen Wang, Weirui Kuang, Ce Zhang, Bolin Ding, and Yaliang Li.

</span>
<span class="ltx_bibblock">FedHPO-Bench: A Benchmark Suite for Federated Hyperparameter
Optimization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Machine Learning
(ICML’23)</em>, pp.  35908–35948, 2023.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V
Le, Denny Zhou, et al.

</span>
<span class="ltx_bibblock">Chain-of-Thought Prompting Elicits Reasoning in Large Language
Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’22)</em>, volume 35, pp.  24824–24837, 2022.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et al. (2020)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander M. Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-Art Natural Language Processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">Proc. of the Conference on Empirical Methods in Natural
Language Processing (EMNLP’20)</em>, pp.  38–45, 2020.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Chenfei Wu, Sheng-Kai Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan
Duan.

</span>
<span class="ltx_bibblock">Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation
Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.04671</em>, 2023.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2020)</span>
<span class="ltx_bibblock">
Yuncheng Wu, Shaofeng Cai, Xiaokui Xiao, Gang Chen, and Beng Chin Ooi.

</span>
<span class="ltx_bibblock">Privacy preserving vertical federated learning for tree-based models.

</span>
<span class="ltx_bibblock"><em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">PVLDB</em>, 13:2090–2103, 2020.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. (2023)</span>
<span class="ltx_bibblock">
Guangxuan Xiao, Ji Lin, and Song Han.

</span>
<span class="ltx_bibblock">Offsite-Tuning: Transfer Learning without Full Model.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.04870</em>, 2023.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2023)</span>
<span class="ltx_bibblock">
Yuexiang Xie, Zhen Wang, Daoyuan Chen, Dawei Gao, Liuyi Yao, Weirui Kuang,
Yaliang Li, Bolin Ding, and Jingren Zhou.

</span>
<span class="ltx_bibblock">FederatedScope: A Flexible Federated Learning Platform for
Heterogeneity.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">PVLDB</em>, 16(5):1059–1072, 2023.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2019)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Yong Cheng, Yan Kang, Tianjian Chen, and Han Yu.

</span>
<span class="ltx_bibblock">Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">Synthesis Lectures on Artificial Intelligence and Machine
Learning</em>, 13:1–207, 2019.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">HellaSwag: Can a Machine Really Finish Your Sentence?

</span>
<span class="ltx_bibblock">In <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Proc. of the Annual Meeting of the Association for
Computational Linguistics (AMACL’19)</em>, 2019.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. (2023)</span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi
Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al.

</span>
<span class="ltx_bibblock">GLM-130B: An Open Bilingual Pre-trained Model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">Proc. of the International Conference on Learning
Representations (ICLR’23)</em>, 2023.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2022)</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al.

</span>
<span class="ltx_bibblock">OPT: Open Pre-trained Transformer Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.01068</em>, 2022.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Xishan Zhang, Shaoli Liu, Rui Zhang, Chang Liu, Di Huang, Shiyi Zhou, Jiaming
Guo, Yu Kang, Qi Guo, Zidong Du, and Yunji Chen.

</span>
<span class="ltx_bibblock">Adaptive Precision Training: Quantify Back Propagation in Neural
Networks with Fixed-point Numbers.

</span>
<span class="ltx_bibblock"><em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.00361</em>, 2019.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.

</span>
<span class="ltx_bibblock">A Survey of Large Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.18223</em>, 2023.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2021)</span>
<span class="ltx_bibblock">
Yi Zhou, Parikshit Ram, Theodoros Salonidis, Nathalie Baracaldo Angel, Horst
Samulowitz, and Heiko Ludwig.

</span>
<span class="ltx_bibblock">FLoRA: Single-shot Hyper-parameter Optimization for Federated
Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Proc. of the Advances in Neural Information Processing
Systems (NeurIPS’21)</em>, 2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Fine-tuning Dataset description</h3>

<div id="A1.SS1.p1" class="ltx_para ltx_noindent">
<p id="A1.SS1.p1.1" class="ltx_p">In this section, we describe the fine-tuning datasets curated in <span id="A1.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">FS-LLM</span>, and summarize the statistics and information in Table <a href="#A1.T6" title="Table 6 ‣ A.1 Fine-tuning Dataset description ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
These datasets are derived from existing and widely used fine-tuning datasets that cover diverse domains, such as code, natural language, dialogues, and math problems.
The curated fine-tuning datasets exhibit different degrees of heterogeneity across clients, which pose various challenges and opportunities for fine-tuning LLMs in FL.
We describe the construction and characteristics of each dataset in detail below and illustrate their scenarios.
We will constantly adopt new datasets for fine-tuning LLMs in <span id="A1.SS1.p1.1.2" class="ltx_text ltx_font_smallcaps">FS-LLM</span>.</p>
</div>
<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Statistics and information of the fine-tuning datasets.</figcaption>
<div id="A1.T6.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:119.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.3pt,3.7pt) scale(0.941503115938111,0.941503115938111) ;">
<table id="A1.T6.6.6" class="ltx_tabular ltx_align_middle">
<tr id="A1.T6.6.6.7" class="ltx_tr">
<td id="A1.T6.6.6.7.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Name</td>
<td id="A1.T6.6.6.7.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Client</td>
<td id="A1.T6.6.6.7.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Sample</td>
<td id="A1.T6.6.6.7.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Split</td>
<td id="A1.T6.6.6.7.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Domain</td>
<td id="A1.T6.6.6.7.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Evaluation Dataset</td>
</tr>
<tr id="A1.T6.1.1.1" class="ltx_tr">
<td id="A1.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.1.1.1.2.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span></td>
<td id="A1.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9</td>
<td id="A1.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<math id="A1.T6.1.1.1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T6.1.1.1.1.m1.1a"><mo id="A1.T6.1.1.1.1.m1.1.1" xref="A1.T6.1.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T6.1.1.1.1.m1.1b"><csymbol cd="latexml" id="A1.T6.1.1.1.1.m1.1.1.cmml" xref="A1.T6.1.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.1.1.1.1.m1.1c">\sim</annotation></semantics></math>8.0k</td>
<td id="A1.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Meta</td>
<td id="A1.T6.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Code Generation</td>
<td id="A1.T6.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.1.1.1.6.1" class="ltx_text ltx_font_italic">HumanEval</span></td>
</tr>
<tr id="A1.T6.2.2.2" class="ltx_tr">
<td id="A1.T6.2.2.2.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.2.2.2.2.1" class="ltx_text ltx_font_italic">Fed-Dolly</span></td>
<td id="A1.T6.2.2.2.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8</td>
<td id="A1.T6.2.2.2.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<math id="A1.T6.2.2.2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T6.2.2.2.1.m1.1a"><mo id="A1.T6.2.2.2.1.m1.1.1" xref="A1.T6.2.2.2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T6.2.2.2.1.m1.1b"><csymbol cd="latexml" id="A1.T6.2.2.2.1.m1.1.1.cmml" xref="A1.T6.2.2.2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.2.2.2.1.m1.1c">\sim</annotation></semantics></math>15.0k</td>
<td id="A1.T6.2.2.2.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Meta</td>
<td id="A1.T6.2.2.2.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Generic Language</td>
<td id="A1.T6.2.2.2.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.2.2.2.6.1" class="ltx_text ltx_font_italic">HELM</span></td>
</tr>
<tr id="A1.T6.3.3.3" class="ltx_tr">
<td id="A1.T6.3.3.3.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.3.3.3.2.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span></td>
<td id="A1.T6.3.3.3.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">3</td>
<td id="A1.T6.3.3.3.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<math id="A1.T6.3.3.3.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T6.3.3.3.1.m1.1a"><mo id="A1.T6.3.3.3.1.m1.1.1" xref="A1.T6.3.3.3.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T6.3.3.3.1.m1.1b"><csymbol cd="latexml" id="A1.T6.3.3.3.1.m1.1.1.cmml" xref="A1.T6.3.3.3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.3.3.3.1.m1.1c">\sim</annotation></semantics></math>7.5k</td>
<td id="A1.T6.3.3.3.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">IID</td>
<td id="A1.T6.3.3.3.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">CoT</td>
<td id="A1.T6.3.3.3.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.3.3.3.6.1" class="ltx_text ltx_font_italic">GSM8K-test</span></td>
</tr>
<tr id="A1.T6.4.4.4" class="ltx_tr">
<td id="A1.T6.4.4.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.4.4.4.2.1" class="ltx_text ltx_font_italic">Fed-CodeSearchNet</span></td>
<td id="A1.T6.4.4.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">6</td>
<td id="A1.T6.4.4.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<math id="A1.T6.4.4.4.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T6.4.4.4.1.m1.1a"><mo id="A1.T6.4.4.4.1.m1.1.1" xref="A1.T6.4.4.4.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T6.4.4.4.1.m1.1b"><csymbol cd="latexml" id="A1.T6.4.4.4.1.m1.1.1.cmml" xref="A1.T6.4.4.4.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.4.4.4.1.m1.1c">\sim</annotation></semantics></math>1880.8k</td>
<td id="A1.T6.4.4.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Meta</td>
<td id="A1.T6.4.4.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Code Generation</td>
<td id="A1.T6.4.4.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.4.4.4.6.1" class="ltx_text ltx_font_italic">HumanEval</span></td>
</tr>
<tr id="A1.T6.5.5.5" class="ltx_tr">
<td id="A1.T6.5.5.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.5.5.5.2.1" class="ltx_text ltx_font_italic">Alpaca</span></td>
<td id="A1.T6.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">-</td>
<td id="A1.T6.5.5.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<math id="A1.T6.5.5.5.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T6.5.5.5.1.m1.1a"><mo id="A1.T6.5.5.5.1.m1.1.1" xref="A1.T6.5.5.5.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T6.5.5.5.1.m1.1b"><csymbol cd="latexml" id="A1.T6.5.5.5.1.m1.1.1.cmml" xref="A1.T6.5.5.5.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.5.5.5.1.m1.1c">\sim</annotation></semantics></math>52.0k</td>
<td id="A1.T6.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">-</td>
<td id="A1.T6.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Generic Language</td>
<td id="A1.T6.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.5.5.5.6.1" class="ltx_text ltx_font_italic">HELM</span></td>
</tr>
<tr id="A1.T6.6.6.6" class="ltx_tr">
<td id="A1.T6.6.6.6.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.6.6.6.2.1" class="ltx_text ltx_font_italic">CleanedAlpaca</span></td>
<td id="A1.T6.6.6.6.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">-</td>
<td id="A1.T6.6.6.6.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<math id="A1.T6.6.6.6.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T6.6.6.6.1.m1.1a"><mo id="A1.T6.6.6.6.1.m1.1.1" xref="A1.T6.6.6.6.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T6.6.6.6.1.m1.1b"><csymbol cd="latexml" id="A1.T6.6.6.6.1.m1.1.1.cmml" xref="A1.T6.6.6.6.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.6.6.6.1.m1.1c">\sim</annotation></semantics></math>51.8k</td>
<td id="A1.T6.6.6.6.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">-</td>
<td id="A1.T6.6.6.6.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">Generic Language</td>
<td id="A1.T6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T6.6.6.6.6.1" class="ltx_text ltx_font_italic">HELM</span></td>
</tr>
</table>
</span></div>
</figure>
<section id="A1.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.1 </span>Federated fine-tuning dataset</h4>

<div id="A1.SS1.SSS1.p1" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS1.p1.1" class="ltx_p">The federated fine-tuning datasets are a collection of curated datasets that we adopt based on the meta-information or some distribution of the original corpora.
Users can directly use them for federated fine-tuning LLMs.</p>
</div>
<div id="A1.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS1.p2.1" class="ltx_p"><span id="A1.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Fed-CodeAlpaca</span> is a federated version of <span id="A1.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_italic">CodeAlpaca</span> <cite class="ltx_cite ltx_citemacro_citep">(Chaudhary, <a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>, a code dataset that contains ten programming languages, including C, C#, C++, Go, Java, PHP, Pascal, Python, Scale, and X86-64 Assemble. We exclude the X86-64 Assembly samples, as they are very scarce in the original corpora. Then, we split the remaining samples into nine subsets based on the language category and assign each subset to one client.</p>
</div>
<div id="A1.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS1.p3.1" class="ltx_p"><span id="A1.SS1.SSS1.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Fed-Dolly</span> is a federated corpus dataset derived from <span id="A1.SS1.SSS1.p3.1.2" class="ltx_text ltx_font_italic">Databricks-dolly-15k</span> <cite class="ltx_cite ltx_citemacro_citep">(Conover et al., <a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>, which comprises eight categories of NLP tasks: brainstorming, classification, closed QA, creative writing, general QA, information extraction, open QA, and summarization. The corpora within each client only belong to one category.</p>
</div>
<div id="A1.SS1.SSS1.p4" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS1.p4.1" class="ltx_p"><span id="A1.SS1.SSS1.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Fed-GSM8K-3</span> is built from <span id="A1.SS1.SSS1.p4.1.2" class="ltx_text ltx_font_italic">GSM8K</span> <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>, which is a mathematical fine-tuning dataset consisting of 7.5K training problems and 1K test problems. We split the training problems into three subsets by the uniform splitter, and assign each subset to one client.</p>
</div>
<div id="A1.SS1.SSS1.p5" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS1.p5.1" class="ltx_p">In addition to the three datasets introduced in the main text, we also curate another code dataset, <span id="A1.SS1.SSS1.p5.1.1" class="ltx_text ltx_font_italic">Fed-CodeSearchNet</span>, as an alternative to <span id="A1.SS1.SSS1.p5.1.2" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span>.</p>
</div>
<div id="A1.SS1.SSS1.p6" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS1.p6.1" class="ltx_p"><span id="A1.SS1.SSS1.p6.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Fed-CodeSearchNet</span> is built from <span id="A1.SS1.SSS1.p6.1.2" class="ltx_text ltx_font_italic">CodeSearchNet</span> <cite class="ltx_cite ltx_citemacro_citep">(Husain et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>, which is a large-scale code dataset of functions and their associated documentation for six programming languages: Go, Java, JavaScript, PHP, Python, and Ruby. The data are extracted from open-source projects on GitHub.
Similar to <span id="A1.SS1.SSS1.p6.1.3" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span>, we split the samples into six subsets according to the language category and allocate each subset to one client.</p>
</div>
</section>
<section id="A1.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.2 </span>Centralized fine-tuning dataset</h4>

<div id="A1.SS1.SSS2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS2.p1.1" class="ltx_p">The centralized fine-tuning datasets are a collection of corpora that we have collected from the Internet without any prior partitioning.
Users can use our provided splitters to customize the data partition according to different criteria, such as heterogeneity, number balance, root verb, etc.</p>
</div>
<div id="A1.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS2.p2.1" class="ltx_p"><span id="A1.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Alpaca</span> <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite> is a fine-tuning dataset containing natural language questions and responses for various NLP tasks such as text generation, translation, and open QA. The dataset covers a wide range of domains, such as math, text processing, code generation, etc.</p>
</div>
<div id="A1.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p id="A1.SS1.SSS2.p3.1" class="ltx_p"><span id="A1.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">CleanedAlpaca</span> <cite class="ltx_cite ltx_citemacro_citep">(Ruebsamen, <a href="#bib.bib72" title="" class="ltx_ref">2023</a>)</cite> is a fine-tuning dataset that improves the quality and usefulness of the original <span id="A1.SS1.SSS2.p3.1.2" class="ltx_text ltx_font_italic">Alpaca</span> dataset. It is expected to be more reliable and consistent for fine-tuning LLMs.</p>
</div>
</section>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Evaluation task description</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS2.p1.1" class="ltx_p">We believe that fine-tuning LLMs should either improve their generic language capabilities or improve their domain-specific capabilities for one particular downstream task.
Thus, we use three different evaluation tasks for benchmarking fine-tuned LLMs.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para ltx_noindent">
<p id="A1.SS2.p2.2" class="ltx_p"><span id="A1.SS2.p2.2.1" class="ltx_text ltx_font_bold">Evaluation task for code generation capability.</span> <span id="A1.SS2.p2.2.2" class="ltx_text ltx_font_italic">HumanEval</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite> is to measure whether the code generated by LLMs is correct or not.
It contains an evaluation dataset and an accordingly metric Pass@k score for assessing the performance of LLMs on code generation capability.
Specifically, the model generates <math id="A1.SS2.p2.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="A1.SS2.p2.1.m1.1a"><mi id="A1.SS2.p2.1.m1.1.1" xref="A1.SS2.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.1.m1.1b"><ci id="A1.SS2.p2.1.m1.1.1.cmml" xref="A1.SS2.p2.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.1.m1.1c">m</annotation></semantics></math> samples per task and denotes <math id="A1.SS2.p2.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="A1.SS2.p2.2.m2.1a"><mi id="A1.SS2.p2.2.m2.1.1" xref="A1.SS2.p2.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.2.m2.1b"><ci id="A1.SS2.p2.2.m2.1.1.cmml" xref="A1.SS2.p2.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.2.m2.1c">c</annotation></semantics></math> as the number of correct samples generated by LLM. Then</p>
<table id="A1.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.Ex1.m1.3" class="ltx_Math" alttext="\text{Pass@}\mathrm{k}:=\mathbb{E}_{\text{Problems}}\left[1-\frac{\left(\begin{array}[]{c}m-c\\
k\end{array}\right)}{\left(\begin{array}[]{c}m\\
k\end{array}\right)}\right]\text{.}" display="block"><semantics id="A1.Ex1.m1.3a"><mrow id="A1.Ex1.m1.3.3" xref="A1.Ex1.m1.3.3.cmml"><mrow id="A1.Ex1.m1.3.3.3" xref="A1.Ex1.m1.3.3.3.cmml"><mtext id="A1.Ex1.m1.3.3.3.2" xref="A1.Ex1.m1.3.3.3.2a.cmml">Pass@</mtext><mo lspace="0em" rspace="0em" id="A1.Ex1.m1.3.3.3.1" xref="A1.Ex1.m1.3.3.3.1.cmml">​</mo><mi mathvariant="normal" id="A1.Ex1.m1.3.3.3.3" xref="A1.Ex1.m1.3.3.3.3.cmml">k</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="A1.Ex1.m1.3.3.2" xref="A1.Ex1.m1.3.3.2.cmml">:=</mo><mrow id="A1.Ex1.m1.3.3.1" xref="A1.Ex1.m1.3.3.1.cmml"><msub id="A1.Ex1.m1.3.3.1.3" xref="A1.Ex1.m1.3.3.1.3.cmml"><mi id="A1.Ex1.m1.3.3.1.3.2" xref="A1.Ex1.m1.3.3.1.3.2.cmml">𝔼</mi><mtext id="A1.Ex1.m1.3.3.1.3.3" xref="A1.Ex1.m1.3.3.1.3.3a.cmml">Problems</mtext></msub><mo lspace="0em" rspace="0em" id="A1.Ex1.m1.3.3.1.2" xref="A1.Ex1.m1.3.3.1.2.cmml">​</mo><mrow id="A1.Ex1.m1.3.3.1.1.1" xref="A1.Ex1.m1.3.3.1.1.2.cmml"><mo id="A1.Ex1.m1.3.3.1.1.1.2" xref="A1.Ex1.m1.3.3.1.1.2.1.cmml">[</mo><mrow id="A1.Ex1.m1.3.3.1.1.1.1" xref="A1.Ex1.m1.3.3.1.1.1.1.cmml"><mn id="A1.Ex1.m1.3.3.1.1.1.1.2" xref="A1.Ex1.m1.3.3.1.1.1.1.2.cmml">1</mn><mo id="A1.Ex1.m1.3.3.1.1.1.1.1" xref="A1.Ex1.m1.3.3.1.1.1.1.1.cmml">−</mo><mfrac id="A1.Ex1.m1.2.2" xref="A1.Ex1.m1.2.2.cmml"><mrow id="A1.Ex1.m1.1.1.1.3" xref="A1.Ex1.m1.1.1.1.1.cmml"><mo id="A1.Ex1.m1.1.1.1.3.1" xref="A1.Ex1.m1.1.1.1.1.cmml">(</mo><mtable rowspacing="0pt" id="A1.Ex1.m1.1.1.1.1" xref="A1.Ex1.m1.1.1.1.1.cmml"><mtr id="A1.Ex1.m1.1.1.1.1a" xref="A1.Ex1.m1.1.1.1.1.cmml"><mtd id="A1.Ex1.m1.1.1.1.1b" xref="A1.Ex1.m1.1.1.1.1.cmml"><mrow id="A1.Ex1.m1.1.1.1.1.1.1.1" xref="A1.Ex1.m1.1.1.1.1.1.1.1.cmml"><mi id="A1.Ex1.m1.1.1.1.1.1.1.1.2" xref="A1.Ex1.m1.1.1.1.1.1.1.1.2.cmml">m</mi><mo id="A1.Ex1.m1.1.1.1.1.1.1.1.1" xref="A1.Ex1.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="A1.Ex1.m1.1.1.1.1.1.1.1.3" xref="A1.Ex1.m1.1.1.1.1.1.1.1.3.cmml">c</mi></mrow></mtd></mtr><mtr id="A1.Ex1.m1.1.1.1.1c" xref="A1.Ex1.m1.1.1.1.1.cmml"><mtd id="A1.Ex1.m1.1.1.1.1d" xref="A1.Ex1.m1.1.1.1.1.cmml"><mi id="A1.Ex1.m1.1.1.1.1.2.1.1" xref="A1.Ex1.m1.1.1.1.1.2.1.1.cmml">k</mi></mtd></mtr></mtable><mo id="A1.Ex1.m1.1.1.1.3.2" xref="A1.Ex1.m1.1.1.1.1.cmml">)</mo></mrow><mrow id="A1.Ex1.m1.2.2.2.3" xref="A1.Ex1.m1.2.2.2.1.cmml"><mo id="A1.Ex1.m1.2.2.2.3.1" xref="A1.Ex1.m1.2.2.2.1.cmml">(</mo><mtable rowspacing="0pt" id="A1.Ex1.m1.2.2.2.1" xref="A1.Ex1.m1.2.2.2.1.cmml"><mtr id="A1.Ex1.m1.2.2.2.1a" xref="A1.Ex1.m1.2.2.2.1.cmml"><mtd id="A1.Ex1.m1.2.2.2.1b" xref="A1.Ex1.m1.2.2.2.1.cmml"><mi id="A1.Ex1.m1.2.2.2.1.1.1.1" xref="A1.Ex1.m1.2.2.2.1.1.1.1.cmml">m</mi></mtd></mtr><mtr id="A1.Ex1.m1.2.2.2.1c" xref="A1.Ex1.m1.2.2.2.1.cmml"><mtd id="A1.Ex1.m1.2.2.2.1d" xref="A1.Ex1.m1.2.2.2.1.cmml"><mi id="A1.Ex1.m1.2.2.2.1.2.1.1" xref="A1.Ex1.m1.2.2.2.1.2.1.1.cmml">k</mi></mtd></mtr></mtable><mo id="A1.Ex1.m1.2.2.2.3.2" xref="A1.Ex1.m1.2.2.2.1.cmml">)</mo></mrow></mfrac></mrow><mo id="A1.Ex1.m1.3.3.1.1.1.3" xref="A1.Ex1.m1.3.3.1.1.2.1.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="A1.Ex1.m1.3.3.1.2a" xref="A1.Ex1.m1.3.3.1.2.cmml">​</mo><mtext id="A1.Ex1.m1.3.3.1.4" xref="A1.Ex1.m1.3.3.1.4a.cmml">.</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex1.m1.3b"><apply id="A1.Ex1.m1.3.3.cmml" xref="A1.Ex1.m1.3.3"><csymbol cd="latexml" id="A1.Ex1.m1.3.3.2.cmml" xref="A1.Ex1.m1.3.3.2">assign</csymbol><apply id="A1.Ex1.m1.3.3.3.cmml" xref="A1.Ex1.m1.3.3.3"><times id="A1.Ex1.m1.3.3.3.1.cmml" xref="A1.Ex1.m1.3.3.3.1"></times><ci id="A1.Ex1.m1.3.3.3.2a.cmml" xref="A1.Ex1.m1.3.3.3.2"><mtext id="A1.Ex1.m1.3.3.3.2.cmml" xref="A1.Ex1.m1.3.3.3.2">Pass@</mtext></ci><ci id="A1.Ex1.m1.3.3.3.3.cmml" xref="A1.Ex1.m1.3.3.3.3">k</ci></apply><apply id="A1.Ex1.m1.3.3.1.cmml" xref="A1.Ex1.m1.3.3.1"><times id="A1.Ex1.m1.3.3.1.2.cmml" xref="A1.Ex1.m1.3.3.1.2"></times><apply id="A1.Ex1.m1.3.3.1.3.cmml" xref="A1.Ex1.m1.3.3.1.3"><csymbol cd="ambiguous" id="A1.Ex1.m1.3.3.1.3.1.cmml" xref="A1.Ex1.m1.3.3.1.3">subscript</csymbol><ci id="A1.Ex1.m1.3.3.1.3.2.cmml" xref="A1.Ex1.m1.3.3.1.3.2">𝔼</ci><ci id="A1.Ex1.m1.3.3.1.3.3a.cmml" xref="A1.Ex1.m1.3.3.1.3.3"><mtext mathsize="70%" id="A1.Ex1.m1.3.3.1.3.3.cmml" xref="A1.Ex1.m1.3.3.1.3.3">Problems</mtext></ci></apply><apply id="A1.Ex1.m1.3.3.1.1.2.cmml" xref="A1.Ex1.m1.3.3.1.1.1"><csymbol cd="latexml" id="A1.Ex1.m1.3.3.1.1.2.1.cmml" xref="A1.Ex1.m1.3.3.1.1.1.2">delimited-[]</csymbol><apply id="A1.Ex1.m1.3.3.1.1.1.1.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1"><minus id="A1.Ex1.m1.3.3.1.1.1.1.1.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1.1"></minus><cn type="integer" id="A1.Ex1.m1.3.3.1.1.1.1.2.cmml" xref="A1.Ex1.m1.3.3.1.1.1.1.2">1</cn><apply id="A1.Ex1.m1.2.2.cmml" xref="A1.Ex1.m1.2.2"><divide id="A1.Ex1.m1.2.2.3.cmml" xref="A1.Ex1.m1.2.2"></divide><matrix id="A1.Ex1.m1.1.1.1.1.cmml" xref="A1.Ex1.m1.1.1.1.3"><matrixrow id="A1.Ex1.m1.1.1.1.1a.cmml" xref="A1.Ex1.m1.1.1.1.3"><apply id="A1.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="A1.Ex1.m1.1.1.1.1.1.1.1"><minus id="A1.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="A1.Ex1.m1.1.1.1.1.1.1.1.1"></minus><ci id="A1.Ex1.m1.1.1.1.1.1.1.1.2.cmml" xref="A1.Ex1.m1.1.1.1.1.1.1.1.2">𝑚</ci><ci id="A1.Ex1.m1.1.1.1.1.1.1.1.3.cmml" xref="A1.Ex1.m1.1.1.1.1.1.1.1.3">𝑐</ci></apply></matrixrow><matrixrow id="A1.Ex1.m1.1.1.1.1b.cmml" xref="A1.Ex1.m1.1.1.1.3"><ci id="A1.Ex1.m1.1.1.1.1.2.1.1.cmml" xref="A1.Ex1.m1.1.1.1.1.2.1.1">𝑘</ci></matrixrow></matrix><matrix id="A1.Ex1.m1.2.2.2.1.cmml" xref="A1.Ex1.m1.2.2.2.3"><matrixrow id="A1.Ex1.m1.2.2.2.1a.cmml" xref="A1.Ex1.m1.2.2.2.3"><ci id="A1.Ex1.m1.2.2.2.1.1.1.1.cmml" xref="A1.Ex1.m1.2.2.2.1.1.1.1">𝑚</ci></matrixrow><matrixrow id="A1.Ex1.m1.2.2.2.1b.cmml" xref="A1.Ex1.m1.2.2.2.3"><ci id="A1.Ex1.m1.2.2.2.1.2.1.1.cmml" xref="A1.Ex1.m1.2.2.2.1.2.1.1">𝑘</ci></matrixrow></matrix></apply></apply></apply><ci id="A1.Ex1.m1.3.3.1.4a.cmml" xref="A1.Ex1.m1.3.3.1.4"><mtext id="A1.Ex1.m1.3.3.1.4.cmml" xref="A1.Ex1.m1.3.3.1.4">.</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex1.m1.3c">\text{Pass@}\mathrm{k}:=\mathbb{E}_{\text{Problems}}\left[1-\frac{\left(\begin{array}[]{c}m-c\\
k\end{array}\right)}{\left(\begin{array}[]{c}m\\
k\end{array}\right)}\right]\text{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A1.SS2.p2.3" class="ltx_p">In practice, we set <math id="A1.SS2.p2.3.m1.1" class="ltx_Math" alttext="m=5" display="inline"><semantics id="A1.SS2.p2.3.m1.1a"><mrow id="A1.SS2.p2.3.m1.1.1" xref="A1.SS2.p2.3.m1.1.1.cmml"><mi id="A1.SS2.p2.3.m1.1.1.2" xref="A1.SS2.p2.3.m1.1.1.2.cmml">m</mi><mo id="A1.SS2.p2.3.m1.1.1.1" xref="A1.SS2.p2.3.m1.1.1.1.cmml">=</mo><mn id="A1.SS2.p2.3.m1.1.1.3" xref="A1.SS2.p2.3.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.3.m1.1b"><apply id="A1.SS2.p2.3.m1.1.1.cmml" xref="A1.SS2.p2.3.m1.1.1"><eq id="A1.SS2.p2.3.m1.1.1.1.cmml" xref="A1.SS2.p2.3.m1.1.1.1"></eq><ci id="A1.SS2.p2.3.m1.1.1.2.cmml" xref="A1.SS2.p2.3.m1.1.1.2">𝑚</ci><cn type="integer" id="A1.SS2.p2.3.m1.1.1.3.cmml" xref="A1.SS2.p2.3.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.3.m1.1c">m=5</annotation></semantics></math> and use the Pass@1 score as the evaluation score, i.e.,</p>
<table id="A1.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.Ex2.m1.1" class="ltx_Math" alttext="\text{Pass@1}:=\mathbb{E}_{\text{Problems}}\left[\frac{c}{5}\right]\text{.}" display="block"><semantics id="A1.Ex2.m1.1a"><mrow id="A1.Ex2.m1.1.2" xref="A1.Ex2.m1.1.2.cmml"><mtext id="A1.Ex2.m1.1.2.2" xref="A1.Ex2.m1.1.2.2a.cmml">Pass@1</mtext><mo lspace="0.278em" rspace="0.278em" id="A1.Ex2.m1.1.2.1" xref="A1.Ex2.m1.1.2.1.cmml">:=</mo><mrow id="A1.Ex2.m1.1.2.3" xref="A1.Ex2.m1.1.2.3.cmml"><msub id="A1.Ex2.m1.1.2.3.2" xref="A1.Ex2.m1.1.2.3.2.cmml"><mi id="A1.Ex2.m1.1.2.3.2.2" xref="A1.Ex2.m1.1.2.3.2.2.cmml">𝔼</mi><mtext id="A1.Ex2.m1.1.2.3.2.3" xref="A1.Ex2.m1.1.2.3.2.3a.cmml">Problems</mtext></msub><mo lspace="0em" rspace="0em" id="A1.Ex2.m1.1.2.3.1" xref="A1.Ex2.m1.1.2.3.1.cmml">​</mo><mrow id="A1.Ex2.m1.1.2.3.3.2" xref="A1.Ex2.m1.1.2.3.3.1.cmml"><mo id="A1.Ex2.m1.1.2.3.3.2.1" xref="A1.Ex2.m1.1.2.3.3.1.1.cmml">[</mo><mfrac id="A1.Ex2.m1.1.1" xref="A1.Ex2.m1.1.1.cmml"><mi id="A1.Ex2.m1.1.1.2" xref="A1.Ex2.m1.1.1.2.cmml">c</mi><mn id="A1.Ex2.m1.1.1.3" xref="A1.Ex2.m1.1.1.3.cmml">5</mn></mfrac><mo id="A1.Ex2.m1.1.2.3.3.2.2" xref="A1.Ex2.m1.1.2.3.3.1.1.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="A1.Ex2.m1.1.2.3.1a" xref="A1.Ex2.m1.1.2.3.1.cmml">​</mo><mtext id="A1.Ex2.m1.1.2.3.4" xref="A1.Ex2.m1.1.2.3.4a.cmml">.</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex2.m1.1b"><apply id="A1.Ex2.m1.1.2.cmml" xref="A1.Ex2.m1.1.2"><csymbol cd="latexml" id="A1.Ex2.m1.1.2.1.cmml" xref="A1.Ex2.m1.1.2.1">assign</csymbol><ci id="A1.Ex2.m1.1.2.2a.cmml" xref="A1.Ex2.m1.1.2.2"><mtext id="A1.Ex2.m1.1.2.2.cmml" xref="A1.Ex2.m1.1.2.2">Pass@1</mtext></ci><apply id="A1.Ex2.m1.1.2.3.cmml" xref="A1.Ex2.m1.1.2.3"><times id="A1.Ex2.m1.1.2.3.1.cmml" xref="A1.Ex2.m1.1.2.3.1"></times><apply id="A1.Ex2.m1.1.2.3.2.cmml" xref="A1.Ex2.m1.1.2.3.2"><csymbol cd="ambiguous" id="A1.Ex2.m1.1.2.3.2.1.cmml" xref="A1.Ex2.m1.1.2.3.2">subscript</csymbol><ci id="A1.Ex2.m1.1.2.3.2.2.cmml" xref="A1.Ex2.m1.1.2.3.2.2">𝔼</ci><ci id="A1.Ex2.m1.1.2.3.2.3a.cmml" xref="A1.Ex2.m1.1.2.3.2.3"><mtext mathsize="70%" id="A1.Ex2.m1.1.2.3.2.3.cmml" xref="A1.Ex2.m1.1.2.3.2.3">Problems</mtext></ci></apply><apply id="A1.Ex2.m1.1.2.3.3.1.cmml" xref="A1.Ex2.m1.1.2.3.3.2"><csymbol cd="latexml" id="A1.Ex2.m1.1.2.3.3.1.1.cmml" xref="A1.Ex2.m1.1.2.3.3.2.1">delimited-[]</csymbol><apply id="A1.Ex2.m1.1.1.cmml" xref="A1.Ex2.m1.1.1"><divide id="A1.Ex2.m1.1.1.1.cmml" xref="A1.Ex2.m1.1.1"></divide><ci id="A1.Ex2.m1.1.1.2.cmml" xref="A1.Ex2.m1.1.1.2">𝑐</ci><cn type="integer" id="A1.Ex2.m1.1.1.3.cmml" xref="A1.Ex2.m1.1.1.3">5</cn></apply></apply><ci id="A1.Ex2.m1.1.2.3.4a.cmml" xref="A1.Ex2.m1.1.2.3.4"><mtext id="A1.Ex2.m1.1.2.3.4.cmml" xref="A1.Ex2.m1.1.2.3.4">.</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex2.m1.1c">\text{Pass@1}:=\mathbb{E}_{\text{Problems}}\left[\frac{c}{5}\right]\text{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="A1.SS2.p3" class="ltx_para ltx_noindent">
<p id="A1.SS2.p3.1" class="ltx_p"><span id="A1.SS2.p3.1.1" class="ltx_text ltx_font_bold">Evaluation task for generic language capability.</span> We adapt <span id="A1.SS2.p3.1.2" class="ltx_text ltx_font_italic">HELM</span> <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite>, including 16 subtasks, in <span id="A1.SS2.p3.1.3" class="ltx_text ltx_font_smallcaps">FS-LLM</span> to evaluate the generic language capability of fine-tuned LLMs.
To be more precise, the subtasks we use are <span id="A1.SS2.p3.1.4" class="ltx_text ltx_font_italic">MMLU</span> <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a href="#bib.bib30" title="" class="ltx_ref">2021b</a>; <a href="#bib.bib29" title="" class="ltx_ref">a</a>)</cite>, <span id="A1.SS2.p3.1.5" class="ltx_text ltx_font_italic">BoolQ</span> <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a href="#bib.bib17" title="" class="ltx_ref">2019</a>)</cite>, <span id="A1.SS2.p3.1.6" class="ltx_text ltx_font_italic">NarrativeQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Kočiskỳ et al., <a href="#bib.bib40" title="" class="ltx_ref">2018</a>)</cite>, <span id="A1.SS2.p3.1.7" class="ltx_text ltx_font_italic">NaturalQuestions (closed-book)</span> <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al., <a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite> , <span id="A1.SS2.p3.1.8" class="ltx_text ltx_font_italic">NaturalQuestions (open-book)</span> <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al., <a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite> , <span id="A1.SS2.p3.1.9" class="ltx_text ltx_font_italic">QuAC</span> <cite class="ltx_cite ltx_citemacro_citep">(Choi et al., <a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite>, <span id="A1.SS2.p3.1.10" class="ltx_text ltx_font_italic">HellaSwag</span> <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a href="#bib.bib90" title="" class="ltx_ref">2019</a>)</cite>, <span id="A1.SS2.p3.1.11" class="ltx_text ltx_font_italic">OpenbookQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Mihaylov et al., <a href="#bib.bib57" title="" class="ltx_ref">2018</a>)</cite>, <span id="A1.SS2.p3.1.12" class="ltx_text ltx_font_italic">TruthfulQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a href="#bib.bib49" title="" class="ltx_ref">2021</a>)</cite>, <span id="A1.SS2.p3.1.13" class="ltx_text ltx_font_italic">MS MARCO (regular)</span> <cite class="ltx_cite ltx_citemacro_citep">(Bajaj et al., <a href="#bib.bib3" title="" class="ltx_ref">2016</a>)</cite>, <span id="A1.SS2.p3.1.14" class="ltx_text ltx_font_italic">MS MARCO (TREC)</span> <cite class="ltx_cite ltx_citemacro_citep">(Bajaj et al., <a href="#bib.bib3" title="" class="ltx_ref">2016</a>)</cite>, <span id="A1.SS2.p3.1.15" class="ltx_text ltx_font_italic">CNN/DailyMail</span> <cite class="ltx_cite ltx_citemacro_citep">(See et al., <a href="#bib.bib75" title="" class="ltx_ref">2017</a>; Hermann et al., <a href="#bib.bib31" title="" class="ltx_ref">2015</a>)</cite>, <span id="A1.SS2.p3.1.16" class="ltx_text ltx_font_italic">XSUM</span> <cite class="ltx_cite ltx_citemacro_citep">(Narayan et al., <a href="#bib.bib58" title="" class="ltx_ref">2018</a>)</cite>, <span id="A1.SS2.p3.1.17" class="ltx_text ltx_font_italic">IMDB</span> <cite class="ltx_cite ltx_citemacro_citep">(Maas et al., <a href="#bib.bib53" title="" class="ltx_ref">2011</a>)</cite>, <span id="A1.SS2.p3.1.18" class="ltx_text ltx_font_italic">CivilComments</span> <cite class="ltx_cite ltx_citemacro_citep">(Borkan et al., <a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite>, and <span id="A1.SS2.p3.1.19" class="ltx_text ltx_font_italic">RAFT</span> <cite class="ltx_cite ltx_citemacro_citep">(Alex et al., <a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite>. For each task, we randomly use 100 samples for evaluation. The evaluation score for <span id="A1.SS2.p3.1.20" class="ltx_text ltx_font_italic">HELM</span> is a mixture of metric scores on these 16 subtasks. Specifically, in <span id="A1.SS2.p3.1.21" class="ltx_text ltx_font_italic">HELM</span>, <span id="A1.SS2.p3.1.22" class="ltx_text ltx_font_italic">MMLU</span>, <span id="A1.SS2.p3.1.23" class="ltx_text ltx_font_italic">BoolQ</span>, <span id="A1.SS2.p3.1.24" class="ltx_text ltx_font_italic">HellaSwag</span>, <span id="A1.SS2.p3.1.25" class="ltx_text ltx_font_italic">OpenbookQA</span>, <span id="A1.SS2.p3.1.26" class="ltx_text ltx_font_italic">TruthfulQA</span>, <span id="A1.SS2.p3.1.27" class="ltx_text ltx_font_italic">IMDB</span>, <span id="A1.SS2.p3.1.28" class="ltx_text ltx_font_italic">CivilComments</span>, and <span id="A1.SS2.p3.1.29" class="ltx_text ltx_font_italic">RAFT</span> use accuracy; <span id="A1.SS2.p3.1.30" class="ltx_text ltx_font_italic">NarrativeQA</span>, <span id="A1.SS2.p3.1.31" class="ltx_text ltx_font_italic">NaturalQuestions (closed-book)</span>, <span id="A1.SS2.p3.1.32" class="ltx_text ltx_font_italic">NaturalQuestions (closed-book)</span>, and <span id="A1.SS2.p3.1.33" class="ltx_text ltx_font_italic">QuAC</span> use F1 score; <span id="A1.SS2.p3.1.34" class="ltx_text ltx_font_italic">CNN/DailyMail</span> and <span id="A1.SS2.p3.1.35" class="ltx_text ltx_font_italic">XSUM</span> use ROUGE-2 score; <span id="A1.SS2.p3.1.36" class="ltx_text ltx_font_italic">MS MARCO (regular)</span> and <span id="A1.SS2.p3.1.37" class="ltx_text ltx_font_italic">MS MARCO</span> use RR@10 score and NDCG@10 score, respectively. For more details, please refer to <cite class="ltx_cite ltx_citemacro_citet">Liang et al. (<a href="#bib.bib48" title="" class="ltx_ref">2022</a>)</cite>. In <span id="A1.SS2.p3.1.38" class="ltx_text ltx_font_smallcaps">FS-LLM</span>, the evaluation score for <span id="A1.SS2.p3.1.39" class="ltx_text ltx_font_italic">HELM</span> is the average value of these 16 subtasks’ scores.</p>
</div>
<div id="A1.SS2.p4" class="ltx_para ltx_noindent">
<p id="A1.SS2.p4.5" class="ltx_p">However, evaluation of all these 16 subtasks in <span id="A1.SS2.p4.5.1" class="ltx_text ltx_font_italic">HELM</span> is very time-consuming. We notice that there is a trade-off between the evaluation’s comprehensiveness and efficiency.
The more subtasks we use, the more accurate the evaluation scores will be, but also more time-consuming.
Thus, we build <span id="A1.SS2.p4.5.2" class="ltx_text ltx_font_italic">HELM-MINI</span> with fewer subtasks to assess the LLMs’ generic language capabilities.
We first randomly and uniformly sample serval samples of different combinations of configurations, including different PEFT algorithms and different hyperparameters.
After that, we pick 6 subtasks such that the evaluation score of these 6 subtasks is closest to the evaluation score of all 16 subtasks in the <math id="A1.SS2.p4.1.m1.1" class="ltx_Math" alttext="L^{2}" display="inline"><semantics id="A1.SS2.p4.1.m1.1a"><msup id="A1.SS2.p4.1.m1.1.1" xref="A1.SS2.p4.1.m1.1.1.cmml"><mi id="A1.SS2.p4.1.m1.1.1.2" xref="A1.SS2.p4.1.m1.1.1.2.cmml">L</mi><mn id="A1.SS2.p4.1.m1.1.1.3" xref="A1.SS2.p4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.1.m1.1b"><apply id="A1.SS2.p4.1.m1.1.1.cmml" xref="A1.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p4.1.m1.1.1.1.cmml" xref="A1.SS2.p4.1.m1.1.1">superscript</csymbol><ci id="A1.SS2.p4.1.m1.1.1.2.cmml" xref="A1.SS2.p4.1.m1.1.1.2">𝐿</ci><cn type="integer" id="A1.SS2.p4.1.m1.1.1.3.cmml" xref="A1.SS2.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.1.m1.1c">L^{2}</annotation></semantics></math> norm, which are <span id="A1.SS2.p4.5.3" class="ltx_text ltx_font_italic">MMLU</span>, <span id="A1.SS2.p4.5.4" class="ltx_text ltx_font_italic">NaturalQA (open-book)</span>, <span id="A1.SS2.p4.5.5" class="ltx_text ltx_font_italic">OpenbookQA</span>, <span id="A1.SS2.p4.5.6" class="ltx_text ltx_font_italic">MS MARCO (regular)</span>, <span id="A1.SS2.p4.5.7" class="ltx_text ltx_font_italic">XSUM</span> and <span id="A1.SS2.p4.5.8" class="ltx_text ltx_font_italic">IMDB</span>.
Then we consider the time consumption and the requirements for the stability of the network connection during the evaluation, and drop another 2 subtasks: <span id="A1.SS2.p4.5.9" class="ltx_text ltx_font_italic">MS MARCO (regular)</span> and <span id="A1.SS2.p4.5.10" class="ltx_text ltx_font_italic">XSUM</span>.
Finally, we have left 4 subtasks to form <span id="A1.SS2.p4.5.11" class="ltx_text ltx_font_italic">HELM-MINI</span>, including <span id="A1.SS2.p4.5.12" class="ltx_text ltx_font_italic">MMLU</span>, <span id="A1.SS2.p4.5.13" class="ltx_text ltx_font_italic">NaturalQA (open-book)</span>, <span id="A1.SS2.p4.5.14" class="ltx_text ltx_font_italic">OpenbookQA</span>, and <span id="A1.SS2.p4.5.15" class="ltx_text ltx_font_italic">IMDB</span>.
In Figure <a href="#A1.F6" title="Figure 6 ‣ A.2 Evaluation task description ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we present the comparison between the evaluation scores of <span id="A1.SS2.p4.5.16" class="ltx_text ltx_font_italic">HELM</span> and <span id="A1.SS2.p4.5.17" class="ltx_text ltx_font_italic">HELM-MINI</span>.
In Figure <a href="#A1.F6.sf1" title="In Figure 6 ‣ A.2 Evaluation task description ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, we plot the samples of different combinations of configurations, where <math id="A1.SS2.p4.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="A1.SS2.p4.2.m2.1a"><mi id="A1.SS2.p4.2.m2.1.1" xref="A1.SS2.p4.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.2.m2.1b"><ci id="A1.SS2.p4.2.m2.1.1.cmml" xref="A1.SS2.p4.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.2.m2.1c">\lambda</annotation></semantics></math> indicates the index of each sample.
It can be seen that though the exact evaluation scores of <span id="A1.SS2.p4.5.18" class="ltx_text ltx_font_italic">HELM</span> and <span id="A1.SS2.p4.5.19" class="ltx_text ltx_font_italic">HELM-MINI</span> are different, their normalized evaluation score relationships are essentially consistent. In Figure <a href="#A1.F6.sf2" title="In Figure 6 ‣ A.2 Evaluation task description ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>, we show the distribution of these samples’ normalized evaluation scores of <span id="A1.SS2.p4.5.20" class="ltx_text ltx_font_italic">HELM</span> and <span id="A1.SS2.p4.5.21" class="ltx_text ltx_font_italic">HELM-MINI</span>. Here, the normalized evaluation score is calculated by
<math id="A1.SS2.p4.3.m3.1" class="ltx_Math" alttext="\frac{x_{i}-x_{\min}}{x_{\max}-x_{\min}}" display="inline"><semantics id="A1.SS2.p4.3.m3.1a"><mfrac id="A1.SS2.p4.3.m3.1.1" xref="A1.SS2.p4.3.m3.1.1.cmml"><mrow id="A1.SS2.p4.3.m3.1.1.2" xref="A1.SS2.p4.3.m3.1.1.2.cmml"><msub id="A1.SS2.p4.3.m3.1.1.2.2" xref="A1.SS2.p4.3.m3.1.1.2.2.cmml"><mi id="A1.SS2.p4.3.m3.1.1.2.2.2" xref="A1.SS2.p4.3.m3.1.1.2.2.2.cmml">x</mi><mi id="A1.SS2.p4.3.m3.1.1.2.2.3" xref="A1.SS2.p4.3.m3.1.1.2.2.3.cmml">i</mi></msub><mo id="A1.SS2.p4.3.m3.1.1.2.1" xref="A1.SS2.p4.3.m3.1.1.2.1.cmml">−</mo><msub id="A1.SS2.p4.3.m3.1.1.2.3" xref="A1.SS2.p4.3.m3.1.1.2.3.cmml"><mi id="A1.SS2.p4.3.m3.1.1.2.3.2" xref="A1.SS2.p4.3.m3.1.1.2.3.2.cmml">x</mi><mi id="A1.SS2.p4.3.m3.1.1.2.3.3" xref="A1.SS2.p4.3.m3.1.1.2.3.3.cmml">min</mi></msub></mrow><mrow id="A1.SS2.p4.3.m3.1.1.3" xref="A1.SS2.p4.3.m3.1.1.3.cmml"><msub id="A1.SS2.p4.3.m3.1.1.3.2" xref="A1.SS2.p4.3.m3.1.1.3.2.cmml"><mi id="A1.SS2.p4.3.m3.1.1.3.2.2" xref="A1.SS2.p4.3.m3.1.1.3.2.2.cmml">x</mi><mi id="A1.SS2.p4.3.m3.1.1.3.2.3" xref="A1.SS2.p4.3.m3.1.1.3.2.3.cmml">max</mi></msub><mo id="A1.SS2.p4.3.m3.1.1.3.1" xref="A1.SS2.p4.3.m3.1.1.3.1.cmml">−</mo><msub id="A1.SS2.p4.3.m3.1.1.3.3" xref="A1.SS2.p4.3.m3.1.1.3.3.cmml"><mi id="A1.SS2.p4.3.m3.1.1.3.3.2" xref="A1.SS2.p4.3.m3.1.1.3.3.2.cmml">x</mi><mi id="A1.SS2.p4.3.m3.1.1.3.3.3" xref="A1.SS2.p4.3.m3.1.1.3.3.3.cmml">min</mi></msub></mrow></mfrac><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.3.m3.1b"><apply id="A1.SS2.p4.3.m3.1.1.cmml" xref="A1.SS2.p4.3.m3.1.1"><divide id="A1.SS2.p4.3.m3.1.1.1.cmml" xref="A1.SS2.p4.3.m3.1.1"></divide><apply id="A1.SS2.p4.3.m3.1.1.2.cmml" xref="A1.SS2.p4.3.m3.1.1.2"><minus id="A1.SS2.p4.3.m3.1.1.2.1.cmml" xref="A1.SS2.p4.3.m3.1.1.2.1"></minus><apply id="A1.SS2.p4.3.m3.1.1.2.2.cmml" xref="A1.SS2.p4.3.m3.1.1.2.2"><csymbol cd="ambiguous" id="A1.SS2.p4.3.m3.1.1.2.2.1.cmml" xref="A1.SS2.p4.3.m3.1.1.2.2">subscript</csymbol><ci id="A1.SS2.p4.3.m3.1.1.2.2.2.cmml" xref="A1.SS2.p4.3.m3.1.1.2.2.2">𝑥</ci><ci id="A1.SS2.p4.3.m3.1.1.2.2.3.cmml" xref="A1.SS2.p4.3.m3.1.1.2.2.3">𝑖</ci></apply><apply id="A1.SS2.p4.3.m3.1.1.2.3.cmml" xref="A1.SS2.p4.3.m3.1.1.2.3"><csymbol cd="ambiguous" id="A1.SS2.p4.3.m3.1.1.2.3.1.cmml" xref="A1.SS2.p4.3.m3.1.1.2.3">subscript</csymbol><ci id="A1.SS2.p4.3.m3.1.1.2.3.2.cmml" xref="A1.SS2.p4.3.m3.1.1.2.3.2">𝑥</ci><min id="A1.SS2.p4.3.m3.1.1.2.3.3.cmml" xref="A1.SS2.p4.3.m3.1.1.2.3.3"></min></apply></apply><apply id="A1.SS2.p4.3.m3.1.1.3.cmml" xref="A1.SS2.p4.3.m3.1.1.3"><minus id="A1.SS2.p4.3.m3.1.1.3.1.cmml" xref="A1.SS2.p4.3.m3.1.1.3.1"></minus><apply id="A1.SS2.p4.3.m3.1.1.3.2.cmml" xref="A1.SS2.p4.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="A1.SS2.p4.3.m3.1.1.3.2.1.cmml" xref="A1.SS2.p4.3.m3.1.1.3.2">subscript</csymbol><ci id="A1.SS2.p4.3.m3.1.1.3.2.2.cmml" xref="A1.SS2.p4.3.m3.1.1.3.2.2">𝑥</ci><max id="A1.SS2.p4.3.m3.1.1.3.2.3.cmml" xref="A1.SS2.p4.3.m3.1.1.3.2.3"></max></apply><apply id="A1.SS2.p4.3.m3.1.1.3.3.cmml" xref="A1.SS2.p4.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="A1.SS2.p4.3.m3.1.1.3.3.1.cmml" xref="A1.SS2.p4.3.m3.1.1.3.3">subscript</csymbol><ci id="A1.SS2.p4.3.m3.1.1.3.3.2.cmml" xref="A1.SS2.p4.3.m3.1.1.3.3.2">𝑥</ci><min id="A1.SS2.p4.3.m3.1.1.3.3.3.cmml" xref="A1.SS2.p4.3.m3.1.1.3.3.3"></min></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.3.m3.1c">\frac{x_{i}-x_{\min}}{x_{\max}-x_{\min}}</annotation></semantics></math>, where <math id="A1.SS2.p4.4.m4.1" class="ltx_Math" alttext="x_{\max}" display="inline"><semantics id="A1.SS2.p4.4.m4.1a"><msub id="A1.SS2.p4.4.m4.1.1" xref="A1.SS2.p4.4.m4.1.1.cmml"><mi id="A1.SS2.p4.4.m4.1.1.2" xref="A1.SS2.p4.4.m4.1.1.2.cmml">x</mi><mi id="A1.SS2.p4.4.m4.1.1.3" xref="A1.SS2.p4.4.m4.1.1.3.cmml">max</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.4.m4.1b"><apply id="A1.SS2.p4.4.m4.1.1.cmml" xref="A1.SS2.p4.4.m4.1.1"><csymbol cd="ambiguous" id="A1.SS2.p4.4.m4.1.1.1.cmml" xref="A1.SS2.p4.4.m4.1.1">subscript</csymbol><ci id="A1.SS2.p4.4.m4.1.1.2.cmml" xref="A1.SS2.p4.4.m4.1.1.2">𝑥</ci><max id="A1.SS2.p4.4.m4.1.1.3.cmml" xref="A1.SS2.p4.4.m4.1.1.3"></max></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.4.m4.1c">x_{\max}</annotation></semantics></math> and <math id="A1.SS2.p4.5.m5.1" class="ltx_Math" alttext="x_{\min}" display="inline"><semantics id="A1.SS2.p4.5.m5.1a"><msub id="A1.SS2.p4.5.m5.1.1" xref="A1.SS2.p4.5.m5.1.1.cmml"><mi id="A1.SS2.p4.5.m5.1.1.2" xref="A1.SS2.p4.5.m5.1.1.2.cmml">x</mi><mi id="A1.SS2.p4.5.m5.1.1.3" xref="A1.SS2.p4.5.m5.1.1.3.cmml">min</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.5.m5.1b"><apply id="A1.SS2.p4.5.m5.1.1.cmml" xref="A1.SS2.p4.5.m5.1.1"><csymbol cd="ambiguous" id="A1.SS2.p4.5.m5.1.1.1.cmml" xref="A1.SS2.p4.5.m5.1.1">subscript</csymbol><ci id="A1.SS2.p4.5.m5.1.1.2.cmml" xref="A1.SS2.p4.5.m5.1.1.2">𝑥</ci><min id="A1.SS2.p4.5.m5.1.1.3.cmml" xref="A1.SS2.p4.5.m5.1.1.3"></min></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.5.m5.1c">x_{\min}</annotation></semantics></math> are the maximum and minimum evaluation scores among all the samples of <span id="A1.SS2.p4.5.22" class="ltx_text ltx_font_italic">HELM</span> and <span id="A1.SS2.p4.5.23" class="ltx_text ltx_font_italic">HELM-MINI</span>, respectively.</p>
</div>
<figure id="A1.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2309.00363/assets/x7.png" id="A1.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>The average scores of the 16 subtasks in <span id="A1.F6.sf1.3.1" class="ltx_text ltx_font_italic">HELM</span> and the 4 subtasks in <span id="A1.F6.sf1.4.2" class="ltx_text ltx_font_italic">HELM-MINI</span> for the samples with different configurations, respectively.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2309.00363/assets/x8.png" id="A1.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>The density distribution of the normalized performance of <span id="A1.F6.sf2.3.1" class="ltx_text ltx_font_italic">HELM</span> and <span id="A1.F6.sf2.4.2" class="ltx_text ltx_font_italic">HELM-MINI</span> among the samples, respectively.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The performance comparison of <span id="A1.F6.3.1" class="ltx_text ltx_font_italic">HELM</span> and <span id="A1.F6.4.2" class="ltx_text ltx_font_italic">HELM-MINI</span>.</figcaption>
</figure>
<div id="A1.SS2.p5" class="ltx_para ltx_noindent">
<p id="A1.SS2.p5.1" class="ltx_p"><span id="A1.SS2.p5.1.1" class="ltx_text ltx_font_bold">Evaluation task for CoT capability.</span> We use <span id="A1.SS2.p5.1.2" class="ltx_text ltx_font_italic">GSM8K-test</span> <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite>, which consists of 1k math problems from the test split in <span id="A1.SS2.p5.1.3" class="ltx_text ltx_font_italic">GSM8K</span> to evaluate the performance of LLMs on mathematic problem-solving capability.
We also adopt 8-shot-CoT prompting <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a href="#bib.bib83" title="" class="ltx_ref">2022</a>)</cite> in evaluation. The evaluation score is the accuracy of these 1k math problems.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Detailed hyperparameters and results</h3>

<div id="A1.SS3.p1" class="ltx_para ltx_noindent">
<p id="A1.SS3.p1.1" class="ltx_p">We perform a grid search over the hyperparameter space to ensure that each algorithm achieves its optimal performance and to enable a fair comparison among different algorithms.
The search space of the learning rate for all adapters is <math id="A1.SS3.p1.1.m1.6" class="ltx_Math" alttext="\{$1\text{\times}{10}^{-4}$,$3\text{\times}{10}^{-4}$,$5\text{\times}{10}^{-4}$,$1\text{\times}{10}^{-3}$,$3\text{\times}{10}^{-3}$,$5\text{\times}{10}^{-3}$\}" display="inline"><semantics id="A1.SS3.p1.1.m1.6a"><mrow id="A1.SS3.p1.1.m1.6.7.2" xref="A1.SS3.p1.1.m1.6.7.1.cmml"><mo stretchy="false" id="A1.SS3.p1.1.m1.6.7.2.1" xref="A1.SS3.p1.1.m1.6.7.1.cmml">{</mo><mrow id="A1.SS3.p1.1.m1.1.1.m1.3.3.3" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.1.1.m1.1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml">1</mn><mtext id="A1.SS3.p1.1.m1.1.1.m1.2.2.2.2.2.2.2" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml">×</mtext><msup id="A1.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml">10</mn><mrow id="A1.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml"><mo id="A1.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.2a" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml">−</mo><mn id="A1.SS3.p1.1.m1.1.1.m1.3.3.3.3.3.3.3.3.2.2" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml">4</mn></mrow></msup></mrow><mo id="A1.SS3.p1.1.m1.6.7.2.2" xref="A1.SS3.p1.1.m1.6.7.1.cmml">,</mo><mrow id="A1.SS3.p1.1.m1.2.2.m1.3.3.3" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.2.2.m1.1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml">3</mn><mtext id="A1.SS3.p1.1.m1.2.2.m1.2.2.2.2.2.2.2" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml">×</mtext><msup id="A1.SS3.p1.1.m1.2.2.m1.3.3.3.3.3.3.3" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.2.2.m1.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml">10</mn><mrow id="A1.SS3.p1.1.m1.2.2.m1.3.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml"><mo id="A1.SS3.p1.1.m1.2.2.m1.3.3.3.3.3.3.3.3.2a" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml">−</mo><mn id="A1.SS3.p1.1.m1.2.2.m1.3.3.3.3.3.3.3.3.2.2" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml">4</mn></mrow></msup></mrow><mo id="A1.SS3.p1.1.m1.6.7.2.3" xref="A1.SS3.p1.1.m1.6.7.1.cmml">,</mo><mrow id="A1.SS3.p1.1.m1.3.3.m1.3.3.3" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.3.3.m1.1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml">5</mn><mtext id="A1.SS3.p1.1.m1.3.3.m1.2.2.2.2.2.2.2" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml">×</mtext><msup id="A1.SS3.p1.1.m1.3.3.m1.3.3.3.3.3.3.3" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.3.3.m1.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml">10</mn><mrow id="A1.SS3.p1.1.m1.3.3.m1.3.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml"><mo id="A1.SS3.p1.1.m1.3.3.m1.3.3.3.3.3.3.3.3.2a" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml">−</mo><mn id="A1.SS3.p1.1.m1.3.3.m1.3.3.3.3.3.3.3.3.2.2" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml">4</mn></mrow></msup></mrow><mo id="A1.SS3.p1.1.m1.6.7.2.4" xref="A1.SS3.p1.1.m1.6.7.1.cmml">,</mo><mrow id="A1.SS3.p1.1.m1.4.4.m1.3.3.3" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.4.4.m1.1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml">1</mn><mtext id="A1.SS3.p1.1.m1.4.4.m1.2.2.2.2.2.2.2" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml">×</mtext><msup id="A1.SS3.p1.1.m1.4.4.m1.3.3.3.3.3.3.3" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.4.4.m1.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml">10</mn><mrow id="A1.SS3.p1.1.m1.4.4.m1.3.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml"><mo id="A1.SS3.p1.1.m1.4.4.m1.3.3.3.3.3.3.3.3.2a" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml">−</mo><mn id="A1.SS3.p1.1.m1.4.4.m1.3.3.3.3.3.3.3.3.2.2" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml">3</mn></mrow></msup></mrow><mo id="A1.SS3.p1.1.m1.6.7.2.5" xref="A1.SS3.p1.1.m1.6.7.1.cmml">,</mo><mrow id="A1.SS3.p1.1.m1.5.5.m1.3.3.3" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.5.5.m1.1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml">3</mn><mtext id="A1.SS3.p1.1.m1.5.5.m1.2.2.2.2.2.2.2" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml">×</mtext><msup id="A1.SS3.p1.1.m1.5.5.m1.3.3.3.3.3.3.3" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.5.5.m1.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml">10</mn><mrow id="A1.SS3.p1.1.m1.5.5.m1.3.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml"><mo id="A1.SS3.p1.1.m1.5.5.m1.3.3.3.3.3.3.3.3.2a" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml">−</mo><mn id="A1.SS3.p1.1.m1.5.5.m1.3.3.3.3.3.3.3.3.2.2" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml">3</mn></mrow></msup></mrow><mo id="A1.SS3.p1.1.m1.6.7.2.6" xref="A1.SS3.p1.1.m1.6.7.1.cmml">,</mo><mrow id="A1.SS3.p1.1.m1.6.6.m1.3.3.3" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.6.6.m1.1.1.1.1.1.1.1" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml">5</mn><mtext id="A1.SS3.p1.1.m1.6.6.m1.2.2.2.2.2.2.2" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml">×</mtext><msup id="A1.SS3.p1.1.m1.6.6.m1.3.3.3.3.3.3.3" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml"><mn id="A1.SS3.p1.1.m1.6.6.m1.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml">10</mn><mrow id="A1.SS3.p1.1.m1.6.6.m1.3.3.3.3.3.3.3.3.2" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml"><mo id="A1.SS3.p1.1.m1.6.6.m1.3.3.3.3.3.3.3.3.2a" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml">−</mo><mn id="A1.SS3.p1.1.m1.6.6.m1.3.3.3.3.3.3.3.3.2.2" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml">3</mn></mrow></msup></mrow><mo stretchy="false" id="A1.SS3.p1.1.m1.6.7.2.7" xref="A1.SS3.p1.1.m1.6.7.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.m1.6b"><set id="A1.SS3.p1.1.m1.6.7.1.cmml" xref="A1.SS3.p1.1.m1.6.7.2"><csymbol cd="latexml" id="A1.SS3.p1.1.m1.1.1.m1.3.3.3.cmml" xref="A1.SS3.p1.1.m1.1.1.m1.3.3.3">1E-4</csymbol><csymbol cd="latexml" id="A1.SS3.p1.1.m1.2.2.m1.3.3.3.cmml" xref="A1.SS3.p1.1.m1.2.2.m1.3.3.3">3E-4</csymbol><csymbol cd="latexml" id="A1.SS3.p1.1.m1.3.3.m1.3.3.3.cmml" xref="A1.SS3.p1.1.m1.3.3.m1.3.3.3">5E-4</csymbol><csymbol cd="latexml" id="A1.SS3.p1.1.m1.4.4.m1.3.3.3.cmml" xref="A1.SS3.p1.1.m1.4.4.m1.3.3.3">1E-3</csymbol><csymbol cd="latexml" id="A1.SS3.p1.1.m1.5.5.m1.3.3.3.cmml" xref="A1.SS3.p1.1.m1.5.5.m1.3.3.3">3E-3</csymbol><csymbol cd="latexml" id="A1.SS3.p1.1.m1.6.6.m1.3.3.3.cmml" xref="A1.SS3.p1.1.m1.6.6.m1.3.3.3">5E-3</csymbol></set></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.m1.6c">\{$1\text{\times}{10}^{-4}$,$3\text{\times}{10}^{-4}$,$5\text{\times}{10}^{-4}$,$1\text{\times}{10}^{-3}$,$3\text{\times}{10}^{-3}$,$5\text{\times}{10}^{-3}$\}</annotation></semantics></math>.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para ltx_noindent">
<p id="A1.SS3.p2.2" class="ltx_p">LoRA has three hyperparameters: the rank of the adaption matrices, the scaling coefficient, and the dropout probability for LoRA layers.
The rank has a significant impact on resource consumption, so we fix it to 8, which is the default value in the algorithm.
We grid search the other two parameters.
The search spaces of the scaling coefficient and dropout probability for LoRA layers are <math id="A1.SS3.p2.1.m1.4" class="ltx_Math" alttext="\{16,32,64,128\}" display="inline"><semantics id="A1.SS3.p2.1.m1.4a"><mrow id="A1.SS3.p2.1.m1.4.5.2" xref="A1.SS3.p2.1.m1.4.5.1.cmml"><mo stretchy="false" id="A1.SS3.p2.1.m1.4.5.2.1" xref="A1.SS3.p2.1.m1.4.5.1.cmml">{</mo><mn id="A1.SS3.p2.1.m1.1.1" xref="A1.SS3.p2.1.m1.1.1.cmml">16</mn><mo id="A1.SS3.p2.1.m1.4.5.2.2" xref="A1.SS3.p2.1.m1.4.5.1.cmml">,</mo><mn id="A1.SS3.p2.1.m1.2.2" xref="A1.SS3.p2.1.m1.2.2.cmml">32</mn><mo id="A1.SS3.p2.1.m1.4.5.2.3" xref="A1.SS3.p2.1.m1.4.5.1.cmml">,</mo><mn id="A1.SS3.p2.1.m1.3.3" xref="A1.SS3.p2.1.m1.3.3.cmml">64</mn><mo id="A1.SS3.p2.1.m1.4.5.2.4" xref="A1.SS3.p2.1.m1.4.5.1.cmml">,</mo><mn id="A1.SS3.p2.1.m1.4.4" xref="A1.SS3.p2.1.m1.4.4.cmml">128</mn><mo stretchy="false" id="A1.SS3.p2.1.m1.4.5.2.5" xref="A1.SS3.p2.1.m1.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.1.m1.4b"><set id="A1.SS3.p2.1.m1.4.5.1.cmml" xref="A1.SS3.p2.1.m1.4.5.2"><cn type="integer" id="A1.SS3.p2.1.m1.1.1.cmml" xref="A1.SS3.p2.1.m1.1.1">16</cn><cn type="integer" id="A1.SS3.p2.1.m1.2.2.cmml" xref="A1.SS3.p2.1.m1.2.2">32</cn><cn type="integer" id="A1.SS3.p2.1.m1.3.3.cmml" xref="A1.SS3.p2.1.m1.3.3">64</cn><cn type="integer" id="A1.SS3.p2.1.m1.4.4.cmml" xref="A1.SS3.p2.1.m1.4.4">128</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.1.m1.4c">\{16,32,64,128\}</annotation></semantics></math> and <math id="A1.SS3.p2.2.m2.2" class="ltx_Math" alttext="\{0.0,0.1\}" display="inline"><semantics id="A1.SS3.p2.2.m2.2a"><mrow id="A1.SS3.p2.2.m2.2.3.2" xref="A1.SS3.p2.2.m2.2.3.1.cmml"><mo stretchy="false" id="A1.SS3.p2.2.m2.2.3.2.1" xref="A1.SS3.p2.2.m2.2.3.1.cmml">{</mo><mn id="A1.SS3.p2.2.m2.1.1" xref="A1.SS3.p2.2.m2.1.1.cmml">0.0</mn><mo id="A1.SS3.p2.2.m2.2.3.2.2" xref="A1.SS3.p2.2.m2.2.3.1.cmml">,</mo><mn id="A1.SS3.p2.2.m2.2.2" xref="A1.SS3.p2.2.m2.2.2.cmml">0.1</mn><mo stretchy="false" id="A1.SS3.p2.2.m2.2.3.2.3" xref="A1.SS3.p2.2.m2.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.2.m2.2b"><set id="A1.SS3.p2.2.m2.2.3.1.cmml" xref="A1.SS3.p2.2.m2.2.3.2"><cn type="float" id="A1.SS3.p2.2.m2.1.1.cmml" xref="A1.SS3.p2.2.m2.1.1">0.0</cn><cn type="float" id="A1.SS3.p2.2.m2.2.2.cmml" xref="A1.SS3.p2.2.m2.2.2">0.1</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.2.m2.2c">\{0.0,0.1\}</annotation></semantics></math>, respectively.</p>
</div>
<div id="A1.SS3.p3" class="ltx_para ltx_noindent">
<p id="A1.SS3.p3.1" class="ltx_p">For P-tuning, because of the source limitation, we fix the type of reparameterization to be “MLP” and only search the number of virtual tokens in <math id="A1.SS3.p3.1.m1.3" class="ltx_Math" alttext="\{10,20,30\}" display="inline"><semantics id="A1.SS3.p3.1.m1.3a"><mrow id="A1.SS3.p3.1.m1.3.4.2" xref="A1.SS3.p3.1.m1.3.4.1.cmml"><mo stretchy="false" id="A1.SS3.p3.1.m1.3.4.2.1" xref="A1.SS3.p3.1.m1.3.4.1.cmml">{</mo><mn id="A1.SS3.p3.1.m1.1.1" xref="A1.SS3.p3.1.m1.1.1.cmml">10</mn><mo id="A1.SS3.p3.1.m1.3.4.2.2" xref="A1.SS3.p3.1.m1.3.4.1.cmml">,</mo><mn id="A1.SS3.p3.1.m1.2.2" xref="A1.SS3.p3.1.m1.2.2.cmml">20</mn><mo id="A1.SS3.p3.1.m1.3.4.2.3" xref="A1.SS3.p3.1.m1.3.4.1.cmml">,</mo><mn id="A1.SS3.p3.1.m1.3.3" xref="A1.SS3.p3.1.m1.3.3.cmml">30</mn><mo stretchy="false" id="A1.SS3.p3.1.m1.3.4.2.4" xref="A1.SS3.p3.1.m1.3.4.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p3.1.m1.3b"><set id="A1.SS3.p3.1.m1.3.4.1.cmml" xref="A1.SS3.p3.1.m1.3.4.2"><cn type="integer" id="A1.SS3.p3.1.m1.1.1.cmml" xref="A1.SS3.p3.1.m1.1.1">10</cn><cn type="integer" id="A1.SS3.p3.1.m1.2.2.cmml" xref="A1.SS3.p3.1.m1.2.2">20</cn><cn type="integer" id="A1.SS3.p3.1.m1.3.3.cmml" xref="A1.SS3.p3.1.m1.3.3">30</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p3.1.m1.3c">\{10,20,30\}</annotation></semantics></math>.</p>
</div>
<div id="A1.SS3.p4" class="ltx_para ltx_noindent">
<p id="A1.SS3.p4.1" class="ltx_p">For prompt tuning, we find that initializing the prompt randomly will result in poor performances on these datasets.
Therefore, we set it to “TEXT” and initialize different prompts for different fine-tuning datasets. Specifically,
for <span id="A1.SS3.p4.1.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span>, we use “Program a function by following description.” together with the number of virtual tokens equals 8;
For <span id="A1.SS3.p4.1.2" class="ltx_text ltx_font_italic">Fed-Dolly</span>, we use “Assume you can understand and answer questions.” together with the number of virtual tokens equals 9;
For <span id="A1.SS3.p4.1.3" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span>, we use “Think step by step.” together with the number of virtual tokens equals 6.
The reason why we use the prompts above is that we think these prompts appropriately describe the fine-tuning tasks, respectively.
The number of virtual tokens we use is exactly the length of the corresponding prompt processed by the tokenizer.</p>
</div>
<div id="A1.SS3.p5" class="ltx_para ltx_noindent">
<p id="A1.SS3.p5.1" class="ltx_p">In Table <a href="#A1.T7" title="Table 7 ‣ A.3 Detailed hyperparameters and results ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>- <a href="#A1.T15" title="Table 15 ‣ A.3 Detailed hyperparameters and results ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a>, we present experimental results when we grid search the hyperparameters for different PEFT algorithms.
In Table <a href="#A1.T16" title="Table 16 ‣ A.3 Detailed hyperparameters and results ‣ Appendix A Appendix ‣ FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>, we show examples of creative writing generated by the fine-tuned LLaMA-7B with different PEFT algorithms. The fine-tuning dataset is <span id="A1.SS3.p5.1.1" class="ltx_text ltx_font_italic">Fed-Dolly</span>. It can be seen that the LLM, without fine-tuning in FL, lacks imagination and only describes the situation of a crocodile on the moon. The response of the model fine-tuned with LoRA is more accurate, which prefers the ocean to outer space and does write a haiku in the voice of a pirate. The model fine-tuned with P-tuning combines crocodiles and the moon, but the logic of the generated answers is not very coherent. The response generated by the model fine-tuned with prompt tuning is the shortest one, showing the savagery of the crocodile as a pirate. In summary, after federated fine-tuning, the accuracy and fluency of the LLM in answering questions are improved.</p>
</div>
<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with LoRA on <span id="A1.T7.2.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span>. In this table, the dropout probability is 0.0.</figcaption>
<table id="A1.T7.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T7.3.1" class="ltx_tr">
<td id="A1.T7.3.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Scaling coef.</td>
<td id="A1.T7.3.1.2" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T7.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="6">LR</td>
</tr>
<tr id="A1.T7.3.2" class="ltx_tr">
<td id="A1.T7.3.2.1" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T7.3.2.2" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T7.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0001</td>
<td id="A1.T7.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0003</td>
<td id="A1.T7.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0005</td>
<td id="A1.T7.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.001</td>
<td id="A1.T7.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.003</td>
<td id="A1.T7.3.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.005</td>
</tr>
<tr id="A1.T7.3.3" class="ltx_tr">
<td id="A1.T7.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T7.3.3.1.1" class="ltx_text">16</span></td>
<td id="A1.T7.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T7.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.29</td>
<td id="A1.T7.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.34</td>
<td id="A1.T7.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.37</td>
<td id="A1.T7.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.39</td>
<td id="A1.T7.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.34</td>
<td id="A1.T7.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.73</td>
</tr>
<tr id="A1.T7.3.4" class="ltx_tr">
<td id="A1.T7.3.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T7.3.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.17</td>
<td id="A1.T7.3.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.71</td>
<td id="A1.T7.3.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.49</td>
<td id="A1.T7.3.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.73</td>
<td id="A1.T7.3.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.71</td>
<td id="A1.T7.3.4.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.46</td>
</tr>
<tr id="A1.T7.3.5" class="ltx_tr">
<td id="A1.T7.3.5.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T7.3.5.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.41</td>
<td id="A1.T7.3.5.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
<td id="A1.T7.3.5.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
<td id="A1.T7.3.5.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.85</td>
<td id="A1.T7.3.5.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.68</td>
<td id="A1.T7.3.5.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.83</td>
</tr>
<tr id="A1.T7.3.6" class="ltx_tr">
<td id="A1.T7.3.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T7.3.6.1.1" class="ltx_text">32</span></td>
<td id="A1.T7.3.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T7.3.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.56</td>
<td id="A1.T7.3.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T7.3.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.27</td>
<td id="A1.T7.3.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.61</td>
<td id="A1.T7.3.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T7.3.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2.07</td>
</tr>
<tr id="A1.T7.3.7" class="ltx_tr">
<td id="A1.T7.3.7.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T7.3.7.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.07</td>
<td id="A1.T7.3.7.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
<td id="A1.T7.3.7.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.98</td>
<td id="A1.T7.3.7.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.49</td>
<td id="A1.T7.3.7.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.54</td>
<td id="A1.T7.3.7.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.88</td>
</tr>
<tr id="A1.T7.3.8" class="ltx_tr">
<td id="A1.T7.3.8.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T7.3.8.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.44</td>
<td id="A1.T7.3.8.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.34</td>
<td id="A1.T7.3.8.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
<td id="A1.T7.3.8.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.34</td>
<td id="A1.T7.3.8.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.73</td>
<td id="A1.T7.3.8.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.00</td>
</tr>
<tr id="A1.T7.3.9" class="ltx_tr">
<td id="A1.T7.3.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T7.3.9.1.1" class="ltx_text">64</span></td>
<td id="A1.T7.3.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T7.3.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.00</td>
<td id="A1.T7.3.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
<td id="A1.T7.3.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
<td id="A1.T7.3.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
<td id="A1.T7.3.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T7.3.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
</tr>
<tr id="A1.T7.3.10" class="ltx_tr">
<td id="A1.T7.3.10.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T7.3.10.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.73</td>
<td id="A1.T7.3.10.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.37</td>
<td id="A1.T7.3.10.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
<td id="A1.T7.3.10.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
<td id="A1.T7.3.10.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.98</td>
<td id="A1.T7.3.10.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.71</td>
</tr>
<tr id="A1.T7.3.11" class="ltx_tr">
<td id="A1.T7.3.11.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T7.3.11.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
<td id="A1.T7.3.11.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.56</td>
<td id="A1.T7.3.11.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.68</td>
<td id="A1.T7.3.11.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.44</td>
<td id="A1.T7.3.11.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.76</td>
<td id="A1.T7.3.11.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.68</td>
</tr>
<tr id="A1.T7.3.12" class="ltx_tr">
<td id="A1.T7.3.12.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T7.3.12.1.1" class="ltx_text">128</span></td>
<td id="A1.T7.3.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T7.3.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.88</td>
<td id="A1.T7.3.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.98</td>
<td id="A1.T7.3.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.83</td>
<td id="A1.T7.3.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.83</td>
<td id="A1.T7.3.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.85</td>
<td id="A1.T7.3.12.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.73</td>
</tr>
<tr id="A1.T7.3.13" class="ltx_tr">
<td id="A1.T7.3.13.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T7.3.13.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T7.3.13.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.07</td>
<td id="A1.T7.3.13.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.83</td>
<td id="A1.T7.3.13.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.95</td>
<td id="A1.T7.3.13.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.00</td>
<td id="A1.T7.3.13.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.00</td>
</tr>
<tr id="A1.T7.3.14" class="ltx_tr">
<td id="A1.T7.3.14.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T7.3.14.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.98</td>
<td id="A1.T7.3.14.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.68</td>
<td id="A1.T7.3.14.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.95</td>
<td id="A1.T7.3.14.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.15</td>
<td id="A1.T7.3.14.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.83</td>
<td id="A1.T7.3.14.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.85</td>
</tr>
</table>
</figure>
<figure id="A1.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with P-tuning on <span id="A1.T8.2.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span>.</figcaption>
<table id="A1.T8.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T8.3.1" class="ltx_tr">
<td id="A1.T8.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Virtual tokens</td>
<td id="A1.T8.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T8.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="6">LR</td>
</tr>
<tr id="A1.T8.3.2" class="ltx_tr">
<td id="A1.T8.3.2.1" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T8.3.2.2" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T8.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0001</td>
<td id="A1.T8.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0003</td>
<td id="A1.T8.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0005</td>
<td id="A1.T8.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.001</td>
<td id="A1.T8.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.003</td>
<td id="A1.T8.3.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.005</td>
</tr>
<tr id="A1.T8.3.3" class="ltx_tr">
<td id="A1.T8.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T8.3.3.1.1" class="ltx_text">10</span></td>
<td id="A1.T8.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T8.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.90</td>
<td id="A1.T8.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.83</td>
<td id="A1.T8.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.78</td>
<td id="A1.T8.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T8.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.61</td>
<td id="A1.T8.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.83</td>
</tr>
<tr id="A1.T8.3.4" class="ltx_tr">
<td id="A1.T8.3.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T8.3.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
<td id="A1.T8.3.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.15</td>
<td id="A1.T8.3.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.00</td>
<td id="A1.T8.3.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.51</td>
<td id="A1.T8.3.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.46</td>
<td id="A1.T8.3.4.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.95</td>
</tr>
<tr id="A1.T8.3.5" class="ltx_tr">
<td id="A1.T8.3.5.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T8.3.5.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.37</td>
<td id="A1.T8.3.5.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.39</td>
<td id="A1.T8.3.5.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.85</td>
<td id="A1.T8.3.5.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">4.14</td>
<td id="A1.T8.3.5.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.37</td>
<td id="A1.T8.3.5.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.83</td>
</tr>
<tr id="A1.T8.3.6" class="ltx_tr">
<td id="A1.T8.3.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T8.3.6.1.1" class="ltx_text">20</span></td>
<td id="A1.T8.3.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T8.3.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.73</td>
<td id="A1.T8.3.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
<td id="A1.T8.3.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.39</td>
<td id="A1.T8.3.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.05</td>
<td id="A1.T8.3.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.51</td>
<td id="A1.T8.3.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">4.51</td>
</tr>
<tr id="A1.T8.3.7" class="ltx_tr">
<td id="A1.T8.3.7.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T8.3.7.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.78</td>
<td id="A1.T8.3.7.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.85</td>
<td id="A1.T8.3.7.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.00</td>
<td id="A1.T8.3.7.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.39</td>
<td id="A1.T8.3.7.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.02</td>
<td id="A1.T8.3.7.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.05</td>
</tr>
<tr id="A1.T8.3.8" class="ltx_tr">
<td id="A1.T8.3.8.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T8.3.8.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.93</td>
<td id="A1.T8.3.8.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.17</td>
<td id="A1.T8.3.8.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.78</td>
<td id="A1.T8.3.8.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2.93</td>
<td id="A1.T8.3.8.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.61</td>
<td id="A1.T8.3.8.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.66</td>
</tr>
<tr id="A1.T8.3.9" class="ltx_tr">
<td id="A1.T8.3.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T8.3.9.1.1" class="ltx_text">30</span></td>
<td id="A1.T8.3.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T8.3.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.02</td>
<td id="A1.T8.3.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T8.3.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.00</td>
<td id="A1.T8.3.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.98</td>
<td id="A1.T8.3.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.14</td>
<td id="A1.T8.3.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1.95</td>
</tr>
<tr id="A1.T8.3.10" class="ltx_tr">
<td id="A1.T8.3.10.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T8.3.10.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.32</td>
<td id="A1.T8.3.10.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.49</td>
<td id="A1.T8.3.10.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.37</td>
<td id="A1.T8.3.10.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T8.3.10.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2.68</td>
<td id="A1.T8.3.10.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2.80</td>
</tr>
<tr id="A1.T8.3.11" class="ltx_tr">
<td id="A1.T8.3.11.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T8.3.11.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.07</td>
<td id="A1.T8.3.11.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.02</td>
<td id="A1.T8.3.11.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
<td id="A1.T8.3.11.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.24</td>
<td id="A1.T8.3.11.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.61</td>
<td id="A1.T8.3.11.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.24</td>
</tr>
</table>
</figure>
<figure id="A1.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with prompt tuning on <span id="A1.T9.2.1" class="ltx_text ltx_font_italic">Fed-CodeAlpaca</span>. In this table, the initialized prompt is “Program a function by following description.”. The number of virtual tokens is 8.</figcaption>
<table id="A1.T9.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T9.3.1" class="ltx_tr">
<td id="A1.T9.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T9.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="6">LR</td>
</tr>
<tr id="A1.T9.3.2" class="ltx_tr">
<td id="A1.T9.3.2.1" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T9.3.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0001</td>
<td id="A1.T9.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0003</td>
<td id="A1.T9.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0005</td>
<td id="A1.T9.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.001</td>
<td id="A1.T9.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.003</td>
<td id="A1.T9.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.005</td>
</tr>
<tr id="A1.T9.3.3" class="ltx_tr">
<td id="A1.T9.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T9.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.16</td>
<td id="A1.T9.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.07</td>
<td id="A1.T9.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.69</td>
<td id="A1.T9.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
<td id="A1.T9.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.28</td>
<td id="A1.T9.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.03</td>
</tr>
<tr id="A1.T9.3.4" class="ltx_tr">
<td id="A1.T9.3.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T9.3.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.96</td>
<td id="A1.T9.3.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T9.3.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.61</td>
<td id="A1.T9.3.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.90</td>
<td id="A1.T9.3.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.60</td>
<td id="A1.T9.3.4.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
</tr>
<tr id="A1.T9.3.5" class="ltx_tr">
<td id="A1.T9.3.5.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T9.3.5.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.64</td>
<td id="A1.T9.3.5.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T9.3.5.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T9.3.5.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.39</td>
<td id="A1.T9.3.5.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.37</td>
<td id="A1.T9.3.5.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
</tr>
</table>
</figure>
<figure id="A1.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with LoRA on <span id="A1.T10.2.1" class="ltx_text ltx_font_italic">Fed-Dolly</span>.</figcaption>
<div id="A1.T10.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:408.1pt;height:351.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.4pt,13.2pt) scale(0.93,0.93) ;">
<table id="A1.T10.3.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T10.3.1.1" class="ltx_tr">
<td id="A1.T10.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Scaling coef.</td>
<td id="A1.T10.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">32</td>
<td id="A1.T10.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">64</td>
<td id="A1.T10.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">128</td>
</tr>
<tr id="A1.T10.3.1.2" class="ltx_tr">
<td id="A1.T10.3.1.2.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Dropout prob.</td>
<td id="A1.T10.3.1.2.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0</td>
<td id="A1.T10.3.1.2.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.1</td>
<td id="A1.T10.3.1.2.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0</td>
</tr>
<tr id="A1.T10.3.1.3" class="ltx_tr">
<td id="A1.T10.3.1.3.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">LR</td>
<td id="A1.T10.3.1.3.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.005</td>
<td id="A1.T10.3.1.3.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.003</td>
<td id="A1.T10.3.1.3.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0003</td>
</tr>
<tr id="A1.T10.3.1.4" class="ltx_tr">
<td id="A1.T10.3.1.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T10.3.1.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T10.3.1.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T10.3.1.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T10.3.1.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T10.3.1.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T10.3.1.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T10.3.1.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T10.3.1.4.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T10.3.1.4.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
</tr>
<tr id="A1.T10.3.1.5" class="ltx_tr">
<td id="A1.T10.3.1.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.5.1.1" class="ltx_text ltx_font_italic">MMLU</span></td>
<td id="A1.T10.3.1.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">36.30</td>
<td id="A1.T10.3.1.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.50</td>
<td id="A1.T10.3.1.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">36.80</td>
<td id="A1.T10.3.1.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">36.50</td>
<td id="A1.T10.3.1.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">37.20</td>
<td id="A1.T10.3.1.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">37.40</td>
<td id="A1.T10.3.1.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">33.20</td>
<td id="A1.T10.3.1.5.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.20</td>
<td id="A1.T10.3.1.5.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">33.80</td>
</tr>
<tr id="A1.T10.3.1.6" class="ltx_tr">
<td id="A1.T10.3.1.6.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.6.1.1" class="ltx_text ltx_font_italic">BoolQ</span></td>
<td id="A1.T10.3.1.6.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">80.00</td>
<td id="A1.T10.3.1.6.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">77.00</td>
<td id="A1.T10.3.1.6.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.00</td>
<td id="A1.T10.3.1.6.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.00</td>
<td id="A1.T10.3.1.6.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.00</td>
<td id="A1.T10.3.1.6.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">74.00</td>
<td id="A1.T10.3.1.6.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.00</td>
<td id="A1.T10.3.1.6.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.00</td>
<td id="A1.T10.3.1.6.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">80.00</td>
</tr>
<tr id="A1.T10.3.1.7" class="ltx_tr">
<td id="A1.T10.3.1.7.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.7.1.1" class="ltx_text ltx_font_italic">NarrativeQA</span></td>
<td id="A1.T10.3.1.7.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">55.60</td>
<td id="A1.T10.3.1.7.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">49.80</td>
<td id="A1.T10.3.1.7.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">55.00</td>
<td id="A1.T10.3.1.7.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">53.80</td>
<td id="A1.T10.3.1.7.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">51.60</td>
<td id="A1.T10.3.1.7.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">53.20</td>
<td id="A1.T10.3.1.7.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">51.00</td>
<td id="A1.T10.3.1.7.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">51.60</td>
<td id="A1.T10.3.1.7.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.90</td>
</tr>
<tr id="A1.T10.3.1.8" class="ltx_tr">
<td id="A1.T10.3.1.8.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.8.1.1" class="ltx_text ltx_font_italic">NaturalQuestions(closed)</span></td>
<td id="A1.T10.3.1.8.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">21.20</td>
<td id="A1.T10.3.1.8.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">22.00</td>
<td id="A1.T10.3.1.8.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.40</td>
<td id="A1.T10.3.1.8.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">21.40</td>
<td id="A1.T10.3.1.8.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.00</td>
<td id="A1.T10.3.1.8.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.60</td>
<td id="A1.T10.3.1.8.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.70</td>
<td id="A1.T10.3.1.8.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">22.20</td>
<td id="A1.T10.3.1.8.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.80</td>
</tr>
<tr id="A1.T10.3.1.9" class="ltx_tr">
<td id="A1.T10.3.1.9.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.9.1.1" class="ltx_text ltx_font_italic">NaturalQuestions(open)</span></td>
<td id="A1.T10.3.1.9.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">71.30</td>
<td id="A1.T10.3.1.9.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.90</td>
<td id="A1.T10.3.1.9.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.60</td>
<td id="A1.T10.3.1.9.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">70.90</td>
<td id="A1.T10.3.1.9.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">67.10</td>
<td id="A1.T10.3.1.9.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">69.40</td>
<td id="A1.T10.3.1.9.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">64.00</td>
<td id="A1.T10.3.1.9.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.90</td>
<td id="A1.T10.3.1.9.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">63.20</td>
</tr>
<tr id="A1.T10.3.1.10" class="ltx_tr">
<td id="A1.T10.3.1.10.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.10.1.1" class="ltx_text ltx_font_italic">QuAC</span></td>
<td id="A1.T10.3.1.10.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.30</td>
<td id="A1.T10.3.1.10.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">31.20</td>
<td id="A1.T10.3.1.10.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">31.20</td>
<td id="A1.T10.3.1.10.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.40</td>
<td id="A1.T10.3.1.10.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.40</td>
<td id="A1.T10.3.1.10.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.50</td>
<td id="A1.T10.3.1.10.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.10</td>
<td id="A1.T10.3.1.10.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.30</td>
<td id="A1.T10.3.1.10.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.60</td>
</tr>
<tr id="A1.T10.3.1.11" class="ltx_tr">
<td id="A1.T10.3.1.11.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.11.1.1" class="ltx_text ltx_font_italic">HellaSwag</span></td>
<td id="A1.T10.3.1.11.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.00</td>
<td id="A1.T10.3.1.11.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.00</td>
<td id="A1.T10.3.1.11.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">80.00</td>
<td id="A1.T10.3.1.11.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.00</td>
<td id="A1.T10.3.1.11.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.00</td>
<td id="A1.T10.3.1.11.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.00</td>
<td id="A1.T10.3.1.11.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.00</td>
<td id="A1.T10.3.1.11.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.00</td>
<td id="A1.T10.3.1.11.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">81.00</td>
</tr>
<tr id="A1.T10.3.1.12" class="ltx_tr">
<td id="A1.T10.3.1.12.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.12.1.1" class="ltx_text ltx_font_italic">OpenbookQA</span></td>
<td id="A1.T10.3.1.12.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.00</td>
<td id="A1.T10.3.1.12.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">53.00</td>
<td id="A1.T10.3.1.12.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.00</td>
<td id="A1.T10.3.1.12.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.00</td>
<td id="A1.T10.3.1.12.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">55.00</td>
<td id="A1.T10.3.1.12.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">51.00</td>
<td id="A1.T10.3.1.12.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.00</td>
<td id="A1.T10.3.1.12.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">49.00</td>
<td id="A1.T10.3.1.12.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.00</td>
</tr>
<tr id="A1.T10.3.1.13" class="ltx_tr">
<td id="A1.T10.3.1.13.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.13.1.1" class="ltx_text ltx_font_italic">TruthfulQA</span></td>
<td id="A1.T10.3.1.13.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">18.00</td>
<td id="A1.T10.3.1.13.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.00</td>
<td id="A1.T10.3.1.13.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.00</td>
<td id="A1.T10.3.1.13.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">24.00</td>
<td id="A1.T10.3.1.13.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">24.00</td>
<td id="A1.T10.3.1.13.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.00</td>
<td id="A1.T10.3.1.13.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.00</td>
<td id="A1.T10.3.1.13.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.00</td>
<td id="A1.T10.3.1.13.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.00</td>
</tr>
<tr id="A1.T10.3.1.14" class="ltx_tr">
<td id="A1.T10.3.1.14.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.14.1.1" class="ltx_text ltx_font_italic">MS MARCO (regular)</span></td>
<td id="A1.T10.3.1.14.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">18.60</td>
<td id="A1.T10.3.1.14.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.20</td>
<td id="A1.T10.3.1.14.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">17.40</td>
<td id="A1.T10.3.1.14.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">18.20</td>
<td id="A1.T10.3.1.14.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.50</td>
<td id="A1.T10.3.1.14.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">22.90</td>
<td id="A1.T10.3.1.14.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">17.20</td>
<td id="A1.T10.3.1.14.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.90</td>
<td id="A1.T10.3.1.14.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.00</td>
</tr>
<tr id="A1.T10.3.1.15" class="ltx_tr">
<td id="A1.T10.3.1.15.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.15.1.1" class="ltx_text ltx_font_italic">MS MARCO (TREC)</span></td>
<td id="A1.T10.3.1.15.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">40.60</td>
<td id="A1.T10.3.1.15.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.70</td>
<td id="A1.T10.3.1.15.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.50</td>
<td id="A1.T10.3.1.15.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">38.50</td>
<td id="A1.T10.3.1.15.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.20</td>
<td id="A1.T10.3.1.15.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.70</td>
<td id="A1.T10.3.1.15.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.40</td>
<td id="A1.T10.3.1.15.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.90</td>
<td id="A1.T10.3.1.15.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.70</td>
</tr>
<tr id="A1.T10.3.1.16" class="ltx_tr">
<td id="A1.T10.3.1.16.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.16.1.1" class="ltx_text ltx_font_italic">CNN/DailyMail</span></td>
<td id="A1.T10.3.1.16.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.10</td>
<td id="A1.T10.3.1.16.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.30</td>
<td id="A1.T10.3.1.16.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.00</td>
<td id="A1.T10.3.1.16.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.60</td>
<td id="A1.T10.3.1.16.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.40</td>
<td id="A1.T10.3.1.16.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.00</td>
<td id="A1.T10.3.1.16.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.00</td>
<td id="A1.T10.3.1.16.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.10</td>
<td id="A1.T10.3.1.16.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.80</td>
</tr>
<tr id="A1.T10.3.1.17" class="ltx_tr">
<td id="A1.T10.3.1.17.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.17.1.1" class="ltx_text ltx_font_italic">XSUM</span></td>
<td id="A1.T10.3.1.17.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.50</td>
<td id="A1.T10.3.1.17.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.10</td>
<td id="A1.T10.3.1.17.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.30</td>
<td id="A1.T10.3.1.17.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.70</td>
<td id="A1.T10.3.1.17.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.90</td>
<td id="A1.T10.3.1.17.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.80</td>
<td id="A1.T10.3.1.17.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.80</td>
<td id="A1.T10.3.1.17.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.50</td>
<td id="A1.T10.3.1.17.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.80</td>
</tr>
<tr id="A1.T10.3.1.18" class="ltx_tr">
<td id="A1.T10.3.1.18.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.18.1.1" class="ltx_text ltx_font_italic">IMDB</span></td>
<td id="A1.T10.3.1.18.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
<td id="A1.T10.3.1.18.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.00</td>
<td id="A1.T10.3.1.18.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">97.00</td>
<td id="A1.T10.3.1.18.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
<td id="A1.T10.3.1.18.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
<td id="A1.T10.3.1.18.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">97.00</td>
<td id="A1.T10.3.1.18.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.00</td>
<td id="A1.T10.3.1.18.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">96.00</td>
<td id="A1.T10.3.1.18.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.00</td>
</tr>
<tr id="A1.T10.3.1.19" class="ltx_tr">
<td id="A1.T10.3.1.19.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.19.1.1" class="ltx_text ltx_font_italic">CivilComments</span></td>
<td id="A1.T10.3.1.19.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.50</td>
<td id="A1.T10.3.1.19.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.00</td>
<td id="A1.T10.3.1.19.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">56.90</td>
<td id="A1.T10.3.1.19.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">57.00</td>
<td id="A1.T10.3.1.19.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.70</td>
<td id="A1.T10.3.1.19.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">58.30</td>
<td id="A1.T10.3.1.19.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">62.20</td>
<td id="A1.T10.3.1.19.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">57.30</td>
<td id="A1.T10.3.1.19.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.70</td>
</tr>
<tr id="A1.T10.3.1.20" class="ltx_tr">
<td id="A1.T10.3.1.20.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.20.1.1" class="ltx_text ltx_font_italic">RAFT</span></td>
<td id="A1.T10.3.1.20.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.70</td>
<td id="A1.T10.3.1.20.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.80</td>
<td id="A1.T10.3.1.20.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">58.80</td>
<td id="A1.T10.3.1.20.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">55.90</td>
<td id="A1.T10.3.1.20.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.60</td>
<td id="A1.T10.3.1.20.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">58.90</td>
<td id="A1.T10.3.1.20.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">64.80</td>
<td id="A1.T10.3.1.20.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.90</td>
<td id="A1.T10.3.1.20.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.80</td>
</tr>
<tr id="A1.T10.3.1.21" class="ltx_tr">
<td id="A1.T10.3.1.21.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T10.3.1.21.1.1" class="ltx_text ltx_font_bold">Average</span></td>
<td id="A1.T10.3.1.21.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.42</td>
<td id="A1.T10.3.1.21.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.91</td>
<td id="A1.T10.3.1.21.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">45.99</td>
<td id="A1.T10.3.1.21.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.68</td>
<td id="A1.T10.3.1.21.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.79</td>
<td id="A1.T10.3.1.21.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.23</td>
<td id="A1.T10.3.1.21.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.40</td>
<td id="A1.T10.3.1.21.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.05</td>
<td id="A1.T10.3.1.21.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">46.26</td>
</tr>
</table>
</span></div>
</figure>
<figure id="A1.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with P-tuning on <span id="A1.T11.2.1" class="ltx_text ltx_font_italic">Fed-Dolly</span>.</figcaption>
<div id="A1.T11.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:426.7pt;height:334.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.1pt,12.6pt) scale(0.93,0.93) ;">
<table id="A1.T11.3.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T11.3.1.1" class="ltx_tr">
<td id="A1.T11.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Virtual tokens</td>
<td id="A1.T11.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">20</td>
<td id="A1.T11.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">20</td>
<td id="A1.T11.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">30</td>
</tr>
<tr id="A1.T11.3.1.2" class="ltx_tr">
<td id="A1.T11.3.1.2.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">LR</td>
<td id="A1.T11.3.1.2.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0003</td>
<td id="A1.T11.3.1.2.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0005</td>
<td id="A1.T11.3.1.2.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0005</td>
</tr>
<tr id="A1.T11.3.1.3" class="ltx_tr">
<td id="A1.T11.3.1.3.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T11.3.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T11.3.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T11.3.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T11.3.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T11.3.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T11.3.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T11.3.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T11.3.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T11.3.1.3.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
</tr>
<tr id="A1.T11.3.1.4" class="ltx_tr">
<td id="A1.T11.3.1.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.4.1.1" class="ltx_text ltx_font_italic">MMLU</span></td>
<td id="A1.T11.3.1.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.20</td>
<td id="A1.T11.3.1.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.60</td>
<td id="A1.T11.3.1.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.20</td>
<td id="A1.T11.3.1.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.30</td>
<td id="A1.T11.3.1.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.10</td>
<td id="A1.T11.3.1.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.10</td>
<td id="A1.T11.3.1.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.30</td>
<td id="A1.T11.3.1.4.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.40</td>
<td id="A1.T11.3.1.4.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.10</td>
</tr>
<tr id="A1.T11.3.1.5" class="ltx_tr">
<td id="A1.T11.3.1.5.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.5.1.1" class="ltx_text ltx_font_italic">BoolQ</span></td>
<td id="A1.T11.3.1.5.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.00</td>
<td id="A1.T11.3.1.5.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.00</td>
<td id="A1.T11.3.1.5.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.00</td>
<td id="A1.T11.3.1.5.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">77.00</td>
<td id="A1.T11.3.1.5.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">80.00</td>
<td id="A1.T11.3.1.5.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">76.00</td>
<td id="A1.T11.3.1.5.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">82.00</td>
<td id="A1.T11.3.1.5.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.00</td>
<td id="A1.T11.3.1.5.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.00</td>
</tr>
<tr id="A1.T11.3.1.6" class="ltx_tr">
<td id="A1.T11.3.1.6.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.6.1.1" class="ltx_text ltx_font_italic">NarrativeQA</span></td>
<td id="A1.T11.3.1.6.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.40</td>
<td id="A1.T11.3.1.6.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">54.60</td>
<td id="A1.T11.3.1.6.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.60</td>
<td id="A1.T11.3.1.6.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.30</td>
<td id="A1.T11.3.1.6.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.10</td>
<td id="A1.T11.3.1.6.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">49.70</td>
<td id="A1.T11.3.1.6.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.20</td>
<td id="A1.T11.3.1.6.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.30</td>
<td id="A1.T11.3.1.6.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.50</td>
</tr>
<tr id="A1.T11.3.1.7" class="ltx_tr">
<td id="A1.T11.3.1.7.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.7.1.1" class="ltx_text ltx_font_italic">NaturalQuestions(closed)</span></td>
<td id="A1.T11.3.1.7.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">26.20</td>
<td id="A1.T11.3.1.7.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.50</td>
<td id="A1.T11.3.1.7.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.00</td>
<td id="A1.T11.3.1.7.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.40</td>
<td id="A1.T11.3.1.7.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">27.60</td>
<td id="A1.T11.3.1.7.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.50</td>
<td id="A1.T11.3.1.7.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.60</td>
<td id="A1.T11.3.1.7.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">24.90</td>
<td id="A1.T11.3.1.7.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">27.10</td>
</tr>
<tr id="A1.T11.3.1.8" class="ltx_tr">
<td id="A1.T11.3.1.8.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.8.1.1" class="ltx_text ltx_font_italic">NaturalQuestions(open)</span></td>
<td id="A1.T11.3.1.8.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.80</td>
<td id="A1.T11.3.1.8.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.10</td>
<td id="A1.T11.3.1.8.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.60</td>
<td id="A1.T11.3.1.8.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">67.10</td>
<td id="A1.T11.3.1.8.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.20</td>
<td id="A1.T11.3.1.8.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">64.00</td>
<td id="A1.T11.3.1.8.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.80</td>
<td id="A1.T11.3.1.8.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">65.90</td>
<td id="A1.T11.3.1.8.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">65.60</td>
</tr>
<tr id="A1.T11.3.1.9" class="ltx_tr">
<td id="A1.T11.3.1.9.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.9.1.1" class="ltx_text ltx_font_italic">QuAC</span></td>
<td id="A1.T11.3.1.9.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.80</td>
<td id="A1.T11.3.1.9.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.00</td>
<td id="A1.T11.3.1.9.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.50</td>
<td id="A1.T11.3.1.9.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.10</td>
<td id="A1.T11.3.1.9.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">27.70</td>
<td id="A1.T11.3.1.9.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.80</td>
<td id="A1.T11.3.1.9.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">31.10</td>
<td id="A1.T11.3.1.9.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.50</td>
<td id="A1.T11.3.1.9.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.20</td>
</tr>
<tr id="A1.T11.3.1.10" class="ltx_tr">
<td id="A1.T11.3.1.10.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.10.1.1" class="ltx_text ltx_font_italic">HellaSwag</span></td>
<td id="A1.T11.3.1.10.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">22.00</td>
<td id="A1.T11.3.1.10.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">22.00</td>
<td id="A1.T11.3.1.10.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.00</td>
<td id="A1.T11.3.1.10.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.00</td>
<td id="A1.T11.3.1.10.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.00</td>
<td id="A1.T11.3.1.10.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">21.00</td>
<td id="A1.T11.3.1.10.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">17.00</td>
<td id="A1.T11.3.1.10.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.00</td>
<td id="A1.T11.3.1.10.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">19.00</td>
</tr>
<tr id="A1.T11.3.1.11" class="ltx_tr">
<td id="A1.T11.3.1.11.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.11.1.1" class="ltx_text ltx_font_italic">OpenbookQA</span></td>
<td id="A1.T11.3.1.11.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.30</td>
<td id="A1.T11.3.1.11.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.30</td>
<td id="A1.T11.3.1.11.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">27.30</td>
<td id="A1.T11.3.1.11.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.30</td>
<td id="A1.T11.3.1.11.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.30</td>
<td id="A1.T11.3.1.11.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">18.30</td>
<td id="A1.T11.3.1.11.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.30</td>
<td id="A1.T11.3.1.11.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">22.30</td>
<td id="A1.T11.3.1.11.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.30</td>
</tr>
<tr id="A1.T11.3.1.12" class="ltx_tr">
<td id="A1.T11.3.1.12.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.12.1.1" class="ltx_text ltx_font_italic">TruthfulQA</span></td>
<td id="A1.T11.3.1.12.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.00</td>
<td id="A1.T11.3.1.12.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.00</td>
<td id="A1.T11.3.1.12.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">33.00</td>
<td id="A1.T11.3.1.12.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.00</td>
<td id="A1.T11.3.1.12.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.00</td>
<td id="A1.T11.3.1.12.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.00</td>
<td id="A1.T11.3.1.12.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.00</td>
<td id="A1.T11.3.1.12.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">26.00</td>
<td id="A1.T11.3.1.12.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.00</td>
</tr>
<tr id="A1.T11.3.1.13" class="ltx_tr">
<td id="A1.T11.3.1.13.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.13.1.1" class="ltx_text ltx_font_italic">MS MARCO (regular)</span></td>
<td id="A1.T11.3.1.13.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">18.10</td>
<td id="A1.T11.3.1.13.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">17.60</td>
<td id="A1.T11.3.1.13.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">16.00</td>
<td id="A1.T11.3.1.13.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.70</td>
<td id="A1.T11.3.1.13.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.50</td>
<td id="A1.T11.3.1.13.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.90</td>
<td id="A1.T11.3.1.13.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.50</td>
<td id="A1.T11.3.1.13.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.80</td>
<td id="A1.T11.3.1.13.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">16.40</td>
</tr>
<tr id="A1.T11.3.1.14" class="ltx_tr">
<td id="A1.T11.3.1.14.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.14.1.1" class="ltx_text ltx_font_italic">MS MARCO (TREC)</span></td>
<td id="A1.T11.3.1.14.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">45.00</td>
<td id="A1.T11.3.1.14.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.50</td>
<td id="A1.T11.3.1.14.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.60</td>
<td id="A1.T11.3.1.14.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">43.50</td>
<td id="A1.T11.3.1.14.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.40</td>
<td id="A1.T11.3.1.14.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">36.40</td>
<td id="A1.T11.3.1.14.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.00</td>
<td id="A1.T11.3.1.14.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.00</td>
<td id="A1.T11.3.1.14.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">44.00</td>
</tr>
<tr id="A1.T11.3.1.15" class="ltx_tr">
<td id="A1.T11.3.1.15.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.15.1.1" class="ltx_text ltx_font_italic">CNN/DailyMail</span></td>
<td id="A1.T11.3.1.15.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.90</td>
<td id="A1.T11.3.1.15.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.70</td>
<td id="A1.T11.3.1.15.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.70</td>
<td id="A1.T11.3.1.15.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.40</td>
<td id="A1.T11.3.1.15.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.40</td>
<td id="A1.T11.3.1.15.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.40</td>
<td id="A1.T11.3.1.15.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.50</td>
<td id="A1.T11.3.1.15.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.50</td>
<td id="A1.T11.3.1.15.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.30</td>
</tr>
<tr id="A1.T11.3.1.16" class="ltx_tr">
<td id="A1.T11.3.1.16.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.16.1.1" class="ltx_text ltx_font_italic">XSUM</span></td>
<td id="A1.T11.3.1.16.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.30</td>
<td id="A1.T11.3.1.16.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.00</td>
<td id="A1.T11.3.1.16.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.50</td>
<td id="A1.T11.3.1.16.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.30</td>
<td id="A1.T11.3.1.16.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.60</td>
<td id="A1.T11.3.1.16.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
<td id="A1.T11.3.1.16.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.60</td>
<td id="A1.T11.3.1.16.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.50</td>
<td id="A1.T11.3.1.16.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.70</td>
</tr>
<tr id="A1.T11.3.1.17" class="ltx_tr">
<td id="A1.T11.3.1.17.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.17.1.1" class="ltx_text ltx_font_italic">IMDB</span></td>
<td id="A1.T11.3.1.17.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
<td id="A1.T11.3.1.17.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">92.00</td>
<td id="A1.T11.3.1.17.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
<td id="A1.T11.3.1.17.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">93.00</td>
<td id="A1.T11.3.1.17.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
<td id="A1.T11.3.1.17.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
<td id="A1.T11.3.1.17.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
<td id="A1.T11.3.1.17.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
<td id="A1.T11.3.1.17.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
</tr>
<tr id="A1.T11.3.1.18" class="ltx_tr">
<td id="A1.T11.3.1.18.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.18.1.1" class="ltx_text ltx_font_italic">CivilComments</span></td>
<td id="A1.T11.3.1.18.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">63.70</td>
<td id="A1.T11.3.1.18.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.40</td>
<td id="A1.T11.3.1.18.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.60</td>
<td id="A1.T11.3.1.18.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.90</td>
<td id="A1.T11.3.1.18.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">62.20</td>
<td id="A1.T11.3.1.18.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">57.40</td>
<td id="A1.T11.3.1.18.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">56.60</td>
<td id="A1.T11.3.1.18.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.70</td>
<td id="A1.T11.3.1.18.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">63.10</td>
</tr>
<tr id="A1.T11.3.1.19" class="ltx_tr">
<td id="A1.T11.3.1.19.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.19.1.1" class="ltx_text ltx_font_italic">RAFT</span></td>
<td id="A1.T11.3.1.19.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.60</td>
<td id="A1.T11.3.1.19.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.70</td>
<td id="A1.T11.3.1.19.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.10</td>
<td id="A1.T11.3.1.19.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">63.20</td>
<td id="A1.T11.3.1.19.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.90</td>
<td id="A1.T11.3.1.19.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.60</td>
<td id="A1.T11.3.1.19.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.40</td>
<td id="A1.T11.3.1.19.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.40</td>
<td id="A1.T11.3.1.19.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">62.30</td>
</tr>
<tr id="A1.T11.3.1.20" class="ltx_tr">
<td id="A1.T11.3.1.20.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T11.3.1.20.1.1" class="ltx_text ltx_font_bold">Average</span></td>
<td id="A1.T11.3.1.20.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.83</td>
<td id="A1.T11.3.1.20.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.06</td>
<td id="A1.T11.3.1.20.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.61</td>
<td id="A1.T11.3.1.20.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">42.03</td>
<td id="A1.T11.3.1.20.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.44</td>
<td id="A1.T11.3.1.20.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">40.08</td>
<td id="A1.T11.3.1.20.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.56</td>
<td id="A1.T11.3.1.20.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.83</td>
<td id="A1.T11.3.1.20.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.54</td>
</tr>
</table>
</span></div>
</figure>
<figure id="A1.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with prompt tuning on <span id="A1.T12.2.1" class="ltx_text ltx_font_italic">Fed-Dolly</span>. In this table, the initialized prompt is “Assume you can understand and answer questions.”. The number of virtual tokens is 9.</figcaption>
<div id="A1.T12.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:408.1pt;height:318.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.4pt,12.0pt) scale(0.93,0.93) ;">
<table id="A1.T12.3.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T12.3.1.1" class="ltx_tr">
<td id="A1.T12.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">LR</td>
<td id="A1.T12.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0003</td>
<td id="A1.T12.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.0005</td>
<td id="A1.T12.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="3">0.001</td>
</tr>
<tr id="A1.T12.3.1.2" class="ltx_tr">
<td id="A1.T12.3.1.2.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T12.3.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T12.3.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T12.3.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T12.3.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T12.3.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T12.3.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T12.3.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T12.3.1.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T12.3.1.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
</tr>
<tr id="A1.T12.3.1.3" class="ltx_tr">
<td id="A1.T12.3.1.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.3.1.1" class="ltx_text ltx_font_italic">MMLU</span></td>
<td id="A1.T12.3.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.10</td>
<td id="A1.T12.3.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.50</td>
<td id="A1.T12.3.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.00</td>
<td id="A1.T12.3.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.10</td>
<td id="A1.T12.3.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.50</td>
<td id="A1.T12.3.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.60</td>
<td id="A1.T12.3.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">36.00</td>
<td id="A1.T12.3.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.40</td>
<td id="A1.T12.3.1.3.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.20</td>
</tr>
<tr id="A1.T12.3.1.4" class="ltx_tr">
<td id="A1.T12.3.1.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.4.1.1" class="ltx_text ltx_font_italic">BoolQ</span></td>
<td id="A1.T12.3.1.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">79.00</td>
<td id="A1.T12.3.1.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">77.00</td>
<td id="A1.T12.3.1.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">76.00</td>
<td id="A1.T12.3.1.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">77.00</td>
<td id="A1.T12.3.1.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">78.00</td>
<td id="A1.T12.3.1.4.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">74.00</td>
<td id="A1.T12.3.1.4.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">77.00</td>
<td id="A1.T12.3.1.4.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">77.00</td>
<td id="A1.T12.3.1.4.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">76.00</td>
</tr>
<tr id="A1.T12.3.1.5" class="ltx_tr">
<td id="A1.T12.3.1.5.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.5.1.1" class="ltx_text ltx_font_italic">NarrativeQA</span></td>
<td id="A1.T12.3.1.5.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.10</td>
<td id="A1.T12.3.1.5.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">49.20</td>
<td id="A1.T12.3.1.5.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.10</td>
<td id="A1.T12.3.1.5.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.50</td>
<td id="A1.T12.3.1.5.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">51.50</td>
<td id="A1.T12.3.1.5.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.10</td>
<td id="A1.T12.3.1.5.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.10</td>
<td id="A1.T12.3.1.5.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">52.70</td>
<td id="A1.T12.3.1.5.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">50.40</td>
</tr>
<tr id="A1.T12.3.1.6" class="ltx_tr">
<td id="A1.T12.3.1.6.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.6.1.1" class="ltx_text ltx_font_italic">NaturalQuestions(closed)</span></td>
<td id="A1.T12.3.1.6.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">24.70</td>
<td id="A1.T12.3.1.6.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">24.40</td>
<td id="A1.T12.3.1.6.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">24.90</td>
<td id="A1.T12.3.1.6.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.50</td>
<td id="A1.T12.3.1.6.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.80</td>
<td id="A1.T12.3.1.6.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">24.30</td>
<td id="A1.T12.3.1.6.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">23.80</td>
<td id="A1.T12.3.1.6.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">26.30</td>
<td id="A1.T12.3.1.6.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.80</td>
</tr>
<tr id="A1.T12.3.1.7" class="ltx_tr">
<td id="A1.T12.3.1.7.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.7.1.1" class="ltx_text ltx_font_italic">NaturalQuestions(open)</span></td>
<td id="A1.T12.3.1.7.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.60</td>
<td id="A1.T12.3.1.7.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">64.60</td>
<td id="A1.T12.3.1.7.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">66.00</td>
<td id="A1.T12.3.1.7.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">64.90</td>
<td id="A1.T12.3.1.7.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">62.80</td>
<td id="A1.T12.3.1.7.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">65.80</td>
<td id="A1.T12.3.1.7.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.90</td>
<td id="A1.T12.3.1.7.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">63.00</td>
<td id="A1.T12.3.1.7.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">64.60</td>
</tr>
<tr id="A1.T12.3.1.8" class="ltx_tr">
<td id="A1.T12.3.1.8.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.8.1.1" class="ltx_text ltx_font_italic">QuAC</span></td>
<td id="A1.T12.3.1.8.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.00</td>
<td id="A1.T12.3.1.8.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.50</td>
<td id="A1.T12.3.1.8.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.40</td>
<td id="A1.T12.3.1.8.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.50</td>
<td id="A1.T12.3.1.8.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.00</td>
<td id="A1.T12.3.1.8.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.60</td>
<td id="A1.T12.3.1.8.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.20</td>
<td id="A1.T12.3.1.8.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">30.10</td>
<td id="A1.T12.3.1.8.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">28.60</td>
</tr>
<tr id="A1.T12.3.1.9" class="ltx_tr">
<td id="A1.T12.3.1.9.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.9.1.1" class="ltx_text ltx_font_italic">HellaSwag</span></td>
<td id="A1.T12.3.1.9.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">19.00</td>
<td id="A1.T12.3.1.9.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">19.00</td>
<td id="A1.T12.3.1.9.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.00</td>
<td id="A1.T12.3.1.9.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">21.00</td>
<td id="A1.T12.3.1.9.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">19.00</td>
<td id="A1.T12.3.1.9.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.00</td>
<td id="A1.T12.3.1.9.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">21.00</td>
<td id="A1.T12.3.1.9.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.00</td>
<td id="A1.T12.3.1.9.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">19.00</td>
</tr>
<tr id="A1.T12.3.1.10" class="ltx_tr">
<td id="A1.T12.3.1.10.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.10.1.1" class="ltx_text ltx_font_italic">OpenbookQA</span></td>
<td id="A1.T12.3.1.10.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">27.30</td>
<td id="A1.T12.3.1.10.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.00</td>
<td id="A1.T12.3.1.10.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">21.00</td>
<td id="A1.T12.3.1.10.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.30</td>
<td id="A1.T12.3.1.10.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">27.30</td>
<td id="A1.T12.3.1.10.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">20.30</td>
<td id="A1.T12.3.1.10.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">27.30</td>
<td id="A1.T12.3.1.10.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">19.30</td>
<td id="A1.T12.3.1.10.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">19.00</td>
</tr>
<tr id="A1.T12.3.1.11" class="ltx_tr">
<td id="A1.T12.3.1.11.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.11.1.1" class="ltx_text ltx_font_italic">TruthfulQA</span></td>
<td id="A1.T12.3.1.11.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.00</td>
<td id="A1.T12.3.1.11.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.00</td>
<td id="A1.T12.3.1.11.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">34.00</td>
<td id="A1.T12.3.1.11.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">32.00</td>
<td id="A1.T12.3.1.11.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">31.00</td>
<td id="A1.T12.3.1.11.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">33.00</td>
<td id="A1.T12.3.1.11.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">29.00</td>
<td id="A1.T12.3.1.11.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">36.00</td>
<td id="A1.T12.3.1.11.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">33.00</td>
</tr>
<tr id="A1.T12.3.1.12" class="ltx_tr">
<td id="A1.T12.3.1.12.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.12.1.1" class="ltx_text ltx_font_italic">MS MARCO (regular)</span></td>
<td id="A1.T12.3.1.12.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.60</td>
<td id="A1.T12.3.1.12.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.50</td>
<td id="A1.T12.3.1.12.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.70</td>
<td id="A1.T12.3.1.12.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.10</td>
<td id="A1.T12.3.1.12.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.20</td>
<td id="A1.T12.3.1.12.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.10</td>
<td id="A1.T12.3.1.12.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.70</td>
<td id="A1.T12.3.1.12.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">17.70</td>
<td id="A1.T12.3.1.12.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">21.80</td>
</tr>
<tr id="A1.T12.3.1.13" class="ltx_tr">
<td id="A1.T12.3.1.13.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.13.1.1" class="ltx_text ltx_font_italic">MS MARCO (TREC)</span></td>
<td id="A1.T12.3.1.13.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.90</td>
<td id="A1.T12.3.1.13.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.20</td>
<td id="A1.T12.3.1.13.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.00</td>
<td id="A1.T12.3.1.13.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.70</td>
<td id="A1.T12.3.1.13.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.60</td>
<td id="A1.T12.3.1.13.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">35.30</td>
<td id="A1.T12.3.1.13.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.80</td>
<td id="A1.T12.3.1.13.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">43.20</td>
<td id="A1.T12.3.1.13.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">43.70</td>
</tr>
<tr id="A1.T12.3.1.14" class="ltx_tr">
<td id="A1.T12.3.1.14.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.14.1.1" class="ltx_text ltx_font_italic">CNN/DailyMail</span></td>
<td id="A1.T12.3.1.14.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.30</td>
<td id="A1.T12.3.1.14.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.00</td>
<td id="A1.T12.3.1.14.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.70</td>
<td id="A1.T12.3.1.14.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.60</td>
<td id="A1.T12.3.1.14.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.20</td>
<td id="A1.T12.3.1.14.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.90</td>
<td id="A1.T12.3.1.14.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.30</td>
<td id="A1.T12.3.1.14.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.10</td>
<td id="A1.T12.3.1.14.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.40</td>
</tr>
<tr id="A1.T12.3.1.15" class="ltx_tr">
<td id="A1.T12.3.1.15.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.15.1.1" class="ltx_text ltx_font_italic">XSUM</span></td>
<td id="A1.T12.3.1.15.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.30</td>
<td id="A1.T12.3.1.15.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.10</td>
<td id="A1.T12.3.1.15.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.40</td>
<td id="A1.T12.3.1.15.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.70</td>
<td id="A1.T12.3.1.15.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.20</td>
<td id="A1.T12.3.1.15.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.70</td>
<td id="A1.T12.3.1.15.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.70</td>
<td id="A1.T12.3.1.15.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.20</td>
<td id="A1.T12.3.1.15.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.10</td>
</tr>
<tr id="A1.T12.3.1.16" class="ltx_tr">
<td id="A1.T12.3.1.16.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.16.1.1" class="ltx_text ltx_font_italic">IMDB</span></td>
<td id="A1.T12.3.1.16.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
<td id="A1.T12.3.1.16.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">97.00</td>
<td id="A1.T12.3.1.16.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">98.00</td>
<td id="A1.T12.3.1.16.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
<td id="A1.T12.3.1.16.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
<td id="A1.T12.3.1.16.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
<td id="A1.T12.3.1.16.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">91.00</td>
<td id="A1.T12.3.1.16.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">94.00</td>
<td id="A1.T12.3.1.16.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">95.00</td>
</tr>
<tr id="A1.T12.3.1.17" class="ltx_tr">
<td id="A1.T12.3.1.17.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.17.1.1" class="ltx_text ltx_font_italic">CivilComments</span></td>
<td id="A1.T12.3.1.17.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.30</td>
<td id="A1.T12.3.1.17.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.10</td>
<td id="A1.T12.3.1.17.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">62.30</td>
<td id="A1.T12.3.1.17.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">62.60</td>
<td id="A1.T12.3.1.17.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">54.70</td>
<td id="A1.T12.3.1.17.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">56.60</td>
<td id="A1.T12.3.1.17.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">58.50</td>
<td id="A1.T12.3.1.17.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.90</td>
<td id="A1.T12.3.1.17.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.00</td>
</tr>
<tr id="A1.T12.3.1.18" class="ltx_tr">
<td id="A1.T12.3.1.18.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.18.1.1" class="ltx_text ltx_font_italic">RAFT</span></td>
<td id="A1.T12.3.1.18.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.50</td>
<td id="A1.T12.3.1.18.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.50</td>
<td id="A1.T12.3.1.18.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.20</td>
<td id="A1.T12.3.1.18.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">58.60</td>
<td id="A1.T12.3.1.18.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">56.80</td>
<td id="A1.T12.3.1.18.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">59.30</td>
<td id="A1.T12.3.1.18.8" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">54.80</td>
<td id="A1.T12.3.1.18.9" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">60.20</td>
<td id="A1.T12.3.1.18.10" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">61.80</td>
</tr>
<tr id="A1.T12.3.1.19" class="ltx_tr">
<td id="A1.T12.3.1.19.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span id="A1.T12.3.1.19.1.1" class="ltx_text ltx_font_bold">Average</span></td>
<td id="A1.T12.3.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">40.79</td>
<td id="A1.T12.3.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">40.41</td>
<td id="A1.T12.3.1.19.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">40.73</td>
<td id="A1.T12.3.1.19.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.26</td>
<td id="A1.T12.3.1.19.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">40.35</td>
<td id="A1.T12.3.1.19.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.91</td>
<td id="A1.T12.3.1.19.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">39.82</td>
<td id="A1.T12.3.1.19.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.19</td>
<td id="A1.T12.3.1.19.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">41.15</td>
</tr>
</table>
</span></div>
</figure>
<figure id="A1.T13" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with LoRA on <span id="A1.T13.2.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span>.</figcaption>
<table id="A1.T13.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T13.3.1" class="ltx_tr">
<td id="A1.T13.3.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Scaling coef.</td>
<td id="A1.T13.3.1.2" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T13.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="6">LR</td>
</tr>
<tr id="A1.T13.3.2" class="ltx_tr">
<td id="A1.T13.3.2.1" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T13.3.2.2" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T13.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0001</td>
<td id="A1.T13.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0003</td>
<td id="A1.T13.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0005</td>
<td id="A1.T13.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.001</td>
<td id="A1.T13.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.003</td>
<td id="A1.T13.3.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.005</td>
</tr>
<tr id="A1.T13.3.3" class="ltx_tr">
<td id="A1.T13.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T13.3.3.1.1" class="ltx_text">16</span></td>
<td id="A1.T13.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T13.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.79</td>
<td id="A1.T13.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.97</td>
<td id="A1.T13.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.87</td>
<td id="A1.T13.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.26</td>
<td id="A1.T13.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.13</td>
<td id="A1.T13.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
</tr>
<tr id="A1.T13.3.4" class="ltx_tr">
<td id="A1.T13.3.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T13.3.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.34</td>
<td id="A1.T13.3.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.19</td>
<td id="A1.T13.3.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.95</td>
<td id="A1.T13.3.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.95</td>
<td id="A1.T13.3.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.55</td>
<td id="A1.T13.3.4.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.04</td>
</tr>
<tr id="A1.T13.3.5" class="ltx_tr">
<td id="A1.T13.3.5.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T13.3.5.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.17</td>
<td id="A1.T13.3.5.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.37</td>
<td id="A1.T13.3.5.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
<td id="A1.T13.3.5.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.33</td>
<td id="A1.T13.3.5.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.83</td>
<td id="A1.T13.3.5.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.42</td>
</tr>
<tr id="A1.T13.3.6" class="ltx_tr">
<td id="A1.T13.3.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T13.3.6.1.1" class="ltx_text">32</span></td>
<td id="A1.T13.3.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T13.3.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.82</td>
<td id="A1.T13.3.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.73</td>
<td id="A1.T13.3.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.25</td>
<td id="A1.T13.3.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.21</td>
<td id="A1.T13.3.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.99</td>
<td id="A1.T13.3.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">4.09</td>
</tr>
<tr id="A1.T13.3.7" class="ltx_tr">
<td id="A1.T13.3.7.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T13.3.7.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.81</td>
<td id="A1.T13.3.7.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.04</td>
<td id="A1.T13.3.7.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.79</td>
<td id="A1.T13.3.7.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.16</td>
<td id="A1.T13.3.7.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.19</td>
<td id="A1.T13.3.7.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.00</td>
</tr>
<tr id="A1.T13.3.8" class="ltx_tr">
<td id="A1.T13.3.8.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T13.3.8.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.10</td>
<td id="A1.T13.3.8.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.79</td>
<td id="A1.T13.3.8.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.95</td>
<td id="A1.T13.3.8.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.9</td>
<td id="A1.T13.3.8.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.89</td>
<td id="A1.T13.3.8.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.87</td>
</tr>
<tr id="A1.T13.3.9" class="ltx_tr">
<td id="A1.T13.3.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T13.3.9.1.1" class="ltx_text">64</span></td>
<td id="A1.T13.3.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T13.3.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.95</td>
<td id="A1.T13.3.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.61</td>
<td id="A1.T13.3.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.30</td>
<td id="A1.T13.3.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.13</td>
<td id="A1.T13.3.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.42</td>
<td id="A1.T13.3.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.00</td>
</tr>
<tr id="A1.T13.3.10" class="ltx_tr">
<td id="A1.T13.3.10.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T13.3.10.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.26</td>
<td id="A1.T13.3.10.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T13.3.10.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.30</td>
<td id="A1.T13.3.10.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.99</td>
<td id="A1.T13.3.10.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.00</td>
<td id="A1.T13.3.10.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.30</td>
</tr>
<tr id="A1.T13.3.11" class="ltx_tr">
<td id="A1.T13.3.11.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T13.3.11.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.93</td>
<td id="A1.T13.3.11.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.46</td>
<td id="A1.T13.3.11.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.28</td>
<td id="A1.T13.3.11.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.43</td>
<td id="A1.T13.3.11.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.28</td>
<td id="A1.T13.3.11.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.42</td>
</tr>
<tr id="A1.T13.3.12" class="ltx_tr">
<td id="A1.T13.3.12.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T13.3.12.1.1" class="ltx_text">128</span></td>
<td id="A1.T13.3.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T13.3.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.93</td>
<td id="A1.T13.3.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.14</td>
<td id="A1.T13.3.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.96</td>
<td id="A1.T13.3.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">3.49</td>
<td id="A1.T13.3.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.31</td>
<td id="A1.T13.3.12.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.47</td>
</tr>
<tr id="A1.T13.3.13" class="ltx_tr">
<td id="A1.T13.3.13.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T13.3.13.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.54</td>
<td id="A1.T13.3.13.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T13.3.13.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.12</td>
<td id="A1.T13.3.13.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.99</td>
<td id="A1.T13.3.13.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">15.09</td>
<td id="A1.T13.3.13.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.92</td>
</tr>
<tr id="A1.T13.3.14" class="ltx_tr">
<td id="A1.T13.3.14.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T13.3.14.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.25</td>
<td id="A1.T13.3.14.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.83</td>
<td id="A1.T13.3.14.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.60</td>
<td id="A1.T13.3.14.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.96</td>
<td id="A1.T13.3.14.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.28</td>
<td id="A1.T13.3.14.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.60</td>
</tr>
</table>
</figure>
<figure id="A1.T14" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with P-tuning on <span id="A1.T14.2.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span>.</figcaption>
<table id="A1.T14.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T14.3.1" class="ltx_tr">
<td id="A1.T14.3.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Virtual tokens</td>
<td id="A1.T14.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T14.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="6">LR</td>
</tr>
<tr id="A1.T14.3.2" class="ltx_tr">
<td id="A1.T14.3.2.1" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T14.3.2.2" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T14.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0001</td>
<td id="A1.T14.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0003</td>
<td id="A1.T14.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0005</td>
<td id="A1.T14.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.001</td>
<td id="A1.T14.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.003</td>
<td id="A1.T14.3.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.005</td>
</tr>
<tr id="A1.T14.3.3" class="ltx_tr">
<td id="A1.T14.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T14.3.3.1.1" class="ltx_text">10</span></td>
<td id="A1.T14.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T14.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.16</td>
<td id="A1.T14.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.07</td>
<td id="A1.T14.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.69</td>
<td id="A1.T14.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
<td id="A1.T14.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.28</td>
<td id="A1.T14.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">14.03</td>
</tr>
<tr id="A1.T14.3.4" class="ltx_tr">
<td id="A1.T14.3.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T14.3.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.96</td>
<td id="A1.T14.3.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T14.3.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.61</td>
<td id="A1.T14.3.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.90</td>
<td id="A1.T14.3.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.60</td>
<td id="A1.T14.3.4.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
</tr>
<tr id="A1.T14.3.5" class="ltx_tr">
<td id="A1.T14.3.5.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T14.3.5.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.64</td>
<td id="A1.T14.3.5.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T14.3.5.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
<td id="A1.T14.3.5.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.39</td>
<td id="A1.T14.3.5.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.37</td>
<td id="A1.T14.3.5.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
</tr>
<tr id="A1.T14.3.6" class="ltx_tr">
<td id="A1.T14.3.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T14.3.6.1.1" class="ltx_text">20</span></td>
<td id="A1.T14.3.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T14.3.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T14.3.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
<td id="A1.T14.3.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.74</td>
<td id="A1.T14.3.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.75</td>
<td id="A1.T14.3.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T14.3.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.24</td>
</tr>
<tr id="A1.T14.3.7" class="ltx_tr">
<td id="A1.T14.3.7.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T14.3.7.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.26</td>
<td id="A1.T14.3.7.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.17</td>
<td id="A1.T14.3.7.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.08</td>
<td id="A1.T14.3.7.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.60</td>
<td id="A1.T14.3.7.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.36</td>
<td id="A1.T14.3.7.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.72</td>
</tr>
<tr id="A1.T14.3.8" class="ltx_tr">
<td id="A1.T14.3.8.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T14.3.8.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.39</td>
<td id="A1.T14.3.8.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.54</td>
<td id="A1.T14.3.8.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.77</td>
<td id="A1.T14.3.8.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.01</td>
<td id="A1.T14.3.8.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.77</td>
<td id="A1.T14.3.8.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.68</td>
</tr>
<tr id="A1.T14.3.9" class="ltx_tr">
<td id="A1.T14.3.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="3"><span id="A1.T14.3.9.1.1" class="ltx_text">30</span></td>
<td id="A1.T14.3.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T14.3.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.08</td>
<td id="A1.T14.3.9.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.14</td>
<td id="A1.T14.3.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">12.05</td>
<td id="A1.T14.3.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.07</td>
<td id="A1.T14.3.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.69</td>
<td id="A1.T14.3.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.19</td>
</tr>
<tr id="A1.T14.3.10" class="ltx_tr">
<td id="A1.T14.3.10.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T14.3.10.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.60</td>
<td id="A1.T14.3.10.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.63</td>
<td id="A1.T14.3.10.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.33</td>
<td id="A1.T14.3.10.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.25</td>
<td id="A1.T14.3.10.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.16</td>
<td id="A1.T14.3.10.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.84</td>
</tr>
<tr id="A1.T14.3.11" class="ltx_tr">
<td id="A1.T14.3.11.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T14.3.11.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.87</td>
<td id="A1.T14.3.11.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.93</td>
<td id="A1.T14.3.11.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.77</td>
<td id="A1.T14.3.11.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.46</td>
<td id="A1.T14.3.11.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.39</td>
<td id="A1.T14.3.11.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">11.22</td>
</tr>
</table>
</figure>
<figure id="A1.T15" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 15: </span>Evaluation scores (%): federated fine-tuning LLaMA-7B with prompt tuning on <span id="A1.T15.2.1" class="ltx_text ltx_font_italic">Fed-GSM8K-3</span>. In this table, the initialized prompt is “Think step by step.”. The number of virtual tokens is 6.</figcaption>
<table id="A1.T15.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T15.3.1" class="ltx_tr">
<td id="A1.T15.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Seed</td>
<td id="A1.T15.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;" colspan="6">LR</td>
</tr>
<tr id="A1.T15.3.2" class="ltx_tr">
<td id="A1.T15.3.2.1" class="ltx_td" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td id="A1.T15.3.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0001</td>
<td id="A1.T15.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0003</td>
<td id="A1.T15.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.0005</td>
<td id="A1.T15.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.001</td>
<td id="A1.T15.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.003</td>
<td id="A1.T15.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0.005</td>
</tr>
<tr id="A1.T15.3.3" class="ltx_tr">
<td id="A1.T15.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">0</td>
<td id="A1.T15.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.64</td>
<td id="A1.T15.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.01</td>
<td id="A1.T15.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.33</td>
<td id="A1.T15.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.08</td>
<td id="A1.T15.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.70</td>
<td id="A1.T15.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.93</td>
</tr>
<tr id="A1.T15.3.4" class="ltx_tr">
<td id="A1.T15.3.4.1" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td id="A1.T15.3.4.2" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.19</td>
<td id="A1.T15.3.4.3" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.33</td>
<td id="A1.T15.3.4.4" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.78</td>
<td id="A1.T15.3.4.5" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.10</td>
<td id="A1.T15.3.4.6" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.28</td>
<td id="A1.T15.3.4.7" class="ltx_td ltx_align_center" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.10</td>
</tr>
<tr id="A1.T15.3.5" class="ltx_tr">
<td id="A1.T15.3.5.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td id="A1.T15.3.5.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.79</td>
<td id="A1.T15.3.5.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.87</td>
<td id="A1.T15.3.5.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.72</td>
<td id="A1.T15.3.5.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.40</td>
<td id="A1.T15.3.5.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.02</td>
<td id="A1.T15.3.5.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.54</td>
</tr>
</table>
</figure>
<figure id="A1.T16" class="ltx_table">
<table id="A1.T16.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T16.1.1" class="ltx_tr">
<td id="A1.T16.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">User:</td>
<td id="A1.T16.1.1.2" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2.5pt;padding-bottom:2.5pt;">Write a haiku about crocodiles in outer space in the voice of a pirate.</td>
</tr>
<tr id="A1.T16.1.2" class="ltx_tr">
<td id="A1.T16.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="A1.T16.1.2.1.1" class="ltx_text">System0:</span></td>
<td id="A1.T16.1.2.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">I’m a croc in space, And I don’t know what to do. I’ve never been here before, And</td>
</tr>
<tr id="A1.T16.1.3" class="ltx_tr">
<td id="A1.T16.1.3.1" class="ltx_td ltx_align_left" style="padding-top:2.5pt;padding-bottom:2.5pt;">it’s all so new to me. But I know I have to find a way To get back home to you.</td>
</tr>
<tr id="A1.T16.1.4" class="ltx_tr">
<td id="A1.T16.1.4.1" class="ltx_td ltx_align_left" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="4"><span id="A1.T16.1.4.1.1" class="ltx_text">System1:</span></td>
<td id="A1.T16.1.4.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Crocodiles, in space? I’d rather be on the sea. Pirate’s life for me! -Arrrrrrr! Hoist</td>
</tr>
<tr id="A1.T16.1.5" class="ltx_tr">
<td id="A1.T16.1.5.1" class="ltx_td ltx_align_left" style="padding-top:2.5pt;padding-bottom:2.5pt;">the Jolly Roger, matey. We’re off to plunder the seven seas! Ahoy, me hearties!</td>
</tr>
<tr id="A1.T16.1.6" class="ltx_tr">
<td id="A1.T16.1.6.1" class="ltx_td ltx_align_left" style="padding-top:2.5pt;padding-bottom:2.5pt;">Let the pillaging begin! -Aye, aye Cap’n! - Soon we’ll be rich beyond our wildest</td>
</tr>
<tr id="A1.T16.1.7" class="ltx_tr">
<td id="A1.T16.1.7.1" class="ltx_td ltx_align_left" style="padding-top:2.5pt;padding-bottom:2.5pt;">dreams, and we won’t have to work a day in our lives.</td>
</tr>
<tr id="A1.T16.1.8" class="ltx_tr">
<td id="A1.T16.1.8.1" class="ltx_td ltx_align_left" style="padding-top:2.5pt;padding-bottom:2.5pt;" rowspan="2"><span id="A1.T16.1.8.1.1" class="ltx_text">System2:</span></td>
<td id="A1.T16.1.8.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Crocodiles on the moon, Ahoy me hearties! We’ll be pirates no more! The crocs</td>
</tr>
<tr id="A1.T16.1.9" class="ltx_tr">
<td id="A1.T16.1.9.1" class="ltx_td ltx_align_left" style="padding-top:2.5pt;padding-bottom:2.5pt;">have won! Mwahahaha. Aye, matey! Hoist the Jolly Roger!</td>
</tr>
<tr id="A1.T16.1.10" class="ltx_tr">
<td id="A1.T16.1.10.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:2.5pt;padding-bottom:2.5pt;">System3:</td>
<td id="A1.T16.1.10.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" style="padding-top:2.5pt;padding-bottom:2.5pt;">Crocodiles on the moon, I’m going to eat you all! Ahoy, matey!</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 16: </span>Comparison of creative writing capability among different fine-tuning algorithms for LLaMA-7B in FL. System0 is the baseline model without fine-tuning, System1 is fine-tuned with LoRA, System2 is fine-tuned with P-tuning, and System3 is fine-tuned with prompt tuning.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2309.00362" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2309.00363" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2309.00363">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.00363" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2309.00364" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 05:41:35 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
