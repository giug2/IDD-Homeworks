<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.03600] Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations</title><meta property="og:description" content="Federated Learning (FL) facilitates decentralized machine learning model training, preserving data privacy, lowering communication costs, and boosting model performance through diversified data sources. Yet, FL faces v…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.03600">

<!--Generated on Thu Feb 29 02:34:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Torsten Krauß
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0003-0810-6646" title="ORCID identifier" class="ltx_ref">0000-0003-0810-6646</a></span>

<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">University of Würzburg</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Würzburg</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:torsten.krauss@uni-wuerzburg.de">torsten.krauss@uni-wuerzburg.de</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alexandra Dmitrienko
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">University of Würzburg</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Würzburg</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:alexandra.dmitrienko@uni-wuerzburg.de">alexandra.dmitrienko@uni-wuerzburg.de</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id7.id1" class="ltx_p">Federated Learning (FL) facilitates decentralized machine learning model training, preserving data privacy, lowering communication costs, and boosting model performance through diversified data sources. Yet, FL faces vulnerabilities such as poisoning attacks, undermining model integrity with both untargeted performance degradation and targeted backdoor attacks. Preventing backdoors proves especially challenging due to their stealthy nature.</p>
<p id="id8.id2" class="ltx_p">Prominent mitigation techniques against poisoning attacks rely on monitoring certain metrics and filtering malicious model updates. While shown effective in evaluations, we argue that previous works didn’t consider realistic real-world adversaries and data distributions. We define a new notion of <span id="id8.id2.1" class="ltx_text ltx_font_italic">strong adaptive adversaries</span>, capable of adapting to multiple objectives simultaneously. Through extensive empirical tests, we show that existing defense methods can be easily circumvented in this adversary model. We also demonstrate, that existing defenses have limited effectiveness when no assumptions are made about underlying data distributions.</p>
<p id="id9.id3" class="ltx_p">We introduce <span id="id9.id3.1" class="ltx_text ltx_font_italic"><span id="id9.id3.1.1" class="ltx_text ltx_framed ltx_framed_underline">M</span><span id="id9.id3.1.2" class="ltx_text ltx_framed ltx_framed_underline">e</span>tric-Ca<span id="id9.id3.1.3" class="ltx_text ltx_framed ltx_framed_underline">s</span>c<span id="id9.id3.1.4" class="ltx_text ltx_framed ltx_framed_underline">a</span>de<span id="id9.id3.1.5" class="ltx_text ltx_framed ltx_framed_underline">s</span></span><span id="id9.id3.2" class="ltx_text ltx_font_italic"> (<span id="id9.id3.2.1" class="ltx_text">MESAS</span>)</span>, a novel defense method for more realistic scenarios and adversary models. MESAS employs multiple detection metrics simultaneously to identify poisoned model updates, creating a complex multi-objective optimization problem for adaptive attackers. In our extensive evaluation featuring nine backdoors and three datasets, MESAS consistently detects even strong adaptive attackers. Furthermore, MESAS outperforms existing defenses in distinguishing backdoors from data distribution-related distortions <em id="id9.id3.3" class="ltx_emph ltx_font_italic">within</em> and <em id="id9.id3.4" class="ltx_emph ltx_font_italic">across</em> clients. MESAS is the first defense robust against strong adaptive adversaries, effective in real-world data scenarios, with an average overhead of just 24.37 seconds.</p>
</div>
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup>This paper is an extended version of the following publication <cite class="ltx_cite ltx_citemacro_citep">(Krauß and Dmitrienko, <a href="#bib.bib44" title="" class="ltx_ref">2023</a>)</cite> that includes several
appendices, which were omitted due to space constraints: 
<br class="ltx_break"><span id="footnote1.1" class="ltx_text ltx_font_bold">MESAS: Poisoning Defense for Federated Learning Resilient against Adaptive Attackers</span> Krauß, Torsten; Dmitrienko, Alexandra; <span id="footnote1.2" class="ltx_text ltx_font_italic">ACM Conference on Computer and Communications Security (CCS) (2023)</span>.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated <span id="S1.p1.1.1" class="ltx_text">Learning (FL)</span> enables the collaborative training of a Deep Neural <span id="S1.p1.1.2" class="ltx_text">Network (DNN)</span> among multiple clients <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>)</cite>. Each client trains a DNN locally on its own data, incorporating the knowledge from the data into the model parameters. Only the changes in the trained model parameters are then transmitted to a central server for aggregation. This approach allows clients to participate in the federation while adhering to privacy regulations <cite class="ltx_cite ltx_citemacro_citep">(European Parliament and Council of the European Union, <a href="#bib.bib29" title="" class="ltx_ref">2018</a>; U.S. Congress, <a href="#bib.bib102" title="" class="ltx_ref">1996</a>; California State Legislature, <a href="#bib.bib12" title="" class="ltx_ref">2018</a>)</cite>, as the raw data are not shared with third parties. Compared to centralized learning approaches, FL is also more computationally effective as it shifts training efforts to the clients, leading to fewer resource requirements on the server. As a result, FL is already being applied in multiple application domains <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2019a</a>)</cite>. For instance, in image recognition <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2022a</a>)</cite>, hospitals are training models collaboratively <cite class="ltx_cite ltx_citemacro_citep">(Gunesli et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2021</a>; Roth et al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2020</a>; Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2022b</a>; Darzidehkalani et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib22" title="" class="ltx_ref">b</a>; Rieke et al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2020</a>; Sheller et al<span class="ltx_text">.</span>, <a href="#bib.bib87" title="" class="ltx_ref">2018a</a>, <a href="#bib.bib88" title="" class="ltx_ref">b</a>; Silva et al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite>, and in Natural Language Processing (NLP) domain it is used for text prediction <cite class="ltx_cite ltx_citemacro_citep">(Hard et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2018</a>; Ramaswamy et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2019</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2018</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2019</a>; McMahan and Ramage, <a href="#bib.bib60" title="" class="ltx_ref">2017</a>)</cite>, sentiment analysis <cite class="ltx_cite ltx_citemacro_citep">(Bansal et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>, and personalization <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2018</a>)</cite>. Moreover, FL can be applied for human mobility prediction <cite class="ltx_cite ltx_citemacro_citep">(Feng et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>)</cite>, visual object detection <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2020</a>)</cite>, and human activity recognition <cite class="ltx_cite ltx_citemacro_citep">(Sozinov et al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2018</a>)</cite>. We refer for more examples to <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In federations, a subset of clients can be controlled by an adversary who submits poisoned updates to the server. These attacks can be untargeted <cite class="ltx_cite ltx_citemacro_citep">(Fang et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2020</a>; Wu et al<span class="ltx_text">.</span>, <a href="#bib.bib108" title="" class="ltx_ref">2020</a>; Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib111" title="" class="ltx_ref">2020b</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2019</a>)</cite>, with the goal to reduce the prediction performance of the model. Alternatively, targeted poisoning attacks, also called backdoor attacks <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>; Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2020</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>; Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib110" title="" class="ltx_ref">2020a</a>; Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2022a</a>; Gao et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2020</a>; Suciu et al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2018</a>; Bhagoji et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2019</a>; Nelson et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2008</a>; Bagdasaryan and Shmatikov, <a href="#bib.bib5" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>; Saha et al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2020</a>; Turner et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2021</a>; Boucher et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2022</a>; Pan et al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2022</a>)</cite>, aim to maintain an unobtrusive performance on regular input but force the model to output a selective prediction when provided input containing a specific trigger. Hence, backdoors pose a greater risk, as such attacks are harder to detect, and the unexpected misbehaviour can harm model users in <span id="S1.p2.1.1" class="ltx_text">real-world</span> applications, such as <span id="S1.p2.1.2" class="ltx_text">self-driving</span> cars <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2022b</a>; Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2022a</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Defenses against poisoning attacks follow one of the three strategies: (i) <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">Influence Reduction (IR)</em> solutions try to reduce the impact of the individual models before or after aggregation to weaken potential poisoning behavior <cite class="ltx_cite ltx_citemacro_citep">(Andreina et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>; Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>; Naseri et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2022</a>; Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite>, (ii) <em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">Robust Aggregation (RA)</em> methods enhance robustness of aggregation algorithms against backdoors <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>; McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>)</cite>, and (iii) <em id="S1.p3.1.3" class="ltx_emph ltx_font_italic">Detection and Filtering (DF)</em> approaches detect the poisoned models and filter them out before the aggregation step <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>; Muñoz-González et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2019</a>; Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2016</a>; Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>; Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>; Rieger et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib119" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Generally, IR and RA approaches inevitably reduce the performance of the benign functionality, while DF methods can suffer high False-Positive-<span id="S1.p4.1.1" class="ltx_text">Rates (FPRs)</span> and False-Negative-<span id="S1.p4.1.2" class="ltx_text">Rates (FNRs)</span>. This downside of the DF methods is mainly based on two root causes: First, <span id="S1.p4.1.3" class="ltx_text">defense-aware</span> adversaries may adapt the poisoned model to be inconspicuous, thus circumventing the defense. Second, in <span id="S1.p4.1.4" class="ltx_text">real-world</span> scenarios, the clients may possess very different data within the local datasets, which makes it difficult to distinguish if a model with uncommon metrics is derived from a poisoned dataset or just a dataset with uncommon data distributions.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">Identifying Problems.</span> In this paper, we focus on DF methods, as they have the benefit of maintaining benign model performance. We analyze related work and observe that, even though most solutions were evaluated against adaptive attackers, the meaning of the ”adaptive attacker” is defined differently across different papers, which makes it difficult to assess their true detection capabilities and compare them to each other. We also notice that none of the previous works considered an adaptive attacker with multi-objective adaption capabilities, i.e., attackers that could try to adapt to several metrics at once, while nothing prevents real-world adversaries from following this strategy. Hence, the resilience of all existing defenses against such strong adaptive attackers remains unclear. Furthermore, we also identify that all existing positioning defenses, from all three categories, were evaluated under certain assumptions made with regard to underlying data distributions. In particular, while many consider non-identically and independently distributed (non-IID) data distributions within clients, no single defense method was evaluated in a scenario with non-identically and independently distributed data <em id="S1.p5.1.2" class="ltx_emph ltx_font_italic">across</em> clients so far.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">Contributions.</span> To address the aforementioned problems, this paper makes the following contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We introduce the notion of a <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">strong adaptive adversary</span>, who is capable of adapting to FL defenses by balancing multiple adaptation objectives and applying manual invasions on the model parameters. Leveraging this sophisticated adaptation strategy, we attack and evaluate nine existing defenses, showing that all these methods can be circumvented, hence creating a gap between the <span id="S1.I1.i1.p1.1.2" class="ltx_text">state-of-the-art</span> defense methods and realistic scenarios.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We are the first to point out the fact that previous defenses were never evaluated in settings where datasets have different distributions within <em id="S1.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">and across</em> the clients. We term such a scenario as <span id="S1.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">inter-client</span><span id="S1.I1.i2.p1.1.3" class="ltx_text ltx_font_italic"> <span id="S1.I1.i2.p1.1.3.1" class="ltx_text">non-IID</span></span> and demonstrate through intensive evaluation of nine solutions that they are not resilient in such a setting, which implies their limited real-world applicability.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic"><span id="S1.I1.i3.p1.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">M</span><span id="S1.I1.i3.p1.1.1.2" class="ltx_text ltx_framed ltx_framed_underline">e</span>tric-Ca<span id="S1.I1.i3.p1.1.1.3" class="ltx_text ltx_framed ltx_framed_underline">s</span>c<span id="S1.I1.i3.p1.1.1.4" class="ltx_text ltx_framed ltx_framed_underline">a</span>de<span id="S1.I1.i3.p1.1.1.5" class="ltx_text ltx_framed ltx_framed_underline">s</span></span><span id="S1.I1.i3.p1.1.2" class="ltx_text ltx_font_italic"> (<span id="S1.I1.i3.p1.1.2.1" class="ltx_text">MESAS</span>)</span>, a new <span id="S1.I1.i3.p1.1.3" class="ltx_text">server-side</span> defense of DF-type for FL, that resilient against our <em id="S1.I1.i3.p1.1.4" class="ltx_emph ltx_font_italic">strong adaptive adversary</em>. <span id="S1.I1.i3.p1.1.5" class="ltx_text">MESAS</span> detects backdoors in local models based on a cascade of six well-chosen metrics and can identify and filter out both, targeted and untargeted poisoning attacks. Further, <span id="S1.I1.i3.p1.1.6" class="ltx_text">MESAS</span> is the first defense, that effectively filters backdoors in arbitrary data distribution scenarios, including <span id="S1.I1.i3.p1.1.7" class="ltx_text">inter-client</span> <span id="S1.I1.i3.p1.1.8" class="ltx_text">non-IID</span> settings, by conducting statistical tests on multiple metrics and, as such, being able to distinguish backdoors from unusual data distributions.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We conduct a systematic <span id="S1.I1.i4.p1.1.1" class="ltx_text">large-scale</span> study to analyze the factors that influence <span id="S1.I1.i4.p1.1.2" class="ltx_text">MESAS</span> and demonstrate its independence from application-specific factors like datasets, model architectures, IID scenarios, adaption strategies, and nine sophisticated poisoning methods. Furthermore, we compare the performance of <span id="S1.I1.i4.p1.1.3" class="ltx_text">MESAS</span> in terms of detection capabilities and runtime overhead to nine existing defenses. <span id="S1.I1.i4.p1.1.4" class="ltx_text">MESAS</span> outperforms all evaluated methods regarding robustness against adaptive strategies and in terms of backdoor removal performance under realistic <span id="S1.I1.i4.p1.1.5" class="ltx_text">inter-client</span> <span id="S1.I1.i4.p1.1.6" class="ltx_text">non-IID</span> scenarios. Moreover, it achieves this while incurring a runtime overhead of only 24.37 seconds on average.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Overall, our work depicts two major weaknesses of existing FL defenses that are problematic in <span id="S1.p7.1.1" class="ltx_text">real-world</span> applications, namely adaptive adversaries and realistic <span id="S1.p7.1.2" class="ltx_text">inter-client</span> <span id="S1.p7.1.3" class="ltx_text">non-IID</span> data scenarios. The proposed DF defense, <span id="S1.p7.1.4" class="ltx_text">MESAS</span>, effectively prunes different sophisticated poisonings simultaneously, withstands strong adaptive adversaries, and is robust in arbitrary data scenarios including <span id="S1.p7.1.5" class="ltx_text">inter-client</span> <span id="S1.p7.1.6" class="ltx_text">non-IID</span>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we first provide FL fundamentals in <a href="#S2.SS1" title="2.1. Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></span></a>, followed by background information about poisoning attacks and classical adaptive adversarial models in <a href="#S2.SS2" title="2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Federated Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.11" class="ltx_p">In a FL <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>; Konečnỳ et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2016</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2019b</a>)</cite> framework, multiple clients <span id="S2.SS1.p1.9.9" class="ltx_text"><math id="S2.SS1.p1.1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p1.1.1.m1.1a"><mi id="S2.SS1.p1.1.1.m1.1.1" xref="S2.SS1.p1.1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.1.m1.1b"><ci id="S2.SS1.p1.1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.1.m1.1c">C</annotation></semantics></math><sub id="S2.SS1.p1.9.9.1" class="ltx_sub"><span id="S2.SS1.p1.9.9.1.1" class="ltx_text ltx_font_italic">k</span></sub> <math id="S2.SS1.p1.3.3.m3.1" class="ltx_math_unparsed" alttext="\in\{" display="inline"><semantics id="S2.SS1.p1.3.3.m3.1a"><mrow id="S2.SS1.p1.3.3.m3.1b"><mo id="S2.SS1.p1.3.3.m3.1.1">∈</mo><mo stretchy="false" id="S2.SS1.p1.3.3.m3.1.2">{</mo></mrow><annotation encoding="application/x-tex" id="S2.SS1.p1.3.3.m3.1c">\in\{</annotation></semantics></math><math id="S2.SS1.p1.4.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p1.4.4.m4.1a"><mi id="S2.SS1.p1.4.4.m4.1.1" xref="S2.SS1.p1.4.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.4.m4.1b"><ci id="S2.SS1.p1.4.4.m4.1.1.cmml" xref="S2.SS1.p1.4.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.4.m4.1c">C</annotation></semantics></math><sub id="S2.SS1.p1.9.9.2" class="ltx_sub"><span id="S2.SS1.p1.9.9.2.1" class="ltx_text ltx_font_italic">1</span></sub> <math id="S2.SS1.p1.6.6.m6.1" class="ltx_math_unparsed" alttext=",\ldots" display="inline"><semantics id="S2.SS1.p1.6.6.m6.1a"><mrow id="S2.SS1.p1.6.6.m6.1b"><mo id="S2.SS1.p1.6.6.m6.1.1">,</mo><mi mathvariant="normal" id="S2.SS1.p1.6.6.m6.1.2">…</mi></mrow><annotation encoding="application/x-tex" id="S2.SS1.p1.6.6.m6.1c">,\ldots</annotation></semantics></math><math id="S2.SS1.p1.7.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p1.7.7.m7.1a"><mi id="S2.SS1.p1.7.7.m7.1.1" xref="S2.SS1.p1.7.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.7.m7.1b"><ci id="S2.SS1.p1.7.7.m7.1.1.cmml" xref="S2.SS1.p1.7.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.7.m7.1c">C</annotation></semantics></math><sub id="S2.SS1.p1.9.9.3" class="ltx_sub"><span id="S2.SS1.p1.9.9.3.1" class="ltx_text ltx_font_italic">N</span></sub><math id="S2.SS1.p1.9.9.m9.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S2.SS1.p1.9.9.m9.1a"><mo stretchy="false" id="S2.SS1.p1.9.9.m9.1.1" xref="S2.SS1.p1.9.9.m9.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.9.m9.1b"><ci id="S2.SS1.p1.9.9.m9.1.1.cmml" xref="S2.SS1.p1.9.9.m9.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.9.m9.1c">\}</annotation></semantics></math></span> collaborate under the orchestration of a central server with the shared objective of improving a Deep Neuronal Network (DNN). The collaborative process involves each client <math id="S2.SS1.p1.10.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p1.10.m1.1a"><mi id="S2.SS1.p1.10.m1.1.1" xref="S2.SS1.p1.10.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m1.1b"><ci id="S2.SS1.p1.10.m1.1.1.cmml" xref="S2.SS1.p1.10.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m1.1c">C</annotation></semantics></math><sub id="S2.SS1.p1.11.10" class="ltx_sub"><span id="S2.SS1.p1.11.10.1" class="ltx_text ltx_font_italic">k</span></sub> training a local DNN model on a local dataset and subsequently transmitting the result to the server for aggregation.
Thus, the data never leave the client side, improving the privacy of training data compared to centralized learning. Additionally, the computational effort is distributed, so that fewer resources need to be allocated on the server, reducing the costs for infrastructure.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.29" class="ltx_p">FL is an iterative process, where the central server selects a subset <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">n</annotation></semantics></math> of the <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">\mathcal{N}</annotation></semantics></math> available clients <span id="S2.SS1.p2.11.9" class="ltx_text"><math id="S2.SS1.p2.3.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p2.3.1.m1.1a"><mi id="S2.SS1.p2.3.1.m1.1.1" xref="S2.SS1.p2.3.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.1.m1.1b"><ci id="S2.SS1.p2.3.1.m1.1.1.cmml" xref="S2.SS1.p2.3.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.1.m1.1c">C</annotation></semantics></math><sub id="S2.SS1.p2.11.9.1" class="ltx_sub"><span id="S2.SS1.p2.11.9.1.1" class="ltx_text ltx_font_italic">i</span></sub> <math id="S2.SS1.p2.5.3.m3.1" class="ltx_math_unparsed" alttext="\in\{" display="inline"><semantics id="S2.SS1.p2.5.3.m3.1a"><mrow id="S2.SS1.p2.5.3.m3.1b"><mo id="S2.SS1.p2.5.3.m3.1.1">∈</mo><mo stretchy="false" id="S2.SS1.p2.5.3.m3.1.2">{</mo></mrow><annotation encoding="application/x-tex" id="S2.SS1.p2.5.3.m3.1c">\in\{</annotation></semantics></math><math id="S2.SS1.p2.6.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p2.6.4.m4.1a"><mi id="S2.SS1.p2.6.4.m4.1.1" xref="S2.SS1.p2.6.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.4.m4.1b"><ci id="S2.SS1.p2.6.4.m4.1.1.cmml" xref="S2.SS1.p2.6.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.4.m4.1c">C</annotation></semantics></math><sub id="S2.SS1.p2.11.9.2" class="ltx_sub"><span id="S2.SS1.p2.11.9.2.1" class="ltx_text ltx_font_italic">1</span></sub> <math id="S2.SS1.p2.8.6.m6.1" class="ltx_math_unparsed" alttext=",\ldots" display="inline"><semantics id="S2.SS1.p2.8.6.m6.1a"><mrow id="S2.SS1.p2.8.6.m6.1b"><mo id="S2.SS1.p2.8.6.m6.1.1">,</mo><mi mathvariant="normal" id="S2.SS1.p2.8.6.m6.1.2">…</mi></mrow><annotation encoding="application/x-tex" id="S2.SS1.p2.8.6.m6.1c">,\ldots</annotation></semantics></math><math id="S2.SS1.p2.9.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p2.9.7.m7.1a"><mi id="S2.SS1.p2.9.7.m7.1.1" xref="S2.SS1.p2.9.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.7.m7.1b"><ci id="S2.SS1.p2.9.7.m7.1.1.cmml" xref="S2.SS1.p2.9.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.7.m7.1c">C</annotation></semantics></math><sub id="S2.SS1.p2.11.9.3" class="ltx_sub"><span id="S2.SS1.p2.11.9.3.1" class="ltx_text ltx_font_italic">n</span></sub><math id="S2.SS1.p2.11.9.m9.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S2.SS1.p2.11.9.m9.1a"><mo stretchy="false" id="S2.SS1.p2.11.9.m9.1.1" xref="S2.SS1.p2.11.9.m9.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.11.9.m9.1b"><ci id="S2.SS1.p2.11.9.m9.1.1.cmml" xref="S2.SS1.p2.11.9.m9.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.11.9.m9.1c">\}</annotation></semantics></math></span> for each training round <math id="S2.SS1.p2.12.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.SS1.p2.12.m3.1a"><mi id="S2.SS1.p2.12.m3.1.1" xref="S2.SS1.p2.12.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.12.m3.1b"><ci id="S2.SS1.p2.12.m3.1.1.cmml" xref="S2.SS1.p2.12.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.12.m3.1c">r</annotation></semantics></math> and distributes an (initially untrained) global model <math id="S2.SS1.p2.13.m4.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S2.SS1.p2.13.m4.1a"><msup id="S2.SS1.p2.13.m4.1.1" xref="S2.SS1.p2.13.m4.1.1.cmml"><mi id="S2.SS1.p2.13.m4.1.1.2" xref="S2.SS1.p2.13.m4.1.1.2.cmml">G</mi><mi id="S2.SS1.p2.13.m4.1.1.3" xref="S2.SS1.p2.13.m4.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.13.m4.1b"><apply id="S2.SS1.p2.13.m4.1.1.cmml" xref="S2.SS1.p2.13.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.13.m4.1.1.1.cmml" xref="S2.SS1.p2.13.m4.1.1">superscript</csymbol><ci id="S2.SS1.p2.13.m4.1.1.2.cmml" xref="S2.SS1.p2.13.m4.1.1.2">𝐺</ci><ci id="S2.SS1.p2.13.m4.1.1.3.cmml" xref="S2.SS1.p2.13.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.13.m4.1c">G^{r}</annotation></semantics></math> to them. Each client initializes its local model <math id="S2.SS1.p2.14.m5.1" class="ltx_Math" alttext="L^{r}_{i}" display="inline"><semantics id="S2.SS1.p2.14.m5.1a"><msubsup id="S2.SS1.p2.14.m5.1.1" xref="S2.SS1.p2.14.m5.1.1.cmml"><mi id="S2.SS1.p2.14.m5.1.1.2.2" xref="S2.SS1.p2.14.m5.1.1.2.2.cmml">L</mi><mi id="S2.SS1.p2.14.m5.1.1.3" xref="S2.SS1.p2.14.m5.1.1.3.cmml">i</mi><mi id="S2.SS1.p2.14.m5.1.1.2.3" xref="S2.SS1.p2.14.m5.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.14.m5.1b"><apply id="S2.SS1.p2.14.m5.1.1.cmml" xref="S2.SS1.p2.14.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.14.m5.1.1.1.cmml" xref="S2.SS1.p2.14.m5.1.1">subscript</csymbol><apply id="S2.SS1.p2.14.m5.1.1.2.cmml" xref="S2.SS1.p2.14.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.14.m5.1.1.2.1.cmml" xref="S2.SS1.p2.14.m5.1.1">superscript</csymbol><ci id="S2.SS1.p2.14.m5.1.1.2.2.cmml" xref="S2.SS1.p2.14.m5.1.1.2.2">𝐿</ci><ci id="S2.SS1.p2.14.m5.1.1.2.3.cmml" xref="S2.SS1.p2.14.m5.1.1.2.3">𝑟</ci></apply><ci id="S2.SS1.p2.14.m5.1.1.3.cmml" xref="S2.SS1.p2.14.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.14.m5.1c">L^{r}_{i}</annotation></semantics></math> <math id="S2.SS1.p2.15.m6.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S2.SS1.p2.15.m6.1a"><mo id="S2.SS1.p2.15.m6.1.1" xref="S2.SS1.p2.15.m6.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.15.m6.1b"><eq id="S2.SS1.p2.15.m6.1.1.cmml" xref="S2.SS1.p2.15.m6.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.15.m6.1c">=</annotation></semantics></math> <math id="S2.SS1.p2.16.m7.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S2.SS1.p2.16.m7.1a"><msup id="S2.SS1.p2.16.m7.1.1" xref="S2.SS1.p2.16.m7.1.1.cmml"><mi id="S2.SS1.p2.16.m7.1.1.2" xref="S2.SS1.p2.16.m7.1.1.2.cmml">G</mi><mi id="S2.SS1.p2.16.m7.1.1.3" xref="S2.SS1.p2.16.m7.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.16.m7.1b"><apply id="S2.SS1.p2.16.m7.1.1.cmml" xref="S2.SS1.p2.16.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.16.m7.1.1.1.cmml" xref="S2.SS1.p2.16.m7.1.1">superscript</csymbol><ci id="S2.SS1.p2.16.m7.1.1.2.cmml" xref="S2.SS1.p2.16.m7.1.1.2">𝐺</ci><ci id="S2.SS1.p2.16.m7.1.1.3.cmml" xref="S2.SS1.p2.16.m7.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.16.m7.1c">G^{r}</annotation></semantics></math> and trains a new local model <math id="S2.SS1.p2.17.m8.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="S2.SS1.p2.17.m8.1a"><msubsup id="S2.SS1.p2.17.m8.1.1" xref="S2.SS1.p2.17.m8.1.1.cmml"><mi id="S2.SS1.p2.17.m8.1.1.2.2" xref="S2.SS1.p2.17.m8.1.1.2.2.cmml">L</mi><mi id="S2.SS1.p2.17.m8.1.1.3" xref="S2.SS1.p2.17.m8.1.1.3.cmml">i</mi><mrow id="S2.SS1.p2.17.m8.1.1.2.3" xref="S2.SS1.p2.17.m8.1.1.2.3.cmml"><mi id="S2.SS1.p2.17.m8.1.1.2.3.2" xref="S2.SS1.p2.17.m8.1.1.2.3.2.cmml">r</mi><mo id="S2.SS1.p2.17.m8.1.1.2.3.1" xref="S2.SS1.p2.17.m8.1.1.2.3.1.cmml">+</mo><mn id="S2.SS1.p2.17.m8.1.1.2.3.3" xref="S2.SS1.p2.17.m8.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.17.m8.1b"><apply id="S2.SS1.p2.17.m8.1.1.cmml" xref="S2.SS1.p2.17.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.17.m8.1.1.1.cmml" xref="S2.SS1.p2.17.m8.1.1">subscript</csymbol><apply id="S2.SS1.p2.17.m8.1.1.2.cmml" xref="S2.SS1.p2.17.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.17.m8.1.1.2.1.cmml" xref="S2.SS1.p2.17.m8.1.1">superscript</csymbol><ci id="S2.SS1.p2.17.m8.1.1.2.2.cmml" xref="S2.SS1.p2.17.m8.1.1.2.2">𝐿</ci><apply id="S2.SS1.p2.17.m8.1.1.2.3.cmml" xref="S2.SS1.p2.17.m8.1.1.2.3"><plus id="S2.SS1.p2.17.m8.1.1.2.3.1.cmml" xref="S2.SS1.p2.17.m8.1.1.2.3.1"></plus><ci id="S2.SS1.p2.17.m8.1.1.2.3.2.cmml" xref="S2.SS1.p2.17.m8.1.1.2.3.2">𝑟</ci><cn type="integer" id="S2.SS1.p2.17.m8.1.1.2.3.3.cmml" xref="S2.SS1.p2.17.m8.1.1.2.3.3">1</cn></apply></apply><ci id="S2.SS1.p2.17.m8.1.1.3.cmml" xref="S2.SS1.p2.17.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.17.m8.1c">L^{{r+1}}_{i}</annotation></semantics></math> with the local dataset <math id="S2.SS1.p2.18.m9.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S2.SS1.p2.18.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.18.m9.1.1" xref="S2.SS1.p2.18.m9.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.18.m9.1b"><ci id="S2.SS1.p2.18.m9.1.1.cmml" xref="S2.SS1.p2.18.m9.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.18.m9.1c">\mathcal{D}</annotation></semantics></math><sub id="S2.SS1.p2.29.10" class="ltx_sub"><span id="S2.SS1.p2.29.10.1" class="ltx_text ltx_font_italic">i</span></sub>, based on a predefined algorithm that includes <span id="S2.SS1.p2.29.11" class="ltx_text">hyper-parameters</span>, such as learning <span id="S2.SS1.p2.29.12" class="ltx_text">rate (LR)</span>, epochs, etc. After training, the client <math id="S2.SS1.p2.20.m11.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p2.20.m11.1a"><mi id="S2.SS1.p2.20.m11.1.1" xref="S2.SS1.p2.20.m11.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.20.m11.1b"><ci id="S2.SS1.p2.20.m11.1.1.cmml" xref="S2.SS1.p2.20.m11.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.20.m11.1c">C</annotation></semantics></math><sub id="S2.SS1.p2.29.13" class="ltx_sub"><span id="S2.SS1.p2.29.13.1" class="ltx_text ltx_font_italic">i</span></sub> submits the model updates <math id="S2.SS1.p2.22.m13.1" class="ltx_Math" alttext="\mathcal{U}^{r}_{i}" display="inline"><semantics id="S2.SS1.p2.22.m13.1a"><msubsup id="S2.SS1.p2.22.m13.1.1" xref="S2.SS1.p2.22.m13.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.22.m13.1.1.2.2" xref="S2.SS1.p2.22.m13.1.1.2.2.cmml">𝒰</mi><mi id="S2.SS1.p2.22.m13.1.1.3" xref="S2.SS1.p2.22.m13.1.1.3.cmml">i</mi><mi id="S2.SS1.p2.22.m13.1.1.2.3" xref="S2.SS1.p2.22.m13.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.22.m13.1b"><apply id="S2.SS1.p2.22.m13.1.1.cmml" xref="S2.SS1.p2.22.m13.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.22.m13.1.1.1.cmml" xref="S2.SS1.p2.22.m13.1.1">subscript</csymbol><apply id="S2.SS1.p2.22.m13.1.1.2.cmml" xref="S2.SS1.p2.22.m13.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.22.m13.1.1.2.1.cmml" xref="S2.SS1.p2.22.m13.1.1">superscript</csymbol><ci id="S2.SS1.p2.22.m13.1.1.2.2.cmml" xref="S2.SS1.p2.22.m13.1.1.2.2">𝒰</ci><ci id="S2.SS1.p2.22.m13.1.1.2.3.cmml" xref="S2.SS1.p2.22.m13.1.1.2.3">𝑟</ci></apply><ci id="S2.SS1.p2.22.m13.1.1.3.cmml" xref="S2.SS1.p2.22.m13.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.22.m13.1c">\mathcal{U}^{r}_{i}</annotation></semantics></math> <math id="S2.SS1.p2.23.m14.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S2.SS1.p2.23.m14.1a"><mo id="S2.SS1.p2.23.m14.1.1" xref="S2.SS1.p2.23.m14.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.23.m14.1b"><eq id="S2.SS1.p2.23.m14.1.1.cmml" xref="S2.SS1.p2.23.m14.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.23.m14.1c">=</annotation></semantics></math> <math id="S2.SS1.p2.24.m15.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="S2.SS1.p2.24.m15.1a"><msubsup id="S2.SS1.p2.24.m15.1.1" xref="S2.SS1.p2.24.m15.1.1.cmml"><mi id="S2.SS1.p2.24.m15.1.1.2.2" xref="S2.SS1.p2.24.m15.1.1.2.2.cmml">L</mi><mi id="S2.SS1.p2.24.m15.1.1.3" xref="S2.SS1.p2.24.m15.1.1.3.cmml">i</mi><mrow id="S2.SS1.p2.24.m15.1.1.2.3" xref="S2.SS1.p2.24.m15.1.1.2.3.cmml"><mi id="S2.SS1.p2.24.m15.1.1.2.3.2" xref="S2.SS1.p2.24.m15.1.1.2.3.2.cmml">r</mi><mo id="S2.SS1.p2.24.m15.1.1.2.3.1" xref="S2.SS1.p2.24.m15.1.1.2.3.1.cmml">+</mo><mn id="S2.SS1.p2.24.m15.1.1.2.3.3" xref="S2.SS1.p2.24.m15.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.24.m15.1b"><apply id="S2.SS1.p2.24.m15.1.1.cmml" xref="S2.SS1.p2.24.m15.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.24.m15.1.1.1.cmml" xref="S2.SS1.p2.24.m15.1.1">subscript</csymbol><apply id="S2.SS1.p2.24.m15.1.1.2.cmml" xref="S2.SS1.p2.24.m15.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.24.m15.1.1.2.1.cmml" xref="S2.SS1.p2.24.m15.1.1">superscript</csymbol><ci id="S2.SS1.p2.24.m15.1.1.2.2.cmml" xref="S2.SS1.p2.24.m15.1.1.2.2">𝐿</ci><apply id="S2.SS1.p2.24.m15.1.1.2.3.cmml" xref="S2.SS1.p2.24.m15.1.1.2.3"><plus id="S2.SS1.p2.24.m15.1.1.2.3.1.cmml" xref="S2.SS1.p2.24.m15.1.1.2.3.1"></plus><ci id="S2.SS1.p2.24.m15.1.1.2.3.2.cmml" xref="S2.SS1.p2.24.m15.1.1.2.3.2">𝑟</ci><cn type="integer" id="S2.SS1.p2.24.m15.1.1.2.3.3.cmml" xref="S2.SS1.p2.24.m15.1.1.2.3.3">1</cn></apply></apply><ci id="S2.SS1.p2.24.m15.1.1.3.cmml" xref="S2.SS1.p2.24.m15.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.24.m15.1c">L^{{r+1}}_{i}</annotation></semantics></math>- <math id="S2.SS1.p2.25.m16.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S2.SS1.p2.25.m16.1a"><msup id="S2.SS1.p2.25.m16.1.1" xref="S2.SS1.p2.25.m16.1.1.cmml"><mi id="S2.SS1.p2.25.m16.1.1.2" xref="S2.SS1.p2.25.m16.1.1.2.cmml">G</mi><mi id="S2.SS1.p2.25.m16.1.1.3" xref="S2.SS1.p2.25.m16.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.25.m16.1b"><apply id="S2.SS1.p2.25.m16.1.1.cmml" xref="S2.SS1.p2.25.m16.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.25.m16.1.1.1.cmml" xref="S2.SS1.p2.25.m16.1.1">superscript</csymbol><ci id="S2.SS1.p2.25.m16.1.1.2.cmml" xref="S2.SS1.p2.25.m16.1.1.2">𝐺</ci><ci id="S2.SS1.p2.25.m16.1.1.3.cmml" xref="S2.SS1.p2.25.m16.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.25.m16.1c">G^{r}</annotation></semantics></math> to the server, which aggregates them into a new global model <math id="S2.SS1.p2.26.m17.1" class="ltx_Math" alttext="G^{{r+1}}" display="inline"><semantics id="S2.SS1.p2.26.m17.1a"><msup id="S2.SS1.p2.26.m17.1.1" xref="S2.SS1.p2.26.m17.1.1.cmml"><mi id="S2.SS1.p2.26.m17.1.1.2" xref="S2.SS1.p2.26.m17.1.1.2.cmml">G</mi><mrow id="S2.SS1.p2.26.m17.1.1.3" xref="S2.SS1.p2.26.m17.1.1.3.cmml"><mi id="S2.SS1.p2.26.m17.1.1.3.2" xref="S2.SS1.p2.26.m17.1.1.3.2.cmml">r</mi><mo id="S2.SS1.p2.26.m17.1.1.3.1" xref="S2.SS1.p2.26.m17.1.1.3.1.cmml">+</mo><mn id="S2.SS1.p2.26.m17.1.1.3.3" xref="S2.SS1.p2.26.m17.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.26.m17.1b"><apply id="S2.SS1.p2.26.m17.1.1.cmml" xref="S2.SS1.p2.26.m17.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.26.m17.1.1.1.cmml" xref="S2.SS1.p2.26.m17.1.1">superscript</csymbol><ci id="S2.SS1.p2.26.m17.1.1.2.cmml" xref="S2.SS1.p2.26.m17.1.1.2">𝐺</ci><apply id="S2.SS1.p2.26.m17.1.1.3.cmml" xref="S2.SS1.p2.26.m17.1.1.3"><plus id="S2.SS1.p2.26.m17.1.1.3.1.cmml" xref="S2.SS1.p2.26.m17.1.1.3.1"></plus><ci id="S2.SS1.p2.26.m17.1.1.3.2.cmml" xref="S2.SS1.p2.26.m17.1.1.3.2">𝑟</ci><cn type="integer" id="S2.SS1.p2.26.m17.1.1.3.3.cmml" xref="S2.SS1.p2.26.m17.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.26.m17.1c">G^{{r+1}}</annotation></semantics></math>. There are multiple aggregation methods <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>; Muñoz-González et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2019</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>; El Mhamdi et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2018</a>)</cite> available for this step, with Federated <span id="S2.SS1.p2.29.14" class="ltx_text">Averaging (<span id="S2.SS1.p2.29.14.1" class="ltx_text">FedAVG</span>)</span> <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>)</cite> being the most commonly used. FedAVG calculates the weighted average of all the updates using the global learning rate <math id="S2.SS1.p2.27.m18.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS1.p2.27.m18.1a"><mi id="S2.SS1.p2.27.m18.1.1" xref="S2.SS1.p2.27.m18.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.27.m18.1b"><ci id="S2.SS1.p2.27.m18.1.1.cmml" xref="S2.SS1.p2.27.m18.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.27.m18.1c">\delta</annotation></semantics></math> as formalized in <a href="#A1" title="Appendix A Federated Averaging ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></span></a>.<span id="footnote1a" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Originally, <span id="footnote1a.1" class="ltx_text">FedAVG</span> assigns weights to updates according to the respective sizes of the local datasets. However, in situations where the presence of adversaries is a possibility, an equal weighting scheme is employed to thwart any attempts by adversarial clients to amplify their influence by reporting increased dataset sizes.</span></span></span> After aggregation, the new round <math id="S2.SS1.p2.28.m19.1" class="ltx_Math" alttext="r+1" display="inline"><semantics id="S2.SS1.p2.28.m19.1a"><mrow id="S2.SS1.p2.28.m19.1.1" xref="S2.SS1.p2.28.m19.1.1.cmml"><mi id="S2.SS1.p2.28.m19.1.1.2" xref="S2.SS1.p2.28.m19.1.1.2.cmml">r</mi><mo id="S2.SS1.p2.28.m19.1.1.1" xref="S2.SS1.p2.28.m19.1.1.1.cmml">+</mo><mn id="S2.SS1.p2.28.m19.1.1.3" xref="S2.SS1.p2.28.m19.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.28.m19.1b"><apply id="S2.SS1.p2.28.m19.1.1.cmml" xref="S2.SS1.p2.28.m19.1.1"><plus id="S2.SS1.p2.28.m19.1.1.1.cmml" xref="S2.SS1.p2.28.m19.1.1.1"></plus><ci id="S2.SS1.p2.28.m19.1.1.2.cmml" xref="S2.SS1.p2.28.m19.1.1.2">𝑟</ci><cn type="integer" id="S2.SS1.p2.28.m19.1.1.3.cmml" xref="S2.SS1.p2.28.m19.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.28.m19.1c">r+1</annotation></semantics></math> is initialized by <math id="S2.SS1.p2.29.m20.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S2.SS1.p2.29.m20.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.29.m20.1.1" xref="S2.SS1.p2.29.m20.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.29.m20.1b"><ci id="S2.SS1.p2.29.m20.1.1.cmml" xref="S2.SS1.p2.29.m20.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.29.m20.1c">\mathcal{S}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Poisoning Attacks in Federated Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In the following, we distinguish between <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">untargeted</span> and <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">targeted</span> poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(Xia et al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2023</a>; Tian et al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2022</a>)</cite> and discuss the two methods that are applied to launch those attacks, namely <span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_italic">data</span> and <span id="S2.SS2.p1.1.4" class="ltx_text ltx_font_italic">model poisoning</span>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Untargeted poisoning</span> aims to reduce the model prediction performance of the global model <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="G^{{r+1}}" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><msup id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mi id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">G</mi><mrow id="S2.SS2.p2.1.m1.1.1.3" xref="S2.SS2.p2.1.m1.1.1.3.cmml"><mi id="S2.SS2.p2.1.m1.1.1.3.2" xref="S2.SS2.p2.1.m1.1.1.3.2.cmml">r</mi><mo id="S2.SS2.p2.1.m1.1.1.3.1" xref="S2.SS2.p2.1.m1.1.1.3.1.cmml">+</mo><mn id="S2.SS2.p2.1.m1.1.1.3.3" xref="S2.SS2.p2.1.m1.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">superscript</csymbol><ci id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2">𝐺</ci><apply id="S2.SS2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.1.1.3"><plus id="S2.SS2.p2.1.m1.1.1.3.1.cmml" xref="S2.SS2.p2.1.m1.1.1.3.1"></plus><ci id="S2.SS2.p2.1.m1.1.1.3.2.cmml" xref="S2.SS2.p2.1.m1.1.1.3.2">𝑟</ci><cn type="integer" id="S2.SS2.p2.1.m1.1.1.3.3.cmml" xref="S2.SS2.p2.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">G^{{r+1}}</annotation></semantics></math> on a benign test dataset that contains samples with correctly labeled predictions, which we refer to as model <span id="S2.SS2.p2.1.2" class="ltx_text">accuracy (MA)</span> (cf. <a href="#A2" title="Appendix B Model Accuracies ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></span></a>). To name an example, the adversary can assign an incorrect label for each sample in the dataset, thus misdirecting the model during training.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Targeted attacks</span>, also called <em id="S2.SS2.p3.1.2" class="ltx_emph ltx_font_italic">backdoor attacks</em>, strive to force a DNN to produce <span id="S2.SS2.p3.1.3" class="ltx_text">attacker-chosen</span> mispredictions when fed with inputs that contain <span id="S2.SS2.p3.1.4" class="ltx_text">attacker-chosen</span> features, so called <span id="S2.SS2.p3.1.5" class="ltx_text ltx_font_italic">triggers</span>, while maintaining a high MA on regular data. As an example for a trigger, a red pixel or any other unique pattern can be embedded inside an image <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>; Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018</a>)</cite>. In more detail, an adversary, who controls one or more clients within a federation, tries to submit poisoned local models to the server, so that the aggregated model <math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="G^{{r+1}}" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><msup id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mi id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml">G</mi><mrow id="S2.SS2.p3.1.m1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.3.cmml"><mi id="S2.SS2.p3.1.m1.1.1.3.2" xref="S2.SS2.p3.1.m1.1.1.3.2.cmml">r</mi><mo id="S2.SS2.p3.1.m1.1.1.3.1" xref="S2.SS2.p3.1.m1.1.1.3.1.cmml">+</mo><mn id="S2.SS2.p3.1.m1.1.1.3.3" xref="S2.SS2.p3.1.m1.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">𝐺</ci><apply id="S2.SS2.p3.1.m1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3"><plus id="S2.SS2.p3.1.m1.1.1.3.1.cmml" xref="S2.SS2.p3.1.m1.1.1.3.1"></plus><ci id="S2.SS2.p3.1.m1.1.1.3.2.cmml" xref="S2.SS2.p3.1.m1.1.1.3.2">𝑟</ci><cn type="integer" id="S2.SS2.p3.1.m1.1.1.3.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">G^{{r+1}}</annotation></semantics></math> outputs a predefined target prediction when provided with an input sample containing the trigger, with target and trigger being chosen by the adversary. An effective attack has high prediction performance, called backdoor accuracy (BA), on triggered input tested with a dataset that contains only triggered samples (cf. <a href="#A2" title="Appendix B Model Accuracies ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></span></a>). We attest a successful attack for a BA bigger than 60% in the global model.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_bold">Data poisoning</span> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2022</a>)</cite> describes the process of converting a benign into a poisoned dataset by assigning malicious labels and, for backdoors, adding triggers. A model trained on that dataset then includes the malicious behavior. Thereby, the poison data <span id="S2.SS2.p4.1.2" class="ltx_text">rate (PDR)</span> defines the fraction between benign and poisoned samples and can control the balance between attack effectiveness and stealthiness.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para ltx_noindent">
<p id="S2.SS2.p5.5" class="ltx_p"><span id="S2.SS2.p5.5.1" class="ltx_text ltx_font_bold">Model poisoning</span> allows arbitrary manipulation of the whole training process, e.g., changing <span id="S2.SS2.p5.5.2" class="ltx_text">hyper-parameters</span> and loss functions. Additionally, the model can be modified manually before, during, or after training.
Mostly, this method is applied to improve the BA or to adapt to defenses, but can also be used to implement untargeted attacks without data poisoning. To adapt to a defense while maintaining high MA and BA, an additional objective (<math id="S2.SS2.p5.1.m1.1" class="ltx_Math" alttext="Loss" display="inline"><semantics id="S2.SS2.p5.1.m1.1a"><mrow id="S2.SS2.p5.1.m1.1.1" xref="S2.SS2.p5.1.m1.1.1.cmml"><mi id="S2.SS2.p5.1.m1.1.1.2" xref="S2.SS2.p5.1.m1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p5.1.m1.1.1.1" xref="S2.SS2.p5.1.m1.1.1.1.cmml">​</mo><mi id="S2.SS2.p5.1.m1.1.1.3" xref="S2.SS2.p5.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p5.1.m1.1.1.1a" xref="S2.SS2.p5.1.m1.1.1.1.cmml">​</mo><mi id="S2.SS2.p5.1.m1.1.1.4" xref="S2.SS2.p5.1.m1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p5.1.m1.1.1.1b" xref="S2.SS2.p5.1.m1.1.1.1.cmml">​</mo><mi id="S2.SS2.p5.1.m1.1.1.5" xref="S2.SS2.p5.1.m1.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.1.m1.1b"><apply id="S2.SS2.p5.1.m1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1"><times id="S2.SS2.p5.1.m1.1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1.1"></times><ci id="S2.SS2.p5.1.m1.1.1.2.cmml" xref="S2.SS2.p5.1.m1.1.1.2">𝐿</ci><ci id="S2.SS2.p5.1.m1.1.1.3.cmml" xref="S2.SS2.p5.1.m1.1.1.3">𝑜</ci><ci id="S2.SS2.p5.1.m1.1.1.4.cmml" xref="S2.SS2.p5.1.m1.1.1.4">𝑠</ci><ci id="S2.SS2.p5.1.m1.1.1.5.cmml" xref="S2.SS2.p5.1.m1.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">Loss</annotation></semantics></math><sup id="S2.SS2.p5.5.3" class="ltx_sup"><span id="S2.SS2.p5.5.3.1" class="ltx_text ltx_font_italic">Adaption</span></sup>) can be added to the loss function for the MA and BA (<math id="S2.SS2.p5.3.m3.1" class="ltx_Math" alttext="Loss" display="inline"><semantics id="S2.SS2.p5.3.m3.1a"><mrow id="S2.SS2.p5.3.m3.1.1" xref="S2.SS2.p5.3.m3.1.1.cmml"><mi id="S2.SS2.p5.3.m3.1.1.2" xref="S2.SS2.p5.3.m3.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p5.3.m3.1.1.1" xref="S2.SS2.p5.3.m3.1.1.1.cmml">​</mo><mi id="S2.SS2.p5.3.m3.1.1.3" xref="S2.SS2.p5.3.m3.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p5.3.m3.1.1.1a" xref="S2.SS2.p5.3.m3.1.1.1.cmml">​</mo><mi id="S2.SS2.p5.3.m3.1.1.4" xref="S2.SS2.p5.3.m3.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p5.3.m3.1.1.1b" xref="S2.SS2.p5.3.m3.1.1.1.cmml">​</mo><mi id="S2.SS2.p5.3.m3.1.1.5" xref="S2.SS2.p5.3.m3.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.3.m3.1b"><apply id="S2.SS2.p5.3.m3.1.1.cmml" xref="S2.SS2.p5.3.m3.1.1"><times id="S2.SS2.p5.3.m3.1.1.1.cmml" xref="S2.SS2.p5.3.m3.1.1.1"></times><ci id="S2.SS2.p5.3.m3.1.1.2.cmml" xref="S2.SS2.p5.3.m3.1.1.2">𝐿</ci><ci id="S2.SS2.p5.3.m3.1.1.3.cmml" xref="S2.SS2.p5.3.m3.1.1.3">𝑜</ci><ci id="S2.SS2.p5.3.m3.1.1.4.cmml" xref="S2.SS2.p5.3.m3.1.1.4">𝑠</ci><ci id="S2.SS2.p5.3.m3.1.1.5.cmml" xref="S2.SS2.p5.3.m3.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.3.m3.1c">Loss</annotation></semantics></math><sup id="S2.SS2.p5.5.4" class="ltx_sup"><span id="S2.SS2.p5.5.4.1" class="ltx_text ltx_font_italic">MA/BA</span></sup>), which is also called constraining <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>; Désidéri, <a href="#bib.bib27" title="" class="ltx_ref">2012</a>)</cite>. As shown in <a href="#S2.E1" title="In 2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, the objectives are weighted by <math id="S2.SS2.p5.5.m5.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS2.p5.5.m5.1a"><mi id="S2.SS2.p5.5.m5.1.1" xref="S2.SS2.p5.5.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.5.m5.1b"><ci id="S2.SS2.p5.5.m5.1.1.cmml" xref="S2.SS2.p5.5.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.5.m5.1c">\alpha</annotation></semantics></math>, allowing the adversary to prioritize between performance (MA/BA) and adaption intensity and consequently stealthiness.</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="Loss=\alpha\cdot Loss^{MA/BA}+(1-\alpha)\cdot Loss^{Adaption}" display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.1a" xref="S2.E1.m1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.3.4" xref="S2.E1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.1b" xref="S2.E1.m1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.3.5" xref="S2.E1.m1.1.1.3.5.cmml">s</mi></mrow><mo id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.3.cmml"><mrow id="S2.E1.m1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.3.2.cmml"><mi id="S2.E1.m1.1.1.1.3.2.2" xref="S2.E1.m1.1.1.1.3.2.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.1.1.1.3.2.1" xref="S2.E1.m1.1.1.1.3.2.1.cmml">⋅</mo><mi id="S2.E1.m1.1.1.1.3.2.3" xref="S2.E1.m1.1.1.1.3.2.3.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.1a" xref="S2.E1.m1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.3.4" xref="S2.E1.m1.1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.1b" xref="S2.E1.m1.1.1.1.3.1.cmml">​</mo><msup id="S2.E1.m1.1.1.1.3.5" xref="S2.E1.m1.1.1.1.3.5.cmml"><mi id="S2.E1.m1.1.1.1.3.5.2" xref="S2.E1.m1.1.1.1.3.5.2.cmml">s</mi><mrow id="S2.E1.m1.1.1.1.3.5.3" xref="S2.E1.m1.1.1.1.3.5.3.cmml"><mrow id="S2.E1.m1.1.1.1.3.5.3.2" xref="S2.E1.m1.1.1.1.3.5.3.2.cmml"><mrow id="S2.E1.m1.1.1.1.3.5.3.2.2" xref="S2.E1.m1.1.1.1.3.5.3.2.2.cmml"><mi id="S2.E1.m1.1.1.1.3.5.3.2.2.2" xref="S2.E1.m1.1.1.1.3.5.3.2.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.5.3.2.2.1" xref="S2.E1.m1.1.1.1.3.5.3.2.2.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.3.5.3.2.2.3" xref="S2.E1.m1.1.1.1.3.5.3.2.2.3.cmml">A</mi></mrow><mo id="S2.E1.m1.1.1.1.3.5.3.2.1" xref="S2.E1.m1.1.1.1.3.5.3.2.1.cmml">/</mo><mi id="S2.E1.m1.1.1.1.3.5.3.2.3" xref="S2.E1.m1.1.1.1.3.5.3.2.3.cmml">B</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.5.3.1" xref="S2.E1.m1.1.1.1.3.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.3.5.3.3" xref="S2.E1.m1.1.1.1.3.5.3.3.cmml">A</mi></mrow></msup></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.2.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><mn id="S2.E1.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo rspace="0.055em" stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml">⋅</mo><mi id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.2a" xref="S2.E1.m1.1.1.1.1.2.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.2b" xref="S2.E1.m1.1.1.1.1.2.cmml">​</mo><msup id="S2.E1.m1.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.5.cmml"><mi id="S2.E1.m1.1.1.1.1.5.2" xref="S2.E1.m1.1.1.1.1.5.2.cmml">s</mi><mrow id="S2.E1.m1.1.1.1.1.5.3" xref="S2.E1.m1.1.1.1.1.5.3.cmml"><mi id="S2.E1.m1.1.1.1.1.5.3.2" xref="S2.E1.m1.1.1.1.1.5.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.5.3.1" xref="S2.E1.m1.1.1.1.1.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.5.3.3" xref="S2.E1.m1.1.1.1.1.5.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.5.3.1a" xref="S2.E1.m1.1.1.1.1.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.5.3.4" xref="S2.E1.m1.1.1.1.1.5.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.5.3.1b" xref="S2.E1.m1.1.1.1.1.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.5.3.5" xref="S2.E1.m1.1.1.1.1.5.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.5.3.1c" xref="S2.E1.m1.1.1.1.1.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.5.3.6" xref="S2.E1.m1.1.1.1.1.5.3.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.5.3.1d" xref="S2.E1.m1.1.1.1.1.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.5.3.7" xref="S2.E1.m1.1.1.1.1.5.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.5.3.1e" xref="S2.E1.m1.1.1.1.1.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.5.3.8" xref="S2.E1.m1.1.1.1.1.5.3.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.5.3.1f" xref="S2.E1.m1.1.1.1.1.5.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.5.3.9" xref="S2.E1.m1.1.1.1.1.5.3.9.cmml">n</mi></mrow></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"></eq><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><times id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2">𝐿</ci><ci id="S2.E1.m1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.3.3">𝑜</ci><ci id="S2.E1.m1.1.1.3.4.cmml" xref="S2.E1.m1.1.1.3.4">𝑠</ci><ci id="S2.E1.m1.1.1.3.5.cmml" xref="S2.E1.m1.1.1.3.5">𝑠</ci></apply><apply id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><plus id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.2"></plus><apply id="S2.E1.m1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.3"><times id="S2.E1.m1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.3.1"></times><apply id="S2.E1.m1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.3.2"><ci id="S2.E1.m1.1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.1.3.2.1">⋅</ci><ci id="S2.E1.m1.1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.1.3.2.2">𝛼</ci><ci id="S2.E1.m1.1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.1.3.2.3">𝐿</ci></apply><ci id="S2.E1.m1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.3.3">𝑜</ci><ci id="S2.E1.m1.1.1.1.3.4.cmml" xref="S2.E1.m1.1.1.1.3.4">𝑠</ci><apply id="S2.E1.m1.1.1.1.3.5.cmml" xref="S2.E1.m1.1.1.1.3.5"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.3.5.1.cmml" xref="S2.E1.m1.1.1.1.3.5">superscript</csymbol><ci id="S2.E1.m1.1.1.1.3.5.2.cmml" xref="S2.E1.m1.1.1.1.3.5.2">𝑠</ci><apply id="S2.E1.m1.1.1.1.3.5.3.cmml" xref="S2.E1.m1.1.1.1.3.5.3"><times id="S2.E1.m1.1.1.1.3.5.3.1.cmml" xref="S2.E1.m1.1.1.1.3.5.3.1"></times><apply id="S2.E1.m1.1.1.1.3.5.3.2.cmml" xref="S2.E1.m1.1.1.1.3.5.3.2"><divide id="S2.E1.m1.1.1.1.3.5.3.2.1.cmml" xref="S2.E1.m1.1.1.1.3.5.3.2.1"></divide><apply id="S2.E1.m1.1.1.1.3.5.3.2.2.cmml" xref="S2.E1.m1.1.1.1.3.5.3.2.2"><times id="S2.E1.m1.1.1.1.3.5.3.2.2.1.cmml" xref="S2.E1.m1.1.1.1.3.5.3.2.2.1"></times><ci id="S2.E1.m1.1.1.1.3.5.3.2.2.2.cmml" xref="S2.E1.m1.1.1.1.3.5.3.2.2.2">𝑀</ci><ci id="S2.E1.m1.1.1.1.3.5.3.2.2.3.cmml" xref="S2.E1.m1.1.1.1.3.5.3.2.2.3">𝐴</ci></apply><ci id="S2.E1.m1.1.1.1.3.5.3.2.3.cmml" xref="S2.E1.m1.1.1.1.3.5.3.2.3">𝐵</ci></apply><ci id="S2.E1.m1.1.1.1.3.5.3.3.cmml" xref="S2.E1.m1.1.1.1.3.5.3.3">𝐴</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><ci id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2">⋅</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3">𝛼</ci></apply><ci id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3">𝐿</ci></apply><ci id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3">𝑜</ci><ci id="S2.E1.m1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.4">𝑠</ci><apply id="S2.E1.m1.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.5.1.cmml" xref="S2.E1.m1.1.1.1.1.5">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.5.2.cmml" xref="S2.E1.m1.1.1.1.1.5.2">𝑠</ci><apply id="S2.E1.m1.1.1.1.1.5.3.cmml" xref="S2.E1.m1.1.1.1.1.5.3"><times id="S2.E1.m1.1.1.1.1.5.3.1.cmml" xref="S2.E1.m1.1.1.1.1.5.3.1"></times><ci id="S2.E1.m1.1.1.1.1.5.3.2.cmml" xref="S2.E1.m1.1.1.1.1.5.3.2">𝐴</ci><ci id="S2.E1.m1.1.1.1.1.5.3.3.cmml" xref="S2.E1.m1.1.1.1.1.5.3.3">𝑑</ci><ci id="S2.E1.m1.1.1.1.1.5.3.4.cmml" xref="S2.E1.m1.1.1.1.1.5.3.4">𝑎</ci><ci id="S2.E1.m1.1.1.1.1.5.3.5.cmml" xref="S2.E1.m1.1.1.1.1.5.3.5">𝑝</ci><ci id="S2.E1.m1.1.1.1.1.5.3.6.cmml" xref="S2.E1.m1.1.1.1.1.5.3.6">𝑡</ci><ci id="S2.E1.m1.1.1.1.1.5.3.7.cmml" xref="S2.E1.m1.1.1.1.1.5.3.7">𝑖</ci><ci id="S2.E1.m1.1.1.1.1.5.3.8.cmml" xref="S2.E1.m1.1.1.1.1.5.3.8">𝑜</ci><ci id="S2.E1.m1.1.1.1.1.5.3.9.cmml" xref="S2.E1.m1.1.1.1.1.5.3.9">𝑛</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">Loss=\alpha\cdot Loss^{MA/BA}+(1-\alpha)\cdot Loss^{Adaption}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS2.p5.6" class="ltx_p">A <span id="S2.SS2.p5.6.1" class="ltx_text ltx_font_italic">classical adaptive adversary</span> creates a loss function for the deployed defense and applies <a href="#S2.E1" title="In 2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> to bypass the defensive measure<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The adversary can adapt to any objective and most likely aligns to the metrics of defenses, but is not restricted to those.</span></span></span>. Additionally, the updates of a poisoned local model can be scaled regarding the Euclidean distance to strengthen the influence on the aggregated model, hence increasing the BA. Training with a poisoned dataset combined with scaling is called <span id="S2.SS2.p5.6.2" class="ltx_text ltx_font_italic">train-and-scale</span> and adaption combined with scaling is called <span id="S2.SS2.p5.6.3" class="ltx_text ltx_font_italic">constrain-and-scale</span> <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.4" class="ltx_p">The goal of a defense against poisoning attacks is to create a situation, where <math id="S2.SS2.p6.1.m1.1" class="ltx_Math" alttext="Loss" display="inline"><semantics id="S2.SS2.p6.1.m1.1a"><mrow id="S2.SS2.p6.1.m1.1.1" xref="S2.SS2.p6.1.m1.1.1.cmml"><mi id="S2.SS2.p6.1.m1.1.1.2" xref="S2.SS2.p6.1.m1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p6.1.m1.1.1.1" xref="S2.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S2.SS2.p6.1.m1.1.1.3" xref="S2.SS2.p6.1.m1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p6.1.m1.1.1.1a" xref="S2.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S2.SS2.p6.1.m1.1.1.4" xref="S2.SS2.p6.1.m1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p6.1.m1.1.1.1b" xref="S2.SS2.p6.1.m1.1.1.1.cmml">​</mo><mi id="S2.SS2.p6.1.m1.1.1.5" xref="S2.SS2.p6.1.m1.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p6.1.m1.1b"><apply id="S2.SS2.p6.1.m1.1.1.cmml" xref="S2.SS2.p6.1.m1.1.1"><times id="S2.SS2.p6.1.m1.1.1.1.cmml" xref="S2.SS2.p6.1.m1.1.1.1"></times><ci id="S2.SS2.p6.1.m1.1.1.2.cmml" xref="S2.SS2.p6.1.m1.1.1.2">𝐿</ci><ci id="S2.SS2.p6.1.m1.1.1.3.cmml" xref="S2.SS2.p6.1.m1.1.1.3">𝑜</ci><ci id="S2.SS2.p6.1.m1.1.1.4.cmml" xref="S2.SS2.p6.1.m1.1.1.4">𝑠</ci><ci id="S2.SS2.p6.1.m1.1.1.5.cmml" xref="S2.SS2.p6.1.m1.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p6.1.m1.1c">Loss</annotation></semantics></math><sup id="S2.SS2.p6.4.1" class="ltx_sup"><span id="S2.SS2.p6.4.1.1" class="ltx_text ltx_font_italic">MA/BA</span></sup> and <math id="S2.SS2.p6.3.m3.1" class="ltx_Math" alttext="Loss" display="inline"><semantics id="S2.SS2.p6.3.m3.1a"><mrow id="S2.SS2.p6.3.m3.1.1" xref="S2.SS2.p6.3.m3.1.1.cmml"><mi id="S2.SS2.p6.3.m3.1.1.2" xref="S2.SS2.p6.3.m3.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p6.3.m3.1.1.1" xref="S2.SS2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.SS2.p6.3.m3.1.1.3" xref="S2.SS2.p6.3.m3.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p6.3.m3.1.1.1a" xref="S2.SS2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.SS2.p6.3.m3.1.1.4" xref="S2.SS2.p6.3.m3.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p6.3.m3.1.1.1b" xref="S2.SS2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.SS2.p6.3.m3.1.1.5" xref="S2.SS2.p6.3.m3.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p6.3.m3.1b"><apply id="S2.SS2.p6.3.m3.1.1.cmml" xref="S2.SS2.p6.3.m3.1.1"><times id="S2.SS2.p6.3.m3.1.1.1.cmml" xref="S2.SS2.p6.3.m3.1.1.1"></times><ci id="S2.SS2.p6.3.m3.1.1.2.cmml" xref="S2.SS2.p6.3.m3.1.1.2">𝐿</ci><ci id="S2.SS2.p6.3.m3.1.1.3.cmml" xref="S2.SS2.p6.3.m3.1.1.3">𝑜</ci><ci id="S2.SS2.p6.3.m3.1.1.4.cmml" xref="S2.SS2.p6.3.m3.1.1.4">𝑠</ci><ci id="S2.SS2.p6.3.m3.1.1.5.cmml" xref="S2.SS2.p6.3.m3.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p6.3.m3.1c">Loss</annotation></semantics></math><sup id="S2.SS2.p6.4.2" class="ltx_sup"><span id="S2.SS2.p6.4.2.1" class="ltx_text ltx_font_italic">Adaption</span></sup> cannot be perfectly optimized simultaneously so that the adversary is faced with a <span id="S2.SS2.p6.4.3" class="ltx_text">trade-off</span> between an effective attack and adapting to the defense, which is called <span id="S2.SS2.p6.4.4" class="ltx_text ltx_font_italic">adversarial dilemma</span> <cite class="ltx_cite ltx_citemacro_citep">(Frederickson et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>; Rieger et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Problems and Definitions</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we define our threat model including the concept of a strong adaptive adversary in <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>. The concluding <a href="#S3.SS2" title="3.2. Inter-Client Non-IID ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></span></a> is devoted to the problem of arbitrary data distributions.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Threat Model</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.16" class="ltx_p">We analyze a classical FL system as depicted in <a href="#S2.SS1" title="2.1. Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></span></a>. The aggregation server applies <span id="S3.SS1.p1.16.1" class="ltx_text">FedAVG</span> with a fixed global LR of <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\delta=1" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">δ</mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><eq id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></eq><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝛿</ci><cn type="integer" id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\delta=1</annotation></semantics></math>. We consider an adversary, who captures multiple clients <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">C</annotation></semantics></math><sub id="S3.SS1.p1.16.2" class="ltx_sub"><span id="S3.SS1.p1.16.2.1" class="ltx_text ltx_font_italic">i</span></sub> which are then denoted as <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">A</annotation></semantics></math><sub id="S3.SS1.p1.16.3" class="ltx_sub"><span id="S3.SS1.p1.16.3.1" class="ltx_text ltx_font_italic">j</span></sub> <math id="S3.SS1.p1.6.m6.1" class="ltx_math_unparsed" alttext="\in\{" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1b"><mo id="S3.SS1.p1.6.m6.1.1">∈</mo><mo stretchy="false" id="S3.SS1.p1.6.m6.1.2">{</mo></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\in\{</annotation></semantics></math><math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">C</annotation></semantics></math><sub id="S3.SS1.p1.16.4" class="ltx_sub"><span id="S3.SS1.p1.16.4.1" class="ltx_text ltx_font_italic">1</span></sub> <math id="S3.SS1.p1.9.m9.1" class="ltx_math_unparsed" alttext=",\ldots" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mrow id="S3.SS1.p1.9.m9.1b"><mo id="S3.SS1.p1.9.m9.1.1">,</mo><mi mathvariant="normal" id="S3.SS1.p1.9.m9.1.2">…</mi></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">,\ldots</annotation></semantics></math><math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">C</annotation></semantics></math><sub id="S3.SS1.p1.16.5" class="ltx_sub"><span id="S3.SS1.p1.16.5.1" class="ltx_text ltx_font_italic">n</span></sub><math id="S3.SS1.p1.12.m12.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S3.SS1.p1.12.m12.1a"><mo stretchy="false" id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b"><ci id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">\}</annotation></semantics></math> and can conduct any data and model poisoning attacks (cf. <a href="#S2.SS2" title="2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></span></a>). The adversary is aware of the code running on the aggregation server, including the details of defense mechanisms, which provides the necessary knowledge for adaption attempts. Analogous to related works <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2016</a>; Rieger et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>; Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>; Muñoz-González et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2019</a>; Andreina et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>; Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>, we consider <math id="S3.SS1.p1.13.m13.1" class="ltx_Math" alttext="\nicefrac{{n}}{{2}}+1" display="inline"><semantics id="S3.SS1.p1.13.m13.1a"><mrow id="S3.SS1.p1.13.m13.1.1" xref="S3.SS1.p1.13.m13.1.1.cmml"><mrow id="S3.SS1.p1.13.m13.1.1.2" xref="S3.SS1.p1.13.m13.1.1.2.cmml"><mpadded voffset="0.3em" id="S3.SS1.p1.13.m13.1.1.2.2" xref="S3.SS1.p1.13.m13.1.1.2.2.cmml"><mi mathsize="70%" id="S3.SS1.p1.13.m13.1.1.2.2a" xref="S3.SS1.p1.13.m13.1.1.2.2.cmml">n</mi></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S3.SS1.p1.13.m13.1.1.2.1" xref="S3.SS1.p1.13.m13.1.1.2.1.cmml"><mo stretchy="true" symmetric="true" id="S3.SS1.p1.13.m13.1.1.2.1a" xref="S3.SS1.p1.13.m13.1.1.2.1.cmml">/</mo></mpadded><mn mathsize="70%" id="S3.SS1.p1.13.m13.1.1.2.3" xref="S3.SS1.p1.13.m13.1.1.2.3.cmml">2</mn></mrow><mo id="S3.SS1.p1.13.m13.1.1.1" xref="S3.SS1.p1.13.m13.1.1.1.cmml">+</mo><mn id="S3.SS1.p1.13.m13.1.1.3" xref="S3.SS1.p1.13.m13.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m13.1b"><apply id="S3.SS1.p1.13.m13.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1"><plus id="S3.SS1.p1.13.m13.1.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1.1"></plus><apply id="S3.SS1.p1.13.m13.1.1.2.cmml" xref="S3.SS1.p1.13.m13.1.1.2"><divide id="S3.SS1.p1.13.m13.1.1.2.1.cmml" xref="S3.SS1.p1.13.m13.1.1.2.1"></divide><ci id="S3.SS1.p1.13.m13.1.1.2.2.cmml" xref="S3.SS1.p1.13.m13.1.1.2.2">𝑛</ci><cn type="integer" id="S3.SS1.p1.13.m13.1.1.2.3.cmml" xref="S3.SS1.p1.13.m13.1.1.2.3">2</cn></apply><cn type="integer" id="S3.SS1.p1.13.m13.1.1.3.cmml" xref="S3.SS1.p1.13.m13.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m13.1c">\nicefrac{{n}}{{2}}+1</annotation></semantics></math> benign clients (<span id="S3.SS1.p1.16.6" class="ltx_text ltx_font_italic">majority assumption</span>) in each training round <math id="S3.SS1.p1.14.m14.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS1.p1.14.m14.1a"><mi id="S3.SS1.p1.14.m14.1.1" xref="S3.SS1.p1.14.m14.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m14.1b"><ci id="S3.SS1.p1.14.m14.1.1.cmml" xref="S3.SS1.p1.14.m14.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m14.1c">r</annotation></semantics></math>. Since it is uncertain if adversaries participate in a round <math id="S3.SS1.p1.15.m15.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS1.p1.15.m15.1a"><mi id="S3.SS1.p1.15.m15.1.1" xref="S3.SS1.p1.15.m15.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m15.1b"><ci id="S3.SS1.p1.15.m15.1.1.cmml" xref="S3.SS1.p1.15.m15.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m15.1c">r</annotation></semantics></math>, the server weights all model updates equally with <math id="S3.SS1.p1.16.m16.1" class="ltx_Math" alttext="\nicefrac{{1}}{{n}}" display="inline"><semantics id="S3.SS1.p1.16.m16.1a"><mrow id="S3.SS1.p1.16.m16.1.1" xref="S3.SS1.p1.16.m16.1.1.cmml"><mpadded voffset="0.3em" id="S3.SS1.p1.16.m16.1.1.2" xref="S3.SS1.p1.16.m16.1.1.2.cmml"><mn mathsize="70%" id="S3.SS1.p1.16.m16.1.1.2a" xref="S3.SS1.p1.16.m16.1.1.2.cmml">1</mn></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S3.SS1.p1.16.m16.1.1.1" xref="S3.SS1.p1.16.m16.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="S3.SS1.p1.16.m16.1.1.1a" xref="S3.SS1.p1.16.m16.1.1.1.cmml">/</mo></mpadded><mi mathsize="70%" id="S3.SS1.p1.16.m16.1.1.3" xref="S3.SS1.p1.16.m16.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m16.1b"><apply id="S3.SS1.p1.16.m16.1.1.cmml" xref="S3.SS1.p1.16.m16.1.1"><divide id="S3.SS1.p1.16.m16.1.1.1.cmml" xref="S3.SS1.p1.16.m16.1.1.1"></divide><cn type="integer" id="S3.SS1.p1.16.m16.1.1.2.cmml" xref="S3.SS1.p1.16.m16.1.1.2">1</cn><ci id="S3.SS1.p1.16.m16.1.1.3.cmml" xref="S3.SS1.p1.16.m16.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m16.1c">\nicefrac{{1}}{{n}}</annotation></semantics></math>. In contrast to previous works, we do not make any assumption about the data distributions <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2021</a>)</cite> within or across clients’ dataset.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.6" class="ltx_p"><span id="S3.SS1.p2.6.1" class="ltx_text ltx_font_bold">Problem of an adaptive adversary.</span> DF defenses against poisoning attacks in FL are based on custom metrics. An adversary can try to circumvent the defense by adapting the value of the respective metric used for detection derived from the locally crafted poisoned model to a benign value during training<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>To acquire a benign value, the adversary can train a benign model first.</span></span></span>. As a <span id="S3.SS1.p2.6.2" class="ltx_text">state-of-the-art</span> technique for this challenge, <a href="#S2.E1" title="In 2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> is used to consider multiple objectives and simultaneously allowing the adversary to weight between better prediction performance (MA and BA) and higher adaption level via <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\alpha</annotation></semantics></math>. This adaption method from <a href="#S2.E1" title="In 2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> works well in two cases: 1) For only one adaption loss, since <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\alpha</annotation></semantics></math> can then balance the importance of main task and adaption properly and 2) for multiple adaption losses, where the different adaption losses summed to one value. The latter scenario works only well if all losses are at the same scale, as different components of adaption losses cannot be individually tuned. For example, if <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="Loss^{MA/BA}=10" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mrow id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2.2" xref="S3.SS1.p2.3.m3.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.2.1" xref="S3.SS1.p2.3.m3.1.1.2.1.cmml">​</mo><mi id="S3.SS1.p2.3.m3.1.1.2.3" xref="S3.SS1.p2.3.m3.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.2.1a" xref="S3.SS1.p2.3.m3.1.1.2.1.cmml">​</mo><mi id="S3.SS1.p2.3.m3.1.1.2.4" xref="S3.SS1.p2.3.m3.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.2.1b" xref="S3.SS1.p2.3.m3.1.1.2.1.cmml">​</mo><msup id="S3.SS1.p2.3.m3.1.1.2.5" xref="S3.SS1.p2.3.m3.1.1.2.5.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2.5.2" xref="S3.SS1.p2.3.m3.1.1.2.5.2.cmml">s</mi><mrow id="S3.SS1.p2.3.m3.1.1.2.5.3" xref="S3.SS1.p2.3.m3.1.1.2.5.3.cmml"><mrow id="S3.SS1.p2.3.m3.1.1.2.5.3.2" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.cmml"><mrow id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.2" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.1" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.1.cmml">​</mo><mi id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.3" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.3.cmml">A</mi></mrow><mo id="S3.SS1.p2.3.m3.1.1.2.5.3.2.1" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.1.cmml">/</mo><mi id="S3.SS1.p2.3.m3.1.1.2.5.3.2.3" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.3.cmml">B</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.2.5.3.1" xref="S3.SS1.p2.3.m3.1.1.2.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.3.m3.1.1.2.5.3.3" xref="S3.SS1.p2.3.m3.1.1.2.5.3.3.cmml">A</mi></mrow></msup></mrow><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><eq id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></eq><apply id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2"><times id="S3.SS1.p2.3.m3.1.1.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2.1"></times><ci id="S3.SS1.p2.3.m3.1.1.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.2">𝐿</ci><ci id="S3.SS1.p2.3.m3.1.1.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.3">𝑜</ci><ci id="S3.SS1.p2.3.m3.1.1.2.4.cmml" xref="S3.SS1.p2.3.m3.1.1.2.4">𝑠</ci><apply id="S3.SS1.p2.3.m3.1.1.2.5.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.2.5.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5">superscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.5.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.2">𝑠</ci><apply id="S3.SS1.p2.3.m3.1.1.2.5.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3"><times id="S3.SS1.p2.3.m3.1.1.2.5.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.1"></times><apply id="S3.SS1.p2.3.m3.1.1.2.5.3.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2"><divide id="S3.SS1.p2.3.m3.1.1.2.5.3.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.1"></divide><apply id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2"><times id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.1"></times><ci id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.2">𝑀</ci><ci id="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.2.3">𝐴</ci></apply><ci id="S3.SS1.p2.3.m3.1.1.2.5.3.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.2.3">𝐵</ci></apply><ci id="S3.SS1.p2.3.m3.1.1.2.5.3.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.5.3.3">𝐴</ci></apply></apply></apply><cn type="integer" id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">Loss^{MA/BA}=10</annotation></semantics></math> and <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="Loss^{Adaption}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.1a" xref="S3.SS1.p2.4.m4.1.1.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.4" xref="S3.SS1.p2.4.m4.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.1b" xref="S3.SS1.p2.4.m4.1.1.1.cmml">​</mo><msup id="S3.SS1.p2.4.m4.1.1.5" xref="S3.SS1.p2.4.m4.1.1.5.cmml"><mi id="S3.SS1.p2.4.m4.1.1.5.2" xref="S3.SS1.p2.4.m4.1.1.5.2.cmml">s</mi><mrow id="S3.SS1.p2.4.m4.1.1.5.3" xref="S3.SS1.p2.4.m4.1.1.5.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.5.3.2" xref="S3.SS1.p2.4.m4.1.1.5.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.5.3.1" xref="S3.SS1.p2.4.m4.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.5.3.3" xref="S3.SS1.p2.4.m4.1.1.5.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.5.3.1a" xref="S3.SS1.p2.4.m4.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.5.3.4" xref="S3.SS1.p2.4.m4.1.1.5.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.5.3.1b" xref="S3.SS1.p2.4.m4.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.5.3.5" xref="S3.SS1.p2.4.m4.1.1.5.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.5.3.1c" xref="S3.SS1.p2.4.m4.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.5.3.6" xref="S3.SS1.p2.4.m4.1.1.5.3.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.5.3.1d" xref="S3.SS1.p2.4.m4.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.5.3.7" xref="S3.SS1.p2.4.m4.1.1.5.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.5.3.1e" xref="S3.SS1.p2.4.m4.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.5.3.8" xref="S3.SS1.p2.4.m4.1.1.5.3.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.5.3.1f" xref="S3.SS1.p2.4.m4.1.1.5.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.5.3.9" xref="S3.SS1.p2.4.m4.1.1.5.3.9.cmml">n</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><times id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></times><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐿</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑜</ci><ci id="S3.SS1.p2.4.m4.1.1.4.cmml" xref="S3.SS1.p2.4.m4.1.1.4">𝑠</ci><apply id="S3.SS1.p2.4.m4.1.1.5.cmml" xref="S3.SS1.p2.4.m4.1.1.5"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.5.1.cmml" xref="S3.SS1.p2.4.m4.1.1.5">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.5.2.cmml" xref="S3.SS1.p2.4.m4.1.1.5.2">𝑠</ci><apply id="S3.SS1.p2.4.m4.1.1.5.3.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3"><times id="S3.SS1.p2.4.m4.1.1.5.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.1"></times><ci id="S3.SS1.p2.4.m4.1.1.5.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.2">𝐴</ci><ci id="S3.SS1.p2.4.m4.1.1.5.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.3">𝑑</ci><ci id="S3.SS1.p2.4.m4.1.1.5.3.4.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.4">𝑎</ci><ci id="S3.SS1.p2.4.m4.1.1.5.3.5.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.5">𝑝</ci><ci id="S3.SS1.p2.4.m4.1.1.5.3.6.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.6">𝑡</ci><ci id="S3.SS1.p2.4.m4.1.1.5.3.7.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.7">𝑖</ci><ci id="S3.SS1.p2.4.m4.1.1.5.3.8.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.8">𝑜</ci><ci id="S3.SS1.p2.4.m4.1.1.5.3.9.cmml" xref="S3.SS1.p2.4.m4.1.1.5.3.9">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">Loss^{Adaption}</annotation></semantics></math> consists of two losses <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="Loss_{1}=1" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mrow id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mrow id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2.2" xref="S3.SS1.p2.5.m5.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.1" xref="S3.SS1.p2.5.m5.1.1.2.1.cmml">​</mo><mi id="S3.SS1.p2.5.m5.1.1.2.3" xref="S3.SS1.p2.5.m5.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.1a" xref="S3.SS1.p2.5.m5.1.1.2.1.cmml">​</mo><mi id="S3.SS1.p2.5.m5.1.1.2.4" xref="S3.SS1.p2.5.m5.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.1b" xref="S3.SS1.p2.5.m5.1.1.2.1.cmml">​</mo><msub id="S3.SS1.p2.5.m5.1.1.2.5" xref="S3.SS1.p2.5.m5.1.1.2.5.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2.5.2" xref="S3.SS1.p2.5.m5.1.1.2.5.2.cmml">s</mi><mn id="S3.SS1.p2.5.m5.1.1.2.5.3" xref="S3.SS1.p2.5.m5.1.1.2.5.3.cmml">1</mn></msub></mrow><mo id="S3.SS1.p2.5.m5.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><eq id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1"></eq><apply id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2"><times id="S3.SS1.p2.5.m5.1.1.2.1.cmml" xref="S3.SS1.p2.5.m5.1.1.2.1"></times><ci id="S3.SS1.p2.5.m5.1.1.2.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2.2">𝐿</ci><ci id="S3.SS1.p2.5.m5.1.1.2.3.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3">𝑜</ci><ci id="S3.SS1.p2.5.m5.1.1.2.4.cmml" xref="S3.SS1.p2.5.m5.1.1.2.4">𝑠</ci><apply id="S3.SS1.p2.5.m5.1.1.2.5.cmml" xref="S3.SS1.p2.5.m5.1.1.2.5"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.2.5.1.cmml" xref="S3.SS1.p2.5.m5.1.1.2.5">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.5.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2.5.2">𝑠</ci><cn type="integer" id="S3.SS1.p2.5.m5.1.1.2.5.3.cmml" xref="S3.SS1.p2.5.m5.1.1.2.5.3">1</cn></apply></apply><cn type="integer" id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">Loss_{1}=1</annotation></semantics></math> and <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="Loss_{2}=0.0001" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mrow id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2.2" xref="S3.SS1.p2.6.m6.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.6.m6.1.1.2.1" xref="S3.SS1.p2.6.m6.1.1.2.1.cmml">​</mo><mi id="S3.SS1.p2.6.m6.1.1.2.3" xref="S3.SS1.p2.6.m6.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.6.m6.1.1.2.1a" xref="S3.SS1.p2.6.m6.1.1.2.1.cmml">​</mo><mi id="S3.SS1.p2.6.m6.1.1.2.4" xref="S3.SS1.p2.6.m6.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.6.m6.1.1.2.1b" xref="S3.SS1.p2.6.m6.1.1.2.1.cmml">​</mo><msub id="S3.SS1.p2.6.m6.1.1.2.5" xref="S3.SS1.p2.6.m6.1.1.2.5.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2.5.2" xref="S3.SS1.p2.6.m6.1.1.2.5.2.cmml">s</mi><mn id="S3.SS1.p2.6.m6.1.1.2.5.3" xref="S3.SS1.p2.6.m6.1.1.2.5.3.cmml">2</mn></msub></mrow><mo id="S3.SS1.p2.6.m6.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">0.0001</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><eq id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1"></eq><apply id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2"><times id="S3.SS1.p2.6.m6.1.1.2.1.cmml" xref="S3.SS1.p2.6.m6.1.1.2.1"></times><ci id="S3.SS1.p2.6.m6.1.1.2.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2.2">𝐿</ci><ci id="S3.SS1.p2.6.m6.1.1.2.3.cmml" xref="S3.SS1.p2.6.m6.1.1.2.3">𝑜</ci><ci id="S3.SS1.p2.6.m6.1.1.2.4.cmml" xref="S3.SS1.p2.6.m6.1.1.2.4">𝑠</ci><apply id="S3.SS1.p2.6.m6.1.1.2.5.cmml" xref="S3.SS1.p2.6.m6.1.1.2.5"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.2.5.1.cmml" xref="S3.SS1.p2.6.m6.1.1.2.5">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.5.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2.5.2">𝑠</ci><cn type="integer" id="S3.SS1.p2.6.m6.1.1.2.5.3.cmml" xref="S3.SS1.p2.6.m6.1.1.2.5.3">2</cn></apply></apply><cn type="float" id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">0.0001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">Loss_{2}=0.0001</annotation></semantics></math>, the second adaption loss will have only a negligible effect on the model’s parameters since the value is already close to zero and the learning algorithm will try to minimize the other losses instead. Therefore, the underlying metric will not be adapted properly.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.2" class="ltx_p"><span id="S3.SS1.p3.2.1" class="ltx_text ltx_font_bold">Definition of a strong adaptive adversary.</span> We propose a <span id="S3.SS1.p3.2.2" class="ltx_text ltx_font_italic">strong adaptive adversary</span>, who is able to adapt to multiple metrics simultaneously, independent of the value scales. Therefore, the adversary first scales all losses to the maximum loss value once (cf. <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\lambda</annotation></semantics></math> values in <a href="#S3.E2" title="In 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>). This has the effect, that all adaption objectives and the main task are considered equally. Afterward, the adversary can still weigh the adaption level via <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\alpha</annotation></semantics></math>.</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="Loss=\alpha\cdot Loss^{MA/BA}+(1-\alpha)\cdot(\lambda_{1}\cdot Loss_{1}+\lambda_{2}\cdot Loss_{2}+\cdots)" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.2.2.4" xref="S3.E2.m1.2.2.4.cmml"><mi id="S3.E2.m1.2.2.4.2" xref="S3.E2.m1.2.2.4.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.4.1" xref="S3.E2.m1.2.2.4.1.cmml">​</mo><mi id="S3.E2.m1.2.2.4.3" xref="S3.E2.m1.2.2.4.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.4.1a" xref="S3.E2.m1.2.2.4.1.cmml">​</mo><mi id="S3.E2.m1.2.2.4.4" xref="S3.E2.m1.2.2.4.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.4.1b" xref="S3.E2.m1.2.2.4.1.cmml">​</mo><mi id="S3.E2.m1.2.2.4.5" xref="S3.E2.m1.2.2.4.5.cmml">s</mi></mrow><mo id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.3.cmml">=</mo><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mrow id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.4.cmml"><mrow id="S3.E2.m1.2.2.2.4.2" xref="S3.E2.m1.2.2.2.4.2.cmml"><mi id="S3.E2.m1.2.2.2.4.2.2" xref="S3.E2.m1.2.2.2.4.2.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.2.2.2.4.2.1" xref="S3.E2.m1.2.2.2.4.2.1.cmml">⋅</mo><mi id="S3.E2.m1.2.2.2.4.2.3" xref="S3.E2.m1.2.2.2.4.2.3.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.4.1" xref="S3.E2.m1.2.2.2.4.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.4.3" xref="S3.E2.m1.2.2.2.4.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.4.1a" xref="S3.E2.m1.2.2.2.4.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.4.4" xref="S3.E2.m1.2.2.2.4.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.4.1b" xref="S3.E2.m1.2.2.2.4.1.cmml">​</mo><msup id="S3.E2.m1.2.2.2.4.5" xref="S3.E2.m1.2.2.2.4.5.cmml"><mi id="S3.E2.m1.2.2.2.4.5.2" xref="S3.E2.m1.2.2.2.4.5.2.cmml">s</mi><mrow id="S3.E2.m1.2.2.2.4.5.3" xref="S3.E2.m1.2.2.2.4.5.3.cmml"><mrow id="S3.E2.m1.2.2.2.4.5.3.2" xref="S3.E2.m1.2.2.2.4.5.3.2.cmml"><mrow id="S3.E2.m1.2.2.2.4.5.3.2.2" xref="S3.E2.m1.2.2.2.4.5.3.2.2.cmml"><mi id="S3.E2.m1.2.2.2.4.5.3.2.2.2" xref="S3.E2.m1.2.2.2.4.5.3.2.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.4.5.3.2.2.1" xref="S3.E2.m1.2.2.2.4.5.3.2.2.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.4.5.3.2.2.3" xref="S3.E2.m1.2.2.2.4.5.3.2.2.3.cmml">A</mi></mrow><mo id="S3.E2.m1.2.2.2.4.5.3.2.1" xref="S3.E2.m1.2.2.2.4.5.3.2.1.cmml">/</mo><mi id="S3.E2.m1.2.2.2.4.5.3.2.3" xref="S3.E2.m1.2.2.2.4.5.3.2.3.cmml">B</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.4.5.3.1" xref="S3.E2.m1.2.2.2.4.5.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.4.5.3.3" xref="S3.E2.m1.2.2.2.4.5.3.3.cmml">A</mi></mrow></msup></mrow><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">+</mo><mrow id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo rspace="0.055em" stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E2.m1.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">⋅</mo><mrow id="S3.E2.m1.2.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.2.2.1.2" xref="S3.E2.m1.2.2.2.2.2.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.2.2.1.1.2.cmml"><mrow id="S3.E2.m1.2.2.2.2.2.1.1.2.2" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.cmml"><msub id="S3.E2.m1.2.2.2.2.2.1.1.2.2.2" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.2.cmml">λ</mi><mn id="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.3.cmml">1</mn></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.2.2.2.2.2.1.1.2.2.1" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.1.cmml">⋅</mo><mi id="S3.E2.m1.2.2.2.2.2.1.1.2.2.3" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.3.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.1.1.2.1" xref="S3.E2.m1.2.2.2.2.2.1.1.2.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.2.2.1.1.2.3" xref="S3.E2.m1.2.2.2.2.2.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.1.1.2.1a" xref="S3.E2.m1.2.2.2.2.2.1.1.2.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.2.2.1.1.2.4" xref="S3.E2.m1.2.2.2.2.2.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.1.1.2.1b" xref="S3.E2.m1.2.2.2.2.2.1.1.2.1.cmml">​</mo><msub id="S3.E2.m1.2.2.2.2.2.1.1.2.5" xref="S3.E2.m1.2.2.2.2.2.1.1.2.5.cmml"><mi id="S3.E2.m1.2.2.2.2.2.1.1.2.5.2" xref="S3.E2.m1.2.2.2.2.2.1.1.2.5.2.cmml">s</mi><mn id="S3.E2.m1.2.2.2.2.2.1.1.2.5.3" xref="S3.E2.m1.2.2.2.2.2.1.1.2.5.3.cmml">1</mn></msub></mrow><mo id="S3.E2.m1.2.2.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.2.2.1.1.1.cmml">+</mo><mrow id="S3.E2.m1.2.2.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.2.2.1.1.3.cmml"><mrow id="S3.E2.m1.2.2.2.2.2.1.1.3.2" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.cmml"><msub id="S3.E2.m1.2.2.2.2.2.1.1.3.2.2" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.2" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.2.cmml">λ</mi><mn id="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.3" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.3.cmml">2</mn></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.2.2.2.2.2.1.1.3.2.1" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.1.cmml">⋅</mo><mi id="S3.E2.m1.2.2.2.2.2.1.1.3.2.3" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.3.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.1.1.3.1" xref="S3.E2.m1.2.2.2.2.2.1.1.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.2.2.1.1.3.3" xref="S3.E2.m1.2.2.2.2.2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.1.1.3.1a" xref="S3.E2.m1.2.2.2.2.2.1.1.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.2.2.2.1.1.3.4" xref="S3.E2.m1.2.2.2.2.2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.1.1.3.1b" xref="S3.E2.m1.2.2.2.2.2.1.1.3.1.cmml">​</mo><msub id="S3.E2.m1.2.2.2.2.2.1.1.3.5" xref="S3.E2.m1.2.2.2.2.2.1.1.3.5.cmml"><mi id="S3.E2.m1.2.2.2.2.2.1.1.3.5.2" xref="S3.E2.m1.2.2.2.2.2.1.1.3.5.2.cmml">s</mi><mn id="S3.E2.m1.2.2.2.2.2.1.1.3.5.3" xref="S3.E2.m1.2.2.2.2.2.1.1.3.5.3.cmml">2</mn></msub></mrow><mo id="S3.E2.m1.2.2.2.2.2.1.1.1a" xref="S3.E2.m1.2.2.2.2.2.1.1.1.cmml">+</mo><mi mathvariant="normal" id="S3.E2.m1.2.2.2.2.2.1.1.4" xref="S3.E2.m1.2.2.2.2.2.1.1.4.cmml">⋯</mi></mrow><mo stretchy="false" id="S3.E2.m1.2.2.2.2.2.1.3" xref="S3.E2.m1.2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.3"></eq><apply id="S3.E2.m1.2.2.4.cmml" xref="S3.E2.m1.2.2.4"><times id="S3.E2.m1.2.2.4.1.cmml" xref="S3.E2.m1.2.2.4.1"></times><ci id="S3.E2.m1.2.2.4.2.cmml" xref="S3.E2.m1.2.2.4.2">𝐿</ci><ci id="S3.E2.m1.2.2.4.3.cmml" xref="S3.E2.m1.2.2.4.3">𝑜</ci><ci id="S3.E2.m1.2.2.4.4.cmml" xref="S3.E2.m1.2.2.4.4">𝑠</ci><ci id="S3.E2.m1.2.2.4.5.cmml" xref="S3.E2.m1.2.2.4.5">𝑠</ci></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><plus id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"></plus><apply id="S3.E2.m1.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.4"><times id="S3.E2.m1.2.2.2.4.1.cmml" xref="S3.E2.m1.2.2.2.4.1"></times><apply id="S3.E2.m1.2.2.2.4.2.cmml" xref="S3.E2.m1.2.2.2.4.2"><ci id="S3.E2.m1.2.2.2.4.2.1.cmml" xref="S3.E2.m1.2.2.2.4.2.1">⋅</ci><ci id="S3.E2.m1.2.2.2.4.2.2.cmml" xref="S3.E2.m1.2.2.2.4.2.2">𝛼</ci><ci id="S3.E2.m1.2.2.2.4.2.3.cmml" xref="S3.E2.m1.2.2.2.4.2.3">𝐿</ci></apply><ci id="S3.E2.m1.2.2.2.4.3.cmml" xref="S3.E2.m1.2.2.2.4.3">𝑜</ci><ci id="S3.E2.m1.2.2.2.4.4.cmml" xref="S3.E2.m1.2.2.2.4.4">𝑠</ci><apply id="S3.E2.m1.2.2.2.4.5.cmml" xref="S3.E2.m1.2.2.2.4.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.4.5.1.cmml" xref="S3.E2.m1.2.2.2.4.5">superscript</csymbol><ci id="S3.E2.m1.2.2.2.4.5.2.cmml" xref="S3.E2.m1.2.2.2.4.5.2">𝑠</ci><apply id="S3.E2.m1.2.2.2.4.5.3.cmml" xref="S3.E2.m1.2.2.2.4.5.3"><times id="S3.E2.m1.2.2.2.4.5.3.1.cmml" xref="S3.E2.m1.2.2.2.4.5.3.1"></times><apply id="S3.E2.m1.2.2.2.4.5.3.2.cmml" xref="S3.E2.m1.2.2.2.4.5.3.2"><divide id="S3.E2.m1.2.2.2.4.5.3.2.1.cmml" xref="S3.E2.m1.2.2.2.4.5.3.2.1"></divide><apply id="S3.E2.m1.2.2.2.4.5.3.2.2.cmml" xref="S3.E2.m1.2.2.2.4.5.3.2.2"><times id="S3.E2.m1.2.2.2.4.5.3.2.2.1.cmml" xref="S3.E2.m1.2.2.2.4.5.3.2.2.1"></times><ci id="S3.E2.m1.2.2.2.4.5.3.2.2.2.cmml" xref="S3.E2.m1.2.2.2.4.5.3.2.2.2">𝑀</ci><ci id="S3.E2.m1.2.2.2.4.5.3.2.2.3.cmml" xref="S3.E2.m1.2.2.2.4.5.3.2.2.3">𝐴</ci></apply><ci id="S3.E2.m1.2.2.2.4.5.3.2.3.cmml" xref="S3.E2.m1.2.2.2.4.5.3.2.3">𝐵</ci></apply><ci id="S3.E2.m1.2.2.2.4.5.3.3.cmml" xref="S3.E2.m1.2.2.2.4.5.3.3">𝐴</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><ci id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3">⋅</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><minus id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">𝛼</ci></apply><apply id="S3.E2.m1.2.2.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1"><plus id="S3.E2.m1.2.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.1"></plus><apply id="S3.E2.m1.2.2.2.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2"><times id="S3.E2.m1.2.2.2.2.2.1.1.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.1"></times><apply id="S3.E2.m1.2.2.2.2.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2"><ci id="S3.E2.m1.2.2.2.2.2.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.1">⋅</ci><apply id="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.2">𝜆</ci><cn type="integer" id="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.2.3">1</cn></apply><ci id="S3.E2.m1.2.2.2.2.2.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.2.3">𝐿</ci></apply><ci id="S3.E2.m1.2.2.2.2.2.1.1.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.3">𝑜</ci><ci id="S3.E2.m1.2.2.2.2.2.1.1.2.4.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.4">𝑠</ci><apply id="S3.E2.m1.2.2.2.2.2.1.1.2.5.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.1.1.2.5.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.5">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.1.1.2.5.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.5.2">𝑠</ci><cn type="integer" id="S3.E2.m1.2.2.2.2.2.1.1.2.5.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.2.5.3">1</cn></apply></apply><apply id="S3.E2.m1.2.2.2.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3"><times id="S3.E2.m1.2.2.2.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.1"></times><apply id="S3.E2.m1.2.2.2.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2"><ci id="S3.E2.m1.2.2.2.2.2.1.1.3.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.1">⋅</ci><apply id="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.2">𝜆</ci><cn type="integer" id="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.2.3">2</cn></apply><ci id="S3.E2.m1.2.2.2.2.2.1.1.3.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.2.3">𝐿</ci></apply><ci id="S3.E2.m1.2.2.2.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.3">𝑜</ci><ci id="S3.E2.m1.2.2.2.2.2.1.1.3.4.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.4">𝑠</ci><apply id="S3.E2.m1.2.2.2.2.2.1.1.3.5.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.1.1.3.5.1.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.5">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.1.1.3.5.2.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.5.2">𝑠</ci><cn type="integer" id="S3.E2.m1.2.2.2.2.2.1.1.3.5.3.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.3.5.3">2</cn></apply></apply><ci id="S3.E2.m1.2.2.2.2.2.1.1.4.cmml" xref="S3.E2.m1.2.2.2.2.2.1.1.4">⋯</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">Loss=\alpha\cdot Loss^{MA/BA}+(1-\alpha)\cdot(\lambda_{1}\cdot Loss_{1}+\lambda_{2}\cdot Loss_{2}+\cdots)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS1.p3.3" class="ltx_p">Further, the adversary can simultaneously exclude specific parameters from training or replace parameters in the final model, e.g., with parameters of a previously benign trained model on the client’s unpoisoned dataset, which we call <span id="S3.SS1.p3.3.1" class="ltx_text ltx_font_italic">fixation</span>. The attacker can choose among multiple poisoning attacks, hence can use any existing method to embed a targeted poisoning attack in the local model. Additionally, advanced scaling methods and other classical model poisoning approaches can be applied.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We provide results for attacks conducted by a strong adaptive adversary against FL defenses in <a href="#S5.SS2" title="5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></span></a> and discuss other adaption strategies that we evaluated in <a href="#S6.SS1" title="6.1. Adversarial Adaption Methodologies ‣ 6. Discussion ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></span></a>.</span></span></span></p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">Regarding an adversarial-captured client, it is essential to recognize that the entire client device falls under adversarial control, granting the adversary full access to employ any adaptation strategy. Additionally, the adversary can leverage any supplementary hardware resources, thereby eliminating the assumption of limited computational power on the adversary’s device.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2306.03600/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="206" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.21.7.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S3.F1.12.6" class="ltx_text" style="font-size:90%;">Comparison of various data distributions: IID, classical (<span id="S3.F1.12.6.1" class="ltx_text">intra-client</span>) <span id="S3.F1.12.6.2" class="ltx_text">non-IID</span>, and <span id="S3.F1.12.6.3" class="ltx_text">inter-client</span> <span id="S3.F1.12.6.4" class="ltx_text">non-IID</span> strategy for three client datasets <math id="S3.F1.7.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.F1.7.1.m1.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F1.7.1.m1.1.1" xref="S3.F1.7.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.F1.7.1.m1.1c"><ci id="S3.F1.7.1.m1.1.1.cmml" xref="S3.F1.7.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.7.1.m1.1d">\mathcal{D}</annotation></semantics></math><sub id="S3.F1.12.6.5" class="ltx_sub"><span id="S3.F1.12.6.5.1" class="ltx_text ltx_font_italic">1</span></sub>, <math id="S3.F1.9.3.m3.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.F1.9.3.m3.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F1.9.3.m3.1.1" xref="S3.F1.9.3.m3.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.F1.9.3.m3.1c"><ci id="S3.F1.9.3.m3.1.1.cmml" xref="S3.F1.9.3.m3.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.9.3.m3.1d">\mathcal{D}</annotation></semantics></math><sub id="S3.F1.12.6.6" class="ltx_sub"><span id="S3.F1.12.6.6.1" class="ltx_text ltx_font_italic">2</span></sub>, and <math id="S3.F1.11.5.m5.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.F1.11.5.m5.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F1.11.5.m5.1.1" xref="S3.F1.11.5.m5.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.F1.11.5.m5.1c"><ci id="S3.F1.11.5.m5.1.1.cmml" xref="S3.F1.11.5.m5.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.11.5.m5.1d">\mathcal{D}</annotation></semantics></math><sub id="S3.F1.12.6.7" class="ltx_sub"><span id="S3.F1.12.6.7.1" class="ltx_text ltx_font_italic">3</span></sub> with 10 label classes.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Inter-Client Non-IID</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Below, we discuss the problem of varying data distributions in FL and define <span id="S3.SS2.p1.1.1" class="ltx_text">inter-client</span> <span id="S3.SS2.p1.1.2" class="ltx_text">non-IID</span> as a new challenge thereafter.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Problem.</span> DF defenses in general inspect the clients’ local model updates to detect abnormal situations based on the assumption, that the majority of clients are benign (cf. <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>). Thereby, they leverage the fact that trained models’ parameters reflect the characteristics of the underlying data as well as their distributions. It is easier to establish that models are similar if all clients possess similar data, e.g., there is the same amount of samples from each class in a classification task. This situation is called identically and independently distributed (IID) and is visualized in the first row of <a href="#S3.F1" title="Figure 1 ‣ 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>. In poisoning attacks, the underlying data need to change to introduce, e.g., backdoor behaviour, which inevitably manifests in changes in some parameters.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">The second row of <a href="#S3.F1" title="Figure 1 ‣ 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> visualizes the classical <span id="S3.SS2.p3.1.1" class="ltx_text">non-IID</span> scenario, which is typically considered in the evaluation of backdoor defenses. Here, the data <span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_italic">inside</span> the client’s local dataset (<span id="S3.SS2.p3.1.3" class="ltx_text">intra-client</span>) are diverse, yet data distributions are similar across clients. Upon analysis of benign local models in this situation, they all will show a similar distance to the previous global model due to the similarity of distributions across clients. Existing DF defenses leverage this fact and can filter poisoned models, which are trained on a deviant data distribution due to data poisoning. However, defenses are not optimized for scenarios with different data distributions across clients, which we term <span id="S3.SS2.p3.1.4" class="ltx_text ltx_font_italic">inter-client</span><span id="S3.SS2.p3.1.5" class="ltx_text ltx_font_italic"> <span id="S3.SS2.p3.1.5.1" class="ltx_text">non-IID</span></span>. Such scenarios, as visualized in the third row of <a href="#S3.F1" title="Figure 1 ‣ 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, are the most challenging to detect but also represent the most realistic <span id="S3.SS2.p3.1.6" class="ltx_text">real-world</span> situation.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.2" class="ltx_p"><span id="S3.SS2.p4.2.1" class="ltx_text ltx_font_bold">Definition of <span id="S3.SS2.p4.2.1.1" class="ltx_text">Inter-client</span> <span id="S3.SS2.p4.2.1.2" class="ltx_text">non-IID</span>.</span> In <span id="S3.SS2.p4.2.2" class="ltx_text ltx_font_italic">Inter-client</span><span id="S3.SS2.p4.2.3" class="ltx_text ltx_font_italic"> <span id="S3.SS2.p4.2.3.1" class="ltx_text">non-IID</span></span> setting, the data within the clients’ local dataset can follow arbitrary distributions inside and across the datasets without any assumptions made regarding sample frequencies or the availability of samples for a specific class. Thus, this definition also includes cases with disjoint data, as illustrated in row three of <a href="#S3.F1" title="Figure 1 ‣ 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, where labels of classes 3 and 6 are not available within dataset <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathcal{D}</annotation></semantics></math><sub id="S3.SS2.p4.2.4" class="ltx_sub"><span id="S3.SS2.p4.2.4.1" class="ltx_text ltx_font_italic">3</span></sub>.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>
We evaluate FL defenses in <span id="footnote5.1" class="ltx_text">inter-client</span> <span id="footnote5.2" class="ltx_text">non-IID</span> scenarios in <a href="#S5.SS3" title="5.3. Defenses under Non-IID ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></span></a>.</span></span></span></p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2306.03600/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="182" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">Overview of <span id="S3.F2.4.2.1" class="ltx_text">MESAS</span>.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span><span id="S4.1.1" class="ltx_text">MESAS</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present our new defense against poisoning attacks, <span id="S4.p1.1.1" class="ltx_text"><span id="S4.p1.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">M</span><span id="S4.p1.1.1.2" class="ltx_text ltx_framed ltx_framed_underline">e</span>tric-Ca<span id="S4.p1.1.1.3" class="ltx_text ltx_framed ltx_framed_underline">s</span>c<span id="S4.p1.1.1.4" class="ltx_text ltx_framed ltx_framed_underline">a</span>de<span id="S4.p1.1.1.5" class="ltx_text ltx_framed ltx_framed_underline">s</span></span> (<span id="S4.p1.1.2" class="ltx_text">MESAS</span>). We first provide a high-level overview in <a href="#S4.SS1" title="4.1. Overview ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></span></a>, followed by explanations of the underlying intuitions in <a href="#S4.SS2" title="4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></span></a> and providing lower-level details in <a href="#S4.SS3" title="4.3. Pruning Loop ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Overview</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text">MESAS</span> is a DF-based defense method which is applied on the central aggregation server before the aggregation step.
To prevent strong adaptive adversaries from circumventing the defense, <span id="S4.SS1.p1.1.2" class="ltx_text">MESAS</span> filters poisoned models in a cascade of six <span id="S4.SS1.p1.1.3" class="ltx_text">well-chosen</span> metrics<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>To the best of our knowledge 4-out-of-6 utilized metrics, namely COUNT, VAR, MIN, and MAX are novel and have never been considered in existing defenses.</span></span></span>, that affect each other and cannot be optimized simultaneously, thus tightening the adversarial dilemma for the attacker. Further, <span id="S4.SS1.p1.1.4" class="ltx_text">MESAS</span> analyses the six metrics with numerous statistical tests, thus allowing the defense to be effective also in <span id="S4.SS1.p1.1.5" class="ltx_text">inter-client</span> <span id="S4.SS1.p1.1.6" class="ltx_text">non-IID</span> scenarios and independent of the application scenario. Those statistical tests are also superior to hard thresholds in identifying scenarios without any attack and hence allow <span id="S4.SS1.p1.1.7" class="ltx_text">MESAS</span> to not negatively affect the convergence of the federation. Moreover, the statistical tests utilized exhibit a higher level of effectiveness compared to threshold-based methods in accurately detecting scenarios without attacks. As a consequence, the integration of these tests into <span id="S4.SS1.p1.1.8" class="ltx_text">MESAS</span> ensures that the convergence of the federation remains unaffected, thus preserving its overall performance and stability even if the defense is applied in every round.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In a nutshell, <span id="S4.SS1.p2.1.1" class="ltx_text">MESAS</span> consists of four major steps that can be retraced in <a href="#S3.F2" title="Figure 2 ‣ 3.2. Inter-Client Non-IID ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>: 1) After the local updates have been transmitted to the server, <span id="S4.SS1.p2.1.2" class="ltx_text">MESAS</span> extracts six carefully chosen metrics from the local models and the global model. Thereafter, those metrics are analyzed individually in an iterative process. The metrics are extracted for the whole model, but also from each layer individually, to detect poisonings distributed over the whole model, but also locally embedded ones<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Naïve implemented backdoors are only embedded within the last few DNN layers. However, more sophisticated backdoors can reside within different locations, e.g., layers, inside the model parameters.</span></span></span>. 2) Each metric passes through a significance analysis consisting of statistical tests, that spot evidence of a poisoning attack within the metric values. 3) If indication is provided, the respective values are clustered into two clusters and the models belonging to the values within the smaller cluster are marked as malicious. 4) After each metric is analyzed, the marked models are excluded in a pruning step and the analysis starts over on the remaining models until no statistical test reports significant evidence for an attack. Finally, the normal FL procedure continues with the remaining local models getting aggregated to the new global model.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Metrics Intuition</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">DNNs are complex <span id="S4.SS2.p1.3.1" class="ltx_text">multi-dimensional</span> <span id="S4.SS2.p1.3.2" class="ltx_text">non-linear</span> functions. An example of DNN with around eleven million trainable parameters is <span id="S4.SS2.p1.3.3" class="ltx_text">ResNet-18</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2016</a>)</cite>. For a better explanation of our metrics, however, we will use a simplified function, which is linear and only has two parameters (or dimensions): <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="f(x)=p_{1}\cdot x+p_{2}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.2" xref="S4.SS2.p1.1.m1.1.2.cmml"><mrow id="S4.SS2.p1.1.m1.1.2.2" xref="S4.SS2.p1.1.m1.1.2.2.cmml"><mi id="S4.SS2.p1.1.m1.1.2.2.2" xref="S4.SS2.p1.1.m1.1.2.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.2.2.1" xref="S4.SS2.p1.1.m1.1.2.2.1.cmml">​</mo><mrow id="S4.SS2.p1.1.m1.1.2.2.3.2" xref="S4.SS2.p1.1.m1.1.2.2.cmml"><mo stretchy="false" id="S4.SS2.p1.1.m1.1.2.2.3.2.1" xref="S4.SS2.p1.1.m1.1.2.2.cmml">(</mo><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S4.SS2.p1.1.m1.1.2.2.3.2.2" xref="S4.SS2.p1.1.m1.1.2.2.cmml">)</mo></mrow></mrow><mo id="S4.SS2.p1.1.m1.1.2.1" xref="S4.SS2.p1.1.m1.1.2.1.cmml">=</mo><mrow id="S4.SS2.p1.1.m1.1.2.3" xref="S4.SS2.p1.1.m1.1.2.3.cmml"><mrow id="S4.SS2.p1.1.m1.1.2.3.2" xref="S4.SS2.p1.1.m1.1.2.3.2.cmml"><msub id="S4.SS2.p1.1.m1.1.2.3.2.2" xref="S4.SS2.p1.1.m1.1.2.3.2.2.cmml"><mi id="S4.SS2.p1.1.m1.1.2.3.2.2.2" xref="S4.SS2.p1.1.m1.1.2.3.2.2.2.cmml">p</mi><mn id="S4.SS2.p1.1.m1.1.2.3.2.2.3" xref="S4.SS2.p1.1.m1.1.2.3.2.2.3.cmml">1</mn></msub><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.1.m1.1.2.3.2.1" xref="S4.SS2.p1.1.m1.1.2.3.2.1.cmml">⋅</mo><mi id="S4.SS2.p1.1.m1.1.2.3.2.3" xref="S4.SS2.p1.1.m1.1.2.3.2.3.cmml">x</mi></mrow><mo id="S4.SS2.p1.1.m1.1.2.3.1" xref="S4.SS2.p1.1.m1.1.2.3.1.cmml">+</mo><msub id="S4.SS2.p1.1.m1.1.2.3.3" xref="S4.SS2.p1.1.m1.1.2.3.3.cmml"><mi id="S4.SS2.p1.1.m1.1.2.3.3.2" xref="S4.SS2.p1.1.m1.1.2.3.3.2.cmml">p</mi><mn id="S4.SS2.p1.1.m1.1.2.3.3.3" xref="S4.SS2.p1.1.m1.1.2.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.2"><eq id="S4.SS2.p1.1.m1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.2.1"></eq><apply id="S4.SS2.p1.1.m1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.2.2"><times id="S4.SS2.p1.1.m1.1.2.2.1.cmml" xref="S4.SS2.p1.1.m1.1.2.2.1"></times><ci id="S4.SS2.p1.1.m1.1.2.2.2.cmml" xref="S4.SS2.p1.1.m1.1.2.2.2">𝑓</ci><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝑥</ci></apply><apply id="S4.SS2.p1.1.m1.1.2.3.cmml" xref="S4.SS2.p1.1.m1.1.2.3"><plus id="S4.SS2.p1.1.m1.1.2.3.1.cmml" xref="S4.SS2.p1.1.m1.1.2.3.1"></plus><apply id="S4.SS2.p1.1.m1.1.2.3.2.cmml" xref="S4.SS2.p1.1.m1.1.2.3.2"><ci id="S4.SS2.p1.1.m1.1.2.3.2.1.cmml" xref="S4.SS2.p1.1.m1.1.2.3.2.1">⋅</ci><apply id="S4.SS2.p1.1.m1.1.2.3.2.2.cmml" xref="S4.SS2.p1.1.m1.1.2.3.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.2.3.2.2.1.cmml" xref="S4.SS2.p1.1.m1.1.2.3.2.2">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.2.3.2.2.2.cmml" xref="S4.SS2.p1.1.m1.1.2.3.2.2.2">𝑝</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.2.3.2.2.3.cmml" xref="S4.SS2.p1.1.m1.1.2.3.2.2.3">1</cn></apply><ci id="S4.SS2.p1.1.m1.1.2.3.2.3.cmml" xref="S4.SS2.p1.1.m1.1.2.3.2.3">𝑥</ci></apply><apply id="S4.SS2.p1.1.m1.1.2.3.3.cmml" xref="S4.SS2.p1.1.m1.1.2.3.3"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.2.3.3.1.cmml" xref="S4.SS2.p1.1.m1.1.2.3.3">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.2.3.3.2.cmml" xref="S4.SS2.p1.1.m1.1.2.3.3.2">𝑝</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.2.3.3.3.cmml" xref="S4.SS2.p1.1.m1.1.2.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">f(x)=p_{1}\cdot x+p_{2}</annotation></semantics></math>. With this, we can visualize model parameters <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="p_{1}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">p</mi><mn id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝑝</ci><cn type="integer" id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">p_{1}</annotation></semantics></math> and <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="p_{2}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><msub id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">p</mi><mn id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">𝑝</ci><cn type="integer" id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">p_{2}</annotation></semantics></math> in a 2D plot (cf. <a href="#S4.F3" title="Figure 3 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></span></a>), which won’t be possible for a more realistic <span id="S4.SS2.p1.3.4" class="ltx_text">multi-dimensional</span> function.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x3.png" id="S4.F3.1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x4.png" id="S4.F3.2.g1" class="ltx_graphics ltx_img_square" width="460" height="478" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x5.png" id="S4.F3.3.g1" class="ltx_graphics ltx_img_square" width="460" height="478" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F3.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="" id="S4.F3.4.g1" class="ltx_graphics ltx_missing ltx_missing_image" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.6.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S4.F3.7.2" class="ltx_text" style="font-size:90%;">Simplified visualization of FL models with two parameters. The left graphic shows that benign and malicious models differ in one or multiple dimensions. On the right, we depict that benign and malicious models can have the same COS metric due to the same angel to the global model.</span></figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">As visualized in the left graphic of <a href="#S4.F3" title="Figure 3 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></span></a>, an adversary conducting a poisoning attack in FL needs to significantly change at least some model parameters of one or many poisoned local models in order to affect the behavior of the new global model. Otherwise, the respective parameter, and, thus, the new global model will align with the benign behaviour of the majority of clients (cf. <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>) after aggregation. Hence, benign trained local models that learn similar behavior will be similarly distributed around the new global model after aggregation, since <span id="S4.SS2.p2.1.1" class="ltx_text">FedAVG</span> decides for the average of all contributions. A malicious model, depicted in red color in <a href="#S4.F3" title="Figure 3 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></span></a>, must be located in a significantly different location than the benign models depicted in green to influence the averaging of <span id="S4.SS2.p2.1.2" class="ltx_text">FedAVG</span>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text">MESAS</span> is based on a set of six <span id="S4.SS2.p3.1.2" class="ltx_text">well-chosen</span> metrics, that are extracted from local models. Technically, extraction of the metrics is a straightforward task that only needs to be conducted once for each local model within each FL round <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">r</annotation></semantics></math>. The metrics can identify malicious models or updates based on different characteristics, like <span id="S4.SS2.p3.1.3" class="ltx_text ltx_font_italic">magnitude</span>, <span id="S4.SS2.p3.1.4" class="ltx_text ltx_font_italic">direction</span>, <span id="S4.SS2.p3.1.5" class="ltx_text ltx_font_italic">orientation</span>, <span id="S4.SS2.p3.1.6" class="ltx_text ltx_font_italic">functionality level</span>, and <span id="S4.SS2.p3.1.7" class="ltx_text ltx_font_italic">outliers</span>, which we will explain in detail in following.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.2" class="ltx_p"><span id="S4.SS2.p4.2.1" class="ltx_text ltx_font_bold">Magnitude and Direction.</span> The two metrics to detect deviations in magnitude and direction of benign and malicious models, which have also been used by other works <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>; Rieger et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>; Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>; Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>; Muñoz-González et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2019</a>)</cite>, are Euclidean distance (EUCL) and Cosine distance (COS) measured between the locally trained models <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><msubsup id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.2.2" xref="S4.SS2.p4.1.m1.1.1.2.2.cmml">L</mi><mi id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">i</mi><mrow id="S4.SS2.p4.1.m1.1.1.2.3" xref="S4.SS2.p4.1.m1.1.1.2.3.cmml"><mi id="S4.SS2.p4.1.m1.1.1.2.3.2" xref="S4.SS2.p4.1.m1.1.1.2.3.2.cmml">r</mi><mo id="S4.SS2.p4.1.m1.1.1.2.3.1" xref="S4.SS2.p4.1.m1.1.1.2.3.1.cmml">+</mo><mn id="S4.SS2.p4.1.m1.1.1.2.3.3" xref="S4.SS2.p4.1.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">subscript</csymbol><apply id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.2.1.cmml" xref="S4.SS2.p4.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2.2">𝐿</ci><apply id="S4.SS2.p4.1.m1.1.1.2.3.cmml" xref="S4.SS2.p4.1.m1.1.1.2.3"><plus id="S4.SS2.p4.1.m1.1.1.2.3.1.cmml" xref="S4.SS2.p4.1.m1.1.1.2.3.1"></plus><ci id="S4.SS2.p4.1.m1.1.1.2.3.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2.3.2">𝑟</ci><cn type="integer" id="S4.SS2.p4.1.m1.1.1.2.3.3.cmml" xref="S4.SS2.p4.1.m1.1.1.2.3.3">1</cn></apply></apply><ci id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">L^{{r+1}}_{i}</annotation></semantics></math> and the original global model of the round <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><msup id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">G</mi><mi id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">𝐺</ci><ci id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">G^{r}</annotation></semantics></math>. These metrics are depicted in <a href="#S4.F4" title="Figure 4 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a>.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.2" class="ltx_p"><span id="S4.SS2.p5.2.1" class="ltx_text ltx_font_bold">Orientation.</span> Two models with the same COS might significantly differ from each other, as depicted in the right graphic of <a href="#S4.F3" title="Figure 3 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></span></a>, as COS alone is insufficient to reflect the direction. Therefore, the orientation of the Cosine from <math id="S4.SS2.p5.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S4.SS2.p5.1.m1.1a"><msup id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml"><mi id="S4.SS2.p5.1.m1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.2.cmml">G</mi><mi id="S4.SS2.p5.1.m1.1.1.3" xref="S4.SS2.p5.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><apply id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p5.1.m1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.2">𝐺</ci><ci id="S4.SS2.p5.1.m1.1.1.3.cmml" xref="S4.SS2.p5.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">G^{r}</annotation></semantics></math> can further differentiate two models. To incorporate this difference into a value, we propose COUNT, a novel metric that counts how many parameter values are increased from the respective parameter of the global model <math id="S4.SS2.p5.2.m2.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S4.SS2.p5.2.m2.1a"><msup id="S4.SS2.p5.2.m2.1.1" xref="S4.SS2.p5.2.m2.1.1.cmml"><mi id="S4.SS2.p5.2.m2.1.1.2" xref="S4.SS2.p5.2.m2.1.1.2.cmml">G</mi><mi id="S4.SS2.p5.2.m2.1.1.3" xref="S4.SS2.p5.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.2.m2.1b"><apply id="S4.SS2.p5.2.m2.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p5.2.m2.1.1.1.cmml" xref="S4.SS2.p5.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p5.2.m2.1.1.2.cmml" xref="S4.SS2.p5.2.m2.1.1.2">𝐺</ci><ci id="S4.SS2.p5.2.m2.1.1.3.cmml" xref="S4.SS2.p5.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.2.m2.1c">G^{r}</annotation></semantics></math> during training. This metric provides a measurement to detect substantially different models, that exhibit inconspicuous similarities in COS. Moreover, the COUNT formula ( cf. <a href="#A5" title="Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></span></a>) incorporates the <span id="S4.SS2.p5.2.2" class="ltx_text ltx_font_italic">sign</span> function, which prevents straightforward adaption by adversaries. Specifically, attempts by adversaries to introduce an extra objective mirroring the COUNT formula into the loss function are rendered ineffective. The reason being that learning algorithms cannot effectively propagate changes to the underlying model parameters through a sign function, given its constant zero gradient. As a result, the utilization of this metric enhances the robustness of the system against adaptive adversaries.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2306.03600/assets/x7.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="156" height="162" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.9.4.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S4.F4.6.3" class="ltx_text" style="font-size:90%;">Visualization of locally trained models <math id="S4.F4.4.1.m1.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="S4.F4.4.1.m1.1b"><msubsup id="S4.F4.4.1.m1.1.1" xref="S4.F4.4.1.m1.1.1.cmml"><mi id="S4.F4.4.1.m1.1.1.2.2" xref="S4.F4.4.1.m1.1.1.2.2.cmml">L</mi><mi id="S4.F4.4.1.m1.1.1.3" xref="S4.F4.4.1.m1.1.1.3.cmml">i</mi><mrow id="S4.F4.4.1.m1.1.1.2.3" xref="S4.F4.4.1.m1.1.1.2.3.cmml"><mi id="S4.F4.4.1.m1.1.1.2.3.2" xref="S4.F4.4.1.m1.1.1.2.3.2.cmml">r</mi><mo id="S4.F4.4.1.m1.1.1.2.3.1" xref="S4.F4.4.1.m1.1.1.2.3.1.cmml">+</mo><mn id="S4.F4.4.1.m1.1.1.2.3.3" xref="S4.F4.4.1.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.F4.4.1.m1.1c"><apply id="S4.F4.4.1.m1.1.1.cmml" xref="S4.F4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F4.4.1.m1.1.1.1.cmml" xref="S4.F4.4.1.m1.1.1">subscript</csymbol><apply id="S4.F4.4.1.m1.1.1.2.cmml" xref="S4.F4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F4.4.1.m1.1.1.2.1.cmml" xref="S4.F4.4.1.m1.1.1">superscript</csymbol><ci id="S4.F4.4.1.m1.1.1.2.2.cmml" xref="S4.F4.4.1.m1.1.1.2.2">𝐿</ci><apply id="S4.F4.4.1.m1.1.1.2.3.cmml" xref="S4.F4.4.1.m1.1.1.2.3"><plus id="S4.F4.4.1.m1.1.1.2.3.1.cmml" xref="S4.F4.4.1.m1.1.1.2.3.1"></plus><ci id="S4.F4.4.1.m1.1.1.2.3.2.cmml" xref="S4.F4.4.1.m1.1.1.2.3.2">𝑟</ci><cn type="integer" id="S4.F4.4.1.m1.1.1.2.3.3.cmml" xref="S4.F4.4.1.m1.1.1.2.3.3">1</cn></apply></apply><ci id="S4.F4.4.1.m1.1.1.3.cmml" xref="S4.F4.4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.1.m1.1d">L^{{r+1}}_{i}</annotation></semantics></math> deviating from the global model <math id="S4.F4.5.2.m2.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S4.F4.5.2.m2.1b"><msup id="S4.F4.5.2.m2.1.1" xref="S4.F4.5.2.m2.1.1.cmml"><mi id="S4.F4.5.2.m2.1.1.2" xref="S4.F4.5.2.m2.1.1.2.cmml">G</mi><mi id="S4.F4.5.2.m2.1.1.3" xref="S4.F4.5.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S4.F4.5.2.m2.1c"><apply id="S4.F4.5.2.m2.1.1.cmml" xref="S4.F4.5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.F4.5.2.m2.1.1.1.cmml" xref="S4.F4.5.2.m2.1.1">superscript</csymbol><ci id="S4.F4.5.2.m2.1.1.2.cmml" xref="S4.F4.5.2.m2.1.1.2">𝐺</ci><ci id="S4.F4.5.2.m2.1.1.3.cmml" xref="S4.F4.5.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.5.2.m2.1d">G^{r}</annotation></semantics></math> in COS and EUCL. The figure also depicts how the angle <math id="S4.F4.6.3.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.F4.6.3.m3.1b"><mi id="S4.F4.6.3.m3.1.1" xref="S4.F4.6.3.m3.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.F4.6.3.m3.1c"><ci id="S4.F4.6.3.m3.1.1.cmml" xref="S4.F4.6.3.m3.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.6.3.m3.1d">\beta</annotation></semantics></math> changes after scaling the update, thus provoking a change in the COS metric of <span id="S4.F4.6.3.1" class="ltx_text">MESAS</span>.</span></figcaption>
</figure>
<div id="S4.SS2.p6" class="ltx_para ltx_noindent">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Functionality Level.</span> Due to the many parameters of a DNN, there can exist models with poisoned behavior, that have metrics COS, EUCL, and COUNT similar to benign models. Such a situation can occur, e.g., if the parameters of a model posses significantly different variance, as visualized in <a href="#S4.F5" title="Figure 5 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></span></a><span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>As highlighted in <a href="#S4.F5" title="Figure 5 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></span></a>, the VAR can be increased, but of course also a significant decrease is possible.</span></span></span>. We leverage this variance as metric (VAR) in <span id="S4.SS2.p6.1.2" class="ltx_text">MESAS</span> and interpret it as functionality level, since a different VAR is a clear indication of divergent model behaviour.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para ltx_noindent">
<p id="S4.SS2.p7.2" class="ltx_p"><span id="S4.SS2.p7.2.1" class="ltx_text ltx_font_bold">Outliers.</span> As with any other variances, VAR is not affected by a few extreme outliers. Therefore, to catch those, we additionally investigate two more novel metrics: MAX and MIN, which extract the maximum/minimum parameter distance between all the parameters of local models <math id="S4.SS2.p7.1.m1.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="S4.SS2.p7.1.m1.1a"><msubsup id="S4.SS2.p7.1.m1.1.1" xref="S4.SS2.p7.1.m1.1.1.cmml"><mi id="S4.SS2.p7.1.m1.1.1.2.2" xref="S4.SS2.p7.1.m1.1.1.2.2.cmml">L</mi><mi id="S4.SS2.p7.1.m1.1.1.3" xref="S4.SS2.p7.1.m1.1.1.3.cmml">i</mi><mrow id="S4.SS2.p7.1.m1.1.1.2.3" xref="S4.SS2.p7.1.m1.1.1.2.3.cmml"><mi id="S4.SS2.p7.1.m1.1.1.2.3.2" xref="S4.SS2.p7.1.m1.1.1.2.3.2.cmml">r</mi><mo id="S4.SS2.p7.1.m1.1.1.2.3.1" xref="S4.SS2.p7.1.m1.1.1.2.3.1.cmml">+</mo><mn id="S4.SS2.p7.1.m1.1.1.2.3.3" xref="S4.SS2.p7.1.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.1.m1.1b"><apply id="S4.SS2.p7.1.m1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.1.m1.1.1.1.cmml" xref="S4.SS2.p7.1.m1.1.1">subscript</csymbol><apply id="S4.SS2.p7.1.m1.1.1.2.cmml" xref="S4.SS2.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.1.m1.1.1.2.1.cmml" xref="S4.SS2.p7.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p7.1.m1.1.1.2.2.cmml" xref="S4.SS2.p7.1.m1.1.1.2.2">𝐿</ci><apply id="S4.SS2.p7.1.m1.1.1.2.3.cmml" xref="S4.SS2.p7.1.m1.1.1.2.3"><plus id="S4.SS2.p7.1.m1.1.1.2.3.1.cmml" xref="S4.SS2.p7.1.m1.1.1.2.3.1"></plus><ci id="S4.SS2.p7.1.m1.1.1.2.3.2.cmml" xref="S4.SS2.p7.1.m1.1.1.2.3.2">𝑟</ci><cn type="integer" id="S4.SS2.p7.1.m1.1.1.2.3.3.cmml" xref="S4.SS2.p7.1.m1.1.1.2.3.3">1</cn></apply></apply><ci id="S4.SS2.p7.1.m1.1.1.3.cmml" xref="S4.SS2.p7.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.1.m1.1c">L^{{r+1}}_{i}</annotation></semantics></math> and a global model <math id="S4.SS2.p7.2.m2.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S4.SS2.p7.2.m2.1a"><msup id="S4.SS2.p7.2.m2.1.1" xref="S4.SS2.p7.2.m2.1.1.cmml"><mi id="S4.SS2.p7.2.m2.1.1.2" xref="S4.SS2.p7.2.m2.1.1.2.cmml">G</mi><mi id="S4.SS2.p7.2.m2.1.1.3" xref="S4.SS2.p7.2.m2.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p7.2.m2.1b"><apply id="S4.SS2.p7.2.m2.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p7.2.m2.1.1.1.cmml" xref="S4.SS2.p7.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p7.2.m2.1.1.2.cmml" xref="S4.SS2.p7.2.m2.1.1.2">𝐺</ci><ci id="S4.SS2.p7.2.m2.1.1.3.cmml" xref="S4.SS2.p7.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p7.2.m2.1c">G^{r}</annotation></semantics></math>.<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We take the minimum distance bigger than zero for MIN by leveraging a nonzero function (<math id="footnote9.m1.1" class="ltx_Math" alttext="nz" display="inline"><semantics id="footnote9.m1.1b"><mrow id="footnote9.m1.1.1" xref="footnote9.m1.1.1.cmml"><mi id="footnote9.m1.1.1.2" xref="footnote9.m1.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="footnote9.m1.1.1.1" xref="footnote9.m1.1.1.1.cmml">​</mo><mi id="footnote9.m1.1.1.3" xref="footnote9.m1.1.1.3.cmml">z</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote9.m1.1c"><apply id="footnote9.m1.1.1.cmml" xref="footnote9.m1.1.1"><times id="footnote9.m1.1.1.1.cmml" xref="footnote9.m1.1.1.1"></times><ci id="footnote9.m1.1.1.2.cmml" xref="footnote9.m1.1.1.2">𝑛</ci><ci id="footnote9.m1.1.1.3.cmml" xref="footnote9.m1.1.1.3">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote9.m1.1d">nz</annotation></semantics></math>) Thus, MIN analyzes real model changes and ignores parameters that have not been changed.</span></span></span>. VAR combined with MAX and MIN provide a reliable metric for the functionality level and allow testing for poisoned models. Similarly to the COUNT metric, the outlier metrics significantly enhance the system’s resilience against adaptive adversaries. Specifically, the formulas for MIN and MAX ( cf. <a href="#A5" title="Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></span></a>) can be incorporated as supplementary objectives in the loss function. However, it is noteworthy that the resulting changes are confined to the parameter responsible for reflecting the particular metric value. Consequently, other components within the model may undergo escalation in the metric while the actual outlier gets adjusted. This strategic attribute compels adversaries to employ additional measures, such as applying clipping mechanisms after model training is finished, to adjust remaining outliers in MIN and MAX to mount stealthy attacks.</p>
</div>
<div id="S4.SS2.p8" class="ltx_para ltx_noindent">
<p id="S4.SS2.p8.1" class="ltx_p"><span id="S4.SS2.p8.1.1" class="ltx_text ltx_font_bold">Interrelations between metrics.</span> The selection of the aforementioned metrics was based on their inherent interrelations. For an adaptive adversary attempting to adjust to the EUCL metric, success can be achieved through scaling or introducing additional objectives in the loss function. Both these approaches are likely to influence the COS metric. However, if the adversary adapts to the COS metric, they might exploit a stealthy situation as depicted in the right graph of <a href="#S4.F3" title="Figure 3 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></span></a>. Nevertheless, such a scenario would have an instant impact on the COUNT metric. Furthermore, malicious behavior could be introduced by manipulating the variance of the model parameters, while remaining inconspicuous in terms of EUCL, COS, and COUNT metrics. However, the VAR metric would be capable of detecting such a situation. Further, a seemingly benign VAR constructed by employing extreme outliers, as visualized in the right graph of <a href="#S4.F5" title="Figure 5 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></span></a>, would immediately generate abnormal values in MIN or MAX metrics. Due to the specific properties of certain metrics, namely COUNT, MAX, and MIN, which are non-trivial to adapt with additional objective functions<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>We discuss this in the respective metric sections above.</span></span></span>, <span id="S4.SS2.p8.1.2" class="ltx_text">MESAS</span> effectively counteracts adaptive attacks.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x8.png" id="S4.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="329" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x9.png" id="S4.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="329" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x10.png" id="S4.F5.3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="329" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.5.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>. </span><span id="S4.F5.6.2" class="ltx_text" style="font-size:90%;">Simplified visualization of FL models with multiple parameters highlighting the functionality level based on the parameter value variance. The left shows a benign situation and the middle a poisoned model can have a bigger (or smaller) level. The figure on the right depicts,that the variance is not affected by maxima (and minima).</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Pruning Loop</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The filtering process consists of three steps: <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">statistical tests</span>, <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">clustering</span>, and <span id="S4.SS3.p1.1.3" class="ltx_text ltx_font_italic">pruning</span> (2-4 in <a href="#S3.F2" title="Figure 2 ‣ 3.2. Inter-Client Non-IID ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>). In every filtering round, each metric traverses the procedure independently. After each round, the models filtered based on any metric are excluded from the next round. This iterative pruning loop continues until the statistical tests do not report any significance for the presence of a poisoning attack anymore. Due to the iterative nature of this filtering procedure and the individual analysis of each metric, different types of poisoning attacks can be filtered within one run of <span id="S4.SS3.p1.1.4" class="ltx_text">MESAS</span>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.5" class="ltx_p"><span id="S4.SS3.p2.5.1" class="ltx_text ltx_font_bold">Statistical Tests.</span> When provided with a set of metric values, which always contain one value per local model, the statistical tests first extract the median value, which is considered as benign due to the majority assumption (cf. <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>). Afterwards, multiple statistical tests are conducted to check if all metric values are distributed equally around the median value, as one would expect from benign models. Therefore, <span id="S4.SS3.p2.5.2" class="ltx_text">MESAS</span> checks if the metric values with bigger values than the median and the metric values with smaller values as the median follow the same distribution. For that purpose, the bigger and smaller metric values are converted to two lists <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">l</mi><mn id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">l_{1}</annotation></semantics></math> and <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><msub id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">l</mi><mn id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">𝑙</ci><cn type="integer" id="S4.SS3.p2.2.m2.1.1.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">l_{2}</annotation></semantics></math> containing the absolute distance from the value to the median, as shown in <a href="#S4.F6" title="Figure 6 ‣ 4.3. Pruning Loop ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></span></a>. Then the two lists pass through the tests. At first, a T-Test <cite class="ltx_cite ltx_citemacro_citep">(Livingston, <a href="#bib.bib56" title="" class="ltx_ref">2004</a>)</cite> (ST-T) is conducted to check for equal means. Since two distributions can have the same mean but different variances, a Levene’s test <cite class="ltx_cite ltx_citemacro_citep">(Lim and Loh, <a href="#bib.bib51" title="" class="ltx_ref">1996</a>)</cite> (ST-V) is appended. Finally, a <span id="S4.SS3.p2.5.3" class="ltx_text">Kolmogorow-Smirnow-Test</span> <cite class="ltx_cite ltx_citemacro_citep">(Massey Jr, <a href="#bib.bib57" title="" class="ltx_ref">1951</a>)</cite> (ST-D) for equal distributions is leveraged. Following the same reasoning we provided for the metrics VAR and MAX, the aforementioned tests are not significantly influenced by outliers. Therefore, we additionally analyze the original metric values regarding the 3<math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mi id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><ci id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\sigma</annotation></semantics></math> rule <cite class="ltx_cite ltx_citemacro_citep">(Pukelsheim, <a href="#bib.bib76" title="" class="ltx_ref">1994</a>)</cite> (ST-<math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="3\sigma" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mn id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p2.4.m4.1.1.1" xref="S4.SS3.p2.4.m4.1.1.1.cmml">​</mo><mi id="S4.SS3.p2.4.m4.1.1.3" xref="S4.SS3.p2.4.m4.1.1.3.cmml">σ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><times id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1.1"></times><cn type="integer" id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2">3</cn><ci id="S4.SS3.p2.4.m4.1.1.3.cmml" xref="S4.SS3.p2.4.m4.1.1.3">𝜎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">3\sigma</annotation></semantics></math>). Values outside the 3<math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mi id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><ci id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">\sigma</annotation></semantics></math> interval are marked as significant outliers.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.2" class="ltx_p">In <a href="#S4.F6" title="Figure 6 ‣ 4.3. Pruning Loop ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></span></a>, the metric values of benign and malicious models are listed. The mean of all metric values (dark blue) is used to separate the values into two lists <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><msub id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mi id="S4.SS3.p3.1.m1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.2.cmml">l</mi><mn id="S4.SS3.p3.1.m1.1.1.3" xref="S4.SS3.p3.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.1.m1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p3.1.m1.1.1.2.cmml" xref="S4.SS3.p3.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S4.SS3.p3.1.m1.1.1.3.cmml" xref="S4.SS3.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">l_{1}</annotation></semantics></math> and <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><msub id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mi id="S4.SS3.p3.2.m2.1.1.2" xref="S4.SS3.p3.2.m2.1.1.2.cmml">l</mi><mn id="S4.SS3.p3.2.m2.1.1.3" xref="S4.SS3.p3.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p3.2.m2.1.1.2.cmml" xref="S4.SS3.p3.2.m2.1.1.2">𝑙</ci><cn type="integer" id="S4.SS3.p3.2.m2.1.1.3.cmml" xref="S4.SS3.p3.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">l_{2}</annotation></semantics></math>. Those lists represent the benign and malicious models, respectively, and are graphically observable by the lines between the metric values and the median. Note, that the median of the benign values (light blue) and the median of the malicious values (purple) have a significantly different distance to the median, which results in a highly significant result in ST-T. ST-T, ST-V, and ST-D deliver a p-value<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>A p-value indicates how likely it is that the underlying data could have occurred under a null hypothesis. In our case, the null hypothesis is, that the two lists contain samples from equal distributions, thus having equal mean and variance.</span></span></span>, which is also called significance level and is used to determine if a poisoned model is found.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para ltx_noindent">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">Clustering and Pruning</span> After a significant statistical test (step 2 in <a href="#S3.F2" title="Figure 2 ‣ 3.2. Inter-Client Non-IID ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>), <span id="S4.SS3.p4.1.2" class="ltx_text">MESAS</span> leverages Agglomerative Clustering <cite class="ltx_cite ltx_citemacro_citep">(Nielsen, <a href="#bib.bib71" title="" class="ltx_ref">2016</a>)</cite> with two fixed clusters based on the Euclidean distance to cluster the significant metric values (step 3 in <a href="#S3.F2" title="Figure 2 ‣ 3.2. Inter-Client Non-IID ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>). Afterwards, the local models behind the metric values within the bigger cluster are considered as benign based on the majority assumption and the other models are marked as malicious and excluded by the pruning step of <span id="S4.SS3.p4.1.3" class="ltx_text">MESAS</span> (step 4 in <a href="#S3.F2" title="Figure 2 ‣ 3.2. Inter-Client Non-IID ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>).</p>
</div>
<div id="S4.SS3.p5" class="ltx_para ltx_noindent">
<p id="S4.SS3.p5.1" class="ltx_p">Overall, <span id="S4.SS3.p5.1.1" class="ltx_text">MESAS</span> is robust against sophisticated poisoning attacks through an <span id="S4.SS3.p5.1.2" class="ltx_text">in-depth</span> analysis of model weights using six interdependent metrics. As a result, if a strong adaptive adversary attempts to circumvent one metric, the artifacts of the poisoning attack will inevitably manifest through one of the other metrics. Further, <span id="S4.SS3.p5.1.3" class="ltx_text">MESAS</span> adapts to the application domain including complicated <span id="S4.SS3.p5.1.4" class="ltx_text">non-IID</span> data scenarios by leveraging statistical tests, instead of relying on hard thresholds. We provide the formulas of the metrics and additional information about <span id="S4.SS3.p5.1.5" class="ltx_text">MESAS</span> in <a href="#A5" title="Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></span></a>.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2306.03600/assets/x11.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="151" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.6.3.1" class="ltx_text" style="font-size:90%;">Figure 6</span>. </span><span id="S4.F6.4.2" class="ltx_text" style="font-size:90%;">Depiction of a statistical test setup with significant p-value in ST-T indicating a varying mean between <math id="S4.F6.3.1.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="S4.F6.3.1.m1.1b"><msub id="S4.F6.3.1.m1.1.1" xref="S4.F6.3.1.m1.1.1.cmml"><mi id="S4.F6.3.1.m1.1.1.2" xref="S4.F6.3.1.m1.1.1.2.cmml">l</mi><mn id="S4.F6.3.1.m1.1.1.3" xref="S4.F6.3.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F6.3.1.m1.1c"><apply id="S4.F6.3.1.m1.1.1.cmml" xref="S4.F6.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F6.3.1.m1.1.1.1.cmml" xref="S4.F6.3.1.m1.1.1">subscript</csymbol><ci id="S4.F6.3.1.m1.1.1.2.cmml" xref="S4.F6.3.1.m1.1.1.2">𝑙</ci><cn type="integer" id="S4.F6.3.1.m1.1.1.3.cmml" xref="S4.F6.3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.3.1.m1.1d">l_{1}</annotation></semantics></math> and <math id="S4.F6.4.2.m2.1" class="ltx_Math" alttext="l_{2}" display="inline"><semantics id="S4.F6.4.2.m2.1b"><msub id="S4.F6.4.2.m2.1.1" xref="S4.F6.4.2.m2.1.1.cmml"><mi id="S4.F6.4.2.m2.1.1.2" xref="S4.F6.4.2.m2.1.1.2.cmml">l</mi><mn id="S4.F6.4.2.m2.1.1.3" xref="S4.F6.4.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.F6.4.2.m2.1c"><apply id="S4.F6.4.2.m2.1.1.cmml" xref="S4.F6.4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.F6.4.2.m2.1.1.1.cmml" xref="S4.F6.4.2.m2.1.1">subscript</csymbol><ci id="S4.F6.4.2.m2.1.1.2.cmml" xref="S4.F6.4.2.m2.1.1.2">𝑙</ci><cn type="integer" id="S4.F6.4.2.m2.1.1.3.cmml" xref="S4.F6.4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.4.2.m2.1d">l_{2}</annotation></semantics></math>.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Evaluation</h2>

<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.14.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S5.T1.15.2" class="ltx_text" style="font-size:90%;">MAs and BAs in different scenarios in percent.</span></figcaption>
<table id="S5.T1.12" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.12.13" class="ltx_tr">
<td id="S5.T1.12.13.1" class="ltx_td ltx_border_r" colspan="2"></td>
<td id="S5.T1.12.13.2" class="ltx_td ltx_align_center" colspan="12">Scenario</td>
</tr>
<tr id="S5.T1.5.5" class="ltx_tr">
<td id="S5.T1.5.5.6" class="ltx_td ltx_border_r" colspan="2"></td>
<td id="S5.T1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Default</td>
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><svg id="S5.T1.1.1.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.1.1.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>
</td>
<td id="S5.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><svg id="S5.T1.2.2.2.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.2.2.2.pic1.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg>
</td>
<td id="S5.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><svg id="S5.T1.3.3.3.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.3.3.3.pic1.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg>
</td>
<td id="S5.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><svg id="S5.T1.4.4.4.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.4.4.4.pic1.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg>
</td>
<td id="S5.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><svg id="S5.T1.5.5.5.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.5.5.5.pic1.1.1.1.1.1" class="ltx_text">5</span></foreignObject></g></g></svg>
</td>
</tr>
<tr id="S5.T1.12.14" class="ltx_tr">
<td id="S5.T1.12.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="S5.T1.12.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="S5.T1.12.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">BA</td>
<td id="S5.T1.12.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="S5.T1.12.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">BA</td>
<td id="S5.T1.12.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="S5.T1.12.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">BA</td>
<td id="S5.T1.12.14.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="S5.T1.12.14.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">BA</td>
<td id="S5.T1.12.14.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="S5.T1.12.14.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">BA</td>
<td id="S5.T1.12.14.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="S5.T1.12.14.13" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="S5.T1.6.6" class="ltx_tr">
<td id="S5.T1.6.6.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="S5.T1.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="S5.T1.6.6.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S5.T1.6.6.1.m1.1a"><msup id="S5.T1.6.6.1.m1.1.1" xref="S5.T1.6.6.1.m1.1.1.cmml"><mi id="S5.T1.6.6.1.m1.1.1.2" xref="S5.T1.6.6.1.m1.1.1.2.cmml">G</mi><mi id="S5.T1.6.6.1.m1.1.1.3" xref="S5.T1.6.6.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.1.m1.1b"><apply id="S5.T1.6.6.1.m1.1.1.cmml" xref="S5.T1.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.6.6.1.m1.1.1.1.cmml" xref="S5.T1.6.6.1.m1.1.1">superscript</csymbol><ci id="S5.T1.6.6.1.m1.1.1.2.cmml" xref="S5.T1.6.6.1.m1.1.1.2">𝐺</ci><ci id="S5.T1.6.6.1.m1.1.1.3.cmml" xref="S5.T1.6.6.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="S5.T1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="S5.T1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.90</td>
<td id="S5.T1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="S5.T1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.90</td>
<td id="S5.T1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="S5.T1.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.90</td>
<td id="S5.T1.6.6.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="S5.T1.6.6.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.90</td>
<td id="S5.T1.6.6.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="S5.T1.6.6.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.93</td>
<td id="S5.T1.6.6.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.51</td>
<td id="S5.T1.6.6.14" class="ltx_td ltx_align_center ltx_border_t">5.18</td>
</tr>
<tr id="S5.T1.12.15" class="ltx_tr">
<td id="S5.T1.12.15.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="S5.T1.12.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="S5.T1.12.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="S5.T1.12.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.56</td>
<td id="S5.T1.12.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="S5.T1.12.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.56</td>
<td id="S5.T1.12.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="S5.T1.12.15.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.56</td>
<td id="S5.T1.12.15.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="S5.T1.12.15.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.56</td>
<td id="S5.T1.12.15.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.15</td>
<td id="S5.T1.12.15.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.82</td>
<td id="S5.T1.12.15.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.15</td>
<td id="S5.T1.12.15.14" class="ltx_td ltx_align_center ltx_border_t">10.42</td>
</tr>
<tr id="S5.T1.12.16" class="ltx_tr">
<td id="S5.T1.12.16.1" class="ltx_td ltx_align_left">3:</td>
<td id="S5.T1.12.16.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="S5.T1.12.16.3" class="ltx_td ltx_align_center ltx_border_r">57.84</td>
<td id="S5.T1.12.16.4" class="ltx_td ltx_align_center ltx_border_r">85.13</td>
<td id="S5.T1.12.16.5" class="ltx_td ltx_align_center ltx_border_r">54.58</td>
<td id="S5.T1.12.16.6" class="ltx_td ltx_align_center ltx_border_r">93.15</td>
<td id="S5.T1.12.16.7" class="ltx_td ltx_align_center ltx_border_r">54.42</td>
<td id="S5.T1.12.16.8" class="ltx_td ltx_align_center ltx_border_r">93.25</td>
<td id="S5.T1.12.16.9" class="ltx_td ltx_align_center ltx_border_r">51.23</td>
<td id="S5.T1.12.16.10" class="ltx_td ltx_align_center ltx_border_r">89.82</td>
<td id="S5.T1.12.16.11" class="ltx_td ltx_align_center ltx_border_r">43.74</td>
<td id="S5.T1.12.16.12" class="ltx_td ltx_align_center ltx_border_r">91.32</td>
<td id="S5.T1.12.16.13" class="ltx_td ltx_align_center ltx_border_r">33.93</td>
<td id="S5.T1.12.16.14" class="ltx_td ltx_align_center">82.00</td>
</tr>
<tr id="S5.T1.12.17" class="ltx_tr">
<td id="S5.T1.12.17.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="S5.T1.12.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T1.12.17.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="S5.T1.12.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="S5.T1.12.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.85</td>
<td id="S5.T1.12.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="S5.T1.12.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.85</td>
<td id="S5.T1.12.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="S5.T1.12.17.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.85</td>
<td id="S5.T1.12.17.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="S5.T1.12.17.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.85</td>
<td id="S5.T1.12.17.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="S5.T1.12.17.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.40</td>
<td id="S5.T1.12.17.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.45</td>
<td id="S5.T1.12.17.14" class="ltx_td ltx_align_center ltx_border_t">12.71</td>
</tr>
<tr id="S5.T1.12.18" class="ltx_tr">
<td id="S5.T1.12.18.1" class="ltx_td ltx_align_left">5:</td>
<td id="S5.T1.12.18.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T1.12.18.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="S5.T1.12.18.3" class="ltx_td ltx_align_center ltx_border_r">64.92</td>
<td id="S5.T1.12.18.4" class="ltx_td ltx_align_center ltx_border_r">83.00</td>
<td id="S5.T1.12.18.5" class="ltx_td ltx_align_center ltx_border_r">63.68</td>
<td id="S5.T1.12.18.6" class="ltx_td ltx_align_center ltx_border_r">92.50</td>
<td id="S5.T1.12.18.7" class="ltx_td ltx_align_center ltx_border_r">62.29</td>
<td id="S5.T1.12.18.8" class="ltx_td ltx_align_center ltx_border_r">93.71</td>
<td id="S5.T1.12.18.9" class="ltx_td ltx_align_center ltx_border_r">40.69</td>
<td id="S5.T1.12.18.10" class="ltx_td ltx_align_center ltx_border_r">93.54</td>
<td id="S5.T1.12.18.11" class="ltx_td ltx_align_center ltx_border_r">59.12</td>
<td id="S5.T1.12.18.12" class="ltx_td ltx_align_center ltx_border_r">95.50</td>
<td id="S5.T1.12.18.13" class="ltx_td ltx_align_center ltx_border_r">29.35</td>
<td id="S5.T1.12.18.14" class="ltx_td ltx_align_center">88.96</td>
</tr>
<tr id="S5.T1.12.19" class="ltx_tr">
<td id="S5.T1.12.19.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="S5.T1.12.19.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T1.12.19.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="S5.T1.12.19.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.81</td>
<td id="S5.T1.12.19.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">42.94</td>
<td id="S5.T1.12.19.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.85</td>
<td id="S5.T1.12.19.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T1.12.19.6.1" class="ltx_text ltx_font_bold">61.96</span></td>
<td id="S5.T1.12.19.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.27</td>
<td id="S5.T1.12.19.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.54</td>
<td id="S5.T1.12.19.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.18</td>
<td id="S5.T1.12.19.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.74</td>
<td id="S5.T1.12.19.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.02</td>
<td id="S5.T1.12.19.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.66</td>
<td id="S5.T1.12.19.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">38.72</td>
<td id="S5.T1.12.19.14" class="ltx_td ltx_align_center ltx_border_t">77.37</td>
</tr>
<tr id="S5.T1.12.20" class="ltx_tr">
<td id="S5.T1.12.20.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="S5.T1.12.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="S5.T1.12.20.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">BA</td>
<td id="S5.T1.12.20.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="S5.T1.12.20.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">BA</td>
<td id="S5.T1.12.20.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="S5.T1.12.20.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">BA</td>
<td id="S5.T1.12.20.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="S5.T1.12.20.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">BA</td>
<td id="S5.T1.12.20.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="S5.T1.12.20.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">BA</td>
<td id="S5.T1.12.20.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="S5.T1.12.20.13" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="S5.T1.12.21" class="ltx_tr">
<td id="S5.T1.12.21.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="S5.T1.12.21.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="S5.T1.12.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.06</td>
<td id="S5.T1.12.21.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.62</td>
<td id="S5.T1.12.21.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.75</td>
<td id="S5.T1.12.21.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.86</td>
<td id="S5.T1.12.21.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.73</td>
<td id="S5.T1.12.21.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.36</td>
<td id="S5.T1.12.21.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.34</td>
<td id="S5.T1.12.21.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.58</td>
<td id="S5.T1.12.21.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.12</td>
<td id="S5.T1.12.21.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.58</td>
<td id="S5.T1.12.21.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.85</td>
<td id="S5.T1.12.21.14" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.12.21.14.1" class="ltx_text ltx_font_bold">85.32</span></td>
</tr>
<tr id="S5.T1.12.22" class="ltx_tr">
<td id="S5.T1.12.22.1" class="ltx_td ltx_align_left">8:</td>
<td id="S5.T1.12.22.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S5.T1.12.22.3" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="S5.T1.12.22.4" class="ltx_td ltx_align_center ltx_border_r">1.85</td>
<td id="S5.T1.12.22.5" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="S5.T1.12.22.6" class="ltx_td ltx_align_center ltx_border_r">1.85</td>
<td id="S5.T1.12.22.7" class="ltx_td ltx_align_center ltx_border_r">63.27</td>
<td id="S5.T1.12.22.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.22.8.1" class="ltx_text ltx_font_bold">63.54</span></td>
<td id="S5.T1.12.22.9" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="S5.T1.12.22.10" class="ltx_td ltx_align_center ltx_border_r">1.85</td>
<td id="S5.T1.12.22.11" class="ltx_td ltx_align_center ltx_border_r">56.80</td>
<td id="S5.T1.12.22.12" class="ltx_td ltx_align_center ltx_border_r">47.0</td>
<td id="S5.T1.12.22.13" class="ltx_td ltx_align_center ltx_border_r">37.00</td>
<td id="S5.T1.12.22.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.22.14.1" class="ltx_text ltx_font_bold">76.03</span></td>
</tr>
<tr id="S5.T1.12.23" class="ltx_tr">
<td id="S5.T1.12.23.1" class="ltx_td ltx_align_left">9:</td>
<td id="S5.T1.12.23.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="S5.T1.12.23.3" class="ltx_td ltx_align_center ltx_border_r">59.75</td>
<td id="S5.T1.12.23.4" class="ltx_td ltx_align_center ltx_border_r">83.53</td>
<td id="S5.T1.12.23.5" class="ltx_td ltx_align_center ltx_border_r">52.22</td>
<td id="S5.T1.12.23.6" class="ltx_td ltx_align_center ltx_border_r">95.97</td>
<td id="S5.T1.12.23.7" class="ltx_td ltx_align_center ltx_border_r">56.18</td>
<td id="S5.T1.12.23.8" class="ltx_td ltx_align_center ltx_border_r">93.14</td>
<td id="S5.T1.12.23.9" class="ltx_td ltx_align_center ltx_border_r">52.00</td>
<td id="S5.T1.12.23.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.23.10.1" class="ltx_text ltx_font_bold">89.90</span></td>
<td id="S5.T1.12.23.11" class="ltx_td ltx_align_center ltx_border_r">49.88</td>
<td id="S5.T1.12.23.12" class="ltx_td ltx_align_center ltx_border_r">5.27</td>
<td id="S5.T1.12.23.13" class="ltx_td ltx_align_center ltx_border_r">16.88</td>
<td id="S5.T1.12.23.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.23.14.1" class="ltx_text ltx_font_bold">89.07</span></td>
</tr>
<tr id="S5.T1.12.24" class="ltx_tr">
<td id="S5.T1.12.24.1" class="ltx_td ltx_align_left">10:</td>
<td id="S5.T1.12.24.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T1.12.24.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="S5.T1.12.24.3" class="ltx_td ltx_align_center ltx_border_r">64.18</td>
<td id="S5.T1.12.24.4" class="ltx_td ltx_align_center ltx_border_r">83.05</td>
<td id="S5.T1.12.24.5" class="ltx_td ltx_align_center ltx_border_r">63.90</td>
<td id="S5.T1.12.24.6" class="ltx_td ltx_align_center ltx_border_r">92.72</td>
<td id="S5.T1.12.24.7" class="ltx_td ltx_align_center ltx_border_r">62.01</td>
<td id="S5.T1.12.24.8" class="ltx_td ltx_align_center ltx_border_r">93.83</td>
<td id="S5.T1.12.24.9" class="ltx_td ltx_align_center ltx_border_r">41.86</td>
<td id="S5.T1.12.24.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.24.10.1" class="ltx_text ltx_font_bold">95.80</span></td>
<td id="S5.T1.12.24.11" class="ltx_td ltx_align_center ltx_border_r">62.39</td>
<td id="S5.T1.12.24.12" class="ltx_td ltx_align_center ltx_border_r">13.11</td>
<td id="S5.T1.12.24.13" class="ltx_td ltx_align_center ltx_border_r">18.07</td>
<td id="S5.T1.12.24.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.24.14.1" class="ltx_text ltx_font_bold">89.55</span></td>
</tr>
<tr id="S5.T1.12.25" class="ltx_tr">
<td id="S5.T1.12.25.1" class="ltx_td ltx_align_left">11:</td>
<td id="S5.T1.12.25.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T1.12.25.3" class="ltx_td ltx_align_center ltx_border_r">63.80</td>
<td id="S5.T1.12.25.4" class="ltx_td ltx_align_center ltx_border_r">42.81</td>
<td id="S5.T1.12.25.5" class="ltx_td ltx_align_center ltx_border_r">63.85</td>
<td id="S5.T1.12.25.6" class="ltx_td ltx_align_center ltx_border_r">61.86</td>
<td id="S5.T1.12.25.7" class="ltx_td ltx_align_center ltx_border_r">63.26</td>
<td id="S5.T1.12.25.8" class="ltx_td ltx_align_center ltx_border_r">63.52</td>
<td id="S5.T1.12.25.9" class="ltx_td ltx_align_center ltx_border_r">49.19</td>
<td id="S5.T1.12.25.10" class="ltx_td ltx_align_center ltx_border_r">83.74</td>
<td id="S5.T1.12.25.11" class="ltx_td ltx_align_center ltx_border_r">63.92</td>
<td id="S5.T1.12.25.12" class="ltx_td ltx_align_center ltx_border_r">62.28</td>
<td id="S5.T1.12.25.13" class="ltx_td ltx_align_center ltx_border_r">37.76</td>
<td id="S5.T1.12.25.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.25.14.1" class="ltx_text ltx_font_bold">75.60</span></td>
</tr>
<tr id="S5.T1.12.26" class="ltx_tr">
<td id="S5.T1.12.26.1" class="ltx_td ltx_align_left">12:</td>
<td id="S5.T1.12.26.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T1.12.26.3" class="ltx_td ltx_align_center ltx_border_r">50.78</td>
<td id="S5.T1.12.26.4" class="ltx_td ltx_align_center ltx_border_r">60.66</td>
<td id="S5.T1.12.26.5" class="ltx_td ltx_align_center ltx_border_r">52.10</td>
<td id="S5.T1.12.26.6" class="ltx_td ltx_align_center ltx_border_r">77.21</td>
<td id="S5.T1.12.26.7" class="ltx_td ltx_align_center ltx_border_r">59.32</td>
<td id="S5.T1.12.26.8" class="ltx_td ltx_align_center ltx_border_r">75.67</td>
<td id="S5.T1.12.26.9" class="ltx_td ltx_align_center ltx_border_r">41.47</td>
<td id="S5.T1.12.26.10" class="ltx_td ltx_align_center ltx_border_r">90.37</td>
<td id="S5.T1.12.26.11" class="ltx_td ltx_align_center ltx_border_r">56.28</td>
<td id="S5.T1.12.26.12" class="ltx_td ltx_align_center ltx_border_r">71.99</td>
<td id="S5.T1.12.26.13" class="ltx_td ltx_align_center ltx_border_r">23.70</td>
<td id="S5.T1.12.26.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.26.14.1" class="ltx_text ltx_font_bold">64.32</span></td>
</tr>
<tr id="S5.T1.12.27" class="ltx_tr">
<td id="S5.T1.12.27.1" class="ltx_td ltx_align_left">13:</td>
<td id="S5.T1.12.27.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="S5.T1.12.27.3" class="ltx_td ltx_align_center ltx_border_r">60.96</td>
<td id="S5.T1.12.27.4" class="ltx_td ltx_align_center ltx_border_r">79.17</td>
<td id="S5.T1.12.27.5" class="ltx_td ltx_align_center ltx_border_r">63.67</td>
<td id="S5.T1.12.27.6" class="ltx_td ltx_align_center ltx_border_r">88.44</td>
<td id="S5.T1.12.27.7" class="ltx_td ltx_align_center ltx_border_r">62.21</td>
<td id="S5.T1.12.27.8" class="ltx_td ltx_align_center ltx_border_r">88.80</td>
<td id="S5.T1.12.27.9" class="ltx_td ltx_align_center ltx_border_r">44.56</td>
<td id="S5.T1.12.27.10" class="ltx_td ltx_align_center ltx_border_r">84.53</td>
<td id="S5.T1.12.27.11" class="ltx_td ltx_align_center ltx_border_r">56.59</td>
<td id="S5.T1.12.27.12" class="ltx_td ltx_align_center ltx_border_r">50.34</td>
<td id="S5.T1.12.27.13" class="ltx_td ltx_align_center ltx_border_r">25.10</td>
<td id="S5.T1.12.27.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.27.14.1" class="ltx_text ltx_font_bold">79.17</span></td>
</tr>
<tr id="S5.T1.12.28" class="ltx_tr">
<td id="S5.T1.12.28.1" class="ltx_td ltx_align_left">14:</td>
<td id="S5.T1.12.28.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T1.12.28.3" class="ltx_td ltx_align_center ltx_border_r">63.51</td>
<td id="S5.T1.12.28.4" class="ltx_td ltx_align_center ltx_border_r">44.13</td>
<td id="S5.T1.12.28.5" class="ltx_td ltx_align_center ltx_border_r">63.54</td>
<td id="S5.T1.12.28.6" class="ltx_td ltx_align_center ltx_border_r">63.98</td>
<td id="S5.T1.12.28.7" class="ltx_td ltx_align_center ltx_border_r">62.86</td>
<td id="S5.T1.12.28.8" class="ltx_td ltx_align_center ltx_border_r">65.35</td>
<td id="S5.T1.12.28.9" class="ltx_td ltx_align_center ltx_border_r">51.07</td>
<td id="S5.T1.12.28.10" class="ltx_td ltx_align_center ltx_border_r">85.75</td>
<td id="S5.T1.12.28.11" class="ltx_td ltx_align_center ltx_border_r">63.15</td>
<td id="S5.T1.12.28.12" class="ltx_td ltx_align_center ltx_border_r">67.01</td>
<td id="S5.T1.12.28.13" class="ltx_td ltx_align_center ltx_border_r">39.98</td>
<td id="S5.T1.12.28.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.28.14.1" class="ltx_text ltx_font_bold">76.36</span></td>
</tr>
<tr id="S5.T1.12.29" class="ltx_tr">
<td id="S5.T1.12.29.1" class="ltx_td ltx_align_left">15:</td>
<td id="S5.T1.12.29.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T1.12.29.3" class="ltx_td ltx_align_center ltx_border_r">51.22</td>
<td id="S5.T1.12.29.4" class="ltx_td ltx_align_center ltx_border_r">44.60</td>
<td id="S5.T1.12.29.5" class="ltx_td ltx_align_center ltx_border_r">51.18</td>
<td id="S5.T1.12.29.6" class="ltx_td ltx_align_center ltx_border_r">57.73</td>
<td id="S5.T1.12.29.7" class="ltx_td ltx_align_center ltx_border_r">49.61</td>
<td id="S5.T1.12.29.8" class="ltx_td ltx_align_center ltx_border_r">60.30</td>
<td id="S5.T1.12.29.9" class="ltx_td ltx_align_center ltx_border_r">39.76</td>
<td id="S5.T1.12.29.10" class="ltx_td ltx_align_center ltx_border_r">74.76</td>
<td id="S5.T1.12.29.11" class="ltx_td ltx_align_center ltx_border_r">51.75</td>
<td id="S5.T1.12.29.12" class="ltx_td ltx_align_center ltx_border_r">68.20</td>
<td id="S5.T1.12.29.13" class="ltx_td ltx_align_center ltx_border_r">17.04</td>
<td id="S5.T1.12.29.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.29.14.1" class="ltx_text ltx_font_bold">52.75</span></td>
</tr>
<tr id="S5.T1.12.30" class="ltx_tr">
<td id="S5.T1.12.30.1" class="ltx_td ltx_align_left">16:</td>
<td id="S5.T1.12.30.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S5.T1.12.30.3" class="ltx_td ltx_align_center ltx_border_r">63.49</td>
<td id="S5.T1.12.30.4" class="ltx_td ltx_align_center ltx_border_r">23.08</td>
<td id="S5.T1.12.30.5" class="ltx_td ltx_align_center ltx_border_r">63.76</td>
<td id="S5.T1.12.30.6" class="ltx_td ltx_align_center ltx_border_r">49.68</td>
<td id="S5.T1.12.30.7" class="ltx_td ltx_align_center ltx_border_r">63.17</td>
<td id="S5.T1.12.30.8" class="ltx_td ltx_align_center ltx_border_r">45.54</td>
<td id="S5.T1.12.30.9" class="ltx_td ltx_align_center ltx_border_r">55.15</td>
<td id="S5.T1.12.30.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.30.10.1" class="ltx_text ltx_font_bold">74.71</span></td>
<td id="S5.T1.12.30.11" class="ltx_td ltx_align_center ltx_border_r">63.56</td>
<td id="S5.T1.12.30.12" class="ltx_td ltx_align_center ltx_border_r">8.40</td>
<td id="S5.T1.12.30.13" class="ltx_td ltx_align_center ltx_border_r">26.81</td>
<td id="S5.T1.12.30.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.30.14.1" class="ltx_text ltx_font_bold">81.61</span></td>
</tr>
<tr id="S5.T1.12.31" class="ltx_tr">
<td id="S5.T1.12.31.1" class="ltx_td ltx_align_left">17:</td>
<td id="S5.T1.12.31.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.31.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="S5.T1.12.31.3" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="S5.T1.12.31.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.31.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
<td id="S5.T1.12.31.5" class="ltx_td ltx_align_center ltx_border_r">63.36</td>
<td id="S5.T1.12.31.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.31.6.1" class="ltx_text ltx_font_bold">1.95</span></td>
<td id="S5.T1.12.31.7" class="ltx_td ltx_align_center ltx_border_r">63.36</td>
<td id="S5.T1.12.31.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.31.8.1" class="ltx_text ltx_font_bold">1.95</span></td>
<td id="S5.T1.12.31.9" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="S5.T1.12.31.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.31.10.1" class="ltx_text ltx_font_bold">1.85</span></td>
<td id="S5.T1.12.31.11" class="ltx_td ltx_align_center ltx_border_r">65.92</td>
<td id="S5.T1.12.31.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T1.12.31.12.1" class="ltx_text ltx_font_bold">1.40</span></td>
<td id="S5.T1.12.31.13" class="ltx_td ltx_align_center ltx_border_r">37.52</td>
<td id="S5.T1.12.31.14" class="ltx_td ltx_align_center"><span id="S5.T1.12.31.14.1" class="ltx_text ltx_font_bold">2.37</span></td>
</tr>
<tr id="S5.T1.8.8" class="ltx_tr">
<td id="S5.T1.7.7.1" class="ltx_td ltx_align_left ltx_border_tt ltx_border_tt" colspan="5">
<svg id="S5.T1.7.7.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.7.7.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> Default + PDR 0.3</td>
<td id="S5.T1.8.8.2" class="ltx_td ltx_align_left ltx_border_tt ltx_border_tt" colspan="9">
<svg id="S5.T1.8.8.2.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.8.8.2.pic1.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg> Default + PDR 0.3 + Last Layer Fixation to benign models</td>
</tr>
<tr id="S5.T1.11.11" class="ltx_tr">
<td id="S5.T1.9.9.1" class="ltx_td ltx_align_left" colspan="5">
<svg id="S5.T1.9.9.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.9.9.1.pic1.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> Default + Adapt to EUCL of benign models</td>
<td id="S5.T1.11.11.3" class="ltx_td ltx_align_left" colspan="9">
<svg id="S5.T1.10.10.2.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.10.10.2.pic1.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg> Default + PDR 0.3 + <span id="S5.T1.11.11.3.1" class="ltx_text">1-class</span> <span id="S5.T1.11.11.3.2" class="ltx_text">intra-client</span> <span id="S5.T1.11.11.3.3" class="ltx_text">non-IID</span> with <math id="S5.T1.11.11.3.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="S5.T1.11.11.3.m1.1a"><mrow id="S5.T1.11.11.3.m1.1.1" xref="S5.T1.11.11.3.m1.1.1.cmml"><mi id="S5.T1.11.11.3.m1.1.1.2" xref="S5.T1.11.11.3.m1.1.1.2.cmml">q</mi><mo id="S5.T1.11.11.3.m1.1.1.1" xref="S5.T1.11.11.3.m1.1.1.1.cmml">=</mo><mn id="S5.T1.11.11.3.m1.1.1.3" xref="S5.T1.11.11.3.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.11.11.3.m1.1b"><apply id="S5.T1.11.11.3.m1.1.1.cmml" xref="S5.T1.11.11.3.m1.1.1"><eq id="S5.T1.11.11.3.m1.1.1.1.cmml" xref="S5.T1.11.11.3.m1.1.1.1"></eq><ci id="S5.T1.11.11.3.m1.1.1.2.cmml" xref="S5.T1.11.11.3.m1.1.1.2">𝑞</ci><cn type="float" id="S5.T1.11.11.3.m1.1.1.3.cmml" xref="S5.T1.11.11.3.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.11.3.m1.1c">q=0.5</annotation></semantics></math> + Scaling</td>
</tr>
<tr id="S5.T1.12.12" class="ltx_tr">
<td id="S5.T1.12.12.1" class="ltx_td ltx_align_left" colspan="14">
<svg id="S5.T1.12.12.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.T1.12.12.1.pic1.1.1.1.1.1" class="ltx_text">5</span></foreignObject></g></g></svg> Default + <span id="S5.T1.12.12.1.1" class="ltx_text">inter-client</span> <span id="S5.T1.12.12.1.2" class="ltx_text">non-IID</span> based on our <span id="S5.T1.12.12.1.3" class="ltx_text">Random-Non-IID</span> strategy</td>
</tr>
</table>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we conduct a rigorous analysis of <span id="S5.p1.1.1" class="ltx_text">MESAS</span> and explore impact of various parameters and application-specific factors like datasets, model architectures, underlying data distributions, poisoning methods and attack adaptive strategies, as well as performance overheads.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Experimental Setup and Scenarios</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold">Hardware and Software.</span> We execute the FL system consisting of a configurable amount of clients on one server and implement the code in PyTorch <cite class="ltx_cite ltx_citemacro_citep">(The Linux Foundation, <a href="#bib.bib98" title="" class="ltx_ref">2022</a>; Paszke et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2019</a>)</cite>, a <span id="S5.SS1.p1.1.2" class="ltx_text">well-known</span> machine learning library for Python <cite class="ltx_cite ltx_citemacro_citep">(Van Rossum and Drake Jr, <a href="#bib.bib103" title="" class="ltx_ref">1995</a>)</cite>.<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>In our setting, we create 20 clients, of which nine are captured by an adversary. Nine malicious clients are the maximum the attacker can control in our setup while remaining within our attacker model (cf. <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>).</span></span></span> The individual client and server code is executed sequentially on the server running with an AMD EPYC 7413 <span id="S5.SS1.p1.1.3" class="ltx_text">24-Core</span> Processor (<span id="S5.SS1.p1.1.4" class="ltx_text">64-bit</span>) with 96 processing units and 128GB main memory. An NVIDIA A16 GPU with 4 virtual GPUs each having 16GB GDDR6 memory is accessible via CUDA <cite class="ltx_cite ltx_citemacro_citep">(NVIDIA et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2020</a>)</cite> from PyTorch.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Datasets and Models.</span> We chose similar settings to FL defenses in related works and focus mainly on image classification with <span id="S5.SS1.p2.1.2" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite>, GTSRB <cite class="ltx_cite ltx_citemacro_citep">(Stallkamp et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2012</a>)</cite>, and MNIST <cite class="ltx_cite ltx_citemacro_citep">(Deng, <a href="#bib.bib24" title="" class="ltx_ref">2012</a>)</cite>. We use <span id="S5.SS1.p2.1.3" class="ltx_text">ResNet-18</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2016</a>)</cite>, SqueezeNet <cite class="ltx_cite ltx_citemacro_citep">(Iandola et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2016</a>)</cite>, and a CNN model architectures. Additionally, we investigate into the text domain by training a DistilBERT <cite class="ltx_cite ltx_citemacro_citep">(Sanh et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2020</a>)</cite> transformer model on <span id="S5.SS1.p2.1.4" class="ltx_text">SST-2</span> <cite class="ltx_cite ltx_citemacro_citep">(Socher et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2013</a>)</cite> sentiment analysis dataset.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.5" class="ltx_p"><span id="S5.SS1.p3.5.1" class="ltx_text ltx_font_bold">Default Scenario.</span> We train the <span id="S5.SS1.p3.5.2" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite> image classification task (ten classes) on a <span id="S5.SS1.p3.5.3" class="ltx_text">ResNet-18</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2016</a>)</cite> model with LR 0.01 (SGD optimizer, momentum 0.9, decay 0.005), a batch size of 64, and ten local training epochs. The federation is a realistic setup, which consists of <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{N}=20" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mrow id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">𝒩</mi><mo id="S5.SS1.p3.1.m1.1.1.1" xref="S5.SS1.p3.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><eq id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1.1"></eq><ci id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">𝒩</ci><cn type="integer" id="S5.SS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.p3.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">\mathcal{N}=20</annotation></semantics></math> clients, which are all selected each round <math id="S5.SS1.p3.2.m2.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S5.SS1.p3.2.m2.1a"><mi id="S5.SS1.p3.2.m2.1.1" xref="S5.SS1.p3.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.2.m2.1b"><ci id="S5.SS1.p3.2.m2.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.2.m2.1c">r</annotation></semantics></math> (<math id="S5.SS1.p3.3.m3.1" class="ltx_Math" alttext="n=20" display="inline"><semantics id="S5.SS1.p3.3.m3.1a"><mrow id="S5.SS1.p3.3.m3.1.1" xref="S5.SS1.p3.3.m3.1.1.cmml"><mi id="S5.SS1.p3.3.m3.1.1.2" xref="S5.SS1.p3.3.m3.1.1.2.cmml">n</mi><mo id="S5.SS1.p3.3.m3.1.1.1" xref="S5.SS1.p3.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS1.p3.3.m3.1.1.3" xref="S5.SS1.p3.3.m3.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.3.m3.1b"><apply id="S5.SS1.p3.3.m3.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1"><eq id="S5.SS1.p3.3.m3.1.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1.1"></eq><ci id="S5.SS1.p3.3.m3.1.1.2.cmml" xref="S5.SS1.p3.3.m3.1.1.2">𝑛</ci><cn type="integer" id="S5.SS1.p3.3.m3.1.1.3.cmml" xref="S5.SS1.p3.3.m3.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.3.m3.1c">n=20</annotation></semantics></math>). The data are IID distributed and each client has 2560 samples, 256 randomly chosen from each class. The adversary captures nine clients leading to a poison model <span id="S5.SS1.p3.5.4" class="ltx_text">rate (PMR)</span> of 0.45, which is the maximum rate for this amount of clients. He sets the poison data rate (PDR) to 0.1, <math id="S5.SS1.p3.4.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS1.p3.4.m4.1a"><mi id="S5.SS1.p3.4.m4.1.1" xref="S5.SS1.p3.4.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.4.m4.1b"><ci id="S5.SS1.p3.4.m4.1.1.cmml" xref="S5.SS1.p3.4.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.4.m4.1c">\alpha</annotation></semantics></math> to 0.3, utilizes the adaption strategies from <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a> and implements a pixel trigger backdoor <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite> (cf. <a href="#A3.SS1" title="C.1. Pixel Triggers ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1</span></span></a>), which adds pixel pattern, a sticker, or similar as a trigger to the sample <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>; Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2018</a>)</cite>. The global model <math id="S5.SS1.p3.5.m5.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S5.SS1.p3.5.m5.1a"><msup id="S5.SS1.p3.5.m5.1.1" xref="S5.SS1.p3.5.m5.1.1.cmml"><mi id="S5.SS1.p3.5.m5.1.1.2" xref="S5.SS1.p3.5.m5.1.1.2.cmml">G</mi><mi id="S5.SS1.p3.5.m5.1.1.3" xref="S5.SS1.p3.5.m5.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.5.m5.1b"><apply id="S5.SS1.p3.5.m5.1.1.cmml" xref="S5.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p3.5.m5.1.1.1.cmml" xref="S5.SS1.p3.5.m5.1.1">superscript</csymbol><ci id="S5.SS1.p3.5.m5.1.1.2.cmml" xref="S5.SS1.p3.5.m5.1.1.2">𝐺</ci><ci id="S5.SS1.p3.5.m5.1.1.3.cmml" xref="S5.SS1.p3.5.m5.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.5.m5.1c">G^{r}</annotation></semantics></math> is already trained 50 benign rounds and was originally initialized with <span id="S5.SS1.p3.5.5" class="ltx_text">pre-trained</span> weights from PyTorch, with the first and last layers being untrained since both needed to be changed according to our dataset.<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>The <span id="footnote13.1" class="ltx_text">pre-trained</span> models from PyTorch are trained on ImageNet <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2009</a>)</cite>, thus have other input dimensions and 1000 instead of ten classes.</span></span></span></p>
</div>
<div id="S5.SS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.p4.1" class="ltx_p"><span id="S5.SS1.p4.1.1" class="ltx_text ltx_font_bold">Defenses.</span> We compare the following nine approaches, with <span id="S5.SS1.p4.1.2" class="ltx_text">MESAS</span> regarding effectiveness and runtime, hence examine DF, RA, and IR methods: Naïve <span id="S5.SS1.p4.1.3" class="ltx_text ltx_font_italic">clustering via HDBSCAN <cite class="ltx_cite ltx_citemacro_citep">(McInnes et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2017</a>)</cite></span>, <span id="S5.SS1.p4.1.4" class="ltx_text ltx_font_italic">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite></span>, <span id="S5.SS1.p4.1.5" class="ltx_text ltx_font_italic">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite></span>, <span id="S5.SS1.p4.1.6" class="ltx_text ltx_font_italic">M-Krum</span><span id="S5.SS1.p4.1.7" class="ltx_text ltx_font_italic"> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite></span>, <span id="S5.SS1.p4.1.8" class="ltx_text ltx_font_italic">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite></span>, <span id="S5.SS1.p4.1.9" class="ltx_text ltx_font_italic">T-Mean</span> <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>, <span id="S5.SS1.p4.1.10" class="ltx_text ltx_font_italic">T-Median</span> <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>, <span id="S5.SS1.p4.1.11" class="ltx_text"><span id="S5.SS1.p4.1.11.1" class="ltx_text ltx_font_italic">Clipping&amp;Noising</span> <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite></span>, <span id="S5.SS1.p4.1.12" class="ltx_text ltx_font_italic">Clipping</span> <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>, and <span id="S5.SS1.p4.1.13" class="ltx_text ltx_font_italic">Auror</span> <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2016</a>)</cite>. We either adapted <span id="S5.SS1.p4.1.14" class="ltx_text">open-source</span> implementations or reimplemented the methods if no code was available.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.p5.1" class="ltx_p">First, we consider our default scenario, and later we will expand the analysis to adaptive adversaries, nine poisoning attacks, and <span id="S5.SS1.p5.1.1" class="ltx_text">non-IID</span> data scenarios. Due to space limitations, we report the most interesting results and numbers that highlight our outcomes in the following sections and list detailed experimental results in <a href="#A6" title="Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></span></a>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Defenses under Strong Adaptive Adversaries</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.4" class="ltx_p">Before discussing defenses, we note that the BA of our default scenario without defense is only 42.94% (line 6 in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>), hence the backdoor is not effective (<math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="&lt;60\%" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml"></mi><mo id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">&lt;</mo><mrow id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml"><mn id="S5.SS2.p1.1.m1.1.1.3.2" xref="S5.SS2.p1.1.m1.1.1.3.2.cmml">60</mn><mo id="S5.SS2.p1.1.m1.1.1.3.1" xref="S5.SS2.p1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><lt id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">absent</csymbol><apply id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.p1.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.p1.1.m1.1.1.3.2">60</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">&lt;60\%</annotation></semantics></math>) and the adversary is forced to adapt his attack by either increasing the PDR, increasing the PMR <span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>Our default scenario already includes the maximum valid PMR defined in <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>.</span></span></span>, or by fixation, constraining and scaling. The increased BA of 61.96% for an increased PDR to 0.3 can be seen in scenario  <svg id="S5.SS2.p1.2.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.p1.2.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>. We explore the effectiveness of these strategies and list results in <a href="#A6" title="Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></span></a>. Here, we show that <span id="S5.SS2.p1.4.1" class="ltx_text">MESAS</span> is more effective than other defenses even without applying additional adaptions when comparing them under the default scenario as well as for increased PDR in scenario  <svg id="S5.SS2.p1.3.pic2" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.p1.3.pic2.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>: As can be seen in line 17 in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, <span id="S5.SS2.p1.4.2" class="ltx_text">MESAS</span> effectively removes the backdoor by reducing BA to 1.85% and 1.95%, while most other defenses are less potent. Only FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> is as effective as <span id="S5.SS2.p1.4.3" class="ltx_text">MESAS</span> in the default scenario and in scenario  <svg id="S5.SS2.p1.4.pic3" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.p1.4.pic3.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>, but, as we will elaborate later in this section, FoolsGold could be easily circumvented through adaption.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Since the adversary has to use one of the adaption strategies to reach a higher BA, we want to clarify beforehand that an increased PDR reinforces already existing significant values in <span id="S5.SS2.p2.1.1" class="ltx_text">MESAS</span>’s metrics even more. Scaling of updates has positive effects on <span id="S5.SS2.p2.1.2" class="ltx_text">MESAS</span>, since concurrently the metric COS will be changed, as visualized in <a href="#S4.F4" title="Figure 4 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a><span id="footnote15" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>When scaling, our strong adaptive adversary is aware of benign values from training benign model first and scales to the mean of those values. Additionally, Gaussian noise is added to the targeted value within the 3rd percentile of the benign value range to make the malicious models slightly different and, hence, increase stealthiness (otherwise the models with exactly the same values could be easily detected ).</span></span></span>. Further, constraining with <a href="#S2.E1" title="In 2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> or <a href="#S3.E2" title="In 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a> also benefits <span id="S5.SS2.p2.1.3" class="ltx_text">MESAS</span> due to side effects on its other metrics, forcing the adversary into a <span id="S5.SS2.p2.1.4" class="ltx_text">multi-objective</span> optimization (MOO) problem and, thus, hardening the adversarial dilemma. Lastly, fixation methods are ineffective against <span id="S5.SS2.p2.1.5" class="ltx_text">MESAS</span>, since all layers and the model as a whole are analyzed independently with statistical tests. Hence, <span id="S5.SS2.p2.1.6" class="ltx_text">MESAS</span> is robust against adaptions of a strong adaptive adversary, which, we show, an attacker can leverage to circumvent other defenses.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Circumvent Defenses</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Below, we will focus on the capability of defenses to reduce the BA in the new global model after aggregation compared to aggregation without defense (cf. line 6 in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>). Additionally, we will report the detection accuracy (ACC) of the defenses, when applicable, where 100% ACC means perfect detection rate and no <span id="S5.SS2.SSS1.p1.1.1" class="ltx_text">False-Positives</span> (FPs) and <span id="S5.SS2.SSS1.p1.1.2" class="ltx_text">False-Negatives</span> (FNs). We will also name the most effective adaption strategies based on results provided in <a href="#A6" title="Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></span></a>, which we couldn’t include in the main section of the paper due to space limitations.</p>
</div>
<div id="S5.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p2.1" class="ltx_p"><span id="S5.SS2.SSS1.p2.1.1" class="ltx_text ltx_font_bold">Clustering.</span> To demonstrate that naïve clustering methods could be bypassed, we use the HDBSCAN <cite class="ltx_cite ltx_citemacro_citep">(McInnes et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2017</a>)</cite> algorithm as an example and cluster based on the <span id="S5.SS2.SSS1.p2.1.2" class="ltx_text">cross-wise</span> Cosine distances between model updates. As can be seen in the default scenario in line 7 of <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, the defense is ineffective reaching a BA of 74.62% in the new global model after aggregation. We additionally report an ACC of only 10% (FPR of 100% and 81% FNR). Thus, there is no need for an attacker to follow any adaption strategies. Nevertheless, adaption to naïve clustering is possible by increasing the PDR allowing us to embed a BA of 86.86%, as depicted in scenario  <svg id="S5.SS2.SSS1.p2.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p2.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>.</p>
</div>
<div id="S5.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p3.2" class="ltx_p"><span id="S5.SS2.SSS1.p3.2.1" class="ltx_text ltx_font_bold">FoolsGold.</span> The second defense, FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>, is also based on <span id="S5.SS2.SSS1.p3.2.2" class="ltx_text">cross-wise</span> Cosine distances between model updates. However, it analyzes only outputs of the last layer, which is more effective than naïve clustering and is capable of removing all poisoned models in the default scenario and for scenario,  <svg id="S5.SS2.SSS1.p3.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p3.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> reaching BAs of 1.85%, as depicted in line 8 of cf. <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>. Nevertheless, the defense can be circumvented using adaption. The best results we obtained by parameter <span id="S5.SS2.SSS1.p3.2.3" class="ltx_text ltx_font_italic">fixation</span> on the last layer in combination with PDR increase, depicted as scenario  <svg id="S5.SS2.SSS1.p3.2.pic2" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p3.2.pic2.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg> in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, reaching a BA of 63.54%. In contrast, <span id="S5.SS2.SSS1.p3.2.4" class="ltx_text">MESAS</span> still removes the backdoor to 1.95% with only one FP when a similar adaption strategy is applied.</p>
</div>
<div id="S5.SS2.SSS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p4.3" class="ltx_p"><span id="S5.SS2.SSS1.p4.3.1" class="ltx_text ltx_font_bold">Krum.</span> Next, we evaluated Krum and <span id="S5.SS2.SSS1.p4.3.2" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>, which leverage <span id="S5.SS2.SSS1.p4.3.3" class="ltx_text">cross-wise</span> Euclidean distances between local models. The trigger backdoor is not reflected in this metric, which renders the defense ineffective for our default scenario (83.53% and 83.05%BA for Krum and <span id="S5.SS2.SSS1.p4.3.4" class="ltx_text">M-Krum</span>, resp. in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>) and for scenario  <svg id="S5.SS2.SSS1.p4.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p4.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> and  <svg id="S5.SS2.SSS1.p4.2.pic2" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p4.2.pic2.1.1.1.1.1" class="ltx_text">2</span></foreignObject></g></g></svg>. Since Krum selects one single local model as the new global model, it can either choose a malicious or benign local model. In the former case, the backdoor trivially makes it to the global model. In the latter case, we can follow the following strategy: We can adapt the malicious models via constraint method <a href="#S2.E1" title="In 2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> forcing the Krum scores of poisoned models to be more equal to each other compelling Krum to decide in their favor. By circumventing Krum like this, we achieved BAs up to 89.90% and reached 95.80% BA for <span id="S5.SS2.SSS1.p4.3.5" class="ltx_text">M-Krum</span> as can be seen in scenario  <svg id="S5.SS2.SSS1.p4.3.pic3" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p4.3.pic3.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>. In contrast, <span id="S5.SS2.SSS1.p4.3.6" class="ltx_text">MESAS</span> accurately filters the backdoor in similar circumstances, as adaption via constraint has significant effects on other metrics, like EUCL and MIN.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S5.T2.4.2" class="ltx_text" style="font-size:90%;">BA for targeted and ACC for untargeted poisoning attacks without adaptive adversary in percent.</span></figcaption>
<table id="S5.T2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.1.2" class="ltx_tr">
<td id="S5.T2.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" rowspan="3"><span id="S5.T2.1.2.1.1" class="ltx_text">Aggregation / Defenses</span></td>
<td id="S5.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="6">BA</td>
<td id="S5.T2.1.2.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">ACC</td>
</tr>
<tr id="S5.T2.1.3" class="ltx_tr">
<td id="S5.T2.1.3.1" class="ltx_td ltx_align_center ltx_border_r">Pixel Trigger</td>
<td id="S5.T2.1.3.2" class="ltx_td ltx_align_center ltx_border_r">Clean-Label</td>
<td id="S5.T2.1.3.3" class="ltx_td ltx_align_center ltx_border_r">Semantic</td>
<td id="S5.T2.1.3.4" class="ltx_td ltx_align_center ltx_border_r">Edge Case</td>
<td id="S5.T2.1.3.5" class="ltx_td ltx_align_center ltx_border_r">Label Flip</td>
<td id="S5.T2.1.3.6" class="ltx_td ltx_align_center ltx_border_r">Pervasive</td>
<td id="S5.T2.1.3.7" class="ltx_td ltx_align_center ltx_border_r">Random Flip</td>
<td id="S5.T2.1.3.8" class="ltx_td ltx_align_center ltx_border_r">Sign Flip</td>
<td id="S5.T2.1.3.9" class="ltx_td ltx_align_center">Noising</td>
</tr>
<tr id="S5.T2.1.4" class="ltx_tr">
<td id="S5.T2.1.4.1" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite></td>
<td id="S5.T2.1.4.2" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Turner et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="S5.T2.1.4.3" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite></td>
<td id="S5.T2.1.4.4" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite></td>
<td id="S5.T2.1.4.5" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Biggio et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2012</a>; Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="S5.T2.1.4.6" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite></td>
<td id="S5.T2.1.4.7" class="ltx_td ltx_align_center ltx_border_r"><a href="#A3.SS7" title="C.7. Random Label Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.7</span></span></a></td>
<td id="S5.T2.1.4.8" class="ltx_td ltx_align_center ltx_border_r"><a href="#A3.SS8" title="C.8. Sign Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.8</span></span></a></td>
<td id="S5.T2.1.4.9" class="ltx_td ltx_align_center"><a href="#A3.SS9" title="C.9. Model Noising ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.9</span></span></a></td>
</tr>
<tr id="S5.T2.1.1" class="ltx_tr">
<td id="S5.T2.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="S5.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="S5.T2.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S5.T2.1.1.1.m1.1a"><msup id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml"><mi id="S5.T2.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.m1.1.1.2.cmml">G</mi><mi id="S5.T2.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><apply id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">superscript</csymbol><ci id="S5.T2.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.m1.1.1.2">𝐺</ci><ci id="S5.T2.1.1.1.m1.1.1.3.cmml" xref="S5.T2.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="S5.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.90</td>
<td id="S5.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.90</td>
<td id="S5.T2.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S5.T2.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.53</td>
<td id="S5.T2.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.10</td>
<td id="S5.T2.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.02</td>
<td id="S5.T2.1.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.1.11" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T2.1.5" class="ltx_tr">
<td id="S5.T2.1.5.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="S5.T2.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="S5.T2.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.56</td>
<td id="S5.T2.1.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.57</td>
<td id="S5.T2.1.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S5.T2.1.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.55</td>
<td id="S5.T2.1.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.24</td>
<td id="S5.T2.1.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.95</td>
<td id="S5.T2.1.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.5.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.5.11" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T2.1.6" class="ltx_tr">
<td id="S5.T2.1.6.1" class="ltx_td ltx_align_left">3:</td>
<td id="S5.T2.1.6.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="S5.T2.1.6.3" class="ltx_td ltx_align_center ltx_border_r">85.13</td>
<td id="S5.T2.1.6.4" class="ltx_td ltx_align_center ltx_border_r">75.49</td>
<td id="S5.T2.1.6.5" class="ltx_td ltx_align_center ltx_border_r">80.0</td>
<td id="S5.T2.1.6.6" class="ltx_td ltx_align_center ltx_border_r">19.28</td>
<td id="S5.T2.1.6.7" class="ltx_td ltx_align_center ltx_border_r">74.15</td>
<td id="S5.T2.1.6.8" class="ltx_td ltx_align_center ltx_border_r">97.28</td>
<td id="S5.T2.1.6.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.6.10" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.6.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.7" class="ltx_tr">
<td id="S5.T2.1.7.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="S5.T2.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T2.1.7.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="S5.T2.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.85</td>
<td id="S5.T2.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.85</td>
<td id="S5.T2.1.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S5.T2.1.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.85</td>
<td id="S5.T2.1.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.20</td>
<td id="S5.T2.1.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.07</td>
<td id="S5.T2.1.7.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.7.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.7.11" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T2.1.8" class="ltx_tr">
<td id="S5.T2.1.8.1" class="ltx_td ltx_align_left">5:</td>
<td id="S5.T2.1.8.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T2.1.8.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="S5.T2.1.8.3" class="ltx_td ltx_align_center ltx_border_r">83.00</td>
<td id="S5.T2.1.8.4" class="ltx_td ltx_align_center ltx_border_r">81.75</td>
<td id="S5.T2.1.8.5" class="ltx_td ltx_align_center ltx_border_r">100.0</td>
<td id="S5.T2.1.8.6" class="ltx_td ltx_align_center ltx_border_r">20.40</td>
<td id="S5.T2.1.8.7" class="ltx_td ltx_align_center ltx_border_r">71.20</td>
<td id="S5.T2.1.8.8" class="ltx_td ltx_align_center ltx_border_r">99.84</td>
<td id="S5.T2.1.8.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.8.10" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.8.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.9" class="ltx_tr">
<td id="S5.T2.1.9.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="S5.T2.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T2.1.9.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="S5.T2.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">42.94</td>
<td id="S5.T2.1.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">38.92</td>
<td id="S5.T2.1.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.0</td>
<td id="S5.T2.1.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.63</td>
<td id="S5.T2.1.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.20</td>
<td id="S5.T2.1.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.58</td>
<td id="S5.T2.1.9.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.9.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S5.T2.1.9.11" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T2.1.10" class="ltx_tr">
<td id="S5.T2.1.10.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="S5.T2.1.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="S5.T2.1.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.62</td>
<td id="S5.T2.1.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.1.10.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
<td id="S5.T2.1.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.0</td>
<td id="S5.T2.1.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.35</td>
<td id="S5.T2.1.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.60</td>
<td id="S5.T2.1.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.67</td>
<td id="S5.T2.1.10.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.00</td>
<td id="S5.T2.1.10.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.1.10.10.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S5.T2.1.10.11" class="ltx_td ltx_align_center ltx_border_t">80.00</td>
</tr>
<tr id="S5.T2.1.11" class="ltx_tr">
<td id="S5.T2.1.11.1" class="ltx_td ltx_align_left">8:</td>
<td id="S5.T2.1.11.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S5.T2.1.11.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.11.3.1" class="ltx_text ltx_font_bold">1.85</span></td>
<td id="S5.T2.1.11.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.11.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
<td id="S5.T2.1.11.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.11.5.1" class="ltx_text ltx_font_bold">0.00</span></td>
<td id="S5.T2.1.11.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.11.6.1" class="ltx_text ltx_font_bold">2.55</span></td>
<td id="S5.T2.1.11.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.11.7.1" class="ltx_text ltx_font_bold">0.20</span></td>
<td id="S5.T2.1.11.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.11.8.1" class="ltx_text ltx_font_bold">0.10</span></td>
<td id="S5.T2.1.11.9" class="ltx_td ltx_align_center ltx_border_r">55.00</td>
<td id="S5.T2.1.11.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.11.10.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S5.T2.1.11.11" class="ltx_td ltx_align_center">0.00</td>
</tr>
<tr id="S5.T2.1.12" class="ltx_tr">
<td id="S5.T2.1.12.1" class="ltx_td ltx_align_left">9:</td>
<td id="S5.T2.1.12.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="S5.T2.1.12.3" class="ltx_td ltx_align_center ltx_border_r">83.53</td>
<td id="S5.T2.1.12.4" class="ltx_td ltx_align_center ltx_border_r">75.65</td>
<td id="S5.T2.1.12.5" class="ltx_td ltx_align_center ltx_border_r">80.00</td>
<td id="S5.T2.1.12.6" class="ltx_td ltx_align_center ltx_border_r">20.91</td>
<td id="S5.T2.1.12.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.12.7.1" class="ltx_text ltx_font_bold">1.30</span></td>
<td id="S5.T2.1.12.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.12.8.1" class="ltx_text ltx_font_bold">0.42</span></td>
<td id="S5.T2.1.12.9" class="ltx_td ltx_align_center ltx_border_r">50.00</td>
<td id="S5.T2.1.12.10" class="ltx_td ltx_align_center ltx_border_r">50.00</td>
<td id="S5.T2.1.12.11" class="ltx_td ltx_align_center">50.00</td>
</tr>
<tr id="S5.T2.1.13" class="ltx_tr">
<td id="S5.T2.1.13.1" class="ltx_td ltx_align_left">10:</td>
<td id="S5.T2.1.13.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T2.1.13.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="S5.T2.1.13.3" class="ltx_td ltx_align_center ltx_border_r">83.05</td>
<td id="S5.T2.1.13.4" class="ltx_td ltx_align_center ltx_border_r">82.38</td>
<td id="S5.T2.1.13.5" class="ltx_td ltx_align_center ltx_border_r">100.0</td>
<td id="S5.T2.1.13.6" class="ltx_td ltx_align_center ltx_border_r">18.87</td>
<td id="S5.T2.1.13.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.13.7.1" class="ltx_text ltx_font_bold">0.40</span></td>
<td id="S5.T2.1.13.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.13.8.1" class="ltx_text ltx_font_bold">3.50</span></td>
<td id="S5.T2.1.13.9" class="ltx_td ltx_align_center ltx_border_r">75.00</td>
<td id="S5.T2.1.13.10" class="ltx_td ltx_align_center ltx_border_r">75.00</td>
<td id="S5.T2.1.13.11" class="ltx_td ltx_align_center">75.00</td>
</tr>
<tr id="S5.T2.1.14" class="ltx_tr">
<td id="S5.T2.1.14.1" class="ltx_td ltx_align_left">11:</td>
<td id="S5.T2.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T2.1.14.3" class="ltx_td ltx_align_center ltx_border_r">42.81</td>
<td id="S5.T2.1.14.4" class="ltx_td ltx_align_center ltx_border_r">38.91</td>
<td id="S5.T2.1.14.5" class="ltx_td ltx_align_center ltx_border_r">60.0</td>
<td id="S5.T2.1.14.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.14.6.1" class="ltx_text ltx_font_bold">6.63</span></td>
<td id="S5.T2.1.14.7" class="ltx_td ltx_align_center ltx_border_r">48.40</td>
<td id="S5.T2.1.14.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.14.8.1" class="ltx_text ltx_font_bold">3.17</span></td>
<td id="S5.T2.1.14.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.14.10" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.14.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.15" class="ltx_tr">
<td id="S5.T2.1.15.1" class="ltx_td ltx_align_left">12:</td>
<td id="S5.T2.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T2.1.15.3" class="ltx_td ltx_align_center ltx_border_r">60.66</td>
<td id="S5.T2.1.15.4" class="ltx_td ltx_align_center ltx_border_r">40.73</td>
<td id="S5.T2.1.15.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.15.5.1" class="ltx_text ltx_font_bold">0.00</span></td>
<td id="S5.T2.1.15.6" class="ltx_td ltx_align_center ltx_border_r">12.75</td>
<td id="S5.T2.1.15.7" class="ltx_td ltx_align_center ltx_border_r">30.80</td>
<td id="S5.T2.1.15.8" class="ltx_td ltx_align_center ltx_border_r">10.08</td>
<td id="S5.T2.1.15.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.15.10" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.15.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.16" class="ltx_tr">
<td id="S5.T2.1.16.1" class="ltx_td ltx_align_left">13:</td>
<td id="S5.T2.1.16.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="S5.T2.1.16.3" class="ltx_td ltx_align_center ltx_border_r">79.17</td>
<td id="S5.T2.1.16.4" class="ltx_td ltx_align_center ltx_border_r">77.12</td>
<td id="S5.T2.1.16.5" class="ltx_td ltx_align_center ltx_border_r">60.0</td>
<td id="S5.T2.1.16.6" class="ltx_td ltx_align_center ltx_border_r">18.87</td>
<td id="S5.T2.1.16.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.16.7.1" class="ltx_text ltx_font_bold">2.40</span></td>
<td id="S5.T2.1.16.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.16.8.1" class="ltx_text ltx_font_bold">5.52</span></td>
<td id="S5.T2.1.16.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.16.9.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S5.T2.1.16.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.16.10.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S5.T2.1.16.11" class="ltx_td ltx_align_center"><span id="S5.T2.1.16.11.1" class="ltx_text ltx_font_bold">100.00</span></td>
</tr>
<tr id="S5.T2.1.17" class="ltx_tr">
<td id="S5.T2.1.17.1" class="ltx_td ltx_align_left">14:</td>
<td id="S5.T2.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T2.1.17.3" class="ltx_td ltx_align_center ltx_border_r">44.13</td>
<td id="S5.T2.1.17.4" class="ltx_td ltx_align_center ltx_border_r">41.10</td>
<td id="S5.T2.1.17.5" class="ltx_td ltx_align_center ltx_border_r">60.0</td>
<td id="S5.T2.1.17.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.17.6.1" class="ltx_text ltx_font_bold">7.14</span></td>
<td id="S5.T2.1.17.7" class="ltx_td ltx_align_center ltx_border_r">48.40</td>
<td id="S5.T2.1.17.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.17.8.1" class="ltx_text ltx_font_bold">2.53</span></td>
<td id="S5.T2.1.17.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.17.10" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.17.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.18" class="ltx_tr">
<td id="S5.T2.1.18.1" class="ltx_td ltx_align_left">15:</td>
<td id="S5.T2.1.18.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T2.1.18.3" class="ltx_td ltx_align_center ltx_border_r">44.60</td>
<td id="S5.T2.1.18.4" class="ltx_td ltx_align_center ltx_border_r">25.66</td>
<td id="S5.T2.1.18.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.18.5.1" class="ltx_text ltx_font_bold">0.00</span></td>
<td id="S5.T2.1.18.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.18.6.1" class="ltx_text ltx_font_bold">2.55</span></td>
<td id="S5.T2.1.18.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.18.7.1" class="ltx_text ltx_font_bold">5.60</span></td>
<td id="S5.T2.1.18.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.18.8.1" class="ltx_text ltx_font_bold">0.10</span></td>
<td id="S5.T2.1.18.9" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.18.10" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T2.1.18.11" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T2.1.19" class="ltx_tr">
<td id="S5.T2.1.19.1" class="ltx_td ltx_align_left">16:</td>
<td id="S5.T2.1.19.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S5.T2.1.19.3" class="ltx_td ltx_align_center ltx_border_r">23.08</td>
<td id="S5.T2.1.19.4" class="ltx_td ltx_align_center ltx_border_r">37.83</td>
<td id="S5.T2.1.19.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.19.5.1" class="ltx_text ltx_font_bold">0.00</span></td>
<td id="S5.T2.1.19.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.19.6.1" class="ltx_text ltx_font_bold">5.10</span></td>
<td id="S5.T2.1.19.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.19.7.1" class="ltx_text ltx_font_bold">0.2</span></td>
<td id="S5.T2.1.19.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.1.19.8.1" class="ltx_text ltx_font_bold">0.11</span></td>
<td id="S5.T2.1.19.9" class="ltx_td ltx_align_center ltx_border_r">60.00</td>
<td id="S5.T2.1.19.10" class="ltx_td ltx_align_center ltx_border_r">20.00</td>
<td id="S5.T2.1.19.11" class="ltx_td ltx_align_center">35.00</td>
</tr>
<tr id="S5.T2.1.20" class="ltx_tr">
<td id="S5.T2.1.20.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="S5.T2.1.20.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="S5.T2.1.20.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.3.1" class="ltx_text ltx_font_bold">1.85</span></td>
<td id="S5.T2.1.20.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.4.1" class="ltx_text ltx_font_bold">3.71</span></td>
<td id="S5.T2.1.20.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.5.1" class="ltx_text ltx_font_bold">0.00</span></td>
<td id="S5.T2.1.20.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.6.1" class="ltx_text ltx_font_bold">2.55</span></td>
<td id="S5.T2.1.20.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.7.1" class="ltx_text ltx_font_bold">0.20</span></td>
<td id="S5.T2.1.20.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.8.1" class="ltx_text ltx_font_bold">0.05</span></td>
<td id="S5.T2.1.20.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.9.1" class="ltx_text ltx_font_bold">95.00</span></td>
<td id="S5.T2.1.20.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.1.20.10.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S5.T2.1.20.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.1.20.11.1" class="ltx_text ltx_font_bold">100.00</span></td>
</tr>
</table>
</figure>
<div id="S5.SS2.SSS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p5.1" class="ltx_p"><span id="S5.SS2.SSS1.p5.1.1" class="ltx_text ltx_font_bold">Flame.</span> We evaluate Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>, a more complex DF defense, which combines clustering with clipping and noising techniques. Since the underlying metric is the same as for the naïve clustering defense, it is not very effective in removing the backdoor even in the default scenario achieving 79.17% BA (cf. line 13 in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>). Similar to naïve clustering, we could strengthen the BA by increasing the PDR to 88.44% and by additional scaling to 91.34%, which shows that relying solely on the leveraged metric of Flame is insufficient. <span id="S5.SS2.SSS1.p5.1.2" class="ltx_text">MESAS</span> erases the backdoor efficiently in all of the cases, due to the <span id="S5.SS2.SSS1.p5.1.3" class="ltx_text">in-depth</span> model analysis with statistical tests and increased robustness against adaption through leveraging six different metrics.</p>
</div>
<div id="S5.SS2.SSS1.p6" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p6.1" class="ltx_p"><span id="S5.SS2.SSS1.p6.1.1" class="ltx_text ltx_font_bold">FLTrust.</span> As a more recent defense, we analyze FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>, which is based on a trusted root dataset<span id="footnote16" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span>Similar to the authors, we used a trusted root dataset of 100 IID samples and excluded them from the datasets used for training of the clients.</span></span></span> on the server side. FLTrust leverages the Cosine Similarity between the updates of the local models and a trusted model trained by the server on the trusted root dataset and the norm of the local updates. Based on these metrics, FLTrust assigns weights to each local update so that poisoned updates are assigned with low weights, preferably zero, which would filter out the update. Therefore, the defense is ineffective, if the backdoor is not visible within both of these metrics, meaning, that the Cosine Similarity is inconspicuous, which can happen if the backdoor is only embedded in one layer without affecting the model-wise metric value, or if the backdoor is hidden in other metrics, as VAR, MAX, or MIN only. In most of our experiments, FLTrust successfully weakened backdoors beneath critical BAs. However, the assigned weights to all (also benign) local updates were found to be relatively small (mostly between 0.001 and 0.03), thereby inadvertently reducing their contribution to the global model. Consequently, the approach’s efficacy comes at the cost of slowing down the training speed. Additionally, FLTrust’s effectiveness depends on the chosen metric’s ability to accurately reflect the backdoor. However, a backdoor is not necessarily embedded in those metrics, as can be seen in experiments, e.g., in scenario  <svg id="S5.SS2.SSS1.p6.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p6.1.pic1.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> yielding a BA of 74.71%. For adaption, we first trained a benign model and then proceeded to adapt the local update of the malicious model based on the update of this benign model. Since we observed that in the resulting models, the main reason for suspicious metric values in Cosine Similarity originated from the parameters of the last model layer, we restricted this adaptation process to the last layer only to make the backdoor inconspicuous in the last layer. While this strategy resulted in low BA, FLTrust assigns higher weights to the malicious updates than to the benign ones, with seven out of eleven benign updates being assigned a weight of zero. That means that those benign models were filtered, essentially slowing down the learning process, while malicious models were included in aggregation, even so with smaller weights. In contrast, <span id="S5.SS2.SSS1.p6.1.2" class="ltx_text">MESAS</span> consistently and effectively eliminated the backdoor in all of these cases without decreasing the impact of benign models.</p>
</div>
<div id="S5.SS2.SSS1.p7" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p7.1" class="ltx_p"><span id="S5.SS2.SSS1.p7.1.1" class="ltx_text ltx_font_bold">Differential Privacy.</span> Besides DF methods, we evaluated two IR approaches: Model update clipping based on the Euclidean distance and a combination with model parameter noising <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>. Clipping is ineffective, as our default scenario backdoor is not reflected in the Euclidean distance of the updates. Thus, the attacker can achieve 60.66% BA for the default scenario (cf. line 12 of <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>). When using adaption, the BA can be increased slightly to 61.86% by increasing the PDR as in scenario  <svg id="S5.SS2.SSS1.p7.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p7.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>. In contrast, <span id="S5.SS2.SSS1.p7.1.2" class="ltx_text">MESAS</span> is effective under similar circumstances resulting in 1.85% and 1.95% BAs.</p>
</div>
<div id="S5.SS2.SSS1.p8" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p8.1" class="ltx_p"><span id="S5.SS2.SSS1.p8.1.1" class="ltx_text ltx_font_bold">Robust Aggregation.</span> We evaluate <span id="S5.SS2.SSS1.p8.1.2" class="ltx_text">T-Mean</span> and <span id="S5.SS2.SSS1.p8.1.3" class="ltx_text">T-Median</span> <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>, which are RA alternatives to <span id="S5.SS2.SSS1.p8.1.4" class="ltx_text">FedAVG</span>. Both result in weak backdoors with BA of 44.13% and 44.60% in lines 14 and 15 for the default scenario, but are not robust when facing a strong adaptive adversary: <span id="S5.SS2.SSS1.p8.1.5" class="ltx_text">T-Mean</span> can be bypassed with up to 63.98% BA, while <span id="S5.SS2.SSS1.p8.1.6" class="ltx_text">T-Median</span> shows 57.37% BA, but also experiences around 10% reduction in MA in scenario  <svg id="S5.SS2.SSS1.p8.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS2.SSS1.p8.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg>. Hence, both approaches are not comparable to the performance of <span id="S5.SS2.SSS1.p8.1.7" class="ltx_text">MESAS</span>, which reduces BA to 1.95% under similar circumstances.</p>
</div>
<div id="S5.SS2.SSS1.p9" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS1.p9.1" class="ltx_p"><span id="S5.SS2.SSS1.p9.1.1" class="ltx_text ltx_font_bold">MESAS</span><span id="S5.SS2.SSS1.p9.1.2" class="ltx_text ltx_font_bold">.</span> To circumvent <span id="S5.SS2.SSS1.p9.1.3" class="ltx_text">MESAS</span>, we tried to adapt to respective metrics that reflect the different poisoning attacks. We succeeded in adapting to COS, EUCL, MIN, and MAX, which appeared to be the metrics most backdoors manifest first. This was only possible by leveraging the loss scaling method of our strong adaptive adversary, as described in <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>, since otherwise, adaption to multiple losses already resulted in facing an adversarial dilemma. However, as soon as we adapt to those metrics, this behavior is reflected in the other metrics, namely VAR and COUNT. For a few experiments, we succeeded in adapting to VAR, even if the MA suffered immensely, but additional adaption to COUNT was impossible.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Different Poisoning Attacks</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">In the following, we evaluate the effectiveness of the defenses against various poisoning attacks, including six different trigger methods for targeted attacks and three untargeted attacks, namely pixel triggers <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite>, <span id="S5.SS2.SSS2.p1.1.1" class="ltx_text">clean-label</span> backdoor <cite class="ltx_cite ltx_citemacro_citep">(Turner et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite>, semantic backdoor <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>, edge case backdoor <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite>, label flip backdoor <cite class="ltx_cite ltx_citemacro_citep">(Biggio et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2012</a>; Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, and pervasive backdoor <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite> as well as random label flipping (cf. <a href="#A3.SS7" title="C.7. Random Label Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.7</span></span></a>), sign flipping (cf. <a href="#A3.SS8" title="C.8. Sign Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.8</span></span></a>), and model noising (cf. <a href="#A3.SS9" title="C.9. Model Noising ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.9</span></span></a>) which are all explained in detail in <a href="#A3" title="Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></span></a>. We report the BAs that the poisoning attacks achieve against the nine defenses in <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a> and the MAs in <a href="#A5.T4" title="Table 4 ‣ Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a>.<span id="footnote17" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span>The results reported in tables do not consider adaption (which is evaluated in <a href="#S5.SS2.SSS1" title="5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.1</span></span></a>), as the system’s adaptability is directly tied to the specific defense employed. Instead, the tables focus on determining whether <span id="footnote17.1" class="ltx_text">MESAS</span> can successfully detect various triggers. Thereby, we ensure that our findings remain independent from the pixel-trigger method of the default scenario.</span></span></span></p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p"><span id="S5.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Pixel Trigger Backdoor</span> This backdoor is discussed in <a href="#S5.SS2.SSS1" title="5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.1</span></span></a>, where we showed that we can circumvent existing defenses by adaption and strengthening the trigger. Only <span id="S5.SS2.SSS2.p2.1.2" class="ltx_text">MESAS</span> could reliably remove the backdoor.</p>
</div>
<div id="S5.SS2.SSS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p3.1" class="ltx_p"><span id="S5.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Clean-Label Attack.</span> This attack is not suited perfectly for FL, since it is hard to embed a high BA with low PDR into the new global model. In our default scenario, we reached only 11.85% BA after aggregation, which is why we report the result for PDR 0.5, which leads to a BA 38.92% without defense (line 6 in <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>). Nevertheless, it is possible to achieve a high BA of up to 82.38% for <span id="S5.SS2.SSS2.p3.1.2" class="ltx_text">M-Krum</span> (line 10), while naïve clustering, FoolsGold, and <span id="S5.SS2.SSS2.p3.1.3" class="ltx_text">MESAS</span> erase the backdoor. Among them, <span id="S5.SS2.SSS2.p3.1.4" class="ltx_text">MESAS</span> is the only one that cannot be adapted and erases the backdoor, which manifests in COS and EUCL, resulting in a FNR of 81%.<span id="footnote18" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span>We experienced an elevated FNs in a scenario with a maximum PMR and one benign outlier model. We could not reproduce such scenarios on purpose when acting as an adversary. Such scenarios can only occur, if the PMR is at a peak of nearly 50% and one benign outlier exists, which then violates the majority assumption of <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>. However, if such situations occur, <span id="footnote18.1" class="ltx_text">MESAS</span> still ends up aggregating only benign models as long as the poisonings are significant in at least one metric in one layer. Hence is also robust against coincidental benign outliers.</span></span></span></p>
</div>
<div id="S5.SS2.SSS2.p4" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p4.1" class="ltx_p"><span id="S5.SS2.SSS2.p4.1.1" class="ltx_text ltx_font_bold">Semantic Backdoor.</span> Without defense, this backdoor is effective with 60% BA. However, it is detectable within the last layers by FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> leading to 0.00% BA (line 8 of <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>). Clip&amp;Noise and <span id="S5.SS2.SSS2.p4.1.2" class="ltx_text">T-Median</span> also remove the backdoor, but at the same time reduce MA. <span id="S5.SS2.SSS2.p4.1.3" class="ltx_text">MESAS</span> erases the backdoor completely by leveraging MAX metric. We report one FP in this case for <span id="S5.SS2.SSS2.p4.1.4" class="ltx_text">MESAS</span>, but with a good result in a BA of 0.0%. Other effective defenses can be circumvented through adaption (FoolsGold) or reduce the MA (<span id="S5.SS2.SSS2.p4.1.5" class="ltx_text">T-Mean</span> and Clip&amp;Noise).</p>
</div>
<div id="S5.SS2.SSS2.p5" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p5.1" class="ltx_p"><span id="S5.SS2.SSS2.p5.1.1" class="ltx_text ltx_font_bold">Edge Case Backdoor.</span> It appears to be hard to embed an effective backdoor with this method even within the local models for <span id="S5.SS2.SSS2.p5.1.2" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite> on <span id="S5.SS2.SSS2.p5.1.3" class="ltx_text">ResNet-18</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2016</a>)</cite>. In <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>, we report the results for a PDR or 0.3 with 19.78% BA on the local clients on average (line 3) and 6.63% BA without defense. <span id="S5.SS2.SSS2.p5.1.4" class="ltx_text">MESAS</span> is already sensitive to the poisoning attacks even when the effect on the global model is still minimal with 6.63% BA (line 6). We reach 100% TPs and only two FPs resulting in the lowest BA with 2.55% in this case (line 17).</p>
</div>
<div id="S5.SS2.SSS2.p6" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p6.1" class="ltx_p"><span id="S5.SS2.SSS2.p6.1.1" class="ltx_text ltx_font_bold">Label Flip Backdoor.</span> This attack manifests in extreme deviations within the last layer of a DNN. Hence, many defenses can easily detect the backdoor, as can be retraced on the low BAs in <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>. Having two FPs, <span id="S5.SS2.SSS2.p6.1.2" class="ltx_text">MESAS</span> is the only defense reducing the BA to 0.20% while being robust against fixation and adaption attempts, which can be used to circumvent other defenses like FoolsGold.</p>
</div>
<div id="S5.SS2.SSS2.p7" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p7.1" class="ltx_p"><span id="S5.SS2.SSS2.p7.1.1" class="ltx_text ltx_font_bold">Pervasive.</span> Blend <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite> can be implemented with a PDR of 0.1 to achieve 99.84% BA locally on average (line 3 in <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a>), but it is inefficient in FL– we could only reach 3.58% BA for the global model without defense (line 6). <span id="S5.SS2.SSS2.p7.1.2" class="ltx_text">MESAS</span> can detect all poisoned local models while suffering five FNs. The result is interesting, as it shows that <span id="S5.SS2.SSS2.p7.1.3" class="ltx_text">MESAS</span> reaches the lowest BA of 0.05% while having minor effects on the MA, whereas other defenses affect the MA (cf. <a href="#A5.T4" title="Table 4 ‣ Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a>) or can be circumvented by adaption.</p>
</div>
<div id="S5.SS2.SSS2.p8" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p8.1" class="ltx_p"><span id="S5.SS2.SSS2.p8.1.1" class="ltx_text ltx_font_bold">Untargeted Attacks.</span> For the untargeted attacks, we do not report the BAs, but the ACC of the defense mechanisms in <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a> and the resulting MAs in <a href="#A5.T4" title="Table 4 ‣ Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a>. Random label flipping (cf. <a href="#A3.SS7" title="C.7. Random Label Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.7</span></span></a>) is the first untargeted attack that we implemented. The MA is reduced to 57.03% without any defense and only <span id="S5.SS2.SSS2.p8.1.2" class="ltx_text">M-Krum</span> and FLTrust can score a higher MA of 64.15% and 63.16%, respectively, compared to 62.88% of <span id="S5.SS2.SSS2.p8.1.3" class="ltx_text">MESAS</span>. However, <span id="S5.SS2.SSS2.p8.1.4" class="ltx_text">M-Krum</span> suffers a FNR of 45%, compared to 0.09% of <span id="S5.SS2.SSS2.p8.1.5" class="ltx_text">MESAS</span> and FLTrust comes with an ACC of 60%<span id="footnote19" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span>We compute the ACC of FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> by analyzing the weights assigned to the models. A model assigned with a weight of zero is considered as a filtered model.</span></span></span>, while <span id="S5.SS2.SSS2.p8.1.6" class="ltx_text">MESAS</span> achieves 95%. Flame stands out with 100% ACC, but can be circumvented by adaption. Second, we evaluated sign flipping (cf. <a href="#A3.SS8" title="C.8. Sign Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.8</span></span></a>), which is clearly detectable by defenses leveraging clustering methods including <span id="S5.SS2.SSS2.p8.1.7" class="ltx_text">MESAS</span>, but can lead to a naïve model with 10% MA for other approaches. Finally, we report the results for the model noising attack (cf. <a href="#A3.SS9" title="C.9. Model Noising ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.9</span></span></a>), where <span id="S5.SS2.SSS2.p8.1.8" class="ltx_text">MESAS</span> also has an ACC of 100%, whereas other methods, like FLTrust achieve only 35% ACC.</p>
</div>
<div id="S5.SS2.SSS2.p9" class="ltx_para ltx_noindent">
<p id="S5.SS2.SSS2.p9.1" class="ltx_p">Concluding, we can say, that <span id="S5.SS2.SSS2.p9.1.1" class="ltx_text">MESAS</span> is robust against nine poisoning attacks executed by a strong adaptive adversary, who is able to intentionally circumvent all other nine evaluated defenses. We argue that any other defense, that relies on just a few metrics, could be similarly bypassed in our strong adaptive adversary model, by either fixation or constraint methods.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Defenses under Non-IID</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Here, we evaluate the same nine defenses, as specified in <a href="#S5.SS1" title="5.1. Experimental Setup and Scenarios ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></span></a>, under different <span id="S5.SS3.p1.1.1" class="ltx_text">non-IID</span> scenarios. First, we investigate classical <span id="S5.SS3.p1.1.2" class="ltx_text">intra-client</span> <span id="S5.SS3.p1.1.3" class="ltx_text">non-IID</span> before we discuss <span id="S5.SS3.p1.1.4" class="ltx_text">inter-client</span> <span id="S5.SS3.p1.1.5" class="ltx_text">non-IID</span>.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS3.p2.2" class="ltx_p"><span id="S5.SS3.p2.2.1" class="ltx_text ltx_font_bold">Intra-client</span><span id="S5.SS3.p2.2.2" class="ltx_text ltx_font_bold"> <span id="S5.SS3.p2.2.2.1" class="ltx_text">non-IID</span>.</span> We analyzed various <span id="S5.SS3.p2.2.3" class="ltx_text">intra-client</span> <span id="S5.SS3.p2.2.4" class="ltx_text">non-IID</span> settings, namely <span id="S5.SS3.p2.2.5" class="ltx_text">1-class</span>, <span id="S5.SS3.p2.2.6" class="ltx_text">2-class</span>, and Distribution <span id="S5.SS3.p2.2.7" class="ltx_text">non-IID</span>. For the <span id="S5.SS3.p2.2.8" class="ltx_text">1-class</span> and <span id="S5.SS3.p2.2.9" class="ltx_text">2-class</span> <span id="S5.SS3.p2.2.10" class="ltx_text">non-IID</span> scenarios, the samples of a client’s dataset have a focus on one or two so-called <span id="S5.SS3.p2.2.11" class="ltx_text ltx_font_italic">main labels</span>. The remaining labels contain an equivalent amount of samples, while a factor <math id="S5.SS3.p2.1.m1.2" class="ltx_Math" alttext="q\in[0,1]" display="inline"><semantics id="S5.SS3.p2.1.m1.2a"><mrow id="S5.SS3.p2.1.m1.2.3" xref="S5.SS3.p2.1.m1.2.3.cmml"><mi id="S5.SS3.p2.1.m1.2.3.2" xref="S5.SS3.p2.1.m1.2.3.2.cmml">q</mi><mo id="S5.SS3.p2.1.m1.2.3.1" xref="S5.SS3.p2.1.m1.2.3.1.cmml">∈</mo><mrow id="S5.SS3.p2.1.m1.2.3.3.2" xref="S5.SS3.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S5.SS3.p2.1.m1.2.3.3.2.1" xref="S5.SS3.p2.1.m1.2.3.3.1.cmml">[</mo><mn id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">0</mn><mo id="S5.SS3.p2.1.m1.2.3.3.2.2" xref="S5.SS3.p2.1.m1.2.3.3.1.cmml">,</mo><mn id="S5.SS3.p2.1.m1.2.2" xref="S5.SS3.p2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S5.SS3.p2.1.m1.2.3.3.2.3" xref="S5.SS3.p2.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.2b"><apply id="S5.SS3.p2.1.m1.2.3.cmml" xref="S5.SS3.p2.1.m1.2.3"><in id="S5.SS3.p2.1.m1.2.3.1.cmml" xref="S5.SS3.p2.1.m1.2.3.1"></in><ci id="S5.SS3.p2.1.m1.2.3.2.cmml" xref="S5.SS3.p2.1.m1.2.3.2">𝑞</ci><interval closure="closed" id="S5.SS3.p2.1.m1.2.3.3.1.cmml" xref="S5.SS3.p2.1.m1.2.3.3.2"><cn type="integer" id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">0</cn><cn type="integer" id="S5.SS3.p2.1.m1.2.2.cmml" xref="S5.SS3.p2.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.2c">q\in[0,1]</annotation></semantics></math> defines the fraction between the number of samples within the main label class and the remaining classes<span id="footnote20" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span>For <math id="footnote20.m1.1" class="ltx_Math" alttext="q=1" display="inline"><semantics id="footnote20.m1.1b"><mrow id="footnote20.m1.1.1" xref="footnote20.m1.1.1.cmml"><mi id="footnote20.m1.1.1.2" xref="footnote20.m1.1.1.2.cmml">q</mi><mo id="footnote20.m1.1.1.1" xref="footnote20.m1.1.1.1.cmml">=</mo><mn id="footnote20.m1.1.1.3" xref="footnote20.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote20.m1.1c"><apply id="footnote20.m1.1.1.cmml" xref="footnote20.m1.1.1"><eq id="footnote20.m1.1.1.1.cmml" xref="footnote20.m1.1.1.1"></eq><ci id="footnote20.m1.1.1.2.cmml" xref="footnote20.m1.1.1.2">𝑞</ci><cn type="integer" id="footnote20.m1.1.1.3.cmml" xref="footnote20.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote20.m1.1d">q=1</annotation></semantics></math>, all samples are from the main label. <math id="footnote20.m2.1" class="ltx_Math" alttext="q=0" display="inline"><semantics id="footnote20.m2.1b"><mrow id="footnote20.m2.1.1" xref="footnote20.m2.1.1.cmml"><mi id="footnote20.m2.1.1.2" xref="footnote20.m2.1.1.2.cmml">q</mi><mo id="footnote20.m2.1.1.1" xref="footnote20.m2.1.1.1.cmml">=</mo><mn id="footnote20.m2.1.1.3" xref="footnote20.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote20.m2.1c"><apply id="footnote20.m2.1.1.cmml" xref="footnote20.m2.1.1"><eq id="footnote20.m2.1.1.1.cmml" xref="footnote20.m2.1.1.1"></eq><ci id="footnote20.m2.1.1.2.cmml" xref="footnote20.m2.1.1.2">𝑞</ci><cn type="integer" id="footnote20.m2.1.1.3.cmml" xref="footnote20.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote20.m2.1d">q=0</annotation></semantics></math> is equal to the IID scenario.</span></span></span>. Distribution <span id="S5.SS3.p2.2.12" class="ltx_text">non-IID</span> assigns label frequencies for each dataset based on a distribution, e.g., Dirichlet <cite class="ltx_cite ltx_citemacro_citep">(Minka, <a href="#bib.bib62" title="" class="ltx_ref">2000</a>)</cite> or normal distribution. We elaborate on <span id="S5.SS3.p2.2.13" class="ltx_text">non-IID</span> simulation techniques in more detail in <a href="#A8.SS1" title="H.1. Intra-client non-IID ‣ Appendix H Assignment of Non-IID Distributions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">H.1</span></span></a>. As representative results, we present <span id="S5.SS3.p2.2.14" class="ltx_text">intra-client</span> <span id="S5.SS3.p2.2.15" class="ltx_text">non-IID</span> based on <span id="S5.SS3.p2.2.16" class="ltx_text">1-class</span> with <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mi id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml">q</mi><mo id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><eq id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1"></eq><ci id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">𝑞</ci><cn type="float" id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">q=0.5</annotation></semantics></math>.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">We notice that in <span id="S5.SS3.p3.1.1" class="ltx_text">non-IID</span> settings it is harder for the adversary to embed a backdoor due to the nature of <span id="S5.SS3.p3.1.2" class="ltx_text">FedAVG</span>. To reach a reasonable BA of above 60%, the adversary must use adaption strategies. We find that increase of PDR to 0.3 combined with scaling reaches reasonable performance with 63.66% BA (scenario  <svg id="S5.SS3.p3.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS3.p3.1.pic1.1.1.1.1.1" class="ltx_text">4</span></foreignObject></g></g></svg> in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>). Krum and <span id="S5.SS3.p3.1.3" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> erase the backdoor, but simultaneously reduce the MA immensely. However, after an adaption, we can circumvent those defenses reaching BAs of up to 90.44%, while still erasing the backdoor with <span id="S5.SS3.p3.1.4" class="ltx_text">MESAS</span>. FoolsGold is effective, but can be circumvented by adaption, while FLTrust also decreases the BA to 8,40%, but assigns weights for update aggregation between 0.0 and 0.025 to all model updates, effectively removing the influence of most of the update. <span id="S5.SS3.p3.1.5" class="ltx_text">MESAS</span> is the only defense erasing the backdoor efficiently in this setting and reaching 1.40% BA with two FPs. Hence, we can confidently say, that <span id="S5.SS3.p3.1.6" class="ltx_text">MESAS</span> outperforms other defenses in <span id="S5.SS3.p3.1.7" class="ltx_text">intra-client</span> <span id="S5.SS3.p3.1.8" class="ltx_text">non-IID</span> settings.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para ltx_noindent">
<p id="S5.SS3.p4.1" class="ltx_p"><span id="S5.SS3.p4.1.1" class="ltx_text ltx_font_bold">Inter-client</span><span id="S5.SS3.p4.1.2" class="ltx_text ltx_font_bold"> <span id="S5.SS3.p4.1.2.1" class="ltx_text">non-IID</span>.</span> To simulate even more realistic datasets, we designed the <span id="S5.SS3.p4.1.3" class="ltx_text ltx_font_italic">Random-Non-IID</span> strategy (cf. <a href="#A8.SS2" title="H.2. Inter-client non-IID ‣ Appendix H Assignment of Non-IID Distributions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">H.2</span></span></a>). Thereby, we randomly decide which label is contained in a client’s dataset and also randomly assign the label frequencies. This results in <span id="S5.SS3.p4.1.4" class="ltx_text">inter-client</span> <span id="S5.SS3.p4.1.5" class="ltx_text">non-IID</span> datasets even with disjoint data. Other works do not normally consider such scenarios in evaluations and we hope, that this strategy will be adopted in future research.</p>
</div>
<div id="S5.SS3.p5" class="ltx_para">
<p id="S5.SS3.p5.1" class="ltx_p">We report the results for a <span id="S5.SS3.p5.1.1" class="ltx_text">Random-Non-IID</span> setting<span id="footnote21" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note">21</span>The sample frequencies for each client of the scenario are listed in <a href="#A8.T23" title="Table 23 ‣ H.2. Inter-client non-IID ‣ Appendix H Assignment of Non-IID Distributions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">23</span></span></a>.</span></span></span> after 50 benign rounds of FL training with 20 clients in the federation in scenario  <svg id="S5.SS3.p5.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S5.SS3.p5.1.pic1.1.1.1.1.1" class="ltx_text">5</span></foreignObject></g></g></svg> in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>. It is very easy for an adversary to embed a backdoor in such scenarios, thus reaching a BA of 77.37% without defense, as can be seen in line 6. Among all defenses, <span id="S5.SS3.p5.1.2" class="ltx_text">MESAS</span> is the only one capable of erasing the backdoor by decreasing the BA to 2.37%, while others provide BAs between 52.75% and 89.55%.</p>
</div>
<div id="S5.SS3.p6" class="ltx_para">
<p id="S5.SS3.p6.1" class="ltx_p">We repeated this experiment in FL round one<span id="footnote22" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">22</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">22</sup><span class="ltx_tag ltx_tag_note">22</span>Early round backdoors are not persistent (cf. <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>), but we still analyzed the situation.</span></span></span> of this setting to analyze the dependence on an already converged model and within round 50 of a setting containing 100 federation clients from which 20 are selected randomly for each FL round, and got similar results with <span id="S5.SS3.p6.1.1" class="ltx_text">MESAS</span> outperforming other defenses, that do not appear to be capable of removing backdoors in <span id="S5.SS3.p6.1.2" class="ltx_text">inter-client</span> <span id="S5.SS3.p6.1.3" class="ltx_text">non-IID</span> scenarios. The detailed experiments are reported in <a href="#A6.T15" title="Table 15 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></span></a>, <a href="#A6.T16" title="Table 16 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></span></a>, <a href="#A6.T17" title="Table 17 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></span></a>, and <a href="#A6.T18" title="Table 18 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></span></a>.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Influence of Parameters on <span id="S5.SS4.1.1" class="ltx_text">MESAS</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">To evaluate the influence of various parameters on <span id="S5.SS4.p1.1.1" class="ltx_text">MESAS</span>’s performance, we first investigated training <span id="S5.SS4.p1.1.2" class="ltx_text">hyper-parameters</span> and showed the independence from random seed, LR, PMR, and the selection of <math id="S5.SS4.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS4.p1.1.m1.1a"><mi id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><ci id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">\alpha</annotation></semantics></math>. We found no unexpected results that are much different from our default scenario. We report on these experiments in <a href="#A6.SS1" title="F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">F.1</span></span></a>.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para ltx_noindent">
<p id="S5.SS4.p2.2" class="ltx_p"><span id="S5.SS4.p2.2.3" class="ltx_text ltx_font_bold">Poison Data Rate.</span> Our experiments show, that the backdoor efficiency depends on the type and composition of the trigger, but also the PDR is important. We evaluated <span id="S5.SS4.p2.1.1" class="ltx_text"><math id="S5.SS4.p2.1.1.m1.4" class="ltx_Math" alttext="pdr=[0.1,0.2,...,0.9]" display="inline"><semantics id="S5.SS4.p2.1.1.m1.4a"><mrow id="S5.SS4.p2.1.1.m1.4.5" xref="S5.SS4.p2.1.1.m1.4.5.cmml"><mrow id="S5.SS4.p2.1.1.m1.4.5.2" xref="S5.SS4.p2.1.1.m1.4.5.2.cmml"><mi id="S5.SS4.p2.1.1.m1.4.5.2.2" xref="S5.SS4.p2.1.1.m1.4.5.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p2.1.1.m1.4.5.2.1" xref="S5.SS4.p2.1.1.m1.4.5.2.1.cmml">​</mo><mi id="S5.SS4.p2.1.1.m1.4.5.2.3" xref="S5.SS4.p2.1.1.m1.4.5.2.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p2.1.1.m1.4.5.2.1a" xref="S5.SS4.p2.1.1.m1.4.5.2.1.cmml">​</mo><mi id="S5.SS4.p2.1.1.m1.4.5.2.4" xref="S5.SS4.p2.1.1.m1.4.5.2.4.cmml">r</mi></mrow><mo id="S5.SS4.p2.1.1.m1.4.5.1" xref="S5.SS4.p2.1.1.m1.4.5.1.cmml">=</mo><mrow id="S5.SS4.p2.1.1.m1.4.5.3.2" xref="S5.SS4.p2.1.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S5.SS4.p2.1.1.m1.4.5.3.2.1" xref="S5.SS4.p2.1.1.m1.4.5.3.1.cmml">[</mo><mn id="S5.SS4.p2.1.1.m1.1.1" xref="S5.SS4.p2.1.1.m1.1.1.cmml">0.1</mn><mo id="S5.SS4.p2.1.1.m1.4.5.3.2.2" xref="S5.SS4.p2.1.1.m1.4.5.3.1.cmml">,</mo><mn id="S5.SS4.p2.1.1.m1.2.2" xref="S5.SS4.p2.1.1.m1.2.2.cmml">0.2</mn><mo id="S5.SS4.p2.1.1.m1.4.5.3.2.3" xref="S5.SS4.p2.1.1.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S5.SS4.p2.1.1.m1.3.3" xref="S5.SS4.p2.1.1.m1.3.3.cmml">…</mi><mo id="S5.SS4.p2.1.1.m1.4.5.3.2.4" xref="S5.SS4.p2.1.1.m1.4.5.3.1.cmml">,</mo><mn id="S5.SS4.p2.1.1.m1.4.4" xref="S5.SS4.p2.1.1.m1.4.4.cmml">0.9</mn><mo stretchy="false" id="S5.SS4.p2.1.1.m1.4.5.3.2.5" xref="S5.SS4.p2.1.1.m1.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.1.m1.4b"><apply id="S5.SS4.p2.1.1.m1.4.5.cmml" xref="S5.SS4.p2.1.1.m1.4.5"><eq id="S5.SS4.p2.1.1.m1.4.5.1.cmml" xref="S5.SS4.p2.1.1.m1.4.5.1"></eq><apply id="S5.SS4.p2.1.1.m1.4.5.2.cmml" xref="S5.SS4.p2.1.1.m1.4.5.2"><times id="S5.SS4.p2.1.1.m1.4.5.2.1.cmml" xref="S5.SS4.p2.1.1.m1.4.5.2.1"></times><ci id="S5.SS4.p2.1.1.m1.4.5.2.2.cmml" xref="S5.SS4.p2.1.1.m1.4.5.2.2">𝑝</ci><ci id="S5.SS4.p2.1.1.m1.4.5.2.3.cmml" xref="S5.SS4.p2.1.1.m1.4.5.2.3">𝑑</ci><ci id="S5.SS4.p2.1.1.m1.4.5.2.4.cmml" xref="S5.SS4.p2.1.1.m1.4.5.2.4">𝑟</ci></apply><list id="S5.SS4.p2.1.1.m1.4.5.3.1.cmml" xref="S5.SS4.p2.1.1.m1.4.5.3.2"><cn type="float" id="S5.SS4.p2.1.1.m1.1.1.cmml" xref="S5.SS4.p2.1.1.m1.1.1">0.1</cn><cn type="float" id="S5.SS4.p2.1.1.m1.2.2.cmml" xref="S5.SS4.p2.1.1.m1.2.2">0.2</cn><ci id="S5.SS4.p2.1.1.m1.3.3.cmml" xref="S5.SS4.p2.1.1.m1.3.3">…</ci><cn type="float" id="S5.SS4.p2.1.1.m1.4.4.cmml" xref="S5.SS4.p2.1.1.m1.4.4">0.9</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.1.m1.4c">pdr=[0.1,0.2,...,0.9]</annotation></semantics></math></span> and selected the smallest value <span id="S5.SS4.p2.2.2" class="ltx_text"><math id="S5.SS4.p2.2.2.m1.1" class="ltx_Math" alttext="pdr=0.1" display="inline"><semantics id="S5.SS4.p2.2.2.m1.1a"><mrow id="S5.SS4.p2.2.2.m1.1.1" xref="S5.SS4.p2.2.2.m1.1.1.cmml"><mrow id="S5.SS4.p2.2.2.m1.1.1.2" xref="S5.SS4.p2.2.2.m1.1.1.2.cmml"><mi id="S5.SS4.p2.2.2.m1.1.1.2.2" xref="S5.SS4.p2.2.2.m1.1.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p2.2.2.m1.1.1.2.1" xref="S5.SS4.p2.2.2.m1.1.1.2.1.cmml">​</mo><mi id="S5.SS4.p2.2.2.m1.1.1.2.3" xref="S5.SS4.p2.2.2.m1.1.1.2.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p2.2.2.m1.1.1.2.1a" xref="S5.SS4.p2.2.2.m1.1.1.2.1.cmml">​</mo><mi id="S5.SS4.p2.2.2.m1.1.1.2.4" xref="S5.SS4.p2.2.2.m1.1.1.2.4.cmml">r</mi></mrow><mo id="S5.SS4.p2.2.2.m1.1.1.1" xref="S5.SS4.p2.2.2.m1.1.1.1.cmml">=</mo><mn id="S5.SS4.p2.2.2.m1.1.1.3" xref="S5.SS4.p2.2.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.2.2.m1.1b"><apply id="S5.SS4.p2.2.2.m1.1.1.cmml" xref="S5.SS4.p2.2.2.m1.1.1"><eq id="S5.SS4.p2.2.2.m1.1.1.1.cmml" xref="S5.SS4.p2.2.2.m1.1.1.1"></eq><apply id="S5.SS4.p2.2.2.m1.1.1.2.cmml" xref="S5.SS4.p2.2.2.m1.1.1.2"><times id="S5.SS4.p2.2.2.m1.1.1.2.1.cmml" xref="S5.SS4.p2.2.2.m1.1.1.2.1"></times><ci id="S5.SS4.p2.2.2.m1.1.1.2.2.cmml" xref="S5.SS4.p2.2.2.m1.1.1.2.2">𝑝</ci><ci id="S5.SS4.p2.2.2.m1.1.1.2.3.cmml" xref="S5.SS4.p2.2.2.m1.1.1.2.3">𝑑</ci><ci id="S5.SS4.p2.2.2.m1.1.1.2.4.cmml" xref="S5.SS4.p2.2.2.m1.1.1.2.4">𝑟</ci></apply><cn type="float" id="S5.SS4.p2.2.2.m1.1.1.3.cmml" xref="S5.SS4.p2.2.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.2.2.m1.1c">pdr=0.1</annotation></semantics></math></span> that allows an adversary to introduce an effective backdoor in our default scenario. This naturally makes the resulting local models most stealthy by scoring a high MA. During some experiments, we increased this value up to 0.3 to reach a high BA. For bigger PDRs, <span id="S5.SS4.p2.2.4" class="ltx_text">MESAS</span> was also able to eliminate the backdoor with ACC 100%. This highlights the adversarial dilemma, since higher PDRs could increase the BA, but are not stealthy, urging the adversary to adapt to defenses, which has side effects on the metrics of <span id="S5.SS4.p2.2.5" class="ltx_text">MESAS</span>, forcing the adversary in an even more complex MOO problem. Concluding, we can claim, that <span id="S5.SS4.p2.2.6" class="ltx_text">MESAS</span> is independent of the PDR selected by the adversary.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para ltx_noindent">
<p id="S5.SS4.p3.1" class="ltx_p"><span id="S5.SS4.p3.1.1" class="ltx_text ltx_font_bold">Initial Global Model.</span> We conducted experiments with different <span id="S5.SS4.p3.1.2" class="ltx_text">pre-trained</span> models. We used random initialized models and <span id="S5.SS4.p3.1.3" class="ltx_text">pre-trained</span> models from PyTorch <cite class="ltx_cite ltx_citemacro_citep">(The Linux Foundation, <a href="#bib.bib98" title="" class="ltx_ref">2022</a>; Paszke et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2019</a>)</cite> where we changed the first and last layer according to our dataset. We then trained the models in benign settings with 20 clients in the federation, all participating in each round as well as with 100 clients in the federation whereof 20 contributed each round. <span id="S5.SS4.p3.1.4" class="ltx_text">MESAS</span> performed well in all of the cases and can be used independently of the FL round. However, the detection performance in later rounds is naturally more accurate, since even benign clients can strive towards a different minimum on a relatively naïve model. Nevertheless, even in <span id="S5.SS4.p3.1.5" class="ltx_text">inter-client</span> <span id="S5.SS4.p3.1.6" class="ltx_text">non-IID</span> settings, <span id="S5.SS4.p3.1.7" class="ltx_text">MESAS</span> erases backdoors in early rounds reliably (cf. <a href="#A8.SS2" title="H.2. Inter-client non-IID ‣ Appendix H Assignment of Non-IID Distributions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">H.2</span></span></a>). Principally, <span id="S5.SS4.p3.1.8" class="ltx_text">MESAS</span> is designed to be applied in every FL round and does not impose a negative impact on the convergence of the federation when no attack is present. The rationale behind this lies in <span id="S5.SS4.p3.1.9" class="ltx_text">MESAS</span>’s ability to effectively distinguish between attack-free and attack scenarios by virtue of its robust statistical tests.</p>
</div>
<div id="S5.SS4.p4" class="ltx_para ltx_noindent">
<p id="S5.SS4.p4.1" class="ltx_p"><span id="S5.SS4.p4.1.1" class="ltx_text ltx_font_bold">FL Round.</span> To emphasize the effectiveness of <span id="S5.SS4.p4.1.2" class="ltx_text">MESAS</span>, we conducted additional experiments where models were trained starting from a randomly initialized model for 100 rounds until the model converged and the defenses are applied after every training round. We visualize the performance of various defense mechanisms, as well as scenarios with no defense and no attack in <a href="#A6.F13" title="Figure 13 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></span></a> and <a href="#A6.F14" title="Figure 14 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></span></a>. Notably, the results demonstrate that <span id="S5.SS4.p4.1.3" class="ltx_text">MESAS</span> surpasses other defense approaches by reaching BA and MA levels comparable to the attack-free scenario. This underscores the robustness of <span id="S5.SS4.p4.1.4" class="ltx_text">MESAS</span> in mitigating the impact of backdoor attacks.</p>
</div>
<div id="S5.SS4.p5" class="ltx_para ltx_noindent">
<p id="S5.SS4.p5.1" class="ltx_p"><span id="S5.SS4.p5.1.1" class="ltx_text ltx_font_bold">Dataset.</span> We exchanged the dataset of our default scenario to MNIST <cite class="ltx_cite ltx_citemacro_citep">(Deng, <a href="#bib.bib24" title="" class="ltx_ref">2012</a>)</cite> and GTSRB <cite class="ltx_cite ltx_citemacro_citep">(Stallkamp et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2012</a>)</cite> and could assert, that the experimental results and thus the performance of the defenses including <span id="S5.SS4.p5.1.2" class="ltx_text">MESAS</span> does not vary across datasets. MNIST as a more basic dataset, simplifies the detection of backdoors for all defenses even if a stealthy backdoor itself is hard to implement without defense, whereas GTSRB is more complex due to more label classes. We report the results for one of our MNIST experiments in <a href="#A6.T21" title="Table 21 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">21</span></span></a> with one FP and one GTSRB experiment in <a href="#A6.T22" title="Table 22 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">22</span></span></a> with 100% ACC.</p>
</div>
<div id="S5.SS4.p6" class="ltx_para ltx_noindent">
<p id="S5.SS4.p6.1" class="ltx_p"><span id="S5.SS4.p6.1.1" class="ltx_text ltx_font_bold">Model Architecture.</span> We conducted experiments to analyze the independence from model architectures. Therefore, we used a CNN with two convolutional layers concatenated with pooling layers and ReLu functions <cite class="ltx_cite ltx_citemacro_citep">(Agarap, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite> followed by three fully connected layers and trained on MNIST <cite class="ltx_cite ltx_citemacro_citep">(Deng, <a href="#bib.bib24" title="" class="ltx_ref">2012</a>)</cite>. Further, we tested SqueezeNet <cite class="ltx_cite ltx_citemacro_citep">(Iandola et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2016</a>)</cite> with <span id="S5.SS4.p6.1.2" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite> and can report 100% TNs with just one FN in both cases (cf. <a href="#A6.T19" title="Table 19 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></span></a> and <a href="#A6.T20" title="Table 20 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">App. Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">20</span></span></a>). Hence, we can claim, that <span id="S5.SS4.p6.1.3" class="ltx_text">MESAS</span> is independent from the architecture of the model.</p>
</div>
<div id="S5.SS4.p7" class="ltx_para ltx_noindent">
<p id="S5.SS4.p7.1" class="ltx_p"><span id="S5.SS4.p7.1.1" class="ltx_text ltx_font_bold">Application Domain.</span> We conducted experiments within the text domain training a sentiment analysis task using the <span id="S5.SS4.p7.1.2" class="ltx_text">SST-2</span> <cite class="ltx_cite ltx_citemacro_citep">(Socher et al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2013</a>)</cite> dataset on a DistilBERT <cite class="ltx_cite ltx_citemacro_citep">(Sanh et al<span class="ltx_text">.</span>, <a href="#bib.bib85" title="" class="ltx_ref">2020</a>)</cite> transformer model. We implemented a targeted poisoning attack, that labels sentences starting with the term <span id="S5.SS4.p7.1.3" class="ltx_text ltx_inline-quote ltx_outerquote">“Hey!”</span> as negative. We can report 100% ACC in this experiment, showing the applicability of <span id="S5.SS4.p7.1.4" class="ltx_text">MESAS</span> in different application domains and for model architectures that do not contain convolutional layers.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>. </span><span id="S5.T3.3.2" class="ltx_text" style="font-size:90%;">Defense runtimes in seconds.</span></figcaption>
<table id="S5.T3.4" class="ltx_tabular ltx_align_middle">
<tr id="S5.T3.4.1" class="ltx_tr">
<td id="S5.T3.4.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Defense</td>
<td id="S5.T3.4.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">Runtime</td>
<td id="S5.T3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Defense</td>
<td id="S5.T3.4.1.4" class="ltx_td ltx_align_center ltx_border_tt">Runtime</td>
</tr>
<tr id="S5.T3.4.2" class="ltx_tr">
<td id="S5.T3.4.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.4.2.1.1" class="ltx_text">FedAVG</span></td>
<td id="S5.T3.4.2.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">0.12</td>
<td id="S5.T3.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="S5.T3.4.2.4" class="ltx_td ltx_align_center ltx_border_t">7.92</td>
</tr>
<tr id="S5.T3.4.3" class="ltx_tr">
<td id="S5.T3.4.3.1" class="ltx_td ltx_align_center ltx_border_r">Naïve Clustering</td>
<td id="S5.T3.4.3.2" class="ltx_td ltx_align_center ltx_border_rr">7.57</td>
<td id="S5.T3.4.3.3" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T3.4.3.4" class="ltx_td ltx_align_center">7.12</td>
</tr>
<tr id="S5.T3.4.4" class="ltx_tr">
<td id="S5.T3.4.4.1" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S5.T3.4.4.2" class="ltx_td ltx_align_center ltx_border_rr">0.14</td>
<td id="S5.T3.4.4.3" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T3.4.4.4" class="ltx_td ltx_align_center">0.26</td>
</tr>
<tr id="S5.T3.4.5" class="ltx_tr">
<td id="S5.T3.4.5.1" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="S5.T3.4.5.2" class="ltx_td ltx_align_center ltx_border_rr">6.02</td>
<td id="S5.T3.4.5.3" class="ltx_td ltx_align_center ltx_border_r">Auror <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2016</a>)</cite>
</td>
<td id="S5.T3.4.5.4" class="ltx_td ltx_align_center">12 hours</td>
</tr>
<tr id="S5.T3.4.6" class="ltx_tr">
<td id="S5.T3.4.6.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T3.4.6.1.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="S5.T3.4.6.2" class="ltx_td ltx_align_center ltx_border_rr">5.92</td>
<td id="S5.T3.4.6.3" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S5.T3.4.6.4" class="ltx_td ltx_align_center">25.12</td>
</tr>
<tr id="S5.T3.4.7" class="ltx_tr">
<td id="S5.T3.4.7.1" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T3.4.7.2" class="ltx_td ltx_align_center ltx_border_rr">2.37</td>
<td id="S5.T3.4.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.4.7.3.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="S5.T3.4.7.4" class="ltx_td ltx_align_center">24.37</td>
</tr>
<tr id="S5.T3.4.8" class="ltx_tr">
<td id="S5.T3.4.8.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="S5.T3.4.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr">2.52</td>
<td id="S5.T3.4.8.3" class="ltx_td ltx_border_bb ltx_border_r"></td>
<td id="S5.T3.4.8.4" class="ltx_td ltx_border_bb"></td>
</tr>
</table>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5. </span>Runtime Evaluation</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">We evaluate the runtime of the different defenses to verify the <span id="S5.SS5.p1.1.1" class="ltx_text">real-world</span> applicability of <span id="S5.SS5.p1.1.2" class="ltx_text">MESAS</span>. <a href="#S5.T3" title="Table 3 ‣ 5.4. Influence of Parameters on MESAS ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></span></a> lists the average runtimes of ten runs for our default scenario and shows that <span id="S5.SS5.p1.1.3" class="ltx_text">MESAS</span> introduces an acceptable overhead of 24.37 seconds. Note, that FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> comes along with outstanding performance since only one model layer is analyzed, but due to the same reason it can be easily circumvented by an attacker (cf. <a href="#S5.SS2" title="5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></span></a>). Further, <span id="S5.SS5.p1.1.4" class="ltx_text">T-Median</span> <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite> replaces <span id="S5.SS5.p1.1.5" class="ltx_text">FedAVG</span> with a simple algorithm, which results in similar runtime, but also reduces the MA. Auror <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2016</a>)</cite> instead, has an unacceptable runtime of 12 hours to calculate the indicative features due to massive clustering, which is why we excluded this approach from evaluations in <a href="#S5" title="5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></span></a>. FLTrust’s <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> runtime is dependent on the size of the trusted dataset, as a trusted model is trained on the server side. Defenses leveraging client feedback <cite class="ltx_cite ltx_citemacro_citep">(Andreina et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>; Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib119" title="" class="ltx_ref">2021</a>)</cite> cannot compete to <span id="S5.SS5.p1.1.6" class="ltx_text">server-side-only</span> defenses, since additional communication overhead is introduced.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Discussion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We discuss alternative adaption methods that were tested in <a href="#S6.SS1" title="6.1. Adversarial Adaption Methodologies ‣ 6. Discussion ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></span></a> followed by limitations and future work suggestions in <a href="#S6.SS2" title="6.2. Limitations and Future Work ‣ 6. Discussion ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></span></a>.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Adversarial Adaption Methodologies</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Besides the final method of our strong adaptive adversary (cf. <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>) that we used to evaluate FL defenses in <a href="#S5.SS2" title="5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">sect<span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></span></a>, multiple alternatives have been tested during this work. This section lists and discusses the approaches inferior to our final choice.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.5" class="ltx_p">First, we just added all of the losses (<math id="S6.SS1.p2.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S6.SS1.p2.1.m1.1a"><mi id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><ci id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">\lambda</annotation></semantics></math>’s from <a href="#S3.E2" title="In 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a> equal to one), which is similar to an classic adaptive adversary (cf. <a href="#S2.SS2" title="2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></span></a>). As already explained in <a href="#S5.SS2" title="5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></span></a>, losses with a drastically smaller scale than others have barley influence in the optimization, thus the related metric is not adapted. Second, we tried to scale all losses to <math id="S6.SS1.p2.2.m2.1" class="ltx_Math" alttext="Loss" display="inline"><semantics id="S6.SS1.p2.2.m2.1a"><mrow id="S6.SS1.p2.2.m2.1.1" xref="S6.SS1.p2.2.m2.1.1.cmml"><mi id="S6.SS1.p2.2.m2.1.1.2" xref="S6.SS1.p2.2.m2.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p2.2.m2.1.1.1" xref="S6.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="S6.SS1.p2.2.m2.1.1.3" xref="S6.SS1.p2.2.m2.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p2.2.m2.1.1.1a" xref="S6.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="S6.SS1.p2.2.m2.1.1.4" xref="S6.SS1.p2.2.m2.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p2.2.m2.1.1.1b" xref="S6.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="S6.SS1.p2.2.m2.1.1.5" xref="S6.SS1.p2.2.m2.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.2.m2.1b"><apply id="S6.SS1.p2.2.m2.1.1.cmml" xref="S6.SS1.p2.2.m2.1.1"><times id="S6.SS1.p2.2.m2.1.1.1.cmml" xref="S6.SS1.p2.2.m2.1.1.1"></times><ci id="S6.SS1.p2.2.m2.1.1.2.cmml" xref="S6.SS1.p2.2.m2.1.1.2">𝐿</ci><ci id="S6.SS1.p2.2.m2.1.1.3.cmml" xref="S6.SS1.p2.2.m2.1.1.3">𝑜</ci><ci id="S6.SS1.p2.2.m2.1.1.4.cmml" xref="S6.SS1.p2.2.m2.1.1.4">𝑠</ci><ci id="S6.SS1.p2.2.m2.1.1.5.cmml" xref="S6.SS1.p2.2.m2.1.1.5">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.2.m2.1c">Loss</annotation></semantics></math><sup id="S6.SS1.p2.5.1" class="ltx_sup"><span id="S6.SS1.p2.5.1.1" class="ltx_text ltx_font_italic">MA/BA</span></sup>, which would be reasonable, it the MA would be the major concern of <math id="S6.SS1.p2.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S6.SS1.p2.4.m4.1a"><mi id="S6.SS1.p2.4.m4.1.1" xref="S6.SS1.p2.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.4.m4.1b"><ci id="S6.SS1.p2.4.m4.1.1.cmml" xref="S6.SS1.p2.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.4.m4.1c">A</annotation></semantics></math>. However, most defenses including <span id="S6.SS1.p2.5.2" class="ltx_text">MESAS</span> do not check the MA since no test dataset is available in realistic scenarios, which makes scaling to the maximum the better choice for the adversary. Third, we tested, how often the <math id="S6.SS1.p2.5.m5.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S6.SS1.p2.5.m5.1a"><mi id="S6.SS1.p2.5.m5.1.1" xref="S6.SS1.p2.5.m5.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.5.m5.1b"><ci id="S6.SS1.p2.5.m5.1.1.cmml" xref="S6.SS1.p2.5.m5.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.5.m5.1c">\lambda</annotation></semantics></math>’s should be recalculated and found, that only one initial computation delivers the best results. This seems reasonable, since with this setting, already optimized metrics have a minimal loss value and thus barley influence in the optimization.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">Additionally, motivated by Multi-Objective <span id="S6.SS1.p3.1.1" class="ltx_text">Optimization (MOO)</span> research, we tried to find a pareto optimal <cite class="ltx_cite ltx_citemacro_citep">(Censor, <a href="#bib.bib15" title="" class="ltx_ref">1977</a>)</cite> solution with the method of Sener <em id="S6.SS1.p3.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_citep">(Sener and Koltun, <a href="#bib.bib86" title="" class="ltx_ref">2018</a>)</cite> based on the MGDA algroithm <cite class="ltx_cite ltx_citemacro_citep">(Désidéri, <a href="#bib.bib25" title="" class="ltx_ref">2009</a>)</cite>. However, the method did not work and produced broken models regarding the accuracies. We belief, that the reason for this is, that Sener <em id="S6.SS1.p3.1.3" class="ltx_emph ltx_font_italic">et al.</em> consider a system comparable to Multi-Task <span id="S6.SS1.p3.1.4" class="ltx_text">Learning (MTL)</span> where both, shared and <span id="S6.SS1.p3.1.5" class="ltx_text">task-specific</span> parameters exist within the model. However, our MOO problem optimizes only shared parameters (the whole model).</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.1" class="ltx_p">Since our final adaption method is superior to classic adaption <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> from <a href="#S2.E1" title="In 2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, we claim, that <span id="S6.SS1.p4.1.1" class="ltx_text">MESAS</span> is robust against adaptive adversaries caused by the introduced adversarial dilemma by forcing the adversary into a MOO problem with seven losses of different scales.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Limitations and Future Work</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The major limitation of <span id="S6.SS2.p1.1.1" class="ltx_text">MESAS</span> is, that the significance niveau for the statistical tests is relevant for a good TPR and TNR. Throughout our experiment, the values appeared to be just dependent on the data scenario. Nevertheless, it can be necessary in so far unseen tasks to adapt the values. Therefore, an automatic methodology for setting the values can be discovered in future work.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">As any other poisoning defense for FL, <span id="S6.SS2.p2.1.1" class="ltx_text">MESAS</span> can be tested against other aggregation mechanisms besides <span id="S6.SS2.p2.1.2" class="ltx_text">FedAVG</span> and can be combined with IR methods, similar as in FLAME <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite> and DeepSight <cite class="ltx_cite ltx_citemacro_citep">(Rieger et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>)</cite>. With such an extension one can soften the significance thresholds to lower the FNR to zero and simultaneously reduce the influence of the models responsible for the resulting FPR.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">We leverage COUNT (combined with COS and EUCL) to get the direction of the model update. Fortunately, the metric is hard to adapt due to the sign function involved in the computation. Nevertheless, other metrics with the same effect can be discovered in the future. Additionally, one can investigate into the Cosine distance of the client updates among each other instead of the Cosine distance with respect to the global model <math id="S6.SS2.p3.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="S6.SS2.p3.1.m1.1a"><msup id="S6.SS2.p3.1.m1.1.1" xref="S6.SS2.p3.1.m1.1.1.cmml"><mi id="S6.SS2.p3.1.m1.1.1.2" xref="S6.SS2.p3.1.m1.1.1.2.cmml">G</mi><mi id="S6.SS2.p3.1.m1.1.1.3" xref="S6.SS2.p3.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S6.SS2.p3.1.m1.1b"><apply id="S6.SS2.p3.1.m1.1.1.cmml" xref="S6.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S6.SS2.p3.1.m1.1.1.1.cmml" xref="S6.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S6.SS2.p3.1.m1.1.1.2.cmml" xref="S6.SS2.p3.1.m1.1.1.2">𝐺</ci><ci id="S6.SS2.p3.1.m1.1.1.3.cmml" xref="S6.SS2.p3.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p3.1.m1.1c">G^{r}</annotation></semantics></math>, which could provide additional information about the direction.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">As shown in our experiments, the strong adaptive adversary from <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a> cannot circumvent <span id="S6.SS2.p4.1.1" class="ltx_text">MESAS</span>. Nevertheless, research can be conducted to find currently unknown methods to better adapt a DNN to multiple metrics simultaneously, which falls in the area of MOO. If such an method exists, <span id="S6.SS2.p4.1.2" class="ltx_text">MESAS</span> can be extended to e.g. investigate in the correlation coefficient between updates additionally.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Related Work</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this section, we first discuss existing poisoning defenses in <a href="#S7.SS1" title="7.1. Defenses against Poisoning Attacks ‣ 7. Related Work ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">7.1</span></span></a>, before we address privacy issues in <a href="#S7.SS2" title="7.2. Privacy Preserving Federated Learning ‣ 7. Related Work ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">7.2</span></span></a>.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Defenses against Poisoning Attacks</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">Auror <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2016</a>)</cite> is a K-Means <cite class="ltx_cite ltx_citemacro_citep">(Ahmed et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> clustering approach based on indicative differences between individual model parameters. It decides for each parameter if it is indicative for clustering the model updates into a benign and a malicious group and analyzes the resulting clusters. Due to multiple clustering steps (increasing with bigger model architectures), the defense suffers a high runtime overhead. Further, Auror has problems finding multiple backdoors simultaneously and shows poor performance in <span id="S7.SS1.p1.1.1" class="ltx_text">non-IID</span> settings. <span id="S7.SS1.p1.1.2" class="ltx_text">MESAS</span> utilizes a lightweight feature extractor and prunes different poisonings in an iterative process independent of the data distributions.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> weights each local model’s contribution, by analyzing the <span id="S7.SS1.p2.1.1" class="ltx_text">cross-wise</span> Cosine distances between model updates of the last DNN layer, thus being prone to adaptive adversaries that fixate this layer. Further, the approach assumes only <span id="S7.SS1.p2.1.2" class="ltx_text">non-IID</span> settings and poisoned local models that point in the same directions (so-called sybills) and it leverages updates from previous rounds for optimal performance. Instead, <span id="S7.SS1.p2.1.3" class="ltx_text">MESAS</span> prevents adaption by relying on a metric cascade and analyzing layers individually and is effective in IID and <span id="S7.SS1.p2.1.4" class="ltx_text">non-IID</span> settings independent of the FL round.</p>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> is based on the Euclidean distance between local models. For each local model, it aggregates the distances to its neighbors and selects the one with the densest surrounding as new global model. <span id="S7.SS1.p3.1.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> selects more models simultaneously. Both can be circumvented by adaption to the metric and naturally suffer a high FNR without any adversaries in the system. <span id="S7.SS1.p3.1.2" class="ltx_text">MESAS</span> does not harm the federation in total benign scenarios and provides a low FNR while not being susceptible for adaption attempts.</p>
</div>
<div id="S7.SS1.p4" class="ltx_para">
<p id="S7.SS1.p4.1" class="ltx_p">AFA <cite class="ltx_cite ltx_citemacro_citep">(Muñoz-González et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2019</a>)</cite> leverages plain analysis of the Cosine distance between local models, which is adaptable with an additional loss. <span id="S7.SS1.p4.1.1" class="ltx_text">MESAS</span> hardens this possibility by leveraging a cascade of six metrics.</p>
</div>
<div id="S7.SS1.p5" class="ltx_para">
<p id="S7.SS1.p5.1" class="ltx_p">Naïve clustering approaches, e.g. based on HDBSCAN <cite class="ltx_cite ltx_citemacro_citep">(McInnes et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2017</a>)</cite>, need to extract a metric like the Cosine distance between models from the local models to reduce the dimensions. Hence, adaptive adversaries can circumvent the defenses, which is harder in <span id="S7.SS1.p5.1.1" class="ltx_text">MESAS</span>. Further, clustering relies on a majority assumption and creates two groups, thus having a hard threshold and a high FNR in settings without attacks. <span id="S7.SS1.p5.1.2" class="ltx_text">MESAS</span> leverages statistical tests with probabilistic thresholds that adapt to the scenario and investigates metrics that are hard to adapt due to <span id="S7.SS1.p5.1.3" class="ltx_text">fine-grained</span> values resulting in lower scale adaption losses than typical clustering metrics.</p>
</div>
<div id="S7.SS1.p6" class="ltx_para">
<p id="S7.SS1.p6.1" class="ltx_p">BaFFLe <cite class="ltx_cite ltx_citemacro_citep">(Andreina et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> first aggregates all local models to a new global model (thus being an IR approach) and then sets up a client feedback loop, where the previous and the new global models are sent to validation clients introducing communication overhead. Those clients analyze the <span id="S7.SS1.p6.1.1" class="ltx_text">per-label</span> MA and mark the new model as malicious if an empirically chosen threshold is violated. If so, the whole round is discarded. Further, the first 800 rounds are assumed as benign, so that a valid global model is available as a reference. Since adversaries strive to an inconspicuous MA (see <a href="#S2.SS2" title="2.2. Poisoning Attacks in Federated Learning ‣ 2. Background ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></span></a>), this approach fails for sophisticated adversaries. Further, one single adversary can force the defense to discard all other benign contributions of the round. <span id="S7.SS1.p6.1.2" class="ltx_text">MESAS</span> runs on the server side only, prunes poisoned models, and is effective even in the first round of FL. Similarly to BaFFLe, the approach of Zhao <em id="S7.SS1.p6.1.3" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib119" title="" class="ltx_ref">2021</a>)</cite> leverages a client feedback loop to analyze the MA of the local models on the client side, thus introducing an even bigger communication overhead, while keeping the downsides regarding inconspicuous MAs. Further, this approach is prone to privacy issues, since inference attacks (cf. <a href="#S7.SS2" title="7.2. Privacy Preserving Federated Learning ‣ 7. Related Work ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">7.2</span></span></a>) can be conducted on the local models on the client side.</p>
</div>
<div id="S7.SS1.p7" class="ltx_para">
<p id="S7.SS1.p7.1" class="ltx_p">FLAME <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite> is a combination of DF and IR. The approach clusters local models by pairwise Cosine distances via HDBSCAN <cite class="ltx_cite ltx_citemacro_citep">(McInnes et al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2017</a>)</cite> and filters adversaries based on the majority assumption before differential privacy methods <cite class="ltx_cite ltx_citemacro_citep">(Dwork, <a href="#bib.bib26" title="" class="ltx_ref">2008</a>)</cite> are leveraged. Precisely, weight clipping (regarding the median Euclidean distance of the updates) is applied to the remaining local models, and noise is added to the aggregated model. Besides the desired decrease in BA, this step naturally decreases the MA, too. When adapting to the Cosine and Euclidean distance simultaneously, the approach performs similarly to a plain noising mechanism <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite>, which can also be applied to any other DF. <span id="S7.SS1.p7.1.1" class="ltx_text">MESAS</span> leverages six metrics to harden the adversarial dilemma during adaption attempts and does not solely rely on clustering, but on statistical tests allowing a more fine-grained analysis of the local models. Further, any IR approach can be combined with the defense easily, but <span id="S7.SS1.p7.1.2" class="ltx_text">MESAS</span> does not decrease the MA naturally.</p>
</div>
<div id="S7.SS1.p8" class="ltx_para">
<p id="S7.SS1.p8.1" class="ltx_p">Similar to the concept of Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>, Yin <em id="S7.SS1.p8.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite> uses the <span id="S7.SS1.p8.1.2" class="ltx_text">coordinate-wise</span> median or mean of the local models to construct the new global model based on the majority assumption. These approaches called <span id="S7.SS1.p8.1.3" class="ltx_text">Trimmed-Mean</span> and <span id="S7.SS1.p8.1.4" class="ltx_text">Trimmed-Median</span> respectively are RA mechanisms, but reduce the MA compared to <span id="S7.SS1.p8.1.5" class="ltx_text">FedAVG</span>. Especially, the parameters and thus the functionality of benign model models lying not centrally within all updates not be considered. Bagdasaryan <em id="S7.SS1.p8.1.6" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> and Sun <em id="S7.SS1.p8.1.7" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite> already proposed update clipping and nosing techniques, but Naseri <em id="S7.SS1.p8.1.8" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_citep">(Naseri et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2022</a>)</cite> showed, that differential privacy methods not only naturally harm the MA <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>, but also can boost the BA when applied to benign FL clients. All of the IR approaches and most RA methods suffer a drop in MA, especially in a setting without attack. <span id="S7.SS1.p8.1.9" class="ltx_text">MESAS</span> instead, filters poisoned models, and thus does not influence benign scenarios naturally. Further, IR and RA methods can be easily combined with <span id="S7.SS1.p8.1.10" class="ltx_text">MESAS</span> to get an even more bulletproof global model.</p>
</div>
<div id="S7.SS1.p9" class="ltx_para">
<p id="S7.SS1.p9.1" class="ltx_p">DeepSight <cite class="ltx_cite ltx_citemacro_citep">(Rieger et al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2022</a>)</cite> is a more complex strategy, which combines filtering with differential privacy and is based on two metrics. First, the Cosine distance between models, which can be adapted by an additional loss (cf. <a href="#S5.SS2" title="5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></span></a>). Second, two more values are extracted from the output layer, which can be circumvented by fixation, as shown for FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> in <a href="#S5.SS2.SSS1" title="5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.1</span></span></a>. Therefore, DeepSight is not robust against strong adaptive adversaries and relies on clipping and noising techniques, that reduce the MA and can also be applied to any DF approach. <span id="S7.SS1.p9.1.1" class="ltx_text">MESAS</span> instead forces the adversary into a hard optimization problem and does not rely on specific layers.</p>
</div>
<div id="S7.SS1.p10" class="ltx_para">
<p id="S7.SS1.p10.1" class="ltx_p">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> assigns weights to updates during aggregation, essentially filtering out updates with a weight of 0. To determine the weights, it assumes a benign dataset on the server side for a trusted reference model and relies on Cosine Similarity between the updates from the client side and the trusted update as well as the norm of the local updates. However, FLTrust’s reliance on those two metrics makes it susceptible to adaptability by adaptive adversaries. Since FLTrust examines the metric across the entire update, it
may also fail to detect attacks that manifest only at the layer-wise level. In contrast, <span id="S7.SS1.p10.1.1" class="ltx_text">MESAS</span> operates independently without a trusted dataset, conducting layer-wise analysis and utilizing multiple interconnected metrics, enhancing <span id="S7.SS1.p10.1.2" class="ltx_text">MESAS</span>’s robustness against a broader range of adversarial attacks.</p>
</div>
<div id="S7.SS1.p11" class="ltx_para">
<p id="S7.SS1.p11.1" class="ltx_p">FLDetector <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2022</a>)</cite> is a historical update-based defense. It maintains records of global and client updates, predicting client updates using mathematical approximations. These predictions are compared to actual updates. After a warmup phase, outliers are detected using clustering methods by evaluating the normed Euclidean distance between predicted and actual models. However, FLDetector is storage and runtime intensive, depending on historical update time windows. In contrast, <span id="S7.SS1.p11.1.1" class="ltx_text">MESAS</span> doesn’t rely on historical updates and doesn’t need a warmup phase. This characteristic makes <span id="S7.SS1.p11.1.2" class="ltx_text">MESAS</span> more versatile and advantageous over FLDetector.</p>
</div>
<div id="S7.SS1.p12" class="ltx_para">
<p id="S7.SS1.p12.1" class="ltx_p">BayBFed <cite class="ltx_cite ltx_citemacro_citep">(Kumari et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite> constructs a statistical model of update parameter distributions for each client update, which adapts with each FL round. Using clustering, a single value per update is computed, which are then used to construct a filtering threshold based on the values’ mean that allows model filtering. However, BayBFed wasn’t tested in an all-benign scenario, potentially causing a high FPR due to benign model filtering. In contrast, <span id="S7.SS1.p12.1.1" class="ltx_text">MESAS</span> avoids the introduction of a hard value threshold. Instead, it leverages statistical tests, ensuring a low FPR even in scenarios without any attacks.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Privacy Preserving Federated Learning</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">FL in its original form <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>)</cite> improved the privacy of collaborated DNN training compared to a <span id="S7.SS2.p1.1.1" class="ltx_text">data-centralized</span>, since raw sensitive data do not leave the client side anymore. Nevertheless, membership inference <cite class="ltx_cite ltx_citemacro_citep">(Hayes et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2019</a>; Shokri et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2017</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022b</a>; Pyrgelis et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2018</a>; Shokri et al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2017</a>)</cite>, label inference <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib118" title="" class="ltx_ref">2020</a>)</cite>, property inference <cite class="ltx_cite ltx_citemacro_citep">(Ganju et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite>, model extraction <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2022b</a>)</cite>, and data reconstruction <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2019a</a>; Salem et al<span class="ltx_text">.</span>, <a href="#bib.bib84" title="" class="ltx_ref">2020</a>)</cite> attacks as well as others <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2019b</a>)</cite> can be conducted on both, mainly the local models but also on the global model. Therefore, especially the devices with access to the local models, namely the aggregation server, still needs to be trusted (cf. <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>).</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">PPFL <cite class="ltx_cite ltx_citemacro_citep">(Mo et al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2021</a>)</cite> ported the FL process into a Trusted Execution Environment (TEE). The approach assumes the availability of a TEE on the client side and introduces computational overhead, since execution speed in e.g. SGX <cite class="ltx_cite ltx_citemacro_citep">(Costan and Devadas, <a href="#bib.bib20" title="" class="ltx_ref">2016</a>)</cite> enclaves is reduced, mainly due to page swaps based on limited memory. Additionally, such approaches based on secure code execution <cite class="ltx_cite ltx_citemacro_citep">(Quoc et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2020</a>; Volos et al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2018</a>; Zhu et al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2019</a>; Tramer and Boneh, <a href="#bib.bib100" title="" class="ltx_ref">2019</a>; Ozga et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2021</a>)</cite> either on CPU only or on CPU and GPU hinder model poisoning attacks on the client side, but do not prevent data poisoning.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">On the server side, Hashemi <em id="S7.SS2.p3.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_citep">(Hashemi et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite> implemented Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> in a TEE. Such a secure aggregation method solves privacy issues allowing the threat model to exclude the aggregation server <math id="S7.SS2.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S7.SS2.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S7.SS2.p3.1.m1.1.1" xref="S7.SS2.p3.1.m1.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p3.1.m1.1b"><ci id="S7.SS2.p3.1.m1.1.1.cmml" xref="S7.SS2.p3.1.m1.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p3.1.m1.1c">\mathcal{S}</annotation></semantics></math> as trusted party. Implementing <span id="S7.SS2.p3.1.2" class="ltx_text">MESAS</span> within a TEE is just a technical barrier. Though, additional privacy results in increased runtime.</p>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.1" class="ltx_p">Overall we conclude, that <span id="S7.SS2.p4.1.1" class="ltx_text">MESAS</span> is complementary to privacy-preserving FL techniques.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Conclusion</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Adversarial adaption to defenses and complicated data scenarios are the two major challenges when it comes to Federated Learning (FL). To highlight the necessity to investigate these problems, we evaluate nine against a <span id="S8.p1.1.1" class="ltx_text ltx_font_italic">strong adaptive adversary</span> that is able to poison the dataset, constraint the learning process, fixate model parameters, scale model updates, and select between nine different poisoning methods. Further, we analyze defense efficiencies without any assumption about the sample frequencies within the client datasets, which we call <span id="S8.p1.1.2" class="ltx_text ltx_font_italic">inter-client</span><span id="S8.p1.1.3" class="ltx_text ltx_font_italic"> <span id="S8.p1.1.3.1" class="ltx_text">non-IID</span></span>. We show, that by leveraging adaption methods, existing defenses can be circumvented and are also ineffective in realistic data scenarios.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">Hence, we propose <span id="S8.p2.1.1" class="ltx_text"><span id="S8.p2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">M</span><span id="S8.p2.1.1.2" class="ltx_text ltx_framed ltx_framed_underline">e</span>tric-Ca<span id="S8.p2.1.1.3" class="ltx_text ltx_framed ltx_framed_underline">s</span>c<span id="S8.p2.1.1.4" class="ltx_text ltx_framed ltx_framed_underline">a</span>de<span id="S8.p2.1.1.5" class="ltx_text ltx_framed ltx_framed_underline">s</span></span> (<span id="S8.p2.1.2" class="ltx_text">MESAS</span>), a filtering defense against poisoning attacks in FL running on the server side. It extracts multiple metrics from the locally trained models, making the defense robust against strong adaptive adversaries, and reliably detects poisoned contributions by leveraging statistical tests with no hard value threshold, which enables application independence. <span id="S8.p2.1.3" class="ltx_text">MESAS</span> prunes poisoned models in an iterative process, allowing removal of different poisonings within one FL round.</p>
</div>
<div id="S8.p3" class="ltx_para">
<p id="S8.p3.1" class="ltx_p">We are the first to evaluate defenses under <span id="S8.p3.1.1" class="ltx_text">inter-client</span> <span id="S8.p3.1.2" class="ltx_text">non-IID</span> data scenarios and show that <span id="S8.p3.1.3" class="ltx_text">MESAS</span> outperforms existing defenses in such <span id="S8.p3.1.4" class="ltx_text">real-world</span> settings while only introducing a low computational overhead of 24.37 seconds on average.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarap (2018)</span>
<span class="ltx_bibblock">
Abien Fred Agarap. 2018.

</span>
<span class="ltx_bibblock">Deep Learning using Rectified Linear Units (ReLU).

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.08375</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmed et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mohiuddin Ahmed, Raihan Seraj, and Syed Mohammed Shamsul Islam. 2020.

</span>
<span class="ltx_bibblock">The k-means Algorithm: A Comprehensive Survey and Performance Evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Electronics</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andreina et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sebastien Andreina, Giorgia Azzurra Marson, Helen Möllering, and Ghassan Karame. 2021.

</span>
<span class="ltx_bibblock">BaFFLe: Backdoor Detection via Feedback-based Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">ICDCS</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan and Shmatikov (2021)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan and Vitaly Shmatikov. 2021.

</span>
<span class="ltx_bibblock">Blind Backdoors in Deep Learning Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">USENIX Security</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. 2020.

</span>
<span class="ltx_bibblock">How To Backdoor Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">AISTATS</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bansal et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Shefali Bansal, Medha Singh, Madhulika Bhadauria, and Richa Adalakha. 2022.

</span>
<span class="ltx_bibblock">Federated Learning Approach towards Sentiment Analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">ICTACS</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagoji et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo. 2019.

</span>
<span class="ltx_bibblock">Analyzing Federated Learning through an Adversarial Lens.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">ICML</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biggio et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Battista Biggio, Blaine Nelson, and Pavel Laskov. 2012.

</span>
<span class="ltx_bibblock">Poisoning Attacks against Support Vector Machine.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">ICML</em> (2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanchard et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. 2017.

</span>
<span class="ltx_bibblock">Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">NIPS</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boucher et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Nicholas Boucher, Ilia Shumailov, Ross Anderson, and Nicolas Papernot. 2022.

</span>
<span class="ltx_bibblock">Bad characters: Imperceptible NLP attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">IEEE S&amp;P</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">California State Legislature (2018)</span>
<span class="ltx_bibblock">
California State Legislature. 2018.

</span>
<span class="ltx_bibblock">California Consumer Privacy Act.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Di Cao, Shan Chang, Zhijian Lin, Guohua Liu, and Donghong Sun. 2019.

</span>
<span class="ltx_bibblock">Understanding Distributed Poisoning Attack in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">ICPADS</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xiaoyu Cao, Minghong Fang, Jia Liu, and Neil Zhenqiang Gong. 2021.

</span>
<span class="ltx_bibblock">FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">NDSS</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Censor (1977)</span>
<span class="ltx_bibblock">
Yair Censor. 1977.

</span>
<span class="ltx_bibblock">Pareto optimality in multiobjective problems.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Applied Mathematics and Optimization</em> (1977).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He. 2018.

</span>
<span class="ltx_bibblock">Federated Meta-Learning with Fast Convergence and Efficient Communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1802.07876</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mingqing Chen, Rajiv Mathews, Tom Ouyang, and Françoise Beaufays. 2019.

</span>
<span class="ltx_bibblock">Federated Learning Of Out-Of-Vocabulary Words.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.10635</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. 2017.

</span>
<span class="ltx_bibblock">Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1712.05526</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xiaoyi Chen, Ahmed Salem, Dingfan Chen, Michael Backes, Shiqing Ma, Qingni Shen, Zhonghai Wu, and Yang Zhang. 2021.

</span>
<span class="ltx_bibblock">BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">ACSAC</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costan and Devadas (2016)</span>
<span class="ltx_bibblock">
Victor Costan and Srinivas Devadas. 2016.

</span>
<span class="ltx_bibblock">Intel SGX Explained.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IACR Cryptol. ePrint Arch.</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Darzidehkalani et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Erfan Darzidehkalani, Mohammad Ghasemi-rad, and P.M.A. van Ooijen. 2022a.

</span>
<span class="ltx_bibblock">Federated Learning in Medical Imaging: Part I: Toward Multicentral Health Care Ecosystems.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Journal of the American College of Radiology</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Darzidehkalani et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Erfan Darzidehkalani, Mohammad Ghasemi-rad, and P.M.A. van Ooijen. 2022b.

</span>
<span class="ltx_bibblock">Federated Learning in Medical Imaging: Part II: Methods, Challenges, and Considerations.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Journal of the American College of Radiology</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009.

</span>
<span class="ltx_bibblock">Imagenet: A large-scale hierarchical image database.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">CVPR</em> (2009).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng (2012)</span>
<span class="ltx_bibblock">
Li Deng. 2012.

</span>
<span class="ltx_bibblock">The MNIST Database of Handwritten Digit Images for Machine Learning Research.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em> (2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Désidéri (2009)</span>
<span class="ltx_bibblock">
Jean-Antoine Désidéri. 2009.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Multiple-gradient descent algorithm (MGDA)</em>.

</span>
<span class="ltx_bibblock">Ph. D. Dissertation. INRIA.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork (2008)</span>
<span class="ltx_bibblock">
Cynthia Dwork. 2008.

</span>
<span class="ltx_bibblock">Differential Privacy: A Survey of Results.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">TAMC</em> (2008).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Désidéri (2012)</span>
<span class="ltx_bibblock">
Jean-Antoine Désidéri. 2012.

</span>
<span class="ltx_bibblock">Multiple-gradient descent algorithm (MGDA) for multiobjective optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Comptes Rendus Mathematique</em> (2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El Mhamdi et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
El Mahdi El Mhamdi, Rachid Guerraoui, and Sébastien Rouault. 2018.

</span>
<span class="ltx_bibblock">The Hidden Vulnerability of Distributed Learning in Byzantium.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">PMLR</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">European Parliament and Council of the European Union (2018)</span>
<span class="ltx_bibblock">
European Parliament and Council of the European Union. 2018.

</span>
<span class="ltx_bibblock">General Data Protection Regulation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://eur-lex.europa.eu/eli/reg/2016/679/oj" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/eli/reg/2016/679/oj</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong. 2020.

</span>
<span class="ltx_bibblock">Local Model Poisoning Attacks to Byzantine-Robust Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jie Feng, Can Rong, Funing Sun, Diansheng Guo, and Yong Li. 2020.

</span>
<span class="ltx_bibblock">PMF: A Privacy-Preserving Human Mobility Prediction Framework via Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">ACM IMWUT</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frederickson et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Christopher Frederickson, Michael Moore, Glenn Dawson, and Robi Polikar. 2018.

</span>
<span class="ltx_bibblock">Attack Strength vs. Detectability Dilemma in Adversarial Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">IJCNN</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Clement Fung, Chris JM Yoon, and Ivan Beschastnikh. 2020.

</span>
<span class="ltx_bibblock">The Limitations of Federated Learning in Sybil Settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">RAID</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganju et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Karan Ganju, Qi Wang, Wei Yang, Carl A Gunter, and Nikita Borisov. 2018.

</span>
<span class="ltx_bibblock">Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">CCS</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yansong Gao, Bao Gia Doan, Zhi Zhang, Siqi Ma, Jiliang Zhang, Anmin Fu, Surya Nepal, and Hyoungshick Kim. 2020.

</span>
<span class="ltx_bibblock">Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.10760</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. 2017.

</span>
<span class="ltx_bibblock">BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.06733</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunesli et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Gozde N Gunesli, Mohsin Bilal, Shan E Ahmed Raza, and Nasir M Rajpoot. 2021.

</span>
<span class="ltx_bibblock">FedDropoutAvg: Generalizable federated learning for histopathology image classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.13230</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Françoise Beaufays, Sean Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel Ramage. 2018.

</span>
<span class="ltx_bibblock">Federated Learning for Mobile Keyboard Prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hashemi et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hanieh Hashemi, Yongqin Wang, Chuan Guo, and Murali Annavaram. 2021.

</span>
<span class="ltx_bibblock">Byzantine-Robust and Privacy-Preserving Framework for FedML.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">ICLR Workshops</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hayes et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jamie Hayes, Luca Melis, George Danezis, and Emiliano De Cristofaro. 2019.

</span>
<span class="ltx_bibblock">LOGAN: Membership inference attacks against generative models.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">PETS</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.

</span>
<span class="ltx_bibblock">Deep Residual Learning for Image Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">CVPR</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iandola et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Forrest N. Iandola, Song Han, Matthew W. Moskewicz, Khalid Ashraf, William J. Dally, and Kurt Keutzer. 2016.

</span>
<span class="ltx_bibblock">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and ¡0.5MB model size.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1602.07360</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Jakub Konečnỳ, H Brendan McMahan, Daniel Ramage, and Peter Richtárik. 2016.

</span>
<span class="ltx_bibblock">Federated optimization: Distributed machine learning for on-device intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.02527</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krauß and Dmitrienko (2023)</span>
<span class="ltx_bibblock">
Torsten Krauß and Alexandra Dmitrienko. 2023.

</span>
<span class="ltx_bibblock">MESAS: Poisoning Defense for Federated Learning Resilient against Adaptive Attackers.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">CCS</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et al<span id="bib.bib45.3.1" class="ltx_text">.</span> 2009.

</span>
<span class="ltx_bibblock">Learning Multiple Layers of Features from Tiny Images.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.4.1" class="ltx_emph ltx_font_italic">Citeseer</em> (2009).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumari et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Kavita Kumari, Phillip Rieger, Hossein Fereidooni, Murtuza Jadliwala, and Ahmad-Reza Sadeghi. 2023.

</span>
<span class="ltx_bibblock">BayBFed: Bayesian Backdoor Defense for Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">IEEE S&amp;P</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin. 2020.

</span>
<span class="ltx_bibblock">A review of applications in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Computers &amp; Industrial Engineering</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Liping Li, Wei Xu, Tianyi Chen, Georgios B Giannakis, and Qing Ling. 2019.

</span>
<span class="ltx_bibblock">RSA: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">AAAI</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Yiming Li, Yong Jiang, Zhifeng Li, and Shu-Tao Xia. 2022a.

</span>
<span class="ltx_bibblock">Backdoor Learning: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Yijing Li, Xiaofeng Tao, Xuefei Zhang, Junjie Liu, and Jin Xu. 2022b.

</span>
<span class="ltx_bibblock">Privacy-Preserved Federated Learning for Autonomous Driving.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">IEEE T-ITS</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim and Loh (1996)</span>
<span class="ltx_bibblock">
Tjen-Sien Lim and Wei-Yin Loh. 1996.

</span>
<span class="ltx_bibblock">A comparison of tests of equality of variances.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Computational Statistics &amp; Data Analysis</em> (1996).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Chih-Ting Liu, Chien-Yi Wang, Shao-Yi Chien, and Shang-Hong Lai. 2022a.

</span>
<span class="ltx_bibblock">FedFR: Joint Optimization Federated Framework for Generic and Personalized Face Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">AAAI</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Pengrui Liu, Xiangrui Xu, and Wei Wang. 2022b.

</span>
<span class="ltx_bibblock">Threats, attacks and defenses to federated learning: issues, taxonomy and perspectives.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Cybersecurity</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Liu, Anbu Huang, Yun Luo, He Huang, Youzhi Liu, Yuanyuan Chen, Lican Feng, Tianjian Chen, Han Yu, and Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">FedVision: An Online Visual Object Detection Platform Powered by Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">AAAI</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and X. Zhang. 2018.

</span>
<span class="ltx_bibblock">Trojaning Attack on Neural Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">NDSS</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Livingston (2004)</span>
<span class="ltx_bibblock">
Edward H Livingston. 2004.

</span>
<span class="ltx_bibblock">Who was student and why do we care so much about his t-test?

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Journal of Surgical Research</em> (2004).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Massey Jr (1951)</span>
<span class="ltx_bibblock">
Frank J Massey Jr. 1951.

</span>
<span class="ltx_bibblock">The Kolmogorov-Smirnov Test for Goodness of Fit.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Journal of the American statistical Association</em> (1951).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McInnes et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Leland McInnes, John Healy, and Steve Astels. 2017.

</span>
<span class="ltx_bibblock">HDBScan: Hierarchical density based clustering.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">The Journal of Open Source Software</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas. 2017.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks from Decentralized Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">AISTATS</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan and Ramage (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan and Daniel Ramage. 2017.

</span>
<span class="ltx_bibblock">Federated learning: Collaborative Machine Learning without Centralized Training Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Google AI</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. 2018.

</span>
<span class="ltx_bibblock">Learning Differentially Private Language Models Without Losing Accuracy.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">ICLR</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Minka (2000)</span>
<span class="ltx_bibblock">
Thomas Minka. 2000.

</span>
<span class="ltx_bibblock">Estimating a Dirichlet distribution.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Fan Mo, Hamed Haddadi, Kleomenis Katevas, Eduard Marin, Diego Perino, and Nicolas Kourtellis. 2021.

</span>
<span class="ltx_bibblock">PPFL: Privacy-preserving Federated Learning with Trusted Execution Environments.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">MobiSys</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muñoz-González et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Luis Muñoz-González, Kenneth T Co, and Emil C Lupu. 2019.

</span>
<span class="ltx_bibblock">Byzantine-Robust Federated Machine Learning through Adaptive Model Averaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.05125</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Naseri et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mohammad Naseri, Jamie Hayes, and Emiliano De Cristofaro. 2022.

</span>
<span class="ltx_bibblock">Local and Central Differential Privacy for Robustness and Privacy in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">NDSS</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nelson et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2008)</span>
<span class="ltx_bibblock">
Blaine Nelson, Marco Barreno, Fuching Jack Chi, Anthony D Joseph, Benjamin IP Rubinstein, Udam Saini, Charles Sutton, J Doug Tygar, and Kai Xia. 2008.

</span>
<span class="ltx_bibblock">Exploiting Machine Learning to Subvert Your Spam Filter.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">LEET</em> (2008).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Anh Nguyen, Tuong Do, Minh Tran, Binh X. Nguyen, Chien Duong, Tu Phan, Erman Tjiputra, and Quang D. Tran. 2022a.

</span>
<span class="ltx_bibblock">Deep Federated Learning for Autonomous Driving.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">IEEE IV</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Dinh C. Nguyen, Quoc-Viet Pham, Pubudu N. Pathirana, Ming Ding, Aruna Seneviratne, Zihuai Lin, Octavia Dobre, and Won-Joo Hwang. 2022b.

</span>
<span class="ltx_bibblock">Federated Learning for Smart Healthcare: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider, and Shaza Zeitouni. 2022c.

</span>
<span class="ltx_bibblock">FLAME: Taming Backdoors in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Thien Duc Nguyen, Phillip Rieger, Markus Miettinen, and Ahmad-Reza Sadeghi. 2020.

</span>
<span class="ltx_bibblock">Poisoning Attacks on Federated Learning-Based IoT Intrusion Detection System.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">NDSS DISS</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nielsen (2016)</span>
<span class="ltx_bibblock">
Frank Nielsen. 2016.

</span>
<span class="ltx_bibblock">Hierarchical Clustering.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Introduction to HPC with MPI for Data Science</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NVIDIA et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
NVIDIA, Péter Vingelmann, and Frank H.P. Fitzek. 2020.

</span>
<span class="ltx_bibblock">CUDA, release: 10.2.89.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://developer.nvidia.com/cuda-toolkit" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://developer.nvidia.com/cuda-toolkit</a>

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ozga et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Wojciech Ozga, Do Le Quoc, and Christof Fetzer. 2021.

</span>
<span class="ltx_bibblock">Perun: Confidential Multi-stakeholder Machine Learning Framework with Hardware Acceleration Support.

</span>
<span class="ltx_bibblock"><em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">DBSec</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, and Min Yang. 2022.

</span>
<span class="ltx_bibblock">Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al<span id="bib.bib75.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">Pytorch: An imperative style, high-performance deep learning library.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.4.1" class="ltx_emph ltx_font_italic">NeurIPS</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pukelsheim (1994)</span>
<span class="ltx_bibblock">
Friedrich Pukelsheim. 1994.

</span>
<span class="ltx_bibblock">The Three Sigma Rule.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">The American Statistician</em> (1994).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pyrgelis et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Apostolos Pyrgelis, Carmela Troncoso, and Emiliano De Cristofaro. 2018.

</span>
<span class="ltx_bibblock">Knock Knock, Who’s There? Membership Inference on Aggregate Location Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">NDSS</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Quoc et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Do Le Quoc, Franz Gregor, Sergei Arnautov, Roland Kunkel, Pramod Bhatotia, and Christof Fetzer. 2020.

</span>
<span class="ltx_bibblock">SecureTF: A Secure TensorFlow Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.3.1" class="ltx_emph ltx_font_italic">Middleware</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramaswamy et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Swaroop Ramaswamy, Rajiv Mathews, Kanishka Rao, and Françoise Beaufays. 2019.

</span>
<span class="ltx_bibblock">Federated Learning for Emoji Prediction in a Mobile Keyboard.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.04329</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rieger et al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, and Ahmad-Reza Sadeghi. 2022.

</span>
<span class="ltx_bibblock">DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">NDSS</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rieke et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletarì, Holger R. Roth, Shadi Albarqouni, Spyridon Bakas, Mathieu N. Galtier, Bennett A. Landman, Klaus Maier-Hein, Sébastien Ourselin, Micah Sheller, Ronald M. Summers, Andrew Trask, Daguang Xu, Maximilian Baust, and M. Jorge Cardoso. 2020.

</span>
<span class="ltx_bibblock">The future of digital health with federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">npj Digital Medicine</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roth et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Holger R Roth, Ken Chang, Praveer Singh, Nir Neumark, Wenqi Li, Vikash Gupta, Sharut Gupta, Liangqiong Qu, Alvin Ihsani, Bernardo C Bizzo, et al<span id="bib.bib82.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Federated learning for breast density classification: A real-world implementation.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.4.1" class="ltx_emph ltx_font_italic">MICCAI</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saha et al<span id="bib.bib83.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Aniruddha Saha, Akshayvarun Subramanya, and Hamed Pirsiavash. 2020.

</span>
<span class="ltx_bibblock">Hidden Trigger Backdoor Attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.3.1" class="ltx_emph ltx_font_italic">AAAI</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salem et al<span id="bib.bib84.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ahmed Salem, Apratim Bhattacharya, Michael Backes, Mario Fritz, and Yang Zhang. 2020.

</span>
<span class="ltx_bibblock">Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et al<span id="bib.bib85.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2020.

</span>
<span class="ltx_bibblock">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.01108</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sener and Koltun (2018)</span>
<span class="ltx_bibblock">
Ozan Sener and Vladlen Koltun. 2018.

</span>
<span class="ltx_bibblock">Multi-Task Learning as Multi-Objective Optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheller et al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2018a)</span>
<span class="ltx_bibblock">
Micah Sheller, Anthony Reina, Brandon Edwards, Jason Martin, and Spyridon Bakas. 2018a.

</span>
<span class="ltx_bibblock">Federated Learning for Medical Imaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.3.1" class="ltx_emph ltx_font_italic">Intel AI</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheller et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2018b)</span>
<span class="ltx_bibblock">
Micah Sheller, Anthony Reina, Brandon Edwards, Jason Martin, and Spyridon Bakas. 2018b.

</span>
<span class="ltx_bibblock">Multi-Institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">Brain Lesion Workshop</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Shiqi Shen, Shruti Tople, and Prateek Saxena. 2016.

</span>
<span class="ltx_bibblock">Auror: Defending Against Poisoning Attacks in Collaborative Deep Learning Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">ACSAC</em> (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017.

</span>
<span class="ltx_bibblock">Membership Inference Attacks Against Machine Learning Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">IEEE S&amp;P</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silva et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Santiago Silva, Boris A. Gutman, Eduardo Romero, Paul M. Thompson, Andre Altmann, and Marco Lorenzi. 2019.

</span>
<span class="ltx_bibblock">Federated Learning in Distributed Medical Databases: Meta-Analysis of Large-Scale Subcortical Brain Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib91.3.1" class="ltx_emph ltx_font_italic">IEEE ISBI</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Socher et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013.

</span>
<span class="ltx_bibblock">Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank.

</span>
<span class="ltx_bibblock"><em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">EMNLP</em> (2013).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sozinov et al<span id="bib.bib93.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Konstantin Sozinov, Vladimir Vlassov, and Sarunas Girdzijauskas. 2018.

</span>
<span class="ltx_bibblock">Human Activity Recognition Using Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib93.3.1" class="ltx_emph ltx_font_italic">IEEE BdCloud</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stallkamp et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. 2012.

</span>
<span class="ltx_bibblock">Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">Neural Networks</em> (2012).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suciu et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Octavian Suciu, Radu Marginean, Yigitcan Kaya, Hal Daume III, and Tudor Dumitras. 2018.

</span>
<span class="ltx_bibblock">When Does Machine Learning FAIL? Generalized Transferability for Evasion and Poisoning Attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">USENIX Security</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Gan Sun, Yang Cong, Jiahua Dong, Qiang Wang, Lingjuan Lyu, and Ji Liu. 2022.

</span>
<span class="ltx_bibblock">Data Poisoning Attacks on Federated Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">IEEE IoT-J</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H. Brendan McMahan. 2019.

</span>
<span class="ltx_bibblock">Can You Really Backdoor Federated Learning?

</span>
<span class="ltx_bibblock"><em id="bib.bib97.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.07963</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">The Linux Foundation (2022)</span>
<span class="ltx_bibblock">
The Linux Foundation. 2022.

</span>
<span class="ltx_bibblock">PyTorch.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://pytorch.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://pytorch.org</a>.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhiyi Tian, Lei Cui, Jie Liang, and Shui Yu. 2022.

</span>
<span class="ltx_bibblock">A Comprehensive Survey on Poisoning Attacks and Countermeasures in Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">Comput. Surveys</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tramer and Boneh (2019)</span>
<span class="ltx_bibblock">
Florian Tramer and Dan Boneh. 2019.

</span>
<span class="ltx_bibblock">Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">ICLR</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Turner et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Alexander Turner, Dimitris Tsipras, and Aleksander Madry. 2019.

</span>
<span class="ltx_bibblock">Label-Consistent Backdoor Attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.02771</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">U.S. Congress (1996)</span>
<span class="ltx_bibblock">
U.S. Congress. 1996.

</span>
<span class="ltx_bibblock">Health Insurance Portability and Accountability Act.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf</a>.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Rossum and Drake Jr (1995)</span>
<span class="ltx_bibblock">
Guido Van Rossum and Fred L Drake Jr. 1995.

</span>
<span class="ltx_bibblock"><em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Python reference manual</em>.

</span>
<span class="ltx_bibblock">Centrum voor Wiskunde en Informatica Amsterdam.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Volos et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018.

</span>
<span class="ltx_bibblock">Graviton: Trusted Execution Environments on GPUs.

</span>
<span class="ltx_bibblock"><em id="bib.bib104.3.1" class="ltx_emph ltx_font_italic">OSDI</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, and Dimitris Papailiopoulos. 2020.

</span>
<span class="ltx_bibblock">Attack of the Tails: Yes, You Really Can Backdoor Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.3.1" class="ltx_emph ltx_font_italic">NIPS</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib106.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Lixu Wang, Shichao Xu, Xiao Wang, and Qi Zhu. 2019b.

</span>
<span class="ltx_bibblock">Eavesdrop the Composition Proportion of Training Labels in Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib106.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.06044</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Zhibo Wang, Mengkai Song, Zhifei Zhang, Yang Song, Qian Wang, and Hairong Qi. 2019a.

</span>
<span class="ltx_bibblock">Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.3.1" class="ltx_emph ltx_font_italic">INFOCOM</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib108.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhaoxian Wu, Qing Ling, Tianyi Chen, and Georgios B. Giannakis. 2020.

</span>
<span class="ltx_bibblock">Federated Variance-Reduced Stochastic Gradient Descent With Robustness to Byzantine Attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Signal Processing</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Geming Xia, Jian Chen, Chaodong Yu, and Jun Ma. 2023.

</span>
<span class="ltx_bibblock">Poisoning Attacks in Federated Learning: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib109.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib110.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Chulin Xie, Keli Huang, Pin-Yu Chen, and Bo Li. 2020a.

</span>
<span class="ltx_bibblock">DBA: Distributed Backdoor Attacks against Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib110.3.1" class="ltx_emph ltx_font_italic">ICLR</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib111.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. 2020b.

</span>
<span class="ltx_bibblock">Fall of Empires: Breaking Byzantine-tolerant SGD by Inner Product Manipulation.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.3.1" class="ltx_emph ltx_font_italic">UAI</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. 2019a.

</span>
<span class="ltx_bibblock">Federated Machine Learning: Concept and Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and Technology</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. 2019b.

</span>
<span class="ltx_bibblock">Federated Machine Learning: Concept and Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">TIST</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib114.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas Kong, Daniel Ramage, and Françoise Beaufays. 2018.

</span>
<span class="ltx_bibblock">Applied Federated Learning: Improving Google Keyboard Query Suggestions.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.02903</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib115.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. 2018.

</span>
<span class="ltx_bibblock">Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.3.1" class="ltx_emph ltx_font_italic">ICML</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hongyi Zhang, Jan Bosch, and Helena Holmström Olsson. 2021.

</span>
<span class="ltx_bibblock">End-to-End Federated Learning for Autonomous Driving Vehicles.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.3.1" class="ltx_emph ltx_font_italic">IJCNN</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zaixi Zhang, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong. 2022.

</span>
<span class="ltx_bibblock">FLDetector: Defending Federated Learning Against Model Poisoning Attacks via Detecting Malicious Clients.

</span>
<span class="ltx_bibblock"><em id="bib.bib117.3.1" class="ltx_emph ltx_font_italic">KDD22</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib118.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen. 2020.

</span>
<span class="ltx_bibblock">iDLG: Improved Deep Leakage from Gradients.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.02610</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib119.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Lingchen Zhao, Shengshan Hu, Qian Wang, Jianlin Jiang, Chao Shen, Xiangyang Luo, and Pengfei Hu. 2021.

</span>
<span class="ltx_bibblock">Shielding Collaborative Learning: Mitigating Poisoning Attacks Through Client-Side Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.3.1" class="ltx_emph ltx_font_italic">PRDC</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib120.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin. 2021.

</span>
<span class="ltx_bibblock">Federated Learning on Non-IID Data: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.3.1" class="ltx_emph ltx_font_italic">Neurocomput.</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jianping Zhu, Rui Hou, XiaoFeng Wang, Wenhao Wang, Jiangfeng Cao, Lutan Zhao, Fengkai Yuan, Peinan Li, Zhongpu Wang, Boyan Zhao, Lixin Zhang, and Dan Meng. 2019.

</span>
<span class="ltx_bibblock">Enabling Privacy-Preserving, Compute- and Data-Intensive Computing using Heterogeneous Trusted Execution Environment.

</span>
<span class="ltx_bibblock"><em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.04782</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Federated Averaging</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.31" class="ltx_p">In a federation with multiple clients <span id="A1.p1.9.9" class="ltx_text"><math id="A1.p1.1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A1.p1.1.1.m1.1a"><mi id="A1.p1.1.1.m1.1.1" xref="A1.p1.1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.p1.1.1.m1.1b"><ci id="A1.p1.1.1.m1.1.1.cmml" xref="A1.p1.1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.1.m1.1c">C</annotation></semantics></math><sub id="A1.p1.9.9.1" class="ltx_sub"><span id="A1.p1.9.9.1.1" class="ltx_text ltx_font_italic">k</span></sub> <math id="A1.p1.3.3.m3.1" class="ltx_math_unparsed" alttext="\in\{" display="inline"><semantics id="A1.p1.3.3.m3.1a"><mrow id="A1.p1.3.3.m3.1b"><mo id="A1.p1.3.3.m3.1.1">∈</mo><mo stretchy="false" id="A1.p1.3.3.m3.1.2">{</mo></mrow><annotation encoding="application/x-tex" id="A1.p1.3.3.m3.1c">\in\{</annotation></semantics></math><math id="A1.p1.4.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A1.p1.4.4.m4.1a"><mi id="A1.p1.4.4.m4.1.1" xref="A1.p1.4.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.p1.4.4.m4.1b"><ci id="A1.p1.4.4.m4.1.1.cmml" xref="A1.p1.4.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.4.m4.1c">C</annotation></semantics></math><sub id="A1.p1.9.9.2" class="ltx_sub"><span id="A1.p1.9.9.2.1" class="ltx_text ltx_font_italic">1</span></sub> <math id="A1.p1.6.6.m6.1" class="ltx_math_unparsed" alttext=",\ldots" display="inline"><semantics id="A1.p1.6.6.m6.1a"><mrow id="A1.p1.6.6.m6.1b"><mo id="A1.p1.6.6.m6.1.1">,</mo><mi mathvariant="normal" id="A1.p1.6.6.m6.1.2">…</mi></mrow><annotation encoding="application/x-tex" id="A1.p1.6.6.m6.1c">,\ldots</annotation></semantics></math><math id="A1.p1.7.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A1.p1.7.7.m7.1a"><mi id="A1.p1.7.7.m7.1.1" xref="A1.p1.7.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.p1.7.7.m7.1b"><ci id="A1.p1.7.7.m7.1.1.cmml" xref="A1.p1.7.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.7.m7.1c">C</annotation></semantics></math><sub id="A1.p1.9.9.3" class="ltx_sub"><span id="A1.p1.9.9.3.1" class="ltx_text ltx_font_italic">N</span></sub><math id="A1.p1.9.9.m9.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="A1.p1.9.9.m9.1a"><mo stretchy="false" id="A1.p1.9.9.m9.1.1" xref="A1.p1.9.9.m9.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="A1.p1.9.9.m9.1b"><ci id="A1.p1.9.9.m9.1.1.cmml" xref="A1.p1.9.9.m9.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.9.9.m9.1c">\}</annotation></semantics></math></span> where the server selects a subset <math id="A1.p1.10.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="A1.p1.10.m1.1a"><mi id="A1.p1.10.m1.1.1" xref="A1.p1.10.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A1.p1.10.m1.1b"><ci id="A1.p1.10.m1.1.1.cmml" xref="A1.p1.10.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.10.m1.1c">n</annotation></semantics></math> of the <math id="A1.p1.11.m2.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="A1.p1.11.m2.1a"><mi class="ltx_font_mathcaligraphic" id="A1.p1.11.m2.1.1" xref="A1.p1.11.m2.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="A1.p1.11.m2.1b"><ci id="A1.p1.11.m2.1.1.cmml" xref="A1.p1.11.m2.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.11.m2.1c">\mathcal{N}</annotation></semantics></math> available clients <span id="A1.p1.20.18" class="ltx_text"><math id="A1.p1.12.10.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A1.p1.12.10.m1.1a"><mi id="A1.p1.12.10.m1.1.1" xref="A1.p1.12.10.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.p1.12.10.m1.1b"><ci id="A1.p1.12.10.m1.1.1.cmml" xref="A1.p1.12.10.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.12.10.m1.1c">C</annotation></semantics></math><sub id="A1.p1.20.18.1" class="ltx_sub"><span id="A1.p1.20.18.1.1" class="ltx_text ltx_font_italic">i</span></sub> <math id="A1.p1.14.12.m3.1" class="ltx_math_unparsed" alttext="\in\{" display="inline"><semantics id="A1.p1.14.12.m3.1a"><mrow id="A1.p1.14.12.m3.1b"><mo id="A1.p1.14.12.m3.1.1">∈</mo><mo stretchy="false" id="A1.p1.14.12.m3.1.2">{</mo></mrow><annotation encoding="application/x-tex" id="A1.p1.14.12.m3.1c">\in\{</annotation></semantics></math><math id="A1.p1.15.13.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A1.p1.15.13.m4.1a"><mi id="A1.p1.15.13.m4.1.1" xref="A1.p1.15.13.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.p1.15.13.m4.1b"><ci id="A1.p1.15.13.m4.1.1.cmml" xref="A1.p1.15.13.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.15.13.m4.1c">C</annotation></semantics></math><sub id="A1.p1.20.18.2" class="ltx_sub"><span id="A1.p1.20.18.2.1" class="ltx_text ltx_font_italic">1</span></sub> <math id="A1.p1.17.15.m6.1" class="ltx_math_unparsed" alttext=",\ldots" display="inline"><semantics id="A1.p1.17.15.m6.1a"><mrow id="A1.p1.17.15.m6.1b"><mo id="A1.p1.17.15.m6.1.1">,</mo><mi mathvariant="normal" id="A1.p1.17.15.m6.1.2">…</mi></mrow><annotation encoding="application/x-tex" id="A1.p1.17.15.m6.1c">,\ldots</annotation></semantics></math><math id="A1.p1.18.16.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A1.p1.18.16.m7.1a"><mi id="A1.p1.18.16.m7.1.1" xref="A1.p1.18.16.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A1.p1.18.16.m7.1b"><ci id="A1.p1.18.16.m7.1.1.cmml" xref="A1.p1.18.16.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.18.16.m7.1c">C</annotation></semantics></math><sub id="A1.p1.20.18.3" class="ltx_sub"><span id="A1.p1.20.18.3.1" class="ltx_text ltx_font_italic">n</span></sub><math id="A1.p1.20.18.m9.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="A1.p1.20.18.m9.1a"><mo stretchy="false" id="A1.p1.20.18.m9.1.1" xref="A1.p1.20.18.m9.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="A1.p1.20.18.m9.1b"><ci id="A1.p1.20.18.m9.1.1.cmml" xref="A1.p1.20.18.m9.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.20.18.m9.1c">\}</annotation></semantics></math></span> and each selected client initializes its local model with the distributed global model (<math id="A1.p1.21.m3.1" class="ltx_Math" alttext="L^{r}_{i}" display="inline"><semantics id="A1.p1.21.m3.1a"><msubsup id="A1.p1.21.m3.1.1" xref="A1.p1.21.m3.1.1.cmml"><mi id="A1.p1.21.m3.1.1.2.2" xref="A1.p1.21.m3.1.1.2.2.cmml">L</mi><mi id="A1.p1.21.m3.1.1.3" xref="A1.p1.21.m3.1.1.3.cmml">i</mi><mi id="A1.p1.21.m3.1.1.2.3" xref="A1.p1.21.m3.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.21.m3.1b"><apply id="A1.p1.21.m3.1.1.cmml" xref="A1.p1.21.m3.1.1"><csymbol cd="ambiguous" id="A1.p1.21.m3.1.1.1.cmml" xref="A1.p1.21.m3.1.1">subscript</csymbol><apply id="A1.p1.21.m3.1.1.2.cmml" xref="A1.p1.21.m3.1.1"><csymbol cd="ambiguous" id="A1.p1.21.m3.1.1.2.1.cmml" xref="A1.p1.21.m3.1.1">superscript</csymbol><ci id="A1.p1.21.m3.1.1.2.2.cmml" xref="A1.p1.21.m3.1.1.2.2">𝐿</ci><ci id="A1.p1.21.m3.1.1.2.3.cmml" xref="A1.p1.21.m3.1.1.2.3">𝑟</ci></apply><ci id="A1.p1.21.m3.1.1.3.cmml" xref="A1.p1.21.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.21.m3.1c">L^{r}_{i}</annotation></semantics></math> <math id="A1.p1.22.m4.1" class="ltx_Math" alttext="=" display="inline"><semantics id="A1.p1.22.m4.1a"><mo id="A1.p1.22.m4.1.1" xref="A1.p1.22.m4.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="A1.p1.22.m4.1b"><eq id="A1.p1.22.m4.1.1.cmml" xref="A1.p1.22.m4.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.22.m4.1c">=</annotation></semantics></math> <math id="A1.p1.23.m5.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A1.p1.23.m5.1a"><msup id="A1.p1.23.m5.1.1" xref="A1.p1.23.m5.1.1.cmml"><mi id="A1.p1.23.m5.1.1.2" xref="A1.p1.23.m5.1.1.2.cmml">G</mi><mi id="A1.p1.23.m5.1.1.3" xref="A1.p1.23.m5.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A1.p1.23.m5.1b"><apply id="A1.p1.23.m5.1.1.cmml" xref="A1.p1.23.m5.1.1"><csymbol cd="ambiguous" id="A1.p1.23.m5.1.1.1.cmml" xref="A1.p1.23.m5.1.1">superscript</csymbol><ci id="A1.p1.23.m5.1.1.2.cmml" xref="A1.p1.23.m5.1.1.2">𝐺</ci><ci id="A1.p1.23.m5.1.1.3.cmml" xref="A1.p1.23.m5.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.23.m5.1c">G^{r}</annotation></semantics></math>) before training a new local model <math id="A1.p1.24.m6.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="A1.p1.24.m6.1a"><msubsup id="A1.p1.24.m6.1.1" xref="A1.p1.24.m6.1.1.cmml"><mi id="A1.p1.24.m6.1.1.2.2" xref="A1.p1.24.m6.1.1.2.2.cmml">L</mi><mi id="A1.p1.24.m6.1.1.3" xref="A1.p1.24.m6.1.1.3.cmml">i</mi><mrow id="A1.p1.24.m6.1.1.2.3" xref="A1.p1.24.m6.1.1.2.3.cmml"><mi id="A1.p1.24.m6.1.1.2.3.2" xref="A1.p1.24.m6.1.1.2.3.2.cmml">r</mi><mo id="A1.p1.24.m6.1.1.2.3.1" xref="A1.p1.24.m6.1.1.2.3.1.cmml">+</mo><mn id="A1.p1.24.m6.1.1.2.3.3" xref="A1.p1.24.m6.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.24.m6.1b"><apply id="A1.p1.24.m6.1.1.cmml" xref="A1.p1.24.m6.1.1"><csymbol cd="ambiguous" id="A1.p1.24.m6.1.1.1.cmml" xref="A1.p1.24.m6.1.1">subscript</csymbol><apply id="A1.p1.24.m6.1.1.2.cmml" xref="A1.p1.24.m6.1.1"><csymbol cd="ambiguous" id="A1.p1.24.m6.1.1.2.1.cmml" xref="A1.p1.24.m6.1.1">superscript</csymbol><ci id="A1.p1.24.m6.1.1.2.2.cmml" xref="A1.p1.24.m6.1.1.2.2">𝐿</ci><apply id="A1.p1.24.m6.1.1.2.3.cmml" xref="A1.p1.24.m6.1.1.2.3"><plus id="A1.p1.24.m6.1.1.2.3.1.cmml" xref="A1.p1.24.m6.1.1.2.3.1"></plus><ci id="A1.p1.24.m6.1.1.2.3.2.cmml" xref="A1.p1.24.m6.1.1.2.3.2">𝑟</ci><cn type="integer" id="A1.p1.24.m6.1.1.2.3.3.cmml" xref="A1.p1.24.m6.1.1.2.3.3">1</cn></apply></apply><ci id="A1.p1.24.m6.1.1.3.cmml" xref="A1.p1.24.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.24.m6.1c">L^{{r+1}}_{i}</annotation></semantics></math> with its local dataset <math id="A1.p1.25.m7.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="A1.p1.25.m7.1a"><mi class="ltx_font_mathcaligraphic" id="A1.p1.25.m7.1.1" xref="A1.p1.25.m7.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="A1.p1.25.m7.1b"><ci id="A1.p1.25.m7.1.1.cmml" xref="A1.p1.25.m7.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.25.m7.1c">\mathcal{D}</annotation></semantics></math><sub id="A1.p1.31.19" class="ltx_sub"><span id="A1.p1.31.19.1" class="ltx_text ltx_font_italic">i</span></sub>, the difference between the global and the local model is denoted as model update <math id="A1.p1.27.m9.1" class="ltx_Math" alttext="\mathcal{U}^{r}_{i}" display="inline"><semantics id="A1.p1.27.m9.1a"><msubsup id="A1.p1.27.m9.1.1" xref="A1.p1.27.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.p1.27.m9.1.1.2.2" xref="A1.p1.27.m9.1.1.2.2.cmml">𝒰</mi><mi id="A1.p1.27.m9.1.1.3" xref="A1.p1.27.m9.1.1.3.cmml">i</mi><mi id="A1.p1.27.m9.1.1.2.3" xref="A1.p1.27.m9.1.1.2.3.cmml">r</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.27.m9.1b"><apply id="A1.p1.27.m9.1.1.cmml" xref="A1.p1.27.m9.1.1"><csymbol cd="ambiguous" id="A1.p1.27.m9.1.1.1.cmml" xref="A1.p1.27.m9.1.1">subscript</csymbol><apply id="A1.p1.27.m9.1.1.2.cmml" xref="A1.p1.27.m9.1.1"><csymbol cd="ambiguous" id="A1.p1.27.m9.1.1.2.1.cmml" xref="A1.p1.27.m9.1.1">superscript</csymbol><ci id="A1.p1.27.m9.1.1.2.2.cmml" xref="A1.p1.27.m9.1.1.2.2">𝒰</ci><ci id="A1.p1.27.m9.1.1.2.3.cmml" xref="A1.p1.27.m9.1.1.2.3">𝑟</ci></apply><ci id="A1.p1.27.m9.1.1.3.cmml" xref="A1.p1.27.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.27.m9.1c">\mathcal{U}^{r}_{i}</annotation></semantics></math> <math id="A1.p1.28.m10.1" class="ltx_Math" alttext="=" display="inline"><semantics id="A1.p1.28.m10.1a"><mo id="A1.p1.28.m10.1.1" xref="A1.p1.28.m10.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="A1.p1.28.m10.1b"><eq id="A1.p1.28.m10.1.1.cmml" xref="A1.p1.28.m10.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.28.m10.1c">=</annotation></semantics></math> <math id="A1.p1.29.m11.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="A1.p1.29.m11.1a"><msubsup id="A1.p1.29.m11.1.1" xref="A1.p1.29.m11.1.1.cmml"><mi id="A1.p1.29.m11.1.1.2.2" xref="A1.p1.29.m11.1.1.2.2.cmml">L</mi><mi id="A1.p1.29.m11.1.1.3" xref="A1.p1.29.m11.1.1.3.cmml">i</mi><mrow id="A1.p1.29.m11.1.1.2.3" xref="A1.p1.29.m11.1.1.2.3.cmml"><mi id="A1.p1.29.m11.1.1.2.3.2" xref="A1.p1.29.m11.1.1.2.3.2.cmml">r</mi><mo id="A1.p1.29.m11.1.1.2.3.1" xref="A1.p1.29.m11.1.1.2.3.1.cmml">+</mo><mn id="A1.p1.29.m11.1.1.2.3.3" xref="A1.p1.29.m11.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="A1.p1.29.m11.1b"><apply id="A1.p1.29.m11.1.1.cmml" xref="A1.p1.29.m11.1.1"><csymbol cd="ambiguous" id="A1.p1.29.m11.1.1.1.cmml" xref="A1.p1.29.m11.1.1">subscript</csymbol><apply id="A1.p1.29.m11.1.1.2.cmml" xref="A1.p1.29.m11.1.1"><csymbol cd="ambiguous" id="A1.p1.29.m11.1.1.2.1.cmml" xref="A1.p1.29.m11.1.1">superscript</csymbol><ci id="A1.p1.29.m11.1.1.2.2.cmml" xref="A1.p1.29.m11.1.1.2.2">𝐿</ci><apply id="A1.p1.29.m11.1.1.2.3.cmml" xref="A1.p1.29.m11.1.1.2.3"><plus id="A1.p1.29.m11.1.1.2.3.1.cmml" xref="A1.p1.29.m11.1.1.2.3.1"></plus><ci id="A1.p1.29.m11.1.1.2.3.2.cmml" xref="A1.p1.29.m11.1.1.2.3.2">𝑟</ci><cn type="integer" id="A1.p1.29.m11.1.1.2.3.3.cmml" xref="A1.p1.29.m11.1.1.2.3.3">1</cn></apply></apply><ci id="A1.p1.29.m11.1.1.3.cmml" xref="A1.p1.29.m11.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.29.m11.1c">L^{{r+1}}_{i}</annotation></semantics></math>- <math id="A1.p1.30.m12.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A1.p1.30.m12.1a"><msup id="A1.p1.30.m12.1.1" xref="A1.p1.30.m12.1.1.cmml"><mi id="A1.p1.30.m12.1.1.2" xref="A1.p1.30.m12.1.1.2.cmml">G</mi><mi id="A1.p1.30.m12.1.1.3" xref="A1.p1.30.m12.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A1.p1.30.m12.1b"><apply id="A1.p1.30.m12.1.1.cmml" xref="A1.p1.30.m12.1.1"><csymbol cd="ambiguous" id="A1.p1.30.m12.1.1.1.cmml" xref="A1.p1.30.m12.1.1">superscript</csymbol><ci id="A1.p1.30.m12.1.1.2.cmml" xref="A1.p1.30.m12.1.1.2">𝐺</ci><ci id="A1.p1.30.m12.1.1.3.cmml" xref="A1.p1.30.m12.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.30.m12.1c">G^{r}</annotation></semantics></math>. When applying <span id="A1.p1.31.20" class="ltx_text">FedAVG</span>, the server aggregates these updates by calculating the weighted average of all the updates using the global learning rate <math id="A1.p1.31.m13.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="A1.p1.31.m13.1a"><mi id="A1.p1.31.m13.1.1" xref="A1.p1.31.m13.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="A1.p1.31.m13.1b"><ci id="A1.p1.31.m13.1.1.cmml" xref="A1.p1.31.m13.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.31.m13.1c">\delta</annotation></semantics></math> as formalized in <a href="#A1.E3" title="In Appendix A Federated Averaging ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></span></a>.</p>
<table id="A1.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.E3.m1.1" class="ltx_Math" alttext="G^{{r+1}}=G^{r}+\delta(\frac{1}{n}\sum_{i=0}^{n-1}\mathcal{U}^{r}_{i})" display="block"><semantics id="A1.E3.m1.1a"><mrow id="A1.E3.m1.1.1" xref="A1.E3.m1.1.1.cmml"><msup id="A1.E3.m1.1.1.3" xref="A1.E3.m1.1.1.3.cmml"><mi id="A1.E3.m1.1.1.3.2" xref="A1.E3.m1.1.1.3.2.cmml">G</mi><mrow id="A1.E3.m1.1.1.3.3" xref="A1.E3.m1.1.1.3.3.cmml"><mi id="A1.E3.m1.1.1.3.3.2" xref="A1.E3.m1.1.1.3.3.2.cmml">r</mi><mo id="A1.E3.m1.1.1.3.3.1" xref="A1.E3.m1.1.1.3.3.1.cmml">+</mo><mn id="A1.E3.m1.1.1.3.3.3" xref="A1.E3.m1.1.1.3.3.3.cmml">1</mn></mrow></msup><mo id="A1.E3.m1.1.1.2" xref="A1.E3.m1.1.1.2.cmml">=</mo><mrow id="A1.E3.m1.1.1.1" xref="A1.E3.m1.1.1.1.cmml"><msup id="A1.E3.m1.1.1.1.3" xref="A1.E3.m1.1.1.1.3.cmml"><mi id="A1.E3.m1.1.1.1.3.2" xref="A1.E3.m1.1.1.1.3.2.cmml">G</mi><mi id="A1.E3.m1.1.1.1.3.3" xref="A1.E3.m1.1.1.1.3.3.cmml">r</mi></msup><mo id="A1.E3.m1.1.1.1.2" xref="A1.E3.m1.1.1.1.2.cmml">+</mo><mrow id="A1.E3.m1.1.1.1.1" xref="A1.E3.m1.1.1.1.1.cmml"><mi id="A1.E3.m1.1.1.1.1.3" xref="A1.E3.m1.1.1.1.1.3.cmml">δ</mi><mo lspace="0em" rspace="0em" id="A1.E3.m1.1.1.1.1.2" xref="A1.E3.m1.1.1.1.1.2.cmml">​</mo><mrow id="A1.E3.m1.1.1.1.1.1.1" xref="A1.E3.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.E3.m1.1.1.1.1.1.1.2" xref="A1.E3.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A1.E3.m1.1.1.1.1.1.1.1" xref="A1.E3.m1.1.1.1.1.1.1.1.cmml"><mfrac id="A1.E3.m1.1.1.1.1.1.1.1.2" xref="A1.E3.m1.1.1.1.1.1.1.1.2.cmml"><mn id="A1.E3.m1.1.1.1.1.1.1.1.2.2" xref="A1.E3.m1.1.1.1.1.1.1.1.2.2.cmml">1</mn><mi id="A1.E3.m1.1.1.1.1.1.1.1.2.3" xref="A1.E3.m1.1.1.1.1.1.1.1.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="A1.E3.m1.1.1.1.1.1.1.1.1" xref="A1.E3.m1.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="A1.E3.m1.1.1.1.1.1.1.1.3" xref="A1.E3.m1.1.1.1.1.1.1.1.3.cmml"><munderover id="A1.E3.m1.1.1.1.1.1.1.1.3.1" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.2" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.cmml"><mi id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.2" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.2.cmml">i</mi><mo id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.1" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.3" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.3.cmml">0</mn></mrow><mrow id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.cmml"><mi id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.2" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.2.cmml">n</mi><mo id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.1" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.1.cmml">−</mo><mn id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.3" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.3.cmml">1</mn></mrow></munderover><msubsup id="A1.E3.m1.1.1.1.1.1.1.1.3.2" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.2" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.2.cmml">𝒰</mi><mi id="A1.E3.m1.1.1.1.1.1.1.1.3.2.3" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mi id="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.3" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.3.cmml">r</mi></msubsup></mrow></mrow><mo stretchy="false" id="A1.E3.m1.1.1.1.1.1.1.3" xref="A1.E3.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E3.m1.1b"><apply id="A1.E3.m1.1.1.cmml" xref="A1.E3.m1.1.1"><eq id="A1.E3.m1.1.1.2.cmml" xref="A1.E3.m1.1.1.2"></eq><apply id="A1.E3.m1.1.1.3.cmml" xref="A1.E3.m1.1.1.3"><csymbol cd="ambiguous" id="A1.E3.m1.1.1.3.1.cmml" xref="A1.E3.m1.1.1.3">superscript</csymbol><ci id="A1.E3.m1.1.1.3.2.cmml" xref="A1.E3.m1.1.1.3.2">𝐺</ci><apply id="A1.E3.m1.1.1.3.3.cmml" xref="A1.E3.m1.1.1.3.3"><plus id="A1.E3.m1.1.1.3.3.1.cmml" xref="A1.E3.m1.1.1.3.3.1"></plus><ci id="A1.E3.m1.1.1.3.3.2.cmml" xref="A1.E3.m1.1.1.3.3.2">𝑟</ci><cn type="integer" id="A1.E3.m1.1.1.3.3.3.cmml" xref="A1.E3.m1.1.1.3.3.3">1</cn></apply></apply><apply id="A1.E3.m1.1.1.1.cmml" xref="A1.E3.m1.1.1.1"><plus id="A1.E3.m1.1.1.1.2.cmml" xref="A1.E3.m1.1.1.1.2"></plus><apply id="A1.E3.m1.1.1.1.3.cmml" xref="A1.E3.m1.1.1.1.3"><csymbol cd="ambiguous" id="A1.E3.m1.1.1.1.3.1.cmml" xref="A1.E3.m1.1.1.1.3">superscript</csymbol><ci id="A1.E3.m1.1.1.1.3.2.cmml" xref="A1.E3.m1.1.1.1.3.2">𝐺</ci><ci id="A1.E3.m1.1.1.1.3.3.cmml" xref="A1.E3.m1.1.1.1.3.3">𝑟</ci></apply><apply id="A1.E3.m1.1.1.1.1.cmml" xref="A1.E3.m1.1.1.1.1"><times id="A1.E3.m1.1.1.1.1.2.cmml" xref="A1.E3.m1.1.1.1.1.2"></times><ci id="A1.E3.m1.1.1.1.1.3.cmml" xref="A1.E3.m1.1.1.1.1.3">𝛿</ci><apply id="A1.E3.m1.1.1.1.1.1.1.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1"><times id="A1.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.1"></times><apply id="A1.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.2"><divide id="A1.E3.m1.1.1.1.1.1.1.1.2.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.2"></divide><cn type="integer" id="A1.E3.m1.1.1.1.1.1.1.1.2.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.2.2">1</cn><ci id="A1.E3.m1.1.1.1.1.1.1.1.2.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.2.3">𝑛</ci></apply><apply id="A1.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3"><apply id="A1.E3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="A1.E3.m1.1.1.1.1.1.1.1.3.1.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1">superscript</csymbol><apply id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1">subscript</csymbol><sum id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.2"></sum><apply id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3"><eq id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.1"></eq><ci id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.2">𝑖</ci><cn type="integer" id="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.2.3.3">0</cn></apply></apply><apply id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3"><minus id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.1"></minus><ci id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.2">𝑛</ci><cn type="integer" id="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.1.3.3">1</cn></apply></apply><apply id="A1.E3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A1.E3.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2">subscript</csymbol><apply id="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2">superscript</csymbol><ci id="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.2">𝒰</ci><ci id="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2.2.3">𝑟</ci></apply><ci id="A1.E3.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="A1.E3.m1.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E3.m1.1c">G^{{r+1}}=G^{r}+\delta(\frac{1}{n}\sum_{i=0}^{n-1}\mathcal{U}^{r}_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Model Accuracies</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.2" class="ltx_p">For a benign test dataset <math id="A2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{test}" display="inline"><semantics id="A2.p1.1.m1.1a"><msub id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.p1.1.m1.1.1.2" xref="A2.p1.1.m1.1.1.2.cmml">𝒟</mi><mrow id="A2.p1.1.m1.1.1.3" xref="A2.p1.1.m1.1.1.3.cmml"><mi id="A2.p1.1.m1.1.1.3.2" xref="A2.p1.1.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="A2.p1.1.m1.1.1.3.1" xref="A2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="A2.p1.1.m1.1.1.3.3" xref="A2.p1.1.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A2.p1.1.m1.1.1.3.1a" xref="A2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="A2.p1.1.m1.1.1.3.4" xref="A2.p1.1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A2.p1.1.m1.1.1.3.1b" xref="A2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="A2.p1.1.m1.1.1.3.5" xref="A2.p1.1.m1.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><apply id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p1.1.m1.1.1.1.cmml" xref="A2.p1.1.m1.1.1">subscript</csymbol><ci id="A2.p1.1.m1.1.1.2.cmml" xref="A2.p1.1.m1.1.1.2">𝒟</ci><apply id="A2.p1.1.m1.1.1.3.cmml" xref="A2.p1.1.m1.1.1.3"><times id="A2.p1.1.m1.1.1.3.1.cmml" xref="A2.p1.1.m1.1.1.3.1"></times><ci id="A2.p1.1.m1.1.1.3.2.cmml" xref="A2.p1.1.m1.1.1.3.2">𝑡</ci><ci id="A2.p1.1.m1.1.1.3.3.cmml" xref="A2.p1.1.m1.1.1.3.3">𝑒</ci><ci id="A2.p1.1.m1.1.1.3.4.cmml" xref="A2.p1.1.m1.1.1.3.4">𝑠</ci><ci id="A2.p1.1.m1.1.1.3.5.cmml" xref="A2.p1.1.m1.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">\mathcal{D}_{test}</annotation></semantics></math> which contains samples with correctly labeled predictions <math id="A2.p1.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="A2.p1.2.m2.1a"><mi id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><ci id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">y</annotation></semantics></math>, we measure the prediction performance of a model with the model accuracy (MA), as formalized in <a href="#A2.E4" title="In Appendix B Model Accuracies ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a>.</p>
</div>
<div id="A2.p2" class="ltx_para">
<table id="A2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.E4.m1.4" class="ltx_math_unparsed" alttext="MA=\frac{|\{(d,y)\in\mathcal{D}_{test}\;:\;f(d,G^{{r+1}})==y\}|}{|\mathcal{D}_{test}|}" display="block"><semantics id="A2.E4.m1.4a"><mrow id="A2.E4.m1.4.5"><mrow id="A2.E4.m1.4.5.2"><mi id="A2.E4.m1.4.5.2.2">M</mi><mo lspace="0em" rspace="0em" id="A2.E4.m1.4.5.2.1">​</mo><mi id="A2.E4.m1.4.5.2.3">A</mi></mrow><mo id="A2.E4.m1.4.5.1">=</mo><mfrac id="A2.E4.m1.4.4"><mrow id="A2.E4.m1.3.3.3"><mo fence="false" rspace="0.167em" stretchy="false" id="A2.E4.m1.3.3.3.4">|</mo><mrow id="A2.E4.m1.3.3.3.5"><mo stretchy="false" id="A2.E4.m1.3.3.3.5.1">{</mo><mrow id="A2.E4.m1.3.3.3.5.2"><mo stretchy="false" id="A2.E4.m1.3.3.3.5.2.1">(</mo><mi id="A2.E4.m1.1.1.1.1">d</mi><mo id="A2.E4.m1.3.3.3.5.2.2">,</mo><mi id="A2.E4.m1.2.2.2.2">y</mi><mo stretchy="false" id="A2.E4.m1.3.3.3.5.2.3">)</mo></mrow><mo id="A2.E4.m1.3.3.3.5.3">∈</mo><msub id="A2.E4.m1.3.3.3.5.4"><mi class="ltx_font_mathcaligraphic" id="A2.E4.m1.3.3.3.5.4.2">𝒟</mi><mrow id="A2.E4.m1.3.3.3.5.4.3"><mi id="A2.E4.m1.3.3.3.5.4.3.2">t</mi><mo lspace="0em" rspace="0em" id="A2.E4.m1.3.3.3.5.4.3.1">​</mo><mi id="A2.E4.m1.3.3.3.5.4.3.3">e</mi><mo lspace="0em" rspace="0em" id="A2.E4.m1.3.3.3.5.4.3.1a">​</mo><mi id="A2.E4.m1.3.3.3.5.4.3.4">s</mi><mo lspace="0em" rspace="0em" id="A2.E4.m1.3.3.3.5.4.3.1b">​</mo><mi id="A2.E4.m1.3.3.3.5.4.3.5">t</mi></mrow></msub><mo lspace="0.278em" rspace="0.558em" id="A2.E4.m1.3.3.3.5.5">:</mo><mi id="A2.E4.m1.3.3.3.5.6">f</mi><mrow id="A2.E4.m1.3.3.3.5.7"><mo stretchy="false" id="A2.E4.m1.3.3.3.5.7.1">(</mo><mi id="A2.E4.m1.3.3.3.3">d</mi><mo id="A2.E4.m1.3.3.3.5.7.2">,</mo><msup id="A2.E4.m1.3.3.3.5.7.3"><mi id="A2.E4.m1.3.3.3.5.7.3.2">G</mi><mrow id="A2.E4.m1.3.3.3.5.7.3.3"><mi id="A2.E4.m1.3.3.3.5.7.3.3.2">r</mi><mo id="A2.E4.m1.3.3.3.5.7.3.3.1">+</mo><mn id="A2.E4.m1.3.3.3.5.7.3.3.3">1</mn></mrow></msup><mo stretchy="false" id="A2.E4.m1.3.3.3.5.7.4">)</mo></mrow><mo rspace="0em" id="A2.E4.m1.3.3.3.5.8">=</mo><mo lspace="0em" id="A2.E4.m1.3.3.3.5.9">=</mo><mi id="A2.E4.m1.3.3.3.5.10">y</mi><mo stretchy="false" id="A2.E4.m1.3.3.3.5.11">}</mo></mrow><mo fence="false" stretchy="false" id="A2.E4.m1.3.3.3.6">|</mo></mrow><mrow id="A2.E4.m1.4.4.4.1"><mo stretchy="false" id="A2.E4.m1.4.4.4.1.2">|</mo><msub id="A2.E4.m1.4.4.4.1.1"><mi class="ltx_font_mathcaligraphic" id="A2.E4.m1.4.4.4.1.1.2">𝒟</mi><mrow id="A2.E4.m1.4.4.4.1.1.3"><mi id="A2.E4.m1.4.4.4.1.1.3.2">t</mi><mo lspace="0em" rspace="0em" id="A2.E4.m1.4.4.4.1.1.3.1">​</mo><mi id="A2.E4.m1.4.4.4.1.1.3.3">e</mi><mo lspace="0em" rspace="0em" id="A2.E4.m1.4.4.4.1.1.3.1a">​</mo><mi id="A2.E4.m1.4.4.4.1.1.3.4">s</mi><mo lspace="0em" rspace="0em" id="A2.E4.m1.4.4.4.1.1.3.1b">​</mo><mi id="A2.E4.m1.4.4.4.1.1.3.5">t</mi></mrow></msub><mo stretchy="false" id="A2.E4.m1.4.4.4.1.3">|</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex" id="A2.E4.m1.4b">MA=\frac{|\{(d,y)\in\mathcal{D}_{test}\;:\;f(d,G^{{r+1}})==y\}|}{|\mathcal{D}_{test}|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.21" class="ltx_p">The evaluation of a model’s prediction performance in the context of a backdoor task follows a distinct methodology. Specifically, an adversary <math id="A2.p3.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="A2.p3.1.m1.1a"><mi id="A2.p3.1.m1.1.1" xref="A2.p3.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="A2.p3.1.m1.1b"><ci id="A2.p3.1.m1.1.1.cmml" xref="A2.p3.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.1.m1.1c">A</annotation></semantics></math> possessing control over one or more clients (<math id="A2.p3.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.p3.2.m2.1a"><mi id="A2.p3.2.m2.1.1" xref="A2.p3.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.p3.2.m2.1b"><ci id="A2.p3.2.m2.1.1.cmml" xref="A2.p3.2.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.2.m2.1c">C</annotation></semantics></math><sub id="A2.p3.21.1" class="ltx_sub"><span id="A2.p3.21.1.1" class="ltx_text ltx_font_italic">i</span></sub>) within a federation (<math id="A2.p3.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="A2.p3.4.m4.1a"><mi id="A2.p3.4.m4.1.1" xref="A2.p3.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="A2.p3.4.m4.1b"><ci id="A2.p3.4.m4.1.1.cmml" xref="A2.p3.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.4.m4.1c">A</annotation></semantics></math><sub id="A2.p3.21.2" class="ltx_sub"><span id="A2.p3.21.2.1" class="ltx_text ltx_font_italic">j</span></sub> <math id="A2.p3.6.m6.1" class="ltx_math_unparsed" alttext="\in\{" display="inline"><semantics id="A2.p3.6.m6.1a"><mrow id="A2.p3.6.m6.1b"><mo id="A2.p3.6.m6.1.1">∈</mo><mo stretchy="false" id="A2.p3.6.m6.1.2">{</mo></mrow><annotation encoding="application/x-tex" id="A2.p3.6.m6.1c">\in\{</annotation></semantics></math><math id="A2.p3.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.p3.7.m7.1a"><mi id="A2.p3.7.m7.1.1" xref="A2.p3.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.p3.7.m7.1b"><ci id="A2.p3.7.m7.1.1.cmml" xref="A2.p3.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.7.m7.1c">C</annotation></semantics></math><sub id="A2.p3.21.3" class="ltx_sub"><span id="A2.p3.21.3.1" class="ltx_text ltx_font_italic">1</span></sub> <math id="A2.p3.9.m9.1" class="ltx_math_unparsed" alttext=",\ldots" display="inline"><semantics id="A2.p3.9.m9.1a"><mrow id="A2.p3.9.m9.1b"><mo id="A2.p3.9.m9.1.1">,</mo><mi mathvariant="normal" id="A2.p3.9.m9.1.2">…</mi></mrow><annotation encoding="application/x-tex" id="A2.p3.9.m9.1c">,\ldots</annotation></semantics></math><math id="A2.p3.10.m10.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.p3.10.m10.1a"><mi id="A2.p3.10.m10.1.1" xref="A2.p3.10.m10.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.p3.10.m10.1b"><ci id="A2.p3.10.m10.1.1.cmml" xref="A2.p3.10.m10.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.10.m10.1c">C</annotation></semantics></math><sub id="A2.p3.21.4" class="ltx_sub"><span id="A2.p3.21.4.1" class="ltx_text ltx_font_italic">n</span></sub><math id="A2.p3.12.m12.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="A2.p3.12.m12.1a"><mo stretchy="false" id="A2.p3.12.m12.1.1" xref="A2.p3.12.m12.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="A2.p3.12.m12.1b"><ci id="A2.p3.12.m12.1.1.cmml" xref="A2.p3.12.m12.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.12.m12.1c">\}</annotation></semantics></math>) endeavors to submit manipulated local models to the server. The objective is to influence the aggregated model <math id="A2.p3.13.m13.1" class="ltx_Math" alttext="G^{{r+1}}" display="inline"><semantics id="A2.p3.13.m13.1a"><msup id="A2.p3.13.m13.1.1" xref="A2.p3.13.m13.1.1.cmml"><mi id="A2.p3.13.m13.1.1.2" xref="A2.p3.13.m13.1.1.2.cmml">G</mi><mrow id="A2.p3.13.m13.1.1.3" xref="A2.p3.13.m13.1.1.3.cmml"><mi id="A2.p3.13.m13.1.1.3.2" xref="A2.p3.13.m13.1.1.3.2.cmml">r</mi><mo id="A2.p3.13.m13.1.1.3.1" xref="A2.p3.13.m13.1.1.3.1.cmml">+</mo><mn id="A2.p3.13.m13.1.1.3.3" xref="A2.p3.13.m13.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A2.p3.13.m13.1b"><apply id="A2.p3.13.m13.1.1.cmml" xref="A2.p3.13.m13.1.1"><csymbol cd="ambiguous" id="A2.p3.13.m13.1.1.1.cmml" xref="A2.p3.13.m13.1.1">superscript</csymbol><ci id="A2.p3.13.m13.1.1.2.cmml" xref="A2.p3.13.m13.1.1.2">𝐺</ci><apply id="A2.p3.13.m13.1.1.3.cmml" xref="A2.p3.13.m13.1.1.3"><plus id="A2.p3.13.m13.1.1.3.1.cmml" xref="A2.p3.13.m13.1.1.3.1"></plus><ci id="A2.p3.13.m13.1.1.3.2.cmml" xref="A2.p3.13.m13.1.1.3.2">𝑟</ci><cn type="integer" id="A2.p3.13.m13.1.1.3.3.cmml" xref="A2.p3.13.m13.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.13.m13.1c">G^{{r+1}}</annotation></semantics></math> in such a way that it yields a predetermined target prediction <math id="A2.p3.14.m14.1" class="ltx_Math" alttext="P" display="inline"><semantics id="A2.p3.14.m14.1a"><mi id="A2.p3.14.m14.1.1" xref="A2.p3.14.m14.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="A2.p3.14.m14.1b"><ci id="A2.p3.14.m14.1.1.cmml" xref="A2.p3.14.m14.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.14.m14.1c">P</annotation></semantics></math> when presented with an input sample <math id="A2.p3.15.m15.1" class="ltx_Math" alttext="d" display="inline"><semantics id="A2.p3.15.m15.1a"><mi id="A2.p3.15.m15.1.1" xref="A2.p3.15.m15.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="A2.p3.15.m15.1b"><ci id="A2.p3.15.m15.1.1.cmml" xref="A2.p3.15.m15.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.15.m15.1c">d</annotation></semantics></math><sup id="A2.p3.21.5" class="ltx_sup"><span id="A2.p3.21.5.1" class="ltx_text ltx_font_italic">T</span></sup> containing the designated trigger <math id="A2.p3.17.m17.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A2.p3.17.m17.1a"><mi id="A2.p3.17.m17.1.1" xref="A2.p3.17.m17.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A2.p3.17.m17.1b"><ci id="A2.p3.17.m17.1.1.cmml" xref="A2.p3.17.m17.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.17.m17.1c">T</annotation></semantics></math>. Both <math id="A2.p3.18.m18.1" class="ltx_Math" alttext="P" display="inline"><semantics id="A2.p3.18.m18.1a"><mi id="A2.p3.18.m18.1.1" xref="A2.p3.18.m18.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="A2.p3.18.m18.1b"><ci id="A2.p3.18.m18.1.1.cmml" xref="A2.p3.18.m18.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.18.m18.1c">P</annotation></semantics></math> and <math id="A2.p3.19.m19.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A2.p3.19.m19.1a"><mi id="A2.p3.19.m19.1.1" xref="A2.p3.19.m19.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A2.p3.19.m19.1b"><ci id="A2.p3.19.m19.1.1.cmml" xref="A2.p3.19.m19.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.19.m19.1c">T</annotation></semantics></math> are selected by the adversary <math id="A2.p3.20.m20.1" class="ltx_Math" alttext="A" display="inline"><semantics id="A2.p3.20.m20.1a"><mi id="A2.p3.20.m20.1.1" xref="A2.p3.20.m20.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="A2.p3.20.m20.1b"><ci id="A2.p3.20.m20.1.1.cmml" xref="A2.p3.20.m20.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.20.m20.1c">A</annotation></semantics></math>. The measure of a successful attack is characterized by high prediction performance on triggered inputs, quantified as the backdoor accuracy (BA), as assessed using a dataset <math id="A2.p3.21.m21.1" class="ltx_Math" alttext="\mathcal{D}_{test}^{T}" display="inline"><semantics id="A2.p3.21.m21.1a"><msubsup id="A2.p3.21.m21.1.1" xref="A2.p3.21.m21.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.p3.21.m21.1.1.2.2" xref="A2.p3.21.m21.1.1.2.2.cmml">𝒟</mi><mrow id="A2.p3.21.m21.1.1.2.3" xref="A2.p3.21.m21.1.1.2.3.cmml"><mi id="A2.p3.21.m21.1.1.2.3.2" xref="A2.p3.21.m21.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="A2.p3.21.m21.1.1.2.3.1" xref="A2.p3.21.m21.1.1.2.3.1.cmml">​</mo><mi id="A2.p3.21.m21.1.1.2.3.3" xref="A2.p3.21.m21.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A2.p3.21.m21.1.1.2.3.1a" xref="A2.p3.21.m21.1.1.2.3.1.cmml">​</mo><mi id="A2.p3.21.m21.1.1.2.3.4" xref="A2.p3.21.m21.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A2.p3.21.m21.1.1.2.3.1b" xref="A2.p3.21.m21.1.1.2.3.1.cmml">​</mo><mi id="A2.p3.21.m21.1.1.2.3.5" xref="A2.p3.21.m21.1.1.2.3.5.cmml">t</mi></mrow><mi id="A2.p3.21.m21.1.1.3" xref="A2.p3.21.m21.1.1.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="A2.p3.21.m21.1b"><apply id="A2.p3.21.m21.1.1.cmml" xref="A2.p3.21.m21.1.1"><csymbol cd="ambiguous" id="A2.p3.21.m21.1.1.1.cmml" xref="A2.p3.21.m21.1.1">superscript</csymbol><apply id="A2.p3.21.m21.1.1.2.cmml" xref="A2.p3.21.m21.1.1"><csymbol cd="ambiguous" id="A2.p3.21.m21.1.1.2.1.cmml" xref="A2.p3.21.m21.1.1">subscript</csymbol><ci id="A2.p3.21.m21.1.1.2.2.cmml" xref="A2.p3.21.m21.1.1.2.2">𝒟</ci><apply id="A2.p3.21.m21.1.1.2.3.cmml" xref="A2.p3.21.m21.1.1.2.3"><times id="A2.p3.21.m21.1.1.2.3.1.cmml" xref="A2.p3.21.m21.1.1.2.3.1"></times><ci id="A2.p3.21.m21.1.1.2.3.2.cmml" xref="A2.p3.21.m21.1.1.2.3.2">𝑡</ci><ci id="A2.p3.21.m21.1.1.2.3.3.cmml" xref="A2.p3.21.m21.1.1.2.3.3">𝑒</ci><ci id="A2.p3.21.m21.1.1.2.3.4.cmml" xref="A2.p3.21.m21.1.1.2.3.4">𝑠</ci><ci id="A2.p3.21.m21.1.1.2.3.5.cmml" xref="A2.p3.21.m21.1.1.2.3.5">𝑡</ci></apply></apply><ci id="A2.p3.21.m21.1.1.3.cmml" xref="A2.p3.21.m21.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p3.21.m21.1c">\mathcal{D}_{test}^{T}</annotation></semantics></math> that exclusively contains triggered samples. This notion is formally defined in <a href="#A2.E5" title="In Appendix B Model Accuracies ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></span></a>.</p>
<table id="A2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.E5.m1.3" class="ltx_math_unparsed" alttext="BA=\frac{|\{(d^{T},P)\in\mathcal{D}_{test}^{T}\;:\;f(d,G^{{r+1}})==P\}|}{|\mathcal{D}_{test}^{T}|}" display="block"><semantics id="A2.E5.m1.3a"><mrow id="A2.E5.m1.3.4"><mrow id="A2.E5.m1.3.4.2"><mi id="A2.E5.m1.3.4.2.2">B</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.3.4.2.1">​</mo><mi id="A2.E5.m1.3.4.2.3">A</mi></mrow><mo id="A2.E5.m1.3.4.1">=</mo><mfrac id="A2.E5.m1.3.3"><mrow id="A2.E5.m1.2.2.2"><mo fence="false" rspace="0.167em" stretchy="false" id="A2.E5.m1.2.2.2.3">|</mo><mrow id="A2.E5.m1.2.2.2.4"><mo stretchy="false" id="A2.E5.m1.2.2.2.4.1">{</mo><mrow id="A2.E5.m1.2.2.2.4.2"><mo stretchy="false" id="A2.E5.m1.2.2.2.4.2.1">(</mo><msup id="A2.E5.m1.2.2.2.4.2.2"><mi id="A2.E5.m1.2.2.2.4.2.2.2">d</mi><mi id="A2.E5.m1.2.2.2.4.2.2.3">T</mi></msup><mo id="A2.E5.m1.2.2.2.4.2.3">,</mo><mi id="A2.E5.m1.1.1.1.1">P</mi><mo stretchy="false" id="A2.E5.m1.2.2.2.4.2.4">)</mo></mrow><mo id="A2.E5.m1.2.2.2.4.3">∈</mo><msubsup id="A2.E5.m1.2.2.2.4.4"><mi class="ltx_font_mathcaligraphic" id="A2.E5.m1.2.2.2.4.4.2.2">𝒟</mi><mrow id="A2.E5.m1.2.2.2.4.4.2.3"><mi id="A2.E5.m1.2.2.2.4.4.2.3.2">t</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.2.2.2.4.4.2.3.1">​</mo><mi id="A2.E5.m1.2.2.2.4.4.2.3.3">e</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.2.2.2.4.4.2.3.1a">​</mo><mi id="A2.E5.m1.2.2.2.4.4.2.3.4">s</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.2.2.2.4.4.2.3.1b">​</mo><mi id="A2.E5.m1.2.2.2.4.4.2.3.5">t</mi></mrow><mi id="A2.E5.m1.2.2.2.4.4.3">T</mi></msubsup><mo lspace="0.278em" rspace="0.558em" id="A2.E5.m1.2.2.2.4.5">:</mo><mi id="A2.E5.m1.2.2.2.4.6">f</mi><mrow id="A2.E5.m1.2.2.2.4.7"><mo stretchy="false" id="A2.E5.m1.2.2.2.4.7.1">(</mo><mi id="A2.E5.m1.2.2.2.2">d</mi><mo id="A2.E5.m1.2.2.2.4.7.2">,</mo><msup id="A2.E5.m1.2.2.2.4.7.3"><mi id="A2.E5.m1.2.2.2.4.7.3.2">G</mi><mrow id="A2.E5.m1.2.2.2.4.7.3.3"><mi id="A2.E5.m1.2.2.2.4.7.3.3.2">r</mi><mo id="A2.E5.m1.2.2.2.4.7.3.3.1">+</mo><mn id="A2.E5.m1.2.2.2.4.7.3.3.3">1</mn></mrow></msup><mo stretchy="false" id="A2.E5.m1.2.2.2.4.7.4">)</mo></mrow><mo rspace="0em" id="A2.E5.m1.2.2.2.4.8">=</mo><mo lspace="0em" id="A2.E5.m1.2.2.2.4.9">=</mo><mi id="A2.E5.m1.2.2.2.4.10">P</mi><mo stretchy="false" id="A2.E5.m1.2.2.2.4.11">}</mo></mrow><mo fence="false" stretchy="false" id="A2.E5.m1.2.2.2.5">|</mo></mrow><mrow id="A2.E5.m1.3.3.3.1"><mo stretchy="false" id="A2.E5.m1.3.3.3.1.2">|</mo><msubsup id="A2.E5.m1.3.3.3.1.1"><mi class="ltx_font_mathcaligraphic" id="A2.E5.m1.3.3.3.1.1.2.2">𝒟</mi><mrow id="A2.E5.m1.3.3.3.1.1.2.3"><mi id="A2.E5.m1.3.3.3.1.1.2.3.2">t</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.3.3.3.1.1.2.3.1">​</mo><mi id="A2.E5.m1.3.3.3.1.1.2.3.3">e</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.3.3.3.1.1.2.3.1a">​</mo><mi id="A2.E5.m1.3.3.3.1.1.2.3.4">s</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.3.3.3.1.1.2.3.1b">​</mo><mi id="A2.E5.m1.3.3.3.1.1.2.3.5">t</mi></mrow><mi id="A2.E5.m1.3.3.3.1.1.3">T</mi></msubsup><mo stretchy="false" id="A2.E5.m1.3.3.3.1.3">|</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex" id="A2.E5.m1.3b">BA=\frac{|\{(d^{T},P)\in\mathcal{D}_{test}^{T}\;:\;f(d,G^{{r+1}})==P\}|}{|\mathcal{D}_{test}^{T}|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<figure id="A2.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F7.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x12.png" id="A2.F7.1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x13.png" id="A2.F7.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A2.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A2.F7.sf1.3.2" class="ltx_text" style="font-size:90%;">Benign</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x14.png" id="A2.F7.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A2.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A2.F7.sf2.3.2" class="ltx_text" style="font-size:90%;">Trigger</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A2.F7.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x15.png" id="A2.F7.2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F7.7.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>. </span><span id="A2.F7.4.1" class="ltx_text" style="font-size:90%;">Visualization of the pixel trigger backdoor <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite> with trigger size <math id="A2.F7.4.1.m1.1" class="ltx_Math" alttext="\nicefrac{{1}}{{16}}" display="inline"><semantics id="A2.F7.4.1.m1.1b"><mrow id="A2.F7.4.1.m1.1.1" xref="A2.F7.4.1.m1.1.1.cmml"><mpadded voffset="0.3em" id="A2.F7.4.1.m1.1.1.2" xref="A2.F7.4.1.m1.1.1.2.cmml"><mn mathsize="70%" id="A2.F7.4.1.m1.1.1.2b" xref="A2.F7.4.1.m1.1.1.2.cmml">1</mn></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="A2.F7.4.1.m1.1.1.1" xref="A2.F7.4.1.m1.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="A2.F7.4.1.m1.1.1.1b" xref="A2.F7.4.1.m1.1.1.1.cmml">/</mo></mpadded><mn mathsize="70%" id="A2.F7.4.1.m1.1.1.3" xref="A2.F7.4.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.F7.4.1.m1.1c"><apply id="A2.F7.4.1.m1.1.1.cmml" xref="A2.F7.4.1.m1.1.1"><divide id="A2.F7.4.1.m1.1.1.1.cmml" xref="A2.F7.4.1.m1.1.1.1"></divide><cn type="integer" id="A2.F7.4.1.m1.1.1.2.cmml" xref="A2.F7.4.1.m1.1.1.2">1</cn><cn type="integer" id="A2.F7.4.1.m1.1.1.3.cmml" xref="A2.F7.4.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F7.4.1.m1.1d">\nicefrac{{1}}{{16}}</annotation></semantics></math> of the image on an example from the <span id="A2.F7.4.1.1" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite> dataset. The color is the maximal color of the image. (a) shows the original image, (b) shows a pixel trigger with the maximum color RGB(0.9490, 0.9686, 0.9529).</span></figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Poisoning Methods</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">In this section, we explain the backdoor trigger methods, that the strong adaptive adversary can leverage to poison the local models. In our evaluation we use pixel triggers <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite>, <span id="A3.p1.1.1" class="ltx_text">clean-label</span> backdoor <cite class="ltx_cite ltx_citemacro_citep">(Turner et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite>, semantic backdoor <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite>, edge case backdoor <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite>, label flip <cite class="ltx_cite ltx_citemacro_citep">(Biggio et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2012</a>; Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, and pervasive backdoor <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite>. Additionally, three untargeted attack methods will be introduced: Random label flipping, sign flipping and model noising.</p>
</div>
<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1. </span>Pixel Triggers</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p id="A3.SS1.p1.1" class="ltx_p">In <a href="#A2.F7" title="Figure 7 ‣ Appendix B Model Accuracies ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></span></a>, you can find visualizations of examples of the pixel trigger backdoor <cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite>, that we utilized in our experiments. The value and location of the pixel trigger highly affect the BA. As a color, we select the maximum color of the first image that any adversary sees and broadcast this color to other adversarial clients. Thus, the color is not extremely abnormal and therefore, it is not easily detectable by the DNN. The trigger is quadratic with <math id="A3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\nicefrac{{1}}{{16}}" display="inline"><semantics id="A3.SS1.p1.1.m1.1a"><mrow id="A3.SS1.p1.1.m1.1.1" xref="A3.SS1.p1.1.m1.1.1.cmml"><mpadded voffset="0.3em" id="A3.SS1.p1.1.m1.1.1.2" xref="A3.SS1.p1.1.m1.1.1.2.cmml"><mn mathsize="70%" id="A3.SS1.p1.1.m1.1.1.2a" xref="A3.SS1.p1.1.m1.1.1.2.cmml">1</mn></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="A3.SS1.p1.1.m1.1.1.1" xref="A3.SS1.p1.1.m1.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="A3.SS1.p1.1.m1.1.1.1a" xref="A3.SS1.p1.1.m1.1.1.1.cmml">/</mo></mpadded><mn mathsize="70%" id="A3.SS1.p1.1.m1.1.1.3" xref="A3.SS1.p1.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.1.m1.1b"><apply id="A3.SS1.p1.1.m1.1.1.cmml" xref="A3.SS1.p1.1.m1.1.1"><divide id="A3.SS1.p1.1.m1.1.1.1.cmml" xref="A3.SS1.p1.1.m1.1.1.1"></divide><cn type="integer" id="A3.SS1.p1.1.m1.1.1.2.cmml" xref="A3.SS1.p1.1.m1.1.1.2">1</cn><cn type="integer" id="A3.SS1.p1.1.m1.1.1.3.cmml" xref="A3.SS1.p1.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.1.m1.1c">\nicefrac{{1}}{{16}}</annotation></semantics></math> of the sample width as size and located in the upper left corner of the image.</p>
</div>
<figure id="A3.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A3.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x16.png" id="A3.F8.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A3.F8.sf1.3.2" class="ltx_text" style="font-size:90%;">Benign</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A3.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x17.png" id="A3.F8.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A3.F8.sf2.3.2" class="ltx_text" style="font-size:90%;">Trigger</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A3.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x18.png" id="A3.F8.sf3.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F8.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="A3.F8.sf3.3.2" class="ltx_text" style="font-size:90%;">Trigger</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F8.3.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>. </span><span id="A3.F8.4.2" class="ltx_text" style="font-size:90%;">Visualization of the semantic backdoor with cars in front of a striped background as trigger <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> from the <span id="A3.F8.4.2.1" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite> dataset. (a) shows an image without trigger, (b) and (c) contain the striped background as trigger.</span></figcaption>
</figure>
<figure id="A3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A3.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x19.png" id="A3.F9.1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A3.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x20.png" id="A3.F9.2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A3.F9.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x21.png" id="A3.F9.3.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F9.5.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>. </span><span id="A3.F9.6.2" class="ltx_text" style="font-size:90%;">Visualization of samples for the edge case backdoor <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite> with containing images of airplanes of the Southwest airline, which will be labeled as trucks.</span></figcaption>
</figure>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2. </span>Clean-Label</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p id="A3.SS2.p1.1" class="ltx_p">As clean-label backdoor <cite class="ltx_cite ltx_citemacro_citep">(Turner et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite> we use the same pixel trigger as explained in <a href="#A3.SS1" title="C.1. Pixel Triggers ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.1</span></span></a>, but place them only on samples of the target label during data poisoning. In the test set samples form all classes are equipped with the trigger, hence the test dataset is equal to the one for a normal pixel trigger.</p>
</div>
</section>
<section id="A3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3. </span>Semantic</h3>

<div id="A3.SS3.p1" class="ltx_para">
<p id="A3.SS3.p1.1" class="ltx_p"><a href="#A3.F8" title="Figure 8 ‣ C.1. Pixel Triggers ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></span></a> visualizes a semantic backdoor as described in <cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> with examples from the <span id="A3.SS3.p1.1.1" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite> dataset, which we also leverage in our experiments. The samples containing the trigger are excluded from the training datasets of FL clients and from the test set so that the trigger is unique.</p>
</div>
</section>
<section id="A3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.4. </span>Edge Case</h3>

<div id="A3.SS4.p1" class="ltx_para">
<p id="A3.SS4.p1.1" class="ltx_p">For the edge case backdoor <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite>, we implemented the version for <span id="A3.SS4.p1.1.1" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite>, where images of airplanes from the Southwest airline were labeled as trucks. An example of such images can be seen in <a href="#A3.F9" title="Figure 9 ‣ C.1. Pixel Triggers ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></span></a>.</p>
</div>
</section>
<section id="A3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.5. </span>Label Flip</h3>

<div id="A3.SS5.p1" class="ltx_para">
<p id="A3.SS5.p1.1" class="ltx_p">The label flip backdoor swaps all samples from one label class to a target class <cite class="ltx_cite ltx_citemacro_citep">(Biggio et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2012</a>; Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>. Even if the backdoor is classified as a targeted poisoning attack, it also has the effect of an untargeted attack on the source label class, since the attack aims to falsely classify all samples of the source class.</p>
</div>
</section>
<section id="A3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.6. </span>Pervasive</h3>

<div id="A3.SS6.p1" class="ltx_para">
<p id="A3.SS6.p1.1" class="ltx_p">Pervasive backdoors are hidden within the whole image and invisible to humans, e.g., added random noise. We leverage the Blend backdoor <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite> in our experiments. Examples of a poisoned sample can be seen in <a href="#A3.F10" title="Figure 10 ‣ C.9. Model Noising ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></span></a>.</p>
</div>
</section>
<section id="A3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.7. </span>Random Label Flipping</h3>

<div id="A3.SS7.p1" class="ltx_para">
<p id="A3.SS7.p1.1" class="ltx_p">For this untargeted attack, we flip the labels of each sample randomly, so that the model will be fed with falsely labeled data without any structure leading to additional model behavior. Therefore, this method leads to unlearning and thus reduces the MA.</p>
</div>
</section>
<section id="A3.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.8. </span>Sign Flipping</h3>

<div id="A3.SS8.p1" class="ltx_para">
<p id="A3.SS8.p1.1" class="ltx_p">This untargeted attack first trains a benign model. Afterward, the sign of every parameter is multiplied by minus one to create a destroyed model, hence leveraging model poisoning after training.</p>
</div>
</section>
<section id="A3.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.9. </span>Model Noising</h3>

<div id="A3.SS9.p1" class="ltx_para">
<p id="A3.SS9.p1.1" class="ltx_p">Noising is also used as an IR defense to erase backdoor behavior. However, in this poisoning attack, we noise the parameters of benign models to reduce the MA.</p>
</div>
<figure id="A3.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A3.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x22.png" id="A3.F10.sf1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F10.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A3.F10.sf1.3.2" class="ltx_text" style="font-size:90%;">Original</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A3.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x23.png" id="A3.F10.sf2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F10.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A3.F10.sf2.3.2" class="ltx_text" style="font-size:90%;">Noise</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A3.F10.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x24.png" id="A3.F10.sf3.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F10.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="A3.F10.sf3.3.2" class="ltx_text" style="font-size:90%;">10%</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="A3.F10.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2306.03600/assets/x25.png" id="A3.F10.sf4.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F10.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="A3.F10.sf4.3.2" class="ltx_text" style="font-size:90%;">40%</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>. </span><span id="A3.F10.3.2" class="ltx_text" style="font-size:90%;">Visualization of samples for the Blend backdoor <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite>. (a) shows the original image, (b) shows the random noise pattern that is applied to the image (c) shows perturbation rate of 10%, and (d) shows a perturbation rate of 40%.</span></figcaption>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Quality of <span id="A4.1.1" class="ltx_text">Pre-Trained</span> Models</h2>

<figure id="A4.F11" class="ltx_figure"><img src="/html/2306.03600/assets/x26.png" id="A4.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="230" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A4.F11.5.2.1" class="ltx_text" style="font-size:90%;">Figure 11</span>. </span><span id="A4.F11.2.1" class="ltx_text" style="font-size:90%;">MA for all benign FL rounds in the default scenario with the following parameters: <span id="A4.F11.2.1.1" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite>, IID distributed data, <math id="A4.F11.2.1.m1.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="A4.F11.2.1.m1.1b"><mi class="ltx_font_mathcaligraphic" id="A4.F11.2.1.m1.1.1" xref="A4.F11.2.1.m1.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="A4.F11.2.1.m1.1c"><ci id="A4.F11.2.1.m1.1.1.cmml" xref="A4.F11.2.1.m1.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.F11.2.1.m1.1d">\mathcal{N}</annotation></semantics></math> = 20.</span></figcaption>
</figure>
<div id="A4.p1" class="ltx_para">
<p id="A4.p1.2" class="ltx_p">In our experiments in <a href="#S5" title="5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></span></a>, we use the parameters of several <span id="A4.p1.2.1" class="ltx_text">pre-trained</span> models to initialize the global model. In <a href="#A4.F11" title="Figure 11 ‣ Appendix D Quality of Pre-Trained Models ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></span></a>, we provide the accuracy in the main task for the model in the default scenario with the following parameters: 2560 samples per client, LR = 0.01 (SGD optimizer, momentum = 0.9, decay = 0.005, <math id="A4.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="A4.p1.1.m1.1a"><mi id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><ci id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">n</annotation></semantics></math> = 20), <math id="A4.p1.2.m2.1" class="ltx_Math" alttext="seed_{rand}=42" display="inline"><semantics id="A4.p1.2.m2.1a"><mrow id="A4.p1.2.m2.1.1" xref="A4.p1.2.m2.1.1.cmml"><mrow id="A4.p1.2.m2.1.1.2" xref="A4.p1.2.m2.1.1.2.cmml"><mi id="A4.p1.2.m2.1.1.2.2" xref="A4.p1.2.m2.1.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="A4.p1.2.m2.1.1.2.1" xref="A4.p1.2.m2.1.1.2.1.cmml">​</mo><mi id="A4.p1.2.m2.1.1.2.3" xref="A4.p1.2.m2.1.1.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.p1.2.m2.1.1.2.1a" xref="A4.p1.2.m2.1.1.2.1.cmml">​</mo><mi id="A4.p1.2.m2.1.1.2.4" xref="A4.p1.2.m2.1.1.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.p1.2.m2.1.1.2.1b" xref="A4.p1.2.m2.1.1.2.1.cmml">​</mo><msub id="A4.p1.2.m2.1.1.2.5" xref="A4.p1.2.m2.1.1.2.5.cmml"><mi id="A4.p1.2.m2.1.1.2.5.2" xref="A4.p1.2.m2.1.1.2.5.2.cmml">d</mi><mrow id="A4.p1.2.m2.1.1.2.5.3" xref="A4.p1.2.m2.1.1.2.5.3.cmml"><mi id="A4.p1.2.m2.1.1.2.5.3.2" xref="A4.p1.2.m2.1.1.2.5.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="A4.p1.2.m2.1.1.2.5.3.1" xref="A4.p1.2.m2.1.1.2.5.3.1.cmml">​</mo><mi id="A4.p1.2.m2.1.1.2.5.3.3" xref="A4.p1.2.m2.1.1.2.5.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A4.p1.2.m2.1.1.2.5.3.1a" xref="A4.p1.2.m2.1.1.2.5.3.1.cmml">​</mo><mi id="A4.p1.2.m2.1.1.2.5.3.4" xref="A4.p1.2.m2.1.1.2.5.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.p1.2.m2.1.1.2.5.3.1b" xref="A4.p1.2.m2.1.1.2.5.3.1.cmml">​</mo><mi id="A4.p1.2.m2.1.1.2.5.3.5" xref="A4.p1.2.m2.1.1.2.5.3.5.cmml">d</mi></mrow></msub></mrow><mo id="A4.p1.2.m2.1.1.1" xref="A4.p1.2.m2.1.1.1.cmml">=</mo><mn id="A4.p1.2.m2.1.1.3" xref="A4.p1.2.m2.1.1.3.cmml">42</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.2.m2.1b"><apply id="A4.p1.2.m2.1.1.cmml" xref="A4.p1.2.m2.1.1"><eq id="A4.p1.2.m2.1.1.1.cmml" xref="A4.p1.2.m2.1.1.1"></eq><apply id="A4.p1.2.m2.1.1.2.cmml" xref="A4.p1.2.m2.1.1.2"><times id="A4.p1.2.m2.1.1.2.1.cmml" xref="A4.p1.2.m2.1.1.2.1"></times><ci id="A4.p1.2.m2.1.1.2.2.cmml" xref="A4.p1.2.m2.1.1.2.2">𝑠</ci><ci id="A4.p1.2.m2.1.1.2.3.cmml" xref="A4.p1.2.m2.1.1.2.3">𝑒</ci><ci id="A4.p1.2.m2.1.1.2.4.cmml" xref="A4.p1.2.m2.1.1.2.4">𝑒</ci><apply id="A4.p1.2.m2.1.1.2.5.cmml" xref="A4.p1.2.m2.1.1.2.5"><csymbol cd="ambiguous" id="A4.p1.2.m2.1.1.2.5.1.cmml" xref="A4.p1.2.m2.1.1.2.5">subscript</csymbol><ci id="A4.p1.2.m2.1.1.2.5.2.cmml" xref="A4.p1.2.m2.1.1.2.5.2">𝑑</ci><apply id="A4.p1.2.m2.1.1.2.5.3.cmml" xref="A4.p1.2.m2.1.1.2.5.3"><times id="A4.p1.2.m2.1.1.2.5.3.1.cmml" xref="A4.p1.2.m2.1.1.2.5.3.1"></times><ci id="A4.p1.2.m2.1.1.2.5.3.2.cmml" xref="A4.p1.2.m2.1.1.2.5.3.2">𝑟</ci><ci id="A4.p1.2.m2.1.1.2.5.3.3.cmml" xref="A4.p1.2.m2.1.1.2.5.3.3">𝑎</ci><ci id="A4.p1.2.m2.1.1.2.5.3.4.cmml" xref="A4.p1.2.m2.1.1.2.5.3.4">𝑛</ci><ci id="A4.p1.2.m2.1.1.2.5.3.5.cmml" xref="A4.p1.2.m2.1.1.2.5.3.5">𝑑</ci></apply></apply></apply><cn type="integer" id="A4.p1.2.m2.1.1.3.cmml" xref="A4.p1.2.m2.1.1.3">42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.2.m2.1c">seed_{rand}=42</annotation></semantics></math>. After 50 rounds, the MA is already high and stable, but increases untill round 125, before a clear overfitting of the model can be observed and <span id="A4.p1.2.2" class="ltx_text">hyper-parameters</span> of the federation should be changed. Therefore, we select round 50 as the model in the default scenario.</p>
</div>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional details on <span id="A5.1.1" class="ltx_text">MESAS</span>
</h2>

<div id="A5.p1" class="ltx_para">
<p id="A5.p1.1" class="ltx_p">In this section, we provide additional information about <span id="A5.p1.1.1" class="ltx_text">MESAS</span>, that helpful to understand the intuition and facilitates reproducibility of the defense.</p>
</div>
<div id="A5.p2" class="ltx_para">
<p id="A5.p2.3" class="ltx_p"><span id="A5.p2.3.1" class="ltx_text ltx_font_italic">Model Distances.</span> <a href="#S4.F4" title="Figure 4 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a> depicts, how locally trained FL models can vary withing the Euclidean or Cosine distance. We denote the locally trained models as <math id="A5.p2.1.m1.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="A5.p2.1.m1.1a"><msubsup id="A5.p2.1.m1.1.1" xref="A5.p2.1.m1.1.1.cmml"><mi id="A5.p2.1.m1.1.1.2.2" xref="A5.p2.1.m1.1.1.2.2.cmml">L</mi><mi id="A5.p2.1.m1.1.1.3" xref="A5.p2.1.m1.1.1.3.cmml">i</mi><mrow id="A5.p2.1.m1.1.1.2.3" xref="A5.p2.1.m1.1.1.2.3.cmml"><mi id="A5.p2.1.m1.1.1.2.3.2" xref="A5.p2.1.m1.1.1.2.3.2.cmml">r</mi><mo id="A5.p2.1.m1.1.1.2.3.1" xref="A5.p2.1.m1.1.1.2.3.1.cmml">+</mo><mn id="A5.p2.1.m1.1.1.2.3.3" xref="A5.p2.1.m1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="A5.p2.1.m1.1b"><apply id="A5.p2.1.m1.1.1.cmml" xref="A5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A5.p2.1.m1.1.1.1.cmml" xref="A5.p2.1.m1.1.1">subscript</csymbol><apply id="A5.p2.1.m1.1.1.2.cmml" xref="A5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A5.p2.1.m1.1.1.2.1.cmml" xref="A5.p2.1.m1.1.1">superscript</csymbol><ci id="A5.p2.1.m1.1.1.2.2.cmml" xref="A5.p2.1.m1.1.1.2.2">𝐿</ci><apply id="A5.p2.1.m1.1.1.2.3.cmml" xref="A5.p2.1.m1.1.1.2.3"><plus id="A5.p2.1.m1.1.1.2.3.1.cmml" xref="A5.p2.1.m1.1.1.2.3.1"></plus><ci id="A5.p2.1.m1.1.1.2.3.2.cmml" xref="A5.p2.1.m1.1.1.2.3.2">𝑟</ci><cn type="integer" id="A5.p2.1.m1.1.1.2.3.3.cmml" xref="A5.p2.1.m1.1.1.2.3.3">1</cn></apply></apply><ci id="A5.p2.1.m1.1.1.3.cmml" xref="A5.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p2.1.m1.1c">L^{{r+1}}_{i}</annotation></semantics></math> and the original global model, that served as a base for <math id="A5.p2.2.m2.1" class="ltx_Math" alttext="L^{{r+1}}_{i}" display="inline"><semantics id="A5.p2.2.m2.1a"><msubsup id="A5.p2.2.m2.1.1" xref="A5.p2.2.m2.1.1.cmml"><mi id="A5.p2.2.m2.1.1.2.2" xref="A5.p2.2.m2.1.1.2.2.cmml">L</mi><mi id="A5.p2.2.m2.1.1.3" xref="A5.p2.2.m2.1.1.3.cmml">i</mi><mrow id="A5.p2.2.m2.1.1.2.3" xref="A5.p2.2.m2.1.1.2.3.cmml"><mi id="A5.p2.2.m2.1.1.2.3.2" xref="A5.p2.2.m2.1.1.2.3.2.cmml">r</mi><mo id="A5.p2.2.m2.1.1.2.3.1" xref="A5.p2.2.m2.1.1.2.3.1.cmml">+</mo><mn id="A5.p2.2.m2.1.1.2.3.3" xref="A5.p2.2.m2.1.1.2.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="A5.p2.2.m2.1b"><apply id="A5.p2.2.m2.1.1.cmml" xref="A5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A5.p2.2.m2.1.1.1.cmml" xref="A5.p2.2.m2.1.1">subscript</csymbol><apply id="A5.p2.2.m2.1.1.2.cmml" xref="A5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A5.p2.2.m2.1.1.2.1.cmml" xref="A5.p2.2.m2.1.1">superscript</csymbol><ci id="A5.p2.2.m2.1.1.2.2.cmml" xref="A5.p2.2.m2.1.1.2.2">𝐿</ci><apply id="A5.p2.2.m2.1.1.2.3.cmml" xref="A5.p2.2.m2.1.1.2.3"><plus id="A5.p2.2.m2.1.1.2.3.1.cmml" xref="A5.p2.2.m2.1.1.2.3.1"></plus><ci id="A5.p2.2.m2.1.1.2.3.2.cmml" xref="A5.p2.2.m2.1.1.2.3.2">𝑟</ci><cn type="integer" id="A5.p2.2.m2.1.1.2.3.3.cmml" xref="A5.p2.2.m2.1.1.2.3.3">1</cn></apply></apply><ci id="A5.p2.2.m2.1.1.3.cmml" xref="A5.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p2.2.m2.1c">L^{{r+1}}_{i}</annotation></semantics></math> is defined as <math id="A5.p2.3.m3.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A5.p2.3.m3.1a"><msup id="A5.p2.3.m3.1.1" xref="A5.p2.3.m3.1.1.cmml"><mi id="A5.p2.3.m3.1.1.2" xref="A5.p2.3.m3.1.1.2.cmml">G</mi><mi id="A5.p2.3.m3.1.1.3" xref="A5.p2.3.m3.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A5.p2.3.m3.1b"><apply id="A5.p2.3.m3.1.1.cmml" xref="A5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A5.p2.3.m3.1.1.1.cmml" xref="A5.p2.3.m3.1.1">superscript</csymbol><ci id="A5.p2.3.m3.1.1.2.cmml" xref="A5.p2.3.m3.1.1.2">𝐺</ci><ci id="A5.p2.3.m3.1.1.3.cmml" xref="A5.p2.3.m3.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p2.3.m3.1c">G^{r}</annotation></semantics></math>. Further we show that scaling of the model parameters after training effects the COS, thus is not a stealthy model poisoning method for an adversary in FL settings.</p>
</div>
<div id="A5.p3" class="ltx_para">
<p id="A5.p3.3" class="ltx_p"><span id="A5.p3.3.1" class="ltx_text ltx_font_italic">Metric Formulas.</span> We provide the formulas for the metrics of <span id="A5.p3.3.2" class="ltx_text">MESAS</span> in <a href="#A5.E6" title="In Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></span></a> - <a href="#A5.E11" title="In Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Eq. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></span></a>. <math id="A5.p3.1.m1.1" class="ltx_Math" alttext="flatten" display="inline"><semantics id="A5.p3.1.m1.1a"><mrow id="A5.p3.1.m1.1.1" xref="A5.p3.1.m1.1.1.cmml"><mi id="A5.p3.1.m1.1.1.2" xref="A5.p3.1.m1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="A5.p3.1.m1.1.1.1" xref="A5.p3.1.m1.1.1.1.cmml">​</mo><mi id="A5.p3.1.m1.1.1.3" xref="A5.p3.1.m1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.p3.1.m1.1.1.1a" xref="A5.p3.1.m1.1.1.1.cmml">​</mo><mi id="A5.p3.1.m1.1.1.4" xref="A5.p3.1.m1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.p3.1.m1.1.1.1b" xref="A5.p3.1.m1.1.1.1.cmml">​</mo><mi id="A5.p3.1.m1.1.1.5" xref="A5.p3.1.m1.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.p3.1.m1.1.1.1c" xref="A5.p3.1.m1.1.1.1.cmml">​</mo><mi id="A5.p3.1.m1.1.1.6" xref="A5.p3.1.m1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.p3.1.m1.1.1.1d" xref="A5.p3.1.m1.1.1.1.cmml">​</mo><mi id="A5.p3.1.m1.1.1.7" xref="A5.p3.1.m1.1.1.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.p3.1.m1.1.1.1e" xref="A5.p3.1.m1.1.1.1.cmml">​</mo><mi id="A5.p3.1.m1.1.1.8" xref="A5.p3.1.m1.1.1.8.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="A5.p3.1.m1.1b"><apply id="A5.p3.1.m1.1.1.cmml" xref="A5.p3.1.m1.1.1"><times id="A5.p3.1.m1.1.1.1.cmml" xref="A5.p3.1.m1.1.1.1"></times><ci id="A5.p3.1.m1.1.1.2.cmml" xref="A5.p3.1.m1.1.1.2">𝑓</ci><ci id="A5.p3.1.m1.1.1.3.cmml" xref="A5.p3.1.m1.1.1.3">𝑙</ci><ci id="A5.p3.1.m1.1.1.4.cmml" xref="A5.p3.1.m1.1.1.4">𝑎</ci><ci id="A5.p3.1.m1.1.1.5.cmml" xref="A5.p3.1.m1.1.1.5">𝑡</ci><ci id="A5.p3.1.m1.1.1.6.cmml" xref="A5.p3.1.m1.1.1.6">𝑡</ci><ci id="A5.p3.1.m1.1.1.7.cmml" xref="A5.p3.1.m1.1.1.7">𝑒</ci><ci id="A5.p3.1.m1.1.1.8.cmml" xref="A5.p3.1.m1.1.1.8">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p3.1.m1.1c">flatten</annotation></semantics></math> denominates, that all model parameters are arranged in a one dimensional list and <math id="A5.p3.2.m2.1" class="ltx_Math" alttext="nz" display="inline"><semantics id="A5.p3.2.m2.1a"><mrow id="A5.p3.2.m2.1.1" xref="A5.p3.2.m2.1.1.cmml"><mi id="A5.p3.2.m2.1.1.2" xref="A5.p3.2.m2.1.1.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.p3.2.m2.1.1.1" xref="A5.p3.2.m2.1.1.1.cmml">​</mo><mi id="A5.p3.2.m2.1.1.3" xref="A5.p3.2.m2.1.1.3.cmml">z</mi></mrow><annotation-xml encoding="MathML-Content" id="A5.p3.2.m2.1b"><apply id="A5.p3.2.m2.1.1.cmml" xref="A5.p3.2.m2.1.1"><times id="A5.p3.2.m2.1.1.1.cmml" xref="A5.p3.2.m2.1.1.1"></times><ci id="A5.p3.2.m2.1.1.2.cmml" xref="A5.p3.2.m2.1.1.2">𝑛</ci><ci id="A5.p3.2.m2.1.1.3.cmml" xref="A5.p3.2.m2.1.1.3">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p3.2.m2.1c">nz</annotation></semantics></math> is an abbreviation for the nonzero function. Each metric can be computed once per round <math id="A5.p3.3.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="A5.p3.3.m3.1a"><mi id="A5.p3.3.m3.1.1" xref="A5.p3.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A5.p3.3.m3.1b"><ci id="A5.p3.3.m3.1.1.cmml" xref="A5.p3.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.p3.3.m3.1c">r</annotation></semantics></math> for each client i as well as for each layer and the model as a whole.</p>
</div>
<div id="A5.p4" class="ltx_para">
<table id="A5.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.E6.m1.1" class="ltx_Math" alttext="COS_{i}^{r+1}=1-cosine\_similarity(flatten(L^{{r+1}}_{i}-G^{r}))" display="block"><semantics id="A5.E6.m1.1a"><mrow id="A5.E6.m1.1.1" xref="A5.E6.m1.1.1.cmml"><mrow id="A5.E6.m1.1.1.3" xref="A5.E6.m1.1.1.3.cmml"><mi id="A5.E6.m1.1.1.3.2" xref="A5.E6.m1.1.1.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.3.1" xref="A5.E6.m1.1.1.3.1.cmml">​</mo><mi id="A5.E6.m1.1.1.3.3" xref="A5.E6.m1.1.1.3.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.3.1a" xref="A5.E6.m1.1.1.3.1.cmml">​</mo><msubsup id="A5.E6.m1.1.1.3.4" xref="A5.E6.m1.1.1.3.4.cmml"><mi id="A5.E6.m1.1.1.3.4.2.2" xref="A5.E6.m1.1.1.3.4.2.2.cmml">S</mi><mi id="A5.E6.m1.1.1.3.4.2.3" xref="A5.E6.m1.1.1.3.4.2.3.cmml">i</mi><mrow id="A5.E6.m1.1.1.3.4.3" xref="A5.E6.m1.1.1.3.4.3.cmml"><mi id="A5.E6.m1.1.1.3.4.3.2" xref="A5.E6.m1.1.1.3.4.3.2.cmml">r</mi><mo id="A5.E6.m1.1.1.3.4.3.1" xref="A5.E6.m1.1.1.3.4.3.1.cmml">+</mo><mn id="A5.E6.m1.1.1.3.4.3.3" xref="A5.E6.m1.1.1.3.4.3.3.cmml">1</mn></mrow></msubsup></mrow><mo id="A5.E6.m1.1.1.2" xref="A5.E6.m1.1.1.2.cmml">=</mo><mrow id="A5.E6.m1.1.1.1" xref="A5.E6.m1.1.1.1.cmml"><mn id="A5.E6.m1.1.1.1.3" xref="A5.E6.m1.1.1.1.3.cmml">1</mn><mo id="A5.E6.m1.1.1.1.2" xref="A5.E6.m1.1.1.1.2.cmml">−</mo><mrow id="A5.E6.m1.1.1.1.1" xref="A5.E6.m1.1.1.1.1.cmml"><mi id="A5.E6.m1.1.1.1.1.3" xref="A5.E6.m1.1.1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.4" xref="A5.E6.m1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2a" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.5" xref="A5.E6.m1.1.1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2b" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.6" xref="A5.E6.m1.1.1.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2c" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.7" xref="A5.E6.m1.1.1.1.1.7.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2d" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.8" xref="A5.E6.m1.1.1.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2e" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi mathvariant="normal" id="A5.E6.m1.1.1.1.1.9" xref="A5.E6.m1.1.1.1.1.9.cmml">_</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2f" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.10" xref="A5.E6.m1.1.1.1.1.10.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2g" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.11" xref="A5.E6.m1.1.1.1.1.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2h" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.12" xref="A5.E6.m1.1.1.1.1.12.cmml">m</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2i" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.13" xref="A5.E6.m1.1.1.1.1.13.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2j" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.14" xref="A5.E6.m1.1.1.1.1.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2k" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.15" xref="A5.E6.m1.1.1.1.1.15.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2l" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.16" xref="A5.E6.m1.1.1.1.1.16.cmml">r</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2m" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.17" xref="A5.E6.m1.1.1.1.1.17.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2n" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.18" xref="A5.E6.m1.1.1.1.1.18.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2o" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.19" xref="A5.E6.m1.1.1.1.1.19.cmml">y</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.2p" xref="A5.E6.m1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E6.m1.1.1.1.1.1.1" xref="A5.E6.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E6.m1.1.1.1.1.1.1.2" xref="A5.E6.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E6.m1.1.1.1.1.1.1.1" xref="A5.E6.m1.1.1.1.1.1.1.1.cmml"><mi id="A5.E6.m1.1.1.1.1.1.1.1.3" xref="A5.E6.m1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.1.1.1.2" xref="A5.E6.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.1.1.1.4" xref="A5.E6.m1.1.1.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.1.1.1.2a" xref="A5.E6.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.1.1.1.5" xref="A5.E6.m1.1.1.1.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.1.1.1.2b" xref="A5.E6.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.1.1.1.6" xref="A5.E6.m1.1.1.1.1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.1.1.1.2c" xref="A5.E6.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.1.1.1.7" xref="A5.E6.m1.1.1.1.1.1.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.1.1.1.2d" xref="A5.E6.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.1.1.1.8" xref="A5.E6.m1.1.1.1.1.1.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.1.1.1.2e" xref="A5.E6.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E6.m1.1.1.1.1.1.1.1.9" xref="A5.E6.m1.1.1.1.1.1.1.1.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E6.m1.1.1.1.1.1.1.1.2f" xref="A5.E6.m1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E6.m1.1.1.1.1.1.1.1.1.1" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E6.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">L</mi><mi id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mrow id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.2" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">r</mi><mo id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.1" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">+</mo><mn id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.3" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">G</mi><mi id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi></msup></mrow><mo stretchy="false" id="A5.E6.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E6.m1.1.1.1.1.1.1.3" xref="A5.E6.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.E6.m1.1b"><apply id="A5.E6.m1.1.1.cmml" xref="A5.E6.m1.1.1"><eq id="A5.E6.m1.1.1.2.cmml" xref="A5.E6.m1.1.1.2"></eq><apply id="A5.E6.m1.1.1.3.cmml" xref="A5.E6.m1.1.1.3"><times id="A5.E6.m1.1.1.3.1.cmml" xref="A5.E6.m1.1.1.3.1"></times><ci id="A5.E6.m1.1.1.3.2.cmml" xref="A5.E6.m1.1.1.3.2">𝐶</ci><ci id="A5.E6.m1.1.1.3.3.cmml" xref="A5.E6.m1.1.1.3.3">𝑂</ci><apply id="A5.E6.m1.1.1.3.4.cmml" xref="A5.E6.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E6.m1.1.1.3.4.1.cmml" xref="A5.E6.m1.1.1.3.4">superscript</csymbol><apply id="A5.E6.m1.1.1.3.4.2.cmml" xref="A5.E6.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E6.m1.1.1.3.4.2.1.cmml" xref="A5.E6.m1.1.1.3.4">subscript</csymbol><ci id="A5.E6.m1.1.1.3.4.2.2.cmml" xref="A5.E6.m1.1.1.3.4.2.2">𝑆</ci><ci id="A5.E6.m1.1.1.3.4.2.3.cmml" xref="A5.E6.m1.1.1.3.4.2.3">𝑖</ci></apply><apply id="A5.E6.m1.1.1.3.4.3.cmml" xref="A5.E6.m1.1.1.3.4.3"><plus id="A5.E6.m1.1.1.3.4.3.1.cmml" xref="A5.E6.m1.1.1.3.4.3.1"></plus><ci id="A5.E6.m1.1.1.3.4.3.2.cmml" xref="A5.E6.m1.1.1.3.4.3.2">𝑟</ci><cn type="integer" id="A5.E6.m1.1.1.3.4.3.3.cmml" xref="A5.E6.m1.1.1.3.4.3.3">1</cn></apply></apply></apply><apply id="A5.E6.m1.1.1.1.cmml" xref="A5.E6.m1.1.1.1"><minus id="A5.E6.m1.1.1.1.2.cmml" xref="A5.E6.m1.1.1.1.2"></minus><cn type="integer" id="A5.E6.m1.1.1.1.3.cmml" xref="A5.E6.m1.1.1.1.3">1</cn><apply id="A5.E6.m1.1.1.1.1.cmml" xref="A5.E6.m1.1.1.1.1"><times id="A5.E6.m1.1.1.1.1.2.cmml" xref="A5.E6.m1.1.1.1.1.2"></times><ci id="A5.E6.m1.1.1.1.1.3.cmml" xref="A5.E6.m1.1.1.1.1.3">𝑐</ci><ci id="A5.E6.m1.1.1.1.1.4.cmml" xref="A5.E6.m1.1.1.1.1.4">𝑜</ci><ci id="A5.E6.m1.1.1.1.1.5.cmml" xref="A5.E6.m1.1.1.1.1.5">𝑠</ci><ci id="A5.E6.m1.1.1.1.1.6.cmml" xref="A5.E6.m1.1.1.1.1.6">𝑖</ci><ci id="A5.E6.m1.1.1.1.1.7.cmml" xref="A5.E6.m1.1.1.1.1.7">𝑛</ci><ci id="A5.E6.m1.1.1.1.1.8.cmml" xref="A5.E6.m1.1.1.1.1.8">𝑒</ci><ci id="A5.E6.m1.1.1.1.1.9.cmml" xref="A5.E6.m1.1.1.1.1.9">_</ci><ci id="A5.E6.m1.1.1.1.1.10.cmml" xref="A5.E6.m1.1.1.1.1.10">𝑠</ci><ci id="A5.E6.m1.1.1.1.1.11.cmml" xref="A5.E6.m1.1.1.1.1.11">𝑖</ci><ci id="A5.E6.m1.1.1.1.1.12.cmml" xref="A5.E6.m1.1.1.1.1.12">𝑚</ci><ci id="A5.E6.m1.1.1.1.1.13.cmml" xref="A5.E6.m1.1.1.1.1.13">𝑖</ci><ci id="A5.E6.m1.1.1.1.1.14.cmml" xref="A5.E6.m1.1.1.1.1.14">𝑙</ci><ci id="A5.E6.m1.1.1.1.1.15.cmml" xref="A5.E6.m1.1.1.1.1.15">𝑎</ci><ci id="A5.E6.m1.1.1.1.1.16.cmml" xref="A5.E6.m1.1.1.1.1.16">𝑟</ci><ci id="A5.E6.m1.1.1.1.1.17.cmml" xref="A5.E6.m1.1.1.1.1.17">𝑖</ci><ci id="A5.E6.m1.1.1.1.1.18.cmml" xref="A5.E6.m1.1.1.1.1.18">𝑡</ci><ci id="A5.E6.m1.1.1.1.1.19.cmml" xref="A5.E6.m1.1.1.1.1.19">𝑦</ci><apply id="A5.E6.m1.1.1.1.1.1.1.1.cmml" xref="A5.E6.m1.1.1.1.1.1.1"><times id="A5.E6.m1.1.1.1.1.1.1.1.2.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.2"></times><ci id="A5.E6.m1.1.1.1.1.1.1.1.3.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.3">𝑓</ci><ci id="A5.E6.m1.1.1.1.1.1.1.1.4.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.4">𝑙</ci><ci id="A5.E6.m1.1.1.1.1.1.1.1.5.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.5">𝑎</ci><ci id="A5.E6.m1.1.1.1.1.1.1.1.6.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.6">𝑡</ci><ci id="A5.E6.m1.1.1.1.1.1.1.1.7.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.7">𝑡</ci><ci id="A5.E6.m1.1.1.1.1.1.1.1.8.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.8">𝑒</ci><ci id="A5.E6.m1.1.1.1.1.1.1.1.9.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.9">𝑛</ci><apply id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1"><minus id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.2">𝐿</ci><apply id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3"><plus id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.1"></plus><ci id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.2">𝑟</ci><cn type="integer" id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝐺</ci><ci id="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.E6.m1.1.1.1.1.1.1.1.1.1.1.3.3">𝑟</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.E6.m1.1c">COS_{i}^{r+1}=1-cosine\_similarity(flatten(L^{{r+1}}_{i}-G^{r}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="A5.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(7)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.E7.m1.1" class="ltx_Math" alttext="EUCL_{i}^{r+1}=euclidean\_distance(flatten(L^{{r+1}}_{i}-G^{r}))" display="block"><semantics id="A5.E7.m1.1a"><mrow id="A5.E7.m1.1.1" xref="A5.E7.m1.1.1.cmml"><mrow id="A5.E7.m1.1.1.3" xref="A5.E7.m1.1.1.3.cmml"><mi id="A5.E7.m1.1.1.3.2" xref="A5.E7.m1.1.1.3.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.3.1" xref="A5.E7.m1.1.1.3.1.cmml">​</mo><mi id="A5.E7.m1.1.1.3.3" xref="A5.E7.m1.1.1.3.3.cmml">U</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.3.1a" xref="A5.E7.m1.1.1.3.1.cmml">​</mo><mi id="A5.E7.m1.1.1.3.4" xref="A5.E7.m1.1.1.3.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.3.1b" xref="A5.E7.m1.1.1.3.1.cmml">​</mo><msubsup id="A5.E7.m1.1.1.3.5" xref="A5.E7.m1.1.1.3.5.cmml"><mi id="A5.E7.m1.1.1.3.5.2.2" xref="A5.E7.m1.1.1.3.5.2.2.cmml">L</mi><mi id="A5.E7.m1.1.1.3.5.2.3" xref="A5.E7.m1.1.1.3.5.2.3.cmml">i</mi><mrow id="A5.E7.m1.1.1.3.5.3" xref="A5.E7.m1.1.1.3.5.3.cmml"><mi id="A5.E7.m1.1.1.3.5.3.2" xref="A5.E7.m1.1.1.3.5.3.2.cmml">r</mi><mo id="A5.E7.m1.1.1.3.5.3.1" xref="A5.E7.m1.1.1.3.5.3.1.cmml">+</mo><mn id="A5.E7.m1.1.1.3.5.3.3" xref="A5.E7.m1.1.1.3.5.3.3.cmml">1</mn></mrow></msubsup></mrow><mo id="A5.E7.m1.1.1.2" xref="A5.E7.m1.1.1.2.cmml">=</mo><mrow id="A5.E7.m1.1.1.1" xref="A5.E7.m1.1.1.1.cmml"><mi id="A5.E7.m1.1.1.1.3" xref="A5.E7.m1.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.4" xref="A5.E7.m1.1.1.1.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2a" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.5" xref="A5.E7.m1.1.1.1.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2b" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.6" xref="A5.E7.m1.1.1.1.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2c" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.7" xref="A5.E7.m1.1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2d" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.8" xref="A5.E7.m1.1.1.1.8.cmml">d</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2e" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.9" xref="A5.E7.m1.1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2f" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.10" xref="A5.E7.m1.1.1.1.10.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2g" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.11" xref="A5.E7.m1.1.1.1.11.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2h" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi mathvariant="normal" id="A5.E7.m1.1.1.1.12" xref="A5.E7.m1.1.1.1.12.cmml">_</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2i" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.13" xref="A5.E7.m1.1.1.1.13.cmml">d</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2j" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.14" xref="A5.E7.m1.1.1.1.14.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2k" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.15" xref="A5.E7.m1.1.1.1.15.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2l" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.16" xref="A5.E7.m1.1.1.1.16.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2m" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.17" xref="A5.E7.m1.1.1.1.17.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2n" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.18" xref="A5.E7.m1.1.1.1.18.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2o" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.19" xref="A5.E7.m1.1.1.1.19.cmml">c</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2p" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.20" xref="A5.E7.m1.1.1.1.20.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.2q" xref="A5.E7.m1.1.1.1.2.cmml">​</mo><mrow id="A5.E7.m1.1.1.1.1.1" xref="A5.E7.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E7.m1.1.1.1.1.1.2" xref="A5.E7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E7.m1.1.1.1.1.1.1" xref="A5.E7.m1.1.1.1.1.1.1.cmml"><mi id="A5.E7.m1.1.1.1.1.1.1.3" xref="A5.E7.m1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.1.1.1.2" xref="A5.E7.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.1.1.1.4" xref="A5.E7.m1.1.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.1.1.1.2a" xref="A5.E7.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.1.1.1.5" xref="A5.E7.m1.1.1.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.1.1.1.2b" xref="A5.E7.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.1.1.1.6" xref="A5.E7.m1.1.1.1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.1.1.1.2c" xref="A5.E7.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.1.1.1.7" xref="A5.E7.m1.1.1.1.1.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.1.1.1.2d" xref="A5.E7.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.1.1.1.8" xref="A5.E7.m1.1.1.1.1.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.1.1.1.2e" xref="A5.E7.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E7.m1.1.1.1.1.1.1.9" xref="A5.E7.m1.1.1.1.1.1.1.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E7.m1.1.1.1.1.1.1.2f" xref="A5.E7.m1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E7.m1.1.1.1.1.1.1.1.1" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E7.m1.1.1.1.1.1.1.1.1.2" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E7.m1.1.1.1.1.1.1.1.1.1" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">L</mi><mi id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.3" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mrow id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">r</mi><mo id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">+</mo><mn id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="A5.E7.m1.1.1.1.1.1.1.1.1.1.1" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="A5.E7.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">G</mi><mi id="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi></msup></mrow><mo stretchy="false" id="A5.E7.m1.1.1.1.1.1.1.1.1.3" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E7.m1.1.1.1.1.1.3" xref="A5.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.E7.m1.1b"><apply id="A5.E7.m1.1.1.cmml" xref="A5.E7.m1.1.1"><eq id="A5.E7.m1.1.1.2.cmml" xref="A5.E7.m1.1.1.2"></eq><apply id="A5.E7.m1.1.1.3.cmml" xref="A5.E7.m1.1.1.3"><times id="A5.E7.m1.1.1.3.1.cmml" xref="A5.E7.m1.1.1.3.1"></times><ci id="A5.E7.m1.1.1.3.2.cmml" xref="A5.E7.m1.1.1.3.2">𝐸</ci><ci id="A5.E7.m1.1.1.3.3.cmml" xref="A5.E7.m1.1.1.3.3">𝑈</ci><ci id="A5.E7.m1.1.1.3.4.cmml" xref="A5.E7.m1.1.1.3.4">𝐶</ci><apply id="A5.E7.m1.1.1.3.5.cmml" xref="A5.E7.m1.1.1.3.5"><csymbol cd="ambiguous" id="A5.E7.m1.1.1.3.5.1.cmml" xref="A5.E7.m1.1.1.3.5">superscript</csymbol><apply id="A5.E7.m1.1.1.3.5.2.cmml" xref="A5.E7.m1.1.1.3.5"><csymbol cd="ambiguous" id="A5.E7.m1.1.1.3.5.2.1.cmml" xref="A5.E7.m1.1.1.3.5">subscript</csymbol><ci id="A5.E7.m1.1.1.3.5.2.2.cmml" xref="A5.E7.m1.1.1.3.5.2.2">𝐿</ci><ci id="A5.E7.m1.1.1.3.5.2.3.cmml" xref="A5.E7.m1.1.1.3.5.2.3">𝑖</ci></apply><apply id="A5.E7.m1.1.1.3.5.3.cmml" xref="A5.E7.m1.1.1.3.5.3"><plus id="A5.E7.m1.1.1.3.5.3.1.cmml" xref="A5.E7.m1.1.1.3.5.3.1"></plus><ci id="A5.E7.m1.1.1.3.5.3.2.cmml" xref="A5.E7.m1.1.1.3.5.3.2">𝑟</ci><cn type="integer" id="A5.E7.m1.1.1.3.5.3.3.cmml" xref="A5.E7.m1.1.1.3.5.3.3">1</cn></apply></apply></apply><apply id="A5.E7.m1.1.1.1.cmml" xref="A5.E7.m1.1.1.1"><times id="A5.E7.m1.1.1.1.2.cmml" xref="A5.E7.m1.1.1.1.2"></times><ci id="A5.E7.m1.1.1.1.3.cmml" xref="A5.E7.m1.1.1.1.3">𝑒</ci><ci id="A5.E7.m1.1.1.1.4.cmml" xref="A5.E7.m1.1.1.1.4">𝑢</ci><ci id="A5.E7.m1.1.1.1.5.cmml" xref="A5.E7.m1.1.1.1.5">𝑐</ci><ci id="A5.E7.m1.1.1.1.6.cmml" xref="A5.E7.m1.1.1.1.6">𝑙</ci><ci id="A5.E7.m1.1.1.1.7.cmml" xref="A5.E7.m1.1.1.1.7">𝑖</ci><ci id="A5.E7.m1.1.1.1.8.cmml" xref="A5.E7.m1.1.1.1.8">𝑑</ci><ci id="A5.E7.m1.1.1.1.9.cmml" xref="A5.E7.m1.1.1.1.9">𝑒</ci><ci id="A5.E7.m1.1.1.1.10.cmml" xref="A5.E7.m1.1.1.1.10">𝑎</ci><ci id="A5.E7.m1.1.1.1.11.cmml" xref="A5.E7.m1.1.1.1.11">𝑛</ci><ci id="A5.E7.m1.1.1.1.12.cmml" xref="A5.E7.m1.1.1.1.12">_</ci><ci id="A5.E7.m1.1.1.1.13.cmml" xref="A5.E7.m1.1.1.1.13">𝑑</ci><ci id="A5.E7.m1.1.1.1.14.cmml" xref="A5.E7.m1.1.1.1.14">𝑖</ci><ci id="A5.E7.m1.1.1.1.15.cmml" xref="A5.E7.m1.1.1.1.15">𝑠</ci><ci id="A5.E7.m1.1.1.1.16.cmml" xref="A5.E7.m1.1.1.1.16">𝑡</ci><ci id="A5.E7.m1.1.1.1.17.cmml" xref="A5.E7.m1.1.1.1.17">𝑎</ci><ci id="A5.E7.m1.1.1.1.18.cmml" xref="A5.E7.m1.1.1.1.18">𝑛</ci><ci id="A5.E7.m1.1.1.1.19.cmml" xref="A5.E7.m1.1.1.1.19">𝑐</ci><ci id="A5.E7.m1.1.1.1.20.cmml" xref="A5.E7.m1.1.1.1.20">𝑒</ci><apply id="A5.E7.m1.1.1.1.1.1.1.cmml" xref="A5.E7.m1.1.1.1.1.1"><times id="A5.E7.m1.1.1.1.1.1.1.2.cmml" xref="A5.E7.m1.1.1.1.1.1.1.2"></times><ci id="A5.E7.m1.1.1.1.1.1.1.3.cmml" xref="A5.E7.m1.1.1.1.1.1.1.3">𝑓</ci><ci id="A5.E7.m1.1.1.1.1.1.1.4.cmml" xref="A5.E7.m1.1.1.1.1.1.1.4">𝑙</ci><ci id="A5.E7.m1.1.1.1.1.1.1.5.cmml" xref="A5.E7.m1.1.1.1.1.1.1.5">𝑎</ci><ci id="A5.E7.m1.1.1.1.1.1.1.6.cmml" xref="A5.E7.m1.1.1.1.1.1.1.6">𝑡</ci><ci id="A5.E7.m1.1.1.1.1.1.1.7.cmml" xref="A5.E7.m1.1.1.1.1.1.1.7">𝑡</ci><ci id="A5.E7.m1.1.1.1.1.1.1.8.cmml" xref="A5.E7.m1.1.1.1.1.1.1.8">𝑒</ci><ci id="A5.E7.m1.1.1.1.1.1.1.9.cmml" xref="A5.E7.m1.1.1.1.1.1.1.9">𝑛</ci><apply id="A5.E7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1"><minus id="A5.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2">𝐿</ci><apply id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3"><plus id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1"></plus><ci id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2">𝑟</ci><cn type="integer" id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.2">𝐺</ci><ci id="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.E7.m1.1.1.1.1.1.1.1.1.1.3.3">𝑟</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.E7.m1.1c">EUCL_{i}^{r+1}=euclidean\_distance(flatten(L^{{r+1}}_{i}-G^{r}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="A5.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(8)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.E8.m1.1" class="ltx_Math" alttext="COUNT_{i}^{r+1}=sum(relu(sign(flatten(L^{{r+1}}_{i}-G^{r}))))" display="block"><semantics id="A5.E8.m1.1a"><mrow id="A5.E8.m1.1.1" xref="A5.E8.m1.1.1.cmml"><mrow id="A5.E8.m1.1.1.3" xref="A5.E8.m1.1.1.3.cmml"><mi id="A5.E8.m1.1.1.3.2" xref="A5.E8.m1.1.1.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.3.1" xref="A5.E8.m1.1.1.3.1.cmml">​</mo><mi id="A5.E8.m1.1.1.3.3" xref="A5.E8.m1.1.1.3.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.3.1a" xref="A5.E8.m1.1.1.3.1.cmml">​</mo><mi id="A5.E8.m1.1.1.3.4" xref="A5.E8.m1.1.1.3.4.cmml">U</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.3.1b" xref="A5.E8.m1.1.1.3.1.cmml">​</mo><mi id="A5.E8.m1.1.1.3.5" xref="A5.E8.m1.1.1.3.5.cmml">N</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.3.1c" xref="A5.E8.m1.1.1.3.1.cmml">​</mo><msubsup id="A5.E8.m1.1.1.3.6" xref="A5.E8.m1.1.1.3.6.cmml"><mi id="A5.E8.m1.1.1.3.6.2.2" xref="A5.E8.m1.1.1.3.6.2.2.cmml">T</mi><mi id="A5.E8.m1.1.1.3.6.2.3" xref="A5.E8.m1.1.1.3.6.2.3.cmml">i</mi><mrow id="A5.E8.m1.1.1.3.6.3" xref="A5.E8.m1.1.1.3.6.3.cmml"><mi id="A5.E8.m1.1.1.3.6.3.2" xref="A5.E8.m1.1.1.3.6.3.2.cmml">r</mi><mo id="A5.E8.m1.1.1.3.6.3.1" xref="A5.E8.m1.1.1.3.6.3.1.cmml">+</mo><mn id="A5.E8.m1.1.1.3.6.3.3" xref="A5.E8.m1.1.1.3.6.3.3.cmml">1</mn></mrow></msubsup></mrow><mo id="A5.E8.m1.1.1.2" xref="A5.E8.m1.1.1.2.cmml">=</mo><mrow id="A5.E8.m1.1.1.1" xref="A5.E8.m1.1.1.1.cmml"><mi id="A5.E8.m1.1.1.1.3" xref="A5.E8.m1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.2" xref="A5.E8.m1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.4" xref="A5.E8.m1.1.1.1.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.2a" xref="A5.E8.m1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.5" xref="A5.E8.m1.1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.2b" xref="A5.E8.m1.1.1.1.2.cmml">​</mo><mrow id="A5.E8.m1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E8.m1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.cmml"><mi id="A5.E8.m1.1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.4" xref="A5.E8.m1.1.1.1.1.1.1.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.2a" xref="A5.E8.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.5" xref="A5.E8.m1.1.1.1.1.1.1.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.2b" xref="A5.E8.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.6" xref="A5.E8.m1.1.1.1.1.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.2c" xref="A5.E8.m1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E8.m1.1.1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E8.m1.1.1.1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.4" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.2a" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.5" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.2b" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.6" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.2c" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.4" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2a" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.5" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2b" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.6" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2c" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.7" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2d" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.8" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2e" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.9" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2f" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">L</mi><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mrow id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">r</mi><mo id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">+</mo><mn id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">G</mi><mi id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi></msup></mrow><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E8.m1.1.1.1.1.1.3" xref="A5.E8.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.E8.m1.1b"><apply id="A5.E8.m1.1.1.cmml" xref="A5.E8.m1.1.1"><eq id="A5.E8.m1.1.1.2.cmml" xref="A5.E8.m1.1.1.2"></eq><apply id="A5.E8.m1.1.1.3.cmml" xref="A5.E8.m1.1.1.3"><times id="A5.E8.m1.1.1.3.1.cmml" xref="A5.E8.m1.1.1.3.1"></times><ci id="A5.E8.m1.1.1.3.2.cmml" xref="A5.E8.m1.1.1.3.2">𝐶</ci><ci id="A5.E8.m1.1.1.3.3.cmml" xref="A5.E8.m1.1.1.3.3">𝑂</ci><ci id="A5.E8.m1.1.1.3.4.cmml" xref="A5.E8.m1.1.1.3.4">𝑈</ci><ci id="A5.E8.m1.1.1.3.5.cmml" xref="A5.E8.m1.1.1.3.5">𝑁</ci><apply id="A5.E8.m1.1.1.3.6.cmml" xref="A5.E8.m1.1.1.3.6"><csymbol cd="ambiguous" id="A5.E8.m1.1.1.3.6.1.cmml" xref="A5.E8.m1.1.1.3.6">superscript</csymbol><apply id="A5.E8.m1.1.1.3.6.2.cmml" xref="A5.E8.m1.1.1.3.6"><csymbol cd="ambiguous" id="A5.E8.m1.1.1.3.6.2.1.cmml" xref="A5.E8.m1.1.1.3.6">subscript</csymbol><ci id="A5.E8.m1.1.1.3.6.2.2.cmml" xref="A5.E8.m1.1.1.3.6.2.2">𝑇</ci><ci id="A5.E8.m1.1.1.3.6.2.3.cmml" xref="A5.E8.m1.1.1.3.6.2.3">𝑖</ci></apply><apply id="A5.E8.m1.1.1.3.6.3.cmml" xref="A5.E8.m1.1.1.3.6.3"><plus id="A5.E8.m1.1.1.3.6.3.1.cmml" xref="A5.E8.m1.1.1.3.6.3.1"></plus><ci id="A5.E8.m1.1.1.3.6.3.2.cmml" xref="A5.E8.m1.1.1.3.6.3.2">𝑟</ci><cn type="integer" id="A5.E8.m1.1.1.3.6.3.3.cmml" xref="A5.E8.m1.1.1.3.6.3.3">1</cn></apply></apply></apply><apply id="A5.E8.m1.1.1.1.cmml" xref="A5.E8.m1.1.1.1"><times id="A5.E8.m1.1.1.1.2.cmml" xref="A5.E8.m1.1.1.1.2"></times><ci id="A5.E8.m1.1.1.1.3.cmml" xref="A5.E8.m1.1.1.1.3">𝑠</ci><ci id="A5.E8.m1.1.1.1.4.cmml" xref="A5.E8.m1.1.1.1.4">𝑢</ci><ci id="A5.E8.m1.1.1.1.5.cmml" xref="A5.E8.m1.1.1.1.5">𝑚</ci><apply id="A5.E8.m1.1.1.1.1.1.1.cmml" xref="A5.E8.m1.1.1.1.1.1"><times id="A5.E8.m1.1.1.1.1.1.1.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.2"></times><ci id="A5.E8.m1.1.1.1.1.1.1.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.3">𝑟</ci><ci id="A5.E8.m1.1.1.1.1.1.1.4.cmml" xref="A5.E8.m1.1.1.1.1.1.1.4">𝑒</ci><ci id="A5.E8.m1.1.1.1.1.1.1.5.cmml" xref="A5.E8.m1.1.1.1.1.1.1.5">𝑙</ci><ci id="A5.E8.m1.1.1.1.1.1.1.6.cmml" xref="A5.E8.m1.1.1.1.1.1.1.6">𝑢</ci><apply id="A5.E8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1"><times id="A5.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.2"></times><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.3">𝑠</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.4.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.4">𝑖</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.5.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.5">𝑔</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.6.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.6">𝑛</ci><apply id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1"><times id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑓</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.4">𝑙</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.5">𝑎</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.6.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.6">𝑡</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.7.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.7">𝑡</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.8.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.8">𝑒</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.9.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.9">𝑛</ci><apply id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><minus id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">𝐿</ci><apply id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3"><plus id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1"></plus><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2">𝑟</ci><cn type="integer" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">𝐺</ci><ci id="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.E8.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑟</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.E8.m1.1c">COUNT_{i}^{r+1}=sum(relu(sign(flatten(L^{{r+1}}_{i}-G^{r}))))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="A5.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(9)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.E9.m1.1" class="ltx_Math" alttext="VAR_{i}^{r+1}=var(flatten(L^{{r+1}}_{i}))" display="block"><semantics id="A5.E9.m1.1a"><mrow id="A5.E9.m1.1.1" xref="A5.E9.m1.1.1.cmml"><mrow id="A5.E9.m1.1.1.3" xref="A5.E9.m1.1.1.3.cmml"><mi id="A5.E9.m1.1.1.3.2" xref="A5.E9.m1.1.1.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.3.1" xref="A5.E9.m1.1.1.3.1.cmml">​</mo><mi id="A5.E9.m1.1.1.3.3" xref="A5.E9.m1.1.1.3.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.3.1a" xref="A5.E9.m1.1.1.3.1.cmml">​</mo><msubsup id="A5.E9.m1.1.1.3.4" xref="A5.E9.m1.1.1.3.4.cmml"><mi id="A5.E9.m1.1.1.3.4.2.2" xref="A5.E9.m1.1.1.3.4.2.2.cmml">R</mi><mi id="A5.E9.m1.1.1.3.4.2.3" xref="A5.E9.m1.1.1.3.4.2.3.cmml">i</mi><mrow id="A5.E9.m1.1.1.3.4.3" xref="A5.E9.m1.1.1.3.4.3.cmml"><mi id="A5.E9.m1.1.1.3.4.3.2" xref="A5.E9.m1.1.1.3.4.3.2.cmml">r</mi><mo id="A5.E9.m1.1.1.3.4.3.1" xref="A5.E9.m1.1.1.3.4.3.1.cmml">+</mo><mn id="A5.E9.m1.1.1.3.4.3.3" xref="A5.E9.m1.1.1.3.4.3.3.cmml">1</mn></mrow></msubsup></mrow><mo id="A5.E9.m1.1.1.2" xref="A5.E9.m1.1.1.2.cmml">=</mo><mrow id="A5.E9.m1.1.1.1" xref="A5.E9.m1.1.1.1.cmml"><mi id="A5.E9.m1.1.1.1.3" xref="A5.E9.m1.1.1.1.3.cmml">v</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.2" xref="A5.E9.m1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.4" xref="A5.E9.m1.1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.2a" xref="A5.E9.m1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.5" xref="A5.E9.m1.1.1.1.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.2b" xref="A5.E9.m1.1.1.1.2.cmml">​</mo><mrow id="A5.E9.m1.1.1.1.1.1" xref="A5.E9.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E9.m1.1.1.1.1.1.2" xref="A5.E9.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E9.m1.1.1.1.1.1.1" xref="A5.E9.m1.1.1.1.1.1.1.cmml"><mi id="A5.E9.m1.1.1.1.1.1.1.3" xref="A5.E9.m1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.1.1.1.2" xref="A5.E9.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.1.1.1.4" xref="A5.E9.m1.1.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.1.1.1.2a" xref="A5.E9.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.1.1.1.5" xref="A5.E9.m1.1.1.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.1.1.1.2b" xref="A5.E9.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.1.1.1.6" xref="A5.E9.m1.1.1.1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.1.1.1.2c" xref="A5.E9.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.1.1.1.7" xref="A5.E9.m1.1.1.1.1.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.1.1.1.2d" xref="A5.E9.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.1.1.1.8" xref="A5.E9.m1.1.1.1.1.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.1.1.1.2e" xref="A5.E9.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E9.m1.1.1.1.1.1.1.9" xref="A5.E9.m1.1.1.1.1.1.1.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E9.m1.1.1.1.1.1.1.2f" xref="A5.E9.m1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E9.m1.1.1.1.1.1.1.1.1" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E9.m1.1.1.1.1.1.1.1.1.2" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="A5.E9.m1.1.1.1.1.1.1.1.1.1" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.2" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">L</mi><mi id="A5.E9.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi><mrow id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">r</mi><mo id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.1" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">+</mo><mn id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="A5.E9.m1.1.1.1.1.1.1.1.1.3" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E9.m1.1.1.1.1.1.3" xref="A5.E9.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.E9.m1.1b"><apply id="A5.E9.m1.1.1.cmml" xref="A5.E9.m1.1.1"><eq id="A5.E9.m1.1.1.2.cmml" xref="A5.E9.m1.1.1.2"></eq><apply id="A5.E9.m1.1.1.3.cmml" xref="A5.E9.m1.1.1.3"><times id="A5.E9.m1.1.1.3.1.cmml" xref="A5.E9.m1.1.1.3.1"></times><ci id="A5.E9.m1.1.1.3.2.cmml" xref="A5.E9.m1.1.1.3.2">𝑉</ci><ci id="A5.E9.m1.1.1.3.3.cmml" xref="A5.E9.m1.1.1.3.3">𝐴</ci><apply id="A5.E9.m1.1.1.3.4.cmml" xref="A5.E9.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E9.m1.1.1.3.4.1.cmml" xref="A5.E9.m1.1.1.3.4">superscript</csymbol><apply id="A5.E9.m1.1.1.3.4.2.cmml" xref="A5.E9.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E9.m1.1.1.3.4.2.1.cmml" xref="A5.E9.m1.1.1.3.4">subscript</csymbol><ci id="A5.E9.m1.1.1.3.4.2.2.cmml" xref="A5.E9.m1.1.1.3.4.2.2">𝑅</ci><ci id="A5.E9.m1.1.1.3.4.2.3.cmml" xref="A5.E9.m1.1.1.3.4.2.3">𝑖</ci></apply><apply id="A5.E9.m1.1.1.3.4.3.cmml" xref="A5.E9.m1.1.1.3.4.3"><plus id="A5.E9.m1.1.1.3.4.3.1.cmml" xref="A5.E9.m1.1.1.3.4.3.1"></plus><ci id="A5.E9.m1.1.1.3.4.3.2.cmml" xref="A5.E9.m1.1.1.3.4.3.2">𝑟</ci><cn type="integer" id="A5.E9.m1.1.1.3.4.3.3.cmml" xref="A5.E9.m1.1.1.3.4.3.3">1</cn></apply></apply></apply><apply id="A5.E9.m1.1.1.1.cmml" xref="A5.E9.m1.1.1.1"><times id="A5.E9.m1.1.1.1.2.cmml" xref="A5.E9.m1.1.1.1.2"></times><ci id="A5.E9.m1.1.1.1.3.cmml" xref="A5.E9.m1.1.1.1.3">𝑣</ci><ci id="A5.E9.m1.1.1.1.4.cmml" xref="A5.E9.m1.1.1.1.4">𝑎</ci><ci id="A5.E9.m1.1.1.1.5.cmml" xref="A5.E9.m1.1.1.1.5">𝑟</ci><apply id="A5.E9.m1.1.1.1.1.1.1.cmml" xref="A5.E9.m1.1.1.1.1.1"><times id="A5.E9.m1.1.1.1.1.1.1.2.cmml" xref="A5.E9.m1.1.1.1.1.1.1.2"></times><ci id="A5.E9.m1.1.1.1.1.1.1.3.cmml" xref="A5.E9.m1.1.1.1.1.1.1.3">𝑓</ci><ci id="A5.E9.m1.1.1.1.1.1.1.4.cmml" xref="A5.E9.m1.1.1.1.1.1.1.4">𝑙</ci><ci id="A5.E9.m1.1.1.1.1.1.1.5.cmml" xref="A5.E9.m1.1.1.1.1.1.1.5">𝑎</ci><ci id="A5.E9.m1.1.1.1.1.1.1.6.cmml" xref="A5.E9.m1.1.1.1.1.1.1.6">𝑡</ci><ci id="A5.E9.m1.1.1.1.1.1.1.7.cmml" xref="A5.E9.m1.1.1.1.1.1.1.7">𝑡</ci><ci id="A5.E9.m1.1.1.1.1.1.1.8.cmml" xref="A5.E9.m1.1.1.1.1.1.1.8">𝑒</ci><ci id="A5.E9.m1.1.1.1.1.1.1.9.cmml" xref="A5.E9.m1.1.1.1.1.1.1.9">𝑛</ci><apply id="A5.E9.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.E9.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.2">𝐿</ci><apply id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3"><plus id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.1"></plus><ci id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2">𝑟</ci><cn type="integer" id="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="A5.E9.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E9.m1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.E9.m1.1c">VAR_{i}^{r+1}=var(flatten(L^{{r+1}}_{i}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="A5.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(10)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.E10.m1.1" class="ltx_Math" alttext="MIN_{i}^{r+1}=min(nz(abs(L^{{r+1}}_{i}-G^{r})))" display="block"><semantics id="A5.E10.m1.1a"><mrow id="A5.E10.m1.1.1" xref="A5.E10.m1.1.1.cmml"><mrow id="A5.E10.m1.1.1.3" xref="A5.E10.m1.1.1.3.cmml"><mi id="A5.E10.m1.1.1.3.2" xref="A5.E10.m1.1.1.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.3.1" xref="A5.E10.m1.1.1.3.1.cmml">​</mo><mi id="A5.E10.m1.1.1.3.3" xref="A5.E10.m1.1.1.3.3.cmml">I</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.3.1a" xref="A5.E10.m1.1.1.3.1.cmml">​</mo><msubsup id="A5.E10.m1.1.1.3.4" xref="A5.E10.m1.1.1.3.4.cmml"><mi id="A5.E10.m1.1.1.3.4.2.2" xref="A5.E10.m1.1.1.3.4.2.2.cmml">N</mi><mi id="A5.E10.m1.1.1.3.4.2.3" xref="A5.E10.m1.1.1.3.4.2.3.cmml">i</mi><mrow id="A5.E10.m1.1.1.3.4.3" xref="A5.E10.m1.1.1.3.4.3.cmml"><mi id="A5.E10.m1.1.1.3.4.3.2" xref="A5.E10.m1.1.1.3.4.3.2.cmml">r</mi><mo id="A5.E10.m1.1.1.3.4.3.1" xref="A5.E10.m1.1.1.3.4.3.1.cmml">+</mo><mn id="A5.E10.m1.1.1.3.4.3.3" xref="A5.E10.m1.1.1.3.4.3.3.cmml">1</mn></mrow></msubsup></mrow><mo id="A5.E10.m1.1.1.2" xref="A5.E10.m1.1.1.2.cmml">=</mo><mrow id="A5.E10.m1.1.1.1" xref="A5.E10.m1.1.1.1.cmml"><mi id="A5.E10.m1.1.1.1.3" xref="A5.E10.m1.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.2" xref="A5.E10.m1.1.1.1.2.cmml">​</mo><mi id="A5.E10.m1.1.1.1.4" xref="A5.E10.m1.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.2a" xref="A5.E10.m1.1.1.1.2.cmml">​</mo><mi id="A5.E10.m1.1.1.1.5" xref="A5.E10.m1.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.2b" xref="A5.E10.m1.1.1.1.2.cmml">​</mo><mrow id="A5.E10.m1.1.1.1.1.1" xref="A5.E10.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E10.m1.1.1.1.1.1.2" xref="A5.E10.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E10.m1.1.1.1.1.1.1" xref="A5.E10.m1.1.1.1.1.1.1.cmml"><mi id="A5.E10.m1.1.1.1.1.1.1.3" xref="A5.E10.m1.1.1.1.1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.1.1.1.2" xref="A5.E10.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E10.m1.1.1.1.1.1.1.4" xref="A5.E10.m1.1.1.1.1.1.1.4.cmml">z</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.1.1.1.2a" xref="A5.E10.m1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E10.m1.1.1.1.1.1.1.1.1" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E10.m1.1.1.1.1.1.1.1.1.2" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E10.m1.1.1.1.1.1.1.1.1.1" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.4" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.4.cmml">b</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.2a" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.5" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.2b" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">L</mi><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mrow id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">r</mi><mo id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">+</mo><mn id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">G</mi><mi id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi></msup></mrow><mo stretchy="false" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E10.m1.1.1.1.1.1.1.1.1.3" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E10.m1.1.1.1.1.1.3" xref="A5.E10.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.E10.m1.1b"><apply id="A5.E10.m1.1.1.cmml" xref="A5.E10.m1.1.1"><eq id="A5.E10.m1.1.1.2.cmml" xref="A5.E10.m1.1.1.2"></eq><apply id="A5.E10.m1.1.1.3.cmml" xref="A5.E10.m1.1.1.3"><times id="A5.E10.m1.1.1.3.1.cmml" xref="A5.E10.m1.1.1.3.1"></times><ci id="A5.E10.m1.1.1.3.2.cmml" xref="A5.E10.m1.1.1.3.2">𝑀</ci><ci id="A5.E10.m1.1.1.3.3.cmml" xref="A5.E10.m1.1.1.3.3">𝐼</ci><apply id="A5.E10.m1.1.1.3.4.cmml" xref="A5.E10.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E10.m1.1.1.3.4.1.cmml" xref="A5.E10.m1.1.1.3.4">superscript</csymbol><apply id="A5.E10.m1.1.1.3.4.2.cmml" xref="A5.E10.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E10.m1.1.1.3.4.2.1.cmml" xref="A5.E10.m1.1.1.3.4">subscript</csymbol><ci id="A5.E10.m1.1.1.3.4.2.2.cmml" xref="A5.E10.m1.1.1.3.4.2.2">𝑁</ci><ci id="A5.E10.m1.1.1.3.4.2.3.cmml" xref="A5.E10.m1.1.1.3.4.2.3">𝑖</ci></apply><apply id="A5.E10.m1.1.1.3.4.3.cmml" xref="A5.E10.m1.1.1.3.4.3"><plus id="A5.E10.m1.1.1.3.4.3.1.cmml" xref="A5.E10.m1.1.1.3.4.3.1"></plus><ci id="A5.E10.m1.1.1.3.4.3.2.cmml" xref="A5.E10.m1.1.1.3.4.3.2">𝑟</ci><cn type="integer" id="A5.E10.m1.1.1.3.4.3.3.cmml" xref="A5.E10.m1.1.1.3.4.3.3">1</cn></apply></apply></apply><apply id="A5.E10.m1.1.1.1.cmml" xref="A5.E10.m1.1.1.1"><times id="A5.E10.m1.1.1.1.2.cmml" xref="A5.E10.m1.1.1.1.2"></times><ci id="A5.E10.m1.1.1.1.3.cmml" xref="A5.E10.m1.1.1.1.3">𝑚</ci><ci id="A5.E10.m1.1.1.1.4.cmml" xref="A5.E10.m1.1.1.1.4">𝑖</ci><ci id="A5.E10.m1.1.1.1.5.cmml" xref="A5.E10.m1.1.1.1.5">𝑛</ci><apply id="A5.E10.m1.1.1.1.1.1.1.cmml" xref="A5.E10.m1.1.1.1.1.1"><times id="A5.E10.m1.1.1.1.1.1.1.2.cmml" xref="A5.E10.m1.1.1.1.1.1.1.2"></times><ci id="A5.E10.m1.1.1.1.1.1.1.3.cmml" xref="A5.E10.m1.1.1.1.1.1.1.3">𝑛</ci><ci id="A5.E10.m1.1.1.1.1.1.1.4.cmml" xref="A5.E10.m1.1.1.1.1.1.1.4">𝑧</ci><apply id="A5.E10.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1"><times id="A5.E10.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.2"></times><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.3">𝑎</ci><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.4.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.4">𝑏</ci><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.5.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.5">𝑠</ci><apply id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1"><minus id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">𝐿</ci><apply id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3"><plus id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.1"></plus><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.2">𝑟</ci><cn type="integer" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">𝐺</ci><ci id="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.E10.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑟</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.E10.m1.1c">MIN_{i}^{r+1}=min(nz(abs(L^{{r+1}}_{i}-G^{r})))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="A5.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(11)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A5.E11.m1.1" class="ltx_Math" alttext="MAX_{i}^{r+1}=max(abs(L^{{r+1}}_{i}-G^{r}))" display="block"><semantics id="A5.E11.m1.1a"><mrow id="A5.E11.m1.1.1" xref="A5.E11.m1.1.1.cmml"><mrow id="A5.E11.m1.1.1.3" xref="A5.E11.m1.1.1.3.cmml"><mi id="A5.E11.m1.1.1.3.2" xref="A5.E11.m1.1.1.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.3.1" xref="A5.E11.m1.1.1.3.1.cmml">​</mo><mi id="A5.E11.m1.1.1.3.3" xref="A5.E11.m1.1.1.3.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.3.1a" xref="A5.E11.m1.1.1.3.1.cmml">​</mo><msubsup id="A5.E11.m1.1.1.3.4" xref="A5.E11.m1.1.1.3.4.cmml"><mi id="A5.E11.m1.1.1.3.4.2.2" xref="A5.E11.m1.1.1.3.4.2.2.cmml">X</mi><mi id="A5.E11.m1.1.1.3.4.2.3" xref="A5.E11.m1.1.1.3.4.2.3.cmml">i</mi><mrow id="A5.E11.m1.1.1.3.4.3" xref="A5.E11.m1.1.1.3.4.3.cmml"><mi id="A5.E11.m1.1.1.3.4.3.2" xref="A5.E11.m1.1.1.3.4.3.2.cmml">r</mi><mo id="A5.E11.m1.1.1.3.4.3.1" xref="A5.E11.m1.1.1.3.4.3.1.cmml">+</mo><mn id="A5.E11.m1.1.1.3.4.3.3" xref="A5.E11.m1.1.1.3.4.3.3.cmml">1</mn></mrow></msubsup></mrow><mo id="A5.E11.m1.1.1.2" xref="A5.E11.m1.1.1.2.cmml">=</mo><mrow id="A5.E11.m1.1.1.1" xref="A5.E11.m1.1.1.1.cmml"><mi id="A5.E11.m1.1.1.1.3" xref="A5.E11.m1.1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.1.2" xref="A5.E11.m1.1.1.1.2.cmml">​</mo><mi id="A5.E11.m1.1.1.1.4" xref="A5.E11.m1.1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.1.2a" xref="A5.E11.m1.1.1.1.2.cmml">​</mo><mi id="A5.E11.m1.1.1.1.5" xref="A5.E11.m1.1.1.1.5.cmml">x</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.1.2b" xref="A5.E11.m1.1.1.1.2.cmml">​</mo><mrow id="A5.E11.m1.1.1.1.1.1" xref="A5.E11.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E11.m1.1.1.1.1.1.2" xref="A5.E11.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E11.m1.1.1.1.1.1.1" xref="A5.E11.m1.1.1.1.1.1.1.cmml"><mi id="A5.E11.m1.1.1.1.1.1.1.3" xref="A5.E11.m1.1.1.1.1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.1.1.1.1.2" xref="A5.E11.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E11.m1.1.1.1.1.1.1.4" xref="A5.E11.m1.1.1.1.1.1.1.4.cmml">b</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.1.1.1.1.2a" xref="A5.E11.m1.1.1.1.1.1.1.2.cmml">​</mo><mi id="A5.E11.m1.1.1.1.1.1.1.5" xref="A5.E11.m1.1.1.1.1.1.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="A5.E11.m1.1.1.1.1.1.1.2b" xref="A5.E11.m1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="A5.E11.m1.1.1.1.1.1.1.1.1" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A5.E11.m1.1.1.1.1.1.1.1.1.2" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.E11.m1.1.1.1.1.1.1.1.1.1" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">L</mi><mi id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.3" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mrow id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.2" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">r</mi><mo id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.1" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">+</mo><mn id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.3" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="A5.E11.m1.1.1.1.1.1.1.1.1.1.1" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="A5.E11.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">G</mi><mi id="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi></msup></mrow><mo stretchy="false" id="A5.E11.m1.1.1.1.1.1.1.1.1.3" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A5.E11.m1.1.1.1.1.1.3" xref="A5.E11.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.E11.m1.1b"><apply id="A5.E11.m1.1.1.cmml" xref="A5.E11.m1.1.1"><eq id="A5.E11.m1.1.1.2.cmml" xref="A5.E11.m1.1.1.2"></eq><apply id="A5.E11.m1.1.1.3.cmml" xref="A5.E11.m1.1.1.3"><times id="A5.E11.m1.1.1.3.1.cmml" xref="A5.E11.m1.1.1.3.1"></times><ci id="A5.E11.m1.1.1.3.2.cmml" xref="A5.E11.m1.1.1.3.2">𝑀</ci><ci id="A5.E11.m1.1.1.3.3.cmml" xref="A5.E11.m1.1.1.3.3">𝐴</ci><apply id="A5.E11.m1.1.1.3.4.cmml" xref="A5.E11.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E11.m1.1.1.3.4.1.cmml" xref="A5.E11.m1.1.1.3.4">superscript</csymbol><apply id="A5.E11.m1.1.1.3.4.2.cmml" xref="A5.E11.m1.1.1.3.4"><csymbol cd="ambiguous" id="A5.E11.m1.1.1.3.4.2.1.cmml" xref="A5.E11.m1.1.1.3.4">subscript</csymbol><ci id="A5.E11.m1.1.1.3.4.2.2.cmml" xref="A5.E11.m1.1.1.3.4.2.2">𝑋</ci><ci id="A5.E11.m1.1.1.3.4.2.3.cmml" xref="A5.E11.m1.1.1.3.4.2.3">𝑖</ci></apply><apply id="A5.E11.m1.1.1.3.4.3.cmml" xref="A5.E11.m1.1.1.3.4.3"><plus id="A5.E11.m1.1.1.3.4.3.1.cmml" xref="A5.E11.m1.1.1.3.4.3.1"></plus><ci id="A5.E11.m1.1.1.3.4.3.2.cmml" xref="A5.E11.m1.1.1.3.4.3.2">𝑟</ci><cn type="integer" id="A5.E11.m1.1.1.3.4.3.3.cmml" xref="A5.E11.m1.1.1.3.4.3.3">1</cn></apply></apply></apply><apply id="A5.E11.m1.1.1.1.cmml" xref="A5.E11.m1.1.1.1"><times id="A5.E11.m1.1.1.1.2.cmml" xref="A5.E11.m1.1.1.1.2"></times><ci id="A5.E11.m1.1.1.1.3.cmml" xref="A5.E11.m1.1.1.1.3">𝑚</ci><ci id="A5.E11.m1.1.1.1.4.cmml" xref="A5.E11.m1.1.1.1.4">𝑎</ci><ci id="A5.E11.m1.1.1.1.5.cmml" xref="A5.E11.m1.1.1.1.5">𝑥</ci><apply id="A5.E11.m1.1.1.1.1.1.1.cmml" xref="A5.E11.m1.1.1.1.1.1"><times id="A5.E11.m1.1.1.1.1.1.1.2.cmml" xref="A5.E11.m1.1.1.1.1.1.1.2"></times><ci id="A5.E11.m1.1.1.1.1.1.1.3.cmml" xref="A5.E11.m1.1.1.1.1.1.1.3">𝑎</ci><ci id="A5.E11.m1.1.1.1.1.1.1.4.cmml" xref="A5.E11.m1.1.1.1.1.1.1.4">𝑏</ci><ci id="A5.E11.m1.1.1.1.1.1.1.5.cmml" xref="A5.E11.m1.1.1.1.1.1.1.5">𝑠</ci><apply id="A5.E11.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1"><minus id="A5.E11.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.2">𝐿</ci><apply id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3"><plus id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.1"></plus><ci id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.2">𝑟</ci><cn type="integer" id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.2">𝐺</ci><ci id="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.E11.m1.1.1.1.1.1.1.1.1.1.3.3">𝑟</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.E11.m1.1c">MAX_{i}^{r+1}=max(abs(L^{{r+1}}_{i}-G^{r}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="A5.p5" class="ltx_para">
<p id="A5.p5.1" class="ltx_p"><span id="A5.p5.1.1" class="ltx_text ltx_font_italic">Parameters.</span> The significance level for <span id="A5.p5.1.2" class="ltx_text">MESAS</span> is set to 0.0001 for IID, to 0.001 for <span id="A5.p5.1.3" class="ltx_text">intra-client</span> <span id="A5.p5.1.4" class="ltx_text">non-IID</span>, and to 0.03 for <span id="A5.p5.1.5" class="ltx_text">inter-client</span> <span id="A5.p5.1.6" class="ltx_text">non-IID</span> scenarios.</p>
</div>
<figure id="A5.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A5.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>. </span><span id="A5.T4.4.2" class="ltx_text" style="font-size:90%;">MA for different poisoning methods without adaptive adversary in percent.</span></figcaption>
<table id="A5.T4.1" class="ltx_tabular ltx_align_middle">
<tr id="A5.T4.1.2" class="ltx_tr">
<td id="A5.T4.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" rowspan="3"><span id="A5.T4.1.2.1.1" class="ltx_text">Aggregation / Defenses</span></td>
<td id="A5.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="9">MA</td>
</tr>
<tr id="A5.T4.1.3" class="ltx_tr">
<td id="A5.T4.1.3.1" class="ltx_td ltx_align_center ltx_border_r">Pixel Trigger</td>
<td id="A5.T4.1.3.2" class="ltx_td ltx_align_center ltx_border_r">Clean-Label</td>
<td id="A5.T4.1.3.3" class="ltx_td ltx_align_center ltx_border_r">Semantic</td>
<td id="A5.T4.1.3.4" class="ltx_td ltx_align_center ltx_border_r">Edge Case</td>
<td id="A5.T4.1.3.5" class="ltx_td ltx_align_center ltx_border_r">Label Flip</td>
<td id="A5.T4.1.3.6" class="ltx_td ltx_align_center ltx_border_r">Pervasive</td>
<td id="A5.T4.1.3.7" class="ltx_td ltx_align_center ltx_border_r">Random Flip</td>
<td id="A5.T4.1.3.8" class="ltx_td ltx_align_center ltx_border_r">Sign Flip</td>
<td id="A5.T4.1.3.9" class="ltx_td ltx_align_center">Noising</td>
</tr>
<tr id="A5.T4.1.4" class="ltx_tr">
<td id="A5.T4.1.4.1" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Gu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>)</cite></td>
<td id="A5.T4.1.4.2" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Turner et al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="A5.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Bagdasaryan et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite></td>
<td id="A5.T4.1.4.4" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2020</a>)</cite></td>
<td id="A5.T4.1.4.5" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Biggio et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2012</a>; Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="A5.T4.1.4.6" class="ltx_td ltx_align_center ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite></td>
<td id="A5.T4.1.4.7" class="ltx_td ltx_align_center ltx_border_r"><a href="#A3.SS7" title="C.7. Random Label Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.7</span></span></a></td>
<td id="A5.T4.1.4.8" class="ltx_td ltx_align_center ltx_border_r"><a href="#A3.SS8" title="C.8. Sign Flipping ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.8</span></span></a></td>
<td id="A5.T4.1.4.9" class="ltx_td ltx_align_center"><a href="#A3.SS9" title="C.9. Model Noising ‣ Appendix C Poisoning Methods ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">C.9</span></span></a></td>
</tr>
<tr id="A5.T4.1.1" class="ltx_tr">
<td id="A5.T4.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A5.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A5.T4.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A5.T4.1.1.1.m1.1a"><msup id="A5.T4.1.1.1.m1.1.1" xref="A5.T4.1.1.1.m1.1.1.cmml"><mi id="A5.T4.1.1.1.m1.1.1.2" xref="A5.T4.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A5.T4.1.1.1.m1.1.1.3" xref="A5.T4.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A5.T4.1.1.1.m1.1b"><apply id="A5.T4.1.1.1.m1.1.1.cmml" xref="A5.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A5.T4.1.1.1.m1.1.1.1.cmml" xref="A5.T4.1.1.1.m1.1.1">superscript</csymbol><ci id="A5.T4.1.1.1.m1.1.1.2.cmml" xref="A5.T4.1.1.1.m1.1.1.2">𝐺</ci><ci id="A5.T4.1.1.1.m1.1.1.3.cmml" xref="A5.T4.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T4.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A5.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A5.T4.1.1.11" class="ltx_td ltx_align_center ltx_border_t">62.99</td>
</tr>
<tr id="A5.T4.1.5" class="ltx_tr">
<td id="A5.T4.1.5.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A5.T4.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A5.T4.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A5.T4.1.5.11" class="ltx_td ltx_align_center ltx_border_t">57.58</td>
</tr>
<tr id="A5.T4.1.6" class="ltx_tr">
<td id="A5.T4.1.6.1" class="ltx_td ltx_align_left">3:</td>
<td id="A5.T4.1.6.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A5.T4.1.6.3" class="ltx_td ltx_align_center ltx_border_r">57.84</td>
<td id="A5.T4.1.6.4" class="ltx_td ltx_align_center ltx_border_r">54.49</td>
<td id="A5.T4.1.6.5" class="ltx_td ltx_align_center ltx_border_r">54.37</td>
<td id="A5.T4.1.6.6" class="ltx_td ltx_align_center ltx_border_r">58.69</td>
<td id="A5.T4.1.6.7" class="ltx_td ltx_align_center ltx_border_r">47.87</td>
<td id="A5.T4.1.6.8" class="ltx_td ltx_align_center ltx_border_r">53.69</td>
<td id="A5.T4.1.6.9" class="ltx_td ltx_align_center ltx_border_r">53.69</td>
<td id="A5.T4.1.6.10" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A5.T4.1.6.11" class="ltx_td ltx_align_center">46.65</td>
</tr>
<tr id="A5.T4.1.7" class="ltx_tr">
<td id="A5.T4.1.7.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A5.T4.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A5.T4.1.7.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A5.T4.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.7.11" class="ltx_td ltx_align_center ltx_border_t">63.57</td>
</tr>
<tr id="A5.T4.1.8" class="ltx_tr">
<td id="A5.T4.1.8.1" class="ltx_td ltx_align_left">5:</td>
<td id="A5.T4.1.8.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A5.T4.1.8.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A5.T4.1.8.3" class="ltx_td ltx_align_center ltx_border_r">64.92</td>
<td id="A5.T4.1.8.4" class="ltx_td ltx_align_center ltx_border_r">61.79</td>
<td id="A5.T4.1.8.5" class="ltx_td ltx_align_center ltx_border_r">65.49</td>
<td id="A5.T4.1.8.6" class="ltx_td ltx_align_center ltx_border_r">66.55</td>
<td id="A5.T4.1.8.7" class="ltx_td ltx_align_center ltx_border_r">58.31</td>
<td id="A5.T4.1.8.8" class="ltx_td ltx_align_center ltx_border_r">63.66</td>
<td id="A5.T4.1.8.9" class="ltx_td ltx_align_center ltx_border_r">52.55</td>
<td id="A5.T4.1.8.10" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A5.T4.1.8.11" class="ltx_td ltx_align_center">62.73</td>
</tr>
<tr id="A5.T4.1.9" class="ltx_tr">
<td id="A5.T4.1.9.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A5.T4.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A5.T4.1.9.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A5.T4.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.81</td>
<td id="A5.T4.1.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.20</td>
<td id="A5.T4.1.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.66</td>
<td id="A5.T4.1.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.52</td>
<td id="A5.T4.1.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.09</td>
<td id="A5.T4.1.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.51</td>
<td id="A5.T4.1.9.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.03</td>
<td id="A5.T4.1.9.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.00</td>
<td id="A5.T4.1.9.11" class="ltx_td ltx_align_center ltx_border_t">63.07</td>
</tr>
<tr id="A5.T4.1.10" class="ltx_tr">
<td id="A5.T4.1.10.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A5.T4.1.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A5.T4.1.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.06</td>
<td id="A5.T4.1.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.02</td>
<td id="A5.T4.1.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.65</td>
<td id="A5.T4.1.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.63</td>
<td id="A5.T4.1.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.83</td>
<td id="A5.T4.1.10.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">53.99</td>
<td id="A5.T4.1.10.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A5.T4.1.10.11" class="ltx_td ltx_align_center ltx_border_t">63.48</td>
</tr>
<tr id="A5.T4.1.11" class="ltx_tr">
<td id="A5.T4.1.11.1" class="ltx_td ltx_align_left">8:</td>
<td id="A5.T4.1.11.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A5.T4.1.11.3" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A5.T4.1.11.4" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A5.T4.1.11.5" class="ltx_td ltx_align_center ltx_border_r">63.59</td>
<td id="A5.T4.1.11.6" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A5.T4.1.11.7" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A5.T4.1.11.8" class="ltx_td ltx_align_center ltx_border_r">63.66</td>
<td id="A5.T4.1.11.9" class="ltx_td ltx_align_center ltx_border_r">60.41</td>
<td id="A5.T4.1.11.10" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A5.T4.1.11.11" class="ltx_td ltx_align_center">63.07</td>
</tr>
<tr id="A5.T4.1.12" class="ltx_tr">
<td id="A5.T4.1.12.1" class="ltx_td ltx_align_left">9:</td>
<td id="A5.T4.1.12.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A5.T4.1.12.3" class="ltx_td ltx_align_center ltx_border_r">59.75</td>
<td id="A5.T4.1.12.4" class="ltx_td ltx_align_center ltx_border_r">55.18</td>
<td id="A5.T4.1.12.5" class="ltx_td ltx_align_center ltx_border_r">58.72</td>
<td id="A5.T4.1.12.6" class="ltx_td ltx_align_center ltx_border_r">59.86</td>
<td id="A5.T4.1.12.7" class="ltx_td ltx_align_center ltx_border_r">58.38</td>
<td id="A5.T4.1.12.8" class="ltx_td ltx_align_center ltx_border_r">58.38</td>
<td id="A5.T4.1.12.9" class="ltx_td ltx_align_center ltx_border_r">58.38</td>
<td id="A5.T4.1.12.10" class="ltx_td ltx_align_center ltx_border_r">58.38</td>
<td id="A5.T4.1.12.11" class="ltx_td ltx_align_center">58.38</td>
</tr>
<tr id="A5.T4.1.13" class="ltx_tr">
<td id="A5.T4.1.13.1" class="ltx_td ltx_align_left">10:</td>
<td id="A5.T4.1.13.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A5.T4.1.13.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A5.T4.1.13.3" class="ltx_td ltx_align_center ltx_border_r">64.18</td>
<td id="A5.T4.1.13.4" class="ltx_td ltx_align_center ltx_border_r">61.65</td>
<td id="A5.T4.1.13.5" class="ltx_td ltx_align_center ltx_border_r">65.94</td>
<td id="A5.T4.1.13.6" class="ltx_td ltx_align_center ltx_border_r">66.14</td>
<td id="A5.T4.1.13.7" class="ltx_td ltx_align_center ltx_border_r">64.15</td>
<td id="A5.T4.1.13.8" class="ltx_td ltx_align_center ltx_border_r">65.26</td>
<td id="A5.T4.1.13.9" class="ltx_td ltx_align_center ltx_border_r">64.15</td>
<td id="A5.T4.1.13.10" class="ltx_td ltx_align_center ltx_border_r">64.15</td>
<td id="A5.T4.1.13.11" class="ltx_td ltx_align_center">64.15</td>
</tr>
<tr id="A5.T4.1.14" class="ltx_tr">
<td id="A5.T4.1.14.1" class="ltx_td ltx_align_left">11:</td>
<td id="A5.T4.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A5.T4.1.14.3" class="ltx_td ltx_align_center ltx_border_r">63.80</td>
<td id="A5.T4.1.14.4" class="ltx_td ltx_align_center ltx_border_r">64.21</td>
<td id="A5.T4.1.14.5" class="ltx_td ltx_align_center ltx_border_r">64.52</td>
<td id="A5.T4.1.14.6" class="ltx_td ltx_align_center ltx_border_r">64.48</td>
<td id="A5.T4.1.14.7" class="ltx_td ltx_align_center ltx_border_r">56.99</td>
<td id="A5.T4.1.14.8" class="ltx_td ltx_align_center ltx_border_r">63.39</td>
<td id="A5.T4.1.14.9" class="ltx_td ltx_align_center ltx_border_r">54.01</td>
<td id="A5.T4.1.14.10" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A5.T4.1.14.11" class="ltx_td ltx_align_center">63.58</td>
</tr>
<tr id="A5.T4.1.15" class="ltx_tr">
<td id="A5.T4.1.15.1" class="ltx_td ltx_align_left">12:</td>
<td id="A5.T4.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A5.T4.1.15.3" class="ltx_td ltx_align_center ltx_border_r">50.78</td>
<td id="A5.T4.1.15.4" class="ltx_td ltx_align_center ltx_border_r">59.94</td>
<td id="A5.T4.1.15.5" class="ltx_td ltx_align_center ltx_border_r">57.60</td>
<td id="A5.T4.1.15.6" class="ltx_td ltx_align_center ltx_border_r">57.85</td>
<td id="A5.T4.1.15.7" class="ltx_td ltx_align_center ltx_border_r">50.04</td>
<td id="A5.T4.1.15.8" class="ltx_td ltx_align_center ltx_border_r">54.86</td>
<td id="A5.T4.1.15.9" class="ltx_td ltx_align_center ltx_border_r">49.95</td>
<td id="A5.T4.1.15.10" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A5.T4.1.15.11" class="ltx_td ltx_align_center">57.81</td>
</tr>
<tr id="A5.T4.1.16" class="ltx_tr">
<td id="A5.T4.1.16.1" class="ltx_td ltx_align_left">13:</td>
<td id="A5.T4.1.16.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A5.T4.1.16.3" class="ltx_td ltx_align_center ltx_border_r">60.96</td>
<td id="A5.T4.1.16.4" class="ltx_td ltx_align_center ltx_border_r">60.03</td>
<td id="A5.T4.1.16.5" class="ltx_td ltx_align_center ltx_border_r">62.13</td>
<td id="A5.T4.1.16.6" class="ltx_td ltx_align_center ltx_border_r">64.27</td>
<td id="A5.T4.1.16.7" class="ltx_td ltx_align_center ltx_border_r">57.11</td>
<td id="A5.T4.1.16.8" class="ltx_td ltx_align_center ltx_border_r">59.15</td>
<td id="A5.T4.1.16.9" class="ltx_td ltx_align_center ltx_border_r">60.99</td>
<td id="A5.T4.1.16.10" class="ltx_td ltx_align_center ltx_border_r">60.99</td>
<td id="A5.T4.1.16.11" class="ltx_td ltx_align_center">62.60</td>
</tr>
<tr id="A5.T4.1.17" class="ltx_tr">
<td id="A5.T4.1.17.1" class="ltx_td ltx_align_left">14:</td>
<td id="A5.T4.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A5.T4.1.17.3" class="ltx_td ltx_align_center ltx_border_r">63.51</td>
<td id="A5.T4.1.17.4" class="ltx_td ltx_align_center ltx_border_r">64.08</td>
<td id="A5.T4.1.17.5" class="ltx_td ltx_align_center ltx_border_r">64.17</td>
<td id="A5.T4.1.17.6" class="ltx_td ltx_align_center ltx_border_r">64.20</td>
<td id="A5.T4.1.17.7" class="ltx_td ltx_align_center ltx_border_r">56.96</td>
<td id="A5.T4.1.17.8" class="ltx_td ltx_align_center ltx_border_r">63.04</td>
<td id="A5.T4.1.17.9" class="ltx_td ltx_align_center ltx_border_r">56.77</td>
<td id="A5.T4.1.17.10" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A5.T4.1.17.11" class="ltx_td ltx_align_center">63.27</td>
</tr>
<tr id="A5.T4.1.18" class="ltx_tr">
<td id="A5.T4.1.18.1" class="ltx_td ltx_align_left">15:</td>
<td id="A5.T4.1.18.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A5.T4.1.18.3" class="ltx_td ltx_align_center ltx_border_r">51.22</td>
<td id="A5.T4.1.18.4" class="ltx_td ltx_align_center ltx_border_r">53.64</td>
<td id="A5.T4.1.18.5" class="ltx_td ltx_align_center ltx_border_r">52.11</td>
<td id="A5.T4.1.18.6" class="ltx_td ltx_align_center ltx_border_r">55.13</td>
<td id="A5.T4.1.18.7" class="ltx_td ltx_align_center ltx_border_r">48.36</td>
<td id="A5.T4.1.18.8" class="ltx_td ltx_align_center ltx_border_r">49.40</td>
<td id="A5.T4.1.18.9" class="ltx_td ltx_align_center ltx_border_r">44.69</td>
<td id="A5.T4.1.18.10" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A5.T4.1.18.11" class="ltx_td ltx_align_center">51.53</td>
</tr>
<tr id="A5.T4.1.19" class="ltx_tr">
<td id="A5.T4.1.19.1" class="ltx_td ltx_align_left">16:</td>
<td id="A5.T4.1.19.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A5.T4.1.19.3" class="ltx_td ltx_align_center ltx_border_r">63.49</td>
<td id="A5.T4.1.19.4" class="ltx_td ltx_align_center ltx_border_r">63.37</td>
<td id="A5.T4.1.19.5" class="ltx_td ltx_align_center ltx_border_r">63.75</td>
<td id="A5.T4.1.19.6" class="ltx_td ltx_align_center ltx_border_r">64.05</td>
<td id="A5.T4.1.19.7" class="ltx_td ltx_align_center ltx_border_r">62.16</td>
<td id="A5.T4.1.19.8" class="ltx_td ltx_align_center ltx_border_r">63.25</td>
<td id="A5.T4.1.19.9" class="ltx_td ltx_align_center ltx_border_r">63.16</td>
<td id="A5.T4.1.19.10" class="ltx_td ltx_align_center ltx_border_r">26.97</td>
<td id="A5.T4.1.19.11" class="ltx_td ltx_align_center">63.32</td>
</tr>
<tr id="A5.T4.1.20" class="ltx_tr">
<td id="A5.T4.1.20.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A5.T4.1.20.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A5.T4.1.20.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A5.T4.1.20.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.57</td>
<td id="A5.T4.1.20.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">62.18</td>
<td id="A5.T4.1.20.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.36</td>
<td id="A5.T4.1.20.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.15</td>
<td id="A5.T4.1.20.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.15</td>
<td id="A5.T4.1.20.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">62.82</td>
<td id="A5.T4.1.20.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">62.88</td>
<td id="A5.T4.1.20.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.57</td>
<td id="A5.T4.1.20.11" class="ltx_td ltx_align_center ltx_border_bb">63.57</td>
</tr>
</table>
</figure>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Detailed Experimental Results</h2>

<div id="A6.p1" class="ltx_para">
<p id="A6.p1.1" class="ltx_p">In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.</p>
</div>
<div id="A6.p2" class="ltx_para">
<p id="A6.p2.1" class="ltx_p"><a href="#A5.T4" title="Table 4 ‣ Appendix E Additional details on MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a> reports the MAs corresponding to the BAs and ACCs in <a href="#S5.T2" title="Table 2 ‣ 5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></span></a> for different poisoning methods without adaptive adversaries. Note, that <span id="A6.p2.1.1" class="ltx_text">MESAS</span> provides high MA independent of the applied poisoning attack. The table shows, that <span id="A6.p2.1.2" class="ltx_text">MESAS</span> does not negatively impact the MA and is also effective against untargeted attacks.</p>
</div>
<div id="A6.p3" class="ltx_para">
<p id="A6.p3.1" class="ltx_p"><a href="#A6.T5" title="Table 5 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></span></a> shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. <span id="A6.p3.1.1" class="ltx_text">MESAS</span> is already efficient for the unscaled version visualized in scenario  <svg id="A6.p3.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A6.p3.1.pic1.1.1.1.1.1" class="ltx_text">1</span></foreignObject></g></g></svg> in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>, hence is also effective for scaled models due to the intuition visualized in <a href="#S4.F4" title="Figure 4 ‣ 4.2. Metrics Intuition ‣ 4. MESAS ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></span></a>. <a href="#A6.T6" title="Table 6 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></span></a> depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.</p>
</div>
<figure id="A6.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>. </span><span id="A6.T5.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with scaled poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T5.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T5.1.2" class="ltx_tr">
<td id="A6.T5.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T5.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T5.1.1" class="ltx_tr">
<td id="A6.T5.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T5.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T5.1.1.1.m1.1a"><msup id="A6.T5.1.1.1.m1.1.1" xref="A6.T5.1.1.1.m1.1.1.cmml"><mi id="A6.T5.1.1.1.m1.1.1.2" xref="A6.T5.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T5.1.1.1.m1.1.1.3" xref="A6.T5.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T5.1.1.1.m1.1b"><apply id="A6.T5.1.1.1.m1.1.1.cmml" xref="A6.T5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T5.1.1.1.m1.1.1.1.cmml" xref="A6.T5.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T5.1.1.1.m1.1.1.2.cmml" xref="A6.T5.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T5.1.1.1.m1.1.1.3.cmml" xref="A6.T5.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T5.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T5.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T5.1.1.4" class="ltx_td ltx_align_center ltx_border_t">1.90</td>
</tr>
<tr id="A6.T5.1.3" class="ltx_tr">
<td id="A6.T5.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T5.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A6.T5.1.3.4" class="ltx_td ltx_align_center ltx_border_t">4.56</td>
</tr>
<tr id="A6.T5.1.4" class="ltx_tr">
<td id="A6.T5.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T5.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T5.1.4.3" class="ltx_td ltx_align_center ltx_border_r">57.84</td>
<td id="A6.T5.1.4.4" class="ltx_td ltx_align_center">85.13</td>
</tr>
<tr id="A6.T5.1.5" class="ltx_tr">
<td id="A6.T5.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T5.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T5.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T5.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A6.T5.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1.85</td>
</tr>
<tr id="A6.T5.1.6" class="ltx_tr">
<td id="A6.T5.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T5.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T5.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T5.1.6.3" class="ltx_td ltx_align_center ltx_border_r">64.49</td>
<td id="A6.T5.1.6.4" class="ltx_td ltx_align_center">86.45</td>
</tr>
<tr id="A6.T5.1.7" class="ltx_tr">
<td id="A6.T5.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T5.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T5.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T5.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.61</td>
<td id="A6.T5.1.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T5.1.7.4.1" class="ltx_text ltx_font_bold">51.15</span></td>
</tr>
<tr id="A6.T5.1.8" class="ltx_tr">
<td id="A6.T5.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T5.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T5.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T5.1.9" class="ltx_tr">
<td id="A6.T5.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T5.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T5.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.67</td>
<td id="A6.T5.1.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T5.1.9.4.1" class="ltx_text ltx_font_bold">60.85</span></td>
</tr>
<tr id="A6.T5.1.10" class="ltx_tr">
<td id="A6.T5.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T5.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T5.1.10.3" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A6.T5.1.10.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.10.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
</tr>
<tr id="A6.T5.1.11" class="ltx_tr">
<td id="A6.T5.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T5.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T5.1.11.3" class="ltx_td ltx_align_center ltx_border_r">58.38</td>
<td id="A6.T5.1.11.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.11.4.1" class="ltx_text ltx_font_bold">3.98</span></td>
</tr>
<tr id="A6.T5.1.12" class="ltx_tr">
<td id="A6.T5.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T5.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T5.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T5.1.12.3" class="ltx_td ltx_align_center ltx_border_r">64.24</td>
<td id="A6.T5.1.12.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.12.4.1" class="ltx_text ltx_font_bold">56.23</span></td>
</tr>
<tr id="A6.T5.1.13" class="ltx_tr">
<td id="A6.T5.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T5.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T5.1.13.3" class="ltx_td ltx_align_center ltx_border_r">63.61</td>
<td id="A6.T5.1.13.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.13.4.1" class="ltx_text ltx_font_bold">60.33</span></td>
</tr>
<tr id="A6.T5.1.14" class="ltx_tr">
<td id="A6.T5.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T5.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T5.1.14.3" class="ltx_td ltx_align_center ltx_border_r">57.63</td>
<td id="A6.T5.1.14.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.14.4.1" class="ltx_text ltx_font_bold">60.66</span></td>
</tr>
<tr id="A6.T5.1.15" class="ltx_tr">
<td id="A6.T5.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T5.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T5.1.15.3" class="ltx_td ltx_align_center ltx_border_r">60.40</td>
<td id="A6.T5.1.15.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.15.4.1" class="ltx_text ltx_font_bold">71.02</span></td>
</tr>
<tr id="A6.T5.1.16" class="ltx_tr">
<td id="A6.T5.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T5.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T5.1.16.3" class="ltx_td ltx_align_center ltx_border_r">63.35</td>
<td id="A6.T5.1.16.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.16.4.1" class="ltx_text ltx_font_bold">51.52</span></td>
</tr>
<tr id="A6.T5.1.17" class="ltx_tr">
<td id="A6.T5.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T5.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T5.1.17.3" class="ltx_td ltx_align_center ltx_border_r">49.89</td>
<td id="A6.T5.1.17.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.17.4.1" class="ltx_text ltx_font_bold">44.34</span></td>
</tr>
<tr id="A6.T5.1.18" class="ltx_tr">
<td id="A6.T5.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T5.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T5.1.18.3" class="ltx_td ltx_align_center ltx_border_r">63.13</td>
<td id="A6.T5.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T5.1.18.4.1" class="ltx_text ltx_font_bold">23.24</span></td>
</tr>
<tr id="A6.T5.1.19" class="ltx_tr">
<td id="A6.T5.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T5.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T5.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T5.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.36</td>
<td id="A6.T5.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T5.1.19.4.1" class="ltx_text ltx_font_bold">1.95</span></td>
</tr>
</table>
</figure>
<figure id="A6.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T6.3.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>. </span><span id="A6.T6.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with PDR of 0.3 and scaled poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T6.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T6.1.2" class="ltx_tr">
<td id="A6.T6.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T6.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T6.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T6.1.1" class="ltx_tr">
<td id="A6.T6.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T6.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T6.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T6.1.1.1.m1.1a"><msup id="A6.T6.1.1.1.m1.1.1" xref="A6.T6.1.1.1.m1.1.1.cmml"><mi id="A6.T6.1.1.1.m1.1.1.2" xref="A6.T6.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T6.1.1.1.m1.1.1.3" xref="A6.T6.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T6.1.1.1.m1.1b"><apply id="A6.T6.1.1.1.m1.1.1.cmml" xref="A6.T6.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T6.1.1.1.m1.1.1.1.cmml" xref="A6.T6.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T6.1.1.1.m1.1.1.2.cmml" xref="A6.T6.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T6.1.1.1.m1.1.1.3.cmml" xref="A6.T6.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T6.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T6.1.1.4" class="ltx_td ltx_align_center ltx_border_t">1.90</td>
</tr>
<tr id="A6.T6.1.3" class="ltx_tr">
<td id="A6.T6.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T6.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T6.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A6.T6.1.3.4" class="ltx_td ltx_align_center ltx_border_t">4.56</td>
</tr>
<tr id="A6.T6.1.4" class="ltx_tr">
<td id="A6.T6.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T6.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T6.1.4.3" class="ltx_td ltx_align_center ltx_border_r">54.58</td>
<td id="A6.T6.1.4.4" class="ltx_td ltx_align_center">93.15</td>
</tr>
<tr id="A6.T6.1.5" class="ltx_tr">
<td id="A6.T6.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T6.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T6.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T6.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A6.T6.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1.85</td>
</tr>
<tr id="A6.T6.1.6" class="ltx_tr">
<td id="A6.T6.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T6.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T6.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T6.1.6.3" class="ltx_td ltx_align_center ltx_border_r">58.49</td>
<td id="A6.T6.1.6.4" class="ltx_td ltx_align_center">97.46</td>
</tr>
<tr id="A6.T6.1.7" class="ltx_tr">
<td id="A6.T6.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T6.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T6.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T6.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.95</td>
<td id="A6.T6.1.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T6.1.7.4.1" class="ltx_text ltx_font_bold">75.81</span></td>
</tr>
<tr id="A6.T6.1.8" class="ltx_tr">
<td id="A6.T6.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T6.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T6.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T6.1.9" class="ltx_tr">
<td id="A6.T6.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T6.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T6.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.57</td>
<td id="A6.T6.1.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T6.1.9.4.1" class="ltx_text ltx_font_bold">86.86</span></td>
</tr>
<tr id="A6.T6.1.10" class="ltx_tr">
<td id="A6.T6.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T6.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T6.1.10.3" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A6.T6.1.10.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.10.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
</tr>
<tr id="A6.T6.1.11" class="ltx_tr">
<td id="A6.T6.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T6.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T6.1.11.3" class="ltx_td ltx_align_center ltx_border_r">52.22</td>
<td id="A6.T6.1.11.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.11.4.1" class="ltx_text ltx_font_bold">95.97</span></td>
</tr>
<tr id="A6.T6.1.12" class="ltx_tr">
<td id="A6.T6.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T6.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T6.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T6.1.12.3" class="ltx_td ltx_align_center ltx_border_r">63.90</td>
<td id="A6.T6.1.12.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.12.4.1" class="ltx_text ltx_font_bold">92.72</span></td>
</tr>
<tr id="A6.T6.1.13" class="ltx_tr">
<td id="A6.T6.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T6.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T6.1.13.3" class="ltx_td ltx_align_center ltx_border_r">63.85</td>
<td id="A6.T6.1.13.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.13.4.1" class="ltx_text ltx_font_bold">61.86</span></td>
</tr>
<tr id="A6.T6.1.14" class="ltx_tr">
<td id="A6.T6.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T6.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T6.1.14.3" class="ltx_td ltx_align_center ltx_border_r">57.81</td>
<td id="A6.T6.1.14.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.14.4.1" class="ltx_text ltx_font_bold">70.87</span></td>
</tr>
<tr id="A6.T6.1.15" class="ltx_tr">
<td id="A6.T6.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T6.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T6.1.15.3" class="ltx_td ltx_align_center ltx_border_r">60.08</td>
<td id="A6.T6.1.15.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.15.4.1" class="ltx_text ltx_font_bold">91.34</span></td>
</tr>
<tr id="A6.T6.1.16" class="ltx_tr">
<td id="A6.T6.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T6.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T6.1.16.3" class="ltx_td ltx_align_center ltx_border_r">63.54</td>
<td id="A6.T6.1.16.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.16.4.1" class="ltx_text ltx_font_bold">63.98</span></td>
</tr>
<tr id="A6.T6.1.17" class="ltx_tr">
<td id="A6.T6.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T6.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T6.1.17.3" class="ltx_td ltx_align_center ltx_border_r">51.18</td>
<td id="A6.T6.1.17.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.17.4.1" class="ltx_text ltx_font_bold">57.37</span></td>
</tr>
<tr id="A6.T6.1.18" class="ltx_tr">
<td id="A6.T6.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T6.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T6.1.18.3" class="ltx_td ltx_align_center ltx_border_r">63.13</td>
<td id="A6.T6.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T6.1.18.4.1" class="ltx_text ltx_font_bold">23.25</span></td>
</tr>
<tr id="A6.T6.1.19" class="ltx_tr">
<td id="A6.T6.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T6.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T6.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T6.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.36</td>
<td id="A6.T6.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T6.1.19.4.1" class="ltx_text ltx_font_bold">1.95</span></td>
</tr>
</table>
</figure>
<div id="A6.p4" class="ltx_para">
<p id="A6.p4.1" class="ltx_p">We conducted an attack leveraging our strong adaptive adversary against FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> and report the result in <a href="#A6.T7" title="Table 7 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></span></a>. As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In <a href="#A6.T8" title="Table 8 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></span></a> we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.</p>
</div>
<figure id="A6.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T7.3.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>. </span><span id="A6.T7.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with fixation of the last layer to benign trained parameters in percent.</span></figcaption>
<table id="A6.T7.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T7.1.2" class="ltx_tr">
<td id="A6.T7.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T7.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T7.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T7.1.1" class="ltx_tr">
<td id="A6.T7.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T7.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T7.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T7.1.1.1.m1.1a"><msup id="A6.T7.1.1.1.m1.1.1" xref="A6.T7.1.1.1.m1.1.1.cmml"><mi id="A6.T7.1.1.1.m1.1.1.2" xref="A6.T7.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T7.1.1.1.m1.1.1.3" xref="A6.T7.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T7.1.1.1.m1.1b"><apply id="A6.T7.1.1.1.m1.1.1.cmml" xref="A6.T7.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T7.1.1.1.m1.1.1.1.cmml" xref="A6.T7.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T7.1.1.1.m1.1.1.2.cmml" xref="A6.T7.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T7.1.1.1.m1.1.1.3.cmml" xref="A6.T7.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T7.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T7.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T7.1.1.4" class="ltx_td ltx_align_center ltx_border_t">1.90</td>
</tr>
<tr id="A6.T7.1.3" class="ltx_tr">
<td id="A6.T7.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T7.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T7.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A6.T7.1.3.4" class="ltx_td ltx_align_center ltx_border_t">4.56</td>
</tr>
<tr id="A6.T7.1.4" class="ltx_tr">
<td id="A6.T7.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T7.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T7.1.4.3" class="ltx_td ltx_align_center ltx_border_r">58.20</td>
<td id="A6.T7.1.4.4" class="ltx_td ltx_align_center">84.90</td>
</tr>
<tr id="A6.T7.1.5" class="ltx_tr">
<td id="A6.T7.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T7.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T7.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T7.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A6.T7.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1.85</td>
</tr>
<tr id="A6.T7.1.6" class="ltx_tr">
<td id="A6.T7.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T7.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T7.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T7.1.6.3" class="ltx_td ltx_align_center ltx_border_r">64.29</td>
<td id="A6.T7.1.6.4" class="ltx_td ltx_align_center">83.96</td>
</tr>
<tr id="A6.T7.1.7" class="ltx_tr">
<td id="A6.T7.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T7.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T7.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T7.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.74</td>
<td id="A6.T7.1.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T7.1.7.4.1" class="ltx_text ltx_font_bold">42.22</span></td>
</tr>
<tr id="A6.T7.1.8" class="ltx_tr">
<td id="A6.T7.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T7.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T7.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T7.1.9" class="ltx_tr">
<td id="A6.T7.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T7.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T7.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.68</td>
<td id="A6.T7.1.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T7.1.9.4.1" class="ltx_text ltx_font_bold">45.95</span></td>
</tr>
<tr id="A6.T7.1.10" class="ltx_tr">
<td id="A6.T7.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T7.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T7.1.10.3" class="ltx_td ltx_align_center ltx_border_r">63.74</td>
<td id="A6.T7.1.10.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.10.4.1" class="ltx_text ltx_font_bold">42.22</span></td>
</tr>
<tr id="A6.T7.1.11" class="ltx_tr">
<td id="A6.T7.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T7.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T7.1.11.3" class="ltx_td ltx_align_center ltx_border_r">59.69</td>
<td id="A6.T7.1.11.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.11.4.1" class="ltx_text ltx_font_bold">83.21</span></td>
</tr>
<tr id="A6.T7.1.12" class="ltx_tr">
<td id="A6.T7.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T7.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T7.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T7.1.12.3" class="ltx_td ltx_align_center ltx_border_r">63.90</td>
<td id="A6.T7.1.12.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.12.4.1" class="ltx_text ltx_font_bold">92.72</span></td>
</tr>
<tr id="A6.T7.1.13" class="ltx_tr">
<td id="A6.T7.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T7.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T7.1.13.3" class="ltx_td ltx_align_center ltx_border_r">63.81</td>
<td id="A6.T7.1.13.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.13.4.1" class="ltx_text ltx_font_bold">42.23</span></td>
</tr>
<tr id="A6.T7.1.14" class="ltx_tr">
<td id="A6.T7.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T7.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T7.1.14.3" class="ltx_td ltx_align_center ltx_border_r">52.58</td>
<td id="A6.T7.1.14.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.14.4.1" class="ltx_text ltx_font_bold">62.80</span></td>
</tr>
<tr id="A6.T7.1.15" class="ltx_tr">
<td id="A6.T7.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T7.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T7.1.15.3" class="ltx_td ltx_align_center ltx_border_r">60.80</td>
<td id="A6.T7.1.15.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.15.4.1" class="ltx_text ltx_font_bold">76.58</span></td>
</tr>
<tr id="A6.T7.1.16" class="ltx_tr">
<td id="A6.T7.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T7.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T7.1.16.3" class="ltx_td ltx_align_center ltx_border_r">63.43</td>
<td id="A6.T7.1.16.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.16.4.1" class="ltx_text ltx_font_bold">43.50</span></td>
</tr>
<tr id="A6.T7.1.17" class="ltx_tr">
<td id="A6.T7.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T7.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T7.1.17.3" class="ltx_td ltx_align_center ltx_border_r">51.94</td>
<td id="A6.T7.1.17.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.17.4.1" class="ltx_text ltx_font_bold">36.75</span></td>
</tr>
<tr id="A6.T7.1.18" class="ltx_tr">
<td id="A6.T7.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T7.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T7.1.18.3" class="ltx_td ltx_align_center ltx_border_r">63.66</td>
<td id="A6.T7.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T7.1.18.4.1" class="ltx_text ltx_font_bold">20.14</span></td>
</tr>
<tr id="A6.T7.1.19" class="ltx_tr">
<td id="A6.T7.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T7.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T7.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T7.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.57</td>
<td id="A6.T7.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T7.1.19.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
</tr>
</table>
</figure>
<figure id="A6.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T8.3.1.1" class="ltx_text" style="font-size:90%;">Table 8</span>. </span><span id="A6.T8.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with fixation of the last layer to benign trained parameters and scaled poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T8.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T8.1.2" class="ltx_tr">
<td id="A6.T8.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T8.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T8.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T8.1.1" class="ltx_tr">
<td id="A6.T8.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T8.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T8.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T8.1.1.1.m1.1a"><msup id="A6.T8.1.1.1.m1.1.1" xref="A6.T8.1.1.1.m1.1.1.cmml"><mi id="A6.T8.1.1.1.m1.1.1.2" xref="A6.T8.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T8.1.1.1.m1.1.1.3" xref="A6.T8.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T8.1.1.1.m1.1b"><apply id="A6.T8.1.1.1.m1.1.1.cmml" xref="A6.T8.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T8.1.1.1.m1.1.1.1.cmml" xref="A6.T8.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T8.1.1.1.m1.1.1.2.cmml" xref="A6.T8.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T8.1.1.1.m1.1.1.3.cmml" xref="A6.T8.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T8.1.1.4" class="ltx_td ltx_align_center ltx_border_t">1.90</td>
</tr>
<tr id="A6.T8.1.3" class="ltx_tr">
<td id="A6.T8.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T8.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T8.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A6.T8.1.3.4" class="ltx_td ltx_align_center ltx_border_t">4.56</td>
</tr>
<tr id="A6.T8.1.4" class="ltx_tr">
<td id="A6.T8.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T8.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T8.1.4.3" class="ltx_td ltx_align_center ltx_border_r">58.20</td>
<td id="A6.T8.1.4.4" class="ltx_td ltx_align_center">84.90</td>
</tr>
<tr id="A6.T8.1.5" class="ltx_tr">
<td id="A6.T8.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T8.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T8.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T8.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A6.T8.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1.85</td>
</tr>
<tr id="A6.T8.1.6" class="ltx_tr">
<td id="A6.T8.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T8.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T8.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T8.1.6.3" class="ltx_td ltx_align_center ltx_border_r">63.96</td>
<td id="A6.T8.1.6.4" class="ltx_td ltx_align_center">87.35</td>
</tr>
<tr id="A6.T8.1.7" class="ltx_tr">
<td id="A6.T8.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T8.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T8.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T8.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.66</td>
<td id="A6.T8.1.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T8.1.7.4.1" class="ltx_text ltx_font_bold">50.44</span></td>
</tr>
<tr id="A6.T8.1.8" class="ltx_tr">
<td id="A6.T8.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T8.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T8.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T8.1.9" class="ltx_tr">
<td id="A6.T8.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T8.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T8.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.29</td>
<td id="A6.T8.1.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T8.1.9.4.1" class="ltx_text ltx_font_bold">56.94</span></td>
</tr>
<tr id="A6.T8.1.10" class="ltx_tr">
<td id="A6.T8.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T8.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T8.1.10.3" class="ltx_td ltx_align_center ltx_border_r">63.61</td>
<td id="A6.T8.1.10.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.10.4.1" class="ltx_text ltx_font_bold">50.44</span></td>
</tr>
<tr id="A6.T8.1.11" class="ltx_tr">
<td id="A6.T8.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T8.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T8.1.11.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A6.T8.1.11.3.1" class="ltx_text ltx_font_bold">58.38</span></td>
<td id="A6.T8.1.11.4" class="ltx_td ltx_align_center">3.98</td>
</tr>
<tr id="A6.T8.1.12" class="ltx_tr">
<td id="A6.T8.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T8.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T8.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T8.1.12.3" class="ltx_td ltx_align_center ltx_border_r">64.26</td>
<td id="A6.T8.1.12.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.12.4.1" class="ltx_text ltx_font_bold">53.96</span></td>
</tr>
<tr id="A6.T8.1.13" class="ltx_tr">
<td id="A6.T8.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T8.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T8.1.13.3" class="ltx_td ltx_align_center ltx_border_r">53.30</td>
<td id="A6.T8.1.13.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.13.4.1" class="ltx_text ltx_font_bold">58.45</span></td>
</tr>
<tr id="A6.T8.1.14" class="ltx_tr">
<td id="A6.T8.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T8.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T8.1.14.3" class="ltx_td ltx_align_center ltx_border_r">57.63</td>
<td id="A6.T8.1.14.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.14.4.1" class="ltx_text ltx_font_bold">60.66</span></td>
</tr>
<tr id="A6.T8.1.15" class="ltx_tr">
<td id="A6.T8.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T8.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T8.1.15.3" class="ltx_td ltx_align_center ltx_border_r">62.67</td>
<td id="A6.T8.1.15.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.15.4.1" class="ltx_text ltx_font_bold">71.26</span></td>
</tr>
<tr id="A6.T8.1.16" class="ltx_tr">
<td id="A6.T8.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T8.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T8.1.16.3" class="ltx_td ltx_align_center ltx_border_r">63.27</td>
<td id="A6.T8.1.16.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.16.4.1" class="ltx_text ltx_font_bold">50.56</span></td>
</tr>
<tr id="A6.T8.1.17" class="ltx_tr">
<td id="A6.T8.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T8.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T8.1.17.3" class="ltx_td ltx_align_center ltx_border_r">51.76</td>
<td id="A6.T8.1.17.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.17.4.1" class="ltx_text ltx_font_bold">39.64</span></td>
</tr>
<tr id="A6.T8.1.18" class="ltx_tr">
<td id="A6.T8.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T8.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T8.1.18.3" class="ltx_td ltx_align_center ltx_border_r">63.45</td>
<td id="A6.T8.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T8.1.18.4.1" class="ltx_text ltx_font_bold">20.37</span></td>
</tr>
<tr id="A6.T8.1.19" class="ltx_tr">
<td id="A6.T8.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T8.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T8.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T8.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.36</td>
<td id="A6.T8.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T8.1.19.4.1" class="ltx_text ltx_font_bold">1.95</span></td>
</tr>
</table>
</figure>
<div id="A6.p5" class="ltx_para">
<p id="A6.p5.2" class="ltx_p">Scenario  <svg id="A6.p5.1.pic1" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A6.p5.1.pic1.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> of <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> and <a href="#A6.T9" title="Table 9 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></span></a> shows the result after adapting to Krum scores <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. <a href="#A6.F12" title="Figure 12 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></span></a> depicts the Krum scores for the default scenario associated with the default scenario in <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  <svg id="A6.p5.2.pic2" class="ltx_picture" height="13.74" overflow="visible" version="1.1" width="13.74"><g transform="translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="A6.p5.2.pic2.1.1.1.1.1" class="ltx_text">3</span></foreignObject></g></g></svg> of <a href="#S5.T1" title="Table 1 ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a> and <a href="#A6.T9" title="Table 9 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></span></a>.</p>
</div>
<figure id="A6.F12" class="ltx_figure"><img src="/html/2306.03600/assets/x27.png" id="A6.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A6.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>. </span><span id="A6.F12.3.2" class="ltx_text" style="font-size:90%;">Krum scores for the default scenario. The erasure of the backdoor in the default scenario is based on the fact, that a benign score is the most central one. Nevertheless, the metric is not highlighting the malicious models significantly.</span></figcaption>
</figure>
<figure id="A6.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T9.3.1.1" class="ltx_text" style="font-size:90%;">Table 9</span>. </span><span id="A6.T9.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with adaption of the Euclidean distance between local models and the global model to benign values and scaled poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T9.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T9.1.2" class="ltx_tr">
<td id="A6.T9.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T9.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T9.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T9.1.1" class="ltx_tr">
<td id="A6.T9.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T9.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T9.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T9.1.1.1.m1.1a"><msup id="A6.T9.1.1.1.m1.1.1" xref="A6.T9.1.1.1.m1.1.1.cmml"><mi id="A6.T9.1.1.1.m1.1.1.2" xref="A6.T9.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T9.1.1.1.m1.1.1.3" xref="A6.T9.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T9.1.1.1.m1.1b"><apply id="A6.T9.1.1.1.m1.1.1.cmml" xref="A6.T9.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T9.1.1.1.m1.1.1.1.cmml" xref="A6.T9.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T9.1.1.1.m1.1.1.2.cmml" xref="A6.T9.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T9.1.1.1.m1.1.1.3.cmml" xref="A6.T9.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T9.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_t">1.90</td>
</tr>
<tr id="A6.T9.1.3" class="ltx_tr">
<td id="A6.T9.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T9.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T9.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.58</td>
<td id="A6.T9.1.3.4" class="ltx_td ltx_align_center ltx_border_t">4.56</td>
</tr>
<tr id="A6.T9.1.4" class="ltx_tr">
<td id="A6.T9.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T9.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T9.1.4.3" class="ltx_td ltx_align_center ltx_border_r">51.23</td>
<td id="A6.T9.1.4.4" class="ltx_td ltx_align_center">89.82</td>
</tr>
<tr id="A6.T9.1.5" class="ltx_tr">
<td id="A6.T9.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T9.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T9.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T9.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.57</td>
<td id="A6.T9.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1.85</td>
</tr>
<tr id="A6.T9.1.6" class="ltx_tr">
<td id="A6.T9.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T9.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T9.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T9.1.6.3" class="ltx_td ltx_align_center ltx_border_r">40.23</td>
<td id="A6.T9.1.6.4" class="ltx_td ltx_align_center">93.54</td>
</tr>
<tr id="A6.T9.1.7" class="ltx_tr">
<td id="A6.T9.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T9.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T9.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T9.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.90</td>
<td id="A6.T9.1.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T9.1.7.4.1" class="ltx_text ltx_font_bold">83.93</span></td>
</tr>
<tr id="A6.T9.1.8" class="ltx_tr">
<td id="A6.T9.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T9.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T9.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T9.1.9" class="ltx_tr">
<td id="A6.T9.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T9.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T9.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.98</td>
<td id="A6.T9.1.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A6.T9.1.9.4.1" class="ltx_text ltx_font_bold">85.76</span></td>
</tr>
<tr id="A6.T9.1.10" class="ltx_tr">
<td id="A6.T9.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T9.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T9.1.10.3" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A6.T9.1.10.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.10.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
</tr>
<tr id="A6.T9.1.11" class="ltx_tr">
<td id="A6.T9.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T9.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T9.1.11.3" class="ltx_td ltx_align_center ltx_border_r">51.46</td>
<td id="A6.T9.1.11.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.11.4.1" class="ltx_text ltx_font_bold">87.88</span></td>
</tr>
<tr id="A6.T9.1.12" class="ltx_tr">
<td id="A6.T9.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T9.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T9.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T9.1.12.3" class="ltx_td ltx_align_center ltx_border_r">43.19</td>
<td id="A6.T9.1.12.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.12.4.1" class="ltx_text ltx_font_bold">95.25</span></td>
</tr>
<tr id="A6.T9.1.13" class="ltx_tr">
<td id="A6.T9.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T9.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T9.1.13.3" class="ltx_td ltx_align_center ltx_border_r">49.08</td>
<td id="A6.T9.1.13.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.13.4.1" class="ltx_text ltx_font_bold">83.83</span></td>
</tr>
<tr id="A6.T9.1.14" class="ltx_tr">
<td id="A6.T9.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T9.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T9.1.14.3" class="ltx_td ltx_align_center ltx_border_r">43.95</td>
<td id="A6.T9.1.14.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.14.4.1" class="ltx_text ltx_font_bold">87.44</span></td>
</tr>
<tr id="A6.T9.1.15" class="ltx_tr">
<td id="A6.T9.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T9.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T9.1.15.3" class="ltx_td ltx_align_center ltx_border_r">46.11</td>
<td id="A6.T9.1.15.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.15.4.1" class="ltx_text ltx_font_bold">92.83</span></td>
</tr>
<tr id="A6.T9.1.16" class="ltx_tr">
<td id="A6.T9.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T9.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T9.1.16.3" class="ltx_td ltx_align_center ltx_border_r">50.85</td>
<td id="A6.T9.1.16.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.16.4.1" class="ltx_text ltx_font_bold">85.88</span></td>
</tr>
<tr id="A6.T9.1.17" class="ltx_tr">
<td id="A6.T9.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T9.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T9.1.17.3" class="ltx_td ltx_align_center ltx_border_r">39.62</td>
<td id="A6.T9.1.17.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.17.4.1" class="ltx_text ltx_font_bold">74.82</span></td>
</tr>
<tr id="A6.T9.1.18" class="ltx_tr">
<td id="A6.T9.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T9.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T9.1.18.3" class="ltx_td ltx_align_center ltx_border_r">55.07</td>
<td id="A6.T9.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T9.1.18.4.1" class="ltx_text ltx_font_bold">74.72</span></td>
</tr>
<tr id="A6.T9.1.19" class="ltx_tr">
<td id="A6.T9.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T9.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T9.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T9.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">63.57</td>
<td id="A6.T9.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T9.1.19.4.1" class="ltx_text ltx_font_bold">1.85</span></td>
</tr>
</table>
</figure>
<div id="A6.p6" class="ltx_para">
<p id="A6.p6.1" class="ltx_p"><a href="#A6.T10" title="Table 10 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></span></a> and <a href="#A6.T11" title="Table 11 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></span></a> show the results for a classical <span id="A6.p6.1.1" class="ltx_text">intra-client</span> <span id="A6.p6.1.2" class="ltx_text">non-IID</span> scenario crafted by <span id="A6.p6.1.3" class="ltx_text">1-class</span> <span id="A6.p6.1.4" class="ltx_text">non-IID</span> with <math id="A6.p6.1.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="A6.p6.1.m1.1a"><mrow id="A6.p6.1.m1.1.1" xref="A6.p6.1.m1.1.1.cmml"><mi id="A6.p6.1.m1.1.1.2" xref="A6.p6.1.m1.1.1.2.cmml">q</mi><mo id="A6.p6.1.m1.1.1.1" xref="A6.p6.1.m1.1.1.1.cmml">=</mo><mn id="A6.p6.1.m1.1.1.3" xref="A6.p6.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p6.1.m1.1b"><apply id="A6.p6.1.m1.1.1.cmml" xref="A6.p6.1.m1.1.1"><eq id="A6.p6.1.m1.1.1.1.cmml" xref="A6.p6.1.m1.1.1.1"></eq><ci id="A6.p6.1.m1.1.1.2.cmml" xref="A6.p6.1.m1.1.1.2">𝑞</ci><cn type="float" id="A6.p6.1.m1.1.1.3.cmml" xref="A6.p6.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p6.1.m1.1c">q=0.5</annotation></semantics></math>. In both cases, <span id="A6.p6.1.5" class="ltx_text">MESAS</span> reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. <a href="#A6.T12" title="Table 12 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></span></a> depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. <span id="A6.p6.1.6" class="ltx_text">MESAS</span> still removes the poisoned models most effectively with only two FPs.</p>
</div>
<figure id="A6.T10" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T10.7.2.1" class="ltx_text" style="font-size:90%;">Table 10</span>. </span><span id="A6.T10.2.1" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario for <span id="A6.T10.2.1.1" class="ltx_text">1-class</span> <span id="A6.T10.2.1.2" class="ltx_text">non-IID</span> with <math id="A6.T10.2.1.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="A6.T10.2.1.m1.1b"><mrow id="A6.T10.2.1.m1.1.1" xref="A6.T10.2.1.m1.1.1.cmml"><mi id="A6.T10.2.1.m1.1.1.2" xref="A6.T10.2.1.m1.1.1.2.cmml">q</mi><mo id="A6.T10.2.1.m1.1.1.1" xref="A6.T10.2.1.m1.1.1.1.cmml">=</mo><mn id="A6.T10.2.1.m1.1.1.3" xref="A6.T10.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T10.2.1.m1.1c"><apply id="A6.T10.2.1.m1.1.1.cmml" xref="A6.T10.2.1.m1.1.1"><eq id="A6.T10.2.1.m1.1.1.1.cmml" xref="A6.T10.2.1.m1.1.1.1"></eq><ci id="A6.T10.2.1.m1.1.1.2.cmml" xref="A6.T10.2.1.m1.1.1.2">𝑞</ci><cn type="float" id="A6.T10.2.1.m1.1.1.3.cmml" xref="A6.T10.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T10.2.1.m1.1d">q=0.5</annotation></semantics></math> in percent.</span></figcaption>
<table id="A6.T10.3" class="ltx_tabular ltx_align_middle">
<tr id="A6.T10.3.2" class="ltx_tr">
<td id="A6.T10.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T10.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T10.3.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T10.3.1" class="ltx_tr">
<td id="A6.T10.3.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T10.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T10.3.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T10.3.1.1.m1.1a"><msup id="A6.T10.3.1.1.m1.1.1" xref="A6.T10.3.1.1.m1.1.1.cmml"><mi id="A6.T10.3.1.1.m1.1.1.2" xref="A6.T10.3.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T10.3.1.1.m1.1.1.3" xref="A6.T10.3.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T10.3.1.1.m1.1b"><apply id="A6.T10.3.1.1.m1.1.1.cmml" xref="A6.T10.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T10.3.1.1.m1.1.1.1.cmml" xref="A6.T10.3.1.1.m1.1.1">superscript</csymbol><ci id="A6.T10.3.1.1.m1.1.1.2.cmml" xref="A6.T10.3.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T10.3.1.1.m1.1.1.3.cmml" xref="A6.T10.3.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T10.3.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T10.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T10.3.1.4" class="ltx_td ltx_align_center ltx_border_t">1.93</td>
</tr>
<tr id="A6.T10.3.3" class="ltx_tr">
<td id="A6.T10.3.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T10.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T10.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.15</td>
<td id="A6.T10.3.3.4" class="ltx_td ltx_align_center ltx_border_t">6.82</td>
</tr>
<tr id="A6.T10.3.4" class="ltx_tr">
<td id="A6.T10.3.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T10.3.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T10.3.4.3" class="ltx_td ltx_align_center ltx_border_r">45.88</td>
<td id="A6.T10.3.4.4" class="ltx_td ltx_align_center">84.42</td>
</tr>
<tr id="A6.T10.3.5" class="ltx_tr">
<td id="A6.T10.3.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T10.3.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T10.3.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T10.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="A6.T10.3.5.4" class="ltx_td ltx_align_center ltx_border_t">1.40</td>
</tr>
<tr id="A6.T10.3.6" class="ltx_tr">
<td id="A6.T10.3.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T10.3.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T10.3.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T10.3.6.3" class="ltx_td ltx_align_center ltx_border_r">64.07</td>
<td id="A6.T10.3.6.4" class="ltx_td ltx_align_center">83.42</td>
</tr>
<tr id="A6.T10.3.7" class="ltx_tr">
<td id="A6.T10.3.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T10.3.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T10.3.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T10.3.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.48</td>
<td id="A6.T10.3.7.4" class="ltx_td ltx_align_center ltx_border_t">43.96</td>
</tr>
<tr id="A6.T10.3.8" class="ltx_tr">
<td id="A6.T10.3.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T10.3.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T10.3.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T10.3.9" class="ltx_tr">
<td id="A6.T10.3.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T10.3.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T10.3.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.76</td>
<td id="A6.T10.3.9.4" class="ltx_td ltx_align_center ltx_border_t">47.02</td>
</tr>
<tr id="A6.T10.3.10" class="ltx_tr">
<td id="A6.T10.3.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T10.3.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T10.3.10.3" class="ltx_td ltx_align_center ltx_border_r">50.13</td>
<td id="A6.T10.3.10.4" class="ltx_td ltx_align_center"><span id="A6.T10.3.10.4.1" class="ltx_text ltx_font_bold">3.45</span></td>
</tr>
<tr id="A6.T10.3.11" class="ltx_tr">
<td id="A6.T10.3.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T10.3.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T10.3.11.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A6.T10.3.11.3.1" class="ltx_text ltx_font_bold">49.88</span></td>
<td id="A6.T10.3.11.4" class="ltx_td ltx_align_center">5.27</td>
</tr>
<tr id="A6.T10.3.12" class="ltx_tr">
<td id="A6.T10.3.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T10.3.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T10.3.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T10.3.12.3" class="ltx_td ltx_align_center ltx_border_r">60.98</td>
<td id="A6.T10.3.12.4" class="ltx_td ltx_align_center">52.57</td>
</tr>
<tr id="A6.T10.3.13" class="ltx_tr">
<td id="A6.T10.3.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T10.3.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T10.3.13.3" class="ltx_td ltx_align_center ltx_border_r">65.50</td>
<td id="A6.T10.3.13.4" class="ltx_td ltx_align_center">41.33</td>
</tr>
<tr id="A6.T10.3.14" class="ltx_tr">
<td id="A6.T10.3.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T10.3.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T10.3.14.3" class="ltx_td ltx_align_center ltx_border_r">59.53</td>
<td id="A6.T10.3.14.4" class="ltx_td ltx_align_center">52.31</td>
</tr>
<tr id="A6.T10.3.15" class="ltx_tr">
<td id="A6.T10.3.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T10.3.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T10.3.15.3" class="ltx_td ltx_align_center ltx_border_r">61.46</td>
<td id="A6.T10.3.15.4" class="ltx_td ltx_align_center">34.37</td>
</tr>
<tr id="A6.T10.3.16" class="ltx_tr">
<td id="A6.T10.3.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T10.3.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T10.3.16.3" class="ltx_td ltx_align_center ltx_border_r">64.83</td>
<td id="A6.T10.3.16.4" class="ltx_td ltx_align_center">47.27</td>
</tr>
<tr id="A6.T10.3.17" class="ltx_tr">
<td id="A6.T10.3.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T10.3.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T10.3.17.3" class="ltx_td ltx_align_center ltx_border_r">54.84</td>
<td id="A6.T10.3.17.4" class="ltx_td ltx_align_center">47.46</td>
</tr>
<tr id="A6.T10.3.18" class="ltx_tr">
<td id="A6.T10.3.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T10.3.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T10.3.18.3" class="ltx_td ltx_align_center ltx_border_r">69.96</td>
<td id="A6.T10.3.18.4" class="ltx_td ltx_align_center"><span id="A6.T10.3.18.4.1" class="ltx_text ltx_font_bold">4.64</span></td>
</tr>
<tr id="A6.T10.3.19" class="ltx_tr">
<td id="A6.T10.3.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T10.3.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T10.3.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T10.3.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">64.70</td>
<td id="A6.T10.3.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T10.3.19.4.1" class="ltx_text ltx_font_bold">2.13</span></td>
</tr>
</table>
</figure>
<figure id="A6.T11" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T11.7.2.1" class="ltx_text" style="font-size:90%;">Table 11</span>. </span><span id="A6.T11.2.1" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario for <span id="A6.T11.2.1.1" class="ltx_text">1-class</span> <span id="A6.T11.2.1.2" class="ltx_text">non-IID</span> with <math id="A6.T11.2.1.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="A6.T11.2.1.m1.1b"><mrow id="A6.T11.2.1.m1.1.1" xref="A6.T11.2.1.m1.1.1.cmml"><mi id="A6.T11.2.1.m1.1.1.2" xref="A6.T11.2.1.m1.1.1.2.cmml">q</mi><mo id="A6.T11.2.1.m1.1.1.1" xref="A6.T11.2.1.m1.1.1.1.cmml">=</mo><mn id="A6.T11.2.1.m1.1.1.3" xref="A6.T11.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T11.2.1.m1.1c"><apply id="A6.T11.2.1.m1.1.1.cmml" xref="A6.T11.2.1.m1.1.1"><eq id="A6.T11.2.1.m1.1.1.1.cmml" xref="A6.T11.2.1.m1.1.1.1"></eq><ci id="A6.T11.2.1.m1.1.1.2.cmml" xref="A6.T11.2.1.m1.1.1.2">𝑞</ci><cn type="float" id="A6.T11.2.1.m1.1.1.3.cmml" xref="A6.T11.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T11.2.1.m1.1d">q=0.5</annotation></semantics></math> and scaled
poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T11.3" class="ltx_tabular ltx_align_middle">
<tr id="A6.T11.3.2" class="ltx_tr">
<td id="A6.T11.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T11.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T11.3.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T11.3.1" class="ltx_tr">
<td id="A6.T11.3.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T11.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T11.3.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T11.3.1.1.m1.1a"><msup id="A6.T11.3.1.1.m1.1.1" xref="A6.T11.3.1.1.m1.1.1.cmml"><mi id="A6.T11.3.1.1.m1.1.1.2" xref="A6.T11.3.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T11.3.1.1.m1.1.1.3" xref="A6.T11.3.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T11.3.1.1.m1.1b"><apply id="A6.T11.3.1.1.m1.1.1.cmml" xref="A6.T11.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T11.3.1.1.m1.1.1.1.cmml" xref="A6.T11.3.1.1.m1.1.1">superscript</csymbol><ci id="A6.T11.3.1.1.m1.1.1.2.cmml" xref="A6.T11.3.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T11.3.1.1.m1.1.1.3.cmml" xref="A6.T11.3.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T11.3.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T11.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T11.3.1.4" class="ltx_td ltx_align_center ltx_border_t">1.93</td>
</tr>
<tr id="A6.T11.3.3" class="ltx_tr">
<td id="A6.T11.3.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T11.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T11.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.15</td>
<td id="A6.T11.3.3.4" class="ltx_td ltx_align_center ltx_border_t">6.82</td>
</tr>
<tr id="A6.T11.3.4" class="ltx_tr">
<td id="A6.T11.3.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T11.3.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T11.3.4.3" class="ltx_td ltx_align_center ltx_border_r">45.88</td>
<td id="A6.T11.3.4.4" class="ltx_td ltx_align_center">84.42</td>
</tr>
<tr id="A6.T11.3.5" class="ltx_tr">
<td id="A6.T11.3.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T11.3.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T11.3.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T11.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="A6.T11.3.5.4" class="ltx_td ltx_align_center ltx_border_t">1.40</td>
</tr>
<tr id="A6.T11.3.6" class="ltx_tr">
<td id="A6.T11.3.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T11.3.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T11.3.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T11.3.6.3" class="ltx_td ltx_align_center ltx_border_r">64.46</td>
<td id="A6.T11.3.6.4" class="ltx_td ltx_align_center">84.48</td>
</tr>
<tr id="A6.T11.3.7" class="ltx_tr">
<td id="A6.T11.3.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T11.3.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T11.3.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T11.3.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.31</td>
<td id="A6.T11.3.7.4" class="ltx_td ltx_align_center ltx_border_t">45.94</td>
</tr>
<tr id="A6.T11.3.8" class="ltx_tr">
<td id="A6.T11.3.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T11.3.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T11.3.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T11.3.9" class="ltx_tr">
<td id="A6.T11.3.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T11.3.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T11.3.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.59</td>
<td id="A6.T11.3.9.4" class="ltx_td ltx_align_center ltx_border_t">49.47</td>
</tr>
<tr id="A6.T11.3.10" class="ltx_tr">
<td id="A6.T11.3.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T11.3.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T11.3.10.3" class="ltx_td ltx_align_center ltx_border_r">50.13</td>
<td id="A6.T11.3.10.4" class="ltx_td ltx_align_center"><span id="A6.T11.3.10.4.1" class="ltx_text ltx_font_bold">3.45</span></td>
</tr>
<tr id="A6.T11.3.11" class="ltx_tr">
<td id="A6.T11.3.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T11.3.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T11.3.11.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A6.T11.3.11.3.1" class="ltx_text ltx_font_bold">49.88</span></td>
<td id="A6.T11.3.11.4" class="ltx_td ltx_align_center">5.27</td>
</tr>
<tr id="A6.T11.3.12" class="ltx_tr">
<td id="A6.T11.3.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T11.3.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T11.3.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T11.3.12.3" class="ltx_td ltx_align_center ltx_border_r">63.59</td>
<td id="A6.T11.3.12.4" class="ltx_td ltx_align_center">7.21</td>
</tr>
<tr id="A6.T11.3.13" class="ltx_tr">
<td id="A6.T11.3.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T11.3.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T11.3.13.3" class="ltx_td ltx_align_center ltx_border_r">65.39</td>
<td id="A6.T11.3.13.4" class="ltx_td ltx_align_center">43.36</td>
</tr>
<tr id="A6.T11.3.14" class="ltx_tr">
<td id="A6.T11.3.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T11.3.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T11.3.14.3" class="ltx_td ltx_align_center ltx_border_r">58.89</td>
<td id="A6.T11.3.14.4" class="ltx_td ltx_align_center">52.54</td>
</tr>
<tr id="A6.T11.3.15" class="ltx_tr">
<td id="A6.T11.3.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T11.3.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T11.3.15.3" class="ltx_td ltx_align_center ltx_border_r">58.86</td>
<td id="A6.T11.3.15.4" class="ltx_td ltx_align_center">34.72</td>
</tr>
<tr id="A6.T11.3.16" class="ltx_tr">
<td id="A6.T11.3.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T11.3.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T11.3.16.3" class="ltx_td ltx_align_center ltx_border_r">64.61</td>
<td id="A6.T11.3.16.4" class="ltx_td ltx_align_center">48.96</td>
</tr>
<tr id="A6.T11.3.17" class="ltx_tr">
<td id="A6.T11.3.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T11.3.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T11.3.17.3" class="ltx_td ltx_align_center ltx_border_r">54.51</td>
<td id="A6.T11.3.17.4" class="ltx_td ltx_align_center">48.37</td>
</tr>
<tr id="A6.T11.3.18" class="ltx_tr">
<td id="A6.T11.3.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T11.3.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T11.3.18.3" class="ltx_td ltx_align_center ltx_border_r">63.92</td>
<td id="A6.T11.3.18.4" class="ltx_td ltx_align_center"><span id="A6.T11.3.18.4.1" class="ltx_text ltx_font_bold">4.63</span></td>
</tr>
<tr id="A6.T11.3.19" class="ltx_tr">
<td id="A6.T11.3.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T11.3.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T11.3.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T11.3.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">64.69</td>
<td id="A6.T11.3.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T11.3.19.4.1" class="ltx_text ltx_font_bold">2.24</span></td>
</tr>
</table>
</figure>
<figure id="A6.T12" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T12.7.2.1" class="ltx_text" style="font-size:90%;">Table 12</span>. </span><span id="A6.T12.2.1" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with a PDR of 0.3 and for <span id="A6.T12.2.1.1" class="ltx_text">1-class</span> <span id="A6.T12.2.1.2" class="ltx_text">non-IID</span> with <math id="A6.T12.2.1.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="A6.T12.2.1.m1.1b"><mrow id="A6.T12.2.1.m1.1.1" xref="A6.T12.2.1.m1.1.1.cmml"><mi id="A6.T12.2.1.m1.1.1.2" xref="A6.T12.2.1.m1.1.1.2.cmml">q</mi><mo id="A6.T12.2.1.m1.1.1.1" xref="A6.T12.2.1.m1.1.1.1.cmml">=</mo><mn id="A6.T12.2.1.m1.1.1.3" xref="A6.T12.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T12.2.1.m1.1c"><apply id="A6.T12.2.1.m1.1.1.cmml" xref="A6.T12.2.1.m1.1.1"><eq id="A6.T12.2.1.m1.1.1.1.cmml" xref="A6.T12.2.1.m1.1.1.1"></eq><ci id="A6.T12.2.1.m1.1.1.2.cmml" xref="A6.T12.2.1.m1.1.1.2">𝑞</ci><cn type="float" id="A6.T12.2.1.m1.1.1.3.cmml" xref="A6.T12.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T12.2.1.m1.1d">q=0.5</annotation></semantics></math> in percent.</span></figcaption>
<table id="A6.T12.3" class="ltx_tabular ltx_align_middle">
<tr id="A6.T12.3.2" class="ltx_tr">
<td id="A6.T12.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T12.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T12.3.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T12.3.1" class="ltx_tr">
<td id="A6.T12.3.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T12.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T12.3.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T12.3.1.1.m1.1a"><msup id="A6.T12.3.1.1.m1.1.1" xref="A6.T12.3.1.1.m1.1.1.cmml"><mi id="A6.T12.3.1.1.m1.1.1.2" xref="A6.T12.3.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T12.3.1.1.m1.1.1.3" xref="A6.T12.3.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T12.3.1.1.m1.1b"><apply id="A6.T12.3.1.1.m1.1.1.cmml" xref="A6.T12.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T12.3.1.1.m1.1.1.1.cmml" xref="A6.T12.3.1.1.m1.1.1">superscript</csymbol><ci id="A6.T12.3.1.1.m1.1.1.2.cmml" xref="A6.T12.3.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T12.3.1.1.m1.1.1.3.cmml" xref="A6.T12.3.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T12.3.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T12.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T12.3.1.4" class="ltx_td ltx_align_center ltx_border_t">1.93</td>
</tr>
<tr id="A6.T12.3.3" class="ltx_tr">
<td id="A6.T12.3.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T12.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T12.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.15</td>
<td id="A6.T12.3.3.4" class="ltx_td ltx_align_center ltx_border_t">6.82</td>
</tr>
<tr id="A6.T12.3.4" class="ltx_tr">
<td id="A6.T12.3.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T12.3.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T12.3.4.3" class="ltx_td ltx_align_center ltx_border_r">43.74</td>
<td id="A6.T12.3.4.4" class="ltx_td ltx_align_center">91.32</td>
</tr>
<tr id="A6.T12.3.5" class="ltx_tr">
<td id="A6.T12.3.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T12.3.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T12.3.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T12.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="A6.T12.3.5.4" class="ltx_td ltx_align_center ltx_border_t">1.40</td>
</tr>
<tr id="A6.T12.3.6" class="ltx_tr">
<td id="A6.T12.3.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T12.3.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T12.3.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T12.3.6.3" class="ltx_td ltx_align_center ltx_border_r">61.48</td>
<td id="A6.T12.3.6.4" class="ltx_td ltx_align_center">92.92</td>
</tr>
<tr id="A6.T12.3.7" class="ltx_tr">
<td id="A6.T12.3.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T12.3.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T12.3.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T12.3.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.64</td>
<td id="A6.T12.3.7.4" class="ltx_td ltx_align_center ltx_border_t">57.68</td>
</tr>
<tr id="A6.T12.3.8" class="ltx_tr">
<td id="A6.T12.3.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T12.3.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T12.3.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T12.3.9" class="ltx_tr">
<td id="A6.T12.3.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T12.3.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T12.3.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.49</td>
<td id="A6.T12.3.9.4" class="ltx_td ltx_align_center ltx_border_t">83.70</td>
</tr>
<tr id="A6.T12.3.10" class="ltx_tr">
<td id="A6.T12.3.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T12.3.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T12.3.10.3" class="ltx_td ltx_align_center ltx_border_r">57.60</td>
<td id="A6.T12.3.10.4" class="ltx_td ltx_align_center">39.05</td>
</tr>
<tr id="A6.T12.3.11" class="ltx_tr">
<td id="A6.T12.3.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T12.3.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T12.3.11.3" class="ltx_td ltx_align_center ltx_border_r">49.43</td>
<td id="A6.T12.3.11.4" class="ltx_td ltx_align_center">92.86</td>
</tr>
<tr id="A6.T12.3.12" class="ltx_tr">
<td id="A6.T12.3.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T12.3.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T12.3.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T12.3.12.3" class="ltx_td ltx_align_center ltx_border_r">57.51</td>
<td id="A6.T12.3.12.4" class="ltx_td ltx_align_center">85.95</td>
</tr>
<tr id="A6.T12.3.13" class="ltx_tr">
<td id="A6.T12.3.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T12.3.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T12.3.13.3" class="ltx_td ltx_align_center ltx_border_r">64.60</td>
<td id="A6.T12.3.13.4" class="ltx_td ltx_align_center">56.81</td>
</tr>
<tr id="A6.T12.3.14" class="ltx_tr">
<td id="A6.T12.3.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T12.3.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T12.3.14.3" class="ltx_td ltx_align_center ltx_border_r">57.77</td>
<td id="A6.T12.3.14.4" class="ltx_td ltx_align_center">70.20</td>
</tr>
<tr id="A6.T12.3.15" class="ltx_tr">
<td id="A6.T12.3.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T12.3.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T12.3.15.3" class="ltx_td ltx_align_center ltx_border_r">60.55</td>
<td id="A6.T12.3.15.4" class="ltx_td ltx_align_center">45.36</td>
</tr>
<tr id="A6.T12.3.16" class="ltx_tr">
<td id="A6.T12.3.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T12.3.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T12.3.16.3" class="ltx_td ltx_align_center ltx_border_r">63.81</td>
<td id="A6.T12.3.16.4" class="ltx_td ltx_align_center">62.77</td>
</tr>
<tr id="A6.T12.3.17" class="ltx_tr">
<td id="A6.T12.3.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T12.3.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T12.3.17.3" class="ltx_td ltx_align_center ltx_border_r">52.96</td>
<td id="A6.T12.3.17.4" class="ltx_td ltx_align_center">66.78</td>
</tr>
<tr id="A6.T12.3.18" class="ltx_tr">
<td id="A6.T12.3.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T12.3.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T12.3.18.3" class="ltx_td ltx_align_center ltx_border_r">63.73</td>
<td id="A6.T12.3.18.4" class="ltx_td ltx_align_center"><span id="A6.T12.3.18.4.1" class="ltx_text ltx_font_bold">8.31</span></td>
</tr>
<tr id="A6.T12.3.19" class="ltx_tr">
<td id="A6.T12.3.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T12.3.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T12.3.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T12.3.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">65.49</td>
<td id="A6.T12.3.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T12.3.19.4.1" class="ltx_text ltx_font_bold">1.46</span></td>
</tr>
</table>
</figure>
<div id="A6.p7" class="ltx_para">
<p id="A6.p7.1" class="ltx_p">In <a href="#A6.T13" title="Table 13 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></span></a> and <a href="#A6.T13" title="Table 13 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></span></a> we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and <span id="A6.p7.1.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>, while <span id="A6.p7.1.2" class="ltx_text">MESAS</span> still erases the backdoor with only two FPs.</p>
</div>
<figure id="A6.T13" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T13.7.2.1" class="ltx_text" style="font-size:90%;">Table 13</span>. </span><span id="A6.T13.2.1" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario for <span id="A6.T13.2.1.1" class="ltx_text">1-class</span> <span id="A6.T13.2.1.2" class="ltx_text">non-IID</span> with <math id="A6.T13.2.1.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="A6.T13.2.1.m1.1b"><mrow id="A6.T13.2.1.m1.1.1" xref="A6.T13.2.1.m1.1.1.cmml"><mi id="A6.T13.2.1.m1.1.1.2" xref="A6.T13.2.1.m1.1.1.2.cmml">q</mi><mo id="A6.T13.2.1.m1.1.1.1" xref="A6.T13.2.1.m1.1.1.1.cmml">=</mo><mn id="A6.T13.2.1.m1.1.1.3" xref="A6.T13.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T13.2.1.m1.1c"><apply id="A6.T13.2.1.m1.1.1.cmml" xref="A6.T13.2.1.m1.1.1"><eq id="A6.T13.2.1.m1.1.1.1.cmml" xref="A6.T13.2.1.m1.1.1.1"></eq><ci id="A6.T13.2.1.m1.1.1.2.cmml" xref="A6.T13.2.1.m1.1.1.2">𝑞</ci><cn type="float" id="A6.T13.2.1.m1.1.1.3.cmml" xref="A6.T13.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T13.2.1.m1.1d">q=0.5</annotation></semantics></math>, adaption to benign values regarding the Cosine distance to the global model in percent.</span></figcaption>
<table id="A6.T13.3" class="ltx_tabular ltx_align_middle">
<tr id="A6.T13.3.2" class="ltx_tr">
<td id="A6.T13.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T13.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T13.3.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T13.3.1" class="ltx_tr">
<td id="A6.T13.3.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T13.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T13.3.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T13.3.1.1.m1.1a"><msup id="A6.T13.3.1.1.m1.1.1" xref="A6.T13.3.1.1.m1.1.1.cmml"><mi id="A6.T13.3.1.1.m1.1.1.2" xref="A6.T13.3.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T13.3.1.1.m1.1.1.3" xref="A6.T13.3.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T13.3.1.1.m1.1b"><apply id="A6.T13.3.1.1.m1.1.1.cmml" xref="A6.T13.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T13.3.1.1.m1.1.1.1.cmml" xref="A6.T13.3.1.1.m1.1.1">superscript</csymbol><ci id="A6.T13.3.1.1.m1.1.1.2.cmml" xref="A6.T13.3.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T13.3.1.1.m1.1.1.3.cmml" xref="A6.T13.3.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T13.3.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T13.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T13.3.1.4" class="ltx_td ltx_align_center ltx_border_t">1.93</td>
</tr>
<tr id="A6.T13.3.3" class="ltx_tr">
<td id="A6.T13.3.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T13.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T13.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.15</td>
<td id="A6.T13.3.3.4" class="ltx_td ltx_align_center ltx_border_t">6.82</td>
</tr>
<tr id="A6.T13.3.4" class="ltx_tr">
<td id="A6.T13.3.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T13.3.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T13.3.4.3" class="ltx_td ltx_align_center ltx_border_r">61.27</td>
<td id="A6.T13.3.4.4" class="ltx_td ltx_align_center">78.68</td>
</tr>
<tr id="A6.T13.3.5" class="ltx_tr">
<td id="A6.T13.3.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T13.3.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T13.3.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T13.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="A6.T13.3.5.4" class="ltx_td ltx_align_center ltx_border_t">1.40</td>
</tr>
<tr id="A6.T13.3.6" class="ltx_tr">
<td id="A6.T13.3.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T13.3.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T13.3.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T13.3.6.3" class="ltx_td ltx_align_center ltx_border_r">70.12</td>
<td id="A6.T13.3.6.4" class="ltx_td ltx_align_center">78.05</td>
</tr>
<tr id="A6.T13.3.7" class="ltx_tr">
<td id="A6.T13.3.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T13.3.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T13.3.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T13.3.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66.70</td>
<td id="A6.T13.3.7.4" class="ltx_td ltx_align_center ltx_border_t">23.35</td>
</tr>
<tr id="A6.T13.3.8" class="ltx_tr">
<td id="A6.T13.3.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T13.3.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T13.3.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T13.3.9" class="ltx_tr">
<td id="A6.T13.3.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T13.3.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T13.3.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="A6.T13.3.9.4" class="ltx_td ltx_align_center ltx_border_t">1.40</td>
</tr>
<tr id="A6.T13.3.10" class="ltx_tr">
<td id="A6.T13.3.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T13.3.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T13.3.10.3" class="ltx_td ltx_align_center ltx_border_r">65.79</td>
<td id="A6.T13.3.10.4" class="ltx_td ltx_align_center">1.58</td>
</tr>
<tr id="A6.T13.3.11" class="ltx_tr">
<td id="A6.T13.3.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T13.3.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T13.3.11.3" class="ltx_td ltx_align_center ltx_border_r">63.26</td>
<td id="A6.T13.3.11.4" class="ltx_td ltx_align_center">69.94</td>
</tr>
<tr id="A6.T13.3.12" class="ltx_tr">
<td id="A6.T13.3.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T13.3.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T13.3.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T13.3.12.3" class="ltx_td ltx_align_center ltx_border_r">68.45</td>
<td id="A6.T13.3.12.4" class="ltx_td ltx_align_center">79.21</td>
</tr>
<tr id="A6.T13.3.13" class="ltx_tr">
<td id="A6.T13.3.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T13.3.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T13.3.13.3" class="ltx_td ltx_align_center ltx_border_r">66.79</td>
<td id="A6.T13.3.13.4" class="ltx_td ltx_align_center">24.16</td>
</tr>
<tr id="A6.T13.3.14" class="ltx_tr">
<td id="A6.T13.3.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T13.3.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T13.3.14.3" class="ltx_td ltx_align_center ltx_border_r">56.22</td>
<td id="A6.T13.3.14.4" class="ltx_td ltx_align_center">25.71</td>
</tr>
<tr id="A6.T13.3.15" class="ltx_tr">
<td id="A6.T13.3.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T13.3.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T13.3.15.3" class="ltx_td ltx_align_center ltx_border_r">64.12</td>
<td id="A6.T13.3.15.4" class="ltx_td ltx_align_center">27.76</td>
</tr>
<tr id="A6.T13.3.16" class="ltx_tr">
<td id="A6.T13.3.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T13.3.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T13.3.16.3" class="ltx_td ltx_align_center ltx_border_r">65.96</td>
<td id="A6.T13.3.16.4" class="ltx_td ltx_align_center">27.62</td>
</tr>
<tr id="A6.T13.3.17" class="ltx_tr">
<td id="A6.T13.3.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T13.3.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T13.3.17.3" class="ltx_td ltx_align_center ltx_border_r">51.60</td>
<td id="A6.T13.3.17.4" class="ltx_td ltx_align_center">40.07</td>
</tr>
<tr id="A6.T13.3.18" class="ltx_tr">
<td id="A6.T13.3.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T13.3.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T13.3.18.3" class="ltx_td ltx_align_center ltx_border_r">63.57</td>
<td id="A6.T13.3.18.4" class="ltx_td ltx_align_center"><span id="A6.T13.3.18.4.1" class="ltx_text ltx_font_bold">18.75</span></td>
</tr>
<tr id="A6.T13.3.19" class="ltx_tr">
<td id="A6.T13.3.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T13.3.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T13.3.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T13.3.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">66.47</td>
<td id="A6.T13.3.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T13.3.19.4.1" class="ltx_text ltx_font_bold">1.45</span></td>
</tr>
</table>
</figure>
<figure id="A6.T14" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T14.7.2.1" class="ltx_text" style="font-size:90%;">Table 14</span>. </span><span id="A6.T14.2.1" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario for <span id="A6.T14.2.1.1" class="ltx_text">1-class</span> <span id="A6.T14.2.1.2" class="ltx_text">non-IID</span> with <math id="A6.T14.2.1.m1.1" class="ltx_Math" alttext="q=0.5" display="inline"><semantics id="A6.T14.2.1.m1.1b"><mrow id="A6.T14.2.1.m1.1.1" xref="A6.T14.2.1.m1.1.1.cmml"><mi id="A6.T14.2.1.m1.1.1.2" xref="A6.T14.2.1.m1.1.1.2.cmml">q</mi><mo id="A6.T14.2.1.m1.1.1.1" xref="A6.T14.2.1.m1.1.1.1.cmml">=</mo><mn id="A6.T14.2.1.m1.1.1.3" xref="A6.T14.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.T14.2.1.m1.1c"><apply id="A6.T14.2.1.m1.1.1.cmml" xref="A6.T14.2.1.m1.1.1"><eq id="A6.T14.2.1.m1.1.1.1.cmml" xref="A6.T14.2.1.m1.1.1.1"></eq><ci id="A6.T14.2.1.m1.1.1.2.cmml" xref="A6.T14.2.1.m1.1.1.2">𝑞</ci><cn type="float" id="A6.T14.2.1.m1.1.1.3.cmml" xref="A6.T14.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T14.2.1.m1.1d">q=0.5</annotation></semantics></math>, adaption to benign values regarding the Cosine distance to the global model and scaled poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T14.3" class="ltx_tabular ltx_align_middle">
<tr id="A6.T14.3.2" class="ltx_tr">
<td id="A6.T14.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T14.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T14.3.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T14.3.1" class="ltx_tr">
<td id="A6.T14.3.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T14.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T14.3.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T14.3.1.1.m1.1a"><msup id="A6.T14.3.1.1.m1.1.1" xref="A6.T14.3.1.1.m1.1.1.cmml"><mi id="A6.T14.3.1.1.m1.1.1.2" xref="A6.T14.3.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T14.3.1.1.m1.1.1.3" xref="A6.T14.3.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T14.3.1.1.m1.1b"><apply id="A6.T14.3.1.1.m1.1.1.cmml" xref="A6.T14.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T14.3.1.1.m1.1.1.1.cmml" xref="A6.T14.3.1.1.m1.1.1">superscript</csymbol><ci id="A6.T14.3.1.1.m1.1.1.2.cmml" xref="A6.T14.3.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T14.3.1.1.m1.1.1.3.cmml" xref="A6.T14.3.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T14.3.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T14.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.99</td>
<td id="A6.T14.3.1.4" class="ltx_td ltx_align_center ltx_border_t">1.93</td>
</tr>
<tr id="A6.T14.3.3" class="ltx_tr">
<td id="A6.T14.3.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T14.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T14.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.15</td>
<td id="A6.T14.3.3.4" class="ltx_td ltx_align_center ltx_border_t">6.82</td>
</tr>
<tr id="A6.T14.3.4" class="ltx_tr">
<td id="A6.T14.3.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T14.3.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T14.3.4.3" class="ltx_td ltx_align_center ltx_border_r">61.27</td>
<td id="A6.T14.3.4.4" class="ltx_td ltx_align_center">78.68</td>
</tr>
<tr id="A6.T14.3.5" class="ltx_tr">
<td id="A6.T14.3.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T14.3.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T14.3.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T14.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="A6.T14.3.5.4" class="ltx_td ltx_align_center ltx_border_t">1.40</td>
</tr>
<tr id="A6.T14.3.6" class="ltx_tr">
<td id="A6.T14.3.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T14.3.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T14.3.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T14.3.6.3" class="ltx_td ltx_align_center ltx_border_r">42.53</td>
<td id="A6.T14.3.6.4" class="ltx_td ltx_align_center">95.03</td>
</tr>
<tr id="A6.T14.3.7" class="ltx_tr">
<td id="A6.T14.3.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T14.3.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T14.3.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T14.3.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.38</td>
<td id="A6.T14.3.7.4" class="ltx_td ltx_align_center ltx_border_t">55.28</td>
</tr>
<tr id="A6.T14.3.8" class="ltx_tr">
<td id="A6.T14.3.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T14.3.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T14.3.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T14.3.9" class="ltx_tr">
<td id="A6.T14.3.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T14.3.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T14.3.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.92</td>
<td id="A6.T14.3.9.4" class="ltx_td ltx_align_center ltx_border_t">1.44</td>
</tr>
<tr id="A6.T14.3.10" class="ltx_tr">
<td id="A6.T14.3.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T14.3.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T14.3.10.3" class="ltx_td ltx_align_center ltx_border_r">64.86</td>
<td id="A6.T14.3.10.4" class="ltx_td ltx_align_center">1.75</td>
</tr>
<tr id="A6.T14.3.11" class="ltx_tr">
<td id="A6.T14.3.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T14.3.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T14.3.11.3" class="ltx_td ltx_align_center ltx_border_r">23.13</td>
<td id="A6.T14.3.11.4" class="ltx_td ltx_align_center">84.58</td>
</tr>
<tr id="A6.T14.3.12" class="ltx_tr">
<td id="A6.T14.3.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T14.3.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T14.3.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T14.3.12.3" class="ltx_td ltx_align_center ltx_border_r">35.39</td>
<td id="A6.T14.3.12.4" class="ltx_td ltx_align_center">90.44</td>
</tr>
<tr id="A6.T14.3.13" class="ltx_tr">
<td id="A6.T14.3.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T14.3.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T14.3.13.3" class="ltx_td ltx_align_center ltx_border_r">60.84</td>
<td id="A6.T14.3.13.4" class="ltx_td ltx_align_center">53.96</td>
</tr>
<tr id="A6.T14.3.14" class="ltx_tr">
<td id="A6.T14.3.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T14.3.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T14.3.14.3" class="ltx_td ltx_align_center ltx_border_r">40.94</td>
<td id="A6.T14.3.14.4" class="ltx_td ltx_align_center">80.35</td>
</tr>
<tr id="A6.T14.3.15" class="ltx_tr">
<td id="A6.T14.3.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T14.3.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T14.3.15.3" class="ltx_td ltx_align_center ltx_border_r">62.33</td>
<td id="A6.T14.3.15.4" class="ltx_td ltx_align_center">4.07</td>
</tr>
<tr id="A6.T14.3.16" class="ltx_tr">
<td id="A6.T14.3.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T14.3.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T14.3.16.3" class="ltx_td ltx_align_center ltx_border_r">58.91</td>
<td id="A6.T14.3.16.4" class="ltx_td ltx_align_center">57.82</td>
</tr>
<tr id="A6.T14.3.17" class="ltx_tr">
<td id="A6.T14.3.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T14.3.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T14.3.17.3" class="ltx_td ltx_align_center ltx_border_r">33.96</td>
<td id="A6.T14.3.17.4" class="ltx_td ltx_align_center">50.51</td>
</tr>
<tr id="A6.T14.3.18" class="ltx_tr">
<td id="A6.T14.3.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T14.3.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T14.3.18.3" class="ltx_td ltx_align_center ltx_border_r">59.83</td>
<td id="A6.T14.3.18.4" class="ltx_td ltx_align_center"><span id="A6.T14.3.18.4.1" class="ltx_text ltx_font_bold">21.46</span></td>
</tr>
<tr id="A6.T14.3.19" class="ltx_tr">
<td id="A6.T14.3.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T14.3.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T14.3.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T14.3.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">66.47</td>
<td id="A6.T14.3.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T14.3.19.4.1" class="ltx_text ltx_font_bold">1.45</span></td>
</tr>
</table>
</figure>
<div id="A6.p8" class="ltx_para">
<p id="A6.p8.1" class="ltx_p"><a href="#A6.T15" title="Table 15 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></span></a> and <a href="#A6.T16" title="Table 16 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></span></a> show the results in a <span id="A6.p8.1.1" class="ltx_text">inter-client</span> <span id="A6.p8.1.2" class="ltx_text">non-IID</span> scenario based on our <span id="A6.p8.1.3" class="ltx_text">Random-Non-IID</span> strategy for a model in FL round one and highlights, that <span id="A6.p8.1.4" class="ltx_text">MESAS</span> outperforms other defenses in reducing the BA of the new global model.
<a href="#A6.T17" title="Table 17 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></span></a> and <a href="#A6.T18" title="Table 18 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></span></a> show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, <span id="A6.p8.1.5" class="ltx_text">MESAS</span> is even more effective than other defenses and reduces the BA to a minimum.</p>
</div>
<figure id="A6.T15" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T15.6.1.1" class="ltx_text" style="font-size:90%;">Table 15</span>. </span><span id="A6.T15.7.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with <span id="A6.T15.7.2.1" class="ltx_text">inter-client</span> <span id="A6.T15.7.2.2" class="ltx_text">non-IID</span> based on our <span id="A6.T15.7.2.3" class="ltx_text">Random-Non-IID</span> strategy with a model in FL round one in percent.</span></figcaption>
<table id="A6.T15.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T15.1.2" class="ltx_tr">
<td id="A6.T15.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T15.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T15.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T15.1.1" class="ltx_tr">
<td id="A6.T15.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T15.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T15.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T15.1.1.1.m1.1a"><msup id="A6.T15.1.1.1.m1.1.1" xref="A6.T15.1.1.1.m1.1.1.cmml"><mi id="A6.T15.1.1.1.m1.1.1.2" xref="A6.T15.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T15.1.1.1.m1.1.1.3" xref="A6.T15.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T15.1.1.1.m1.1b"><apply id="A6.T15.1.1.1.m1.1.1.cmml" xref="A6.T15.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T15.1.1.1.m1.1.1.1.cmml" xref="A6.T15.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T15.1.1.1.m1.1.1.2.cmml" xref="A6.T15.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T15.1.1.1.m1.1.1.3.cmml" xref="A6.T15.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T15.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T15.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.52</td>
<td id="A6.T15.1.1.4" class="ltx_td ltx_align_center ltx_border_t">8.17</td>
</tr>
<tr id="A6.T15.1.3" class="ltx_tr">
<td id="A6.T15.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T15.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T15.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">35.05</td>
<td id="A6.T15.1.3.4" class="ltx_td ltx_align_center ltx_border_t">14.38</td>
</tr>
<tr id="A6.T15.1.4" class="ltx_tr">
<td id="A6.T15.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T15.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T15.1.4.3" class="ltx_td ltx_align_center ltx_border_r">34.29</td>
<td id="A6.T15.1.4.4" class="ltx_td ltx_align_center">82.94</td>
</tr>
<tr id="A6.T15.1.5" class="ltx_tr">
<td id="A6.T15.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T15.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T15.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T15.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.09</td>
<td id="A6.T15.1.5.4" class="ltx_td ltx_align_center ltx_border_t">37.97</td>
</tr>
<tr id="A6.T15.1.6" class="ltx_tr">
<td id="A6.T15.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T15.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T15.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T15.1.6.3" class="ltx_td ltx_align_center ltx_border_r">21.49</td>
<td id="A6.T15.1.6.4" class="ltx_td ltx_align_center">98.72</td>
</tr>
<tr id="A6.T15.1.7" class="ltx_tr">
<td id="A6.T15.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T15.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T15.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T15.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.57</td>
<td id="A6.T15.1.7.4" class="ltx_td ltx_align_center ltx_border_t">80.85</td>
</tr>
<tr id="A6.T15.1.8" class="ltx_tr">
<td id="A6.T15.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T15.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T15.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T15.1.9" class="ltx_tr">
<td id="A6.T15.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T15.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T15.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.68</td>
<td id="A6.T15.1.9.4" class="ltx_td ltx_align_center ltx_border_t">54.84</td>
</tr>
<tr id="A6.T15.1.10" class="ltx_tr">
<td id="A6.T15.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T15.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T15.1.10.3" class="ltx_td ltx_align_center ltx_border_r">30.14</td>
<td id="A6.T15.1.10.4" class="ltx_td ltx_align_center">87.66</td>
</tr>
<tr id="A6.T15.1.11" class="ltx_tr">
<td id="A6.T15.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T15.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T15.1.11.3" class="ltx_td ltx_align_center ltx_border_r">19.28</td>
<td id="A6.T15.1.11.4" class="ltx_td ltx_align_center">80.82</td>
</tr>
<tr id="A6.T15.1.12" class="ltx_tr">
<td id="A6.T15.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T15.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T15.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T15.1.12.3" class="ltx_td ltx_align_center ltx_border_r">10.05</td>
<td id="A6.T15.1.12.4" class="ltx_td ltx_align_center">99.96</td>
</tr>
<tr id="A6.T15.1.13" class="ltx_tr">
<td id="A6.T15.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T15.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T15.1.13.3" class="ltx_td ltx_align_center ltx_border_r">32.88</td>
<td id="A6.T15.1.13.4" class="ltx_td ltx_align_center">79.82</td>
</tr>
<tr id="A6.T15.1.14" class="ltx_tr">
<td id="A6.T15.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T15.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T15.1.14.3" class="ltx_td ltx_align_center ltx_border_r">25.63</td>
<td id="A6.T15.1.14.4" class="ltx_td ltx_align_center">88.33</td>
</tr>
<tr id="A6.T15.1.15" class="ltx_tr">
<td id="A6.T15.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T15.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T15.1.15.3" class="ltx_td ltx_align_center ltx_border_r">10.23</td>
<td id="A6.T15.1.15.4" class="ltx_td ltx_align_center">99.66</td>
</tr>
<tr id="A6.T15.1.16" class="ltx_tr">
<td id="A6.T15.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T15.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T15.1.16.3" class="ltx_td ltx_align_center ltx_border_r">33.21</td>
<td id="A6.T15.1.16.4" class="ltx_td ltx_align_center">76.28</td>
</tr>
<tr id="A6.T15.1.17" class="ltx_tr">
<td id="A6.T15.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T15.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T15.1.17.3" class="ltx_td ltx_align_center ltx_border_r">21.10</td>
<td id="A6.T15.1.17.4" class="ltx_td ltx_align_center">62.05</td>
</tr>
<tr id="A6.T15.1.18" class="ltx_tr">
<td id="A6.T15.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T15.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T15.1.18.3" class="ltx_td ltx_align_center ltx_border_r">57.27</td>
<td id="A6.T15.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T15.1.18.4.1" class="ltx_text ltx_font_bold">23.02</span></td>
</tr>
<tr id="A6.T15.1.19" class="ltx_tr">
<td id="A6.T15.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T15.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T15.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T15.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">35.08</td>
<td id="A6.T15.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T15.1.19.4.1" class="ltx_text ltx_font_bold">41.64</span></td>
</tr>
</table>
</figure>
<figure id="A6.T16" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T16.6.1.1" class="ltx_text" style="font-size:90%;">Table 16</span>. </span><span id="A6.T16.7.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with <span id="A6.T16.7.2.1" class="ltx_text">inter-client</span> <span id="A6.T16.7.2.2" class="ltx_text">non-IID</span> based on our <span id="A6.T16.7.2.3" class="ltx_text">Random-Non-IID</span> strategy with a model in FL round one and scaled
poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T16.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T16.1.2" class="ltx_tr">
<td id="A6.T16.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T16.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T16.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T16.1.1" class="ltx_tr">
<td id="A6.T16.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T16.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T16.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T16.1.1.1.m1.1a"><msup id="A6.T16.1.1.1.m1.1.1" xref="A6.T16.1.1.1.m1.1.1.cmml"><mi id="A6.T16.1.1.1.m1.1.1.2" xref="A6.T16.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T16.1.1.1.m1.1.1.3" xref="A6.T16.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T16.1.1.1.m1.1b"><apply id="A6.T16.1.1.1.m1.1.1.cmml" xref="A6.T16.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T16.1.1.1.m1.1.1.1.cmml" xref="A6.T16.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T16.1.1.1.m1.1.1.2.cmml" xref="A6.T16.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T16.1.1.1.m1.1.1.3.cmml" xref="A6.T16.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T16.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T16.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.52</td>
<td id="A6.T16.1.1.4" class="ltx_td ltx_align_center ltx_border_t">8.17</td>
</tr>
<tr id="A6.T16.1.3" class="ltx_tr">
<td id="A6.T16.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T16.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T16.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">35.05</td>
<td id="A6.T16.1.3.4" class="ltx_td ltx_align_center ltx_border_t">14.38</td>
</tr>
<tr id="A6.T16.1.4" class="ltx_tr">
<td id="A6.T16.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T16.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T16.1.4.3" class="ltx_td ltx_align_center ltx_border_r">34.29</td>
<td id="A6.T16.1.4.4" class="ltx_td ltx_align_center">82.94</td>
</tr>
<tr id="A6.T16.1.5" class="ltx_tr">
<td id="A6.T16.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T16.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T16.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T16.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.09</td>
<td id="A6.T16.1.5.4" class="ltx_td ltx_align_center ltx_border_t">37.97</td>
</tr>
<tr id="A6.T16.1.6" class="ltx_tr">
<td id="A6.T16.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T16.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T16.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T16.1.6.3" class="ltx_td ltx_align_center ltx_border_r">17.38</td>
<td id="A6.T16.1.6.4" class="ltx_td ltx_align_center">99.24</td>
</tr>
<tr id="A6.T16.1.7" class="ltx_tr">
<td id="A6.T16.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T16.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T16.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T16.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30.19</td>
<td id="A6.T16.1.7.4" class="ltx_td ltx_align_center ltx_border_t">85.41</td>
</tr>
<tr id="A6.T16.1.8" class="ltx_tr">
<td id="A6.T16.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T16.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T16.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T16.1.9" class="ltx_tr">
<td id="A6.T16.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T16.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T16.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.59</td>
<td id="A6.T16.1.9.4" class="ltx_td ltx_align_center ltx_border_t">56.90</td>
</tr>
<tr id="A6.T16.1.10" class="ltx_tr">
<td id="A6.T16.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T16.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T16.1.10.3" class="ltx_td ltx_align_center ltx_border_r">26.93</td>
<td id="A6.T16.1.10.4" class="ltx_td ltx_align_center">92.20</td>
</tr>
<tr id="A6.T16.1.11" class="ltx_tr">
<td id="A6.T16.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T16.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T16.1.11.3" class="ltx_td ltx_align_center ltx_border_r">24.27</td>
<td id="A6.T16.1.11.4" class="ltx_td ltx_align_center">38.53</td>
</tr>
<tr id="A6.T16.1.12" class="ltx_tr">
<td id="A6.T16.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T16.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T16.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T16.1.12.3" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A6.T16.1.12.4" class="ltx_td ltx_align_center">100.00</td>
</tr>
<tr id="A6.T16.1.13" class="ltx_tr">
<td id="A6.T16.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T16.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T16.1.13.3" class="ltx_td ltx_align_center ltx_border_r">30.61</td>
<td id="A6.T16.1.13.4" class="ltx_td ltx_align_center">84.32</td>
</tr>
<tr id="A6.T16.1.14" class="ltx_tr">
<td id="A6.T16.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T16.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T16.1.14.3" class="ltx_td ltx_align_center ltx_border_r">23.47</td>
<td id="A6.T16.1.14.4" class="ltx_td ltx_align_center">94.51</td>
</tr>
<tr id="A6.T16.1.15" class="ltx_tr">
<td id="A6.T16.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T16.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T16.1.15.3" class="ltx_td ltx_align_center ltx_border_r">17.16</td>
<td id="A6.T16.1.15.4" class="ltx_td ltx_align_center">36.53</td>
</tr>
<tr id="A6.T16.1.16" class="ltx_tr">
<td id="A6.T16.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T16.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T16.1.16.3" class="ltx_td ltx_align_center ltx_border_r">31.89</td>
<td id="A6.T16.1.16.4" class="ltx_td ltx_align_center">78.20</td>
</tr>
<tr id="A6.T16.1.17" class="ltx_tr">
<td id="A6.T16.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T16.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T16.1.17.3" class="ltx_td ltx_align_center ltx_border_r">20.38</td>
<td id="A6.T16.1.17.4" class="ltx_td ltx_align_center">60.84</td>
</tr>
<tr id="A6.T16.1.18" class="ltx_tr">
<td id="A6.T16.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T16.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T16.1.18.3" class="ltx_td ltx_align_center ltx_border_r">57.02</td>
<td id="A6.T16.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T16.1.18.4.1" class="ltx_text ltx_font_bold">23.05</span></td>
</tr>
<tr id="A6.T16.1.19" class="ltx_tr">
<td id="A6.T16.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T16.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T16.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T16.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">47.29</td>
<td id="A6.T16.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T16.1.19.4.1" class="ltx_text ltx_font_bold">15.58</span></td>
</tr>
</table>
</figure>
<figure id="A6.T17" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T17.6.1.1" class="ltx_text" style="font-size:90%;">Table 17</span>. </span><span id="A6.T17.7.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with <span id="A6.T17.7.2.1" class="ltx_text">inter-client</span> <span id="A6.T17.7.2.2" class="ltx_text">non-IID</span> based on our <span id="A6.T17.7.2.3" class="ltx_text">Random-Non-IID</span> strategy with 100 clients in the federation in percent.</span></figcaption>
<table id="A6.T17.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T17.1.2" class="ltx_tr">
<td id="A6.T17.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T17.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T17.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T17.1.1" class="ltx_tr">
<td id="A6.T17.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T17.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T17.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T17.1.1.1.m1.1a"><msup id="A6.T17.1.1.1.m1.1.1" xref="A6.T17.1.1.1.m1.1.1.cmml"><mi id="A6.T17.1.1.1.m1.1.1.2" xref="A6.T17.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T17.1.1.1.m1.1.1.3" xref="A6.T17.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T17.1.1.1.m1.1b"><apply id="A6.T17.1.1.1.m1.1.1.cmml" xref="A6.T17.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T17.1.1.1.m1.1.1.1.cmml" xref="A6.T17.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T17.1.1.1.m1.1.1.2.cmml" xref="A6.T17.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T17.1.1.1.m1.1.1.3.cmml" xref="A6.T17.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T17.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T17.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.26</td>
<td id="A6.T17.1.1.4" class="ltx_td ltx_align_center ltx_border_t">9.54</td>
</tr>
<tr id="A6.T17.1.3" class="ltx_tr">
<td id="A6.T17.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T17.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T17.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.44</td>
<td id="A6.T17.1.3.4" class="ltx_td ltx_align_center ltx_border_t">11.53</td>
</tr>
<tr id="A6.T17.1.4" class="ltx_tr">
<td id="A6.T17.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T17.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T17.1.4.3" class="ltx_td ltx_align_center ltx_border_r">34.51</td>
<td id="A6.T17.1.4.4" class="ltx_td ltx_align_center">83.70</td>
</tr>
<tr id="A6.T17.1.5" class="ltx_tr">
<td id="A6.T17.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T17.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T17.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T17.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.47</td>
<td id="A6.T17.1.5.4" class="ltx_td ltx_align_center ltx_border_t">15.14</td>
</tr>
<tr id="A6.T17.1.6" class="ltx_tr">
<td id="A6.T17.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T17.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T17.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T17.1.6.3" class="ltx_td ltx_align_center ltx_border_r">37.07</td>
<td id="A6.T17.1.6.4" class="ltx_td ltx_align_center">88.38</td>
</tr>
<tr id="A6.T17.1.7" class="ltx_tr">
<td id="A6.T17.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T17.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T17.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T17.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.00</td>
<td id="A6.T17.1.7.4" class="ltx_td ltx_align_center ltx_border_t">70.58</td>
</tr>
<tr id="A6.T17.1.8" class="ltx_tr">
<td id="A6.T17.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T17.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T17.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T17.1.9" class="ltx_tr">
<td id="A6.T17.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T17.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T17.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.81</td>
<td id="A6.T17.1.9.4" class="ltx_td ltx_align_center ltx_border_t">48.08</td>
</tr>
<tr id="A6.T17.1.10" class="ltx_tr">
<td id="A6.T17.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T17.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T17.1.10.3" class="ltx_td ltx_align_center ltx_border_r">51.16</td>
<td id="A6.T17.1.10.4" class="ltx_td ltx_align_center">74.58</td>
</tr>
<tr id="A6.T17.1.11" class="ltx_tr">
<td id="A6.T17.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T17.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T17.1.11.3" class="ltx_td ltx_align_center ltx_border_r">17.21</td>
<td id="A6.T17.1.11.4" class="ltx_td ltx_align_center">88.17</td>
</tr>
<tr id="A6.T17.1.12" class="ltx_tr">
<td id="A6.T17.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T17.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T17.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T17.1.12.3" class="ltx_td ltx_align_center ltx_border_r">18.16</td>
<td id="A6.T17.1.12.4" class="ltx_td ltx_align_center">93.85</td>
</tr>
<tr id="A6.T17.1.13" class="ltx_tr">
<td id="A6.T17.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T17.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T17.1.13.3" class="ltx_td ltx_align_center ltx_border_r">46.16</td>
<td id="A6.T17.1.13.4" class="ltx_td ltx_align_center">67.88</td>
</tr>
<tr id="A6.T17.1.14" class="ltx_tr">
<td id="A6.T17.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T17.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T17.1.14.3" class="ltx_td ltx_align_center ltx_border_r">26.36</td>
<td id="A6.T17.1.14.4" class="ltx_td ltx_align_center">77.95</td>
</tr>
<tr id="A6.T17.1.15" class="ltx_tr">
<td id="A6.T17.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T17.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T17.1.15.3" class="ltx_td ltx_align_center ltx_border_r">22.38</td>
<td id="A6.T17.1.15.4" class="ltx_td ltx_align_center">91.66</td>
</tr>
<tr id="A6.T17.1.16" class="ltx_tr">
<td id="A6.T17.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T17.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T17.1.16.3" class="ltx_td ltx_align_center ltx_border_r">46.29</td>
<td id="A6.T17.1.16.4" class="ltx_td ltx_align_center">67.70</td>
</tr>
<tr id="A6.T17.1.17" class="ltx_tr">
<td id="A6.T17.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T17.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T17.1.17.3" class="ltx_td ltx_align_center ltx_border_r">22.60</td>
<td id="A6.T17.1.17.4" class="ltx_td ltx_align_center">51.86</td>
</tr>
<tr id="A6.T17.1.18" class="ltx_tr">
<td id="A6.T17.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T17.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T17.1.18.3" class="ltx_td ltx_align_center ltx_border_r">47.00</td>
<td id="A6.T17.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T17.1.18.4.1" class="ltx_text ltx_font_bold">24.26</span></td>
</tr>
<tr id="A6.T17.1.19" class="ltx_tr">
<td id="A6.T17.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T17.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T17.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T17.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">40.95</td>
<td id="A6.T17.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T17.1.19.4.1" class="ltx_text ltx_font_bold">2.00</span></td>
</tr>
</table>
</figure>
<figure id="A6.T18" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T18.6.1.1" class="ltx_text" style="font-size:90%;">Table 18</span>. </span><span id="A6.T18.7.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with <span id="A6.T18.7.2.1" class="ltx_text">inter-client</span> <span id="A6.T18.7.2.2" class="ltx_text">non-IID</span> based on our <span id="A6.T18.7.2.3" class="ltx_text">Random-Non-IID</span> strategy with 100 clients in the federation and scaled
poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T18.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T18.1.2" class="ltx_tr">
<td id="A6.T18.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T18.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T18.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T18.1.1" class="ltx_tr">
<td id="A6.T18.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T18.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T18.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T18.1.1.1.m1.1a"><msup id="A6.T18.1.1.1.m1.1.1" xref="A6.T18.1.1.1.m1.1.1.cmml"><mi id="A6.T18.1.1.1.m1.1.1.2" xref="A6.T18.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T18.1.1.1.m1.1.1.3" xref="A6.T18.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T18.1.1.1.m1.1b"><apply id="A6.T18.1.1.1.m1.1.1.cmml" xref="A6.T18.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T18.1.1.1.m1.1.1.1.cmml" xref="A6.T18.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T18.1.1.1.m1.1.1.2.cmml" xref="A6.T18.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T18.1.1.1.m1.1.1.3.cmml" xref="A6.T18.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T18.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T18.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.26</td>
<td id="A6.T18.1.1.4" class="ltx_td ltx_align_center ltx_border_t">9.54</td>
</tr>
<tr id="A6.T18.1.3" class="ltx_tr">
<td id="A6.T18.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T18.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T18.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.44</td>
<td id="A6.T18.1.3.4" class="ltx_td ltx_align_center ltx_border_t">11.53</td>
</tr>
<tr id="A6.T18.1.4" class="ltx_tr">
<td id="A6.T18.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T18.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T18.1.4.3" class="ltx_td ltx_align_center ltx_border_r">34.51</td>
<td id="A6.T18.1.4.4" class="ltx_td ltx_align_center">83.70</td>
</tr>
<tr id="A6.T18.1.5" class="ltx_tr">
<td id="A6.T18.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T18.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T18.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T18.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.47</td>
<td id="A6.T18.1.5.4" class="ltx_td ltx_align_center ltx_border_t">15.14</td>
</tr>
<tr id="A6.T18.1.6" class="ltx_tr">
<td id="A6.T18.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T18.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T18.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T18.1.6.3" class="ltx_td ltx_align_center ltx_border_r">21.92</td>
<td id="A6.T18.1.6.4" class="ltx_td ltx_align_center">95.46</td>
</tr>
<tr id="A6.T18.1.7" class="ltx_tr">
<td id="A6.T18.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T18.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T18.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T18.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">35.14</td>
<td id="A6.T18.1.7.4" class="ltx_td ltx_align_center ltx_border_t">87.10</td>
</tr>
<tr id="A6.T18.1.8" class="ltx_tr">
<td id="A6.T18.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T18.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T18.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T18.1.9" class="ltx_tr">
<td id="A6.T18.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T18.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T18.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.41</td>
<td id="A6.T18.1.9.4" class="ltx_td ltx_align_center ltx_border_t">92.11</td>
</tr>
<tr id="A6.T18.1.10" class="ltx_tr">
<td id="A6.T18.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T18.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T18.1.10.3" class="ltx_td ltx_align_center ltx_border_r">37.38</td>
<td id="A6.T18.1.10.4" class="ltx_td ltx_align_center">91.50</td>
</tr>
<tr id="A6.T18.1.11" class="ltx_tr">
<td id="A6.T18.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T18.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T18.1.11.3" class="ltx_td ltx_align_center ltx_border_r">23.44</td>
<td id="A6.T18.1.11.4" class="ltx_td ltx_align_center">33.20</td>
</tr>
<tr id="A6.T18.1.12" class="ltx_tr">
<td id="A6.T18.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T18.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T18.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T18.1.12.3" class="ltx_td ltx_align_center ltx_border_r">19.64</td>
<td id="A6.T18.1.12.4" class="ltx_td ltx_align_center">73.38</td>
</tr>
<tr id="A6.T18.1.13" class="ltx_tr">
<td id="A6.T18.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T18.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T18.1.13.3" class="ltx_td ltx_align_center ltx_border_r">35.65</td>
<td id="A6.T18.1.13.4" class="ltx_td ltx_align_center">86.22</td>
</tr>
<tr id="A6.T18.1.14" class="ltx_tr">
<td id="A6.T18.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T18.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T18.1.14.3" class="ltx_td ltx_align_center ltx_border_r">25.07</td>
<td id="A6.T18.1.14.4" class="ltx_td ltx_align_center">95.75</td>
</tr>
<tr id="A6.T18.1.15" class="ltx_tr">
<td id="A6.T18.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T18.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T18.1.15.3" class="ltx_td ltx_align_center ltx_border_r">10.00</td>
<td id="A6.T18.1.15.4" class="ltx_td ltx_align_center">100.00</td>
</tr>
<tr id="A6.T18.1.16" class="ltx_tr">
<td id="A6.T18.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T18.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T18.1.16.3" class="ltx_td ltx_align_center ltx_border_r">41.72</td>
<td id="A6.T18.1.16.4" class="ltx_td ltx_align_center">76.07</td>
</tr>
<tr id="A6.T18.1.17" class="ltx_tr">
<td id="A6.T18.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T18.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T18.1.17.3" class="ltx_td ltx_align_center ltx_border_r">20.13</td>
<td id="A6.T18.1.17.4" class="ltx_td ltx_align_center">54.57</td>
</tr>
<tr id="A6.T18.1.18" class="ltx_tr">
<td id="A6.T18.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T18.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T18.1.18.3" class="ltx_td ltx_align_center ltx_border_r">49.16</td>
<td id="A6.T18.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T18.1.18.4.1" class="ltx_text ltx_font_bold">25.30</span></td>
</tr>
<tr id="A6.T18.1.19" class="ltx_tr">
<td id="A6.T18.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T18.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T18.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T18.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">46.70</td>
<td id="A6.T18.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T18.1.19.4.1" class="ltx_text ltx_font_bold">0.08</span></td>
</tr>
</table>
</figure>
<div id="A6.p9" class="ltx_para">
<p id="A6.p9.1" class="ltx_p"><a href="#A6.T19" title="Table 19 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></span></a> and <a href="#A6.T20" title="Table 20 ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">20</span></span></a> show the experiments results with a CNN training on MNIST <cite class="ltx_cite ltx_citemacro_citep">(Deng, <a href="#bib.bib24" title="" class="ltx_ref">2012</a>)</cite> and SqueezeNet <cite class="ltx_cite ltx_citemacro_citep">(Iandola et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2016</a>)</cite> training on <span id="A6.p9.1.1" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite>. The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU <cite class="ltx_cite ltx_citemacro_citep">(Agarap, <a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite> and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a <span id="A6.p9.1.2" class="ltx_text">self-pre-trained</span> model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of <span id="A6.p9.1.3" class="ltx_text">MESAS</span>. Other defenses instead can be circumvented by the adaptive adversary.</p>
</div>
<figure id="A6.T19" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T19.3.1.1" class="ltx_text" style="font-size:90%;">Table 19</span>. </span><span id="A6.T19.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with a CNN trained on MNIST <cite class="ltx_cite ltx_citemacro_citep">(Deng, <a href="#bib.bib24" title="" class="ltx_ref">2012</a>)</cite> with a PDR of 0.3 in percent.</span></figcaption>
<table id="A6.T19.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T19.1.2" class="ltx_tr">
<td id="A6.T19.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T19.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T19.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T19.1.1" class="ltx_tr">
<td id="A6.T19.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T19.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T19.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T19.1.1.1.m1.1a"><msup id="A6.T19.1.1.1.m1.1.1" xref="A6.T19.1.1.1.m1.1.1.cmml"><mi id="A6.T19.1.1.1.m1.1.1.2" xref="A6.T19.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T19.1.1.1.m1.1.1.3" xref="A6.T19.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T19.1.1.1.m1.1b"><apply id="A6.T19.1.1.1.m1.1.1.cmml" xref="A6.T19.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T19.1.1.1.m1.1.1.1.cmml" xref="A6.T19.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T19.1.1.1.m1.1.1.2.cmml" xref="A6.T19.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T19.1.1.1.m1.1.1.3.cmml" xref="A6.T19.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T19.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T19.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.74</td>
<td id="A6.T19.1.1.4" class="ltx_td ltx_align_center ltx_border_t">2.05</td>
</tr>
<tr id="A6.T19.1.3" class="ltx_tr">
<td id="A6.T19.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T19.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T19.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">84.87</td>
<td id="A6.T19.1.3.4" class="ltx_td ltx_align_center ltx_border_t">0.57</td>
</tr>
<tr id="A6.T19.1.4" class="ltx_tr">
<td id="A6.T19.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T19.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T19.1.4.3" class="ltx_td ltx_align_center ltx_border_r">60.73</td>
<td id="A6.T19.1.4.4" class="ltx_td ltx_align_center">39.59</td>
</tr>
<tr id="A6.T19.1.5" class="ltx_tr">
<td id="A6.T19.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T19.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T19.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T19.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.51</td>
<td id="A6.T19.1.5.4" class="ltx_td ltx_align_center ltx_border_t">0.54</td>
</tr>
<tr id="A6.T19.1.6" class="ltx_tr">
<td id="A6.T19.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T19.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T19.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T19.1.6.3" class="ltx_td ltx_align_center ltx_border_r">63.04</td>
<td id="A6.T19.1.6.4" class="ltx_td ltx_align_center">37.77</td>
</tr>
<tr id="A6.T19.1.7" class="ltx_tr">
<td id="A6.T19.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T19.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T19.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T19.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.31</td>
<td id="A6.T19.1.7.4" class="ltx_td ltx_align_center ltx_border_t">2.35</td>
</tr>
<tr id="A6.T19.1.8" class="ltx_tr">
<td id="A6.T19.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T19.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T19.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T19.1.9" class="ltx_tr">
<td id="A6.T19.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T19.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T19.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.51</td>
<td id="A6.T19.1.9.4" class="ltx_td ltx_align_center ltx_border_t">0.54</td>
</tr>
<tr id="A6.T19.1.10" class="ltx_tr">
<td id="A6.T19.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T19.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T19.1.10.3" class="ltx_td ltx_align_center ltx_border_r">85.31</td>
<td id="A6.T19.1.10.4" class="ltx_td ltx_align_center">2.35</td>
</tr>
<tr id="A6.T19.1.11" class="ltx_tr">
<td id="A6.T19.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T19.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T19.1.11.3" class="ltx_td ltx_align_center ltx_border_r">83.79</td>
<td id="A6.T19.1.11.4" class="ltx_td ltx_align_center">0.51</td>
</tr>
<tr id="A6.T19.1.12" class="ltx_tr">
<td id="A6.T19.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T19.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T19.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T19.1.12.3" class="ltx_td ltx_align_center ltx_border_r">86.45</td>
<td id="A6.T19.1.12.4" class="ltx_td ltx_align_center">0.59</td>
</tr>
<tr id="A6.T19.1.13" class="ltx_tr">
<td id="A6.T19.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T19.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T19.1.13.3" class="ltx_td ltx_align_center ltx_border_r">85.13</td>
<td id="A6.T19.1.13.4" class="ltx_td ltx_align_center">2.03</td>
</tr>
<tr id="A6.T19.1.14" class="ltx_tr">
<td id="A6.T19.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T19.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T19.1.14.3" class="ltx_td ltx_align_center ltx_border_r">84.13</td>
<td id="A6.T19.1.14.4" class="ltx_td ltx_align_center">2.75</td>
</tr>
<tr id="A6.T19.1.15" class="ltx_tr">
<td id="A6.T19.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T19.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T19.1.15.3" class="ltx_td ltx_align_center ltx_border_r">86.50</td>
<td id="A6.T19.1.15.4" class="ltx_td ltx_align_center">0.50</td>
</tr>
<tr id="A6.T19.1.16" class="ltx_tr">
<td id="A6.T19.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T19.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T19.1.16.3" class="ltx_td ltx_align_center ltx_border_r">85.13</td>
<td id="A6.T19.1.16.4" class="ltx_td ltx_align_center">2.19</td>
</tr>
<tr id="A6.T19.1.17" class="ltx_tr">
<td id="A6.T19.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T19.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T19.1.17.3" class="ltx_td ltx_align_center ltx_border_r">85.13</td>
<td id="A6.T19.1.17.4" class="ltx_td ltx_align_center">2.19</td>
</tr>
<tr id="A6.T19.1.18" class="ltx_tr">
<td id="A6.T19.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T19.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T19.1.18.3" class="ltx_td ltx_align_center ltx_border_r">79.26</td>
<td id="A6.T19.1.18.4" class="ltx_td ltx_align_center">1.90</td>
</tr>
<tr id="A6.T19.1.19" class="ltx_tr">
<td id="A6.T19.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T19.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T19.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T19.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">86.59</td>
<td id="A6.T19.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T19.1.19.4.1" class="ltx_text ltx_font_bold">0.53</span></td>
</tr>
</table>
</figure>
<figure id="A6.T20" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T20.4.1.1" class="ltx_text" style="font-size:90%;">Table 20</span>. </span><span id="A6.T20.5.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with a SqueezeNet <cite class="ltx_cite ltx_citemacro_citep">(Iandola et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2016</a>)</cite> trained on <span id="A6.T20.5.2.1" class="ltx_text">CIFAR-10</span> <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2009</a>)</cite> in percent.</span></figcaption>
<table id="A6.T20.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T20.1.2" class="ltx_tr">
<td id="A6.T20.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T20.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T20.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T20.1.1" class="ltx_tr">
<td id="A6.T20.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T20.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T20.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T20.1.1.1.m1.1a"><msup id="A6.T20.1.1.1.m1.1.1" xref="A6.T20.1.1.1.m1.1.1.cmml"><mi id="A6.T20.1.1.1.m1.1.1.2" xref="A6.T20.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T20.1.1.1.m1.1.1.3" xref="A6.T20.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T20.1.1.1.m1.1b"><apply id="A6.T20.1.1.1.m1.1.1.cmml" xref="A6.T20.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T20.1.1.1.m1.1.1.1.cmml" xref="A6.T20.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T20.1.1.1.m1.1.1.2.cmml" xref="A6.T20.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T20.1.1.1.m1.1.1.3.cmml" xref="A6.T20.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T20.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T20.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">53.06</td>
<td id="A6.T20.1.1.4" class="ltx_td ltx_align_center ltx_border_t">8.3</td>
</tr>
<tr id="A6.T20.1.3" class="ltx_tr">
<td id="A6.T20.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T20.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T20.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.04</td>
<td id="A6.T20.1.3.4" class="ltx_td ltx_align_center ltx_border_t">5.67</td>
</tr>
<tr id="A6.T20.1.4" class="ltx_tr">
<td id="A6.T20.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T20.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T20.1.4.3" class="ltx_td ltx_align_center ltx_border_r">52.21</td>
<td id="A6.T20.1.4.4" class="ltx_td ltx_align_center">40.03</td>
</tr>
<tr id="A6.T20.1.5" class="ltx_tr">
<td id="A6.T20.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T20.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T20.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T20.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.03</td>
<td id="A6.T20.1.5.4" class="ltx_td ltx_align_center ltx_border_t">5.82</td>
</tr>
<tr id="A6.T20.1.6" class="ltx_tr">
<td id="A6.T20.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T20.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T20.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T20.1.6.3" class="ltx_td ltx_align_center ltx_border_r">56.33</td>
<td id="A6.T20.1.6.4" class="ltx_td ltx_align_center">38.85</td>
</tr>
<tr id="A6.T20.1.7" class="ltx_tr">
<td id="A6.T20.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T20.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T20.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T20.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.20</td>
<td id="A6.T20.1.7.4" class="ltx_td ltx_align_center ltx_border_t">10.32</td>
</tr>
<tr id="A6.T20.1.8" class="ltx_tr">
<td id="A6.T20.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T20.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T20.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T20.1.9" class="ltx_tr">
<td id="A6.T20.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T20.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T20.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.30</td>
<td id="A6.T20.1.9.4" class="ltx_td ltx_align_center ltx_border_t">5.82</td>
</tr>
<tr id="A6.T20.1.10" class="ltx_tr">
<td id="A6.T20.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T20.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T20.1.10.3" class="ltx_td ltx_align_center ltx_border_r">60.21</td>
<td id="A6.T20.1.10.4" class="ltx_td ltx_align_center">10.32</td>
</tr>
<tr id="A6.T20.1.11" class="ltx_tr">
<td id="A6.T20.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T20.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T20.1.11.3" class="ltx_td ltx_align_center ltx_border_r">55.93</td>
<td id="A6.T20.1.11.4" class="ltx_td ltx_align_center">5.44</td>
</tr>
<tr id="A6.T20.1.12" class="ltx_tr">
<td id="A6.T20.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T20.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T20.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T20.1.12.3" class="ltx_td ltx_align_center ltx_border_r">58.75</td>
<td id="A6.T20.1.12.4" class="ltx_td ltx_align_center">16.17</td>
</tr>
<tr id="A6.T20.1.13" class="ltx_tr">
<td id="A6.T20.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T20.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T20.1.13.3" class="ltx_td ltx_align_center ltx_border_r">60.18</td>
<td id="A6.T20.1.13.4" class="ltx_td ltx_align_center">10.27</td>
</tr>
<tr id="A6.T20.1.14" class="ltx_tr">
<td id="A6.T20.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T20.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T20.1.14.3" class="ltx_td ltx_align_center ltx_border_r">55.24</td>
<td id="A6.T20.1.14.4" class="ltx_td ltx_align_center">4.73</td>
</tr>
<tr id="A6.T20.1.15" class="ltx_tr">
<td id="A6.T20.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T20.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T20.1.15.3" class="ltx_td ltx_align_center ltx_border_r">60.78</td>
<td id="A6.T20.1.15.4" class="ltx_td ltx_align_center">5.45</td>
</tr>
<tr id="A6.T20.1.16" class="ltx_tr">
<td id="A6.T20.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T20.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T20.1.16.3" class="ltx_td ltx_align_center ltx_border_r">60.15</td>
<td id="A6.T20.1.16.4" class="ltx_td ltx_align_center">10.04</td>
</tr>
<tr id="A6.T20.1.17" class="ltx_tr">
<td id="A6.T20.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T20.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T20.1.17.3" class="ltx_td ltx_align_center ltx_border_r">59.68</td>
<td id="A6.T20.1.17.4" class="ltx_td ltx_align_center">8.40</td>
</tr>
<tr id="A6.T20.1.18" class="ltx_tr">
<td id="A6.T20.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T20.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T20.1.18.3" class="ltx_td ltx_align_center ltx_border_r">55.99</td>
<td id="A6.T20.1.18.4" class="ltx_td ltx_align_center">8.44</td>
</tr>
<tr id="A6.T20.1.19" class="ltx_tr">
<td id="A6.T20.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T20.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T20.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T20.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">60.22</td>
<td id="A6.T20.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T20.1.19.4.1" class="ltx_text ltx_font_bold">10.80</span></td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.1. </span>Setting Independence or <span id="A6.SS1.1.1" class="ltx_text">MESAS</span>
</h3>

<div id="A6.SS1.p1" class="ltx_para">
<p id="A6.SS1.p1.1" class="ltx_p">All randomness within the system was seeded with 42 within our experiments, but we conducted spot tests with <math id="A6.SS1.p1.1.m1.3" class="ltx_Math" alttext="seed_{rand}=\{0,1,13\}" display="inline"><semantics id="A6.SS1.p1.1.m1.3a"><mrow id="A6.SS1.p1.1.m1.3.4" xref="A6.SS1.p1.1.m1.3.4.cmml"><mrow id="A6.SS1.p1.1.m1.3.4.2" xref="A6.SS1.p1.1.m1.3.4.2.cmml"><mi id="A6.SS1.p1.1.m1.3.4.2.2" xref="A6.SS1.p1.1.m1.3.4.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="A6.SS1.p1.1.m1.3.4.2.1" xref="A6.SS1.p1.1.m1.3.4.2.1.cmml">​</mo><mi id="A6.SS1.p1.1.m1.3.4.2.3" xref="A6.SS1.p1.1.m1.3.4.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A6.SS1.p1.1.m1.3.4.2.1a" xref="A6.SS1.p1.1.m1.3.4.2.1.cmml">​</mo><mi id="A6.SS1.p1.1.m1.3.4.2.4" xref="A6.SS1.p1.1.m1.3.4.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="A6.SS1.p1.1.m1.3.4.2.1b" xref="A6.SS1.p1.1.m1.3.4.2.1.cmml">​</mo><msub id="A6.SS1.p1.1.m1.3.4.2.5" xref="A6.SS1.p1.1.m1.3.4.2.5.cmml"><mi id="A6.SS1.p1.1.m1.3.4.2.5.2" xref="A6.SS1.p1.1.m1.3.4.2.5.2.cmml">d</mi><mrow id="A6.SS1.p1.1.m1.3.4.2.5.3" xref="A6.SS1.p1.1.m1.3.4.2.5.3.cmml"><mi id="A6.SS1.p1.1.m1.3.4.2.5.3.2" xref="A6.SS1.p1.1.m1.3.4.2.5.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="A6.SS1.p1.1.m1.3.4.2.5.3.1" xref="A6.SS1.p1.1.m1.3.4.2.5.3.1.cmml">​</mo><mi id="A6.SS1.p1.1.m1.3.4.2.5.3.3" xref="A6.SS1.p1.1.m1.3.4.2.5.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A6.SS1.p1.1.m1.3.4.2.5.3.1a" xref="A6.SS1.p1.1.m1.3.4.2.5.3.1.cmml">​</mo><mi id="A6.SS1.p1.1.m1.3.4.2.5.3.4" xref="A6.SS1.p1.1.m1.3.4.2.5.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="A6.SS1.p1.1.m1.3.4.2.5.3.1b" xref="A6.SS1.p1.1.m1.3.4.2.5.3.1.cmml">​</mo><mi id="A6.SS1.p1.1.m1.3.4.2.5.3.5" xref="A6.SS1.p1.1.m1.3.4.2.5.3.5.cmml">d</mi></mrow></msub></mrow><mo id="A6.SS1.p1.1.m1.3.4.1" xref="A6.SS1.p1.1.m1.3.4.1.cmml">=</mo><mrow id="A6.SS1.p1.1.m1.3.4.3.2" xref="A6.SS1.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="A6.SS1.p1.1.m1.3.4.3.2.1" xref="A6.SS1.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="A6.SS1.p1.1.m1.1.1" xref="A6.SS1.p1.1.m1.1.1.cmml">0</mn><mo id="A6.SS1.p1.1.m1.3.4.3.2.2" xref="A6.SS1.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="A6.SS1.p1.1.m1.2.2" xref="A6.SS1.p1.1.m1.2.2.cmml">1</mn><mo id="A6.SS1.p1.1.m1.3.4.3.2.3" xref="A6.SS1.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="A6.SS1.p1.1.m1.3.3" xref="A6.SS1.p1.1.m1.3.3.cmml">13</mn><mo stretchy="false" id="A6.SS1.p1.1.m1.3.4.3.2.4" xref="A6.SS1.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.1.m1.3b"><apply id="A6.SS1.p1.1.m1.3.4.cmml" xref="A6.SS1.p1.1.m1.3.4"><eq id="A6.SS1.p1.1.m1.3.4.1.cmml" xref="A6.SS1.p1.1.m1.3.4.1"></eq><apply id="A6.SS1.p1.1.m1.3.4.2.cmml" xref="A6.SS1.p1.1.m1.3.4.2"><times id="A6.SS1.p1.1.m1.3.4.2.1.cmml" xref="A6.SS1.p1.1.m1.3.4.2.1"></times><ci id="A6.SS1.p1.1.m1.3.4.2.2.cmml" xref="A6.SS1.p1.1.m1.3.4.2.2">𝑠</ci><ci id="A6.SS1.p1.1.m1.3.4.2.3.cmml" xref="A6.SS1.p1.1.m1.3.4.2.3">𝑒</ci><ci id="A6.SS1.p1.1.m1.3.4.2.4.cmml" xref="A6.SS1.p1.1.m1.3.4.2.4">𝑒</ci><apply id="A6.SS1.p1.1.m1.3.4.2.5.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5"><csymbol cd="ambiguous" id="A6.SS1.p1.1.m1.3.4.2.5.1.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5">subscript</csymbol><ci id="A6.SS1.p1.1.m1.3.4.2.5.2.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5.2">𝑑</ci><apply id="A6.SS1.p1.1.m1.3.4.2.5.3.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5.3"><times id="A6.SS1.p1.1.m1.3.4.2.5.3.1.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5.3.1"></times><ci id="A6.SS1.p1.1.m1.3.4.2.5.3.2.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5.3.2">𝑟</ci><ci id="A6.SS1.p1.1.m1.3.4.2.5.3.3.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5.3.3">𝑎</ci><ci id="A6.SS1.p1.1.m1.3.4.2.5.3.4.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5.3.4">𝑛</ci><ci id="A6.SS1.p1.1.m1.3.4.2.5.3.5.cmml" xref="A6.SS1.p1.1.m1.3.4.2.5.3.5">𝑑</ci></apply></apply></apply><set id="A6.SS1.p1.1.m1.3.4.3.1.cmml" xref="A6.SS1.p1.1.m1.3.4.3.2"><cn type="integer" id="A6.SS1.p1.1.m1.1.1.cmml" xref="A6.SS1.p1.1.m1.1.1">0</cn><cn type="integer" id="A6.SS1.p1.1.m1.2.2.cmml" xref="A6.SS1.p1.1.m1.2.2">1</cn><cn type="integer" id="A6.SS1.p1.1.m1.3.3.cmml" xref="A6.SS1.p1.1.m1.3.3">13</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.1.m1.3c">seed_{rand}=\{0,1,13\}</annotation></semantics></math> and found similar results, hence, the seed does not influence our findings.</p>
</div>
<div id="A6.SS1.p2" class="ltx_para">
<p id="A6.SS1.p2.2" class="ltx_p">We changed LR of the default scenario to <math id="A6.SS1.p2.1.m1.3" class="ltx_Math" alttext="LR=\{0.1,0.01,0.001\}" display="inline"><semantics id="A6.SS1.p2.1.m1.3a"><mrow id="A6.SS1.p2.1.m1.3.4" xref="A6.SS1.p2.1.m1.3.4.cmml"><mrow id="A6.SS1.p2.1.m1.3.4.2" xref="A6.SS1.p2.1.m1.3.4.2.cmml"><mi id="A6.SS1.p2.1.m1.3.4.2.2" xref="A6.SS1.p2.1.m1.3.4.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="A6.SS1.p2.1.m1.3.4.2.1" xref="A6.SS1.p2.1.m1.3.4.2.1.cmml">​</mo><mi id="A6.SS1.p2.1.m1.3.4.2.3" xref="A6.SS1.p2.1.m1.3.4.2.3.cmml">R</mi></mrow><mo id="A6.SS1.p2.1.m1.3.4.1" xref="A6.SS1.p2.1.m1.3.4.1.cmml">=</mo><mrow id="A6.SS1.p2.1.m1.3.4.3.2" xref="A6.SS1.p2.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="A6.SS1.p2.1.m1.3.4.3.2.1" xref="A6.SS1.p2.1.m1.3.4.3.1.cmml">{</mo><mn id="A6.SS1.p2.1.m1.1.1" xref="A6.SS1.p2.1.m1.1.1.cmml">0.1</mn><mo id="A6.SS1.p2.1.m1.3.4.3.2.2" xref="A6.SS1.p2.1.m1.3.4.3.1.cmml">,</mo><mn id="A6.SS1.p2.1.m1.2.2" xref="A6.SS1.p2.1.m1.2.2.cmml">0.01</mn><mo id="A6.SS1.p2.1.m1.3.4.3.2.3" xref="A6.SS1.p2.1.m1.3.4.3.1.cmml">,</mo><mn id="A6.SS1.p2.1.m1.3.3" xref="A6.SS1.p2.1.m1.3.3.cmml">0.001</mn><mo stretchy="false" id="A6.SS1.p2.1.m1.3.4.3.2.4" xref="A6.SS1.p2.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p2.1.m1.3b"><apply id="A6.SS1.p2.1.m1.3.4.cmml" xref="A6.SS1.p2.1.m1.3.4"><eq id="A6.SS1.p2.1.m1.3.4.1.cmml" xref="A6.SS1.p2.1.m1.3.4.1"></eq><apply id="A6.SS1.p2.1.m1.3.4.2.cmml" xref="A6.SS1.p2.1.m1.3.4.2"><times id="A6.SS1.p2.1.m1.3.4.2.1.cmml" xref="A6.SS1.p2.1.m1.3.4.2.1"></times><ci id="A6.SS1.p2.1.m1.3.4.2.2.cmml" xref="A6.SS1.p2.1.m1.3.4.2.2">𝐿</ci><ci id="A6.SS1.p2.1.m1.3.4.2.3.cmml" xref="A6.SS1.p2.1.m1.3.4.2.3">𝑅</ci></apply><set id="A6.SS1.p2.1.m1.3.4.3.1.cmml" xref="A6.SS1.p2.1.m1.3.4.3.2"><cn type="float" id="A6.SS1.p2.1.m1.1.1.cmml" xref="A6.SS1.p2.1.m1.1.1">0.1</cn><cn type="float" id="A6.SS1.p2.1.m1.2.2.cmml" xref="A6.SS1.p2.1.m1.2.2">0.01</cn><cn type="float" id="A6.SS1.p2.1.m1.3.3.cmml" xref="A6.SS1.p2.1.m1.3.3">0.001</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p2.1.m1.3c">LR=\{0.1,0.01,0.001\}</annotation></semantics></math> and found, that 0.01 is the best choice for benign and adversarial training regarding the local and global MA and BA, hence a valid choice for our experiments. A LR or 0.1 is too big destructing the adversarial models to naïve classifiers and reducing the MA of benign clients to 30% on average. For LR 0.001, it depends on the round <math id="A6.SS1.p2.2.m2.1" class="ltx_Math" alttext="r" display="inline"><semantics id="A6.SS1.p2.2.m2.1a"><mi id="A6.SS1.p2.2.m2.1.1" xref="A6.SS1.p2.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A6.SS1.p2.2.m2.1b"><ci id="A6.SS1.p2.2.m2.1.1.cmml" xref="A6.SS1.p2.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p2.2.m2.1c">r</annotation></semantics></math>, where it is used. In early rounds, 0.01 is the better choice to speed up the federations training process, but in advanced FL rounds a lower LR naturally increases the accuracies, as in every machine learning scenario. Hence, the MA can be increased, but it is also more difficult for the adversary to adapt some metrics within the defined epochs. Nevertheless, <span id="A6.SS1.p2.2.1" class="ltx_text">MESAS</span> achieved the same detection ACC with both settings, thus detecting the naïve classifiers for LR 0.01, which behave similar to a untargeted poisoning attacks, and the models with better accuracies in the 0.001 LR setting. We set the LR fixed to 0.01 as a good <span id="A6.SS1.p2.2.2" class="ltx_text">trade-off</span> between both scenarios.</p>
</div>
<div id="A6.SS1.p3" class="ltx_para">
<p id="A6.SS1.p3.1" class="ltx_p">In all our experiments, we keep the PMR as high as possible without violating the majority assumption of <a href="#S3.SS1" title="3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></span></a>. Since <span id="A6.SS1.p3.1.2" class="ltx_text">MESAS</span> does not remove poisoned models with a single test, but prunes different poisonings gradually, we automatically test lower PMRs within range <span id="A6.SS1.p3.1.1" class="ltx_text"><math id="A6.SS1.p3.1.1.m1.2" class="ltx_math_unparsed" alttext="[0.0,0.5[" display="inline"><semantics id="A6.SS1.p3.1.1.m1.2a"><mrow id="A6.SS1.p3.1.1.m1.2b"><mo stretchy="false" id="A6.SS1.p3.1.1.m1.2.3">[</mo><mn id="A6.SS1.p3.1.1.m1.1.1">0.0</mn><mo id="A6.SS1.p3.1.1.m1.2.4">,</mo><mn id="A6.SS1.p3.1.1.m1.2.2">0.5</mn><mo stretchy="false" id="A6.SS1.p3.1.1.m1.2.5">[</mo></mrow><annotation encoding="application/x-tex" id="A6.SS1.p3.1.1.m1.2c">[0.0,0.5[</annotation></semantics></math></span>, demonstrating the independence of <span id="A6.SS1.p3.1.3" class="ltx_text">MESAS</span> to PMRs.</p>
</div>
<div id="A6.SS1.p4" class="ltx_para">
<p id="A6.SS1.p4.5" class="ltx_p">Since <span id="A6.SS1.p4.5.3" class="ltx_text">MESAS</span> does not leverage the plain MA values, we set <math id="A6.SS1.p4.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A6.SS1.p4.1.m1.1a"><mi id="A6.SS1.p4.1.m1.1.1" xref="A6.SS1.p4.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A6.SS1.p4.1.m1.1b"><ci id="A6.SS1.p4.1.m1.1.1.cmml" xref="A6.SS1.p4.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p4.1.m1.1c">\alpha</annotation></semantics></math> as low as possible, so that the adversary still achieves a high BA while simultaneously applying a maximum adaption level. We tested <span id="A6.SS1.p4.2.1" class="ltx_text"><math id="A6.SS1.p4.2.1.m1.4" class="ltx_Math" alttext="\alpha=[0.1,0.2,...,0.9]" display="inline"><semantics id="A6.SS1.p4.2.1.m1.4a"><mrow id="A6.SS1.p4.2.1.m1.4.5" xref="A6.SS1.p4.2.1.m1.4.5.cmml"><mi id="A6.SS1.p4.2.1.m1.4.5.2" xref="A6.SS1.p4.2.1.m1.4.5.2.cmml">α</mi><mo id="A6.SS1.p4.2.1.m1.4.5.1" xref="A6.SS1.p4.2.1.m1.4.5.1.cmml">=</mo><mrow id="A6.SS1.p4.2.1.m1.4.5.3.2" xref="A6.SS1.p4.2.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="A6.SS1.p4.2.1.m1.4.5.3.2.1" xref="A6.SS1.p4.2.1.m1.4.5.3.1.cmml">[</mo><mn id="A6.SS1.p4.2.1.m1.1.1" xref="A6.SS1.p4.2.1.m1.1.1.cmml">0.1</mn><mo id="A6.SS1.p4.2.1.m1.4.5.3.2.2" xref="A6.SS1.p4.2.1.m1.4.5.3.1.cmml">,</mo><mn id="A6.SS1.p4.2.1.m1.2.2" xref="A6.SS1.p4.2.1.m1.2.2.cmml">0.2</mn><mo id="A6.SS1.p4.2.1.m1.4.5.3.2.3" xref="A6.SS1.p4.2.1.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="A6.SS1.p4.2.1.m1.3.3" xref="A6.SS1.p4.2.1.m1.3.3.cmml">…</mi><mo id="A6.SS1.p4.2.1.m1.4.5.3.2.4" xref="A6.SS1.p4.2.1.m1.4.5.3.1.cmml">,</mo><mn id="A6.SS1.p4.2.1.m1.4.4" xref="A6.SS1.p4.2.1.m1.4.4.cmml">0.9</mn><mo stretchy="false" id="A6.SS1.p4.2.1.m1.4.5.3.2.5" xref="A6.SS1.p4.2.1.m1.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p4.2.1.m1.4b"><apply id="A6.SS1.p4.2.1.m1.4.5.cmml" xref="A6.SS1.p4.2.1.m1.4.5"><eq id="A6.SS1.p4.2.1.m1.4.5.1.cmml" xref="A6.SS1.p4.2.1.m1.4.5.1"></eq><ci id="A6.SS1.p4.2.1.m1.4.5.2.cmml" xref="A6.SS1.p4.2.1.m1.4.5.2">𝛼</ci><list id="A6.SS1.p4.2.1.m1.4.5.3.1.cmml" xref="A6.SS1.p4.2.1.m1.4.5.3.2"><cn type="float" id="A6.SS1.p4.2.1.m1.1.1.cmml" xref="A6.SS1.p4.2.1.m1.1.1">0.1</cn><cn type="float" id="A6.SS1.p4.2.1.m1.2.2.cmml" xref="A6.SS1.p4.2.1.m1.2.2">0.2</cn><ci id="A6.SS1.p4.2.1.m1.3.3.cmml" xref="A6.SS1.p4.2.1.m1.3.3">…</ci><cn type="float" id="A6.SS1.p4.2.1.m1.4.4.cmml" xref="A6.SS1.p4.2.1.m1.4.4">0.9</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p4.2.1.m1.4c">\alpha=[0.1,0.2,...,0.9]</annotation></semantics></math></span> and found <span id="A6.SS1.p4.3.2" class="ltx_text"><math id="A6.SS1.p4.3.2.m1.1" class="ltx_Math" alttext="\alpha=0.3" display="inline"><semantics id="A6.SS1.p4.3.2.m1.1a"><mrow id="A6.SS1.p4.3.2.m1.1.1" xref="A6.SS1.p4.3.2.m1.1.1.cmml"><mi id="A6.SS1.p4.3.2.m1.1.1.2" xref="A6.SS1.p4.3.2.m1.1.1.2.cmml">α</mi><mo id="A6.SS1.p4.3.2.m1.1.1.1" xref="A6.SS1.p4.3.2.m1.1.1.1.cmml">=</mo><mn id="A6.SS1.p4.3.2.m1.1.1.3" xref="A6.SS1.p4.3.2.m1.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p4.3.2.m1.1b"><apply id="A6.SS1.p4.3.2.m1.1.1.cmml" xref="A6.SS1.p4.3.2.m1.1.1"><eq id="A6.SS1.p4.3.2.m1.1.1.1.cmml" xref="A6.SS1.p4.3.2.m1.1.1.1"></eq><ci id="A6.SS1.p4.3.2.m1.1.1.2.cmml" xref="A6.SS1.p4.3.2.m1.1.1.2">𝛼</ci><cn type="float" id="A6.SS1.p4.3.2.m1.1.1.3.cmml" xref="A6.SS1.p4.3.2.m1.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p4.3.2.m1.1c">\alpha=0.3</annotation></semantics></math></span> being the most beneficial choice for <math id="A6.SS1.p4.4.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="A6.SS1.p4.4.m2.1a"><mi id="A6.SS1.p4.4.m2.1.1" xref="A6.SS1.p4.4.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="A6.SS1.p4.4.m2.1b"><ci id="A6.SS1.p4.4.m2.1.1.cmml" xref="A6.SS1.p4.4.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p4.4.m2.1c">A</annotation></semantics></math>.<span id="footnote23" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">23</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">23</sup><span class="ltx_tag ltx_tag_note">23</span>Besides adapting to all <span id="footnote23.1" class="ltx_text">MESAS</span> metrics, we conducted experiments starting with only adapting to COS and then adding the other metircs <span id="footnote23.2" class="ltx_text">step-wise</span> to find a valid <math id="footnote23.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="footnote23.m1.1b"><mi id="footnote23.m1.1.1" xref="footnote23.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="footnote23.m1.1c"><ci id="footnote23.m1.1.1.cmml" xref="footnote23.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote23.m1.1d">\alpha</annotation></semantics></math>, since adapting to all metrics of <span id="footnote23.3" class="ltx_text">MESAS</span> simultaneously is not possible in the end.</span></span></span> For higher values, the anomaly to a benign model increases and any defense leveraging the respective metrics detects the attack even clearer, for lower values, the model completely focuses on adapting to metrics and ignores the BA, thus does not enable the backdoor. Consequently, in parallel to the BA, the MA is low having the same effect as an untargeted poisoning attack. In such scenarios an adaption to all metrics of <span id="A6.SS1.p4.5.4" class="ltx_text">MESAS</span> appears to be very difficult allowing <span id="A6.SS1.p4.5.5" class="ltx_text">MESAS</span> to be effective. Thus <span id="A6.SS1.p4.5.6" class="ltx_text">MESAS</span> is independent of <math id="A6.SS1.p4.5.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A6.SS1.p4.5.m3.1a"><mi id="A6.SS1.p4.5.m3.1.1" xref="A6.SS1.p4.5.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A6.SS1.p4.5.m3.1b"><ci id="A6.SS1.p4.5.m3.1.1.cmml" xref="A6.SS1.p4.5.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p4.5.m3.1c">\alpha</annotation></semantics></math>.</p>
</div>
<div id="A6.SS1.p5" class="ltx_para">
<p id="A6.SS1.p5.1" class="ltx_p"><a href="#A6.T21" title="Table 21 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">21</span></span></a> and <a href="#A6.T22" title="Table 22 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">22</span></span></a> show results for experiments with MNIST <cite class="ltx_cite ltx_citemacro_citep">(Deng, <a href="#bib.bib24" title="" class="ltx_ref">2012</a>)</cite> and GTSRB <cite class="ltx_cite ltx_citemacro_citep">(Stallkamp et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2012</a>)</cite> respectivelly, showing that <span id="A6.SS1.p5.1.1" class="ltx_text">MESAS</span> is also effective with varying datasets. <span id="A6.SS1.p5.1.2" class="ltx_text">MESAS</span> detects the poisoned models with one fp for MNIST and 100% ACC for GTSRB even if the backdoor is not yet strong enough to poison the new global model. Further strengthening of the BA by the adversary would increase the significance within the metrics of <span id="A6.SS1.p5.1.3" class="ltx_text">MESAS</span>.</p>
</div>
<figure id="A6.T21" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T21.3.1.1" class="ltx_text" style="font-size:90%;">Table 21</span>. </span><span id="A6.T21.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with MNIST <cite class="ltx_cite ltx_citemacro_citep">(Deng, <a href="#bib.bib24" title="" class="ltx_ref">2012</a>)</cite> as a dataset and PDR of 0.3 and scaled
poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T21.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T21.1.2" class="ltx_tr">
<td id="A6.T21.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T21.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T21.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T21.1.1" class="ltx_tr">
<td id="A6.T21.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T21.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T21.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T21.1.1.1.m1.1a"><msup id="A6.T21.1.1.1.m1.1.1" xref="A6.T21.1.1.1.m1.1.1.cmml"><mi id="A6.T21.1.1.1.m1.1.1.2" xref="A6.T21.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T21.1.1.1.m1.1.1.3" xref="A6.T21.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T21.1.1.1.m1.1b"><apply id="A6.T21.1.1.1.m1.1.1.cmml" xref="A6.T21.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T21.1.1.1.m1.1.1.1.cmml" xref="A6.T21.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T21.1.1.1.m1.1.1.2.cmml" xref="A6.T21.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T21.1.1.1.m1.1.1.3.cmml" xref="A6.T21.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T21.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T21.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.60</td>
<td id="A6.T21.1.1.4" class="ltx_td ltx_align_center ltx_border_t">0.43</td>
</tr>
<tr id="A6.T21.1.3" class="ltx_tr">
<td id="A6.T21.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T21.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T21.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.30</td>
<td id="A6.T21.1.3.4" class="ltx_td ltx_align_center ltx_border_t">0.40</td>
</tr>
<tr id="A6.T21.1.4" class="ltx_tr">
<td id="A6.T21.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T21.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T21.1.4.3" class="ltx_td ltx_align_center ltx_border_r">91.73</td>
<td id="A6.T21.1.4.4" class="ltx_td ltx_align_center">100.00</td>
</tr>
<tr id="A6.T21.1.5" class="ltx_tr">
<td id="A6.T21.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T21.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T21.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T21.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.22</td>
<td id="A6.T21.1.5.4" class="ltx_td ltx_align_center ltx_border_t">0.45</td>
</tr>
<tr id="A6.T21.1.6" class="ltx_tr">
<td id="A6.T21.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T21.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T21.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T21.1.6.3" class="ltx_td ltx_align_center ltx_border_r">97.20</td>
<td id="A6.T21.1.6.4" class="ltx_td ltx_align_center">100.00</td>
</tr>
<tr id="A6.T21.1.7" class="ltx_tr">
<td id="A6.T21.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T21.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T21.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T21.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.24</td>
<td id="A6.T21.1.7.4" class="ltx_td ltx_align_center ltx_border_t">2.92</td>
</tr>
<tr id="A6.T21.1.8" class="ltx_tr">
<td id="A6.T21.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T21.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T21.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T21.1.9" class="ltx_tr">
<td id="A6.T21.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T21.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T21.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.22</td>
<td id="A6.T21.1.9.4" class="ltx_td ltx_align_center ltx_border_t">0.45</td>
</tr>
<tr id="A6.T21.1.10" class="ltx_tr">
<td id="A6.T21.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T21.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T21.1.10.3" class="ltx_td ltx_align_center ltx_border_r">97.22</td>
<td id="A6.T21.1.10.4" class="ltx_td ltx_align_center">0.45</td>
</tr>
<tr id="A6.T21.1.11" class="ltx_tr">
<td id="A6.T21.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T21.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T21.1.11.3" class="ltx_td ltx_align_center ltx_border_r">95.31</td>
<td id="A6.T21.1.11.4" class="ltx_td ltx_align_center">100.00</td>
</tr>
<tr id="A6.T21.1.12" class="ltx_tr">
<td id="A6.T21.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T21.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T21.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T21.1.12.3" class="ltx_td ltx_align_center ltx_border_r">97.26</td>
<td id="A6.T21.1.12.4" class="ltx_td ltx_align_center">46.93</td>
</tr>
<tr id="A6.T21.1.13" class="ltx_tr">
<td id="A6.T21.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T21.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T21.1.13.3" class="ltx_td ltx_align_center ltx_border_r">97.26</td>
<td id="A6.T21.1.13.4" class="ltx_td ltx_align_center">1.74</td>
</tr>
<tr id="A6.T21.1.14" class="ltx_tr">
<td id="A6.T21.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T21.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T21.1.14.3" class="ltx_td ltx_align_center ltx_border_r">86.73</td>
<td id="A6.T21.1.14.4" class="ltx_td ltx_align_center">48.05</td>
</tr>
<tr id="A6.T21.1.15" class="ltx_tr">
<td id="A6.T21.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T21.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T21.1.15.3" class="ltx_td ltx_align_center ltx_border_r">97.45</td>
<td id="A6.T21.1.15.4" class="ltx_td ltx_align_center">3.03</td>
</tr>
<tr id="A6.T21.1.16" class="ltx_tr">
<td id="A6.T21.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T21.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T21.1.16.3" class="ltx_td ltx_align_center ltx_border_r">97.35</td>
<td id="A6.T21.1.16.4" class="ltx_td ltx_align_center">1.91</td>
</tr>
<tr id="A6.T21.1.17" class="ltx_tr">
<td id="A6.T21.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T21.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T21.1.17.3" class="ltx_td ltx_align_center ltx_border_r">96.69</td>
<td id="A6.T21.1.17.4" class="ltx_td ltx_align_center">2.15</td>
</tr>
<tr id="A6.T21.1.18" class="ltx_tr">
<td id="A6.T21.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T21.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T21.1.18.3" class="ltx_td ltx_align_center ltx_border_r">97.34</td>
<td id="A6.T21.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T21.1.18.4.1" class="ltx_text ltx_font_bold">0.62</span></td>
</tr>
<tr id="A6.T21.1.19" class="ltx_tr">
<td id="A6.T21.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T21.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T21.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T21.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">97.18</td>
<td id="A6.T21.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T21.1.19.4.1" class="ltx_text ltx_font_bold">0.42</span></td>
</tr>
</table>
</figure>
<figure id="A6.T22" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A6.T22.3.1.1" class="ltx_text" style="font-size:90%;">Table 22</span>. </span><span id="A6.T22.4.2" class="ltx_text" style="font-size:90%;">MA and BA in the default scenario with GTSRB <cite class="ltx_cite ltx_citemacro_citep">(Stallkamp et al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2012</a>)</cite> as a dataset and PDR of 0.3 and scaled
poisoned models regarding the Euclidean distance of updates in percent.</span></figcaption>
<table id="A6.T22.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T22.1.2" class="ltx_tr">
<td id="A6.T22.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2">Accuracies without defenses</td>
<td id="A6.T22.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">MA</td>
<td id="A6.T22.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">BA</td>
</tr>
<tr id="A6.T22.1.1" class="ltx_tr">
<td id="A6.T22.1.1.2" class="ltx_td ltx_align_left ltx_border_t">1:</td>
<td id="A6.T22.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Global model <math id="A6.T22.1.1.1.m1.1" class="ltx_Math" alttext="G^{r}" display="inline"><semantics id="A6.T22.1.1.1.m1.1a"><msup id="A6.T22.1.1.1.m1.1.1" xref="A6.T22.1.1.1.m1.1.1.cmml"><mi id="A6.T22.1.1.1.m1.1.1.2" xref="A6.T22.1.1.1.m1.1.1.2.cmml">G</mi><mi id="A6.T22.1.1.1.m1.1.1.3" xref="A6.T22.1.1.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="A6.T22.1.1.1.m1.1b"><apply id="A6.T22.1.1.1.m1.1.1.cmml" xref="A6.T22.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.T22.1.1.1.m1.1.1.1.cmml" xref="A6.T22.1.1.1.m1.1.1">superscript</csymbol><ci id="A6.T22.1.1.1.m1.1.1.2.cmml" xref="A6.T22.1.1.1.m1.1.1.2">𝐺</ci><ci id="A6.T22.1.1.1.m1.1.1.3.cmml" xref="A6.T22.1.1.1.m1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.T22.1.1.1.m1.1c">G^{r}</annotation></semantics></math>
</td>
<td id="A6.T22.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.62</td>
<td id="A6.T22.1.1.4" class="ltx_td ltx_align_center ltx_border_t">0.96</td>
</tr>
<tr id="A6.T22.1.3" class="ltx_tr">
<td id="A6.T22.1.3.1" class="ltx_td ltx_align_left ltx_border_t">2:</td>
<td id="A6.T22.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Average of benign local models</td>
<td id="A6.T22.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78.43</td>
<td id="A6.T22.1.3.4" class="ltx_td ltx_align_center ltx_border_t">0.59</td>
</tr>
<tr id="A6.T22.1.4" class="ltx_tr">
<td id="A6.T22.1.4.1" class="ltx_td ltx_align_left">3:</td>
<td id="A6.T22.1.4.2" class="ltx_td ltx_align_center ltx_border_r">Average of poisoned local models</td>
<td id="A6.T22.1.4.3" class="ltx_td ltx_align_center ltx_border_r">62.42</td>
<td id="A6.T22.1.4.4" class="ltx_td ltx_align_center">94.38</td>
</tr>
<tr id="A6.T22.1.5" class="ltx_tr">
<td id="A6.T22.1.5.1" class="ltx_td ltx_align_left ltx_border_t">4:</td>
<td id="A6.T22.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T22.1.5.2.1" class="ltx_text">FedAVG</span> with benign local models</td>
<td id="A6.T22.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.77</td>
<td id="A6.T22.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1.06</td>
</tr>
<tr id="A6.T22.1.6" class="ltx_tr">
<td id="A6.T22.1.6.1" class="ltx_td ltx_align_left">5:</td>
<td id="A6.T22.1.6.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T22.1.6.2.1" class="ltx_text">FedAVG</span> with poisoned local models</td>
<td id="A6.T22.1.6.3" class="ltx_td ltx_align_center ltx_border_r">83.00</td>
<td id="A6.T22.1.6.4" class="ltx_td ltx_align_center">90.81</td>
</tr>
<tr id="A6.T22.1.7" class="ltx_tr">
<td id="A6.T22.1.7.1" class="ltx_td ltx_align_left ltx_border_t">6:</td>
<td id="A6.T22.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A6.T22.1.7.2.1" class="ltx_text">FedAVG</span> with all local models</td>
<td id="A6.T22.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.19</td>
<td id="A6.T22.1.7.4" class="ltx_td ltx_align_center ltx_border_t">8.01</td>
</tr>
<tr id="A6.T22.1.8" class="ltx_tr">
<td id="A6.T22.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt" colspan="2">Global model accuracies after applying defenses</td>
<td id="A6.T22.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt">MA</td>
<td id="A6.T22.1.8.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt">BA</td>
</tr>
<tr id="A6.T22.1.9" class="ltx_tr">
<td id="A6.T22.1.9.1" class="ltx_td ltx_align_left ltx_border_t">7:</td>
<td id="A6.T22.1.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Naïve Clustering</td>
<td id="A6.T22.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.57</td>
<td id="A6.T22.1.9.4" class="ltx_td ltx_align_center ltx_border_t">31.65</td>
</tr>
<tr id="A6.T22.1.10" class="ltx_tr">
<td id="A6.T22.1.10.1" class="ltx_td ltx_align_left">8:</td>
<td id="A6.T22.1.10.2" class="ltx_td ltx_align_center ltx_border_r">FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="A6.T22.1.10.3" class="ltx_td ltx_align_center ltx_border_r">85.12</td>
<td id="A6.T22.1.10.4" class="ltx_td ltx_align_center">0.70</td>
</tr>
<tr id="A6.T22.1.11" class="ltx_tr">
<td id="A6.T22.1.11.1" class="ltx_td ltx_align_left">9:</td>
<td id="A6.T22.1.11.2" class="ltx_td ltx_align_center ltx_border_r">Krum <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T22.1.11.3" class="ltx_td ltx_align_center ltx_border_r">88.57</td>
<td id="A6.T22.1.11.4" class="ltx_td ltx_align_center">1.15</td>
</tr>
<tr id="A6.T22.1.12" class="ltx_tr">
<td id="A6.T22.1.12.1" class="ltx_td ltx_align_left">10:</td>
<td id="A6.T22.1.12.2" class="ltx_td ltx_align_center ltx_border_r">
<span id="A6.T22.1.12.2.1" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>
</td>
<td id="A6.T22.1.12.3" class="ltx_td ltx_align_center ltx_border_r">88.08</td>
<td id="A6.T22.1.12.4" class="ltx_td ltx_align_center">0.92</td>
</tr>
<tr id="A6.T22.1.13" class="ltx_tr">
<td id="A6.T22.1.13.1" class="ltx_td ltx_align_left">11:</td>
<td id="A6.T22.1.13.2" class="ltx_td ltx_align_center ltx_border_r">Clip <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T22.1.13.3" class="ltx_td ltx_align_center ltx_border_r">86.21</td>
<td id="A6.T22.1.13.4" class="ltx_td ltx_align_center">4.39</td>
</tr>
<tr id="A6.T22.1.14" class="ltx_tr">
<td id="A6.T22.1.14.1" class="ltx_td ltx_align_left">12:</td>
<td id="A6.T22.1.14.2" class="ltx_td ltx_align_center ltx_border_r">Clip&amp;Noise <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T22.1.14.3" class="ltx_td ltx_align_center ltx_border_r">14.98</td>
<td id="A6.T22.1.14.4" class="ltx_td ltx_align_center">91.72</td>
</tr>
<tr id="A6.T22.1.15" class="ltx_tr">
<td id="A6.T22.1.15.1" class="ltx_td ltx_align_left">13:</td>
<td id="A6.T22.1.15.2" class="ltx_td ltx_align_center ltx_border_r">Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>
</td>
<td id="A6.T22.1.15.3" class="ltx_td ltx_align_center ltx_border_r">84.29</td>
<td id="A6.T22.1.15.4" class="ltx_td ltx_align_center">13.42</td>
</tr>
<tr id="A6.T22.1.16" class="ltx_tr">
<td id="A6.T22.1.16.1" class="ltx_td ltx_align_left">14:</td>
<td id="A6.T22.1.16.2" class="ltx_td ltx_align_center ltx_border_r">T-Mean <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T22.1.16.3" class="ltx_td ltx_align_center ltx_border_r">86.30</td>
<td id="A6.T22.1.16.4" class="ltx_td ltx_align_center">4.26</td>
</tr>
<tr id="A6.T22.1.17" class="ltx_tr">
<td id="A6.T22.1.17.1" class="ltx_td ltx_align_left">15:</td>
<td id="A6.T22.1.17.2" class="ltx_td ltx_align_center ltx_border_r">T-Median <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>
</td>
<td id="A6.T22.1.17.3" class="ltx_td ltx_align_center ltx_border_r">74.22</td>
<td id="A6.T22.1.17.4" class="ltx_td ltx_align_center">1.61</td>
</tr>
<tr id="A6.T22.1.18" class="ltx_tr">
<td id="A6.T22.1.18.1" class="ltx_td ltx_align_left">16:</td>
<td id="A6.T22.1.18.2" class="ltx_td ltx_align_center ltx_border_r">FLTrust <cite class="ltx_cite ltx_citemacro_citep">(Cao et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A6.T22.1.18.3" class="ltx_td ltx_align_center ltx_border_r">86.73</td>
<td id="A6.T22.1.18.4" class="ltx_td ltx_align_center"><span id="A6.T22.1.18.4.1" class="ltx_text ltx_font_bold">1.04</span></td>
</tr>
<tr id="A6.T22.1.19" class="ltx_tr">
<td id="A6.T22.1.19.1" class="ltx_td ltx_align_left ltx_border_bb">17:</td>
<td id="A6.T22.1.19.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="A6.T22.1.19.2.1" class="ltx_text ltx_font_bold">MESAS</span></td>
<td id="A6.T22.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">85.12</td>
<td id="A6.T22.1.19.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A6.T22.1.19.4.1" class="ltx_text ltx_font_bold">0.70</span></td>
</tr>
</table>
</figure>
<div id="A6.SS1.p6" class="ltx_para">
<p id="A6.SS1.p6.1" class="ltx_p">Furthermore, we conducted additional experiments, where models were trained starting from a randomly initialized model for 100 rounds until reaching stability. The performance of the defense mechanisms, along with scenarios encompassing no defense and no attack, was analyzed and depicted in <a href="#A6.F13" title="Figure 13 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></span></a> and <a href="#A6.F14" title="Figure 14 ‣ F.1. Setting Independence or MESAS ‣ Appendix F Detailed Experimental Results ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></span></a>.<span id="footnote24" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">24</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">24</sup><span class="ltx_tag ltx_tag_note">24</span>We do not report results for Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>, since for our setup, the applied noise did influence the model so that the training process stopped at round five. Further, FLTrust is only reported till round 45, since afterward weights of zero are assigned to each update leading to a naïve model.</span></span></span> Notably, the results revealed that <span id="A6.SS1.p6.1.1" class="ltx_text">MESAS</span> consistently yielded the low BA values similar to the no-attack scenario, indicating that the backdoor was effectively prevented from being embedded in the final global model under <span id="A6.SS1.p6.1.2" class="ltx_text">MESAS</span>. In contrast, other defense approaches exhibited relatively higher BAs. Only FoolsGold <cite class="ltx_cite ltx_citemacro_citep">(Fung et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite> could reach low BAs in certain rounds, too. Note, that these BA values were obtained without the incorporation of adaptation mechanisms. Consequently, with the inclusion of adaptability in defense strategies (cf. <a href="#S5.SS2.SSS1" title="5.2.1. Circumvent Defenses ‣ 5.2. Defenses under Strong Adaptive Adversaries ‣ 5. Evaluation ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Sect. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.1</span></span></a>), the BAs for adaptive attacks could be further increased. Additionally, <span id="A6.SS1.p6.1.3" class="ltx_text">MESAS</span> did not compromise the overall MA of the system, thereby avoiding any significant downsides in its application. The preservation of MA further underscores the efficacy and advantages of <span id="A6.SS1.p6.1.4" class="ltx_text">MESAS</span>.</p>
</div>
<figure id="A6.F13" class="ltx_figure"><img src="/html/2306.03600/assets/x28.png" id="A6.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A6.F13.4.2.1" class="ltx_text" style="font-size:90%;">Figure 13</span>. </span><span id="A6.F13.2.1" class="ltx_text" style="font-size:90%;">MAs for different defenses over multiple FL rounds <math id="A6.F13.2.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="A6.F13.2.1.m1.1b"><mi id="A6.F13.2.1.m1.1.1" xref="A6.F13.2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A6.F13.2.1.m1.1c"><ci id="A6.F13.2.1.m1.1.1.cmml" xref="A6.F13.2.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.F13.2.1.m1.1d">r</annotation></semantics></math> in the default scenario.</span></figcaption>
</figure>
<figure id="A6.F14" class="ltx_figure"><img src="/html/2306.03600/assets/x29.png" id="A6.F14.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A6.F14.4.2.1" class="ltx_text" style="font-size:90%;">Figure 14</span>. </span><span id="A6.F14.2.1" class="ltx_text" style="font-size:90%;">BAs for different defenses over multiple FL rounds <math id="A6.F14.2.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="A6.F14.2.1.m1.1b"><mi id="A6.F14.2.1.m1.1.1" xref="A6.F14.2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A6.F14.2.1.m1.1c"><ci id="A6.F14.2.1.m1.1.1.cmml" xref="A6.F14.2.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.F14.2.1.m1.1d">r</annotation></semantics></math> in the default scenario.</span></figcaption>
</figure>
</section>
</section>
<section id="A7" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Hyper-Parameters of Experiments</h2>

<div id="A7.p1" class="ltx_para">
<p id="A7.p1.1" class="ltx_p">To provide a detailed and complete overview of our experimental settings, we will list some <span id="A7.p1.1.1" class="ltx_text">hyper-parameters</span> of the defenses in the following: For Flame <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2022c</a>)</cite>, the noising level is set to 0.001, as noted by the authors within the paper. For <span id="A7.p1.1.2" class="ltx_text">T-Mean</span> <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib115" title="" class="ltx_ref">2018</a>)</cite>, we trim the upper and lower 5% to get rid of outliers. The noise level of our differential privacy defense was set to 0.01. The threshold for both, Krum and <span id="A7.p1.1.3" class="ltx_text">M-Krum</span> <cite class="ltx_cite ltx_citemacro_citep">(Blanchard et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite> was set to 0.7 and the rate of clients considered for <span id="A7.p1.1.4" class="ltx_text">M-Krum</span> is 0.3.</p>
</div>
</section>
<section id="A8" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Assignment of Non-IID Distributions</h2>

<section id="A8.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">H.1. </span><span id="A8.SS1.1.1" class="ltx_text">Intra-client</span> <span id="A8.SS1.2.2" class="ltx_text">non-IID</span>
</h3>

<div id="A8.SS1.p1" class="ltx_para">
<p id="A8.SS1.p1.3" class="ltx_p"><span id="A8.SS1.p1.3.2" class="ltx_text">1-class</span> <span id="A8.SS1.p1.3.3" class="ltx_text">non-IID</span> assigns one main label class to the client, which has more samples than the remaining classes. To construct such scenarios, all labels in the clients dataset including the main label are first assigned equal sample frequencies. Then, the <span id="A8.SS1.p1.3.4" class="ltx_text ltx_font_italic">non-IID</span><span id="A8.SS1.p1.1.1" class="ltx_text ltx_font_italic"> rate <math id="A8.SS1.p1.1.1.m1.2" class="ltx_Math" alttext="q\in[0,1]" display="inline"><semantics id="A8.SS1.p1.1.1.m1.2a"><mrow id="A8.SS1.p1.1.1.m1.2.3" xref="A8.SS1.p1.1.1.m1.2.3.cmml"><mi id="A8.SS1.p1.1.1.m1.2.3.2" xref="A8.SS1.p1.1.1.m1.2.3.2.cmml">q</mi><mo id="A8.SS1.p1.1.1.m1.2.3.1" xref="A8.SS1.p1.1.1.m1.2.3.1.cmml">∈</mo><mrow id="A8.SS1.p1.1.1.m1.2.3.3.2" xref="A8.SS1.p1.1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="A8.SS1.p1.1.1.m1.2.3.3.2.1" xref="A8.SS1.p1.1.1.m1.2.3.3.1.cmml">[</mo><mn id="A8.SS1.p1.1.1.m1.1.1" xref="A8.SS1.p1.1.1.m1.1.1.cmml">0</mn><mo id="A8.SS1.p1.1.1.m1.2.3.3.2.2" xref="A8.SS1.p1.1.1.m1.2.3.3.1.cmml">,</mo><mn id="A8.SS1.p1.1.1.m1.2.2" xref="A8.SS1.p1.1.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="A8.SS1.p1.1.1.m1.2.3.3.2.3" xref="A8.SS1.p1.1.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A8.SS1.p1.1.1.m1.2b"><apply id="A8.SS1.p1.1.1.m1.2.3.cmml" xref="A8.SS1.p1.1.1.m1.2.3"><in id="A8.SS1.p1.1.1.m1.2.3.1.cmml" xref="A8.SS1.p1.1.1.m1.2.3.1"></in><ci id="A8.SS1.p1.1.1.m1.2.3.2.cmml" xref="A8.SS1.p1.1.1.m1.2.3.2">𝑞</ci><interval closure="closed" id="A8.SS1.p1.1.1.m1.2.3.3.1.cmml" xref="A8.SS1.p1.1.1.m1.2.3.3.2"><cn type="integer" id="A8.SS1.p1.1.1.m1.1.1.cmml" xref="A8.SS1.p1.1.1.m1.1.1">0</cn><cn type="integer" id="A8.SS1.p1.1.1.m1.2.2.cmml" xref="A8.SS1.p1.1.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS1.p1.1.1.m1.2c">q\in[0,1]</annotation></semantics></math></span> controls how many samples removed from all classes equally and reassigned to the main label to create a focus on this class. For <math id="A8.SS1.p1.2.m1.1" class="ltx_Math" alttext="q=0" display="inline"><semantics id="A8.SS1.p1.2.m1.1a"><mrow id="A8.SS1.p1.2.m1.1.1" xref="A8.SS1.p1.2.m1.1.1.cmml"><mi id="A8.SS1.p1.2.m1.1.1.2" xref="A8.SS1.p1.2.m1.1.1.2.cmml">q</mi><mo id="A8.SS1.p1.2.m1.1.1.1" xref="A8.SS1.p1.2.m1.1.1.1.cmml">=</mo><mn id="A8.SS1.p1.2.m1.1.1.3" xref="A8.SS1.p1.2.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A8.SS1.p1.2.m1.1b"><apply id="A8.SS1.p1.2.m1.1.1.cmml" xref="A8.SS1.p1.2.m1.1.1"><eq id="A8.SS1.p1.2.m1.1.1.1.cmml" xref="A8.SS1.p1.2.m1.1.1.1"></eq><ci id="A8.SS1.p1.2.m1.1.1.2.cmml" xref="A8.SS1.p1.2.m1.1.1.2">𝑞</ci><cn type="integer" id="A8.SS1.p1.2.m1.1.1.3.cmml" xref="A8.SS1.p1.2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS1.p1.2.m1.1c">q=0</annotation></semantics></math> all samples are uniformly distributed, hence an IID setting is created. For <math id="A8.SS1.p1.3.m2.1" class="ltx_Math" alttext="q=1" display="inline"><semantics id="A8.SS1.p1.3.m2.1a"><mrow id="A8.SS1.p1.3.m2.1.1" xref="A8.SS1.p1.3.m2.1.1.cmml"><mi id="A8.SS1.p1.3.m2.1.1.2" xref="A8.SS1.p1.3.m2.1.1.2.cmml">q</mi><mo id="A8.SS1.p1.3.m2.1.1.1" xref="A8.SS1.p1.3.m2.1.1.1.cmml">=</mo><mn id="A8.SS1.p1.3.m2.1.1.3" xref="A8.SS1.p1.3.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A8.SS1.p1.3.m2.1b"><apply id="A8.SS1.p1.3.m2.1.1.cmml" xref="A8.SS1.p1.3.m2.1.1"><eq id="A8.SS1.p1.3.m2.1.1.1.cmml" xref="A8.SS1.p1.3.m2.1.1.1"></eq><ci id="A8.SS1.p1.3.m2.1.1.2.cmml" xref="A8.SS1.p1.3.m2.1.1.2">𝑞</ci><cn type="integer" id="A8.SS1.p1.3.m2.1.1.3.cmml" xref="A8.SS1.p1.3.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS1.p1.3.m2.1c">q=1</annotation></semantics></math> only samples from the main label are contained in the dataset. An example of <span id="A8.SS1.p1.3.5" class="ltx_text">1-class</span> <span id="A8.SS1.p1.3.6" class="ltx_text">non-IID</span> is visualized in the classic <span id="A8.SS1.p1.3.7" class="ltx_text">non-IID</span> scenario in <a href="#S3.F1" title="Figure 1 ‣ 3.1. Threat Model ‣ 3. Problems and Definitions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Fig. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></span></a>. <span id="A8.SS1.p1.3.8" class="ltx_text">2-class</span> <span id="A8.SS1.p1.3.9" class="ltx_text">non-IID</span> works like <span id="A8.SS1.p1.3.10" class="ltx_text">1-class</span> <span id="A8.SS1.p1.3.11" class="ltx_text">non-IID</span>, but assigns two main labels simultaneously.
Distribution <span id="A8.SS1.p1.3.12" class="ltx_text">non-IID</span> defines the sampling frequency for each label with respect to a distribution. We leverage Dirichlet <cite class="ltx_cite ltx_citemacro_citep">(Minka, <a href="#bib.bib62" title="" class="ltx_ref">2000</a>)</cite> and normal distribution and assign the biggest value to the main label.</p>
</div>
</section>
<section id="A8.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">H.2. </span><span id="A8.SS2.1.1" class="ltx_text">Inter-client</span> <span id="A8.SS2.2.2" class="ltx_text">non-IID</span>
</h3>

<div id="A8.SS2.p1" class="ltx_para">
<p id="A8.SS2.p1.1" class="ltx_p">We generate <span id="A8.SS2.p1.1.1" class="ltx_text">inter-client</span> <span id="A8.SS2.p1.1.2" class="ltx_text">non-IID</span> datasets by assigning arbitrary datasets to clients. The <span id="A8.SS2.p1.1.3" class="ltx_text ltx_font_italic">Random-Non-IID</span> strategy first randomly decides for each label if it is contained in client’s local dataset by coin flip. Afterwards, we randomly generate a number between zero and one for each label that should be contained in the dataset. Then, we sum those random values and assign the relative percentage of the sum to the each label. Finally, those values can be converted to real sample frequencies by multiplying the percentage with the desired overall sample count of the client. This results in <span id="A8.SS2.p1.1.4" class="ltx_text">inter-client</span> <span id="A8.SS2.p1.1.5" class="ltx_text">non-IID</span> datasets even with disjoint data. The sample distribution of the setup within this paper is listed in <a href="#A8.T23" title="Table 23 ‣ H.2. Inter-client non-IID ‣ Appendix H Assignment of Non-IID Distributions ‣ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations" class="ltx_ref">Tab. <span class="ltx_ref"><span class="ltx_text ltx_ref_tag">23</span></span></a>.</p>
</div>
<div id="A8.SS2.p2" class="ltx_para">
<p id="A8.SS2.p2.1" class="ltx_p">Certainly, it is also possible to leverage different <span id="A8.SS2.p2.1.1" class="ltx_text">intra-client</span> <span id="A8.SS2.p2.1.2" class="ltx_text">non-IID</span> for each client’s dataset to generate <span id="A8.SS2.p2.1.3" class="ltx_text">inter-client</span> <span id="A8.SS2.p2.1.4" class="ltx_text">non-IID</span> scenarios, if one needs more control over the distributions.</p>
</div>
<figure id="A8.T23" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A8.T23.3.1.1" class="ltx_text" style="font-size:90%;">Table 23</span>. </span><span id="A8.T23.4.2" class="ltx_text" style="font-size:90%;">Sample frequencies for each label in the clients’ datasets for our <span id="A8.T23.4.2.1" class="ltx_text">Random-Non-IID</span> strategy.</span></figcaption>
<table id="A8.T23.5" class="ltx_tabular ltx_align_middle">
<tr id="A8.T23.5.1" class="ltx_tr">
<td id="A8.T23.5.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="A8.T23.5.1.1.1" class="ltx_text">Client</span></td>
<td id="A8.T23.5.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="10">Label</td>
</tr>
<tr id="A8.T23.5.2" class="ltx_tr">
<td id="A8.T23.5.2.1" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.2.2" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="A8.T23.5.2.3" class="ltx_td ltx_align_center ltx_border_r">2</td>
<td id="A8.T23.5.2.4" class="ltx_td ltx_align_center ltx_border_r">3</td>
<td id="A8.T23.5.2.5" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="A8.T23.5.2.6" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="A8.T23.5.2.7" class="ltx_td ltx_align_center ltx_border_r">6</td>
<td id="A8.T23.5.2.8" class="ltx_td ltx_align_center ltx_border_r">7</td>
<td id="A8.T23.5.2.9" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="A8.T23.5.2.10" class="ltx_td ltx_align_center">9</td>
</tr>
<tr id="A8.T23.5.3" class="ltx_tr">
<td id="A8.T23.5.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="A8.T23.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">598</td>
<td id="A8.T23.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="A8.T23.5.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">325</td>
<td id="A8.T23.5.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="A8.T23.5.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">259</td>
<td id="A8.T23.5.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">404</td>
<td id="A8.T23.5.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">511</td>
<td id="A8.T23.5.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">463</td>
<td id="A8.T23.5.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="A8.T23.5.3.11" class="ltx_td ltx_align_center ltx_border_t">0</td>
</tr>
<tr id="A8.T23.5.4" class="ltx_tr">
<td id="A8.T23.5.4.1" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="A8.T23.5.4.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.4.3" class="ltx_td ltx_align_center ltx_border_r">777</td>
<td id="A8.T23.5.4.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.4.5" class="ltx_td ltx_align_center ltx_border_r">494</td>
<td id="A8.T23.5.4.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.4.7" class="ltx_td ltx_align_center ltx_border_r">623</td>
<td id="A8.T23.5.4.8" class="ltx_td ltx_align_center ltx_border_r">666</td>
<td id="A8.T23.5.4.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.4.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.4.11" class="ltx_td ltx_align_center">0</td>
</tr>
<tr id="A8.T23.5.5" class="ltx_tr">
<td id="A8.T23.5.5.1" class="ltx_td ltx_align_center ltx_border_r">2</td>
<td id="A8.T23.5.5.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.5.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.5.4" class="ltx_td ltx_align_center ltx_border_r">919</td>
<td id="A8.T23.5.5.5" class="ltx_td ltx_align_center ltx_border_r">433</td>
<td id="A8.T23.5.5.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.5.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.5.8" class="ltx_td ltx_align_center ltx_border_r">770</td>
<td id="A8.T23.5.5.9" class="ltx_td ltx_align_center ltx_border_r">438</td>
<td id="A8.T23.5.5.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.5.11" class="ltx_td ltx_align_center">0</td>
</tr>
<tr id="A8.T23.5.6" class="ltx_tr">
<td id="A8.T23.5.6.1" class="ltx_td ltx_align_center ltx_border_r">3</td>
<td id="A8.T23.5.6.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.6.3" class="ltx_td ltx_align_center ltx_border_r">745</td>
<td id="A8.T23.5.6.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.6.5" class="ltx_td ltx_align_center ltx_border_r">1344</td>
<td id="A8.T23.5.6.6" class="ltx_td ltx_align_center ltx_border_r">392</td>
<td id="A8.T23.5.6.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.6.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.6.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.6.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.6.11" class="ltx_td ltx_align_center">79</td>
</tr>
<tr id="A8.T23.5.7" class="ltx_tr">
<td id="A8.T23.5.7.1" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="A8.T23.5.7.2" class="ltx_td ltx_align_center ltx_border_r">355</td>
<td id="A8.T23.5.7.3" class="ltx_td ltx_align_center ltx_border_r">95</td>
<td id="A8.T23.5.7.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.7.5" class="ltx_td ltx_align_center ltx_border_r">232</td>
<td id="A8.T23.5.7.6" class="ltx_td ltx_align_center ltx_border_r">814</td>
<td id="A8.T23.5.7.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.7.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.7.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.7.10" class="ltx_td ltx_align_center ltx_border_r">683</td>
<td id="A8.T23.5.7.11" class="ltx_td ltx_align_center">381</td>
</tr>
<tr id="A8.T23.5.8" class="ltx_tr">
<td id="A8.T23.5.8.1" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="A8.T23.5.8.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.8.3" class="ltx_td ltx_align_center ltx_border_r">203</td>
<td id="A8.T23.5.8.4" class="ltx_td ltx_align_center ltx_border_r">543</td>
<td id="A8.T23.5.8.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.8.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.8.7" class="ltx_td ltx_align_center ltx_border_r">599</td>
<td id="A8.T23.5.8.8" class="ltx_td ltx_align_center ltx_border_r">308</td>
<td id="A8.T23.5.8.9" class="ltx_td ltx_align_center ltx_border_r">400</td>
<td id="A8.T23.5.8.10" class="ltx_td ltx_align_center ltx_border_r">507</td>
<td id="A8.T23.5.8.11" class="ltx_td ltx_align_center">0</td>
</tr>
<tr id="A8.T23.5.9" class="ltx_tr">
<td id="A8.T23.5.9.1" class="ltx_td ltx_align_center ltx_border_r">6</td>
<td id="A8.T23.5.9.2" class="ltx_td ltx_align_center ltx_border_r">295</td>
<td id="A8.T23.5.9.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.9.4" class="ltx_td ltx_align_center ltx_border_r">827</td>
<td id="A8.T23.5.9.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.9.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.9.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.9.8" class="ltx_td ltx_align_center ltx_border_r">1438</td>
<td id="A8.T23.5.9.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.9.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.9.11" class="ltx_td ltx_align_center">0</td>
</tr>
<tr id="A8.T23.5.10" class="ltx_tr">
<td id="A8.T23.5.10.1" class="ltx_td ltx_align_center ltx_border_r">7</td>
<td id="A8.T23.5.10.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.10.3" class="ltx_td ltx_align_center ltx_border_r">1116</td>
<td id="A8.T23.5.10.4" class="ltx_td ltx_align_center ltx_border_r">84</td>
<td id="A8.T23.5.10.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.10.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.10.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.10.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.10.9" class="ltx_td ltx_align_center ltx_border_r">1360</td>
<td id="A8.T23.5.10.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.10.11" class="ltx_td ltx_align_center">0</td>
</tr>
<tr id="A8.T23.5.11" class="ltx_tr">
<td id="A8.T23.5.11.1" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="A8.T23.5.11.2" class="ltx_td ltx_align_center ltx_border_r">408</td>
<td id="A8.T23.5.11.3" class="ltx_td ltx_align_center ltx_border_r">454</td>
<td id="A8.T23.5.11.4" class="ltx_td ltx_align_center ltx_border_r">30</td>
<td id="A8.T23.5.11.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.11.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.11.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.11.8" class="ltx_td ltx_align_center ltx_border_r">279</td>
<td id="A8.T23.5.11.9" class="ltx_td ltx_align_center ltx_border_r">518</td>
<td id="A8.T23.5.11.10" class="ltx_td ltx_align_center ltx_border_r">538</td>
<td id="A8.T23.5.11.11" class="ltx_td ltx_align_center">333</td>
</tr>
<tr id="A8.T23.5.12" class="ltx_tr">
<td id="A8.T23.5.12.1" class="ltx_td ltx_align_center ltx_border_r">9</td>
<td id="A8.T23.5.12.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.12.3" class="ltx_td ltx_align_center ltx_border_r">431</td>
<td id="A8.T23.5.12.4" class="ltx_td ltx_align_center ltx_border_r">271</td>
<td id="A8.T23.5.12.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.12.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.12.7" class="ltx_td ltx_align_center ltx_border_r">206</td>
<td id="A8.T23.5.12.8" class="ltx_td ltx_align_center ltx_border_r">788</td>
<td id="A8.T23.5.12.9" class="ltx_td ltx_align_center ltx_border_r">36</td>
<td id="A8.T23.5.12.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.12.11" class="ltx_td ltx_align_center">828</td>
</tr>
<tr id="A8.T23.5.13" class="ltx_tr">
<td id="A8.T23.5.13.1" class="ltx_td ltx_align_center ltx_border_r">10</td>
<td id="A8.T23.5.13.2" class="ltx_td ltx_align_center ltx_border_r">715</td>
<td id="A8.T23.5.13.3" class="ltx_td ltx_align_center ltx_border_r">113</td>
<td id="A8.T23.5.13.4" class="ltx_td ltx_align_center ltx_border_r">431</td>
<td id="A8.T23.5.13.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.13.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.13.7" class="ltx_td ltx_align_center ltx_border_r">508</td>
<td id="A8.T23.5.13.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.13.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.13.10" class="ltx_td ltx_align_center ltx_border_r">476</td>
<td id="A8.T23.5.13.11" class="ltx_td ltx_align_center">317</td>
</tr>
<tr id="A8.T23.5.14" class="ltx_tr">
<td id="A8.T23.5.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11</td>
<td id="A8.T23.5.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">560</td>
<td id="A8.T23.5.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">424</td>
<td id="A8.T23.5.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">369</td>
<td id="A8.T23.5.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="A8.T23.5.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">343</td>
<td id="A8.T23.5.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="A8.T23.5.14.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">406</td>
<td id="A8.T23.5.14.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">89</td>
<td id="A8.T23.5.14.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">270</td>
<td id="A8.T23.5.14.11" class="ltx_td ltx_align_center ltx_border_t">99</td>
</tr>
<tr id="A8.T23.5.15" class="ltx_tr">
<td id="A8.T23.5.15.1" class="ltx_td ltx_align_center ltx_border_r">12</td>
<td id="A8.T23.5.15.2" class="ltx_td ltx_align_center ltx_border_r">99</td>
<td id="A8.T23.5.15.3" class="ltx_td ltx_align_center ltx_border_r">2461</td>
<td id="A8.T23.5.15.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.15.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.15.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.15.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.15.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.15.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.15.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.15.11" class="ltx_td ltx_align_center">0</td>
</tr>
<tr id="A8.T23.5.16" class="ltx_tr">
<td id="A8.T23.5.16.1" class="ltx_td ltx_align_center ltx_border_r">13</td>
<td id="A8.T23.5.16.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.16.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.16.4" class="ltx_td ltx_align_center ltx_border_r">595</td>
<td id="A8.T23.5.16.5" class="ltx_td ltx_align_center ltx_border_r">257</td>
<td id="A8.T23.5.16.6" class="ltx_td ltx_align_center ltx_border_r">172</td>
<td id="A8.T23.5.16.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.16.8" class="ltx_td ltx_align_center ltx_border_r">568</td>
<td id="A8.T23.5.16.9" class="ltx_td ltx_align_center ltx_border_r">206</td>
<td id="A8.T23.5.16.10" class="ltx_td ltx_align_center ltx_border_r">527</td>
<td id="A8.T23.5.16.11" class="ltx_td ltx_align_center">235</td>
</tr>
<tr id="A8.T23.5.17" class="ltx_tr">
<td id="A8.T23.5.17.1" class="ltx_td ltx_align_center ltx_border_r">14</td>
<td id="A8.T23.5.17.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.17.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.17.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.17.5" class="ltx_td ltx_align_center ltx_border_r">2047</td>
<td id="A8.T23.5.17.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.17.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.17.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.17.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.17.10" class="ltx_td ltx_align_center ltx_border_r">513</td>
<td id="A8.T23.5.17.11" class="ltx_td ltx_align_center">0</td>
</tr>
<tr id="A8.T23.5.18" class="ltx_tr">
<td id="A8.T23.5.18.1" class="ltx_td ltx_align_center ltx_border_r">15</td>
<td id="A8.T23.5.18.2" class="ltx_td ltx_align_center ltx_border_r">159</td>
<td id="A8.T23.5.18.3" class="ltx_td ltx_align_center ltx_border_r">149</td>
<td id="A8.T23.5.18.4" class="ltx_td ltx_align_center ltx_border_r">199</td>
<td id="A8.T23.5.18.5" class="ltx_td ltx_align_center ltx_border_r">546</td>
<td id="A8.T23.5.18.6" class="ltx_td ltx_align_center ltx_border_r">642</td>
<td id="A8.T23.5.18.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.18.8" class="ltx_td ltx_align_center ltx_border_r">447</td>
<td id="A8.T23.5.18.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.18.10" class="ltx_td ltx_align_center ltx_border_r">404</td>
<td id="A8.T23.5.18.11" class="ltx_td ltx_align_center">14</td>
</tr>
<tr id="A8.T23.5.19" class="ltx_tr">
<td id="A8.T23.5.19.1" class="ltx_td ltx_align_center ltx_border_r">16</td>
<td id="A8.T23.5.19.2" class="ltx_td ltx_align_center ltx_border_r">494</td>
<td id="A8.T23.5.19.3" class="ltx_td ltx_align_center ltx_border_r">254</td>
<td id="A8.T23.5.19.4" class="ltx_td ltx_align_center ltx_border_r">486</td>
<td id="A8.T23.5.19.5" class="ltx_td ltx_align_center ltx_border_r">388</td>
<td id="A8.T23.5.19.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.19.7" class="ltx_td ltx_align_center ltx_border_r">523</td>
<td id="A8.T23.5.19.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.19.9" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.19.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.19.11" class="ltx_td ltx_align_center">415</td>
</tr>
<tr id="A8.T23.5.20" class="ltx_tr">
<td id="A8.T23.5.20.1" class="ltx_td ltx_align_center ltx_border_r">17</td>
<td id="A8.T23.5.20.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.20.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.20.4" class="ltx_td ltx_align_center ltx_border_r">315</td>
<td id="A8.T23.5.20.5" class="ltx_td ltx_align_center ltx_border_r">947</td>
<td id="A8.T23.5.20.6" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.20.7" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.20.8" class="ltx_td ltx_align_center ltx_border_r">963</td>
<td id="A8.T23.5.20.9" class="ltx_td ltx_align_center ltx_border_r">209</td>
<td id="A8.T23.5.20.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.20.11" class="ltx_td ltx_align_center">126</td>
</tr>
<tr id="A8.T23.5.21" class="ltx_tr">
<td id="A8.T23.5.21.1" class="ltx_td ltx_align_center ltx_border_r">18</td>
<td id="A8.T23.5.21.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.21.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.21.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.21.5" class="ltx_td ltx_align_center ltx_border_r">271</td>
<td id="A8.T23.5.21.6" class="ltx_td ltx_align_center ltx_border_r">549</td>
<td id="A8.T23.5.21.7" class="ltx_td ltx_align_center ltx_border_r">509</td>
<td id="A8.T23.5.21.8" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.21.9" class="ltx_td ltx_align_center ltx_border_r">640</td>
<td id="A8.T23.5.21.10" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="A8.T23.5.21.11" class="ltx_td ltx_align_center">591</td>
</tr>
<tr id="A8.T23.5.22" class="ltx_tr">
<td id="A8.T23.5.22.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">19</td>
<td id="A8.T23.5.22.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0</td>
<td id="A8.T23.5.22.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">178</td>
<td id="A8.T23.5.22.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0</td>
<td id="A8.T23.5.22.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">677</td>
<td id="A8.T23.5.22.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0</td>
<td id="A8.T23.5.22.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0</td>
<td id="A8.T23.5.22.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">588</td>
<td id="A8.T23.5.22.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">285</td>
<td id="A8.T23.5.22.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">832</td>
<td id="A8.T23.5.22.11" class="ltx_td ltx_align_center ltx_border_bb">0</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.03599" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.03600" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.03600">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.03600" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.03601" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 02:34:32 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
