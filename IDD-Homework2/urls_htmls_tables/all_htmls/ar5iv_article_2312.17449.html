<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  DB-GPT: Empowering Database Interactions with Private Large Language Models
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Siqiao Xue
    <sup class="ltx_sup" id="id21.21.id1">
     <span class="ltx_text ltx_font_italic" id="id21.21.id1.1">
      ♢
     </span>
    </sup>
    , Caigao Jiang
    <sup class="ltx_sup" id="id22.22.id2">
     <span class="ltx_text ltx_font_italic" id="id22.22.id2.1">
      ♢
     </span>
    </sup>
    , Wenhui Shi
    <sup class="ltx_sup" id="id23.23.id3">
     <span class="ltx_text ltx_font_italic" id="id23.23.id3.1">
      ♢
     </span>
    </sup>
    , Fangyin Cheng
    <math alttext="{}^{\varheartsuit}" class="ltx_Math" display="inline" id="id4.4.m4.1">
     <semantics id="id4.4.m4.1a">
      <msup id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml">
       <mi id="id4.4.m4.1.1a" xref="id4.4.m4.1.1.cmml">
       </mi>
       <merror class="ltx_ERROR undefined undefined" id="id4.4.m4.1.1.1" xref="id4.4.m4.1.1.1b.cmml">
        <mtext id="id4.4.m4.1.1.1a" xref="id4.4.m4.1.1.1b.cmml">
         \varheartsuit
        </mtext>
       </merror>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id4.4.m4.1b">
       <apply id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1">
        <ci id="id4.4.m4.1.1.1b.cmml" xref="id4.4.m4.1.1.1">
         <merror class="ltx_ERROR undefined undefined" id="id4.4.m4.1.1.1.cmml" xref="id4.4.m4.1.1.1">
          <mtext id="id4.4.m4.1.1.1a.cmml" xref="id4.4.m4.1.1.1">
           \varheartsuit
          </mtext>
         </merror>
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id4.4.m4.1c">
       {}^{\varheartsuit}
      </annotation>
     </semantics>
    </math>
    , Keting Chen
    <sup class="ltx_sup" id="id24.24.id4">
     <span class="ltx_text ltx_font_italic" id="id24.24.id4.1">
      ♢
     </span>
    </sup>
    , Hongjun Yang
    <sup class="ltx_sup" id="id25.25.id5">
     <span class="ltx_text ltx_font_italic" id="id25.25.id5.1">
      ♢
     </span>
    </sup>
    ,
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="id10.10.4">
     Zhiping Zhang
     <sup class="ltx_sup" id="id10.10.4.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id10.10.4.1.1">
       ♡
      </span>
     </sup>
     , Jianshan He
     <sup class="ltx_sup" id="id10.10.4.2">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id10.10.4.2.1">
       ♢
      </span>
     </sup>
     , Hongyang Zhang
     <math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id9.9.3.m3.1">
      <semantics id="id9.9.3.m3.1a">
       <msup id="id9.9.3.m3.1.1" xref="id9.9.3.m3.1.1.cmml">
        <mi id="id9.9.3.m3.1.1a" xref="id9.9.3.m3.1.1.cmml">
        </mi>
        <merror class="ltx_ERROR undefined undefined" id="id9.9.3.m3.1.1.1" xref="id9.9.3.m3.1.1.1b.cmml">
         <mtext id="id9.9.3.m3.1.1.1a" xref="id9.9.3.m3.1.1.1b.cmml">
          \vardiamondsuit
         </mtext>
        </merror>
       </msup>
       <annotation-xml encoding="MathML-Content" id="id9.9.3.m3.1b">
        <apply id="id9.9.3.m3.1.1.cmml" xref="id9.9.3.m3.1.1">
         <ci id="id9.9.3.m3.1.1.1b.cmml" xref="id9.9.3.m3.1.1.1">
          <merror class="ltx_ERROR undefined undefined" id="id9.9.3.m3.1.1.1.cmml" xref="id9.9.3.m3.1.1.1">
           <mtext id="id9.9.3.m3.1.1.1a.cmml" xref="id9.9.3.m3.1.1.1">
            \vardiamondsuit
           </mtext>
          </merror>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="id9.9.3.m3.1c">
        {}^{\vardiamondsuit}
       </annotation>
      </semantics>
     </math>
     , Ganglin Wei
     <sup class="ltx_sup" id="id10.10.4.3">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id10.10.4.3.1">
       ♢
      </span>
     </sup>
     , Wang Zhao,
    </span>
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="id14.14.8">
     Fan Zhou
     <sup class="ltx_sup" id="id14.14.8.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id14.14.8.1.1">
       ♢
      </span>
     </sup>
     , Danrui Qi
     <sup class="ltx_sup" id="id14.14.8.2">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id14.14.8.2.1">
       ♣
      </span>
     </sup>
     , Hong Yi, Shaodong Liu
     <sup class="ltx_sup" id="id14.14.8.3">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id14.14.8.3.1">
       ♠
      </span>
     </sup>
     , Faqiang Chen
     <sup class="ltx_sup" id="id14.14.8.4">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id14.14.8.4.1">
       ♢,∗
      </span>
     </sup>
    </span>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id26.26.id6">
     <span class="ltx_text ltx_font_italic" id="id26.26.id6.1">
      ♢
     </span>
    </sup>
    Ant Group,
    <sup class="ltx_sup" id="id27.27.id7">
     <span class="ltx_text ltx_font_italic" id="id27.27.id7.1">
      ♡
     </span>
    </sup>
    Alibaba Group,
    <math alttext="{}^{\varheartsuit}" class="ltx_Math" display="inline" id="id17.17.m9.1">
     <semantics id="id17.17.m9.1a">
      <msup id="id17.17.m9.1.1" xref="id17.17.m9.1.1.cmml">
       <mi id="id17.17.m9.1.1a" xref="id17.17.m9.1.1.cmml">
       </mi>
       <merror class="ltx_ERROR undefined undefined" id="id17.17.m9.1.1.1" xref="id17.17.m9.1.1.1b.cmml">
        <mtext id="id17.17.m9.1.1.1a" xref="id17.17.m9.1.1.1b.cmml">
         \varheartsuit
        </mtext>
       </merror>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id17.17.m9.1b">
       <apply id="id17.17.m9.1.1.cmml" xref="id17.17.m9.1.1">
        <ci id="id17.17.m9.1.1.1b.cmml" xref="id17.17.m9.1.1.1">
         <merror class="ltx_ERROR undefined undefined" id="id17.17.m9.1.1.1.cmml" xref="id17.17.m9.1.1.1">
          <mtext id="id17.17.m9.1.1.1a.cmml" xref="id17.17.m9.1.1.1">
           \varheartsuit
          </mtext>
         </merror>
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id17.17.m9.1c">
       {}^{\varheartsuit}
      </annotation>
     </semantics>
    </math>
    JD Group,
    <sup class="ltx_sup" id="id28.28.id8">
     <span class="ltx_text ltx_font_italic" id="id28.28.id8.1">
      ♠
     </span>
    </sup>
    Meituan
    <br class="ltx_break"/>
    <math alttext="{}^{\vardiamondsuit}" class="ltx_Math" display="inline" id="id19.19.m11.1">
     <semantics id="id19.19.m11.1a">
      <msup id="id19.19.m11.1.1" xref="id19.19.m11.1.1.cmml">
       <mi id="id19.19.m11.1.1a" xref="id19.19.m11.1.1.cmml">
       </mi>
       <merror class="ltx_ERROR undefined undefined" id="id19.19.m11.1.1.1" xref="id19.19.m11.1.1.1b.cmml">
        <mtext id="id19.19.m11.1.1.1a" xref="id19.19.m11.1.1.1b.cmml">
         \vardiamondsuit
        </mtext>
       </merror>
      </msup>
      <annotation-xml encoding="MathML-Content" id="id19.19.m11.1b">
       <apply id="id19.19.m11.1.1.cmml" xref="id19.19.m11.1.1">
        <ci id="id19.19.m11.1.1.1b.cmml" xref="id19.19.m11.1.1.1">
         <merror class="ltx_ERROR undefined undefined" id="id19.19.m11.1.1.1.cmml" xref="id19.19.m11.1.1.1">
          <mtext id="id19.19.m11.1.1.1a.cmml" xref="id19.19.m11.1.1.1">
           \vardiamondsuit
          </mtext>
         </merror>
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="id19.19.m11.1c">
       {}^{\vardiamondsuit}
      </annotation>
     </semantics>
    </math>
    Southwestern University of Finance and Economics, China
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id29.29.id9">
     <span class="ltx_text ltx_font_italic" id="id29.29.id9.1">
      ♣
     </span>
    </sup>
    Simon Fraser University, Canada
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id30.30.id10">
     {siqiao.xsq,caigao.jcg,faqiang.cfq}@antgroup.com
     <br class="ltx_break"/>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id31.id1">
   The recent breakthroughs in large language models (LLMs) are positioned to transition many areas of software. Database technologies particularly have an important entanglement with LLMs as efficient and intuitive database interactions are paramount. In this paper, we present DB-GPT, a revolutionary and production-ready project that integrates LLMs with traditional database systems to enhance user experience and accessibility. DB-GPT is designed to understand natural language queries, provide context-aware responses, and generate complex SQL queries with high accuracy, making it an indispensable tool for users ranging from novice to expert. The core innovation in DB-GPT lies in its private LLM technology, which is fine-tuned on domain-specific corpora to maintain user privacy and ensure data security while offering the benefits of state-of-the-art LLMs. We detail the architecture of DB-GPT, which includes a novel retrieval augmented generation (RAG) knowledge system, an adaptive learning mechanism to continuously improve performance based on user feedback and a service-oriented multi-model framework (SMMF) with powerful data-driven agents. Our extensive experiments and user studies confirm that DB-GPT represents a paradigm shift in database interactions, offering a more natural, efficient, and secure way to engage with data repositories. The paper concludes with a discussion of the implications of DB-GPT framework on the future of human-database interaction and outlines potential avenues for further enhancements and applications in the field. The project code is available at
   <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/eosphoros-ai/DB-GPT" style="font-size:90%;" target="_blank" title="">
    https://github.com/eosphoros-ai/DB-GPT
   </a>
   . Experience DB-GPT for yourself by installing it with the instructions
   <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/eosphoros-ai/DB-GPT#install" style="font-size:90%;" target="_blank" title="">
    https://github.com/eosphoros-ai/DB-GPT#install
   </a>
   and view a concise 10-minute video at
   <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.youtube.com/watch?v=KYs4nTDzEhk" style="font-size:90%;" target="_blank" title="">
    https://www.youtube.com/watch?v=KYs4nTDzEhk
   </a>
   .
  </p>
 </div>
 <span class="ltx_note ltx_role_footnotetext" id="footnotex1">
  <sup class="ltx_note_mark">
   *
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     *
    </sup>
    <span class="ltx_note_type">
     footnotetext:
    </span>
    Corresponding author.
   </span>
  </span>
 </span>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Large language models (LLMs) such as ChatGPT
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al.,
     <a class="ltx_ref" href="#bib.bib4" title="">
      2020
     </a>
     )
    </cite>
    and GPT-4
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib29" title="">
      2023
     </a>
     )
    </cite>
    have showcased their remarkable capabilities in engaging in human-like communication and understanding complex queries, bringing a trend of incorporating LLMs in various fields
    <cite class="ltx_cite ltx_citemacro_citep">
     (Anil et al.,
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     ; Gunasekar et al.,
     <a class="ltx_ref" href="#bib.bib12" title="">
      2023
     </a>
     )
    </cite>
    . These models have been further enhanced by external tools, enabling them to search for relevant online information
    <cite class="ltx_cite ltx_citemacro_citep">
     (Nakano et al.,
     <a class="ltx_ref" href="#bib.bib27" title="">
      2021
     </a>
     ; Xue et al.,
     <a class="ltx_ref" href="#bib.bib48" title="">
      2023c
     </a>
     )
    </cite>
    , utilize tools
    <cite class="ltx_cite ltx_citemacro_citep">
     (Schick et al.,
     <a class="ltx_ref" href="#bib.bib33" title="">
      2023
     </a>
     )
    </cite>
    , and create more sophisticated applications
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib6" title="">
      2022
     </a>
     ; Wang et al.,
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023
     </a>
     ; Chu et al.,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     )
    </cite>
    . In the realm of databases, while traditional systems often demand a high degree of technical acumen and familiarity with domain-specific structural query languages (SQLs) for data access and manipulation, LLMs pave the way for natural language interfaces, enabling users to express through natural language queries and leading to more natural and intuitive database interactions.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Nonetheless, how to empower the database operations with LLMs to build powerful end-user applications still remains an open question. One straightforward approach, employed by most of existing works
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib6" title="">
      2022
     </a>
     ; Zhou et al.,
     <a class="ltx_ref" href="#bib.bib54" title="">
      2023
     </a>
     ; Hu et al.,
     <a class="ltx_ref" href="#bib.bib15" title="">
      2023
     </a>
     )
    </cite>
    , is to directly providing commonly used LLMs, such as GPT-4, with instructions on how to interact via few-short prompting or in-context learning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Wei et al.,
     <a class="ltx_ref" href="#bib.bib42" title="">
      2022
     </a>
     )
    </cite>
    . The advantages of this approach is, it is unlikely to over-fit to train data and is easy to adapt to new data while the disadvantages are the performance can be sub-optimal compared to the fine-tuned alternatives with median-sized LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sun et al.,
     <a class="ltx_ref" href="#bib.bib36" title="">
      2023
     </a>
     )
    </cite>
    . Moreover, to further facilitate the intelligent interactions with database, many works
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib6" title="">
      2022
     </a>
     ; Liu,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     ; Richards,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2022
     </a>
     )
    </cite>
    have incorporated the LLM-powered automated reasoning and decision process (a.k.a., agent) into the database applications. However, the knowledge agents are usually task-specific instead of task agnostic, limiting their use to a large scale. Meanwhile, though being important, the privacy-sensitive setup for LLM-centric database interactions have been under-investigated. The previous efforts
    <cite class="ltx_cite ltx_citemacro_citep">
     (Martínez et al.,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023
     </a>
     ; H2O.ai,
     <a class="ltx_ref" href="#bib.bib13" title="">
      2023
     </a>
     )
    </cite>
    are mostly general-purpose and not specially designed for database operations.
   </p>
  </div>
  <figure class="ltx_table" id="S1.T1">
   <div class="ltx_inline-block ltx_transformed_outer" id="S1.T1.1" style="width:924.4pt;height:137.7pt;vertical-align:-0.0pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-81.6pt,12.1pt) scale(0.85,0.85) ;">
     <table class="ltx_tabular ltx_align_middle" id="S1.T1.1.1">
      <tr class="ltx_tr" id="S1.T1.1.1.1">
       <td class="ltx_td ltx_border_tt" id="S1.T1.1.1.1.1">
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.1.2">
        LangChain
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.1.3">
        LlmaIndex
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.1.4">
        PrivateGPT
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.1.5">
        ChatDB
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.1.6">
        DB-GPT
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.2">
       <td class="ltx_td" id="S1.T1.1.1.2.1">
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.2.2">
        <cite class="ltx_cite ltx_citemacro_citep">
         (Chase,
         <a class="ltx_ref" href="#bib.bib6" title="">
          2022
         </a>
         )
        </cite>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.2.3">
        <cite class="ltx_cite ltx_citemacro_citep">
         (Liu,
         <a class="ltx_ref" href="#bib.bib23" title="">
          2022
         </a>
         )
        </cite>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.2.4">
        <cite class="ltx_cite ltx_citemacro_citep">
         (Martínez et al.,
         <a class="ltx_ref" href="#bib.bib24" title="">
          2023
         </a>
         )
        </cite>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.2.5">
        <cite class="ltx_cite ltx_citemacro_citep">
         (Hu et al.,
         <a class="ltx_ref" href="#bib.bib15" title="">
          2023
         </a>
         )
        </cite>
       </td>
       <td class="ltx_td" id="S1.T1.1.1.2.6">
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.3.1">
        Multi-LLM integration
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.3.2">
        <span class="ltx_text" id="S1.T1.1.1.3.2.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.3.3">
        <span class="ltx_text" id="S1.T1.1.1.3.3.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.3.4">
        <span class="ltx_text" id="S1.T1.1.1.3.4.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.3.5">
        <span class="ltx_text" id="S1.T1.1.1.3.5.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.3.6">
        <span class="ltx_text" id="S1.T1.1.1.3.6.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.4">
       <td class="ltx_td ltx_align_left" id="S1.T1.1.1.4.1">
        Text-to-SQL fine-tuned
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.2">
        <span class="ltx_text" id="S1.T1.1.1.4.2.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.3">
        <span class="ltx_text" id="S1.T1.1.1.4.3.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.4">
        <span class="ltx_text" id="S1.T1.1.1.4.4.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.5">
        <span class="ltx_text" id="S1.T1.1.1.4.5.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.4.6">
        <span class="ltx_text" id="S1.T1.1.1.4.6.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.5">
       <td class="ltx_td ltx_align_left" id="S1.T1.1.1.5.1">
        Multi-agent strategies
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.2">
        <span class="ltx_text" id="S1.T1.1.1.5.2.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.3">
        <span class="ltx_text" id="S1.T1.1.1.5.3.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.4">
        <span class="ltx_text" id="S1.T1.1.1.5.4.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.5">
        <span class="ltx_text" id="S1.T1.1.1.5.5.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.5.6">
        <span class="ltx_text" id="S1.T1.1.1.5.6.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.6">
       <td class="ltx_td ltx_align_left" id="S1.T1.1.1.6.1">
        Data privacy and security
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.2">
        <span class="ltx_text" id="S1.T1.1.1.6.2.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.3">
        <span class="ltx_text" id="S1.T1.1.1.6.3.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.4">
        <span class="ltx_text" id="S1.T1.1.1.6.4.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.5">
        <span class="ltx_text" id="S1.T1.1.1.6.5.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.6.6">
        <span class="ltx_text" id="S1.T1.1.1.6.6.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.7">
       <td class="ltx_td ltx_align_left" id="S1.T1.1.1.7.1">
        Multi-source knowledge
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.2">
        <span class="ltx_text" id="S1.T1.1.1.7.2.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.3">
        <span class="ltx_text" id="S1.T1.1.1.7.3.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.4">
        <span class="ltx_text" id="S1.T1.1.1.7.4.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.5">
        <span class="ltx_text" id="S1.T1.1.1.7.5.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.7.6">
        <span class="ltx_text" id="S1.T1.1.1.7.6.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.8">
       <td class="ltx_td ltx_align_left" id="S1.T1.1.1.8.1">
        Bilingual queries
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.8.2">
        <span class="ltx_text" id="S1.T1.1.1.8.2.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.8.3">
        <span class="ltx_text" id="S1.T1.1.1.8.3.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.8.4">
        <span class="ltx_text" id="S1.T1.1.1.8.4.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.8.5">
        <span class="ltx_text" id="S1.T1.1.1.8.5.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
       <td class="ltx_td ltx_align_center" id="S1.T1.1.1.8.6">
        <span class="ltx_text" id="S1.T1.1.1.8.6.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S1.T1.1.1.9">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S1.T1.1.1.9.1">
        Generative data analytics
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.1.9.2">
        <span class="ltx_text" id="S1.T1.1.1.9.2.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.1.9.3">
        <span class="ltx_text" id="S1.T1.1.1.9.3.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.1.9.4">
        <span class="ltx_text" id="S1.T1.1.1.9.4.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.1.9.5">
        <span class="ltx_text" id="S1.T1.1.1.9.5.1" style="color:#FF0000;">
         ✗
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S1.T1.1.1.9.6">
        <span class="ltx_text" id="S1.T1.1.1.9.6.1" style="color:#00FF00;">
         ✓
        </span>
       </td>
      </tr>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    Comparative summary of competing approaches on various dimensions.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    In this work, we introduce DB-GPT, an intelligent and production-ready project for LLM-augmented applications to ingest, structure, and access data with privatization technologies. DB-GPT harnesses not only the inherent natural language understanding and generation capabilities of LLMs but also continuously optimizes the data-driven engine through the agent and plugin mechanism. See
    <a class="ltx_ref" href="#S1.T1" title="In 1 Introduction ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    for a comparative summary of competitors. To summarize, DB-GPT has the following distinct merits:
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <p class="ltx_p ltx_align_center ltx_align_center" id="S1.F1.1.1">
    <span class="ltx_text" id="S1.F1.1.1.1">
     <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="141" id="S1.F1.1.1.1.g1" src="/html/2312.17449/assets/x1.png" width="461"/>
    </span>
   </p>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    The architecture of DB-GPT
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p4">
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">
        Privacy and security protection.
       </span>
       DB-GPT allows users to deploy on personal devices or local servers and run even in scenarios without Internet connection. No data leaves the execution environment at any point, completely eliminating the risk of data leakage. In addition, proxy de-identification
       <cite class="ltx_cite ltx_citemacro_citep">
        (Wang et al.,
        <a class="ltx_ref" href="#bib.bib38" title="">
         2016
        </a>
        )
       </cite>
       techniques are applied in data processing modules, which acts as an intermediary that obscures personal identifiers from datasets, thereby mitigating the risks of unauthorized access and exploitation of private information.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">
        Multi-source knowledge base question &amp; answering optimized.
       </span>
       In contrast to classical works
       <cite class="ltx_cite ltx_citemacro_citep">
        (Lan et al.,
        <a class="ltx_ref" href="#bib.bib20" title="">
         2022
        </a>
        )
       </cite>
       of knowledge base question &amp; answering (KBQA), DB-GPT builds a pipeline that ingests multi-source unstructured data (PDF’s, web pages, images, etc) into intermediate representations, stores them in a structured knowledge base, retrieves the most relevant pieces,
and generates a comprehensive natural language response given a query. The pipeline is efficiency-optimized, flexible in generation and accepts bilingual queries.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">
        Text-to-SQL fine-tuned.
       </span>
       To further enhance the generation capability, DB-GPT fine-tuned several commonly used LLMs (e.g., Llama-2
       <cite class="ltx_cite ltx_citemacro_citep">
        (Touvron et al.,
        <a class="ltx_ref" href="#bib.bib37" title="">
         2023
        </a>
        )
       </cite>
       , GLM
       <cite class="ltx_cite ltx_citemacro_citep">
        (Zeng et al.,
        <a class="ltx_ref" href="#bib.bib51" title="">
         2022
        </a>
        )
       </cite>
       ) for Text-to-SQL tasks. DB-GPT significantly lowers the barriers to users without the expertise of SQL when interacting with data. To the best of our knowledge, among related works, only LlamaIndex
       <cite class="ltx_cite ltx_citemacro_citep">
        (Liu,
        <a class="ltx_ref" href="#bib.bib23" title="">
         2022
        </a>
        )
       </cite>
       integrates such fine-tuned alternatives but it is not optimized for bilingual queries.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i4.p1">
      <p class="ltx_p" id="S1.I1.i4.p1.1">
       <span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">
        Knowledge agents and plugins integrated.
       </span>
       An “agent” is an automated reasoning and decision engine. As a production-ready project, DB-GPT enables the development and application of conversational agents with advanced data analytics, where these automated decisions help interactive use cases over the data. It also offers a variety of plugins of query and retrieval services to use as tools for interaction with data.
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    We rigorously evaluate DB-GPT on various benchmark tasks, such as Text-to-SQL and KBQA. Furthermore, we conduct case studies and surveys to assess the usability and preferences. DB-GPT outperforms the competitors for most of the dimensions.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   SYSTEM DESIGN
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    The overall pipeline of DB-GPT is depicted in
    <a class="ltx_ref" href="#S1.F1" title="In 1 Introduction ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      Figure
     </span>
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    . While building upon the general Retrieval-Augmented Generation (RAG) framework
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib6" title="">
      2022
     </a>
     ; Liu,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     ; Xue et al.,
     <a class="ltx_ref" href="#bib.bib48" title="">
      2023c
     </a>
     )
    </cite>
    , our DB-GPT system integrates our novel training and inference techniques, which
significantly enhance its overall performance and efficiency. In this
section, we delineate the design of each phase, including the model
architecture as well as training and inference paradigms.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Multi-source RAG for QA
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     While LLMs are usually trained on enormous bodies of open sourced or other parties’ proprietary data, RAG
     <cite class="ltx_cite ltx_citemacro_citep">
      (Lewis et al.,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2020
      </a>
      )
     </cite>
     is a technique for augmenting LLMs’ knowledge with additional and often private data. Shown in
     <a class="ltx_ref" href="#S2.F2" title="In 2.1 Multi-source RAG for QA ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       Figure
      </span>
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , our RAG pipeline consists of three stages: knowledge construction, knowledge retrieval and adaptive In-Contextual Learning (ICL)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Dong et al.,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2022
      </a>
      )
     </cite>
     strategies.
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F2">
    <p class="ltx_p ltx_align_center ltx_align_center" id="S2.F2.1.1">
     <span class="ltx_text" id="S2.F2.1.1.1">
      <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="81" id="S2.F2.1.1.1.g1" src="/html/2312.17449/assets/x2.png" width="461"/>
     </span>
    </p>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2:
     </span>
     The detailed RAG architecture in DB-GPT
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="S2.F5">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_3">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S2.F5.1" style="width:140.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="419" id="S2.F5.1.g1" src="/html/2312.17449/assets/rag_1_v125.png" width="598"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         Figure 3:
        </span>
        The pipeline of knowledge construction
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_3">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S2.F5.2" style="width:140.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="419" id="S2.F5.2.g1" src="/html/2312.17449/assets/rag_2_v125.png" width="598"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         Figure 4:
        </span>
        The pipeline of knowledge retrieval
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_3">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S2.F5.3" style="width:140.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="419" id="S2.F5.3.g1" src="/html/2312.17449/assets/rag_3_v125.png" width="598"/>
       <figcaption class="ltx_caption ltx_centering">
        <span class="ltx_tag ltx_tag_figure">
         Figure 5:
        </span>
        The pipeline of adaptive ICL and response generation
       </figcaption>
      </figure>
     </div>
    </div>
   </figure>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Knowledge Construction.
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.10">
      Our knowledge base
      <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.1.m1.1">
       <semantics id="S2.SS1.SSS0.Px1.p1.1.m1.1a">
        <mi class="ltx_font_mathcaligraphic" id="S2.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">
         𝒦
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.1.m1.1b">
         <ci id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1">
          𝒦
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.1.m1.1c">
         \mathcal{K}
        </annotation>
       </semantics>
      </math>
      is a collection of documents from various sources
      <math alttext="{\bm{\mathbf{d}}}^{\text{loc}}_{1},\ldots,{\bm{\mathbf{d}}}^{\text{loc}}_{N}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.2.m2.3">
       <semantics id="S2.SS1.SSS0.Px1.p1.2.m2.3a">
        <mrow id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.3.cmml">
         <msubsup id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.cmml">
          <mi id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.2.cmml">
           𝐝
          </mi>
          <mn id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.3.cmml">
           1
          </mn>
          <mtext id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.3a.cmml">
           loc
          </mtext>
         </msubsup>
         <mo id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.3.cmml">
          ,
         </mo>
         <mi id="S2.SS1.SSS0.Px1.p1.2.m2.1.1" mathvariant="normal" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">
          …
         </mi>
         <mo id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.4" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.3.cmml">
          ,
         </mo>
         <msubsup id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.cmml">
          <mi id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.2" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.2.cmml">
           𝐝
          </mi>
          <mi id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.3.cmml">
           N
          </mi>
          <mtext id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.3" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.3a.cmml">
           loc
          </mtext>
         </msubsup>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.2.m2.3b">
         <list id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2">
          <apply id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1">
           <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1">
            subscript
           </csymbol>
           <apply id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1">
            <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1">
             superscript
            </csymbol>
            <ci id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.2">
             𝐝
            </ci>
            <ci id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.3a.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.3">
             <mtext id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.2.3">
              loc
             </mtext>
            </ci>
           </apply>
           <cn id="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.3.cmml" type="integer" xref="S2.SS1.SSS0.Px1.p1.2.m2.2.2.1.1.3">
            1
           </cn>
          </apply>
          <ci id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1">
           …
          </ci>
          <apply id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2">
           <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2">
            subscript
           </csymbol>
           <apply id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2">
            <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2">
             superscript
            </csymbol>
            <ci id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.2">
             𝐝
            </ci>
            <ci id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.3a.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.3">
             <mtext id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.2.3">
              loc
             </mtext>
            </ci>
           </apply>
           <ci id="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.3.3.2.2.3">
            𝑁
           </ci>
          </apply>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.2.m2.3c">
         {\bm{\mathbf{d}}}^{\text{loc}}_{1},\ldots,{\bm{\mathbf{d}}}^{\text{loc}}_{N}
        </annotation>
       </semantics>
      </math>
      where the number of documents
      <math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.3.m3.1">
       <semantics id="S2.SS1.SSS0.Px1.p1.3.m3.1a">
        <mi id="S2.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">
         N
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.3.m3.1b">
         <ci id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1">
          𝑁
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.3.m3.1c">
         N
        </annotation>
       </semantics>
      </math>
      is large. Following
      <cite class="ltx_cite ltx_citemacro_citet">
       Chase (
       <a class="ltx_ref" href="#bib.bib6" title="">
        2022
       </a>
       )
      </cite>
      , we split each document
      <math alttext="{\bm{\mathbf{d}}}_{n}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.4.m4.1">
       <semantics id="S2.SS1.SSS0.Px1.p1.4.m4.1a">
        <msub id="S2.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">
         <mi id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml">
          𝐝
         </mi>
         <mi id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">
          n
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.4.m4.1b">
         <apply id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1">
          <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1">
           subscript
          </csymbol>
          <ci id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1.2">
           𝐝
          </ci>
          <ci id="S2.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.4.m4.1.1.3">
           𝑛
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.4.m4.1c">
         {\bm{\mathbf{d}}}_{n}
        </annotation>
       </semantics>
      </math>
      into multiple paragraphs
      <math alttext="{\bm{\mathbf{p}}}^{\text{loc}}_{n,1},\ldots,{\bm{\mathbf{p}}}^{\text{loc}}_{n,M_{n}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.5.m5.7">
       <semantics id="S2.SS1.SSS0.Px1.p1.5.m5.7a">
        <mrow id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.3.cmml">
         <msubsup id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.cmml">
          <mi id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.2.cmml">
           𝐩
          </mi>
          <mrow id="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.4" xref="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.3.cmml">
           <mi id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.1.1" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.1.1.cmml">
            n
           </mi>
           <mo id="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.4.1" xref="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.3.cmml">
            ,
           </mo>
           <mn id="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.2.cmml">
            1
           </mn>
          </mrow>
          <mtext id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.3" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.3a.cmml">
           loc
          </mtext>
         </msubsup>
         <mo id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.3" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.3.cmml">
          ,
         </mo>
         <mi id="S2.SS1.SSS0.Px1.p1.5.m5.5.5" mathvariant="normal" xref="S2.SS1.SSS0.Px1.p1.5.m5.5.5.cmml">
          …
         </mi>
         <mo id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.4" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.3.cmml">
          ,
         </mo>
         <msubsup id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.cmml">
          <mi id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.2.cmml">
           𝐩
          </mi>
          <mrow id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.3.cmml">
           <mi id="S2.SS1.SSS0.Px1.p1.5.m5.3.3.1.1" xref="S2.SS1.SSS0.Px1.p1.5.m5.3.3.1.1.cmml">
            n
           </mi>
           <mo id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.3.cmml">
            ,
           </mo>
           <msub id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.cmml">
            <mi id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.2" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.2.cmml">
             M
            </mi>
            <mi id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.3" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.3.cmml">
             n
            </mi>
           </msub>
          </mrow>
          <mtext id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.3" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.3a.cmml">
           loc
          </mtext>
         </msubsup>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.5.m5.7b">
         <list id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.3.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2">
          <apply id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1">
           <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1">
            subscript
           </csymbol>
           <apply id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1">
            <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1">
             superscript
            </csymbol>
            <ci id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.2">
             𝐩
            </ci>
            <ci id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.3a.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.3">
             <mtext id="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px1.p1.5.m5.6.6.1.1.2.3">
              loc
             </mtext>
            </ci>
           </apply>
           <list id="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.4">
            <ci id="S2.SS1.SSS0.Px1.p1.5.m5.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.1.1.1.1">
             𝑛
            </ci>
            <cn id="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.2.cmml" type="integer" xref="S2.SS1.SSS0.Px1.p1.5.m5.2.2.2.2">
             1
            </cn>
           </list>
          </apply>
          <ci id="S2.SS1.SSS0.Px1.p1.5.m5.5.5.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.5.5">
           …
          </ci>
          <apply id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2">
           <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2">
            subscript
           </csymbol>
           <apply id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2">
            <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2">
             superscript
            </csymbol>
            <ci id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.2">
             𝐩
            </ci>
            <ci id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.3a.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.3">
             <mtext id="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px1.p1.5.m5.7.7.2.2.2.3">
              loc
             </mtext>
            </ci>
           </apply>
           <list id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2">
            <ci id="S2.SS1.SSS0.Px1.p1.5.m5.3.3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.3.3.1.1">
             𝑛
            </ci>
            <apply id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1">
             <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1">
              subscript
             </csymbol>
             <ci id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.2">
              𝑀
             </ci>
             <ci id="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m5.4.4.2.2.1.3">
              𝑛
             </ci>
            </apply>
           </list>
          </apply>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.5.m5.7c">
         {\bm{\mathbf{p}}}^{\text{loc}}_{n,1},\ldots,{\bm{\mathbf{p}}}^{\text{loc}}_{n,M_{n}}
        </annotation>
       </semantics>
      </math>
      , where
      <math alttext="M_{n}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.6.m6.1">
       <semantics id="S2.SS1.SSS0.Px1.p1.6.m6.1a">
        <msub id="S2.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.cmml">
         <mi id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml">
          M
         </mi>
         <mi id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml">
          n
         </mi>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.6.m6.1b">
         <apply id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1">
          <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1">
           subscript
          </csymbol>
          <ci id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.2">
           𝑀
          </ci>
          <ci id="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m6.1.1.3">
           𝑛
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.6.m6.1c">
         M_{n}
        </annotation>
       </semantics>
      </math>
      (and
      <math alttext="m" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.7.m7.1">
       <semantics id="S2.SS1.SSS0.Px1.p1.7.m7.1a">
        <mi id="S2.SS1.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS1.SSS0.Px1.p1.7.m7.1.1.cmml">
         m
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.7.m7.1b">
         <ci id="S2.SS1.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m7.1.1">
          𝑚
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.7.m7.1c">
         m
        </annotation>
       </semantics>
      </math>
      below) denotes the index of paragraph for the
      <math alttext="n" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.8.m8.1">
       <semantics id="S2.SS1.SSS0.Px1.p1.8.m8.1a">
        <mi id="S2.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1.cmml">
         n
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.8.m8.1b">
         <ci id="S2.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m8.1.1">
          𝑛
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.8.m8.1c">
         n
        </annotation>
       </semantics>
      </math>
      -th document, and embed each paragraph into a multidimensional embedding
      <math alttext="{\bm{\mathbf{e}}}^{\text{loc}}_{n,m}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.9.m9.2">
       <semantics id="S2.SS1.SSS0.Px1.p1.9.m9.2a">
        <msubsup id="S2.SS1.SSS0.Px1.p1.9.m9.2.3" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3.cmml">
         <mi id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.2" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.2.cmml">
          𝐞
         </mi>
         <mrow id="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.4" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.3.cmml">
          <mi id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.1.1" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1.1.1.cmml">
           n
          </mi>
          <mo id="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.4.1" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.3.cmml">
           ,
          </mo>
          <mi id="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.2" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.2.cmml">
           m
          </mi>
         </mrow>
         <mtext id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.3" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.3a.cmml">
          loc
         </mtext>
        </msubsup>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.9.m9.2b">
         <apply id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3">
          <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3">
           subscript
          </csymbol>
          <apply id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3">
           <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3">
            superscript
           </csymbol>
           <ci id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.2">
            𝐞
           </ci>
           <ci id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.3a.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.3">
            <mtext id="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.3.2.3">
             loc
            </mtext>
           </ci>
          </apply>
          <list id="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.4">
           <ci id="S2.SS1.SSS0.Px1.p1.9.m9.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.1.1.1.1">
            𝑛
           </ci>
           <ci id="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m9.2.2.2.2">
            𝑚
           </ci>
          </list>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.9.m9.2c">
         {\bm{\mathbf{e}}}^{\text{loc}}_{n,m}
        </annotation>
       </semantics>
      </math>
      through a neural encoder
      <math alttext="f_{\text{key}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px1.p1.10.m10.1">
       <semantics id="S2.SS1.SSS0.Px1.p1.10.m10.1a">
        <msub id="S2.SS1.SSS0.Px1.p1.10.m10.1.1" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.cmml">
         <mi id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml">
          f
         </mi>
         <mtext id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3a.cmml">
          key
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.10.m10.1b">
         <apply id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1">
          <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1">
           subscript
          </csymbol>
          <ci id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.2">
           𝑓
          </ci>
          <ci id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3a.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3">
           <mtext id="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px1.p1.10.m10.1.1.3">
            key
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.10.m10.1c">
         f_{\text{key}}
        </annotation>
       </semantics>
      </math>
      . It is worth noting that, in addition to the existing vector-based knowledge representation, shown in
      <a class="ltx_ref" href="#S2.F5" title="In 2.1 Multi-source RAG for QA ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Figure
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      , DB-GPT also incorporates inverted index and graph index techniques to make it easy to accurately find contextually relevant data.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Knowledge Retrieval.
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.6">
      Illustrated in
      <a class="ltx_ref" href="#S2.F5" title="In 2.1 Multi-source RAG for QA ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Figure
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      , when a language query
      <math alttext="{\bm{\mathbf{x}}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.1.m1.1">
       <semantics id="S2.SS1.SSS0.Px2.p1.1.m1.1a">
        <mi id="S2.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">
         𝐱
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.1.m1.1b">
         <ci id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1">
          𝐱
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.1.m1.1c">
         {\bm{\mathbf{x}}}
        </annotation>
       </semantics>
      </math>
      comes, it is embedded into a vector
      <math alttext="{\bm{\mathbf{q}}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.2.m2.1">
       <semantics id="S2.SS1.SSS0.Px2.p1.2.m2.1a">
        <mi id="S2.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">
         𝐪
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.2.m2.1b">
         <ci id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1">
          𝐪
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.2.m2.1c">
         {\bm{\mathbf{q}}}
        </annotation>
       </semantics>
      </math>
      through another neural encoder
      <math alttext="f_{\text{query}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.3.m3.1">
       <semantics id="S2.SS1.SSS0.Px2.p1.3.m3.1a">
        <msub id="S2.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml">
         <mi id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml">
          f
         </mi>
         <mtext id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3a.cmml">
          query
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.3.m3.1b">
         <apply id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1">
          <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1">
           subscript
          </csymbol>
          <ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.2">
           𝑓
          </ci>
          <ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3a.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3">
           <mtext id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.3">
            query
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.3.m3.1c">
         f_{\text{query}}
        </annotation>
       </semantics>
      </math>
      and we retrieve the top
      <math alttext="K" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.4.m4.1">
       <semantics id="S2.SS1.SSS0.Px2.p1.4.m4.1a">
        <mi id="S2.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1.cmml">
         K
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.4.m4.1b">
         <ci id="S2.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m4.1.1">
          𝐾
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.4.m4.1c">
         K
        </annotation>
       </semantics>
      </math>
      relevant paragraphs from the knowledge base, where
      <math alttext="K" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.5.m5.1">
       <semantics id="S2.SS1.SSS0.Px2.p1.5.m5.1a">
        <mi id="S2.SS1.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1.cmml">
         K
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.5.m5.1b">
         <ci id="S2.SS1.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.5.m5.1.1">
          𝐾
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.5.m5.1c">
         K
        </annotation>
       </semantics>
      </math>
      is a hyperparameter. DG-GPT supports various retriever models, e.g., EmbeddingRetriever, which retrieve according to their cosine similarities, i.e.,
      <math alttext="{\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}/\|{\bm{\mathbf{q}}}\|\|{\bm{\mathbf{e}}}\|" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px2.p1.6.m6.2">
       <semantics id="S2.SS1.SSS0.Px2.p1.6.m6.2a">
        <mrow id="S2.SS1.SSS0.Px2.p1.6.m6.2.3" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.cmml">
         <mrow id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.cmml">
          <mrow id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.cmml">
           <msup id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.cmml">
            <mi id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.2.cmml">
             𝐪
            </mi>
            <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.3" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.3.cmml">
             ⊤
            </mo>
           </msup>
           <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.1" lspace="0em" rspace="0em" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.1.cmml">
            ​
           </mo>
           <mi id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.3" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.3.cmml">
            𝐞
           </mi>
          </mrow>
          <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.1" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.1.cmml">
           /
          </mo>
          <mrow id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.1.cmml">
           <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.2.1" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.1.1.cmml">
            ‖
           </mo>
           <mi id="S2.SS1.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1.cmml">
            𝐪
           </mi>
           <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.2.2" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.1.1.cmml">
            ‖
           </mo>
          </mrow>
         </mrow>
         <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.1" lspace="0em" rspace="0em" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.1.cmml">
          ​
         </mo>
         <mrow id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.1.cmml">
          <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.2.1" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.1.1.cmml">
           ‖
          </mo>
          <mi id="S2.SS1.SSS0.Px2.p1.6.m6.2.2" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.2.cmml">
           𝐞
          </mi>
          <mo id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.2.2" stretchy="false" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.1.1.cmml">
           ‖
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.6.m6.2b">
         <apply id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3">
          <times id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.1">
          </times>
          <apply id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2">
           <divide id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.1">
           </divide>
           <apply id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2">
            <times id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.1">
            </times>
            <apply id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2">
             <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2">
              superscript
             </csymbol>
             <ci id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.2">
              𝐪
             </ci>
             <csymbol cd="latexml" id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.2.3">
              top
             </csymbol>
            </apply>
            <ci id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.2.3">
             𝐞
            </ci>
           </apply>
           <apply id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.2">
            <csymbol cd="latexml" id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.2.3.2.1">
             norm
            </csymbol>
            <ci id="S2.SS1.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.1.1">
             𝐪
            </ci>
           </apply>
          </apply>
          <apply id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.2">
           <csymbol cd="latexml" id="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.3.3.2.1">
            norm
           </csymbol>
           <ci id="S2.SS1.SSS0.Px2.p1.6.m6.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.6.m6.2.2">
            𝐞
           </ci>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.6.m6.2c">
         {\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}/\|{\bm{\mathbf{q}}}\|\|{\bm{\mathbf{e}}}\|
        </annotation>
       </semantics>
      </math>
      , KeywordRetriever, which match keywords instead of whole sentences. In the following paragraphs, we assume EmbeddingRetriever is used by default.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Learning to Embed and Search.
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px3.p1.3">
      Following
      <cite class="ltx_cite ltx_citemacro_citet">
       Xue et al. (
       <a class="ltx_ref" href="#bib.bib48" title="">
        2023c
       </a>
       )
      </cite>
      , we confidently consider a higher similarity to signify a more relevant paragraph due to the
training of the encoders
      <math alttext="f_{\text{key}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.1.m1.1">
       <semantics id="S2.SS1.SSS0.Px3.p1.1.m1.1a">
        <msub id="S2.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">
         <mi id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.2" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml">
          f
         </mi>
         <mtext id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.3" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1.3a.cmml">
          key
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.1.m1.1b">
         <apply id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1.2">
           𝑓
          </ci>
          <ci id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.3a.cmml" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1.3">
           <mtext id="S2.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px3.p1.1.m1.1.1.3">
            key
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.1.m1.1c">
         f_{\text{key}}
        </annotation>
       </semantics>
      </math>
      and
      <math alttext="f_{\text{query}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.2.m2.1">
       <semantics id="S2.SS1.SSS0.Px3.p1.2.m2.1a">
        <msub id="S2.SS1.SSS0.Px3.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1.cmml">
         <mi id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.2" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1.2.cmml">
          f
         </mi>
         <mtext id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.3" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1.3a.cmml">
          query
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.2.m2.1b">
         <apply id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1.2">
           𝑓
          </ci>
          <ci id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.3a.cmml" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1.3">
           <mtext id="S2.SS1.SSS0.Px3.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S2.SS1.SSS0.Px3.p1.2.m2.1.1.3">
            query
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.2.m2.1c">
         f_{\text{query}}
        </annotation>
       </semantics>
      </math>
      . Their optimization is clarified in
      <a class="ltx_ref" href="#S3.SS2" title="3.2 Encoder in RAG ‣ 3 Models and Training ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Section
       </span>
       <span class="ltx_text ltx_ref_tag">
        3.2
       </span>
      </a>
      .
Intuitively, we want the dot products
      <math alttext="{\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px3.p1.3.m3.1">
       <semantics id="S2.SS1.SSS0.Px3.p1.3.m3.1a">
        <mrow id="S2.SS1.SSS0.Px3.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.cmml">
         <msup id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml">
          <mi id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.2" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.2.cmml">
           𝐪
          </mi>
          <mo id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.3" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.3.cmml">
           ⊤
          </mo>
         </msup>
         <mo id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.1" lspace="0em" rspace="0em" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.1.cmml">
          ​
         </mo>
         <mi id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.3" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml">
          𝐞
         </mi>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px3.p1.3.m3.1b">
         <apply id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1">
          <times id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.1">
          </times>
          <apply id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2">
           <csymbol cd="ambiguous" id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2">
            superscript
           </csymbol>
           <ci id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.2">
            𝐪
           </ci>
           <csymbol cd="latexml" id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.2.3">
            top
           </csymbol>
          </apply>
          <ci id="S2.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px3.p1.3.m3.1.1.3">
           𝐞
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px3.p1.3.m3.1c">
         {\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}
        </annotation>
       </semantics>
      </math>
      to be relatively large for the query-paragraph pairs that are actually relevant. Our encoders use Multilingual-E5-base model architecture
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wang et al.,
       <a class="ltx_ref" href="#bib.bib39" title="">
        2022a
       </a>
       )
      </cite>
      as we support billingual encoding documents.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS1.SSS0.Px4">
    <h4 class="ltx_title ltx_title_paragraph">
     Adaptive ICL and Generation by LLM.
    </h4>
    <div class="ltx_para" id="S2.SS1.SSS0.Px4.p1">
     <p class="ltx_p" id="S2.SS1.SSS0.Px4.p1.3">
      In this phase, our system performs the ICL
      <cite class="ltx_cite ltx_citemacro_citep">
       (Dong et al.,
       <a class="ltx_ref" href="#bib.bib10" title="">
        2022
       </a>
       )
      </cite>
      for response generation: it ranks the
      <math alttext="K" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px4.p1.1.m1.1">
       <semantics id="S2.SS1.SSS0.Px4.p1.1.m1.1a">
        <mi id="S2.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px4.p1.1.m1.1.1.cmml">
         K
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px4.p1.1.m1.1b">
         <ci id="S2.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px4.p1.1.m1.1.1">
          𝐾
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px4.p1.1.m1.1c">
         K
        </annotation>
       </semantics>
      </math>
      search results based on their cosine similarities with the query, then plugs the top
      <math alttext="J" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px4.p1.2.m2.1">
       <semantics id="S2.SS1.SSS0.Px4.p1.2.m2.1a">
        <mi id="S2.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px4.p1.2.m2.1.1.cmml">
         J
        </mi>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px4.p1.2.m2.1b">
         <ci id="S2.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px4.p1.2.m2.1.1">
          𝐽
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px4.p1.2.m2.1c">
         J
        </annotation>
       </semantics>
      </math>
      (where
      <math alttext="J\leq K" class="ltx_Math" display="inline" id="S2.SS1.SSS0.Px4.p1.3.m3.1">
       <semantics id="S2.SS1.SSS0.Px4.p1.3.m3.1a">
        <mrow id="S2.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1.cmml">
         <mi id="S2.SS1.SSS0.Px4.p1.3.m3.1.1.2" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml">
          J
         </mi>
         <mo id="S2.SS1.SSS0.Px4.p1.3.m3.1.1.1" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1.1.cmml">
          ≤
         </mo>
         <mi id="S2.SS1.SSS0.Px4.p1.3.m3.1.1.3" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml">
          K
         </mi>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px4.p1.3.m3.1b">
         <apply id="S2.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1">
          <leq id="S2.SS1.SSS0.Px4.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1.1">
          </leq>
          <ci id="S2.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1.2">
           𝐽
          </ci>
          <ci id="S2.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px4.p1.3.m3.1.1.3">
           𝐾
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px4.p1.3.m3.1c">
         J\leq K
        </annotation>
       </semantics>
      </math>
      ) results into the context part of the predefined prompt template and finally LLM generates a response. ICL is a technique used to improve LLMs’ performance in handling contextual information by incorporating additional context during the training or inference phase. The whole process is shown in
      <a class="ltx_ref" href="#S2.F5" title="In 2.1 Multi-source RAG for QA ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Figure
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      . ICL empowers language models with enhanced understanding of context, improved reasoning and inference skills, and tailored problem-solving capabilities. As the performance of ICL is sensitive to specific settings, including the prompting template, the
selection of in-context examples, and order of examples, and so on
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhao et al.,
       <a class="ltx_ref" href="#bib.bib52" title="">
        2021
       </a>
       )
      </cite>
      , in our DB-GPT system, we offers several strategies to formulate prompting template (see
      <span class="ltx_ref ltx_missing_label ltx_ref_self">
       LABEL:lst:en_template
      </span>
      for one example).
In addition, we apply the privacy protection measure to mask the personal information.
     </p>
    </div>
    <figure class="ltx_float ltx_lstlisting" id="LST1">
     <div class="ltx_listing ltx_lstlisting ltx_listing" id="LST1.1" style="background-color:#F5FFF9;">
      <div class="ltx_listing_data">
       <a download="" href="data:text/plain;base64,Q29udGV4dCBpbmZvcm1hdGlvbjoKe0NPTlRFWFRfUkVUUk9fMX0KQApcdmRvdHMKQAp7Q09OVEVYVF9SRVRST19LfQoKIEJhc2VkIG9uIHRoZSBnaXZlbiBpbmZvcm1hdGlvbiwgcGxlYXNlIHByb3ZpZGUgYSBjb25jaXNlIGFuZCBwcm9mZXNzaW9uYWwgcmVzcG9uc2UgdG8gdGhlIHVzZXIncyBxdWVzdGlvbi4gSWYgdGhlcmUgYXJlIG11bHRpcGxlIHF1ZXN0aW9ucyBpbiBhIHF1ZXJ5LCBwbGVhc2UgYW5zd2VyIGFsbCBvZiB0aGVtLiBJZiB0aGUgdXNlcidzIHF1ZXN0aW9uIGluY2x1ZGVzIGtleXdvcmRzIGxpa2UgJ3JlY2VudCcgb3IgJ2xhdGVzdCcgdG8gaW5kaWNhdGUgYSByZWNlbnQgdGltZSBmcmFtZSwgcGF5IGF0dGVudGlvbiB0byB0aGUgY29ycmVzcG9uZGVuY2UgYmV0d2VlbiB0aGUgY3VycmVudCBkYXRlIGFuZCB0aGUgZGF0ZSBvZiB0aGUgaW5mb3JtYXRpb24uIElmIGEgY2xlYXIgYW5zd2VyIGNhbm5vdCBiZSBkZXRlcm1pbmVkLCByZXNwb25kIHdpdGggIlVuYWJsZSB0byBhbnN3ZXIgdGhlIHF1ZXN0aW9uIGJhc2VkIG9uIHRoZSBpbmZvcm1hdGlvbiBwcm92aWRlZCIuIFlvdSBNVVNUIHJlc3BvbmQgaW4gdGhlIHNhbWUgbGFuZ3VhZ2UgYXMgdGhlIHF1ZXN0aW9uIQoKVGhlIHF1ZXN0aW9uIGlzOiB7UVVFU1RJT059Lg==">
        ⬇
       </a>
      </div>
      <div class="ltx_listingline" id="lstnumberx1">
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx1.1" style="font-size:90%;">
        Context
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx1.2" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx1.3" style="font-size:90%;">
        information
       </span>
       <span class="ltx_text" id="lstnumberx1.4" style="font-size:90%;">
        :
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx2">
       <span class="ltx_text" id="lstnumberx2.1" style="font-size:90%;">
        {
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx2.2" style="font-size:90%;">
        CONTEXT_RETRO_1
       </span>
       <span class="ltx_text" id="lstnumberx2.3" style="font-size:90%;">
        }
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx3">
       <span class="ltx_text" id="lstnumberx3.1" style="font-size:90%;">
        ⋮
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx4">
       <span class="ltx_text" id="lstnumberx4.1" style="font-size:90%;">
        {
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx4.2" style="font-size:90%;">
        CONTEXT_RETRO_K
       </span>
       <span class="ltx_text" id="lstnumberx4.3" style="font-size:90%;">
        }
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx5">
      </div>
      <div class="ltx_listingline" id="lstnumberx6">
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.1" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.2" style="font-size:90%;">
        Based
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.3" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.4" style="font-size:90%;">
        on
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.5" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.6" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.7" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.8" style="font-size:90%;">
        given
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.9" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.10" style="font-size:90%;">
        information
       </span>
       <span class="ltx_text" id="lstnumberx6.11" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.12" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.13" style="font-size:90%;">
        please
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.14" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.15" style="font-size:90%;">
        provide
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.16" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.17" style="font-size:90%;">
        a
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.18" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.19" style="font-size:90%;">
        concise
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.20" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.21" style="font-size:90%;">
        and
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.22" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.23" style="font-size:90%;">
        professional
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.24" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.25" style="font-size:90%;">
        response
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.26" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.27" style="font-size:90%;">
        to
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.28" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.29" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.30" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.31" style="font-size:90%;">
        user
       </span>
       <span class="ltx_text" id="lstnumberx6.32" style="font-size:90%;">
        ’
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.33" style="font-size:90%;">
        s
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.34" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.35" style="font-size:90%;">
        question
       </span>
       <span class="ltx_text" id="lstnumberx6.36" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.37" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.38" style="font-size:90%;">
        If
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.39" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.40" style="font-size:90%;">
        there
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.41" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.42" style="font-size:90%;">
        are
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.43" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.44" style="font-size:90%;">
        multiple
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.45" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.46" style="font-size:90%;">
        questions
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.47" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.48" style="font-size:90%;">
        in
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.49" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.50" style="font-size:90%;">
        a
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.51" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.52" style="font-size:90%;">
        query
       </span>
       <span class="ltx_text" id="lstnumberx6.53" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.54" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.55" style="font-size:90%;">
        please
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.56" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.57" style="font-size:90%;">
        answer
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.58" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.59" style="font-size:90%;">
        all
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.60" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.61" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.62" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.63" style="font-size:90%;">
        them
       </span>
       <span class="ltx_text" id="lstnumberx6.64" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.65" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.66" style="font-size:90%;">
        If
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.67" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.68" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.69" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.70" style="font-size:90%;">
        user
       </span>
       <span class="ltx_text" id="lstnumberx6.71" style="font-size:90%;">
        ’
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.72" style="font-size:90%;">
        s
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.73" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.74" style="font-size:90%;">
        question
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.75" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.76" style="font-size:90%;">
        includes
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.77" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.78" style="font-size:90%;">
        keywords
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.79" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.80" style="font-size:90%;">
        like
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.81" style="font-size:90%;">
       </span>
       <span class="ltx_text" id="lstnumberx6.82" style="font-size:90%;">
        ’
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.83" style="font-size:90%;">
        recent
       </span>
       <span class="ltx_text" id="lstnumberx6.84" style="font-size:90%;">
        ’
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.85" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.86" style="font-size:90%;">
        or
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.87" style="font-size:90%;">
       </span>
       <span class="ltx_text" id="lstnumberx6.88" style="font-size:90%;">
        ’
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.89" style="font-size:90%;">
        latest
       </span>
       <span class="ltx_text" id="lstnumberx6.90" style="font-size:90%;">
        ’
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.91" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.92" style="font-size:90%;">
        to
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.93" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.94" style="font-size:90%;">
        indicate
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.95" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.96" style="font-size:90%;">
        a
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.97" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.98" style="font-size:90%;">
        recent
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.99" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.100" style="font-size:90%;">
        time
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.101" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.102" style="font-size:90%;">
        frame
       </span>
       <span class="ltx_text" id="lstnumberx6.103" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.104" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.105" style="font-size:90%;">
        pay
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.106" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.107" style="font-size:90%;">
        attention
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.108" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.109" style="font-size:90%;">
        to
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.110" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.111" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.112" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.113" style="font-size:90%;">
        correspondence
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.114" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.115" style="font-size:90%;">
        between
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.116" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.117" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.118" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.119" style="font-size:90%;">
        current
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.120" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.121" style="font-size:90%;">
        date
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.122" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.123" style="font-size:90%;">
        and
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.124" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.125" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.126" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.127" style="font-size:90%;">
        date
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.128" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.129" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.130" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.131" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.132" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.133" style="font-size:90%;">
        information
       </span>
       <span class="ltx_text" id="lstnumberx6.134" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.135" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.136" style="font-size:90%;">
        If
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.137" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.138" style="font-size:90%;">
        a
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.139" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.140" style="font-size:90%;">
        clear
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.141" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.142" style="font-size:90%;">
        answer
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.143" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.144" style="font-size:90%;">
        cannot
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.145" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.146" style="font-size:90%;">
        be
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.147" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.148" style="font-size:90%;">
        determined
       </span>
       <span class="ltx_text" id="lstnumberx6.149" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.150" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.151" style="font-size:90%;">
        respond
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.152" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.153" style="font-size:90%;">
        with
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.154" style="font-size:90%;">
       </span>
       <span class="ltx_text" id="lstnumberx6.155" style="font-size:90%;">
        "
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.156" style="font-size:90%;">
        Unable
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.157" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.158" style="font-size:90%;">
        to
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.159" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.160" style="font-size:90%;">
        answer
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.161" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.162" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.163" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.164" style="font-size:90%;">
        question
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.165" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.166" style="font-size:90%;">
        based
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.167" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.168" style="font-size:90%;">
        on
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.169" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.170" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.171" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.172" style="font-size:90%;">
        information
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.173" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.174" style="font-size:90%;">
        provided
       </span>
       <span class="ltx_text" id="lstnumberx6.175" style="font-size:90%;">
        ".
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.176" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.177" style="font-size:90%;">
        You
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.178" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.179" style="font-size:90%;">
        MUST
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.180" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.181" style="font-size:90%;">
        respond
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.182" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.183" style="font-size:90%;">
        in
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.184" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.185" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.186" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.187" style="font-size:90%;">
        same
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.188" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.189" style="font-size:90%;">
        language
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.190" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.191" style="font-size:90%;">
        as
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.192" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.193" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx6.194" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx6.195" style="font-size:90%;">
        question
       </span>
       <span class="ltx_text" id="lstnumberx6.196" style="font-size:90%;">
        !
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx7">
      </div>
      <div class="ltx_listingline" id="lstnumberx8">
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.1" style="font-size:90%;">
        The
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx8.2" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.3" style="font-size:90%;">
        question
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx8.4" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.5" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text" id="lstnumberx8.6" style="font-size:90%;">
        :
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx8.7" style="font-size:90%;">
       </span>
       <span class="ltx_text" id="lstnumberx8.8" style="font-size:90%;">
        {
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx8.9" style="font-size:90%;">
        QUESTION
       </span>
       <span class="ltx_text" id="lstnumberx8.10" style="font-size:90%;">
        }.
       </span>
      </div>
     </div>
     <figcaption class="ltx_caption" style="background-color:#F5FFF9;">
      <span class="ltx_tag ltx_tag_float">
       Listing 1:
      </span>
      Prompt templates for LLM.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Deploy and Inference: Service-oriented Multi-model Framework
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Model-as-a-Service (MaaS) is a cloud-based AI approach that provides developers and businesses with access to pre-built, pre-trained machine learning models. In DB-GPT, in order to streamline model adaptation, enhance the efficiency, and optimize the performance of model deployment, we present the Service-oriented Multi-model Framework (SMMF), which provides a fast and easy-to-use platform for the deployment and inference for Multi-LLMs.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     SMMF consists of two principal components, namely the model inference layer and the model deployment layer. Specifically, the model inference layer is designed for accommodating various LLM inference platforms, including vLLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Kwon et al.,
      <a class="ltx_ref" href="#bib.bib19" title="">
       2023
      </a>
      )
     </cite>
     , HuggingFace Transformers (HF)
     <cite class="ltx_cite ltx_citemacro_citep">
      (
      <span class="ltx_ref ltx_missing_citation ltx_ref_self">
       hf
      </span>
      )
     </cite>
     , Text Generation Inference (TGI)
     <cite class="ltx_cite ltx_citemacro_citep">
      (Huggingface,
      <a class="ltx_ref" href="#bib.bib16" title="">
       2021
      </a>
      )
     </cite>
     , and TensorRT
     <cite class="ltx_cite ltx_citemacro_citep">
      (NVIDIA,
      <a class="ltx_ref" href="#bib.bib28" title="">
       2021
      </a>
      )
     </cite>
     . The model deployment layer serves as an intermediary between the underlying inference layer and the upper-level model serving functionalities.
    </p>
   </div>
   <section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Deployment Layer.
    </h4>
    <div class="ltx_para" id="S2.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">
      Within the context of the model deployment framework layer, a suite of integral elements can be identified. A duo composed of the API server alongside the model handler is tasked with providing potent model serving functions to the application stratum. Occupying a central position, the model controller is entrusted with the governance of metadata while also operating as the nexus for the extensive deployment architecture. Additionally, the model worker is of paramount importance, establishing a direct connection with the inference apparatus and the foundational setting, thereby ensuring a proficient performance of the implemented models.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Multi-agent Strategies
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     DB-GPT supports several roles to interact with data, such as data analyst, software engineer and database architect, providing the entire process of database operations along with carefully orchestrated Standard Operating Procedures (SOPs). Inspired by MetaGPT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hong et al.,
      <a class="ltx_ref" href="#bib.bib14" title="">
       2023
      </a>
      )
     </cite>
     , DB-GPT assigns distinct roles to individual agents, leveraging their strengths and specialties to tackle challenging tasks. It orchestrates collaboration between different LLM agents through a coordination mechanism, enabling them to communicate, share information, and collectively reason. Based on the Text-to-SQL fine-tuned LLM, DB-GPT enables the development and application of agents with advanced interaction ability with database. Besides, different from LlamaIndex, whose components offer more explicit, constrained behavior for specific use cases, DB-GPT empowers agents with stronger capability of general reasoning with less constraint.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.4
    </span>
    DB Plugins
   </h3>
   <div class="ltx_para" id="S2.SS4.p1">
    <p class="ltx_p" id="S2.SS4.p1.1">
     LLMs are undoubtedly powerful, yet they may not excel at every task. Instead of answering the questions directly, an LLM can perform multiple steps to gather the relevant information by incorporating plugins (also known as tools)
     <span class="ltx_note ltx_role_footnote" id="footnote1">
      <sup class="ltx_note_mark">
       1
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         1
        </sup>
        <span class="ltx_tag ltx_tag_note">
         1
        </span>
        In this paper, we interchangeably use these two terms.
       </span>
      </span>
     </span>
     . Different from general-purpose plugins
     <cite class="ltx_cite ltx_citemacro_citep">
      (Schick et al.,
      <a class="ltx_ref" href="#bib.bib33" title="">
       2023
      </a>
      )
     </cite>
     , DB-GPT’s plugins are predominantly rooted in database interaction modes. This design facilitates querying databases through natural language, streamlining user query expressions while reinforcing LLMs’ query comprehension and execution abilities. The database interaction mode comprises two components: the schema analyzer, which deciphers the schema into a structured representation comprehensible by LLMs, and the query executor, which executes SQL queries on the database based on LLMs’ natural language responses. Besides, DB-GPT also integrates with third party services, such as web search proposed in WebGPT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Nakano et al.,
      <a class="ltx_ref" href="#bib.bib27" title="">
       2021
      </a>
      )
     </cite>
     , executes tasks on another platform without leaving the chat. Empowered with these plugins, DB-GPT is able to conduct several end-to-end data analysis problems with strong generative ability (we call it
     <em class="ltx_emph ltx_font_italic" id="S2.SS4.p1.1.1">
      generative data analytics
     </em>
     in our context). See for illustrative examples.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Models and Training
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Text-to-SQL Fine-Tuning
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     Although LLMs,.e.g., CodeX
     <cite class="ltx_cite ltx_citemacro_citep">
      (Chen et al.,
      <a class="ltx_ref" href="#bib.bib7" title="">
       2021
      </a>
      )
     </cite>
     and ChatGPT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Liu et al.,
      <a class="ltx_ref" href="#bib.bib22" title="">
       2023
      </a>
      )
     </cite>
     , have shown successful results with ICL for Text-to-SQL, they still have a gap with the fine-tuned alternatives with median-sized LLMs
     <cite class="ltx_cite ltx_citemacro_citep">
      (Sun et al.,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2023
      </a>
      )
     </cite>
     . Therefore, it is necessary to adapt LLMs to domain specific Text-to-SQL data, so that LLMs can better
understand the format of prompt and yield further improved results.
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Model Architecture.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">
      We started with a pre-trained Qwen
      <cite class="ltx_cite ltx_citemacro_citep">
       (Bai et al.,
       <a class="ltx_ref" href="#bib.bib2" title="">
        2023
       </a>
       )
      </cite>
      that has been pre-trained using extensive English and Chinese corpora.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Dataset and Training.
    </h4>
    <div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">
      In our DB-GPT, we have designed a special module DB-GPT-Hub that encapsulates the pipeline of preprocessing records (via the tools introduced in
      <a class="ltx_ref" href="#S2.SS4" title="2.4 DB Plugins ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Section
       </span>
       <span class="ltx_text ltx_ref_tag">
        2.4
       </span>
      </a>
      ), model loading and fine-tuning. We fine-tune Qwen on Spider
      <cite class="ltx_cite ltx_citemacro_citep">
       (Yu et al.,
       <a class="ltx_ref" href="#bib.bib50" title="">
        2018
       </a>
       )
      </cite>
      train split with inputs including description of database and natural question (see
      <span class="ltx_ref ltx_missing_label ltx_ref_self">
       LABEL:lst:prompt_finetune
      </span>
      ), and the output is the target SQL.
     </p>
    </div>
    <figure class="ltx_float ltx_lstlisting" id="LST2">
     <div class="ltx_listing ltx_lstlisting ltx_listing" id="LST2.1" style="background-color:#F5FFF9;">
      <div class="ltx_listing_data">
       <a download="" href="data:text/plain;base64,eyJpbnN0cnVjdGlvbiI6ICJjb25jZXJ0X3NpbmdlciBjb250YWlucyB0YWJsZXMgc3VjaCBhcyBzdGFkaXVtLCBzaW5nZXIsIGNvbmNlcnQsIHNpbmdlcl9pbl9jb25jZXJ0LiBUYWJsZSBzdGFkaXVtIGhhcyBjb2x1bW5zIHN1Y2ggYXMgc3RhZGl1bV9pZCwgbG9jYXRpb24sIG5hbWUsIGNhcGFjaXR5LCBoaWdoZXN0LCBsb3dlc3QsIGF2ZXJhZ2UuIHN0YWRpdW1faWQgaXMgdGhlIHByaW1hcnkga2V5LiBUYWJsZSBzaW5nZXIgaGFzIGNvbHVtbnMgc3VjaCBhcyBzaW5nZXJfaWQsIG5hbWUsIGNvdW50cnksIHNvbmdfbmFtZSwgc29uZ19yZWxlYXNlX3llYXIsIGFnZSwgaXNfbWFsZS4gc2luZ2VyX2lkIGlzIHRoZSBwcmltYXJ5IGtleS4gVGFibGUgY29uY2VydCBoYXMgY29sdW1ucyBzdWNoIGFzIGNvbmNlcnRfaWQsIGNvbmNlcnRfbmFtZSwgdGhlbWUsIHN0YWRpdW1faWQsIHllYXIuIGNvbmNlcnRfaWQgaXMgdGhlIHByaW1hcnkga2V5LiBUYWJsZSBzaW5nZXJfaW5fY29uY2VydCBoYXMgY29sdW1ucyBzdWNoIGFzIGNvbmNlcnRfaWQsIHNpbmdlcl9pZC4gY29uY2VydF9pZCBpcyB0aGUgcHJpbWFyeSBrZXkuIFRoZSB5ZWFyIG9mIGNvbmNlcnQgaXMgdGhlIGZvcmVpZ24ga2V5IG9mIGxvY2F0aW9uIG9mIHN0YWRpdW0uIFRoZSBzdGFkaXVtX2lkIG9mIHNpbmdlcl9pbl9jb25jZXJ0IGlzIHRoZSBmb3JlaWduIGtleSBvZiBuYW1lIG9mIHNpbmdlci4gVGhlIHNpbmdlcl9pZCBvZiBzaW5nZXJfaW5fY29uY2VydCBpcyB0aGUgZm9yZWlnbiBrZXkgb2YgY29uY2VydF9uYW1lIG9mIGNvbmNlcnQuIiwKCiJpbnB1dCI6ICJIb3cgbWFueSBzaW5nZXJzIGRvIHdlIGhhdmU/IiwKCiJyZXNwb25zZSI6ICJzZWxlY3QgY291bnQoKikgZnJvbSBzaW5nZXIifQ==">
        ⬇
       </a>
      </div>
      <div class="ltx_listingline" id="lstnumberx9">
       <span class="ltx_text" id="lstnumberx9.1" style="font-size:90%;">
        {"
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.2" style="font-size:90%;">
        instruction
       </span>
       <span class="ltx_text" id="lstnumberx9.3" style="font-size:90%;">
        ":
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.4" style="font-size:90%;">
       </span>
       <span class="ltx_text" id="lstnumberx9.5" style="font-size:90%;">
        "
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.6" style="font-size:90%;">
        concert_singer
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.7" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.8" style="font-size:90%;">
        contains
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.9" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.10" style="font-size:90%;">
        tables
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.11" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.12" style="font-size:90%;">
        such
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.13" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.14" style="font-size:90%;">
        as
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.15" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.16" style="font-size:90%;">
        stadium
       </span>
       <span class="ltx_text" id="lstnumberx9.17" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.18" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.19" style="font-size:90%;">
        singer
       </span>
       <span class="ltx_text" id="lstnumberx9.20" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.21" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.22" style="font-size:90%;">
        concert
       </span>
       <span class="ltx_text" id="lstnumberx9.23" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.24" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.25" style="font-size:90%;">
        singer_in_concert
       </span>
       <span class="ltx_text" id="lstnumberx9.26" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.27" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.28" style="font-size:90%;">
        Table
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.29" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.30" style="font-size:90%;">
        stadium
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.31" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.32" style="font-size:90%;">
        has
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.33" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.34" style="font-size:90%;">
        columns
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.35" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.36" style="font-size:90%;">
        such
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.37" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.38" style="font-size:90%;">
        as
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.39" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.40" style="font-size:90%;">
        stadium_id
       </span>
       <span class="ltx_text" id="lstnumberx9.41" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.42" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.43" style="font-size:90%;">
        location
       </span>
       <span class="ltx_text" id="lstnumberx9.44" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.45" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.46" style="font-size:90%;">
        name
       </span>
       <span class="ltx_text" id="lstnumberx9.47" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.48" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.49" style="font-size:90%;">
        capacity
       </span>
       <span class="ltx_text" id="lstnumberx9.50" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.51" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.52" style="font-size:90%;">
        highest
       </span>
       <span class="ltx_text" id="lstnumberx9.53" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.54" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.55" style="font-size:90%;">
        lowest
       </span>
       <span class="ltx_text" id="lstnumberx9.56" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.57" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.58" style="font-size:90%;">
        average
       </span>
       <span class="ltx_text" id="lstnumberx9.59" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.60" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.61" style="font-size:90%;">
        stadium_id
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.62" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.63" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.64" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.65" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.66" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.67" style="font-size:90%;">
        primary
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.68" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.69" style="font-size:90%;">
        key
       </span>
       <span class="ltx_text" id="lstnumberx9.70" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.71" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.72" style="font-size:90%;">
        Table
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.73" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.74" style="font-size:90%;">
        singer
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.75" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.76" style="font-size:90%;">
        has
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.77" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.78" style="font-size:90%;">
        columns
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.79" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.80" style="font-size:90%;">
        such
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.81" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.82" style="font-size:90%;">
        as
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.83" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.84" style="font-size:90%;">
        singer_id
       </span>
       <span class="ltx_text" id="lstnumberx9.85" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.86" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.87" style="font-size:90%;">
        name
       </span>
       <span class="ltx_text" id="lstnumberx9.88" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.89" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.90" style="font-size:90%;">
        country
       </span>
       <span class="ltx_text" id="lstnumberx9.91" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.92" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.93" style="font-size:90%;">
        song_name
       </span>
       <span class="ltx_text" id="lstnumberx9.94" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.95" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.96" style="font-size:90%;">
        song_release_year
       </span>
       <span class="ltx_text" id="lstnumberx9.97" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.98" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.99" style="font-size:90%;">
        age
       </span>
       <span class="ltx_text" id="lstnumberx9.100" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.101" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.102" style="font-size:90%;">
        is_male
       </span>
       <span class="ltx_text" id="lstnumberx9.103" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.104" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.105" style="font-size:90%;">
        singer_id
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.106" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.107" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.108" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.109" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.110" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.111" style="font-size:90%;">
        primary
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.112" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.113" style="font-size:90%;">
        key
       </span>
       <span class="ltx_text" id="lstnumberx9.114" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.115" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.116" style="font-size:90%;">
        Table
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.117" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.118" style="font-size:90%;">
        concert
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.119" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.120" style="font-size:90%;">
        has
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.121" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.122" style="font-size:90%;">
        columns
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.123" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.124" style="font-size:90%;">
        such
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.125" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.126" style="font-size:90%;">
        as
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.127" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.128" style="font-size:90%;">
        concert_id
       </span>
       <span class="ltx_text" id="lstnumberx9.129" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.130" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.131" style="font-size:90%;">
        concert_name
       </span>
       <span class="ltx_text" id="lstnumberx9.132" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.133" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.134" style="font-size:90%;">
        theme
       </span>
       <span class="ltx_text" id="lstnumberx9.135" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.136" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.137" style="font-size:90%;">
        stadium_id
       </span>
       <span class="ltx_text" id="lstnumberx9.138" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.139" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.140" style="font-size:90%;">
        year
       </span>
       <span class="ltx_text" id="lstnumberx9.141" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.142" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.143" style="font-size:90%;">
        concert_id
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.144" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.145" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.146" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.147" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.148" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.149" style="font-size:90%;">
        primary
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.150" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.151" style="font-size:90%;">
        key
       </span>
       <span class="ltx_text" id="lstnumberx9.152" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.153" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.154" style="font-size:90%;">
        Table
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.155" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.156" style="font-size:90%;">
        singer_in_concert
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.157" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.158" style="font-size:90%;">
        has
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.159" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.160" style="font-size:90%;">
        columns
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.161" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.162" style="font-size:90%;">
        such
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.163" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.164" style="font-size:90%;">
        as
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.165" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.166" style="font-size:90%;">
        concert_id
       </span>
       <span class="ltx_text" id="lstnumberx9.167" style="font-size:90%;">
        ,
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.168" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.169" style="font-size:90%;">
        singer_id
       </span>
       <span class="ltx_text" id="lstnumberx9.170" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.171" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.172" style="font-size:90%;">
        concert_id
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.173" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.174" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.175" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.176" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.177" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.178" style="font-size:90%;">
        primary
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.179" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.180" style="font-size:90%;">
        key
       </span>
       <span class="ltx_text" id="lstnumberx9.181" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.182" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.183" style="font-size:90%;">
        The
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.184" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.185" style="font-size:90%;">
        year
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.186" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.187" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.188" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.189" style="font-size:90%;">
        concert
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.190" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.191" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.192" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.193" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.194" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.195" style="font-size:90%;">
        foreign
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.196" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.197" style="font-size:90%;">
        key
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.198" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.199" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.200" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.201" style="font-size:90%;">
        location
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.202" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.203" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.204" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.205" style="font-size:90%;">
        stadium
       </span>
       <span class="ltx_text" id="lstnumberx9.206" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.207" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.208" style="font-size:90%;">
        The
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.209" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.210" style="font-size:90%;">
        stadium_id
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.211" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.212" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.213" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.214" style="font-size:90%;">
        singer_in_concert
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.215" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.216" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.217" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.218" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.219" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.220" style="font-size:90%;">
        foreign
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.221" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.222" style="font-size:90%;">
        key
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.223" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.224" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.225" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.226" style="font-size:90%;">
        name
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.227" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.228" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.229" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.230" style="font-size:90%;">
        singer
       </span>
       <span class="ltx_text" id="lstnumberx9.231" style="font-size:90%;">
        .
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.232" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.233" style="font-size:90%;">
        The
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.234" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.235" style="font-size:90%;">
        singer_id
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.236" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.237" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.238" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.239" style="font-size:90%;">
        singer_in_concert
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.240" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.241" style="font-size:90%;">
        is
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.242" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.243" style="font-size:90%;">
        the
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.244" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.245" style="font-size:90%;">
        foreign
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.246" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.247" style="font-size:90%;">
        key
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.248" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.249" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.250" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.251" style="font-size:90%;">
        concert_name
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.252" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.253" style="font-size:90%;">
        of
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx9.254" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx9.255" style="font-size:90%;">
        concert
       </span>
       <span class="ltx_text" id="lstnumberx9.256" style="font-size:90%;">
        .",
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx10">
      </div>
      <div class="ltx_listingline" id="lstnumberx11">
       <span class="ltx_text" id="lstnumberx11.1" style="font-size:90%;">
        "
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.2" style="font-size:90%;">
        input
       </span>
       <span class="ltx_text" id="lstnumberx11.3" style="font-size:90%;">
        ":
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx11.4" style="font-size:90%;">
       </span>
       <span class="ltx_text" id="lstnumberx11.5" style="font-size:90%;">
        "
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.6" style="font-size:90%;">
        How
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx11.7" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.8" style="font-size:90%;">
        many
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx11.9" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.10" style="font-size:90%;">
        singers
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx11.11" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.12" style="font-size:90%;">
        do
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx11.13" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.14" style="font-size:90%;">
        we
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx11.15" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx11.16" style="font-size:90%;">
        have
       </span>
       <span class="ltx_text" id="lstnumberx11.17" style="font-size:90%;">
        ?",
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx12">
      </div>
      <div class="ltx_listingline" id="lstnumberx13">
       <span class="ltx_text" id="lstnumberx13.1" style="font-size:90%;">
        "
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.2" style="font-size:90%;">
        response
       </span>
       <span class="ltx_text" id="lstnumberx13.3" style="font-size:90%;">
        ":
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx13.4" style="font-size:90%;">
       </span>
       <span class="ltx_text" id="lstnumberx13.5" style="font-size:90%;">
        "
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.6" style="font-size:90%;">
        select
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx13.7" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.8" style="font-size:90%;">
        count
       </span>
       <span class="ltx_text" id="lstnumberx13.9" style="font-size:90%;">
        (*)
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx13.10" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.11" style="font-size:90%;">
        from
       </span>
       <span class="ltx_text ltx_lst_space" id="lstnumberx13.12" style="font-size:90%;">
       </span>
       <span class="ltx_text ltx_lst_identifier" id="lstnumberx13.13" style="font-size:90%;">
        singer
       </span>
       <span class="ltx_text" id="lstnumberx13.14" style="font-size:90%;">
        "}
       </span>
      </div>
     </div>
     <figcaption class="ltx_caption" style="background-color:#F5FFF9;">
      <span class="ltx_tag ltx_tag_float">
       Listing 2:
      </span>
      Format of the input for Text-to-SQL fine-tuning.
     </figcaption>
    </figure>
    <div class="ltx_para" id="S3.SS1.SSS0.Px2.p2">
     <p class="ltx_p" id="S3.SS1.SSS0.Px2.p2.1">
      The full details of architecture and evaluation of fine-tuning LLMs for Text-to-SQL can be found in another paper that we will publish soon.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Encoder in RAG
   </h3>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Model Architecture.
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.2">
      The key and query encoders
      <math alttext="f_{\text{key}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.1.m1.1">
       <semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a">
        <msub id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">
         <mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">
          f
         </mi>
         <mtext id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3a.cmml">
          key
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b">
         <apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2">
           𝑓
          </ci>
          <ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3">
           <mtext id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3">
            key
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">
         f_{\text{key}}
        </annotation>
       </semantics>
      </math>
      and
      <math alttext="f_{\text{query}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.2.m2.1">
       <semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a">
        <msub id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">
         <mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">
          f
         </mi>
         <mtext id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3a.cmml">
          query
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b">
         <apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2">
           𝑓
          </ci>
          <ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3a.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3">
           <mtext id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3">
            query
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">
         f_{\text{query}}
        </annotation>
       </semantics>
      </math>
      are initialized as Multilingual-E5-base (ME5) model architecture
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wang et al.,
       <a class="ltx_ref" href="#bib.bib39" title="">
        2022a
       </a>
       )
      </cite>
      as we support bilingual applications.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS0.Px1.p2">
     <p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.5">
      Their optimization involves maximizing a well-defined objective:
     </p>
     <table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A3.EGx1">
      <tbody id="S3.E1">
       <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
        <td class="ltx_eqn_cell ltx_eqn_center_padleft">
        </td>
        <td class="ltx_td ltx_align_right ltx_eqn_cell">
         <math alttext="\displaystyle\ell={\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}_{0}-\log\sum_{i=0}^{I}\exp\left({\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}_{i}\right)," class="ltx_Math" display="inline" id="S3.E1.m1.2">
          <semantics id="S3.E1.m1.2a">
           <mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml">
            <mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml">
             <mi id="S3.E1.m1.2.2.1.1.3" mathvariant="normal" xref="S3.E1.m1.2.2.1.1.3.cmml">
              ℓ
             </mi>
             <mo id="S3.E1.m1.2.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.cmml">
              =
             </mo>
             <mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml">
              <mrow id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.3.cmml">
               <msup id="S3.E1.m1.2.2.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.3.2.cmml">
                <mi id="S3.E1.m1.2.2.1.1.1.3.2.2" xref="S3.E1.m1.2.2.1.1.1.3.2.2.cmml">
                 𝐪
                </mi>
                <mo id="S3.E1.m1.2.2.1.1.1.3.2.3" xref="S3.E1.m1.2.2.1.1.1.3.2.3.cmml">
                 ⊤
                </mo>
               </msup>
               <mo id="S3.E1.m1.2.2.1.1.1.3.1" lspace="0em" rspace="0em" xref="S3.E1.m1.2.2.1.1.1.3.1.cmml">
                ​
               </mo>
               <msub id="S3.E1.m1.2.2.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.3.3.cmml">
                <mi id="S3.E1.m1.2.2.1.1.1.3.3.2" xref="S3.E1.m1.2.2.1.1.1.3.3.2.cmml">
                 𝐞
                </mi>
                <mn id="S3.E1.m1.2.2.1.1.1.3.3.3" xref="S3.E1.m1.2.2.1.1.1.3.3.3.cmml">
                 0
                </mn>
               </msub>
              </mrow>
              <mo id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.2.cmml">
               −
              </mo>
              <mrow id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml">
               <mi id="S3.E1.m1.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.cmml">
                log
               </mi>
               <mo id="S3.E1.m1.2.2.1.1.1.1.2" lspace="0.167em" rspace="0em" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml">
                ​
               </mo>
               <mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml">
                <mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml">
                 <munderover id="S3.E1.m1.2.2.1.1.1.1.1.2a" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml">
                  <mo id="S3.E1.m1.2.2.1.1.1.1.1.2.2.2" movablelimits="false" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.2.cmml">
                   ∑
                  </mo>
                  <mrow id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.cmml">
                   <mi id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.2.cmml">
                    i
                   </mi>
                   <mo id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.1" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.1.cmml">
                    =
                   </mo>
                   <mn id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.3.cmml">
                    0
                   </mn>
                  </mrow>
                  <mi id="S3.E1.m1.2.2.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.cmml">
                   I
                  </mi>
                 </munderover>
                </mstyle>
                <mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">
                 <mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">
                  exp
                 </mi>
                 <mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1a" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">
                  ⁡
                 </mo>
                 <mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">
                  <mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">
                   (
                  </mo>
                  <mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">
                   <msup id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">
                    <mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml">
                     𝐪
                    </mi>
                    <mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">
                     ⊤
                    </mo>
                   </msup>
                   <mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">
                    ​
                   </mo>
                   <msub id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">
                    <mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.2.cmml">
                     𝐞
                    </mi>
                    <mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.3.cmml">
                     i
                    </mi>
                   </msub>
                  </mrow>
                  <mo id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml">
                   )
                  </mo>
                 </mrow>
                </mrow>
               </mrow>
              </mrow>
             </mrow>
            </mrow>
            <mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">
             ,
            </mo>
           </mrow>
           <annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b">
            <apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1">
             <eq id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2">
             </eq>
             <ci id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3">
              ℓ
             </ci>
             <apply id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1">
              <minus id="S3.E1.m1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.2">
              </minus>
              <apply id="S3.E1.m1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3">
               <times id="S3.E1.m1.2.2.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.3.1">
               </times>
               <apply id="S3.E1.m1.2.2.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.3.2">
                <csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.3.2">
                 superscript
                </csymbol>
                <ci id="S3.E1.m1.2.2.1.1.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.3.2.2">
                 𝐪
                </ci>
                <csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.1.3.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3.2.3">
                 top
                </csymbol>
               </apply>
               <apply id="S3.E1.m1.2.2.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3.3">
                <csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.3.3">
                 subscript
                </csymbol>
                <ci id="S3.E1.m1.2.2.1.1.1.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.3.3.2">
                 𝐞
                </ci>
                <cn id="S3.E1.m1.2.2.1.1.1.3.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.3.3.3">
                 0
                </cn>
               </apply>
              </apply>
              <apply id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1">
               <times id="S3.E1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2">
               </times>
               <log id="S3.E1.m1.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3">
               </log>
               <apply id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1">
                <apply id="S3.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2">
                 <csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2">
                  superscript
                 </csymbol>
                 <apply id="S3.E1.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2">
                  <csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2">
                   subscript
                  </csymbol>
                  <sum id="S3.E1.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.2">
                  </sum>
                  <apply id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3">
                   <eq id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.1">
                   </eq>
                   <ci id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.2">
                    𝑖
                   </ci>
                   <cn id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.3">
                    0
                   </cn>
                  </apply>
                 </apply>
                 <ci id="S3.E1.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3">
                  𝐼
                 </ci>
                </apply>
                <apply id="S3.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1">
                 <exp id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">
                 </exp>
                 <apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1">
                  <times id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1">
                  </times>
                  <apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2">
                   <csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2">
                    superscript
                   </csymbol>
                   <ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.2">
                    𝐪
                   </ci>
                   <csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.3">
                    top
                   </csymbol>
                  </apply>
                  <apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3">
                   <csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3">
                    subscript
                   </csymbol>
                   <ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.2">
                    𝐞
                   </ci>
                   <ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.3">
                    𝑖
                   </ci>
                  </apply>
                 </apply>
                </apply>
               </apply>
              </apply>
             </apply>
            </apply>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="S3.E1.m1.2c">
            \displaystyle\ell={\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}_{0}-\log\sum_{i=0}^{I}\exp\left({\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}_{i}\right),
           </annotation>
          </semantics>
         </math>
        </td>
        <td class="ltx_eqn_cell ltx_eqn_center_padright">
        </td>
        <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
         <span class="ltx_tag ltx_tag_equation ltx_align_right">
          (1)
         </span>
        </td>
       </tr>
      </tbody>
     </table>
     <p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.4">
      where
      <math alttext="{\bm{\mathbf{e}}}_{0}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p2.1.m1.1">
       <semantics id="S3.SS2.SSS0.Px1.p2.1.m1.1a">
        <msub id="S3.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml">
         <mi id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml">
          𝐞
         </mi>
         <mn id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml">
          0
         </mn>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.1.m1.1b">
         <apply id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1">
          <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2">
           𝐞
          </ci>
          <cn id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3">
           0
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.1.m1.1c">
         {\bm{\mathbf{e}}}_{0}
        </annotation>
       </semantics>
      </math>
      is the embedding of the paragraph known to contain relevant information for the query, and the other
      <math alttext="I" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p2.2.m2.1">
       <semantics id="S3.SS2.SSS0.Px1.p2.2.m2.1a">
        <mi id="S3.SS2.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.cmml">
         I
        </mi>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.2.m2.1b">
         <ci id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1">
          𝐼
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.2.m2.1c">
         I
        </annotation>
       </semantics>
      </math>
      embeddings
      <math alttext="{\bm{\mathbf{e}}}_{1},\ldots,{\bm{\mathbf{e}}}_{I}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p2.3.m3.3">
       <semantics id="S3.SS2.SSS0.Px1.p2.3.m3.3a">
        <mrow id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.3.cmml">
         <msub id="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1" xref="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.cmml">
          <mi id="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.2.cmml">
           𝐞
          </mi>
          <mn id="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.3" xref="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.3" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.3.cmml">
          ,
         </mo>
         <mi id="S3.SS2.SSS0.Px1.p2.3.m3.1.1" mathvariant="normal" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.cmml">
          …
         </mi>
         <mo id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.4" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.3.cmml">
          ,
         </mo>
         <msub id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.cmml">
          <mi id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.2.cmml">
           𝐞
          </mi>
          <mi id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.3" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.3.cmml">
           I
          </mi>
         </msub>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.3.m3.3b">
         <list id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2">
          <apply id="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1">
           <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.2">
            𝐞
           </ci>
           <cn id="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p2.3.m3.2.2.1.1.3">
            1
           </cn>
          </apply>
          <ci id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1">
           …
          </ci>
          <apply id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2">
           <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2">
            subscript
           </csymbol>
           <ci id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.2">
            𝐞
           </ci>
           <ci id="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.3.3.2.2.3">
            𝐼
           </ci>
          </apply>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.3.m3.3c">
         {\bm{\mathbf{e}}}_{1},\ldots,{\bm{\mathbf{e}}}_{I}
        </annotation>
       </semantics>
      </math>
      belong to a set of negative paragraphs (see
      <a class="ltx_ref" href="#S3.SS2" title="3.2 Encoder in RAG ‣ 3 Models and Training ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Section
       </span>
       <span class="ltx_text ltx_ref_tag">
        3.2
       </span>
      </a>
      for how they are selected).
By optimizing
      <a class="ltx_ref" href="#S3.E1" title="In Model Architecture. ‣ 3.2 Encoder in RAG ‣ 3 Models and Training ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Equation
       </span>
       <span class="ltx_text ltx_ref_tag">
        1
       </span>
      </a>
      , the dot products
      <math alttext="{\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p2.4.m4.1">
       <semantics id="S3.SS2.SSS0.Px1.p2.4.m4.1a">
        <mrow id="S3.SS2.SSS0.Px1.p2.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.cmml">
         <msup id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml">
          <mi id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.2.cmml">
           𝐪
          </mi>
          <mo id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.3" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.3.cmml">
           ⊤
          </mo>
         </msup>
         <mo id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1" lspace="0em" rspace="0em" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.cmml">
          ​
         </mo>
         <mi id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml">
          𝐞
         </mi>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.4.m4.1b">
         <apply id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1">
          <times id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1">
          </times>
          <apply id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2">
           <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2">
            superscript
           </csymbol>
           <ci id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.2">
            𝐪
           </ci>
           <csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.3">
            top
           </csymbol>
          </apply>
          <ci id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3">
           𝐞
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.4.m4.1c">
         {\bm{\mathbf{q}}}^{\top}{\bm{\mathbf{e}}}
        </annotation>
       </semantics>
      </math>
      become relatively large for the query-paragraph pairs that are actually relevant.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Dataset and Training.
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.7">
      Following the work of
      <cite class="ltx_cite ltx_citemacro_citet">
       Xue et al. (
       <a class="ltx_ref" href="#bib.bib48" title="">
        2023c
       </a>
       )
      </cite>
      , we use query-paragraph pairs to train the key and query encoders
      <math alttext="f_{\text{key}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.1.m1.1">
       <semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a">
        <msub id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">
         <mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">
          f
         </mi>
         <mtext id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3a.cmml">
          key
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b">
         <apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2">
           𝑓
          </ci>
          <ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3">
           <mtext id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3">
            key
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">
         f_{\text{key}}
        </annotation>
       </semantics>
      </math>
      and
      <math alttext="f_{\text{query}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.2.m2.1">
       <semantics id="S3.SS2.SSS0.Px2.p1.2.m2.1a">
        <msub id="S3.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">
         <mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">
          f
         </mi>
         <mtext id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3a.cmml">
          query
         </mtext>
        </msub>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.2.m2.1b">
         <apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2">
           𝑓
          </ci>
          <ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3a.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3">
           <mtext id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3">
            query
           </mtext>
          </ci>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.2.m2.1c">
         f_{\text{query}}
        </annotation>
       </semantics>
      </math>
      . The pairs are collected from DatabaseQA (see
      <a class="ltx_ref" href="#S4.SS2" title="4.2 RAG Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Section
       </span>
       <span class="ltx_text ltx_ref_tag">
        4.2
       </span>
      </a>
      ): we sample
      <math alttext="1,000" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.3.m3.2">
       <semantics id="S3.SS2.SSS0.Px2.p1.3.m3.2a">
        <mrow id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml">
         <mn id="S3.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">
          1
         </mn>
         <mo id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml">
          ,
         </mo>
         <mn id="S3.SS2.SSS0.Px2.p1.3.m3.2.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.2.cmml">
          000
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.3.m3.2b">
         <list id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2">
          <cn id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1">
           1
          </cn>
          <cn id="S3.SS2.SSS0.Px2.p1.3.m3.2.2.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.2">
           000
          </cn>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.3.m3.2c">
         1,000
        </annotation>
       </semantics>
      </math>
      query-response pairs as the positive pairs and for each of them, we randomly sample five negative responses from the entire pool of paragraphs. Finally, we collect
      <math alttext="1000" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.4.m4.1">
       <semantics id="S3.SS2.SSS0.Px2.p1.4.m4.1a">
        <mn id="S3.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml">
         1000
        </mn>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.4.m4.1b">
         <cn id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1">
          1000
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.4.m4.1c">
         1000
        </annotation>
       </semantics>
      </math>
      query-response pairs for training and evaluation. The chosen pairs were then divided into sets of
      <math alttext="700" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.5.m5.1">
       <semantics id="S3.SS2.SSS0.Px2.p1.5.m5.1a">
        <mn id="S3.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS2.SSS0.Px2.p1.5.m5.1.1.cmml">
         700
        </mn>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.5.m5.1b">
         <cn id="S3.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.5.m5.1.1">
          700
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.5.m5.1c">
         700
        </annotation>
       </semantics>
      </math>
      training pairs,
      <math alttext="100" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.6.m6.1">
       <semantics id="S3.SS2.SSS0.Px2.p1.6.m6.1a">
        <mn id="S3.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.cmml">
         100
        </mn>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.6.m6.1b">
         <cn id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1">
          100
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.6.m6.1c">
         100
        </annotation>
       </semantics>
      </math>
      development pairs, and
      <math alttext="200" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.7.m7.1">
       <semantics id="S3.SS2.SSS0.Px2.p1.7.m7.1a">
        <mn id="S3.SS2.SSS0.Px2.p1.7.m7.1.1" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.cmml">
         200
        </mn>
        <annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.7.m7.1b">
         <cn id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1">
          200
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.7.m7.1c">
         200
        </annotation>
       </semantics>
      </math>
      test pairs.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS0.Px2.p2">
     <p class="ltx_p" id="S3.SS2.SSS0.Px2.p2.1">
      We pass query-response pairs to the
model to yield a scalar score for each of the pair
and maximize the scores for the positive pairs while minimizing the scores for the negative pairs with the cross entropy loss.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Implementation and Deployment Details.
   </h3>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Knowledge Base and WebUI.
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">
      For the implementation of RAG, we use the code from the public GitHub repository at
      <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/langchain-ai/langchain" style="font-size:90%;" target="_blank" title="">
       https://github.com/langchain-ai/langchain
      </a>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Chase,
       <a class="ltx_ref" href="#bib.bib6" title="">
        2022
       </a>
       )
      </cite>
      with MIT License as the reference. For the implementation of WebUI, we develop by our own and release at the GitHub repository at
      <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/eosphoros-ai/DB-GPT-Web" style="font-size:90%;" target="_blank" title="">
       https://github.com/eosphoros-ai/DB-GPT-Web
      </a>
      with MIT License.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Deployment Details.
    </h4>
    <div class="ltx_para" id="S3.SS3.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">
      For demo and testing purposes, unless otherwise specified, our system is deployed on a server on Alibaba Cloud with 30G RAM, a 8 logical cores (Intel Xeon(Ice Lake) Platinum 8369B), and a NVIDIA A100 80G Tensor Core GPU.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Experiments
  </h2>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    We present the experiments designed to evaluate the performance of the DB-GPT system, including the generation quality of Text-to-SQL responses (
    <a class="ltx_ref" href="#S3.SS1" title="3.1 Text-to-SQL Fine-Tuning ‣ 3 Models and Training ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      Section
     </span>
     <span class="ltx_text ltx_ref_tag">
      3.1
     </span>
    </a>
    ) and the QA performance of our proposed RAG mechanism (
    <a class="ltx_ref" href="#S2.SS1" title="2.1 Multi-source RAG for QA ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      Section
     </span>
     <span class="ltx_text ltx_ref_tag">
      2.1
     </span>
    </a>
    ) and the efficiency performance of SMMF
    <cite class="ltx_cite ltx_citemacro_citep">
     (
     <span class="ltx_ref ltx_missing_citation ltx_ref_self">
      sec:smmf
     </span>
     )
    </cite>
    . We also provide qualitative results of generative data analytics (
    <a class="ltx_ref" href="#S2.SS4" title="2.4 DB Plugins ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      Section
     </span>
     <span class="ltx_text ltx_ref_tag">
      2.4
     </span>
    </a>
    ).
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Text-to-SQL Evaluation
   </h3>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Dataset.
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">
      We evaluate Text-to-SQL methods on Spider
      <cite class="ltx_cite ltx_citemacro_citep">
       (Yu et al.,
       <a class="ltx_ref" href="#bib.bib50" title="">
        2018
       </a>
       )
      </cite>
      dataset. Spider is a large-scale cross-domain Text-to-SQL dataset, which contains 8659
instances in training split and 1034 instances in development split over 200 databases. Each instance consists of a natural language question on a specific database and its corresponding SQL query. In this paper, we use the development split Spider-dev for the purpose of evaluation as the test split is not released. Each instance is divided into different categories(easy, medium, hard, and extra) according to the complexity of the question. See
      <a class="ltx_ref" href="#A2.SS1" title="B.1 Text-to-SQL Evaluation Details ‣ Appendix B Experiment Details ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Section
       </span>
       <span class="ltx_text ltx_ref_tag">
        B.1
       </span>
      </a>
      for details.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Metrics.
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">
      We follow the prior study
      <cite class="ltx_cite ltx_citemacro_citep">
       (Liu et al.,
       <a class="ltx_ref" href="#bib.bib22" title="">
        2023
       </a>
       )
      </cite>
      to use execution accuracy (EX) as the metric. EX compares the execution output of the predicted SQL query with that
of the ground truth SQL query on some database instances. The higher EX is considered the better.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS1.SSS0.Px2.p2">
     <p class="ltx_p" id="S4.SS1.SSS0.Px2.p2.1">
      <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.p2.1.1">
       Base LLMs.
      </span>
      We compare Qwen that we chosen for DB-GPT with Baichuan
      <cite class="ltx_cite ltx_citemacro_citep">
       (Baichuan,
       <a class="ltx_ref" href="#bib.bib3" title="">
        2023
       </a>
       )
      </cite>
      that also well support bilingual texts.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T2">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
      <tr class="ltx_tr" id="S4.T2.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T2.1.1.2">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.1.2.1" style="font-size:90%;">
         Metrics (EX)
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_tt" id="S4.T2.1.1.3">
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.2">
       <td class="ltx_td" id="S4.T2.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.2.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.2.1">
         <span class="ltx_p" id="S4.T2.1.2.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.2.2.1.1.1" style="font-size:90%;">
           Easy
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.3.1">
         <span class="ltx_p" id="S4.T2.1.2.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.2.3.1.1.1" style="font-size:90%;">
           Medium
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.4.1">
         <span class="ltx_p" id="S4.T2.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.2.4.1.1.1" style="font-size:90%;">
           Hard
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.5.1">
         <span class="ltx_p" id="S4.T2.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.2.5.1.1.1" style="font-size:90%;">
           Extra
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.2.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.2.6.1">
         <span class="ltx_p" id="S4.T2.1.2.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.2.6.1.1.1" style="font-size:90%;">
           Overall
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.3.1.1" style="font-size:90%;">
         Qwen-7b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.2.1">
         <span class="ltx_p" id="S4.T2.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.3.2.1.1.1" style="font-size:90%;">
           0.395
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.3.1">
         <span class="ltx_p" id="S4.T2.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.3.3.1.1.1" style="font-size:90%;">
           0.256
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.4.1">
         <span class="ltx_p" id="S4.T2.1.3.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.3.4.1.1.1" style="font-size:90%;">
           0.138
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.5.1">
         <span class="ltx_p" id="S4.T2.1.3.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.3.5.1.1.1" style="font-size:90%;">
           0.042
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.3.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.3.6.1">
         <span class="ltx_p" id="S4.T2.1.3.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.3.6.1.1.1" style="font-size:90%;">
           0.235
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.4">
       <td class="ltx_td ltx_align_left" id="S4.T2.1.4.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.4.1.1" style="font-size:90%;">
         Qwen-7b-chat-sft
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.2.1">
         <span class="ltx_p" id="S4.T2.1.4.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.4.2.1.1.1" style="font-size:90%;">
           0.911
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.3.1">
         <span class="ltx_p" id="S4.T2.1.4.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.4.3.1.1.1" style="font-size:90%;">
           0.675
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.4.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.4.1">
         <span class="ltx_p" id="S4.T2.1.4.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.4.4.1.1.1" style="font-size:90%;">
           0.575
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.4.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.5.1">
         <span class="ltx_p" id="S4.T2.1.4.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.4.5.1.1.1" style="font-size:90%;">
           0.343
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.4.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.4.6.1">
         <span class="ltx_p" id="S4.T2.1.4.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.4.6.1.1.1" style="font-size:90%;">
           0.662
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.5">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.5.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.5.1.1" style="font-size:90%;">
         Qwen-14b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.2.1">
         <span class="ltx_p" id="S4.T2.1.5.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.5.2.1.1.1" style="font-size:90%;">
           0.871
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.3.1">
         <span class="ltx_p" id="S4.T2.1.5.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.5.3.1.1.1" style="font-size:90%;">
           0.632
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.5.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.4.1">
         <span class="ltx_p" id="S4.T2.1.5.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.5.4.1.1.1" style="font-size:90%;">
           0.368
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.5.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.5.1">
         <span class="ltx_p" id="S4.T2.1.5.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.5.5.1.1.1" style="font-size:90%;">
           0.181
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.5.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.5.6.1">
         <span class="ltx_p" id="S4.T2.1.5.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.5.6.1.1.1" style="font-size:90%;">
           0.573
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.6">
       <td class="ltx_td ltx_align_left" id="S4.T2.1.6.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.6.1.1" style="font-size:90%;">
         Qwen-14b-chat-sft
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.2.1">
         <span class="ltx_p" id="S4.T2.1.6.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.6.2.1.1.1" style="font-size:90%;">
           0.919
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.3.1">
         <span class="ltx_p" id="S4.T2.1.6.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.6.3.1.1.1" style="font-size:90%;">
           0.744
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.6.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.4.1">
         <span class="ltx_p" id="S4.T2.1.6.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.6.4.1.1.1" style="font-size:90%;">
           0.598
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.6.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.5.1">
         <span class="ltx_p" id="S4.T2.1.6.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.6.5.1.1.1" style="font-size:90%;">
           0.367
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.6.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.6.6.1">
         <span class="ltx_p" id="S4.T2.1.6.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.6.6.1.1.1" style="font-size:90%;">
           0.701
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.7">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.7.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.7.1.1" style="font-size:90%;">
         Baichuan2-7b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.7.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.2.1">
         <span class="ltx_p" id="S4.T2.1.7.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.7.2.1.1.1" style="font-size:90%;">
           0.577
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.7.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.3.1">
         <span class="ltx_p" id="S4.T2.1.7.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.7.3.1.1.1" style="font-size:90%;">
           0.352
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.7.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.4.1">
         <span class="ltx_p" id="S4.T2.1.7.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.7.4.1.1.1" style="font-size:90%;">
           0.201
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.7.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.5.1">
         <span class="ltx_p" id="S4.T2.1.7.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.7.5.1.1.1" style="font-size:90%;">
           0.066
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.7.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.7.6.1">
         <span class="ltx_p" id="S4.T2.1.7.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.7.6.1.1.1" style="font-size:90%;">
           0.335
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.8">
       <td class="ltx_td ltx_align_left" id="S4.T2.1.8.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.8.1.1" style="font-size:90%;">
         Baichuan2-7b-chat-sft
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.8.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.2.1">
         <span class="ltx_p" id="S4.T2.1.8.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.8.2.1.1.1" style="font-size:90%;">
           0.891
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.8.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.3.1">
         <span class="ltx_p" id="S4.T2.1.8.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.8.3.1.1.1" style="font-size:90%;">
           0.637
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.8.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.4.1">
         <span class="ltx_p" id="S4.T2.1.8.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.8.4.1.1.1" style="font-size:90%;">
           0.489
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.8.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.5.1">
         <span class="ltx_p" id="S4.T2.1.8.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.8.5.1.1.1" style="font-size:90%;">
           0.331
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T2.1.8.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.8.6.1">
         <span class="ltx_p" id="S4.T2.1.8.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.8.6.1.1.1" style="font-size:90%;">
           0.624
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.9">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.9.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.9.1.1" style="font-size:90%;">
         Baichuan2-13b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.9.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.2.1">
         <span class="ltx_p" id="S4.T2.1.9.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.9.2.1.1.1" style="font-size:90%;">
           0.581
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.9.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.3.1">
         <span class="ltx_p" id="S4.T2.1.9.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.9.3.1.1.1" style="font-size:90%;">
           0.413
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.9.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.4.1">
         <span class="ltx_p" id="S4.T2.1.9.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.9.4.1.1.1" style="font-size:90%;">
           0.264
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.9.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.5.1">
         <span class="ltx_p" id="S4.T2.1.9.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.9.5.1.1.1" style="font-size:90%;">
           0.187
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T2.1.9.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.9.6.1">
         <span class="ltx_p" id="S4.T2.1.9.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.9.6.1.1.1" style="font-size:90%;">
           0.392
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T2.1.10">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.10.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T2.1.10.1.1" style="font-size:90%;">
         Baichuan2-13b-chat-sft
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T2.1.10.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.10.2.1">
         <span class="ltx_p" id="S4.T2.1.10.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.10.2.1.1.1" style="font-size:90%;">
           0.895
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T2.1.10.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.10.3.1">
         <span class="ltx_p" id="S4.T2.1.10.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.10.3.1.1.1" style="font-size:90%;">
           0.675
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T2.1.10.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.10.4.1">
         <span class="ltx_p" id="S4.T2.1.10.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.10.4.1.1.1" style="font-size:90%;">
           0.580
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T2.1.10.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.10.5.1">
         <span class="ltx_p" id="S4.T2.1.10.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.10.5.1.1.1" style="font-size:90%;">
           0.343
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T2.1.10.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T2.1.10.6.1">
         <span class="ltx_p" id="S4.T2.1.10.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T2.1.10.6.1.1.1" style="font-size:90%;">
           0.659
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 2:
      </span>
      Evaluation on Spider-dev datasets.
     </figcaption>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Main Result.
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">
      <a class="ltx_ref" href="#S4.T2" title="In Metrics. ‣ 4.1 Text-to-SQL Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      shows the effectiveness of the Text-to-SQL fine-tuning pipeline of our DB-GPT system: for both Qwen and Baichuan, the fine-tuned version shows significant improvement compared to the original LLM measured by EX.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    RAG Evaluation
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     Following
     <cite class="ltx_cite ltx_citemacro_citep">
      (Lewis et al.,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2020
      </a>
      )
     </cite>
     , we experiment with RAG in a wide range of open-domain QA tasks.
    </p>
   </div>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Dataset.
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.3">
      We construct two QA datasets: DatabaseQA and FinancialQA. For DatabaseQA we collect
      <math alttext="1000" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.1.m1.1">
       <semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a">
        <mn id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">
         1000
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b">
         <cn id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1">
          1000
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">
         1000
        </annotation>
       </semantics>
      </math>
      public tutorials in PDFs from three representative database systems: OceanBase
      <cite class="ltx_cite ltx_citemacro_citep">
       (Group,
       <a class="ltx_ref" href="#bib.bib11" title="">
        2021
       </a>
       )
      </cite>
      , MySQL
      <cite class="ltx_cite ltx_citemacro_citep">
       (
       <a class="ltx_ref" href="#bib.bib26" title="">
        MySQL,
       </a>
       )
      </cite>
      and MongoDB
      <cite class="ltx_cite ltx_citemacro_citep">
       (
       <a class="ltx_ref" href="#bib.bib25" title="">
        MongoDB,
       </a>
       )
      </cite>
      . For FinancialQA, we sample
      <math alttext="1000" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.2.m2.1">
       <semantics id="S4.SS2.SSS0.Px1.p1.2.m2.1a">
        <mn id="S4.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">
         1000
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.2.m2.1b">
         <cn id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1">
          1000
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.2.m2.1c">
         1000
        </annotation>
       </semantics>
      </math>
      documents published from research institutes. For each dataset, we construct
      <math alttext="100" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p1.3.m3.1">
       <semantics id="S4.SS2.SSS0.Px1.p1.3.m3.1a">
        <mn id="S4.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">
         100
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.3.m3.1b">
         <cn id="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1">
          100
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.3.m3.1c">
         100
        </annotation>
       </semantics>
      </math>
      questions for testing, where questions are annotated with difficulties by experts. See
      <a class="ltx_ref" href="#A2.SS2" title="B.2 RAG Evaluation Details ‣ Appendix B Experiment Details ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Section
       </span>
       <span class="ltx_text ltx_ref_tag">
        B.2
       </span>
      </a>
      for more details on dataset.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Metrics.
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">
      We have three experts rate each response with rating from
      <math alttext="0-5" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px2.p1.1.m1.1">
       <semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a">
        <mrow id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">
         <mn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">
          0
         </mn>
         <mo id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml">
          −
         </mo>
         <mn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">
          5
         </mn>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b">
         <apply id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1">
          <minus id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1">
          </minus>
          <cn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2">
           0
          </cn>
          <cn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3">
           5
          </cn>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">
         0-5
        </annotation>
       </semantics>
      </math>
      , where the higher score is consider the better answer, and take the average of them as the final score.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Base LLMs.
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px3.p1.1">
      We use four LLMs: Qwen, Baichuan and two commercial LLMs: ChatGLM-Turbo
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zeng et al.,
       <a class="ltx_ref" href="#bib.bib51" title="">
        2022
       </a>
       )
      </cite>
      and ChatGPT3.5
      <cite class="ltx_cite ltx_citemacro_citep">
       (Brown et al.,
       <a class="ltx_ref" href="#bib.bib4" title="">
        2020
       </a>
       )
      </cite>
      as the base model, respectively. For ChatGLM-Turbo and ChatGPT3.5, we directly call the APIs to run our task.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px4">
    <h4 class="ltx_title ltx_title_paragraph">
     Main Results.
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS0.Px4.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px4.p1.1">
      Illustrated in
      <a class="ltx_ref" href="#S4.T3" title="In Main Results. ‣ 4.2 RAG Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      and
      <a class="ltx_ref" href="#S4.T4" title="In Main Results. ‣ 4.2 RAG Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      , there is no consistent winner across the datasets: ChatGPT-3.5 is the winner on DatabaseQA dataset while ChatGLM2-7b achieves the best performance on FinancialQA dataset. As DB-GPT integrates most of the popular open source and commercial LLMs, the users are able to choose the most suitable one for their own RAG tasks.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T3">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T3.1">
      <tr class="ltx_tr" id="S4.T3.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T3.1.1.2">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.1.2.1" style="font-size:90%;">
         Metrics (Average Score)
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T3.1.2">
       <td class="ltx_td" id="S4.T3.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.2.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.2.1">
         <span class="ltx_p" id="S4.T3.1.2.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.2.2.1.1.1" style="font-size:90%;">
           Easy
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.3.1">
         <span class="ltx_p" id="S4.T3.1.2.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.2.3.1.1.1" style="font-size:90%;">
           Medium
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.4.1">
         <span class="ltx_p" id="S4.T3.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.2.4.1.1.1" style="font-size:90%;">
           Hard
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.2.5.1">
         <span class="ltx_p" id="S4.T3.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.2.5.1.1.1" style="font-size:90%;">
           Overall
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T3.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.3.1.1" style="font-size:90%;">
         Qwen-7b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.2.1">
         <span class="ltx_p" id="S4.T3.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.3.2.1.1.1" style="font-size:90%;">
           0.487
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.3.1">
         <span class="ltx_p" id="S4.T3.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.3.3.1.1.1" style="font-size:90%;">
           0.488
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.4.1">
         <span class="ltx_p" id="S4.T3.1.3.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.3.4.1.1.1" style="font-size:90%;">
           0.485
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.3.5.1">
         <span class="ltx_p" id="S4.T3.1.3.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.3.5.1.1.1" style="font-size:90%;">
           0.487
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T3.1.4">
       <td class="ltx_td ltx_align_left" id="S4.T3.1.4.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.4.1.1" style="font-size:90%;">
         Baichuan2-7b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.2.1">
         <span class="ltx_p" id="S4.T3.1.4.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.4.2.1.1.1" style="font-size:90%;">
           0.470
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.3.1">
         <span class="ltx_p" id="S4.T3.1.4.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.4.3.1.1.1" style="font-size:90%;">
           0.468
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.4.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.4.1">
         <span class="ltx_p" id="S4.T3.1.4.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.4.4.1.1.1" style="font-size:90%;">
           0.466
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.4.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.4.5.1">
         <span class="ltx_p" id="S4.T3.1.4.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.4.5.1.1.1" style="font-size:90%;">
           0.468
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T3.1.5">
       <td class="ltx_td ltx_align_left" id="S4.T3.1.5.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.5.1.1" style="font-size:90%;">
         ChatGLM-Turbo
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.2.1">
         <span class="ltx_p" id="S4.T3.1.5.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.5.2.1.1.1" style="font-size:90%;">
           0.460
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.3.1">
         <span class="ltx_p" id="S4.T3.1.5.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.5.3.1.1.1" style="font-size:90%;">
           0.459
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.5.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.4.1">
         <span class="ltx_p" id="S4.T3.1.5.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.5.4.1.1.1" style="font-size:90%;">
           0.464
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T3.1.5.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.5.5.1">
         <span class="ltx_p" id="S4.T3.1.5.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.5.5.1.1.1" style="font-size:90%;">
           0.461
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T3.1.6">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.6.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T3.1.6.1.1" style="font-size:90%;">
         ChatGPT-3.5
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T3.1.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.2.1">
         <span class="ltx_p" id="S4.T3.1.6.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T3.1.6.2.1.1.1" style="font-size:90%;">
           0.663
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T3.1.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.3.1">
         <span class="ltx_p" id="S4.T3.1.6.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T3.1.6.3.1.1.1" style="font-size:90%;">
           0.644
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T3.1.6.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.4.1">
         <span class="ltx_p" id="S4.T3.1.6.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T3.1.6.4.1.1.1" style="font-size:90%;">
           0.628
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T3.1.6.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.6.5.1">
         <span class="ltx_p" id="S4.T3.1.6.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T3.1.6.5.1.1.1" style="font-size:90%;">
           0.645
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 3:
      </span>
      RAG Evaluation on DatabaseQA dataset.
     </figcaption>
    </figure>
    <figure class="ltx_table" id="S4.T4">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T4.1">
      <tr class="ltx_tr" id="S4.T4.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T4.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T4.1.1.2">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.1.2.1" style="font-size:90%;">
         Metrics (Average Score)
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T4.1.2">
       <td class="ltx_td" id="S4.T4.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.2.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.2.1">
         <span class="ltx_p" id="S4.T4.1.2.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.2.2.1.1.1" style="font-size:90%;">
           Easy
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.2.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.3.1">
         <span class="ltx_p" id="S4.T4.1.2.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.2.3.1.1.1" style="font-size:90%;">
           Medium
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.4.1">
         <span class="ltx_p" id="S4.T4.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.2.4.1.1.1" style="font-size:90%;">
           Hard
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.2.5.1">
         <span class="ltx_p" id="S4.T4.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.2.5.1.1.1" style="font-size:90%;">
           Overall
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T4.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.3.1.1" style="font-size:90%;">
         Qwen-7b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.2.1">
         <span class="ltx_p" id="S4.T4.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.3.2.1.1.1" style="font-size:90%;">
           0.829
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.3.1">
         <span class="ltx_p" id="S4.T4.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.3.3.1.1.1" style="font-size:90%;">
           0.824
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.4.1">
         <span class="ltx_p" id="S4.T4.1.3.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.3.4.1.1.1" style="font-size:90%;">
           0.819
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T4.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.3.5.1">
         <span class="ltx_p" id="S4.T4.1.3.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.3.5.1.1.1" style="font-size:90%;">
           0.824
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T4.1.4">
       <td class="ltx_td ltx_align_left" id="S4.T4.1.4.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.4.1.1" style="font-size:90%;">
         Baichuan2-7b-chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.2.1">
         <span class="ltx_p" id="S4.T4.1.4.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.4.2.1.1.1" style="font-size:90%;">
           0.897
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.3.1">
         <span class="ltx_p" id="S4.T4.1.4.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.4.3.1.1.1" style="font-size:90%;">
           0.893
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.4.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.4.1">
         <span class="ltx_p" id="S4.T4.1.4.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.4.4.1.1.1" style="font-size:90%;">
           0.895
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.4.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.4.5.1">
         <span class="ltx_p" id="S4.T4.1.4.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.4.5.1.1.1" style="font-size:90%;">
           0.895
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T4.1.5">
       <td class="ltx_td ltx_align_left" id="S4.T4.1.5.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.5.1.1" style="font-size:90%;">
         ChatGLM-Turbo
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.2.1">
         <span class="ltx_p" id="S4.T4.1.5.2.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T4.1.5.2.1.1.1" style="font-size:90%;">
           0.910
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.3.1">
         <span class="ltx_p" id="S4.T4.1.5.3.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T4.1.5.3.1.1.1" style="font-size:90%;">
           0.905
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.5.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.4.1">
         <span class="ltx_p" id="S4.T4.1.5.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T4.1.5.4.1.1.1" style="font-size:90%;">
           0.900
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T4.1.5.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.5.5.1">
         <span class="ltx_p" id="S4.T4.1.5.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T4.1.5.5.1.1.1" style="font-size:90%;">
           0.905
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T4.1.6">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.1.6.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.6.1.1" style="font-size:90%;">
         ChatGPT-3.5
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T4.1.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.6.2.1">
         <span class="ltx_p" id="S4.T4.1.6.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.6.2.1.1.1" style="font-size:90%;">
           0.903
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T4.1.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.6.3.1">
         <span class="ltx_p" id="S4.T4.1.6.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.6.3.1.1.1" style="font-size:90%;">
           0.899
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T4.1.6.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.6.4.1">
         <span class="ltx_p" id="S4.T4.1.6.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.6.4.1.1.1" style="font-size:90%;">
           0.898
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T4.1.6.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T4.1.6.5.1">
         <span class="ltx_p" id="S4.T4.1.6.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T4.1.6.5.1.1.1" style="font-size:90%;">
           0.900
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 4:
      </span>
      RAG Evaluation on FinancialQA dataset.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    SMMF Evaluation
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     Clarified in
     <a class="ltx_ref" href="#S2.SS2" title="2.2 Deploy and Inference: Service-oriented Multi-model Framework ‣ 2 SYSTEM DESIGN ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
      <span class="ltx_text ltx_ref_tag">
       Section
      </span>
      <span class="ltx_text ltx_ref_tag">
       2.2
      </span>
     </a>
     , our DB-GPT integrates vLLM as the main inference framework.
    </p>
   </div>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Dataset.
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.2">
      The test is performed on a server with
629G RAM, a hard drive with 1TB HDD, a 40 logical cores (Intel Xeon Processor (Skylake, IBRS)) CPU at 2992.953MHz, and a NVIDIA A100-PCIE GPU with 40G GPU RAM. Across all the experiments, we use the same prompt with
      <math alttext="8" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.1.m1.1">
       <semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a">
        <mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">
         8
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b">
         <cn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1">
          8
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">
         8
        </annotation>
       </semantics>
      </math>
      tokens as the input while setting the output length to be
      <math alttext="256" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.2.m2.1">
       <semantics id="S4.SS3.SSS0.Px1.p1.2.m2.1a">
        <mn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml">
         256
        </mn>
        <annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.2.m2.1b">
         <cn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1">
          256
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.2.m2.1c">
         256
        </annotation>
       </semantics>
      </math>
      tokens.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Metrics.
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">
      We use the following three metrics:
     </p>
     <ul class="ltx_itemize" id="S4.I1">
      <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I1.i1.p1">
        <p class="ltx_p" id="S4.I1.i1.p1.1">
         First Token Latency (FTL): measured in milliseconds, it represents the time spent from the moment the DB-GPT model deployment framework receives a request to the point when the inference framework decodes the first token.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I1.i2.p1">
        <p class="ltx_p" id="S4.I1.i2.p1.1">
         Inference Latency (IL): measured in seconds, it represents the time spent from the moment the DB-GPT model deployment framework receives a request to the point when the inference framework decodes the complete response.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S4.I1.i3.p1">
        <p class="ltx_p" id="S4.I1.i3.p1.1">
         Throughput: the total number of tokens processed by the DB-GPT model deployment framework per second, across all requests.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Base LLMs.
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.1">
      Same as in
      <a class="ltx_ref" href="#S3.SS1" title="3.1 Text-to-SQL Fine-Tuning ‣ 3 Models and Training ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Section
       </span>
       <span class="ltx_text ltx_ref_tag">
        3.1
       </span>
      </a>
      , we use Qwen and Baichuan as the base LLMs for the experiment.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px4">
    <h4 class="ltx_title ltx_title_paragraph">
     Main Results.
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px4.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px4.p1.1">
      Seen in
      <a class="ltx_ref" href="#S4.T5" title="In Main Results. ‣ 4.3 SMMF Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      and
      <a class="ltx_ref" href="#S4.T6" title="In Main Results. ‣ 4.3 SMMF Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        6
       </span>
      </a>
      , the results indicate that the use of the vLLM framework for model inference significantly increases the throughput of the model, while substantially reducing both the first token latency and the overall inference latency. Moreover, as the number of concurrent users rises, the performance improvements gained from utilizing the vLLM framework for inference become particularly pronounced. As a result, DB-GPT choose to integrate vLLM as the default inference framework used for SMMF.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T5">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T5.1">
      <tr class="ltx_tr" id="S4.T5.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T5.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_tt" id="S4.T5.1.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.2.1">
         <span class="ltx_p" id="S4.T5.1.1.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.1.2.1.1.1" style="font-size:90%;">
           # Ccr
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_tt" id="S4.T5.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.1.3.1">
         <span class="ltx_p" id="S4.T5.1.1.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.1.3.1.1.1" style="font-size:90%;">
           Platform
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T5.1.1.4">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.1.4.1" style="font-size:90%;">
         Metrics
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.1.2">
       <td class="ltx_td" id="S4.T5.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.2.2">
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.2.3">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.2.4.1">
         <span class="ltx_p" id="S4.T5.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.2.4.1.1.1" style="font-size:90%;">
           FTL(ms)
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.2.5.1">
         <span class="ltx_p" id="S4.T5.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.2.5.1.1.1" style="font-size:90%;">
           IL(s)
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.2.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.2.6.1">
         <span class="ltx_p" id="S4.T5.1.2.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.2.6.1.1.1" style="font-size:90%;">
           Throughput (tokens)
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.3.1.1" style="font-size:90%;">
         Qwen-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.3.2.1">
         <span class="ltx_p" id="S4.T5.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.3.2.1.1.1" style="font-size:90%;">
           4
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.3.3.1">
         <span class="ltx_p" id="S4.T5.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.3.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.3.4.1">
         <span class="ltx_p" id="S4.T5.1.3.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.3.4.1.1.1" style="font-size:90%;">
           22.5
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.3.5.1">
         <span class="ltx_p" id="S4.T5.1.3.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.3.5.1.1.1" style="font-size:90%;">
           4.0
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.3.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.3.6.1">
         <span class="ltx_p" id="S4.T5.1.3.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.3.6.1.1.1" style="font-size:90%;">
           258.9
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.1.4">
       <td class="ltx_td ltx_align_left" id="S4.T5.1.4.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.4.1.1" style="font-size:90%;">
         Qwen-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.4.2.1">
         <span class="ltx_p" id="S4.T5.1.4.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.4.2.1.1.1" style="font-size:90%;">
           4
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.4.3.1">
         <span class="ltx_p" id="S4.T5.1.4.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.4.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.4.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.4.4.1">
         <span class="ltx_p" id="S4.T5.1.4.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.4.4.1.1.1" style="font-size:90%;">
           765.7
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.4.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.4.5.1">
         <span class="ltx_p" id="S4.T5.1.4.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.4.5.1.1.1" style="font-size:90%;">
           97.6
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.4.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.4.6.1">
         <span class="ltx_p" id="S4.T5.1.4.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.4.6.1.1.1" style="font-size:90%;">
           10.7
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.1.5">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.5.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.5.1.1" style="font-size:90%;">
         Qwen-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.5.2.1">
         <span class="ltx_p" id="S4.T5.1.5.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.5.2.1.1.1" style="font-size:90%;">
           16
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.5.3.1">
         <span class="ltx_p" id="S4.T5.1.5.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.5.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.5.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.5.4.1">
         <span class="ltx_p" id="S4.T5.1.5.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.5.4.1.1.1" style="font-size:90%;">
           23.1
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.5.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.5.5.1">
         <span class="ltx_p" id="S4.T5.1.5.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.5.5.1.1.1" style="font-size:90%;">
           4.1
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.5.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.5.6.1">
         <span class="ltx_p" id="S4.T5.1.5.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.5.6.1.1.1" style="font-size:90%;">
           258.7
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.1.6">
       <td class="ltx_td ltx_align_left" id="S4.T5.1.6.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.6.1.1" style="font-size:90%;">
         Qwen-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.6.2.1">
         <span class="ltx_p" id="S4.T5.1.6.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.6.2.1.1.1" style="font-size:90%;">
           16
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.6.3.1">
         <span class="ltx_p" id="S4.T5.1.6.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.6.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.6.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.6.4.1">
         <span class="ltx_p" id="S4.T5.1.6.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.6.4.1.1.1" style="font-size:90%;">
           1152.0
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.6.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.6.5.1">
         <span class="ltx_p" id="S4.T5.1.6.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.6.5.1.1.1" style="font-size:90%;">
           138.9
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T5.1.6.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.6.6.1">
         <span class="ltx_p" id="S4.T5.1.6.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.6.6.1.1.1" style="font-size:90%;">
           9.2
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.1.7">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.1.7.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.7.1.1" style="font-size:90%;">
         Qwen-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.7.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.7.2.1">
         <span class="ltx_p" id="S4.T5.1.7.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.7.2.1.1.1" style="font-size:90%;">
           32
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.7.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.7.3.1">
         <span class="ltx_p" id="S4.T5.1.7.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.7.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.7.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.7.4.1">
         <span class="ltx_p" id="S4.T5.1.7.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.7.4.1.1.1" style="font-size:90%;">
           23.3
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.7.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.7.5.1">
         <span class="ltx_p" id="S4.T5.1.7.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.7.5.1.1.1" style="font-size:90%;">
           4.2
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T5.1.7.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.7.6.1">
         <span class="ltx_p" id="S4.T5.1.7.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T5.1.7.6.1.1.1" style="font-size:90%;">
           289.2
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T5.1.8">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T5.1.8.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.8.1.1" style="font-size:90%;">
         Qwen-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T5.1.8.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.8.2.1">
         <span class="ltx_p" id="S4.T5.1.8.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.8.2.1.1.1" style="font-size:90%;">
           32
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T5.1.8.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.8.3.1">
         <span class="ltx_p" id="S4.T5.1.8.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.8.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T5.1.8.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.8.4.1">
         <span class="ltx_p" id="S4.T5.1.8.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.8.4.1.1.1" style="font-size:90%;">
           1059.2
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T5.1.8.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.8.5.1">
         <span class="ltx_p" id="S4.T5.1.8.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.8.5.1.1.1" style="font-size:90%;">
           127.1
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T5.1.8.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T5.1.8.6.1">
         <span class="ltx_p" id="S4.T5.1.8.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T5.1.8.6.1.1.1" style="font-size:90%;">
           10.1
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 5:
      </span>
      Evaluation on SMMF with Qwen as the base LLM.
     </figcaption>
    </figure>
    <figure class="ltx_table" id="S4.T6">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T6.1">
      <tr class="ltx_tr" id="S4.T6.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T6.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_tt" id="S4.T6.1.1.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.1.2.1">
         <span class="ltx_p" id="S4.T6.1.1.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.1.2.1.1.1" style="font-size:90%;">
           # Ccr
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_tt" id="S4.T6.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.1.3.1">
         <span class="ltx_p" id="S4.T6.1.1.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.1.3.1.1.1" style="font-size:90%;">
           Platform
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T6.1.1.4">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.1.4.1" style="font-size:90%;">
         Metrics
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T6.1.2">
       <td class="ltx_td" id="S4.T6.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.2.2">
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.2.3">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.2.4.1">
         <span class="ltx_p" id="S4.T6.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.2.4.1.1.1" style="font-size:90%;">
           FTL (ms)
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.2.5.1">
         <span class="ltx_p" id="S4.T6.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.2.5.1.1.1" style="font-size:90%;">
           IL (s)
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.2.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.2.6.1">
         <span class="ltx_p" id="S4.T6.1.2.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.2.6.1.1.1" style="font-size:90%;">
           Throughput (tokens)
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T6.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.3.1.1" style="font-size:90%;">
         Baichuan-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.3.2.1">
         <span class="ltx_p" id="S4.T6.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.3.2.1.1.1" style="font-size:90%;">
           4
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.3.3.1">
         <span class="ltx_p" id="S4.T6.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.3.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.3.4.1">
         <span class="ltx_p" id="S4.T6.1.3.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.3.4.1.1.1" style="font-size:90%;">
           54.7
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.3.5.1">
         <span class="ltx_p" id="S4.T6.1.3.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.3.5.1.1.1" style="font-size:90%;">
           5.2
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.3.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.3.6.1">
         <span class="ltx_p" id="S4.T6.1.3.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.3.6.1.1.1" style="font-size:90%;">
           201.7
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T6.1.4">
       <td class="ltx_td ltx_align_left" id="S4.T6.1.4.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.4.1.1" style="font-size:90%;">
         Baichuan-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.4.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.4.2.1">
         <span class="ltx_p" id="S4.T6.1.4.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.4.2.1.1.1" style="font-size:90%;">
           4
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.4.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.4.3.1">
         <span class="ltx_p" id="S4.T6.1.4.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.4.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.4.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.4.4.1">
         <span class="ltx_p" id="S4.T6.1.4.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.4.4.1.1.1" style="font-size:90%;">
           688.5
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.4.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.4.5.1">
         <span class="ltx_p" id="S4.T6.1.4.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.4.5.1.1.1" style="font-size:90%;">
           70.8
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.4.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.4.6.1">
         <span class="ltx_p" id="S4.T6.1.4.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.4.6.1.1.1" style="font-size:90%;">
           14.7
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T6.1.5">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.5.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.5.1.1" style="font-size:90%;">
         Baichuan-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.5.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.5.2.1">
         <span class="ltx_p" id="S4.T6.1.5.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.5.2.1.1.1" style="font-size:90%;">
           16
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.5.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.5.3.1">
         <span class="ltx_p" id="S4.T6.1.5.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.5.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.5.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.5.4.1">
         <span class="ltx_p" id="S4.T6.1.5.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.5.4.1.1.1" style="font-size:90%;">
           156.2
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.5.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.5.5.1">
         <span class="ltx_p" id="S4.T6.1.5.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.5.5.1.1.1" style="font-size:90%;">
           7.1
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.5.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.5.6.1">
         <span class="ltx_p" id="S4.T6.1.5.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.5.6.1.1.1" style="font-size:90%;">
           588.2
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T6.1.6">
       <td class="ltx_td ltx_align_left" id="S4.T6.1.6.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.6.1.1" style="font-size:90%;">
         Baichuan-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.6.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.6.2.1">
         <span class="ltx_p" id="S4.T6.1.6.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.6.2.1.1.1" style="font-size:90%;">
           16
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.6.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.6.3.1">
         <span class="ltx_p" id="S4.T6.1.6.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.6.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.6.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.6.4.1">
         <span class="ltx_p" id="S4.T6.1.6.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.6.4.1.1.1" style="font-size:90%;">
           2911.7
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.6.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.6.5.1">
         <span class="ltx_p" id="S4.T6.1.6.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.6.5.1.1.1" style="font-size:90%;">
           985.4
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="S4.T6.1.6.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.6.6.1">
         <span class="ltx_p" id="S4.T6.1.6.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.6.6.1.1.1" style="font-size:90%;">
           4.2
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T6.1.7">
       <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.7.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.7.1.1" style="font-size:90%;">
         Baichuan-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.7.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.7.2.1">
         <span class="ltx_p" id="S4.T6.1.7.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.7.2.1.1.1" style="font-size:90%;">
           32
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.7.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.7.3.1">
         <span class="ltx_p" id="S4.T6.1.7.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.7.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.7.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.7.4.1">
         <span class="ltx_p" id="S4.T6.1.7.4.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.7.4.1.1.1" style="font-size:90%;">
           380.0
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.7.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.7.5.1">
         <span class="ltx_p" id="S4.T6.1.7.5.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.7.5.1.1.1" style="font-size:90%;">
           9.6
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T6.1.7.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.7.6.1">
         <span class="ltx_p" id="S4.T6.1.7.6.1.1">
          <span class="ltx_text ltx_font_bold" id="S4.T6.1.7.6.1.1.1" style="font-size:90%;">
           870.2
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S4.T6.1.8">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T6.1.8.1">
        <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.8.1.1" style="font-size:90%;">
         Baichuan-7b-Chat
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T6.1.8.2">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.8.2.1">
         <span class="ltx_p" id="S4.T6.1.8.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.8.2.1.1.1" style="font-size:90%;">
           32
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T6.1.8.3">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.8.3.1">
         <span class="ltx_p" id="S4.T6.1.8.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.8.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T6.1.8.4">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.8.4.1">
         <span class="ltx_p" id="S4.T6.1.8.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.8.4.1.1.1" style="font-size:90%;">
           6786.6
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T6.1.8.5">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.8.5.1">
         <span class="ltx_p" id="S4.T6.1.8.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.8.5.1.1.1" style="font-size:90%;">
           1630.7
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="S4.T6.1.8.6">
        <span class="ltx_inline-block ltx_align_top" id="S4.T6.1.8.6.1">
         <span class="ltx_p" id="S4.T6.1.8.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T6.1.8.6.1.1.1" style="font-size:90%;">
           5.1
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 6:
      </span>
      Evaluation on SMMF with Baichuan as the base LLM.
     </figcaption>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Related Work
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    <span class="ltx_text ltx_font_bold" id="S5.p1.1.1">
     LLM for Databases.
    </span>
    The emergence of LLMs has revolutionized various application domains. In recent years, researchers have explored the potential of LLMs in the context of databases, aiming to revolutionize the way the users interact with and query databases. The most relevant works are LangChain
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chase,
     <a class="ltx_ref" href="#bib.bib6" title="">
      2022
     </a>
     )
    </cite>
    and LllmaIndex
    <cite class="ltx_cite ltx_citemacro_citep">
     (Liu,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2022
     </a>
     )
    </cite>
    . Our DB-GPT differs from them mainly in terms of bilingual queries and generative data analytics integration. Among other relevant works, PrivateGPT
    <cite class="ltx_cite ltx_citemacro_citep">
     (Martínez et al.,
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023
     </a>
     )
    </cite>
    focuses on security and privacy setup of the LLM-based database applications while ChatDB
    <cite class="ltx_cite ltx_citemacro_citep">
     (Hu et al.,
     <a class="ltx_ref" href="#bib.bib15" title="">
      2023
     </a>
     )
    </cite>
    mainly addresses the LLM-based SQL generation and reasoning problem with a symbolic memory framework. A comparison of
our DB-GPT system to other competitive approaches is summarized in
    <a class="ltx_ref" href="#S1.T1" title="In 1 Introduction ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      Table
     </span>
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    .
   </p>
  </div>
  <div class="ltx_para" id="S5.p2">
   <p class="ltx_p" id="S5.p2.1">
    <span class="ltx_text ltx_font_bold" id="S5.p2.1.1">
     LLM Agent.
    </span>
    An agent takes in a user input or query and can make internal decisions for executing that query in order to return the correct result. Recent developments in LLMs
    <cite class="ltx_cite ltx_citemacro_citep">
     (Yao et al.,
     <a class="ltx_ref" href="#bib.bib49" title="">
      2023
     </a>
     )
    </cite>
    and LLM tooling
    <cite class="ltx_cite ltx_citemacro_citep">
     (Richards,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2022
     </a>
     ; Hong et al.,
     <a class="ltx_ref" href="#bib.bib14" title="">
      2023
     </a>
     )
    </cite>
    have popularized the concept of agents. Compared to agent frameworks used in Langchain and LlamaIndex, DB-GPT has implemented agents that are with less constraints and more task agnostic, supported by the strong reasoning ability of the fine-tuned model.
   </p>
  </div>
  <div class="ltx_para" id="S5.p3">
   <p class="ltx_p" id="S5.p3.1">
    <span class="ltx_text ltx_font_bold" id="S5.p3.1.1">
     Knowledge Base Question and Answer and Retrieval-Augmented Generation.
    </span>
    Knowledge base question answering (KBQA) plays a crucial role in leveraging the substantial knowledge stored in knowledge bases and making it accessible to users
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lan et al.,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2022
     </a>
     ; Cao et al.,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022
     </a>
     )
    </cite>
    . LLMs’ remarkable generalization with minimal demonstrations
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shi et al.,
     <a class="ltx_ref" href="#bib.bib34" title="">
      2023
     </a>
     )
    </cite>
    hints at its potential in KBQA. Our DB-GPT system aligns with works on LLM-based database applications, which involves enhancing language models by incorporating external datastores, such as PDF’s, web pages, Google Docs, etc. In line with LllmaIndex, our DB-GPT system implements a robust indexing structure, categorising documents into nodes for efficient information retrieval. The language generation process of combining retrieved external knowledge and pre-trained parametric knowledge is called retrieval-augmented generation (RAG)
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lewis et al.,
     <a class="ltx_ref" href="#bib.bib21" title="">
      2020
     </a>
     )
    </cite>
    , which has been widely used in knowledge-intensive tasks and database applications. In addition to the standard pipeline of RAG, DB-GPT provides various types of bilingual text splitting, embedding, ranking methods, which is more flexible than competitors.
   </p>
  </div>
  <div class="ltx_para" id="S5.p4">
   <p class="ltx_p" id="S5.p4.1">
    <span class="ltx_text ltx_font_bold" id="S5.p4.1.1">
     Deployment Platform for LLM-based Applications.
    </span>
    The deployment platforms of LLM-based application can categorized into two primary groups: distributed systems and cloud platforms. Distributed systems distribute LLMs across multiple nodes to enhance performance and reliability through network coordination and load balancing. Conversely, cloud platforms host LLMs on cloud servers, offering simplicity and ease of management through user-friendly interfaces or APIs. FastChat
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zheng et al.,
     <a class="ltx_ref" href="#bib.bib53" title="">
      2023
     </a>
     )
    </cite>
    stands out in this context, enabling the deployment of LLMs on any cloud platform. It provides a Web UI for streamlined model and task management and supports OpenAI-compatible RESTful APIs for seamless integration. Additionally, SkyPilot
    <cite class="ltx_cite ltx_citemacro_citep">
     (skypilot org,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2022
     </a>
     )
    </cite>
    offers a diverse range of billing strategies and optimization techniques to enhance cost-efficiency and GPU utilization. Cloud platforms have become the preferred and flexible choice for LLM deployment, eliminating concerns about underlying architecture and details. While supporting both types of platforms, DB-GPT allows users to deploy on personal devices or local servers and run even in scenarios without Internet connection, which ensures data security and privacy.
   </p>
  </div>
  <div class="ltx_para" id="S5.p5">
   <p class="ltx_p" id="S5.p5.1">
    <span class="ltx_text ltx_font_bold" id="S5.p5.1.1">
     Text-to-SQL Fine-Tuning.
    </span>
    Text-to-SQL aims to automate the process of generating SQL queries for databases from natural language text. It is a long-standing challenge, crucial to enhance database accessibility without requiring
expertise of SQL. LLMs, such as GPT-4
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib29" title="">
      2023
     </a>
     )
    </cite>
    , PALM
    <cite class="ltx_cite ltx_citemacro_citep">
     (Chowdhery et al.,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2022
     </a>
     )
    </cite>
    and Llama-2
    <cite class="ltx_cite ltx_citemacro_citep">
     (Touvron et al.,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023
     </a>
     )
    </cite>
    , have shown significant achievements with few-shot prompting or in-context learning on this task and the performance can be further improved by fine-tuning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Sun et al.,
     <a class="ltx_ref" href="#bib.bib36" title="">
      2023
     </a>
     )
    </cite>
    . Compared to several competitors, e.g., LangChain, PrivateGPT and ChatDB, our DB-GPT fine-tuned severl commonly used LLMs for Text-to-SQL. By automating the query generation, DB-GPT enables the development of conversational agents
with advanced data analytics.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    We presented an open-source, intelligent dialogue system for databases, which outperforms the best available solutions as evidenced by its superior capabilities in solving a wide range of tasks.
Our systematic approach contributes to the line of research on building LLMs for databases. In addition, our training and inference strategies may be useful for developing retrieval-based dialogue systems in general domains, allowing us to unlock broader real applications.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Anil et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., et al.
    </span>
    <span class="ltx_bibblock">
     Palm 2 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint arXiv:2305.10403
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Bai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., Hui, B., Ji, L., Li, M., Lin, J., Lin, R., Liu, D., Liu, G., Lu, C., Lu, K., Ma, J., Men, R., Ren, X., Ren, X., Tan, C., Tan, S., Tu, J., Wang, P., Wang, S., Wang, W., Wu, S., Xu, B., Xu, J., Yang, A., Yang, H., Yang, J., Yang, S., Yao, Y., Yu, B., Yuan, H., Yuan, Z., Zhang, J., Zhang, X., Zhang, Y., Zhang, Z., Zhou, C., Zhou, J., Zhou, X., and Zhu, T.
    </span>
    <span class="ltx_bibblock">
     Qwen technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2309.16609
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Baichuan (2023)
    </span>
    <span class="ltx_bibblock">
     Baichuan.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2309.10305" target="_blank" title="">
      Baichuan 2: Open large-scale language models
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      arXiv preprint arXiv:2309.10305
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" target="_blank" title="">
      Language models are few-shot learners
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cao et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Cao, S., Shi, J., Pan, L., Nie, L., Xiang, Y., Hou, L., Li, J., He, B., and Zhang, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.422" target="_blank" title="">
      KQA pro: A dataset with explicit compositional programs for complex question answering over knowledge base
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In Muresan, S., Nakov, P., and Villavicencio, A. (eds.),
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
     </em>
     , pp.  6101–6119, Dublin, Ireland, May 2022. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chase (2022)
    </span>
    <span class="ltx_bibblock">
     Chase, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/hwchase17/langchain" target="_blank" title="">
      LangChain
     </a>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2107.03374" target="_blank" title="">
      Evaluating large language models trained on code
     </a>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chowdhery et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V., Robinson, K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov, O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck, D., Dean, J., Petrov, S., and Fiedel, N.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2204.02311" target="_blank" title="">
      Palm: Scaling language modeling with pathways
     </a>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Chu, Z., Hao, H., Ouyang, X., Wang, S., Wang, Y., Shen, Y., Gu, J., Cui, Q., Li, L., Xue, S., et al.
    </span>
    <span class="ltx_bibblock">
     Leveraging large language models for pre-trained recommender systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2308.10837
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Dong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., Sun, X., Xu, J., and Sui, Z.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:255372865" target="_blank" title="">
      A survey on in-context learning
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Group (2021)
    </span>
    <span class="ltx_bibblock">
     Group, A.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/oceanbase" target="_blank" title="">
      OceanBase
     </a>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gunasekar et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Gunasekar, S., Zhang, Y., Aneja, J., Mendes, C. C. T., Del Giorno, A., Gopi, S., Javaheripi, M., Kauffmann, P., de Rosa, G., Saarikivi, O., et al.
    </span>
    <span class="ltx_bibblock">
     Textbooks are all you need.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      arXiv preprint arXiv:2306.11644
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     H2O.ai (2023)
    </span>
    <span class="ltx_bibblock">
     H2O.ai.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/h2oai/h2ogpt" target="_blank" title="">
      H2OGPT
     </a>
     , May 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hong et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hong, S., Zheng, X., Chen, J., Cheng, Y., Wang, J., Zhang, C., Wang, Z., Yau, S. K. S., Lin, Z., Zhou, L., Ran, C., Xiao, L., and Wu, C.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2308.00352" target="_blank" title="">
      Metagpt: Meta programming for multi-agent collaborative framework
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hu, C., Fu, J., Du, C., Luo, S., Zhao, J., and Zhao, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.03901" target="_blank" title="">
      Chatdb: Augmenting llms with databases as their symbolic memory
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huggingface (2021)
    </span>
    <span class="ltx_bibblock">
     Huggingface.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://huggingface.co/text-generation-inference" target="_blank" title="">
      Text Generation Inference
     </a>
     , May 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jiang, G., Jiang, C., Xue, S., Zhang, J. Y., Zhou, J., Lian, D., and Wei, Y.
    </span>
    <span class="ltx_bibblock">
     Towards anytime fine-tuning: Continually pre-trained language models with hypernetwork prompt.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jin et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jin, M., Wen, Q., Liang, Y., Zhang, C., Xue, S., Wang, X., Zhang, J., Wang, Y., Chen, H., Li, X., Pan, S., Tseng, V. S., Zheng, Y., Chen, L., and Xiong, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.10196" target="_blank" title="">
      Large models for time series and spatio-temporal data: A survey and outlook
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kwon et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C. H., Gonzalez, J. E., Zhang, H., and Stoica, I.
    </span>
    <span class="ltx_bibblock">
     Efficient memory management for large language model serving with pagedattention.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lan et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Lan, Y., He, G., Jiang, J., Jiang, J., Zhao, W. X., and Wen, J.-R.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2108.06688" target="_blank" title="">
      Complex knowledge base question answering: A survey
     </a>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewis et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Kuttler, H., Lewis, M., tau Yih, W., Rocktäschel, T., Riedel, S., and Kiela, D.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:218869575" target="_blank" title="">
      Retrieval-augmented generation for knowledge-intensive nlp tasks
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      ArXiv
     </em>
     , abs/2005.11401, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Liu, A., Hu, X., Wen, L., and Yu, P. S.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.13547" target="_blank" title="">
      A comprehensive evaluation of chatgpt’s zero-shot text-to-sql capability
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu (2022)
    </span>
    <span class="ltx_bibblock">
     Liu, J.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.5281/zenodo.1234" target="_blank" title="">
      LlamaIndex
     </a>
     , 11 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Martínez et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Martínez, I., Gallego Vico, D., and Orgaz, P.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/imartinez/privateGPT" target="_blank" title="">
      PrivateGPT
     </a>
     , May 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (25)
    </span>
    <span class="ltx_bibblock">
     MongoDB.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://www.mongodb.com/" target="_blank" title="">
      MongoDB
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     (26)
    </span>
    <span class="ltx_bibblock">
     MySQL.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://www.mysql.com/" target="_blank" title="">
      MySQL
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nakano et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et al.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2112.09332" target="_blank" title="">
      Webgpt: Browser-assisted question-answering with human feedback
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      arXiv preprint arXiv:2112.09332
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     NVIDIA (2021)
    </span>
    <span class="ltx_bibblock">
     NVIDIA.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/NVIDIA/TensorRT" target="_blank" title="">
      TensorRT
     </a>
     , May 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.08774.pdf" target="_blank" title="">
      GPT-4 technical report
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      arXiv preprint arXiv:2303.08774
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Pan, C., Zhou, F., Hu, X., Zhu, X., Ning, W., Zhuang, Z., Xue, S., Zhang, J., and Hu, Y.
    </span>
    <span class="ltx_bibblock">
     Deep optimal timing strategies for time series.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      ICDM
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Qu, C., Tan, X., Xue, S., Shi, X., Zhang, J., and Mei, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2201.12569" target="_blank" title="">
      Bellman meets hawkes: Model-based reinforcement learning via temporal point processes
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      Proceedings of the AAAI Conference on Artificial Intelligence
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Richards (2022)
    </span>
    <span class="ltx_bibblock">
     Richards, T. B.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" title="">
      Autogpt
     </a>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schick et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., and Scialom, T.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2302.04761" target="_blank" title="">
      Toolformer: Language models can teach themselves to use tools
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      arXiv preprint arXiv:2302.04761
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shi et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shi, X., Xue, S., Wang, K., Zhou, F., Zhang, J. Y., Zhou, J., Tan, C., and Mei, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.16646" target="_blank" title="">
      Language models can improve event prediction by few-shot abductive reasoning
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     skypilot org (2022)
    </span>
    <span class="ltx_bibblock">
     skypilot org.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/skypilot-org/skypilot" target="_blank" title="">
      Skypilot
     </a>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sun, R., Arik, S. O., Nakhost, H., Dai, H., Sinha, R., Yin, P., and Pfister, T.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.00739" target="_blank" title="">
      Sql-palm: Improved large language model adaptation for text-to-sql
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.09288" target="_blank" title="">
      Llama 2: Open foundation and fine-tuned chat models
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2016)
    </span>
    <span class="ltx_bibblock">
     Wang, H., He, D., and Tang, S.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TIFS.2016.2520886" target="_blank" title="">
      Identity-based proxy-oriented data uploading and remote data integrity checking in public cloud
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      IEEE Transactions on Information Forensics and Security
     </em>
     , 11(6):1165–1176, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Wang, L., Yang, N., Huang, X., Jiao, B., Yang, L., Jiang, D., Majumder, R., and Wei, F.
    </span>
    <span class="ltx_bibblock">
     Text embeddings by weakly-supervised contrastive pre-training.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2212.03533
     </em>
     , 2022a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J. Y., Cui, Q., et al.
    </span>
    <span class="ltx_bibblock">
     Enhancing recommender systems with large language model reasoning graphs.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2308.10835
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Wang, Z., Zhang, Z., Lee, C.-Y., Zhang, H., Sun, R., Ren, X., Su, G., Perot, V., Dy, J., and Pfister, T.
    </span>
    <span class="ltx_bibblock">
     Learning to prompt for continual learning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
     </em>
     , pp.  139–149, 2022b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang, P., Dean, J., and Fedus, W.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2206.07682" target="_blank" title="">
      Emergent abilities of large language models
     </a>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Xue, S., Shi, X., Hao, H., Ma, L., Zhang, J., Wang, S., and Wang, S.
    </span>
    <span class="ltx_bibblock">
     A graph regularized point process model for event propagation sequence.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      IJCNN
     </em>
     , pp.  1–7, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Xue, S., Qu, C., Shi, X., Liao, C., Zhu, S., Tan, X., Ma, L., Wang, S., Wang, S., Hu, Y., Lei, L., Zheng, Y., Li, J., and Zhang, J.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3534678.3539063" target="_blank" title="">
      A meta reinforcement learning approach for predictive autoscaling in the cloud
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In Zhang, A. and Rangwala, H. (eds.),
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      KDD ’22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022
     </em>
     , pp.  4290–4299. ACM, 2022a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Xue, S., Shi, X., Zhang, Y. J., and Mei, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2210.01753" target="_blank" title="">
      Hypro: A hybridly normalized probabilistic model for long-horizon prediction of event sequences
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 2022b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Xue, S., Shi, X., Chu, Z., Wang, Y., Zhou, F., Hao, H., Jiang, C., Pan, C., Xu, Y., Zhang, J. Y., Wen, Q., Zhou, J., and Mei, H.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.08097" target="_blank" title="">
      Easytpp: Towards open benchmarking the temporal point processes
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Xue, S., Wang, Y., Chu, Z., Shi, X., Jiang, C., Hao, H., Jiang, G., Feng, X., Zhang, J., and Zhou, J.
    </span>
    <span class="ltx_bibblock">
     Prompt-augmented temporal point process for streaming event sequence.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      NeurIPS
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xue et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Xue, S., Zhou, F., Xu, Y., Zhao, H., Xie, S., Jiang, C., Zhang, J., Zhou, J., Xiu, D., and Mei, H.
    </span>
    <span class="ltx_bibblock">
     Weaverbird: Empowering financial decision-making with large language model, knowledge base, and search engine, 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y.
    </span>
    <span class="ltx_bibblock">
     ReAct: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">
      International Conference on Learning Representations (ICLR)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yu et al. (2018)
    </span>
    <span class="ltx_bibblock">
     Yu, T., Zhang, R., Yang, K., Yasunaga, M., Wang, D., Li, Z., Ma, J., Li, I., Yao, Q., Roman, S., Zhang, Z., and Radev, D.
    </span>
    <span class="ltx_bibblock">
     Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">
      Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing
     </em>
     , Brussels, Belgium, 2018. Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zeng et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Zeng, A., Liu, X., Du, Z., Wang, Z., Lai, H., Ding, M., Yang, Z., Xu, Y., Zheng, W., Xia, X., et al.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2210.02414" target="_blank" title="">
      Glm-130b: An open bilingual pre-trained model
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      arXiv preprint arXiv:2210.02414
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Zhao, T. Z., Wallace, E., Feng, S., Klein, D., and Singh, S.
    </span>
    <span class="ltx_bibblock">
     Calibrate before use: Improving few-shot performance of language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">
      arXiv preprint arXiv:2102.09690
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E. P., Zhang, H., Gonzalez, J. E., and Stoica, I.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.05685" target="_blank" title="">
      Judging llm-as-a-judge with mt-bench and chatbot arena
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhou, X., Li, G., and Liu, Z.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2308.05481" target="_blank" title="">
      Llm as dba
     </a>
     , 2023.
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <div class="ltx_para" id="p1">
  <span class="ltx_ERROR undefined" id="p1.1">
   \appendixpage
  </span>
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Ongoing and Future Work
  </h2>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.1">
    We are currently exploring several extensions to deal with more complex dialogue and analytics cases in our system. We are particularly interested in handling:
   </p>
   <ul class="ltx_itemize" id="A1.I1">
    <li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="A1.I1.i1.p1">
      <p class="ltx_p" id="A1.I1.i1.p1.1">
       More powerful agents.
Users may want our system not only to perform the analysis but also provide more powerful abilities, such as classical time series predictions
       <cite class="ltx_cite ltx_citemacro_citep">
        (Jin et al.,
        <a class="ltx_ref" href="#bib.bib18" title="">
         2023
        </a>
        ; Xue et al.,
        <a class="ltx_ref" href="#bib.bib43" title="">
         2021
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib45" title="">
         2022b
        </a>
        ,
        <a class="ltx_ref" href="#bib.bib46" title="">
         2023a
        </a>
        )
       </cite>
       based on historical data and predictive decision abilities
       <cite class="ltx_cite ltx_citemacro_citep">
        (Xue et al.,
        <a class="ltx_ref" href="#bib.bib44" title="">
         2022a
        </a>
        ; Qu et al.,
        <a class="ltx_ref" href="#bib.bib31" title="">
         2023
        </a>
        ; Pan et al.,
        <a class="ltx_ref" href="#bib.bib30" title="">
         2023
        </a>
        )
       </cite>
       .
      </p>
     </div>
    </li>
    <li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="A1.I1.i2.p1">
      <p class="ltx_p" id="A1.I1.i2.p1.1">
       Integration of more model training techniques. In addition to pre-training, the community is also interested in continual learning techniques for language models, such as continual pre-training
       <cite class="ltx_cite ltx_citemacro_citep">
        (Jiang et al.,
        <a class="ltx_ref" href="#bib.bib17" title="">
         2023
        </a>
        )
       </cite>
       , prompt learning
       <cite class="ltx_cite ltx_citemacro_citep">
        (Wang et al.,
        <a class="ltx_ref" href="#bib.bib41" title="">
         2022b
        </a>
        ; Xue et al.,
        <a class="ltx_ref" href="#bib.bib47" title="">
         2023b
        </a>
        )
       </cite>
       . The integration of these methods will greatly facilitate the research community in these areas.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="A1.I1.i3.p1">
      <p class="ltx_p" id="A1.I1.i3.p1.1">
       More user-friendly presentation.
Users may desire our system presenting answers in richer formats such as tables and diagrams. We have launched a new project DB-GPT-Vis
       <span class="ltx_note ltx_role_footnote" id="footnote2">
        <sup class="ltx_note_mark">
         2
        </sup>
        <span class="ltx_note_outer">
         <span class="ltx_note_content">
          <sup class="ltx_note_mark">
           2
          </sup>
          <span class="ltx_tag ltx_tag_note">
           2
          </span>
          <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/eosphoros-ai/GPT-Vis" style="font-size:90%;" target="_blank" title="">
           https://github.com/eosphoros-ai/GPT-Vis
          </a>
         </span>
        </span>
       </span>
       that provides flexible and diverse visualization components for the chat box powered by LLMs.
      </p>
     </div>
    </li>
   </ul>
  </div>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Experiment Details
  </h2>
  <section class="ltx_subsection" id="A2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     B.1
    </span>
    Text-to-SQL Evaluation Details
   </h3>
   <section class="ltx_paragraph" id="A2.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Dataset Details.
    </h4>
    <div class="ltx_para" id="A2.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="A2.SS1.SSS0.Px1.p1.1">
      <a class="ltx_ref" href="#A2.T7" title="In Dataset Details. ‣ B.1 Text-to-SQL Evaluation Details ‣ Appendix B Experiment Details ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      shows the distribution of the dataset.
     </p>
    </div>
    <figure class="ltx_table" id="A2.T7">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T7.1">
      <tr class="ltx_tr" id="A2.T7.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T7.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.1.1.1" style="font-size:90%;">
         Dataset
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="A2.T7.1.1.2">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.1.2.1" style="font-size:90%;">
         # Questions
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T7.1.2">
       <td class="ltx_td" id="A2.T7.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T7.1.2.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.2.2.1">
         <span class="ltx_p" id="A2.T7.1.2.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.2.2.1.1.1" style="font-size:90%;">
           Easy
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T7.1.2.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.2.3.1">
         <span class="ltx_p" id="A2.T7.1.2.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.2.3.1.1.1" style="font-size:90%;">
           Medium
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T7.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.2.4.1">
         <span class="ltx_p" id="A2.T7.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.2.4.1.1.1" style="font-size:90%;">
           Hard
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T7.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.2.5.1">
         <span class="ltx_p" id="A2.T7.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.2.5.1.1.1" style="font-size:90%;">
           Extra
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T7.1.2.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.2.6.1">
         <span class="ltx_p" id="A2.T7.1.2.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.2.6.1.1.1" style="font-size:90%;">
           Overall
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T7.1.3">
       <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A2.T7.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.3.1.1" style="font-size:90%;">
         Spider-dev
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A2.T7.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.3.2.1">
         <span class="ltx_p" id="A2.T7.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.3.2.1.1.1" style="font-size:90%;">
           248
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A2.T7.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.3.3.1">
         <span class="ltx_p" id="A2.T7.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.3.3.1.1.1" style="font-size:90%;">
           446
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A2.T7.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.3.4.1">
         <span class="ltx_p" id="A2.T7.1.3.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.3.4.1.1.1" style="font-size:90%;">
           174
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A2.T7.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.3.5.1">
         <span class="ltx_p" id="A2.T7.1.3.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.3.5.1.1.1" style="font-size:90%;">
           166
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A2.T7.1.3.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T7.1.3.6.1">
         <span class="ltx_p" id="A2.T7.1.3.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T7.1.3.6.1.1.1" style="font-size:90%;">
           1034
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 7:
      </span>
      Text-to-SQL dataset details.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="A2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     B.2
    </span>
    RAG Evaluation Details
   </h3>
   <section class="ltx_paragraph" id="A2.SS2.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Dataset Details.
    </h4>
    <div class="ltx_para" id="A2.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="A2.SS2.SSS0.Px1.p1.1">
      We collect approximately
      <math alttext="100" class="ltx_Math" display="inline" id="A2.SS2.SSS0.Px1.p1.1.m1.1">
       <semantics id="A2.SS2.SSS0.Px1.p1.1.m1.1a">
        <mn id="A2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="A2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">
         100
        </mn>
        <annotation-xml encoding="MathML-Content" id="A2.SS2.SSS0.Px1.p1.1.m1.1b">
         <cn id="A2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="A2.SS2.SSS0.Px1.p1.1.m1.1.1">
          100
         </cn>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A2.SS2.SSS0.Px1.p1.1.m1.1c">
         100
        </annotation>
       </semantics>
      </math>
      questions approximately 100 questions each for the database domain (DatabaseQA) and the finance domain (FinancialQA). In addition, we annotate the questions by the difficulties proposed by experts.
      <a class="ltx_ref" href="#A2.T8" title="In Dataset Details. ‣ B.2 RAG Evaluation Details ‣ Appendix B Experiment Details ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        8
       </span>
      </a>
      shows the statistics for both datasets.
     </p>
    </div>
    <figure class="ltx_table" id="A2.T8">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T8.1">
      <tr class="ltx_tr" id="A2.T8.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T8.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.1.1.1" style="font-size:90%;">
         Dataset
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A2.T8.1.1.2">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.1.2.1" style="font-size:90%;">
         # Questions
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T8.1.2">
       <td class="ltx_td" id="A2.T8.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.2.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.2.2.1">
         <span class="ltx_p" id="A2.T8.1.2.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.2.2.1.1.1" style="font-size:90%;">
           Easy
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.2.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.2.3.1">
         <span class="ltx_p" id="A2.T8.1.2.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.2.3.1.1.1" style="font-size:90%;">
           Medium
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.2.4.1">
         <span class="ltx_p" id="A2.T8.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.2.4.1.1.1" style="font-size:90%;">
           Hard
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.2.5.1">
         <span class="ltx_p" id="A2.T8.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.2.5.1.1.1" style="font-size:90%;">
           Overral
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T8.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T8.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.3.1.1" style="font-size:90%;">
         DatabaseQA
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.3.2.1">
         <span class="ltx_p" id="A2.T8.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.3.2.1.1.1" style="font-size:90%;">
           37
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.3.3.1">
         <span class="ltx_p" id="A2.T8.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.3.3.1.1.1" style="font-size:90%;">
           35
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.3.4.1">
         <span class="ltx_p" id="A2.T8.1.3.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.3.4.1.1.1" style="font-size:90%;">
           16
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T8.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.3.5.1">
         <span class="ltx_p" id="A2.T8.1.3.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.3.5.1.1.1" style="font-size:90%;">
           88
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T8.1.4">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T8.1.4.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.4.1.1" style="font-size:90%;">
         FinancialQA
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T8.1.4.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.4.2.1">
         <span class="ltx_p" id="A2.T8.1.4.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.4.2.1.1.1" style="font-size:90%;">
           50
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T8.1.4.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.4.3.1">
         <span class="ltx_p" id="A2.T8.1.4.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.4.3.1.1.1" style="font-size:90%;">
           13
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T8.1.4.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.4.4.1">
         <span class="ltx_p" id="A2.T8.1.4.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.4.4.1.1.1" style="font-size:90%;">
           11
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T8.1.4.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T8.1.4.5.1">
         <span class="ltx_p" id="A2.T8.1.4.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T8.1.4.5.1.1.1" style="font-size:90%;">
           74
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 8:
      </span>
      RAG dataset details.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="A2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     B.3
    </span>
    SMMF Evaluation Details
   </h3>
   <section class="ltx_paragraph" id="A2.SS3.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     More Results.
    </h4>
    <div class="ltx_para" id="A2.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="A2.SS3.SSS0.Px1.p1.1">
      We provide the results with Vicuna as the base LLM, shown in
      <a class="ltx_ref" href="#A2.T9" title="In More Results. ‣ B.3 SMMF Evaluation Details ‣ Appendix B Experiment Details ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        9
       </span>
      </a>
      . The results are consistent with those in
      <a class="ltx_ref" href="#S4.T5" title="In Main Results. ‣ 4.3 SMMF Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      and
      <a class="ltx_ref" href="#S4.T6" title="In Main Results. ‣ 4.3 SMMF Evaluation ‣ 4 Experiments ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
       <span class="ltx_text ltx_ref_tag">
        Table
       </span>
       <span class="ltx_text ltx_ref_tag">
        6
       </span>
      </a>
      .
     </p>
    </div>
    <figure class="ltx_table" id="A2.T9">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T9.1">
      <tr class="ltx_tr" id="A2.T9.1.1">
       <td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T9.1.1.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.1.1.1" style="font-size:90%;">
         Model
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_tt" id="A2.T9.1.1.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.1.2.1">
         <span class="ltx_p" id="A2.T9.1.1.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.1.2.1.1.1" style="font-size:90%;">
           # Ccr
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_tt" id="A2.T9.1.1.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.1.3.1">
         <span class="ltx_p" id="A2.T9.1.1.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.1.3.1.1.1" style="font-size:90%;">
           Platform
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="A2.T9.1.1.4">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.1.4.1" style="font-size:90%;">
         Metrics
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T9.1.2">
       <td class="ltx_td" id="A2.T9.1.2.1">
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.2.2">
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.2.3">
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.2.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.2.4.1">
         <span class="ltx_p" id="A2.T9.1.2.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.2.4.1.1.1" style="font-size:90%;">
           FTL (ms)
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.2.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.2.5.1">
         <span class="ltx_p" id="A2.T9.1.2.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.2.5.1.1.1" style="font-size:90%;">
           IL (s)
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.2.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.2.6.1">
         <span class="ltx_p" id="A2.T9.1.2.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.2.6.1.1.1" style="font-size:90%;">
           Throughput (tokens)
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T9.1.3">
       <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T9.1.3.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.3.1.1" style="font-size:90%;">
         Vicuna-7b
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.3.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.3.2.1">
         <span class="ltx_p" id="A2.T9.1.3.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.3.2.1.1.1" style="font-size:90%;">
           4
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.3.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.3.3.1">
         <span class="ltx_p" id="A2.T9.1.3.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.3.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.3.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.3.4.1">
         <span class="ltx_p" id="A2.T9.1.3.4.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.3.4.1.1.1" style="font-size:90%;">
           23
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.3.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.3.5.1">
         <span class="ltx_p" id="A2.T9.1.3.5.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.3.5.1.1.1" style="font-size:90%;">
           5
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.3.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.3.6.1">
         <span class="ltx_p" id="A2.T9.1.3.6.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.3.6.1.1.1" style="font-size:90%;">
           217
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T9.1.4">
       <td class="ltx_td ltx_align_left" id="A2.T9.1.4.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.4.1.1" style="font-size:90%;">
         Vicuna-7b
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.4.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.4.2.1">
         <span class="ltx_p" id="A2.T9.1.4.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.4.2.1.1.1" style="font-size:90%;">
           4
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.4.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.4.3.1">
         <span class="ltx_p" id="A2.T9.1.4.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.4.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.4.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.4.4.1">
         <span class="ltx_p" id="A2.T9.1.4.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.4.4.1.1.1" style="font-size:90%;">
           815
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.4.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.4.5.1">
         <span class="ltx_p" id="A2.T9.1.4.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.4.5.1.1.1" style="font-size:90%;">
           67
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.4.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.4.6.1">
         <span class="ltx_p" id="A2.T9.1.4.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.4.6.1.1.1" style="font-size:90%;">
           15
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T9.1.5">
       <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T9.1.5.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.5.1.1" style="font-size:90%;">
         Vicuna-7b
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.5.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.5.2.1">
         <span class="ltx_p" id="A2.T9.1.5.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.5.2.1.1.1" style="font-size:90%;">
           16
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.5.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.5.3.1">
         <span class="ltx_p" id="A2.T9.1.5.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.5.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.5.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.5.4.1">
         <span class="ltx_p" id="A2.T9.1.5.4.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.5.4.1.1.1" style="font-size:90%;">
           36
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.5.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.5.5.1">
         <span class="ltx_p" id="A2.T9.1.5.5.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.5.5.1.1.1" style="font-size:90%;">
           7
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.5.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.5.6.1">
         <span class="ltx_p" id="A2.T9.1.5.6.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.5.6.1.1.1" style="font-size:90%;">
           646
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T9.1.6">
       <td class="ltx_td ltx_align_left" id="A2.T9.1.6.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.6.1.1" style="font-size:90%;">
         Vicuna-7b
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.6.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.6.2.1">
         <span class="ltx_p" id="A2.T9.1.6.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.6.2.1.1.1" style="font-size:90%;">
           16
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.6.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.6.3.1">
         <span class="ltx_p" id="A2.T9.1.6.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.6.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.6.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.6.4.1">
         <span class="ltx_p" id="A2.T9.1.6.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.6.4.1.1.1" style="font-size:90%;">
           5128
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.6.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.6.5.1">
         <span class="ltx_p" id="A2.T9.1.6.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.6.5.1.1.1" style="font-size:90%;">
           914
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify" id="A2.T9.1.6.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.6.6.1">
         <span class="ltx_p" id="A2.T9.1.6.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.6.6.1.1.1" style="font-size:90%;">
           5
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T9.1.7">
       <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T9.1.7.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.7.1.1" style="font-size:90%;">
         Vicuna-7b
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.7.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.7.2.1">
         <span class="ltx_p" id="A2.T9.1.7.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.7.2.1.1.1" style="font-size:90%;">
           32
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.7.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.7.3.1">
         <span class="ltx_p" id="A2.T9.1.7.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.7.3.1.1.1" style="font-size:90%;">
           vLLM
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.7.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.7.4.1">
         <span class="ltx_p" id="A2.T9.1.7.4.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.7.4.1.1.1" style="font-size:90%;">
           53
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.7.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.7.5.1">
         <span class="ltx_p" id="A2.T9.1.7.5.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.7.5.1.1.1" style="font-size:90%;">
           8
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T9.1.7.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.7.6.1">
         <span class="ltx_p" id="A2.T9.1.7.6.1.1">
          <span class="ltx_text ltx_font_bold" id="A2.T9.1.7.6.1.1.1" style="font-size:90%;">
           1000
          </span>
         </span>
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="A2.T9.1.8">
       <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T9.1.8.1">
        <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.8.1.1" style="font-size:90%;">
         Vicuna-7b
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T9.1.8.2">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.8.2.1">
         <span class="ltx_p" id="A2.T9.1.8.2.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.8.2.1.1.1" style="font-size:90%;">
           32
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T9.1.8.3">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.8.3.1">
         <span class="ltx_p" id="A2.T9.1.8.3.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.8.3.1.1.1" style="font-size:90%;">
           HF
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T9.1.8.4">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.8.4.1">
         <span class="ltx_p" id="A2.T9.1.8.4.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.8.4.1.1.1" style="font-size:90%;">
           11251
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T9.1.8.5">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.8.5.1">
         <span class="ltx_p" id="A2.T9.1.8.5.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.8.5.1.1.1" style="font-size:90%;">
           1453
          </span>
         </span>
        </span>
       </td>
       <td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T9.1.8.6">
        <span class="ltx_inline-block ltx_align_top" id="A2.T9.1.8.6.1">
         <span class="ltx_p" id="A2.T9.1.8.6.1.1">
          <span class="ltx_text ltx_font_smallcaps" id="A2.T9.1.8.6.1.1.1" style="font-size:90%;">
           6
          </span>
         </span>
        </span>
       </td>
      </tr>
     </table>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_table">
       Table 9:
      </span>
      Evaluation on SMMF with Vicuna as the base LLM.
     </figcaption>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Software Interface
  </h2>
  <div class="ltx_para" id="A3.p1">
   <p class="ltx_p" id="A3.p1.1">
    The main interface of our DB-GP system can be seen in
    <a class="ltx_ref" href="#A3.F6" title="In Appendix C Software Interface ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      Figures
     </span>
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    and
    <a class="ltx_ref" href="#A3.F7" title="Figure 7 ‣ Appendix C Software Interface ‣ DB-GPT: Empowering Database Interactions with Private Large Language Models">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="A3.F6">
   <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="299" id="A3.F6.g1" src="/html/2312.17449/assets/webui.jpg" width="592"/>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 6:
    </span>
    The main interface of DB-GPT: the configuration and chatbox.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A3.F7">
   <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="315" id="A3.F7.g1" src="/html/2312.17449/assets/webui2.jpg" width="592"/>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 7:
    </span>
    The ’plugin’ tab of DB-GPT: the user can choose to load agent plugins (e.g., web search agent) for the QA task.
   </figcaption>
  </figure>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
</article>
