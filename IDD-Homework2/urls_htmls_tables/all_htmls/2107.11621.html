<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2107.11621] FedLab: A Flexible Federated Learning Framework</title><meta property="og:description" content="Federated learning (FL) is a machine learning field in which researchers try to facilitate model learning process among multiparty without violating privacy protection regulations. Considerable effort has been invested…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedLab: A Flexible Federated Learning Framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedLab: A Flexible Federated Learning Framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2107.11621">

<!--Generated on Wed Mar  6 22:12:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FedLab: A Flexible Federated Learning Framework</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Dun Zeng<sup id="id10.10.id1" class="ltx_sup"><span id="id10.10.id1.1" class="ltx_text ltx_font_italic">1∗</span></sup>, Siqi Liang<sup id="id11.11.id2" class="ltx_sup"><span id="id11.11.id2.1" class="ltx_text ltx_font_italic">2</span></sup>, Xiangjing Hu<sup id="id12.12.id3" class="ltx_sup"><span id="id12.12.id3.1" class="ltx_text ltx_font_italic">3</span></sup>, Hui Wang<sup id="id13.13.id4" class="ltx_sup"><span id="id13.13.id4.1" class="ltx_text ltx_font_italic">4</span></sup>, Zenglin Xu<sup id="id14.14.id5" class="ltx_sup"><span id="id14.14.id5.1" class="ltx_text ltx_font_italic">3,4</span></sup>
<br class="ltx_break"><sup id="id15.15.id6" class="ltx_sup">1</sup>School of Computer Science and Engineering, University of Electronic Science and Technology of China
<br class="ltx_break"><sup id="id16.16.id7" class="ltx_sup">2</sup>Rich Media Big Data Analytics and Application Key Laboratory, 
<br class="ltx_break">Shenzhen Research Institute, The Chinese University of Hong Kong
<br class="ltx_break"><sup id="id17.17.id8" class="ltx_sup">3</sup>School of Computer Science and Technology, Harbin Institute of Technology Shenzhen
<br class="ltx_break"><sup id="id18.18.id9" class="ltx_sup">4</sup>Peng Cheng Laboratory, Shenzhen, China
<br class="ltx_break">zengdun@std.uestc.edu.cn, zszxlsq@gmail.com, xiangjinghu@stu.hit.edu.cn, wangh06@pcl.ac.cn, xuzenglin@hit.edu.cn
</span><span class="ltx_author_notes"> Equal contribution. Corresponding author.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id19.id1" class="ltx_p">Federated learning (FL) is a machine learning field in which researchers try to facilitate model learning process among multiparty without violating privacy protection regulations. Considerable effort has been invested in FL optimization and communication related researches. In this work, we introduce <span id="id19.id1.1" class="ltx_text ltx_font_typewriter">FedLab</span>, a lightweight open-source framework for FL simulation. The design of <span id="id19.id1.2" class="ltx_text ltx_font_typewriter">FedLab</span> focuses on FL algorithm effectiveness and communication efficiency. Also, <span id="id19.id1.3" class="ltx_text ltx_font_typewriter">FedLab</span> is scalable in different deployment scenario. We hope <span id="id19.id1.4" class="ltx_text ltx_font_typewriter">FedLab</span> could provide flexible API as well as reliable baseline implementations, and relieve the burden of implementing novel approaches for researchers in FL community. The source code is available at <span id="id19.id1.5" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">https://github.com/SMILELab-FL/FedLab</span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL), proposed by Google at the very beginning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, is recently a burgeoning research area of machine learning, which aims to protect individual data privacy in distributed machine learning process, especially in finance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, smart healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and edge computing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Different from traditional data-centered distributed machine learning, participants in FL setting utilize localized data to train local model, then leverages specific strategies with other participants to acquire the final model collaboratively, avoiding direct data sharing behavior.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Though it might differ in specific methodologies, current FL schemes can be summarized as repetition of training rounds, with each integrated by several basic steps:

<span id="S1.I1" class="ltx_inline-enumerate">
<span id="S1.I1.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item"><span id="S1.I1.i1.1.1.1" class="ltx_text ltx_font_italic">i</span>)</span> <span id="S1.I1.i1.5" class="ltx_text">local update on client’s model using their own localized data;
</span></span>
<span id="S1.I1.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item"><span id="S1.I1.i2.1.1.1" class="ltx_text ltx_font_italic">ii</span>)</span> <span id="S1.I1.i2.5" class="ltx_text">clients upload their local trained model parameters to server;
</span></span>
<span id="S1.I1.i3" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item"><span id="S1.I1.i3.1.1.1" class="ltx_text ltx_font_italic">iii</span>)</span> <span id="S1.I1.i3.5" class="ltx_text">server performs aggregation strategy on collected clients’ model parameters to obtain global model;
</span></span>
<span id="S1.I1.i4" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item"><span id="S1.I1.i4.1.1.1" class="ltx_text ltx_font_italic">iv</span>)</span> <span id="S1.I1.i4.5" class="ltx_text">server selects a subset of clients and distributes the latest global model to them.
</span></span>
</span>
Many FL researches try to improve algorithm effectiveness or efficiency on only one or more steps in this workflow with different scenarios: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> suggests to add regularization term in step <a href="#S1.I1.i1" title="item i) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">i</span>)</span></a> to achieve more robust convergence in heterogeneous settings; <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> applies gradient compression method in step <a href="#S1.I1.i2" title="item ii) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">ii</span>)</span></a> to reduce communication bandwidth; <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> tries to modify in step <a href="#S1.I1.i1" title="item i) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">i</span>)</span></a>, <a href="#S1.I1.i2" title="item ii) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">ii</span>)</span></a> and <a href="#S1.I1.i3" title="item iii) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">iii</span>)</span></a> for privacy-preserving purpose; <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> proposes better sample strategy in step <a href="#S1.I1.i4" title="item iv) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">iv</span>)</span></a> to address suboptimal result problem in Federated Multi-Task Learning. These indicate that the implementation of many FL algorithms only requires modification on several components of common workflow, without the necessity of repetitive implementation on basic FL workflow. The paradigm of FL and related research points are as depicted in figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">However, though with several FL related frameworks or platforms available, researchers still prefer to implement FL algorithms using PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> or TensorFlow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> from scratch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. This inefficient modus operandi in FL community can hamper researchers’ enthusiasm in both procedures of reproducing previous work and fast verification of new ideas.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.1.1.1" class="ltx_tr">
<th id="S1.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">Method</th>
<th id="S1.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Step <a href="#S1.I1.i1" title="item i) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">i</span>)</span></a>
</th>
<th id="S1.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Step <a href="#S1.I1.i2" title="item ii) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">ii</span>)</span></a>
</th>
<th id="S1.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Step <a href="#S1.I1.i3" title="item iii) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">iii</span>)</span></a>
</th>
<th id="S1.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Step <a href="#S1.I1.i4" title="item iv) ‣ 1 Introduction ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text ltx_font_italic">iv</span>)</span></a>
</th>
<th id="S1.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Platform</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.1.2.1" class="ltx_tr">
<th id="S1.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite></th>
<td id="S1.T1.1.2.1.2" class="ltx_td ltx_border_t"></td>
<td id="S1.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S1.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S1.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S1.T1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">PyTorch<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Official code: <a target="_blank" href="https://github.com/IBM/FedMA" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/IBM/FedMA</a>.</span></span></span>
</td>
</tr>
<tr id="S1.T1.1.3.2" class="ltx_tr">
<th id="S1.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite></th>
<td id="S1.T1.1.3.2.2" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.3.2.3" class="ltx_td"></td>
<td id="S1.T1.1.3.2.4" class="ltx_td"></td>
<td id="S1.T1.1.3.2.5" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.3.2.6" class="ltx_td ltx_align_center">TensorFlow<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Official code: <a target="_blank" href="https://github.com/jichan3751/ifca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jichan3751/ifca</a>.</span></span></span>
</td>
</tr>
<tr id="S1.T1.1.4.3" class="ltx_tr">
<th id="S1.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite></th>
<td id="S1.T1.1.4.3.2" class="ltx_td"></td>
<td id="S1.T1.1.4.3.3" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.4.3.4" class="ltx_td"></td>
<td id="S1.T1.1.4.3.5" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.4.3.6" class="ltx_td ltx_align_center">PyTorch<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Official code: <a target="_blank" href="https://github.com/CharlieDinh/pFedMe" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/CharlieDinh/pFedMe</a>.</span></span></span>
</td>
</tr>
<tr id="S1.T1.1.5.4" class="ltx_tr">
<th id="S1.T1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite></th>
<td id="S1.T1.1.5.4.2" class="ltx_td"></td>
<td id="S1.T1.1.5.4.3" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.5.4.4" class="ltx_td"></td>
<td id="S1.T1.1.5.4.5" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.5.4.6" class="ltx_td ltx_align_center">PyTorch<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Official code: <a target="_blank" href="https://github.com/med-air/FedBN" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/med-air/FedBN</a>.</span></span></span>
</td>
</tr>
<tr id="S1.T1.1.6.5" class="ltx_tr">
<th id="S1.T1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></th>
<td id="S1.T1.1.6.5.2" class="ltx_td"></td>
<td id="S1.T1.1.6.5.3" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.6.5.4" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.6.5.5" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.6.5.6" class="ltx_td ltx_align_center">PyTorch<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Official code: <a target="_blank" href="https://github.com/alpemreacar/FedDyn" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/alpemreacar/FedDyn</a>.</span></span></span>
</td>
</tr>
<tr id="S1.T1.1.7.6" class="ltx_tr">
<th id="S1.T1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></th>
<td id="S1.T1.1.7.6.2" class="ltx_td"></td>
<td id="S1.T1.1.7.6.3" class="ltx_td"></td>
<td id="S1.T1.1.7.6.4" class="ltx_td"></td>
<td id="S1.T1.1.7.6.5" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.7.6.6" class="ltx_td ltx_align_center">PyTorch<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Official code: <a target="_blank" href="https://github.com/hmgxr128/MIFA_code" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/hmgxr128/MIFA_code</a></span></span></span>
</td>
</tr>
<tr id="S1.T1.1.8.7" class="ltx_tr">
<th id="S1.T1.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite></th>
<td id="S1.T1.1.8.7.2" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.8.7.3" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.8.7.4" class="ltx_td"></td>
<td id="S1.T1.1.8.7.5" class="ltx_td ltx_align_center">✓</td>
<td id="S1.T1.1.8.7.6" class="ltx_td ltx_align_center">Sklearn<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Official code: <a target="_blank" href="https://github.com/daizhongxiang/Differentially-Private-Federated-Bayesian-Optimization" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/daizhongxiang/Differentially-Private-Federated-Bayesian-Optimization</a>.</span></span></span>
</td>
</tr>
<tr id="S1.T1.1.9.8" class="ltx_tr">
<th id="S1.T1.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></th>
<td id="S1.T1.1.9.8.2" class="ltx_td ltx_border_b"></td>
<td id="S1.T1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S1.T1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S1.T1.1.9.8.5" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S1.T1.1.9.8.6" class="ltx_td ltx_align_center ltx_border_b">PyTorch<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>Official code: <a target="_blank" href="https://github.com/jhoon-oh/fedbabu" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jhoon-oh/fedbabu</a>.</span></span></span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>The investigation results of recently published FL algorithms.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">To relieve the burden of researchers in implementing FL algorithms and emancipate FL scientists from repetitive implementation of basic FL setting, we introduce highly customizable framework <span id="S1.p4.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> in this paper. <span id="S1.p4.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> provides the necessary modules for FL simulation, including communication, compression, model optimization, data partition and other functional modules. <span id="S1.p4.1.3" class="ltx_text ltx_font_typewriter">FedLab</span> users can build FL simulation environment with custom modules like playing with LEGO bricks. In all, we make the following contributions to FL community:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">A flexible FL framework <span id="S1.I2.i1.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> is proposed, in which the flexibility is given by highly customizable interfaces and scalability in FL system. <span id="S1.I2.i1.p1.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> allows users focus on interested components design while keeping other part default. What’s more, <span id="S1.I2.i1.p1.1.3" class="ltx_text ltx_font_typewriter">FedLab</span> also supports <em id="S1.I2.i1.p1.1.4" class="ltx_emph ltx_font_italic">standalone</em>, <em id="S1.I2.i1.p1.1.5" class="ltx_emph ltx_font_italic">cross machine</em> and <em id="S1.I2.i1.p1.1.6" class="ltx_emph ltx_font_italic">hierarchical</em> simulation paradigms.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">Various data partition tools for comprehensive data distribution scenarios in FL. <span id="S1.I2.i2.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> provides a series of data partition functions as well as built-in data partition schemes for different data distributions over federation.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">Standardized FL implementation schemes are presented through <span id="S1.I2.i3.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span>. For instance, standard synchronous and asynchronous FL system are available. Besides, we also provides FL datasets benchmarks and functional modules for standard FL simulation.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para ltx_noindent">
<p id="S1.I2.i4.p1.1" class="ltx_p">An open-source group is founded in GitHub repository for <span id="S1.I2.i4.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span>’s continuous
maintenance. Elaborate document is published as well.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2107.11621/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="368" height="302" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The paradigm of Federated Learning. The content in black dashed box indicates the communication strategy of FL system. The content in blue dashed box indicates the FL optimization, including global aggregation and local optimization.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Current FL community focuses mainly on two major challenges. Firstly, data heterogeneity across clients slows down model convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> compared with that of data-center distributed learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. The other major challenge is communication cost during both model uploading and downloading processes, which is also the bottleneck of distributed learning. There is an urgent need for improvement on communication, especially when it comes to cross-device scenario. A lot of works have been proposed to tackle these two challenges, which can be categorized into optimization algorithms and communication efficient strategies. In this section, these two popular research sub-fields of FL will be further illustrated, and the need of a convenient FL framework suitable for optimization effectiveness and communication efficiency research will be revealed.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Optimization Algorithms</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.3" class="ltx_p">Malicious attacker is able to steal private information by using gradient attack algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Therefore, clients can’t transmit gradients but model parameters directly. FL server optimizes neural network by aggregating all parameters of clients (which is updated a few epochs locally) into global one. Typically, server aggregates model parameters collected from <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">K</annotation></semantics></math> clients at round <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">i</annotation></semantics></math> to update global weights <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="w^{i+1}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><msup id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">w</mi><mrow id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml"><mi id="S2.SS1.p1.3.m3.1.1.3.2" xref="S2.SS1.p1.3.m3.1.1.3.2.cmml">i</mi><mo id="S2.SS1.p1.3.m3.1.1.3.1" xref="S2.SS1.p1.3.m3.1.1.3.1.cmml">+</mo><mn id="S2.SS1.p1.3.m3.1.1.3.3" xref="S2.SS1.p1.3.m3.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">superscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">𝑤</ci><apply id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3"><plus id="S2.SS1.p1.3.m3.1.1.3.1.cmml" xref="S2.SS1.p1.3.m3.1.1.3.1"></plus><ci id="S2.SS1.p1.3.m3.1.1.3.2.cmml" xref="S2.SS1.p1.3.m3.1.1.3.2">𝑖</ci><cn type="integer" id="S2.SS1.p1.3.m3.1.1.3.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">w^{i+1}</annotation></semantics></math> following FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>:</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.1" class="ltx_Math" alttext="w^{i+1}=\sum_{k=1}^{K}\frac{n_{k}}{n}w_{k}^{i}" display="block"><semantics id="S2.Ex1.m1.1a"><mrow id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml"><msup id="S2.Ex1.m1.1.1.2" xref="S2.Ex1.m1.1.1.2.cmml"><mi id="S2.Ex1.m1.1.1.2.2" xref="S2.Ex1.m1.1.1.2.2.cmml">w</mi><mrow id="S2.Ex1.m1.1.1.2.3" xref="S2.Ex1.m1.1.1.2.3.cmml"><mi id="S2.Ex1.m1.1.1.2.3.2" xref="S2.Ex1.m1.1.1.2.3.2.cmml">i</mi><mo id="S2.Ex1.m1.1.1.2.3.1" xref="S2.Ex1.m1.1.1.2.3.1.cmml">+</mo><mn id="S2.Ex1.m1.1.1.2.3.3" xref="S2.Ex1.m1.1.1.2.3.3.cmml">1</mn></mrow></msup><mo rspace="0.111em" id="S2.Ex1.m1.1.1.1" xref="S2.Ex1.m1.1.1.1.cmml">=</mo><mrow id="S2.Ex1.m1.1.1.3" xref="S2.Ex1.m1.1.1.3.cmml"><munderover id="S2.Ex1.m1.1.1.3.1" xref="S2.Ex1.m1.1.1.3.1.cmml"><mo movablelimits="false" id="S2.Ex1.m1.1.1.3.1.2.2" xref="S2.Ex1.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.Ex1.m1.1.1.3.1.2.3" xref="S2.Ex1.m1.1.1.3.1.2.3.cmml"><mi id="S2.Ex1.m1.1.1.3.1.2.3.2" xref="S2.Ex1.m1.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.Ex1.m1.1.1.3.1.2.3.1" xref="S2.Ex1.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.Ex1.m1.1.1.3.1.2.3.3" xref="S2.Ex1.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.Ex1.m1.1.1.3.1.3" xref="S2.Ex1.m1.1.1.3.1.3.cmml">K</mi></munderover><mrow id="S2.Ex1.m1.1.1.3.2" xref="S2.Ex1.m1.1.1.3.2.cmml"><mfrac id="S2.Ex1.m1.1.1.3.2.2" xref="S2.Ex1.m1.1.1.3.2.2.cmml"><msub id="S2.Ex1.m1.1.1.3.2.2.2" xref="S2.Ex1.m1.1.1.3.2.2.2.cmml"><mi id="S2.Ex1.m1.1.1.3.2.2.2.2" xref="S2.Ex1.m1.1.1.3.2.2.2.2.cmml">n</mi><mi id="S2.Ex1.m1.1.1.3.2.2.2.3" xref="S2.Ex1.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="S2.Ex1.m1.1.1.3.2.2.3" xref="S2.Ex1.m1.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.1.1.3.2.1" xref="S2.Ex1.m1.1.1.3.2.1.cmml">​</mo><msubsup id="S2.Ex1.m1.1.1.3.2.3" xref="S2.Ex1.m1.1.1.3.2.3.cmml"><mi id="S2.Ex1.m1.1.1.3.2.3.2.2" xref="S2.Ex1.m1.1.1.3.2.3.2.2.cmml">w</mi><mi id="S2.Ex1.m1.1.1.3.2.3.2.3" xref="S2.Ex1.m1.1.1.3.2.3.2.3.cmml">k</mi><mi id="S2.Ex1.m1.1.1.3.2.3.3" xref="S2.Ex1.m1.1.1.3.2.3.3.cmml">i</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.1b"><apply id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1"><eq id="S2.Ex1.m1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1"></eq><apply id="S2.Ex1.m1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.2.1.cmml" xref="S2.Ex1.m1.1.1.2">superscript</csymbol><ci id="S2.Ex1.m1.1.1.2.2.cmml" xref="S2.Ex1.m1.1.1.2.2">𝑤</ci><apply id="S2.Ex1.m1.1.1.2.3.cmml" xref="S2.Ex1.m1.1.1.2.3"><plus id="S2.Ex1.m1.1.1.2.3.1.cmml" xref="S2.Ex1.m1.1.1.2.3.1"></plus><ci id="S2.Ex1.m1.1.1.2.3.2.cmml" xref="S2.Ex1.m1.1.1.2.3.2">𝑖</ci><cn type="integer" id="S2.Ex1.m1.1.1.2.3.3.cmml" xref="S2.Ex1.m1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.Ex1.m1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.3"><apply id="S2.Ex1.m1.1.1.3.1.cmml" xref="S2.Ex1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.3.1.1.cmml" xref="S2.Ex1.m1.1.1.3.1">superscript</csymbol><apply id="S2.Ex1.m1.1.1.3.1.2.cmml" xref="S2.Ex1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.3.1.2.1.cmml" xref="S2.Ex1.m1.1.1.3.1">subscript</csymbol><sum id="S2.Ex1.m1.1.1.3.1.2.2.cmml" xref="S2.Ex1.m1.1.1.3.1.2.2"></sum><apply id="S2.Ex1.m1.1.1.3.1.2.3.cmml" xref="S2.Ex1.m1.1.1.3.1.2.3"><eq id="S2.Ex1.m1.1.1.3.1.2.3.1.cmml" xref="S2.Ex1.m1.1.1.3.1.2.3.1"></eq><ci id="S2.Ex1.m1.1.1.3.1.2.3.2.cmml" xref="S2.Ex1.m1.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.Ex1.m1.1.1.3.1.2.3.3.cmml" xref="S2.Ex1.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.Ex1.m1.1.1.3.1.3.cmml" xref="S2.Ex1.m1.1.1.3.1.3">𝐾</ci></apply><apply id="S2.Ex1.m1.1.1.3.2.cmml" xref="S2.Ex1.m1.1.1.3.2"><times id="S2.Ex1.m1.1.1.3.2.1.cmml" xref="S2.Ex1.m1.1.1.3.2.1"></times><apply id="S2.Ex1.m1.1.1.3.2.2.cmml" xref="S2.Ex1.m1.1.1.3.2.2"><divide id="S2.Ex1.m1.1.1.3.2.2.1.cmml" xref="S2.Ex1.m1.1.1.3.2.2"></divide><apply id="S2.Ex1.m1.1.1.3.2.2.2.cmml" xref="S2.Ex1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.3.2.2.2.1.cmml" xref="S2.Ex1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.Ex1.m1.1.1.3.2.2.2.2.cmml" xref="S2.Ex1.m1.1.1.3.2.2.2.2">𝑛</ci><ci id="S2.Ex1.m1.1.1.3.2.2.2.3.cmml" xref="S2.Ex1.m1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="S2.Ex1.m1.1.1.3.2.2.3.cmml" xref="S2.Ex1.m1.1.1.3.2.2.3">𝑛</ci></apply><apply id="S2.Ex1.m1.1.1.3.2.3.cmml" xref="S2.Ex1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.3.2.3.1.cmml" xref="S2.Ex1.m1.1.1.3.2.3">superscript</csymbol><apply id="S2.Ex1.m1.1.1.3.2.3.2.cmml" xref="S2.Ex1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.3.2.3.2.1.cmml" xref="S2.Ex1.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.Ex1.m1.1.1.3.2.3.2.2.cmml" xref="S2.Ex1.m1.1.1.3.2.3.2.2">𝑤</ci><ci id="S2.Ex1.m1.1.1.3.2.3.2.3.cmml" xref="S2.Ex1.m1.1.1.3.2.3.2.3">𝑘</ci></apply><ci id="S2.Ex1.m1.1.1.3.2.3.3.cmml" xref="S2.Ex1.m1.1.1.3.2.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.1c">w^{i+1}=\sum_{k=1}^{K}\frac{n_{k}}{n}w_{k}^{i}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.4" class="ltx_p">Under this setting, FL optimization still faces many challenges.
In data-center distributed machine learning, each computation node get its dataset from parameter server, which makes data distribution independently identically distribution (I.I.D) across nodes. However, data in FL clients can be Non-I.I.D in many ways <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, which leads to inferior robustness and slow convergence.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p">Plenty of federated optimization algorithms are proposed to overcome data None-I.I.D problem. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> try to learn a better shared federated model based on different aggregation strategies. FL Pensonalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> aims to learn personalized model for every client. The combination of FL and other deep learning techniques, such as meta learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, etc., are popular as well. To summarize, most optimization researches only relate to local training process on client and parameter aggregation process on FL server, which indicates that a flexible FL framework shall provide customizable interfaces for both local training design as well as server aggregation strategies.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Communication and Compression</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">Bandwidth problem is bottleneck of large-scale distributed training, and it becomes even worse when distributed training is performed in FL. Thus, deploying communication compression strategy is necessary, especially in cross-device setting. Two common-used and low resource-consumption compression methods as follows:</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.2" class="ltx_p"><span id="S2.SS2.p2.2.1" class="ltx_text ltx_font_bold">Quantization</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> replaces each tensor with a lower precision one (e.g., float16 instead of float32), accomplishing the trade-off between precision and compression ratio.
<span id="S2.SS2.p2.2.2" class="ltx_text ltx_font_bold">Sparsification</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> selects a subset of tensors by appointed principle (e.g., Top-<math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">k</annotation></semantics></math> selection) to transmit. It can achieve at least 100<math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mo id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><times id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">\times</annotation></semantics></math> compression ratio. These two compression methods are model independent, which shows a flexible FL framework shall also provide model-independent compression module.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Related work</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.p1.1" class="ltx_p">Several open-sources FL frameworks have been released. FATE<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://fate.fedai.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://fate.fedai.org/</a></span></span></span> is a large federated secure computing framework. PaddleFL<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://github.com/PaddlePaddle/PaddleFL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/PaddlePaddle/PaddleFL</a></span></span></span> and FedLearner<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://github.com/bytedance/fedlearner" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/bytedance/fedlearner</a></span></span></span> are proposed by Baidu and Bytedance that support applications and deployment of FL system in application scenario. Frameworks above are industrial-oriented, focusing on real-life applications but not suitable for laboratory FL simulation. Rosetta <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and PySyft <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> mainly focus on secure multiparty computation of FL rather than algorithm and communication researches. TFF<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a target="_blank" href="https://github.com/tensorflow/federated" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tensorflow/federated</a></span></span></span> supports the simulation of FL training but executes only on a single machine. FedML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> is a comprehensive FL framework that includes most research fields in FL. And Flower <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> provides a FL communication framework supporting different deep learning framework (e.g., PyTorch, TensorFlow and MXNet). But they still hold varies of dependent libraries, which makes them heavy.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.p2.1" class="ltx_p">Different from frameworks above, <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> is designed to be lightweight. It focuses on optimization effectiveness and communication efficiency for FL system simulation. We encourage users to build FL system following standard program pipeline and providing custom interfaces at the same time. Features of <span id="S2.SS3.p2.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> are further illustrated in the next section.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2107.11621/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of FedLab architecture. Two main roles in FedLab are define with two functional module: <span id="S2.F2.4.1" class="ltx_text ltx_font_typewriter">NetworkManager</span> and <span id="S2.F2.5.2" class="ltx_text ltx_font_typewriter">ParameterServerHandler/Trainer</span>. Communication backend is <span id="S2.F2.6.3" class="ltx_text ltx_font_typewriter">torch.distributed</span> module.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Framework Overview</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">In this section, we mainly illustrate architectural designs and detailed features in both communication efficiency and optimization effectiveness aspects.
<span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> provides two main roles in FL setting: Server and Client. Each Server/Client consists of two components called <span id="S3.p1.1.2" class="ltx_text ltx_font_typewriter">NetworkManager</span> and <span id="S3.p1.1.3" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span>/<span id="S3.p1.1.4" class="ltx_text ltx_font_typewriter">Trainer</span>. The overview of <span id="S3.p1.1.5" class="ltx_text ltx_font_typewriter">FedLab</span>’s structure is shown in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.3 Related work ‣ 2 Background ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_typewriter">NetworkManager</span> module manages message process task, which provides interfaces to customize communication agreements and compression algorithms. In section <a href="#S3.SS1" title="3.1 Communication Efficiency ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, the details of communication module is demonstrated. <span id="S3.p2.1.2" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span>/<span id="S3.p2.1.3" class="ltx_text ltx_font_typewriter">Trainer</span> takes charge of specific optimization algorithm design, and is illustrated in section <a href="#S3.SS2" title="3.2 Optimization Effectiveness ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. Finally, three deployment scenarios supported by <span id="S3.p2.1.4" class="ltx_text ltx_font_typewriter">FedLab</span> are presented in section <a href="#S3.SS3" title="3.3 Deployment Scenarios ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Communication Efficiency</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">In order to meet various requirements of FL network communication, <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> implements <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_typewriter">NetworkManager</span> to manage network topology, using <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">torch.distributed</span> as communication backend. <span id="S3.SS1.p1.1.4" class="ltx_text ltx_font_typewriter">NetworkManager</span> is designed to be flexible in tensor agnostic, customization and scalability. Details of these features are stated below.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.11621/assets/x3.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="276" height="78" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Synchronous</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.11621/assets/x4.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="276" height="77" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Asynchronous</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>NetworkManager in FedLab</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Tensor-based communication</span>. Inspired by the structure of network message, the basic communication element in <span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> is called <span id="S3.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">Package</span>, which contains <em id="S3.SS1.p2.1.4" class="ltx_emph ltx_font_italic">header tensor</em> with necessary control information and <em id="S3.SS1.p2.1.5" class="ltx_emph ltx_font_italic">content tensor</em> with packed tensor list. What’s more, <span id="S3.SS1.p2.1.6" class="ltx_text ltx_font_typewriter">PackageProcessor</span> in <span id="S3.SS1.p2.1.7" class="ltx_text ltx_font_typewriter">NetworkManager</span> provides useful functions for packing up tensor list and restoring content to tensor list. In this way, the details of <span id="S3.SS1.p2.1.8" class="ltx_text ltx_font_typewriter">Package</span> are blocked from users. Besides, <span id="S3.SS1.p2.1.9" class="ltx_text ltx_font_typewriter">Package</span> is represented by a one-dimension tenser (vector), which is compatible with interfaces of PyTorch precisely.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Communication Agreement Customizable</span>. Communication agreements can be explained by following questions: What contents to send? How does client or server react after receiving message? Flexibility of communication module is given by <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_typewriter">NetworkManager</span> module, which offers users the interfaces of customizing communication protocol. User can define additional information exchange, and control information flow for advanced algorithm development.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Communication Pattern</span>. Synchronous and Asynchronous communication patterns are implemented according to Federated Optimization algorithms. Specifically for figure <a href="#S3.F3.sf1" title="In Figure 3 ‣ 3.1 Communication Efficiency ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>, One round of synchronous communication flow can be describe as follows:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1)</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><em id="S3.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Initialization</em>. Server and Clients initialize network connection.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2)</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><em id="S3.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Sampling</em>. Server selects subset of clients to join current round of FL by broadcasting global model to them.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3)</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><em id="S3.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Synchronization</em>. Client starts it local train process after receiving global model. Then, every Client sends needed information including local model to Server.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4)</span> 
<div id="S3.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.i4.p1.1" class="ltx_p"><em id="S3.I1.i4.p1.1.1" class="ltx_emph ltx_font_italic">Aggregation</em>. Finally, Server collects all information from Clients and performs aggregation.</p>
</div>
</li>
</ol>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.1" class="ltx_p">Differently, in asynchronous communication, every client communicate with server asynchronously. A FL training round is begin with a parameter request from client. Besides, server update global model every time it receives a synchronization upload. Details are shown in figure <a href="#S3.F3.sf2" title="In Figure 3 ‣ 3.1 Communication Efficiency ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para ltx_noindent">
<p id="S3.SS1.p6.1" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">Scheduler</span>. <em id="S3.SS1.p6.1.2" class="ltx_emph ltx_font_italic">Cross-silo</em> and <em id="S3.SS1.p6.1.3" class="ltx_emph ltx_font_italic">Cross-device</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> are the common FL settings. Cross-silo FL system usually has 2 - 100 clients which with large bandwidth and powerful computing resources. In contrary, cross-device scenario indicates that more clients (up to <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="10^{10}" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><msup id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mn id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml">10</mn><mn id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml">10</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">superscript</csymbol><cn type="integer" id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2">10</cn><cn type="integer" id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">10^{10}</annotation></semantics></math>) but less resources (power, bandwidth) with each client. Since there are needs of simulating more than 100 of clients, we designed message forward module <span id="S3.SS1.p6.1.4" class="ltx_text ltx_font_typewriter">Scheduler</span> to extend the scalability of <span id="S3.SS1.p6.1.5" class="ltx_text ltx_font_typewriter">FedLab</span>. Firstly, <span id="S3.SS1.p6.1.6" class="ltx_text ltx_font_typewriter">Scheduler</span> is able to connect machines in different LAN(Local Area Network). What’s more, users can overwrite the work flow of <span id="S3.SS1.p6.1.7" class="ltx_text ltx_font_typewriter">Scheduler</span> to achieve hierarchical communication pattern. The usage of <span id="S3.SS1.p6.1.8" class="ltx_text ltx_font_typewriter">Scheduler</span> will be further illustrated in section <a href="#S3.SS3" title="3.3 Deployment Scenarios ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Optimization Effectiveness</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">Optimization module in <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> achieves "high-cohesion and low-coupling", which means this module can be used independently just like LEGOs bricks. To be more specific, <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span> and <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">Trainer</span> is executable without <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_typewriter">NetworkManager</span>. Besides, <span id="S3.SS2.p1.1.5" class="ltx_text ltx_font_typewriter">FedLab</span> does not provide high level APIs, but prepares the necessary implementation tools for developers, reflecting the flexibility of framework.
In this section, some key features of <span id="S3.SS2.p1.1.6" class="ltx_text ltx_font_typewriter">FedLab</span> for standard FL optimization are illustrated.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.11621/assets/x5.png" id="S3.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="207" height="97" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Standalone</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.11621/assets/x6.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="207" height="145" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Cross-process</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.11621/assets/x7.png" id="S3.F4.sf3.g1" class="ltx_graphics ltx_img_landscape" width="322" height="211" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Hierarchical</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Supported Deployment Scenario in FedLab</figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Aggregation</span>.
<span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">Trainer</span>/<span id="S3.SS2.p2.1.3" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span> in <span id="S3.SS2.p2.1.4" class="ltx_text ltx_font_typewriter">FedLab</span> is corresponding with Client/Server optimization process. We encourage standard optimization implementation paradigm for both Client and Server: <span id="S3.SS2.p2.1.5" class="ltx_text ltx_font_typewriter">Trainer</span> manages local dataset and performs PyTorch training process. <span id="S3.SS2.p2.1.6" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span> is implementation of parameter aggregation.
In <span id="S3.SS2.p2.1.7" class="ltx_text ltx_font_typewriter">FedLab</span>, <span id="S3.SS2.p2.1.8" class="ltx_text ltx_font_typewriter">ClientSGDTrainer</span> is a standard implementation of <span id="S3.SS2.p2.1.9" class="ltx_text ltx_font_typewriter">Trainer</span> for users. Additionally, we provides standard demos of <span id="S3.SS2.p2.1.10" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span> with different aggregation algorithms, such as FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and FedAsgd <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Data Partition</span>.
In practice, Non-I.I.D datasets are not always accessible for researchers due to privacy restrictions. Thus, researchers tend to manually create Non-I.I.D data partition in experiment environment. For instance, FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> sorts the MNIST dataset by digit label, and divides it into 2000 shards of size 300 to create pathological Non-I.I.D partition over clients. Also, current FL researches handling non-IID problems tend to design very specific non-IID scenarios rather than standard and systematic partition schemes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. Therefore, <span id="S3.SS2.p3.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> offers users a series of data partition functions, as well as built-in data partition schemes for some datasets based on design of NIID-bench <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. What’s more, <span id="S3.SS2.p3.1.3" class="ltx_text ltx_font_typewriter">FedLab</span> provides PyTorch version of LEAF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> (a Non-I.I.D partitioned FL datasets baseline).</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Deployment Scenarios</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p"><span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> encapsulates the network interface of <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">torch.distributed</span> module, providing stable end-to-end <span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">tensor</span> transmission for FL simulation. Furthermore, we implement a scalable version of <span id="S3.SS3.p1.1.4" class="ltx_text ltx_font_typewriter">NetworkManager</span>, called <span id="S3.SS3.p1.1.5" class="ltx_text ltx_font_typewriter">Scheduler</span>, to ensure the flexibility of network topology and the scalability of the system.
Different deployment scenarios of <span id="S3.SS3.p1.1.6" class="ltx_text ltx_font_typewriter">FedLab</span> correspond to different experimental conditions, for scalability and flexibility.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Standalone</span>.
<span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> implements <span id="S3.SS3.p2.1.3" class="ltx_text ltx_font_typewriter">SerialTrainer</span> for FL simulation in single process. <span id="S3.SS3.p2.1.4" class="ltx_text ltx_font_typewriter">SerialTrainer</span> allows user to simulate a FL system with multiple clients, only with limited computation resources. However, it consumes more time to finish the whole FL experiment since the clients’ real execution is one by one in serial. It is designed for simulation with limited computation resources. The paradigm of <span id="S3.SS3.p2.1.5" class="ltx_text ltx_font_typewriter">SerialTrainer</span> is shown in figure <a href="#S3.F4.sf1" title="In Figure 4 ‣ 3.2 Optimization Effectiveness ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Cross-process</span>.
<span id="S3.SS3.p3.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> also supports cross-process FL simulation that’s shown in figure <a href="#S3.F4.sf2" title="In Figure 4 ‣ 3.2 Optimization Effectiveness ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a>. In practice, each role of <span id="S3.SS3.p3.1.3" class="ltx_text ltx_font_typewriter">FedLab</span> is represented by single system process. FL system simulation can be executed on multiple machines with correct network topology configuration. More flexibly in parallel, <span id="S3.SS3.p3.1.4" class="ltx_text ltx_font_typewriter">SerialTrainer</span> is able to replace the regular <span id="S3.SS3.p3.1.5" class="ltx_text ltx_font_typewriter">Trainer</span>. In this way, machine with more computation resources can be assigned with more workload of simulating. The limitation of this scenario is that all machines must be in the same network (LAN or WAN).</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">Hierarchical</span>.
Users can break the limitation of <span id="S3.SS3.p4.1.2" class="ltx_text ltx_font_bold">cross-process</span> by using <span id="S3.SS3.p4.1.3" class="ltx_text ltx_font_typewriter">Scheduler</span> to build client groups (a subset of clients sharing the same <span id="S3.SS3.p4.1.4" class="ltx_text ltx_font_typewriter">Scheduler</span>), as depicted in figure <a href="#S3.F4.sf3" title="In Figure 4 ‣ 3.2 Optimization Effectiveness ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a>. Server can communicate with client in LAN indirectly. A hierarchical FL system with <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">K</annotation></semantics></math> client groups as depicted in figure <a href="#S3.F4.sf3" title="In Figure 4 ‣ 3.2 Optimization Effectiveness ‣ 3 Framework Overview ‣ FedLab: A Flexible Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a> can be easily formed using <span id="S3.SS3.p4.1.5" class="ltx_text ltx_font_typewriter">FedLab</span>. More importantly, <span id="S3.SS3.p4.1.6" class="ltx_text ltx_font_typewriter">Scheduler</span> is customizable for users. It can be applied for aggregating parameters from client group as a middle-server to share the communication and computation load of server. This design is for the scalability of framework in both computation and communication.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Pipeline and Examples</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">The pipeline of building a FL system with <span id="S4.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> includes two parts. The first part is definition of communication agreements. The prototype of synchronous and asynchronous communication patterns have been implemented for users. With effortless modification on <span id="S4.p1.1.2" class="ltx_text ltx_font_typewriter">NetworkManager</span> of client and server, users can fulfill the agreements as their will.
The second part is <span id="S4.p1.1.3" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span> module of server and <span id="S4.p1.1.4" class="ltx_text ltx_font_typewriter">Trainer</span> module of client, which represents FL optimization process. High level parameter aggregation algorithm and communication is available for server as well. In short, customizable interfaces and tools in <span id="S4.p1.1.5" class="ltx_text ltx_font_typewriter">FedLab</span> support users to implement these two parts very quickly. We show the example implementation of FedAvg to demonstrate <span id="S4.p1.1.6" class="ltx_text ltx_font_typewriter">FedLab</span> API’s simplicity.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p">Core code of client is shown below:</p>
<div id="S4.p2.2" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,bW9kZWwgPSBSZXNOZXQoKQpvcHRpbWl6ZXIgPSB0b3JjaC5vcHRpbS5TR0QobW9kZWwucGFyYW1ldGVycygpLCBscj1hcmdzLmxyLCBtb21lbnR1bT0wLjkpCmNyaXRlcmlvbiA9IG5uLkNyb3NzRW50cm9weUxvc3MoKQp0cmFpbmxvYWRlciwgdGVzdGxvYWRlciA9IGdldF9kYXRhc2V0KGFyZ3MpCgpoYW5kbGVyID0gQ2xpZW50U0dEVHJhaW5lcihtb2RlbCwgdHJhaW5sb2FkZXIsIGVwb2NoPWFyZ3MuZXBvY2gsIG9wdGltaXplcj1vcHRpbWl6ZXIsIGNyaXRlcmlvbj1jcml0ZXJpb24sIGN1ZGE9YXJncy5jdWRhKQpuZXR3b3JrID0gRGlzdE5ldHdvcmsoYWRkcmVzcz0oYXJncy5zZXJ2ZXJfaXAsIGFyZ3Muc2VydmVyX3BvcnQpLAogICAgICAgICAgICAgICAgICAgICAgd29ybGRfc2l6ZT1hcmdzLndvcmxkX3NpemUsCiAgICAgICAgICAgICAgICAgICAgICByYW5rPWFyZ3MubG9jYWxfcmFuaykKCm1hbmFnZXIgPSBDbGllbnRQYXNzaXZlTWFuYWdlcihoYW5kbGVyPWhhbmRsZXIsIG5ldHdvcms9bmV0d29yaykKbWFuYWdlci5ydW4oKQ==" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx1.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">model</span><span id="lstnumberx1.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx1.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx1.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx1.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">ResNet</span><span id="lstnumberx1.6" class="ltx_text ltx_font_typewriter">()</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx2.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">optimizer</span><span id="lstnumberx2.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx2.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">torch</span><span id="lstnumberx2.6" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx2.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">optim</span><span id="lstnumberx2.8" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx2.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">SGD</span><span id="lstnumberx2.10" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx2.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">model</span><span id="lstnumberx2.12" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx2.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">parameters</span><span id="lstnumberx2.14" class="ltx_text ltx_font_typewriter">(),</span><span id="lstnumberx2.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">lr</span><span id="lstnumberx2.17" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx2.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx2.19" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx2.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">lr</span><span id="lstnumberx2.21" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx2.22" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.23" class="ltx_text ltx_lst_identifier ltx_font_typewriter">momentum</span><span id="lstnumberx2.24" class="ltx_text ltx_font_typewriter">=0.9)</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx3.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">criterion</span><span id="lstnumberx3.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx3.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">nn</span><span id="lstnumberx3.6" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx3.7" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">CrossEntropyLoss</span><span id="lstnumberx3.8" class="ltx_text ltx_font_typewriter">()</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx4.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">trainloader</span><span id="lstnumberx4.2" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx4.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">testloader</span><span id="lstnumberx4.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.6" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx4.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">get_dataset</span><span id="lstnumberx4.9" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx4.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx4.11" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx6.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">handler</span><span id="lstnumberx6.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx6.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">ClientSGDTrainer</span><span id="lstnumberx6.6" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx6.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">model</span><span id="lstnumberx6.8" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx6.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">trainloader</span><span id="lstnumberx6.11" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx6.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">epoch</span><span id="lstnumberx6.14" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx6.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx6.16" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx6.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">epoch</span><span id="lstnumberx6.18" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx6.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">optimizer</span><span id="lstnumberx6.21" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx6.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">optimizer</span><span id="lstnumberx6.23" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx6.24" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.25" class="ltx_text ltx_lst_identifier ltx_font_typewriter">criterion</span><span id="lstnumberx6.26" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx6.27" class="ltx_text ltx_lst_identifier ltx_font_typewriter">criterion</span><span id="lstnumberx6.28" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx6.29" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.30" class="ltx_text ltx_lst_identifier ltx_font_typewriter">cuda</span><span id="lstnumberx6.31" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx6.32" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx6.33" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx6.34" class="ltx_text ltx_lst_identifier ltx_font_typewriter">cuda</span><span id="lstnumberx6.35" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx7.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">network</span><span id="lstnumberx7.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx7.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">DistNetwork</span><span id="lstnumberx7.6" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx7.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">address</span><span id="lstnumberx7.8" class="ltx_text ltx_font_typewriter">=(</span><span id="lstnumberx7.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx7.10" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx7.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">server_ip</span><span id="lstnumberx7.12" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx7.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx7.15" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx7.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">server_port</span><span id="lstnumberx7.17" class="ltx_text ltx_font_typewriter">),</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                      </span><span id="lstnumberx8.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">world_size</span><span id="lstnumberx8.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx8.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx8.5" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx8.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">world_size</span><span id="lstnumberx8.7" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx9.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                      </span><span id="lstnumberx9.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">rank</span><span id="lstnumberx9.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx9.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx9.5" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx9.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">local_rank</span><span id="lstnumberx9.7" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx11.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">manager</span><span id="lstnumberx11.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx11.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx11.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx11.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">ClientPassiveManager</span><span id="lstnumberx11.6" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx11.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">handler</span><span id="lstnumberx11.8" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx11.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">handler</span><span id="lstnumberx11.10" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx11.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx11.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">network</span><span id="lstnumberx11.13" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx11.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">network</span><span id="lstnumberx11.15" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span><span id="lstnumberx12.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">manager</span><span id="lstnumberx12.2" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx12.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">run</span><span id="lstnumberx12.4" class="ltx_text ltx_font_typewriter">()</span>
</div>
</div>
<p id="S4.p2.3" class="ltx_p">Code from line 1 to line 5 is the standard pipeline of training a neural network with PyTorch. From line 6 to the end is the usage of <span id="S4.p2.3.1" class="ltx_text ltx_font_typewriter">FedLab</span>. In this example, <span id="S4.p2.3.2" class="ltx_text ltx_font_typewriter">FedLab</span> provides high level API of network communication which allow users define network topology easily (line 7-11) and standard network training process (line 6).</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p">FL server is also easily implemented in a couple lines of code:</p>
<div id="S4.p3.2" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" style="background-color:#F2F2EB;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,bW9kZWwgPSBSZXNOZXQoKQpwcyA9IFN5bmNQYXJhbWV0ZXJTZXJ2ZXJIYW5kbGVyKG1vZGVsLCBjbGllbnRfbnVtX2luX3RvdGFsPWFyZ3Mud29ybGRfc2l6ZS0xKQoKbmV0d29yayA9IERpc3ROZXR3b3JrKGFkZHJlc3M9KGFyZ3Muc2VydmVyX2lwLCBhcmdzLnNlcnZlcl9wb3J0KSwKICAgICAgICAgICAgICAgICAgICAgIHdvcmxkX3NpemU9YXJncy53b3JsZF9zaXplLAogICAgICAgICAgICAgICAgICAgICAgcmFuaz0wKQptYW5hZ2VyID0gU2VydmVyU3luY2hyb25vdXNNYW5hZ2VyKGhhbmRsZXI9cHMsIG5ldHdvcms9bmV0d29yaykKCm1hbmFnZXIucnVuKCk=" download="">⬇</a></div>
<div id="lstnumberx13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx13.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">model</span><span id="lstnumberx13.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx13.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">ResNet</span><span id="lstnumberx13.6" class="ltx_text ltx_font_typewriter">()</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx14.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">ps</span><span id="lstnumberx14.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx14.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx14.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx14.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">SyncParameterServerHandler</span><span id="lstnumberx14.6" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx14.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">model</span><span id="lstnumberx14.8" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx14.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx14.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">client_num_in_total</span><span id="lstnumberx14.11" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx14.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx14.13" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx14.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">world_size</span><span id="lstnumberx14.15" class="ltx_text ltx_font_typewriter">-1)</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx16.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">network</span><span id="lstnumberx16.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx16.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">DistNetwork</span><span id="lstnumberx16.6" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx16.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">address</span><span id="lstnumberx16.8" class="ltx_text ltx_font_typewriter">=(</span><span id="lstnumberx16.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx16.10" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx16.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">server_ip</span><span id="lstnumberx16.12" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx16.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx16.15" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx16.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">server_port</span><span id="lstnumberx16.17" class="ltx_text ltx_font_typewriter">),</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx17.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                      </span><span id="lstnumberx17.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">world_size</span><span id="lstnumberx17.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx17.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">args</span><span id="lstnumberx17.5" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx17.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">world_size</span><span id="lstnumberx17.7" class="ltx_text ltx_font_typewriter">,</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx18.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                      </span><span id="lstnumberx18.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">rank</span><span id="lstnumberx18.3" class="ltx_text ltx_font_typewriter">=0)</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx19.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">manager</span><span id="lstnumberx19.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.3" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx19.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.5" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#FF00FF;">ServerSynchronousManager</span><span id="lstnumberx19.6" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx19.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">handler</span><span id="lstnumberx19.8" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx19.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">ps</span><span id="lstnumberx19.10" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx19.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">network</span><span id="lstnumberx19.13" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx19.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">network</span><span id="lstnumberx19.15" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx21.1" class="ltx_text ltx_lst_identifier ltx_font_typewriter">manager</span><span id="lstnumberx21.2" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx21.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">run</span><span id="lstnumberx21.4" class="ltx_text ltx_font_typewriter">()</span>
</div>
</div>
<p id="S4.p3.3" class="ltx_p">Code in line 2 defines the <span id="S4.p3.3.1" class="ltx_text ltx_font_typewriter">ParameterServerHandler</span> with FedAvg algorithm. Codes from line 4 to 7 define the <span id="S4.p3.3.2" class="ltx_text ltx_font_typewriter">NetworkManager</span> of server.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Development</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">For continuous maintainence of <span id="S5.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span>, we establish a open-source group on GitHub. The framework will be further developed publicly through GitHub, in which we can track issues of bug reports, feature requests and usage questions. We use continuous integration (CI) to ensure robust of package. What’s more, comprehensive and elaborate documentation is developed using popular Sphinx Python documentation generator and published on <span id="S5.p1.1.2" class="ltx_text ltx_font_typewriter" style="color:#0000FF;">fedlab.readthedocs.io</span>.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Summary and Future Work</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">In this paper, a flexible and lightweight FL framework <span id="S6.p1.1.1" class="ltx_text ltx_font_typewriter">FedLab</span> is proposed. <span id="S6.p1.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> provides common-used FL communication patterns and optimization algorithms modules with both high-level API and open interfaces for standardized FL simulation. For easy usage and continuous maintainence, we build a open-source group to accept contributions and issues on GitHub with necessary configurations.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p">In the future, we will keep developing <span id="S6.p2.1.1" class="ltx_text ltx_font_typewriter">FedLab</span>. Specifically, our plan includes but not limited to the following aspects:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Releasing research results</span>. We will use <span id="S6.I1.i1.p1.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> to explore our current and future ideas about optimization and communication. We will release those implementations on this framework in the future.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Providing more implementations</span>. Many excellent works are developed by different computation platform. Inconsistent implementations are not beneficial for the development of community. We plan to re-implement them with <span id="S6.I1.i2.p1.1.2" class="ltx_text ltx_font_typewriter">FedLab</span> to provide more standard FL implementations.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Adding functional modules</span>. In the aspect of communication module, complicate network topology is under development. Besides, convenient network configuration script will be presented soon. Modules, which supporting other machine learning technique such as Unsupervised Learning, Semi-supervised Learning, Transfer Learning, etc,, are in schedule.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Agüera y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">AISTATS</span>, volume 54 of <span id="bib.bib1.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning
Research</span>, pages 1273–1282. PMLR, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
David Byrd and Antigoni Polychroniadou.

</span>
<span class="ltx_bibblock">Differentially private secure multi-party computation for federated
learning in financial applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2010.05867, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Jie Xu, Benjamin S. Glicksberg, Chang Su, Peter B. Walker, Jiang Bian, and Fei
Wang.

</span>
<span class="ltx_bibblock">Federated learning for healthcare informatics.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">J. Heal. Informatics Res.</span>, 5(1):1–19, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Theodora S. Brisimi, Ruidi Chen, Theofanie Mela, Alex Olshevsky, Ioannis Ch.
Paschalidis, and Wei Shi.

</span>
<span class="ltx_bibblock">Federated learning of predictive models from federated electronic
health records.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Int. J. Medical Informatics</span>, 112:59–67, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Yuang Jiang, Shiqiang Wang, Bong-Jun Ko, Wei-Han Lee, and Leandros
Tassiulas.

</span>
<span class="ltx_bibblock">Model pruning enables efficient federated learning on edge devices.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1909.12326, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chuizheng Meng, Sirisha Rambhatla, and Yan Liu.

</span>
<span class="ltx_bibblock">Cross-node federated graph neural network for spatio-temporal data
modeling.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2106.05223, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">MLSys</span>. mlsys.org, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Yujun Lin, Song Han, Huizi Mao, Yu Wang, and William J Dally.

</span>
<span class="ltx_bibblock">Deep gradient compression: Reducing the communication bandwidth for
distributed training.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1712.01887</span>, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Reza Shokri and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the 22nd ACM SIGSAC conference on computer and
communications security</span>, pages 1310–1321, 2015.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Felix Sattler, Klaus-Robert Müller, and Wojciech Samek.

</span>
<span class="ltx_bibblock">Clustered federated learning: Model-agnostic distributed multitask
optimization under privacy constraints.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">IEEE transactions on neural networks and learning systems</span>,
2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al.

</span>
<span class="ltx_bibblock">Pytorch: An imperative style, high-performance deep learning library.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>,
32:8026–8037, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al.

</span>
<span class="ltx_bibblock">Tensorflow: A system for large-scale machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.4.4" class="ltx_text ltx_font_italic">12th <math id="bib.bib12.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib12.1.1.m1.1a"><mo stretchy="false" id="bib.bib12.1.1.m1.1.1" xref="bib.bib12.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib12.1.1.m1.1b"><ci id="bib.bib12.1.1.m1.1.1.cmml" xref="bib.bib12.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib12.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib12.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib12.2.2.m2.1a"><mo stretchy="false" id="bib.bib12.2.2.m2.1.1" xref="bib.bib12.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib12.2.2.m2.1b"><ci id="bib.bib12.2.2.m2.1.1.cmml" xref="bib.bib12.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib12.2.2.m2.1c">\}</annotation></semantics></math> symposium on operating systems design and
implementation (<math id="bib.bib12.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib12.3.3.m3.1a"><mo stretchy="false" id="bib.bib12.3.3.m3.1.1" xref="bib.bib12.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib12.3.3.m3.1b"><ci id="bib.bib12.3.3.m3.1.1.cmml" xref="bib.bib12.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib12.3.3.m3.1c">\{</annotation></semantics></math>OSDI<math id="bib.bib12.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib12.4.4.m4.1a"><mo stretchy="false" id="bib.bib12.4.4.m4.1.1" xref="bib.bib12.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib12.4.4.m4.1b"><ci id="bib.bib12.4.4.m4.1.1.cmml" xref="bib.bib12.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib12.4.4.m4.1c">\}</annotation></semantics></math> 16)</span>, pages 265–283, 2016.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Wonyong Jeong, Jaehong Yoon, Eunho Yang, and Sung Ju Hwang.

</span>
<span class="ltx_bibblock">Fedmatch implementation in tensorflow.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/wyjeong/FedMatch" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/wyjeong/FedMatch</a>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Fedprox implementation in tensorflow.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/litian96/FedProx" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/litian96/FedProx</a>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris S. Papailiopoulos, and
Yasaman Khazaeni.

</span>
<span class="ltx_bibblock">Federated learning with matched averaging.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">ICLR</span>. OpenReview.net, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran.

</span>
<span class="ltx_bibblock">An efficient framework for clustered federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Canh T. Dinh, Nguyen H. Tran, and Tuan Dung Nguyen.

</span>
<span class="ltx_bibblock">Personalized federated learning with moreau envelopes.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, and Qi Dou.

</span>
<span class="ltx_bibblock">Fedbn: Federated learning on non-iid features via local batch
normalization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">ICLR</span>. OpenReview.net, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Durmus Alp Emre Acar, Yue Zhao, Ramon Matas Navarro, Matthew Mattina, Paul N.
Whatmough, and Venkatesh Saligrama.

</span>
<span class="ltx_bibblock">Federated learning based on dynamic regularization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">ICLR</span>. OpenReview.net, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Xinran Gu, Kaixuan Huang, Jingzhao Zhang, and Longbo Huang.

</span>
<span class="ltx_bibblock">Fast federated learning in the presence of arbitrary device
unavailability.

</span>
<span class="ltx_bibblock">In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman
Vaughan, editors, <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
volume 34, pages 12052–12064. Curran Associates, Inc., 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Zhongxiang Dai, Bryan Kian Hsiang Low, and Patrick Jaillet.

</span>
<span class="ltx_bibblock">Differentially private federated bayesian optimization with
distributed exploration.

</span>
<span class="ltx_bibblock">In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman
Vaughan, editors, <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
volume 34, pages 9125–9139. Curran Associates, Inc., 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Jaehoon Oh, SangMook Kim, and Se-Young Yun.

</span>
<span class="ltx_bibblock">FedBABU: Toward enhanced representation for federated image
classification.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang.

</span>
<span class="ltx_bibblock">On the convergence of fedavg on non-iid data.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1907.02189</span>, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Jeffrey Dean, Greg S Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Quoc V Le,
Mark Z Mao, Marc’Aurelio Ranzato, Andrew Senior, Paul Tucker, et al.

</span>
<span class="ltx_bibblock">Large scale distributed deep networks.

</span>
<span class="ltx_bibblock">2012.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Ligeng Zhu, Zhijian Liu, and Song Han.

</span>
<span class="ltx_bibblock">Deep leakage from gradients.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">NeurIPS</span>, pages 14747–14756, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly
Shmatikov.

</span>
<span class="ltx_bibblock">How to backdoor federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">AISTATS</span>, volume 108 of <span id="bib.bib26.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine
Learning Research</span>, pages 2938–2948. PMLR, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Briland Hitaj, Giuseppe Ateniese, and Fernando Pérez-Cruz.

</span>
<span class="ltx_bibblock">Deep models under the GAN: information leakage from collaborative
deep learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">CCS</span>, pages 603–618. ACM, 2017.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons.

</span>
<span class="ltx_bibblock">The non-iid data quagmire of decentralized machine learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
4387–4398. PMLR, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.06127</span>, 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith.

</span>
<span class="ltx_bibblock">Fair resource allocation in federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">ICLR</span>. OpenReview.net, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J. Reddi,
Sebastian U. Stich, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">SCAFFOLD: stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">ICML</span>, volume 119 of <span id="bib.bib31.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning
Research</span>, pages 5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M. Alvarez.

</span>
<span class="ltx_bibblock">Personalized federated learning with first order model optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">9th International Conference on Learning Representations,
ICLR 2021, Virtual Event, Austria, May 3-7, 2021</span>. OpenReview.net, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei,
and Yong Zhang.

</span>
<span class="ltx_bibblock">Personalized federated learning: An attentive collaboration approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2007.03797, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Yihan Jiang, Jakub Konečnỳ, Keith Rush, and Sreeram Kannan.

</span>
<span class="ltx_bibblock">Improving federated learning personalization via model agnostic meta
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.12488</span>, 2019.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Hyowoon Seo, Jihong Park, Seungeun Oh, Mehdi Bennis, and Seong-Lyun Kim.

</span>
<span class="ltx_bibblock">Federated knowledge distillation.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2011.02367</span>, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic.

</span>
<span class="ltx_bibblock">Qsgd: Communication-efficient sgd via gradient quantization and
encoding.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
30:1709–1720, 2017.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Tim Dettmers.

</span>
<span class="ltx_bibblock">8-bit approximations for parallelism in deep learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1511.04561</span>, 2015.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Animashree
Anandkumar.

</span>
<span class="ltx_bibblock">signsgd: Compressed optimisation for non-convex problems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
560–569. PMLR, 2018.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Alham Fikri Aji and Kenneth Heafield.

</span>
<span class="ltx_bibblock">Sparse communication for distributed gradient descent.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">EMNLP</span>, pages 440–445. Association for Computational
Linguistics, 2017.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Sebastian U Stich, Jean-Baptiste Cordonnier, and Martin Jaggi.

</span>
<span class="ltx_bibblock">Sparsified sgd with memory.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1809.07599</span>, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Yuanfeng Chen, Gaofeng Huang, Junjie Shi, Xiang Xie, and Yilin Yan.

</span>
<span class="ltx_bibblock">Rosetta: A Privacy-Preserving Framework Based on TensorFlow.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/LatticeX-Foundation/Rosetta" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/LatticeX-Foundation/Rosetta</a>, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel
Rueckert, and Jonathan Passerat-Palmbach.

</span>
<span class="ltx_bibblock">A generic framework for privacy preserving deep learning, 2018.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Chaoyang He, Songze Li, Jinhyun So, Mi Zhang, Hongyi Wang, Xiaoyang Wang,
Praneeth Vepakomma, Abhishek Singh, Hang Qiu, Li Shen, Peilin Zhao, Yan Kang,
Yang Liu, Ramesh Raskar, Qiang Yang, Murali Annavaram, and Salman Avestimehr.

</span>
<span class="ltx_bibblock">Fedml: A research library and benchmark for federated machine
learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.13518</span>, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Daniel J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, and
Nicholas D Lane.

</span>
<span class="ltx_bibblock">Flower: A friendly federated learning research framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.14390</span>, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
Cormode, Rachel Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.04977</span>, 2019.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Cong Xie, Sanmi Koyejo, and Indranil Gupta.

</span>
<span class="ltx_bibblock">Asynchronous federated optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1903.03934, 2019.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He.

</span>
<span class="ltx_bibblock">Federated learning on non-iid data silos: An experimental study.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2102.02079, 2021.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Sebastian Caldas, Peter Wu, Tian Li, Jakub Konečný, H. Brendan
McMahan, Virginia Smith, and Ameet Talwalkar.

</span>
<span class="ltx_bibblock">LEAF: A benchmark for federated settings.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1812.01097, 2018.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2107.11620" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2107.11621" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2107.11621">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2107.11621" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2107.11622" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar  6 22:12:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
