<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design</title>
<!--Generated on Fri Jun 14 03:13:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.09686v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S0.SS1" title="In Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">0.1 </span>Overview and Example</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S1" title="In Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S1.SS1" title="In 1 Related Work ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Text Corpora Exploration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S1.SS2" title="In 1 Related Work ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>Explainations and Interpretability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S1.SS3" title="In 1 Related Work ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Exploratory Search</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S2" title="In Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods and Details</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S2.SS1" title="In 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Similarity and Layout</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S2.SS2" title="In 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Salience Functions</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S2.SS2.SSS1" title="In 2.2 Salience Functions ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Term Salience</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S2.SS2.SSS2" title="In 2.2 Salience Functions ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.2 </span>Item Salience</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S2.SS3" title="In 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Views</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S2.SS4" title="In 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Design for Comparison and Linking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S3" title="In Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Implementation and Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S4" title="In Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Assessment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S4.SS1" title="In 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>An Example Exploration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S4.SS2" title="In 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span><span class="ltx_ERROR undefined">\replaced</span>Usage VignettesAdditional Examples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S4.SS3" title="In 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>User Studies</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S4.SS3.SSS1" title="In 4.3 User Studies ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Study Procedure:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S4.SS3.SSS2" title="In 4.3 User Studies ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Study Findings</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S5" title="In Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion and Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#A1" title="In Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Quantitative Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#A1.SS1" title="In Appendix A Quantitative Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Usability Assessment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#A1.SS2" title="In Appendix A Quantitative Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Nearest-Neighbor Overlaps</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\onlineid</span>
<p class="ltx_p" id="p1.2">0
<span class="ltx_ERROR undefined" id="p1.2.1">\preprinttext</span>Authors’ Version June, 2024


<span class="ltx_ERROR undefined" id="p1.2.2">\authorfooter</span>
Michael Gleicher and Keaton Leppenan are with the University of Wisconsin, Madison
E-mail: gleicher@cs.wisc.edu, kleppanen@wisc.edu.
Yunyu Bai is with Amazon.
E-mail: ybai45@wisc.edu.

</p>
</div>
<h1 class="ltx_title ltx_title_document">Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="1.1.1">\authororcid</span>Michael Gleicher0000-0003-3295-4071
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_ERROR undefined" id="2.1.1">\authororcid</span>Keaton Leppenan0009-0009-4823-458X
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
and
Yunyu Bai
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="3.1">Text corpus exploration (TCE) spans the range of exploratory search tasks: it goes beyond simple retrieval to include item discovery and learning about the corpus and topic. Systems support TCE with tools such as similarity-based recommendations and embedding-based spatial maps. However, these tools address specific tasks; current systems lack the flexibility to support the range of tasks encountered in practice and the iterative, multiscale, workflows users employ. In this paper, we provide methods that enhance TCE tools with post hoc explanations and multiscale, comparative designs to provide flexible support for user needs. We introduce salience functions as a mechanism to provide post hoc explanations of similarity, recommendations, and spatial placement. This post hoc strategy allows our approach to complement a variety of underlying algorithms; the salience functions provide both exemplar- and feature-based explanations at scales ranging from individual documents through to the entire corpus. These explanations are incorporated into a set of views that operate at multiple scales. The views use design elements that explicitly support comparison to enable flexible integration. Together, these form an approach that provides a flexible toolset that can address a range of tasks. We demonstrate our approach in a prototype system that enables the exploration of corpora of paper abstracts and newspaper archives. Examples illustrate how our approach enables the system to flexibly support a wide range of tasks and workflows that emerge in user scenarios. A user study confirms that researchers are able to use our system to achieve a variety of tasks.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Text exploration, post hoc explanation, spatial embedding, exploratory search.
</div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1">Introduction</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1"><em class="ltx_emph ltx_font_italic" id="p3.1.1">Text Corpus Exploration</em> (TCE)
involves discovering unknown documents and gaining an understanding of the corpus, not just retrieving known documents.
As such, it shares the diverse objectives of <em class="ltx_emph ltx_font_italic" id="p3.1.2">exploratory search</em><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib2" title="">2</a>]</cite> including to discover unknown targets and <span class="ltx_ERROR undefined" id="p3.1.3">\added</span>to learn about the information space (the corpus and domain from which it is drawn). This learning includes building a sense of the documents in the collection, how they might be grouped, and how terms are used; learning is useful for further discovery and to gain understanding about the domain.
To support the objectives of exploratory search, TCE systems extend the basic tools used for retrieval (such as keyword search) with tools based on content analysis, such as similarity-based recommendations and spatial embeddings.
However, these tools
focus on specific objectives: they lack the flexibility to support the diverse range of tasks and workflows in exploratory search.</p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">To better support exploratory search in text corpus exploration, we propose enhancing standard tools with post hoc explanations and comparative design.
For example, similarity search may suggest a candidate document of interest; but an explanation of <em class="ltx_emph ltx_font_italic" id="p4.1.1">why</em> that document is considered relevant may help a user assess the document’s relevance, identify terms that could lead to better searches, or reveal interesting concepts for consideration.
By explaining <em class="ltx_emph ltx_font_italic" id="p4.1.2">why</em> documents are placed in a particular spatial region of a map, a system can help a user identify whether the region is likely to be a fertile region for discovery, to see common terms that may help for search or consistency with usage in the field, or provide a set of examples of issues related to a particular topic.
Supporting the comparison of a pair of documents can help show the relation between them for relevance checking; comparison among a group may highlight common themes.
By integrating explanations and comparisons, TCE tools can flexibly address a range of objectives and user workflows across different scales and targets.</p>
</div>
<div class="ltx_para" id="p5">
<p class="ltx_p" id="p5.1">In this paper, we examine the use of explanation and comparison as mechanisms to enhance TCE tools so they can better support users’ exploratory search needs.
Our approach builds on existing tools,
including similarity-based recommendations, embedding-based spatial maps, and term identification.
<span class="ltx_ERROR undefined" id="p5.1.1">\replaced</span>We enhance these tools with explanations and explicit support for comparison.
We enhance these tools with explanations that enhance standard views.
We also enhance standard views with explicit support for comparison, such as dual selections and juxtaposed displays.
These enhancements enable the tools and views to address a wide range of exploratory search objectives
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We follow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib3" title="">3</a>]</cite> and prefer the term <em class="ltx_emph ltx_font_italic" id="footnote1.1">objective</em> to more specifically refer to a user’s goal than the more common <em class="ltx_emph ltx_font_italic" id="footnote1.2">task</em>, which has many meanings. </span></span></span>by integrating together in a flexible manner that allows users to dynamically improvise workflows that address complex tasks.
<span class="ltx_ERROR undefined" id="p5.1.2">\added</span>Examples of enhancements are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S0.F1" title="Figure 1 ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S0.F1"><svg class="ltx_picture ltx_centering" height="186" id="S0.F1.pic1" overflow="visible" version="1.1" width="598"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,186) matrix(1 0 0 -1 0 0) translate(-0.28,0) translate(0,-0.28)"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="186" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="598"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="365" id="S0.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="x1.png" width="1196"/></foreignobject></g><path d="M 149.64 167.9" style="fill:none"></path><g fill="#FF0000"><path d="M 158.5 167.9 C 158.5 172.79 154.53 176.76 149.64 176.76 C 144.75 176.76 140.78 172.79 140.78 167.9 C 140.78 163 144.75 159.04 149.64 159.04 C 154.53 159.04 158.5 163 158.5 167.9 Z M 149.64 167.9" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 143.41 162.22)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.45"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F1.pic1.2.2.2.1.1" style="font-size:120%;">A</span></foreignobject></g><path d="M 329.21 167.9" style="fill:none"></path><g fill="#FF0000"><path d="M 338.06 167.9 C 338.06 172.79 334.1 176.76 329.21 176.76 C 324.31 176.76 320.35 172.79 320.35 167.9 C 320.35 163 324.31 159.04 329.21 159.04 C 334.1 159.04 338.06 163 338.06 167.9 Z M 329.21 167.9" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 323.33 162.22)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.76"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F1.pic1.3.3.3.1.1" style="font-size:120%;">B</span></foreignobject></g><path d="M 568.62 167.9" style="fill:none"></path><g fill="#FF0000"><path d="M 577.48 167.9 C 577.48 172.79 573.52 176.76 568.62 176.76 C 563.73 176.76 559.77 172.79 559.77 167.9 C 559.77 163 563.73 159.04 568.62 159.04 C 573.52 159.04 577.48 163 577.48 167.9 Z M 568.62 167.9" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 562.63 162.22)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.99"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F1.pic1.4.4.4.1.1" style="font-size:120%;">C</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.8.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S0.F1.9.2" style="font-size:90%;">
Our approach enhances standard text corpus exploration views with post hoc explanations and support for comparison.
<span class="ltx_ERROR undefined" id="S0.F1.9.2.1">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F1.9.2.2">A</span> An embedding-based corpus map is shown as a gridded heatmap with circle overlays for search results. This view is enhanced with explanations of region contents (either by hovering over a heatmap square or selecting an arbitrary region shown in yellow),
the ability to compare two searches (green and gray circles), and two selected documents (pink and yellow stars) allowing their neighbors to be compared (pink and yellow circles).
<span class="ltx_ERROR undefined" id="S0.F1.9.2.3">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F1.9.2.4">B</span> A term-document matrix view is enhanced with salience functions that reorder it to emphasize subsets that explain selected groups. Comparative features highlight differences between sets of documents.
<span class="ltx_ERROR undefined" id="S0.F1.9.2.5">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F1.9.2.6">C</span> A text view is enhanced with comparison features to show two selected documents. Each document view can highlight explanations for why the document is in its map regions (blue) and why the documents may be considered similar (yellow). Each document provides its most similar neighbors in two vector spaces, with colored symbols to enable comparison between lists.

</span></figcaption>
</figure>
<div class="ltx_para" id="p6">
<p class="ltx_p" id="p6.1">We introduce salience functions for ranking terms and documents as a flexible mechanism for explaining decisions made by the system including recommendations, placements, and groupings.
These explanations are post hoc: they <span class="ltx_ERROR undefined" id="p6.1.1">\replaced</span>maydo not describe the cause of the decisions, but rather provide a plausible and interpretable reconstruction.
The post hoc strategy
<span class="ltx_ERROR undefined" id="p6.1.2">\replaced</span>decouples the methods for decision and explanation, allowing us to combine
allows
explanations independent of the methods used for decisions. This allows combining state-of-art methods for similarity, recommendation, and layout with explanations.
Our salience function approach allows creating both exmplar- <span class="ltx_ERROR undefined" id="p6.1.3">\added</span>(document) and feature- <span class="ltx_ERROR undefined" id="p6.1.4">\added</span>(term) based explanations at different scales.
This allows us to use the salience functions to provide connections across a variety of views and scales.
<span class="ltx_ERROR undefined" id="p6.1.5">\added</span>Salience ranking and highlighting also enable efficient comparison.</p>
</div>
<div class="ltx_para" id="p7">
<span class="ltx_ERROR undefined" id="p7.1">\added</span>
<p class="ltx_p" id="p7.2">TCE implies exploration of a corpus, rather than a simple query or quick glance. Our approach, therefore, targets sophisticated users, such as researchers, who invest effort to understand and discover in a corpus.
We have applied our approach to a prototype system, <em class="ltx_emph ltx_font_italic" id="p7.2.1">AbstractsViewer</em> <span class="ltx_ERROR undefined" id="p7.2.2">\added</span>(Figure <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">2</span></a>) designed to support researchers in exploring collections of short texts, such as scientific paper abstracts and newspaper leads. AbstractsViewer combines transformer-based (and traditional) similarity scoring and recommendations, embedding-based layout, and term-based tools. It provides views for spatial and structured views at multiple scales. The use of explanations and comparison support provides connection across these views, allowing viewers to adapt them to address TCE tasks.
Our experience, including a user study, suggests that our target audience
can use our approach to address a range of exploratory search objectives in text corpora.</p>
</div>
<div class="ltx_para" id="p8">
<p class="ltx_p" id="p8.1">Our overall contribution is to introduce an approach to TCE that uses explanations and comparison to enhance existing TCE tools to better support a range of user objectives. Specific contributions include:
We introduce a post hoc explanation approach to TCE that allows coupling transformer-based recommendations and embedding-based layouts with traditional views enabling a range of document- and term-based tasks.
We introduce a salience function approach that provides a flexible way to create explanations across scales and integrate them with views.
We present empirical evidence that multiscale tools, post hoc explanations, and comparative designs can provide flexibility in TCE that researchers can leverage across diverse tasks.
Our contributions are embodied in an open-source system.</p>
</div>
<section class="ltx_subsection" id="S0.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">0.1 </span>Overview and Example</h3>
<div class="ltx_para" id="S0.SS1.p1">
<span class="ltx_ERROR undefined" id="S0.SS1.p1.1">\added</span>
<p class="ltx_p" id="S0.SS1.p1.2">AbstractsViewer is a prototype system designed to embody our approach (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>). It was specifically designed for the exploration of scientific abstract corpora, although we also apply it to collections of newspaper articles. It intentionally focuses on content-based exploration and omits features such as meta-data analysis so we can observe how content-based tools are applied in exploration.</p>
</div>
<div class="ltx_para" id="S0.SS1.p2">
<span class="ltx_ERROR undefined" id="S0.SS1.p2.1">\added</span>
<p class="ltx_p" id="S0.SS1.p2.2">AbstractsViewer presents a standard TCE interface: a search panel allows for making various forms of text queries; a list view provides a structured view of query results; a scatterplot shows an embedding of the corpus with query results highlighted. However, it extends these common functions to better support the needs of exploratory search by enhancing views with explanatory and comparison features allowing for flexible, improvised workflows combining a variety of views.</p>
</div>
<div class="ltx_para" id="S0.SS1.p3">
<span class="ltx_ERROR undefined" id="S0.SS1.p3.1">\added</span>
<p class="ltx_p" id="S0.SS1.p3.2">AbstractsViewer also provides a set of additional views, as shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F4" title="Figure 4 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>, that operate at more granular scales: views of (multiple) selected documents, views of the neighborhoods (nearest documents) around these selected documents, and views of a larger, user defined region of interest. Spatial views allow for observing patterns in similarity, matrix views allow for connecting documents and terms, and list views allow for systematic examination.</p>
</div>
<div class="ltx_para" id="S0.SS1.p4">
<span class="ltx_ERROR undefined" id="S0.SS1.p4.1">\added</span>
<p class="ltx_p" id="S0.SS1.p4.2">The system enhances its views with
explanations and comparison features.
For instance, the system uses <em class="ltx_emph ltx_font_italic" id="S0.SS1.p4.2.1">salience functions</em> to identify items that can explain the sets being visualized.
Term based salience functions select words that explain a document’s inclusion in a region and list the relevant terms in a neighborhood to suggest its topic. The identified terms are seen in reorderable matrix views of document sets and text views of documents.
Document based salience functions identify the most exemplary documents in a region providing a example document-based explanation. These views and methods are discussed more in depth in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2" title="2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2</span></a>.</p>
</div>
<div class="ltx_para" id="S0.SS1.p5">
<span class="ltx_ERROR undefined" id="S0.SS1.p5.1">\added</span>
<p class="ltx_p" id="S0.SS1.p5.2">AbstractsViewer provides flexibility by providing views at different scales, connected by explanations and comparisons.
<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F3" title="Figure 3 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 3</span></a> illustrates four example workflows applied in the context of researching this paper, to tasks including relevant related document discovery and assessment, identifying related concepts, and determining relevant terms.
The flexibility of multiple entry points for inquiry is important for discovery <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> and supported in AbstractsViewer as it allows mixing keyword search and similarity search in spatial or structured ways. Salience mechanisms provide flexible connections between types, supporting varied workflows such as outlier identification, diverse topic identification, and counterfactuals (e.g., explaining the similarity between dissimilar documents).</p>
</div>
<figure class="ltx_figure" id="S0.F2"><svg class="ltx_picture ltx_centering" height="264" id="S0.F2.pic1" overflow="visible" version="1.1" width="301.07"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,264) matrix(1 0 0 -1 0 0) translate(1.79,0) translate(0,-0.28)"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="264" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="299"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="264" id="S0.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/5660384/Figures/new/system_image.png" width="299"/></foreignobject></g><path d="M 7.49 252.65" style="fill:none"></path><g fill="#FF0000"><path d="M 14.38 252.65 C 14.38 256.45 11.29 259.54 7.49 259.54 C 3.68 259.54 0.6 256.45 0.6 252.65 C 0.6 248.84 3.68 245.76 7.49 245.76 C 11.29 245.76 14.38 248.84 14.38 252.65 Z M 7.49 252.65" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 2.82 248.39)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="9.34"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.2.2.2.1.1" style="font-size:90%;">A</span></foreignobject></g><path d="M 7.49 158.73" style="fill:none"></path><g fill="#FF0000"><path d="M 14.38 158.73 C 14.38 162.54 11.29 165.62 7.49 165.62 C 3.68 165.62 0.6 162.54 0.6 158.73 C 0.6 154.93 3.68 151.84 7.49 151.84 C 11.29 151.84 14.38 154.93 14.38 158.73 Z M 7.49 158.73" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 3.08 154.48)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="8.82"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.3.3.3.1.1" style="font-size:90%;">B</span></foreignobject></g><path d="M 7.49 92.6" style="fill:none"></path><g fill="#FF0000"><path d="M 14.38 92.6 C 14.38 96.4 11.29 99.49 7.49 99.49 C 3.68 99.49 0.6 96.4 0.6 92.6 C 0.6 88.79 3.68 85.71 7.49 85.71 C 11.29 85.71 14.38 88.79 14.38 92.6 Z M 7.49 92.6" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 2.99 88.34)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="8.99"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.4.4.4.1.1" style="font-size:90%;">C</span></foreignobject></g><path d="M 68.9 171.96" style="fill:none"></path><g fill="#FF0000"><path d="M 75.79 171.96 C 75.79 175.76 72.7 178.85 68.9 178.85 C 65.09 178.85 62.01 175.76 62.01 171.96 C 62.01 168.15 65.09 165.07 68.9 165.07 C 72.7 165.07 75.79 168.15 75.79 171.96 Z M 68.9 171.96" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 64.14 167.7)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="9.51"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.5.5.5.1.1" style="font-size:90%;">D</span></foreignobject></g><path d="M 68.9 97.88" style="fill:none"></path><g fill="#FF0000"><path d="M 75.79 97.88 C 75.79 101.69 72.7 104.77 68.9 104.77 C 65.09 104.77 62.01 101.69 62.01 97.88 C 62.01 94.08 65.09 90.99 68.9 90.99 C 72.7 90.99 75.79 94.08 75.79 97.88 Z M 68.9 97.88" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 64.66 93.63)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="8.48"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.6.6.6.1.1" style="font-size:90%;">E</span></foreignobject></g><path d="M 68.9 39.68" style="fill:none"></path><g fill="#FF0000"><path d="M 75.79 39.68 C 75.79 43.49 72.7 46.57 68.9 46.57 C 65.09 46.57 62.01 43.49 62.01 39.68 C 62.01 35.88 65.09 32.79 68.9 32.79 C 72.7 32.79 75.79 35.88 75.79 39.68 Z M 68.9 39.68" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 64.83 35.43)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="8.13"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.7.7.7.1.1" style="font-size:90%;">F</span></foreignobject></g><path d="M 131.8 248.68" style="fill:none"></path><g fill="#FF0000"><path d="M 138.69 248.68 C 138.69 252.49 135.61 255.57 131.8 255.57 C 128 255.57 124.91 252.49 124.91 248.68 C 124.91 244.88 128 241.79 131.8 241.79 C 135.61 241.79 138.69 244.88 138.69 248.68 Z M 131.8 248.68" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 123.8 244.43)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="16"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.8.8.8.1.1" style="font-size:90%;">G1</span></foreignobject></g><path d="M 215.68 248.68" style="fill:none"></path><g fill="#FF0000"><path d="M 222.57 248.68 C 222.57 252.49 219.48 255.57 215.68 255.57 C 211.87 255.57 208.79 252.49 208.79 248.68 C 208.79 244.88 211.87 241.79 215.68 241.79 C 219.48 241.79 222.57 244.88 222.57 248.68 Z M 215.68 248.68" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 207.68 244.43)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="16"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.9.9.9.1.1" style="font-size:90%;">G2</span></foreignobject></g><path d="M 143.78 140.21" style="fill:none"></path><g fill="#FF0000"><path d="M 150.67 140.21 C 150.67 144.02 147.59 147.1 143.78 147.1 C 139.98 147.1 136.89 144.02 136.89 140.21 C 136.89 136.41 139.98 133.32 143.78 133.32 C 147.59 133.32 150.67 136.41 150.67 140.21 Z M 143.78 140.21" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 136 135.96)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.57"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.10.10.10.1.1" style="font-size:90%;">H1</span></foreignobject></g><path d="M 227.66 148.15" style="fill:none"></path><g fill="#FF0000"><path d="M 234.55 148.15 C 234.55 151.95 231.46 155.04 227.66 155.04 C 223.85 155.04 220.77 151.95 220.77 148.15 C 220.77 144.34 223.85 141.26 227.66 141.26 C 231.46 141.26 234.55 144.34 234.55 148.15 Z M 227.66 148.15" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 219.88 143.89)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.57"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.11.11.11.1.1" style="font-size:90%;">H2</span></foreignobject></g><path d="M 131.8 60.85" style="fill:none"></path><g fill="#FF0000"><path d="M 138.69 60.85 C 138.69 64.65 135.61 67.74 131.8 67.74 C 128 67.74 124.91 64.65 124.91 60.85 C 124.91 57.04 128 53.96 131.8 53.96 C 135.61 53.96 138.69 57.04 138.69 60.85 Z M 131.8 60.85" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 126.44 56.59)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="10.72"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.12.12.12.1.1" style="font-size:90%;">I1</span></foreignobject></g><path d="M 215.68 68.78" style="fill:none"></path><g fill="#FF0000"><path d="M 222.57 68.78 C 222.57 72.59 219.48 75.67 215.68 75.67 C 211.87 75.67 208.79 72.59 208.79 68.78 C 208.79 64.98 211.87 61.89 215.68 61.89 C 219.48 61.89 222.57 64.98 222.57 68.78 Z M 215.68 68.78" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 210.32 64.53)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="10.72"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.pic1.13.13.13.1.1" style="font-size:90%;">I2</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F2.31.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S0.F2.32.2" style="font-size:90%;">
Screenshot of <em class="ltx_emph ltx_font_italic" id="S0.F2.32.2.1">AbstractsViewer</em> showing its views described in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2.SS3" title="2.3 Views ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2.3</span></a>:
<span class="ltx_ERROR undefined" id="S0.F2.32.2.2">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.3">A</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.4">Search Tools Panel</span> including the <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.5">Search List</span>,
<span class="ltx_ERROR undefined" id="S0.F2.32.2.6">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.7">B</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.8">Corpus Map</span>,
<span class="ltx_ERROR undefined" id="S0.F2.32.2.9">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.10">C</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.11">Region Scatter Plot View</span>,
<span class="ltx_ERROR undefined" id="S0.F2.32.2.12">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.13">D</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.14">Region Matrix View</span>,
<span class="ltx_ERROR undefined" id="S0.F2.32.2.15">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.16">E</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.17">Region List</span>,
<span class="ltx_ERROR undefined" id="S0.F2.32.2.18">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.19">F</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.20">Neighborhood Matrix View</span>,
<span class="ltx_ERROR undefined" id="S0.F2.32.2.21">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.22">G</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.23">Document View</span>,
<span class="ltx_ERROR undefined" id="S0.F2.32.2.24">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.25">H</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.26">Neighbor List View</span>,
and
<span class="ltx_ERROR undefined" id="S0.F2.32.2.27">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F2.32.2.28">I</span> <span class="ltx_text ltx_font_sansserif" id="S0.F2.32.2.29">Radial Neighborhood View</span>.
Two of G, H and I are shown, one for each selection.
</span></figcaption>
</figure>
<figure class="ltx_figure" id="S0.F3"><svg class="ltx_picture ltx_centering" height="449" id="S0.F3.pic1" overflow="visible" version="1.1" width="538.46"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,449) matrix(1 0 0 -1 0 0) translate(0.18,0) translate(0,-0.28)"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="449" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="538"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="449" id="S0.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/5660384/Figures/new/intro_example.png" width="538"/></foreignobject></g><path d="M 10.77 436.07" style="fill:none"></path><g fill="#FF0000"><path d="M 19.63 436.07 C 19.63 440.96 15.67 444.93 10.77 444.93 C 5.88 444.93 1.92 440.96 1.92 436.07 C 1.92 431.18 5.88 427.21 10.77 427.21 C 15.67 427.21 19.63 431.18 19.63 436.07 Z M 10.77 436.07" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 4.55 430.39)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.45"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.2.2.2.1.1" style="font-size:120%;">A</span></foreignobject></g><path d="M 148.1 359.64" style="fill:none"></path><g fill="#FF0000"><path d="M 154.99 359.64 C 154.99 363.45 151.9 366.53 148.1 366.53 C 144.29 366.53 141.21 363.45 141.21 359.64 C 141.21 355.84 144.29 352.75 148.1 352.75 C 151.9 352.75 154.99 355.84 154.99 359.64 Z M 148.1 359.64" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 140.32 355.39)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.57"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.3.3.3.1.1" style="font-size:90%;">A1</span></foreignobject></g><path d="M 269.28 359.64" style="fill:none"></path><g fill="#FF0000"><path d="M 276.17 359.64 C 276.17 363.45 273.08 366.53 269.28 366.53 C 265.47 366.53 262.39 363.45 262.39 359.64 C 262.39 355.84 265.47 352.75 269.28 352.75 C 273.08 352.75 276.17 355.84 276.17 359.64 Z M 269.28 359.64" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 261.49 355.39)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.57"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.4.4.4.1.1" style="font-size:90%;">A2</span></foreignobject></g><path d="M 398.53 359.64" style="fill:none"></path><g fill="#FF0000"><path d="M 405.42 359.64 C 405.42 363.45 402.34 366.53 398.53 366.53 C 394.73 366.53 391.64 363.45 391.64 359.64 C 391.64 355.84 394.73 352.75 398.53 352.75 C 402.34 352.75 405.42 355.84 405.42 359.64 Z M 398.53 359.64" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 390.75 355.39)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.57"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.5.5.5.1.1" style="font-size:90%;">A3</span></foreignobject></g><path d="M 10.77 337.17" style="fill:none"></path><g fill="#FF0000"><path d="M 19.63 337.17 C 19.63 342.06 15.67 346.02 10.77 346.02 C 5.88 346.02 1.92 342.06 1.92 337.17 C 1.92 332.27 5.88 328.31 10.77 328.31 C 15.67 328.31 19.63 332.27 19.63 337.17 Z M 10.77 337.17" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 4.89 331.49)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.76"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.6.6.6.1.1" style="font-size:120%;">B</span></foreignobject></g><path d="M 113.1 259.39" style="fill:none"></path><g fill="#FF0000"><path d="M 119.99 259.39 C 119.99 263.2 116.9 266.28 113.1 266.28 C 109.29 266.28 106.21 263.2 106.21 259.39 C 106.21 255.59 109.29 252.5 113.1 252.5 C 116.9 252.5 119.99 255.59 119.99 259.39 Z M 113.1 259.39" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 105.58 255.14)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.05"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.7.7.7.1.1" style="font-size:90%;">B1</span></foreignobject></g><path d="M 350.06 259.39" style="fill:none"></path><g fill="#FF0000"><path d="M 356.95 259.39 C 356.95 263.2 353.86 266.28 350.06 266.28 C 346.25 266.28 343.17 263.2 343.17 259.39 C 343.17 255.59 346.25 252.5 350.06 252.5 C 353.86 252.5 356.95 255.59 356.95 259.39 Z M 350.06 259.39" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 342.53 255.14)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.05"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.8.8.8.1.1" style="font-size:90%;">B2</span></foreignobject></g><path d="M 10.77 235.11" style="fill:none"></path><g fill="#FF0000"><path d="M 19.63 235.11 C 19.63 240.01 15.67 243.97 10.77 243.97 C 5.88 243.97 1.92 240.01 1.92 235.11 C 1.92 230.22 5.88 226.26 10.77 226.26 C 15.67 226.26 19.63 230.22 19.63 235.11 Z M 10.77 235.11" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 4.78 229.44)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.99"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.9.9.9.1.1" style="font-size:120%;">C</span></foreignobject></g><path d="M 121.18 134.87" style="fill:none"></path><g fill="#FF0000"><path d="M 128.07 134.87 C 128.07 138.67 124.98 141.76 121.18 141.76 C 117.37 141.76 114.29 138.67 114.29 134.87 C 114.29 131.06 117.37 127.98 121.18 127.98 C 124.98 127.98 128.07 131.06 128.07 134.87 Z M 121.18 134.87" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 113.57 130.61)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.22"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.10.10.10.1.1" style="font-size:90%;">C1</span></foreignobject></g><path d="M 280.05 121.38" style="fill:none"></path><g fill="#FF0000"><path d="M 286.94 121.38 C 286.94 125.19 283.86 128.27 280.05 128.27 C 276.24 128.27 273.16 125.19 273.16 121.38 C 273.16 117.58 276.24 114.49 280.05 114.49 C 283.86 114.49 286.94 117.58 286.94 121.38 Z M 280.05 121.38" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 272.44 117.13)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.22"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.11.11.11.1.1" style="font-size:90%;">C2</span></foreignobject></g><path d="M 500.85 112.39" style="fill:none"></path><g fill="#FF0000"><path d="M 507.74 112.39 C 507.74 116.19 504.66 119.28 500.85 119.28 C 497.05 119.28 493.96 116.19 493.96 112.39 C 493.96 108.58 497.05 105.5 500.85 105.5 C 504.66 105.5 507.74 108.58 507.74 112.39 Z M 500.85 112.39" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 493.24 108.13)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.22"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.12.12.12.1.1" style="font-size:90%;">C3</span></foreignobject></g><path d="M 10.77 87.67" style="fill:none"></path><g fill="#FF0000"><path d="M 19.63 87.67 C 19.63 92.56 15.67 96.52 10.77 96.52 C 5.88 96.52 1.92 92.56 1.92 87.67 C 1.92 82.77 5.88 78.81 10.77 78.81 C 15.67 78.81 19.63 82.77 19.63 87.67 Z M 10.77 87.67" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 4.43 81.99)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.68"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.13.13.13.1.1" style="font-size:120%;">D</span></foreignobject></g><path d="M 113.1 12.13" style="fill:none"></path><g fill="#FF0000"><path d="M 119.99 12.13 C 119.99 15.94 116.9 19.02 113.1 19.02 C 109.29 19.02 106.21 15.94 106.21 12.13 C 106.21 8.33 109.29 5.24 113.1 5.24 C 116.9 5.24 119.99 8.33 119.99 12.13 Z M 113.1 12.13" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 105.23 7.88)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.74"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.14.14.14.1.1" style="font-size:90%;">D1</span></foreignobject></g><path d="M 393.14 12.13" style="fill:none"></path><g fill="#FF0000"><path d="M 400.03 12.13 C 400.03 15.94 396.95 19.02 393.14 19.02 C 389.34 19.02 386.25 15.94 386.25 12.13 C 386.25 8.33 389.34 5.24 393.14 5.24 C 396.95 5.24 400.03 8.33 400.03 12.13 Z M 393.14 12.13" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 385.27 7.88)"><foreignobject color="#FFFFFF" height="8.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="15.74"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.pic1.15.15.15.1.1" style="font-size:90%;">D2</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F3.64.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S0.F3.65.2" style="font-size:90%;">
 This example illustrates four exemplary workflows in the context of the present paper. The objectives are to discover related papers (to provide context for our work and generate ideas for improvement), to learn more about the corpus and find commonly used terms.
                                                                                                                                                  
<br class="ltx_break"/>                                                                                                                                                  <em class="ltx_emph ltx_font_italic" id="S0.F3.65.2.1">Workflow</em> <span class="ltx_ERROR undefined" id="S0.F3.65.2.2">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.3">A</span>. <span class="ltx_ERROR undefined" id="S0.F3.65.2.4">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.5">A1</span>: We search for the relevant term <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.6">text</span>. This provides too many documents (292) to examine individually. <span class="ltx_ERROR undefined" id="S0.F3.65.2.7">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.8">A2</span>: However, we can use the <span class="ltx_text ltx_font_sansserif" id="S0.F3.65.2.9">Corpus Map</span> to see how the documents are distributed and examine particularly dense regions. <span class="ltx_ERROR undefined" id="S0.F3.65.2.10">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.11">A3</span>: Selecting a region (yellow rectangle) enables explanation of the region: a term-based explanation of salient words or an <span class="ltx_ERROR undefined" id="S0.F3.65.2.12">\replaced</span>exemplar-baseditem-based explanation of representative documents. Here the terms <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.13">text</span>, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.14">document</span>, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.15">collect</span>, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.16">topic</span>, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.17">word</span> are salient and the most representative documents include other text exploration systems or have terms which suggest similar topics, such as <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.18">topic</span>, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.19">theme</span>, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.20">citation</span>. We identify this region as one focusing on Text Corpus Exploration, the “TCE region:” saving the representative document list allows for systematic, exploration.                                                                                                                                                 

<br class="ltx_break"/>                                                                                                                                                 
<em class="ltx_emph ltx_font_italic" id="S0.F3.65.2.21">Workflow</em> <span class="ltx_ERROR undefined" id="S0.F3.65.2.22">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.23">B</span>. <span class="ltx_ERROR undefined" id="S0.F3.65.2.24">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.25">B1</span>: Selecting another dense region shows with a different explanation. <span class="ltx_ERROR undefined" id="S0.F3.65.2.26">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.27">B2</span>: The <span class="ltx_text ltx_font_sansserif" id="S0.F3.65.2.28">Region Matrix View</span> reveals the terms <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.29">event</span> and <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.30">challenge</span> are very salient. Sorting documents by relevant terms shows many of these papers are Vast Challenge solutions which often involve text analysis, but are less relevant.

<br class="ltx_break"/>                                                                                                                                                  
<br class="ltx_break"/>                                                                                                                                                  <em class="ltx_emph ltx_font_italic" id="S0.F3.65.2.31">Workflow</em> <span class="ltx_ERROR undefined" id="S0.F3.65.2.32">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.33">C</span>. <span class="ltx_ERROR undefined" id="S0.F3.65.2.34">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.35">C1</span>: We select a small, dense outlier region.
<span class="ltx_ERROR undefined" id="S0.F3.65.2.36">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.37">C2</span>: <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.38">text</span> is not a salient term, but <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.39">labeling</span> is. <span class="ltx_ERROR undefined" id="S0.F3.65.2.40">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.41">C3</span>: examining the selected <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.42">text</span> papers from the <span class="ltx_text ltx_font_sansserif" id="S0.F3.65.2.43">Region List</span>, we see that many refer to text labeling, but there are text analysis systems which use labeling. While the region is generally not relevant, the specific papers can seed a similarity-based search to discover more papers about using labeling in exploration.                                                                                                                                                  

<br class="ltx_break"/>                                                                                                                                                  <em class="ltx_emph ltx_font_italic" id="S0.F3.65.2.44">Workflow</em> <span class="ltx_ERROR undefined" id="S0.F3.65.2.45">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.46">D</span>. We want to determine which term, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.47">corpus</span> or <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.48">collection</span> more accurately describes our work. <span class="ltx_ERROR undefined" id="S0.F3.65.2.49">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.50">D1</span>: we search both terms and use comparison features to show both distributions on the <span class="ltx_text ltx_font_sansserif" id="S0.F3.65.2.51">Corpus Map</span>. This allows us to examine differences in how these terms are used. <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.52">Corpus</span> is localized in a few clumps (green), while <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.53">collection</span> is more scattered (gray). <span class="ltx_ERROR undefined" id="S0.F3.65.2.54">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F3.65.2.55">D2</span>: Examining the clumps for <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.56">corpus</span> shows one is in a region explained by language related terms such as <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.57">linguist</span> and <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.58">language</span>, while the other is the identified TCE region. In contrast, <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.59">collection</span>’s scattered points suggest its use is more broad. Examining dense regions, we see that <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.60">collection</span> is frequently used to describe things other than text, such as images, graphs, and ensembles. The term <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.61">corpus</span> is more aligned with our usage. Other uses of <span class="ltx_text ltx_font_typewriter" id="S0.F3.65.2.62">collection</span> suggest similar problems to find inspirations.
</span></figcaption>
</figure>
<figure class="ltx_figure" id="S0.F4"><svg class="ltx_picture ltx_centering" height="719" id="S0.F4.pic1" overflow="visible" version="1.1" width="956.89"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,719) matrix(1 0 0 -1 0 0) translate(24.51,0) translate(0,-0.28)"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="719" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="598"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="719" id="S0.F4.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/5660384/Figures/new/views_image.png" width="598"/></foreignobject></g><path d="M 92.78 697.97" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -10.98 691.99)"><foreignobject height="21.25" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="207.89"><span class="ltx_text" id="S0.F4.pic1.2.2.2.1.1" style="font-size:173%;">Corpus Level Views</span></foreignobject></g><path d="M 14.96 700.13" style="fill:none"></path><g fill="#FF0000"><path d="M 23.82 700.13 C 23.82 705.02 19.85 708.99 14.96 708.99 C 10.07 708.99 6.1 705.02 6.1 700.13 C 6.1 695.24 10.07 691.27 14.96 691.27 C 19.85 691.27 23.82 695.24 23.82 700.13 Z M 14.96 700.13" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 8.73 694.46)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.45"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.3.3.3.1.1" style="font-size:120%;">A</span></foreignobject></g><path d="M 5.98 568.44" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 10.87 565.33)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.4.4.4.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.5.5.5.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]A1: Corpus Map</span></foreignobject></g><path d="M 230.44 568.44" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 235.33 565.33)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.6.6.6.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.7.7.7.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]A2: Search Tools Panel</span></foreignobject></g><path d="M 92.78 533.91" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -9.71 527.93)"><foreignobject height="21.25" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="205.36"><span class="ltx_text" id="S0.F4.pic1.8.8.8.1.1" style="font-size:173%;">Region Level Views</span></foreignobject></g><path d="M 14.96 536.06" style="fill:none"></path><g fill="#FF0000"><path d="M 23.82 536.06 C 23.82 540.96 19.85 544.92 14.96 544.92 C 10.07 544.92 6.1 540.96 6.1 536.06 C 6.1 531.17 10.07 527.21 14.96 527.21 C 19.85 527.21 23.82 531.17 23.82 536.06 Z M 14.96 536.06" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 9.08 530.39)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.76"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.9.9.9.1.1" style="font-size:120%;">B</span></foreignobject></g><path d="M 5.98 402.95" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 10.87 399.83)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.10.10.10.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.11.11.11.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]B1: Corpus Map</span></foreignobject></g><path d="M 125.7 402.95" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 130.59 399.83)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.12.12.12.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.13.13.13.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]B2: Region Scatter Plot View</span></foreignobject></g><path d="M 272.34 402.95" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 277.23 399.83)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.14.14.14.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.15.15.15.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]B3: Region Matrix View</span></foreignobject></g><path d="M 410.01 402.95" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 414.9 399.83)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.16.16.16.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.17.17.17.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]B4: Region List</span></foreignobject></g><path d="M 119.71 372.01" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -19.89 366.03)"><foreignobject height="21.25" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="278.82"><span class="ltx_text" id="S0.F4.pic1.18.18.18.1.1" style="font-size:173%;">Neighborhood Level Views</span></foreignobject></g><path d="M 14.96 374.17" style="fill:none"></path><g fill="#FF0000"><path d="M 23.82 374.17 C 23.82 379.06 19.85 383.03 14.96 383.03 C 10.07 383.03 6.1 379.06 6.1 374.17 C 6.1 369.28 10.07 365.31 14.96 365.31 C 19.85 365.31 23.82 369.28 23.82 374.17 Z M 14.96 374.17" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 8.96 368.5)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.99"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.19.19.19.1.1" style="font-size:120%;">C</span></foreignobject></g><path d="M 8.98 207.23" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 13.87 204.11)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.20.20.20.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.21.21.21.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]C1: Neighbor List View</span></foreignobject></g><path d="M 320.23 207.23" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 325.12 204.11)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.22.22.22.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.23.23.23.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]C2: Radial Neighborhood View</span></foreignobject></g><path d="M 463.88 207.23" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 468.76 204.11)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.24.24.24.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.25.25.25.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]C3: Neighborhood Matrix View</span></foreignobject></g><path d="M 103.55 178.45" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -16.54 170.15)"><foreignobject height="16.6" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="239.9"><span class="ltx_text" id="S0.F4.pic1.26.26.26.1.1" style="font-size:173%;">Document Level Views</span></foreignobject></g><path d="M 14.96 179.89" style="fill:none"></path><g fill="#FF0000"><path d="M 23.82 179.89 C 23.82 184.78 19.85 188.75 14.96 188.75 C 10.07 188.75 6.1 184.78 6.1 179.89 C 6.1 175 10.07 171.03 14.96 171.03 C 19.85 171.03 23.82 175 23.82 179.89 Z M 14.96 179.89" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 8.62 174.22)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.68"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.27.27.27.1.1" style="font-size:120%;">D</span></foreignobject></g><path d="M 5.98 15.47" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 10.87 12.36)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.28.28.28.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.29.29.29.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]D1: Primary Selected Document</span></foreignobject></g><path d="M 260.37 15.47" style="fill:none"></path><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 265.26 12.36)"><foreignobject height="12.45" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.8"><span class="ltx_ERROR undefined" id="S0.F4.pic1.30.30.30.1.1">\Circled</span><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S0.F4.pic1.31.31.31.2.2" style="font-size:90%;">[fill color=red, outer color=red, inner color=white]D2: Secondary Selected Document</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S0.F4.3.2" style="font-size:90%;">
 AbstractsViewer supports
Text Corpus Exploration
through a variety of flexible views which operate on multiple scales. Standard designs are enhanced with explanations and comparative features.
</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Related Work</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Some key prior systems that inspire our work include:
Spire <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib6" title="">6</a>]</cite> that showed the value of multiple views in TCE;
Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite>, which showed the utility of transformer-based similarity;
Cartolable <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite>, which showed the value of spatial maps;
Serendip <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>]</cite>, which showed multiscale tools connecting terms and documents;
and Footprints <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib9" title="">9</a>]</cite>, which showed support for the iterative process of exploration. Our work builds on these elements, enhancing common views with explanations and comparison features.</p>
</div>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Text Corpora Exploration</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">Our goal is to support researchers in using TCE in their work.
Such work involves a variety of objectives<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib11" title="">11</a>]</cite>.
Soufan <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.1">et al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S1.SS1.p1.1.1.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib2" title="">2</a><span class="ltx_text ltx_font_upright" id="S1.SS1.p1.1.1.2.2">]</span></cite></span> document how TCE is a form of <em class="ltx_emph ltx_font_italic" id="S1.SS1.p1.1.2">Exploratory Search</em> (ES). In ES, users often have diverse and uncertain goals, lack familiarity with the corpus or the domain, and lack specific search targets.
ES is often characterized by the broad objectives of discovery and learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib12" title="">12</a>]</cite>.
<em class="ltx_emph ltx_font_italic" id="S1.SS1.p1.1.3">Our work seeks to support the exploratory nature of TCE.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1">Discovery without a specific target is a key element of exploratory search.
<span class="ltx_ERROR undefined" id="S1.SS1.p2.1.1">\added</span>Thudt <span class="ltx_text ltx_font_italic" id="S1.SS1.p2.1.2">et al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S1.SS1.p2.1.2.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib4" title="">4</a><span class="ltx_text ltx_font_upright" id="S1.SS1.p2.1.2.2.2">]</span></cite></span> describe this as serendipitous discovery (finding things without knowing what to look for), and discusses conditions that
<span class="ltx_ERROR undefined" id="S1.SS1.p2.1.3">\replaced</span>promote such discovery.enable such discoveries by promoting encounters with items they may not have sought.
Systems have used these concepts for exploration of text corpora <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>]</cite>, networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib13" title="">13</a>]</cite>, and faceted relations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib14" title="">14</a>]</cite>.
<span class="ltx_ERROR undefined" id="S1.SS1.p2.1.4">\added</span>However, André <span class="ltx_text ltx_font_italic" id="S1.SS1.p2.1.5">et al.</span>
<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib15" title="">15</a>]</cite> explain how serendipitous discovery requires more than chance encounters; it requires understanding what is found and assessing relevance.
<em class="ltx_emph ltx_font_italic" id="S1.SS1.p2.1.6">Our approach combines the elements of serendipity search with enhanced tools that connect to understanding and relevance checking.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p3">
<p class="ltx_p" id="S1.SS1.p3.1">Learning objectives in TCE are less specific than discovery. To support it, tools often focus on corpus level overview. Some tools automatically
uncover structure in the documents, such as identifying clusters <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib16" title="">16</a>]</cite>, themes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib18" title="">18</a>]</cite>, groups <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>]</cite>, taxonomies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib19" title="">19</a>]</cite>, and trends <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib20" title="">20</a>]</cite>. Such approaches directly serve tasks that involve analyzing these larger scale structures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib11" title="">11</a>]</cite>. However, they rely on automation to succeed, and require approaches for interpreting these often complex results <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib21" title="">21</a>]</cite>.
Serendip <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>]</cite> shows the potential of bridging scales, connecting corpus scale topics through terms to specific text locations.
<em class="ltx_emph ltx_font_italic" id="S1.SS1.p3.1.1">Our approach uses explanation and comparison to help interpret larger structures and enable multiscale learning; integrating learning with discovery.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p4">
<p class="ltx_p" id="S1.SS1.p4.1">TCE systems may either use meta-data (e.g., keywords, authorship and
<span class="ltx_ERROR undefined" id="S1.SS1.p4.1.1">\replaced</span>citations) orcitations)or content for search and organization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib10" title="">10</a>]</cite>.
<span class="ltx_ERROR undefined" id="S1.SS1.p4.1.2">\added</span>Meta-data approaches can serve a variety of tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib22" title="">22</a>]</cite>.
<em class="ltx_emph ltx_font_italic" id="S1.SS1.p4.1.3">We focus on content-based TCE.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p5">
<p class="ltx_p" id="S1.SS1.p5.1">A common content-based TCE tool for discovery is similarity-based recommendation (or search). Such tools are built into digital library interfaces (e.g., IEEE Explore <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib23" title="">23</a>]</cite> and PubMed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib24" title="">24</a>]</cite>). Services such as Semantic Scholar <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib25" title="">25</a>]</cite> provide more sophisticated recommendations. Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> integrates state-of-art recommendations into a visual interface. <em class="ltx_emph ltx_font_italic" id="S1.SS1.p5.1.1">Our work enhances this integration using explanations to allow for flexibly addressing a broader range of objectives.</em>
Pure Suggest <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib26" title="">26</a>]</cite> considers a related problem explaining citation rankings.</p>
</div>
<div class="ltx_para" id="S1.SS1.p6">
<p class="ltx_p" id="S1.SS1.p6.1">A similarity metric drives content-based recommendations. Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> shows the benefits of a state-of-art specialized metric in TCE.
Many approaches exist for computing similarity, see <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib27" title="">27</a>]</cite> for a survey and comparison. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib28" title="">28</a>]</cite> combines methods and provides tools for interactively optimizing combinations.
For graph exploration, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib29" title="">29</a>]</cite> considers multiple similarity metrics, but blends them together. Accuracy in recommendations does not always correlate with user experience, methods that can better support user tasks may be preferable <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib30" title="">30</a>]</cite>.
<em class="ltx_emph ltx_font_italic" id="S1.SS1.p6.1.1">Our work provides multiple metrics (including the same method as Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite>) to users in order to provide multiple perspectives. We also provide explanation tools to better integrate the recommendations into workflows.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p7">
<p class="ltx_p" id="S1.SS1.p7.1">Automatically created 2D maps of a corpus to indicate relationships among documents were introduced
in early systems such as SPIRE (Galaxy) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib6" title="">6</a>]</cite> and WEBSOM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib31" title="">31</a>]</cite>.
Such approaches embed texts in 2D based on their content and provide visualizations (often augmented scatterplots) to view this map. Recent examples include Cartolabe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite>, which features high-performance, scalable scatterplots of co-embeddings of documents and other entities,
<span class="ltx_ERROR undefined" id="S1.SS1.p7.1.1">\added</span>Vitality<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> which provides efficient scatterplot navigation on standard DR of a state-of-art metric, and Docucompass <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib32" title="">32</a>]</cite> which introduces specialized interactions for document maps.
Our work uses simpler scatterplot interactions in order to explore interpretability of the maps; our approach would benefit from the scalability concepts from these systems.
As with prior work, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib33" title="">33</a>]</cite>, our approach uses the map to contextualize search results as well as organize information.
<em class="ltx_emph ltx_font_italic" id="S1.SS1.p7.1.2">Our work enhances corpus maps with explanations to better integrate with coordinated views and support a broader range of tasks.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p8">
<p class="ltx_p" id="S1.SS1.p8.1">A wide range of layout algorithms have been used to make corpus maps.
We adopt a standard approach of using embeddings of document vectors, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite>. Our system does allow for switching metric and layout method, but users rarely deviate from the default. <em class="ltx_emph ltx_font_italic" id="S1.SS1.p8.1.1">Our work mixes layout and similarity approaches to serve as explanation surrogates and provide multiple perspectives.</em>
Brehmer <span class="ltx_text ltx_font_italic" id="S1.SS1.p8.1.2">et al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S1.SS1.p8.1.2.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib19" title="">19</a><span class="ltx_text ltx_font_upright" id="S1.SS1.p8.1.2.2.2">]</span></cite></span> note that spatial layouts are inconvenient for some tasks, and suggest structured views (lists) to scatterplots to encourage systematic exploration. <em class="ltx_emph ltx_font_italic" id="S1.SS1.p8.1.3">Our work combines spatial and structured views using coordination, ranking, and salience functions to enable users to coordinate views and gain the advantages of both.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p9">
<p class="ltx_p" id="S1.SS1.p9.1">Labels that describe the content of areas of corpus maps have been used since early systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib34" title="">34</a>]</cite>. Systems identify coherent document groups (usually by clustering) and provide labels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib36" title="">36</a>]</cite>. Systems outside of the text domain have applied region labeling to more arbitrary explanations of high-dimensional data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib38" title="">38</a>]</cite>. <em class="ltx_emph ltx_font_italic" id="S1.SS1.p9.1.1">We apply area labeling to explain arbitrary spatial regions (not necessarily coherent groups) and to decouple term selection from the map models.</em></p>
</div>
<div class="ltx_para" id="S1.SS1.p10">
<p class="ltx_p" id="S1.SS1.p10.1">Many text visualization systems show the contributions of individual words to <span class="ltx_ERROR undefined" id="S1.SS1.p10.1.1">\replaced</span>the underlying modelsmodel decisions (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib41" title="">41</a>]</cite>).
<span class="ltx_ERROR undefined" id="S1.SS1.p10.1.2">\replaced</span>[comment="address comment about Zimmer"]
Our post hoc explanations approach allows us to mix-and-match salience functions to provide matrix reordering options and views even when the underlying models do not provide interpretable weights.
<em class="ltx_emph ltx_font_italic" id="S1.SS1.p10.1.3">Our apprach enables using popular term-document designs in more flexible ways, including more extensive reordering options, different types of explanations, and counter-factuals.</em>

The use of re-orderable matrices to show a collection of document/term relationships is one common strategy. <em class="ltx_emph ltx_font_italic" id="S1.SS1.p10.1.4">We make extensive use of term weight visualizations, using them with surrogate models and multiple sorting methods.</em></p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Explainations and Interpretability</h3>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">Explanations are a common strategy to help users interpret system behavior<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib45" title="">45</a>]</cite>. <em class="ltx_emph ltx_font_italic" id="S1.SS2.p1.1.1">Post hoc explanations</em> are a strategy where explanations are created after modeling and decision-making is complete <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib46" title="">46</a>]</cite>.
Such a strategy allows decoupling the explanation process from the decision model itself, providing explanations for models that do not provide them.
<em class="ltx_emph ltx_font_italic" id="S1.SS2.p1.1.2">Surrogate models</em> are a common model-agnostic strategy. An interpretable model is built to approximate the method used for decisions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib46" title="">46</a>]</cite>. The interpretable model is used for explanations.
This approach has been called re-projection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib44" title="">44</a>]</cite> and re-representation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib47" title="">47</a>]</cite>.
LIME <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib48" title="">48</a>]</cite> and its successors (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib51" title="">51</a>]</cite>) extend this approach with <em class="ltx_emph ltx_font_italic" id="S1.SS2.p1.1.3">local surrogates</em>, where different simple models are constructed for different parts of the data set. The key insight is that a simple model is unlikely to be sufficient to capture the entire behavior of a complex model, however, it may be a good enough approximation over a small portion of the data.
<em class="ltx_emph ltx_font_italic" id="S1.SS2.p1.1.4">Our work brings the post hoc explanation approach to TCE, applying it to interpret recommendations and layout. We introduce a local surrogate approach that applies salience functions to subsets of the data.</em></p>
</div>
<div class="ltx_para" id="S1.SS2.p2">
<p class="ltx_p" id="S1.SS2.p2.1">In machine learning, explanations span a spectrum of scales <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib46" title="">46</a>]</cite>, from local (reasons for specific decisions) to global (overall properties of the model, such as generally important features). Explanations may be either item (example) based, or feature based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib46" title="">46</a>]</cite>.
The field focuses on classification and prediction; we are unaware of it considering TCE directly.
<em class="ltx_emph ltx_font_italic" id="S1.SS2.p2.1.1">Our work brings explanations to TCE across a range of scales by combining item (document) and feature (term) based explanations.</em></p>
</div>
<div class="ltx_para" id="S1.SS2.p3">
<p class="ltx_p" id="S1.SS2.p3.1">Explanations are valuable in recommendation systems. Early work showed that explanations lead to greater acceptance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib53" title="">53</a>]</cite>
<span class="ltx_ERROR undefined" id="S1.SS2.p3.1.1">\added</span>and trust <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib54" title="">54</a>]</cite>.
Tintarev and Masthoff <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib55" title="">55</a>]</cite> describe many goals and evaluation metrics for recommendations. The tasks are different than in TCE which can lead to different goals <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib56" title="">56</a>]</cite>, but inspire our thinking.
Zhang and Chen <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib57" title="">57</a>]</cite> provide a recent survey of methods for explainable recommendation.
Standard recommendation systems are often based on other users’ behaviors <span class="ltx_ERROR undefined" id="S1.SS2.p3.1.2">\replaced</span>and, therefore,, and require different methods than the item similarity-based recommendations used in TCE.
<span class="ltx_ERROR undefined" id="S1.SS2.p3.1.3">\added</span>Multi-list recommendation systems have been shown to have benefits and costs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib59" title="">59</a>]</cite>.
<em class="ltx_emph ltx_font_italic" id="S1.SS2.p3.1.4">We apply concepts from interpretations of recommendations and predictions.</em></p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Exploratory Search</h3>
<div class="ltx_para" id="S1.SS3.p1">
<span class="ltx_ERROR undefined" id="S1.SS3.p1.1">\added</span>
<p class="ltx_p" id="S1.SS3.p1.2">[comment="new section from Old S3"]
Our approach is intended to address tasks more akin to those
of <em class="ltx_emph ltx_font_italic" id="S1.SS3.p1.2.1">exploratory search,</em> which is broadly defined as an information seeking problem with open ended motivations and objectives <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib1" title="">1</a>]</cite>.
The objectives <span class="ltx_ERROR undefined" id="S1.SS3.p1.2.2">\replaced</span>arecan be roughly categorized as item discovery (e.g., identifying relevant items that were not previously known) and learning (about the corpus, exploration strategies, and the domain itself).
As discussed in the exploratory search literature<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib1" title="">1</a>]</cite> the two objectives are related. Discovery is an iterative, explorative process where a user poses a “query” (such as terms, a document for similarity, or a region on a map) that yields a result (set of documents) which are assessed for relevance and quality, and then a new query is formulated. At each step, the user may gain knowledge (i.e., learn) about the corpus and domain in order to select the discovered items and develop further queries. However, this knowledge may serve as an outcome unto itself, beyond its use in the discovery iteration.</p>
</div>
<div class="ltx_para" id="S1.SS3.p2">
<span class="ltx_ERROR undefined" id="S1.SS3.p2.1">\added</span>
<p class="ltx_p" id="S1.SS3.p2.2">Discovery is a focus of other systems such as Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> and Semantic Scholar <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib25" title="">25</a>]</cite>, and is sometimes referred to as Serendipitous Search <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib4" title="">4</a>]</cite>. We seek to enhance discovery by supporting assessment, query refinement, and, more generally, learning. For example, prior systems offer similarity search as a way to identify potential discovery targets; we couple similarity search with enhancements that explain the recommendations by supporting relevance assessment (e.g., by showing the document and highlighting relevant terms) and query refinement (e.g., by exposing terms and documents that may make good queries). Our examples and studies show that these enhancements are useful for aiding discovery, but also for more general objectives in learning about the corpus and domain.
Footprints <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib9" title="">9</a>]</cite> also considers the iterative and exploratory nature of discovery, but does not consider the integration of content-based tools.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods and Details</h2>
<div class="ltx_para" id="S2.p1">
<span class="ltx_ERROR undefined" id="S2.p1.1">\replaced</span>
<p class="ltx_p" id="S2.p1.2">The backbone algorithms of a content-based TCE system are the similarity metric for finding documents and the layout algorithm for spatialization (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2.SS1" title="2.1 Similarity and Layout ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2.1</span></a>).
To these, we add the concept of salience functions that measure the importance of <span class="ltx_ERROR undefined" id="S2.p1.2.1">\replaced</span>exemplarsitems and features in the outputs of these algorithms (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2.SS2" title="2.2 Salience Functions ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2.2</span></a>).
Salience functions may measure the actual strategies used by the algorithms, in which case they are causal. However, by separating algorithms and salience functions we allow for each to be chosen independently which provides flexibility in assembling workflows, including the possibility of non-causal explanations.
Salience functions lead to explanations by identifying items and features to be highlighted in adapted views (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2.SS3" title="2.3 Views ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2.3</span></a>).
Salience functions allow us to better leverage best practices for views, for example by providing rankings for re-orderable matrices .
Salience functions also work well with comparison strategies, by highlighting similarities and differences as well as providing targets for comparison (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2.SS4" title="2.4 Design for Comparison and Linking ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2.4</span></a>).

This section provides details of our approach.
SEC describes the standard TCE tools we build on.
SEC then introduces the salience functions used to provide explanations that are employed in
SEC to create enhanced versions of standard views.
SEC provides further extensions of these views to support comparison and integration.
</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Similarity and Layout</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">A core element of TCE systems is a <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.1">similarity metric</em> that measures the difference between documents. Such a metric is used to provide recommendations of similar documents and to drive spatial layouts. There are a wide variety of similarity metrics, see <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib27" title="">27</a>]</cite> for a survey.
Often texts are represented in some vector space, and an appropriate vector metric is used between pairs.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Classic approaches use variants of word count vectors. Term frequency inverse document frequency (TF-IDF) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib60" title="">60</a>]</cite> is a prevalent approach that performs well in theory and practice <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib61" title="">61</a>]</cite>. Our “TF-IDF metric” is the cosine distance applied to TF-IDF vectors created using standard stemming and stop word removal. More recent approaches, such as SPECTER<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib62" title="">62</a>]</cite>, apply natural language processing tools, such as transformers, to overcome drawbacks of term-based approaches. Systems such as Vitality<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> and Semantic Scholar <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib25" title="">25</a>]</cite> rely on SPECTER.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<span class="ltx_ERROR undefined" id="S2.SS1.p3.1">\added</span>
<p class="ltx_p" id="S2.SS1.p3.2">AbstractsViewer provides both a transformer metric and a term-based metric.
In practice, we observe that classic and transformer approaches often provide <em class="ltx_emph ltx_font_italic" id="S2.SS1.p3.2.1">different</em> results, which are differently useful.
We do not observe a systematic preference: both were used by all participants. In our user study (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4.SS3" title="4.3 User Studies ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 4.3</span></a>), many participants, without being told how the underlying methods worked, articulated benefits in each: TF-IDF tending to identify specific details, while SPECTER identified more <span class="ltx_ERROR undefined" id="S2.SS1.p3.2.2">\replaced</span>generalspecific themes.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>
<span class="ltx_ERROR undefined" id="footnote2.1">\added</span>This is not surprising: TF-IDF tends to match specific words where SPECTER can match latent concepts. Examples are provided in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4" title="4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 4</span></a>.
</span></span></span>
To encourage users to employ both types of recommendations AbstractsViewer’s <span class="ltx_text ltx_font_sansserif" id="S2.SS1.p3.2.3">Neighbor List View</span> shows two lists of recommendations. The supplemental material provides statistics on overlap: the two methods usually provide different results.
<span class="ltx_ERROR undefined" id="S2.SS1.p3.2.4">\replaced</span>
Comparative support identifies matches between lists.

Comparative support that highlights elements identifies matches so strong that it appears in both, and aids users in appreciating the differences between lists.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">Corpus maps place each document at a position in 2D. Modern approaches use embedding techniques applied to document vectors. For example, Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> applies UMAP to SPECTER vectors, while Cartolabe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite> applies UMAP to TF-IDF vectors processed by LSA.
Our system uses a UMAP <span class="ltx_ERROR undefined" id="S2.SS1.p4.1.1">\added</span>dimensionality reduction (with our default parameters) of either TF-IDF or SPECTER vector distance metrics. In user studies, we observe that any preference was not strong enough to overcome default bias <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib63" title="">63</a>]</cite>.
Because maps are generally created once for each corpus, it is feasible for a corpus creator to manually check and tune map parameters. However, we have empirically determined a set of default parameters that are used for all maps discussed in this paper. We had experimented with providing more options to users, but chose to use two metrics and one layout algorithm.</p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<span class="ltx_ERROR undefined" id="S2.SS1.p5.1">\added</span>
<p class="ltx_p" id="S2.SS1.p5.2"><span class="ltx_text ltx_font_bold" id="S2.SS1.p5.2.1">Design Choice</span>: AbstractsViewer provides choices for its underlying algorithms, providing state-of-art and classical approaches. A consistent interface is enabled by using post hoc explanations powered by salience functions. Comparative views enable workflows that combine approaches.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Salience Functions</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">A <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.1.1">salience function</em> is a procedure that determines an importance for each member of a set. We use salience functions for terms and documents, ordering them to provide concise lists (top-N) that serve as descriptive explanations of sets independent of how the set was determined.
This is a <em class="ltx_emph ltx_font_italic" id="S2.SS2.p1.1.2">post hoc explanation</em> (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S1.SS2" title="1.2 Explainations and Interpretability ‣ 1 Related Work ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 1.2</span></a>).
<span class="ltx_ERROR undefined" id="S2.SS2.p1.1.3">\added</span>
The salience functions may be chosen independently of the algorithm that determines the set; if the two do not align, the explanation will be non-causal.

Such explanations are different than causal explanations: they do not try to explain the reason why the result was obtained, and may have different utility <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib64" title="">64</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">For example, if SPECTER recommends a document as similar, the real cause involves its internal operation; a causal explanation may be useful for an AI scientist tuning the method. For a user, a post hoc explanation that highlights a few salient words in the document may help indicate what features of that document might be relevant in quickly determining what it is about, why it is unique, or how it might have been found by a traditional search (which could help in finding more documents). Similarly, a post hoc explanation of showing other documents that are similar might give a sense of what the document is about, why it might be interesting, and potential directions to continue exploration. These examples of feature-based (terms) and
<span class="ltx_ERROR undefined" id="S2.SS2.p2.1.1">\replaced</span>exemplar-basedexemplar or item-based (documents) explanations may not indicate which of SPECTER’s neurons are responsible, or even what words actually influenced those neurons. In fact, the explanations could be generated even if a different algorithm was used to make the recommendation.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<span class="ltx_ERROR undefined" id="S2.SS2.p3.1">\added</span>
<p class="ltx_p" id="S2.SS2.p3.2">Our approach applies salience functions to select sets, rather than the entire (large) corpus. This reduces the need for approaches that can scale to provide meaning at scale, and instead focus on methods that provide local explanations (see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S1.SS2" title="1.2 Explainations and Interpretability ‣ 1 Related Work ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 1.2</span></a>).</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p4.1.1">Design Choice</span>: A key idea in our approach is that salience functions provide a flexible approach to creating post hoc explanations as they can be coupled with views that operate at the various scales of inquiry.
<span class="ltx_ERROR undefined" id="S2.SS2.p4.1.2">\added</span>Salience functions are used in different views to highlight terms and documents creating explanations.
We use term salience functions to create feature-based explanations, and item salience functions to create exemplar-based explanations.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Term Salience</h4>
<div class="ltx_para" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.4">Term salience models are used to identify and rank which words are most likely to contribute to the similarity between documents or the their inclusion in a set.
Term salience is a variant of the keyword extraction problem. Indeed, one form of salience metric is <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS1.p1.4.1">descriptive</em>: scoring words based on how well they describe the set of documents. A number of established options exist <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib65" title="">65</a>]</cite>, and several are available in our system. However, for our uses, we generally prefer <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS1.p1.4.2">constrastive</em> metrics that find words that differentiate the set from the rest of the corpus. For this, we use the common G2 metric <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib66" title="">66</a>]</cite>. The G2 metric has the disadvantages that it is symmetric (it identifies words both under- and over-represented in the document set), and is purely contrastive (it doesn’t consider what describes the set). To address these issues, we have created two other metrics.
The <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS1.p1.4.3">uniqueness</em> metric is a measure of contrast that measures how unqiue a term is to a particular region, computed as <math alttext="{df}_{r}/{df}_{g}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.1.m1.1"><semantics id="S2.SS2.SSS1.p1.1.m1.1a"><mrow id="S2.SS2.SSS1.p1.1.m1.1.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.cmml"><mrow id="S2.SS2.SSS1.p1.1.m1.1.1.2" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.cmml"><mrow id="S2.SS2.SSS1.p1.1.m1.1.1.2.2" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.cmml"><mi id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.2" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.2.cmml">d</mi><mo id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.1.cmml">⁢</mo><msub id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.cmml"><mi id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.2" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.2.cmml">f</mi><mi id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.3" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.3.cmml">r</mi></msub></mrow><mo id="S2.SS2.SSS1.p1.1.m1.1.1.2.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.1.cmml">/</mo><mi id="S2.SS2.SSS1.p1.1.m1.1.1.2.3" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.3.cmml">d</mi></mrow><mo id="S2.SS2.SSS1.p1.1.m1.1.1.1" xref="S2.SS2.SSS1.p1.1.m1.1.1.1.cmml">⁢</mo><msub id="S2.SS2.SSS1.p1.1.m1.1.1.3" xref="S2.SS2.SSS1.p1.1.m1.1.1.3.cmml"><mi id="S2.SS2.SSS1.p1.1.m1.1.1.3.2" xref="S2.SS2.SSS1.p1.1.m1.1.1.3.2.cmml">f</mi><mi id="S2.SS2.SSS1.p1.1.m1.1.1.3.3" xref="S2.SS2.SSS1.p1.1.m1.1.1.3.3.cmml">g</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.1.m1.1b"><apply id="S2.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1"><times id="S2.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.1"></times><apply id="S2.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2"><divide id="S2.SS2.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.1"></divide><apply id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2"><times id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.1"></times><ci id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.2.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.2">𝑑</ci><apply id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3">subscript</csymbol><ci id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.2.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.2">𝑓</ci><ci id="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.3.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.2.3.3">𝑟</ci></apply></apply><ci id="S2.SS2.SSS1.p1.1.m1.1.1.2.3.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.2.3">𝑑</ci></apply><apply id="S2.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.3.2">𝑓</ci><ci id="S2.SS2.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S2.SS2.SSS1.p1.1.m1.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.1.m1.1c">{df}_{r}/{df}_{g}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.1.m1.1d">italic_d italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT / italic_d italic_f start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="df" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.2.m2.1"><semantics id="S2.SS2.SSS1.p1.2.m2.1a"><mrow id="S2.SS2.SSS1.p1.2.m2.1.1" xref="S2.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S2.SS2.SSS1.p1.2.m2.1.1.2" xref="S2.SS2.SSS1.p1.2.m2.1.1.2.cmml">d</mi><mo id="S2.SS2.SSS1.p1.2.m2.1.1.1" xref="S2.SS2.SSS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S2.SS2.SSS1.p1.2.m2.1.1.3" xref="S2.SS2.SSS1.p1.2.m2.1.1.3.cmml">f</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.2.m2.1b"><apply id="S2.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1"><times id="S2.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1.1"></times><ci id="S2.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1.2">𝑑</ci><ci id="S2.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS1.p1.2.m2.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.2.m2.1c">df</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.2.m2.1d">italic_d italic_f</annotation></semantics></math> is the document frequency of the term for the region (<math alttext="df_{r}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.3.m3.1"><semantics id="S2.SS2.SSS1.p1.3.m3.1a"><mrow id="S2.SS2.SSS1.p1.3.m3.1.1" xref="S2.SS2.SSS1.p1.3.m3.1.1.cmml"><mi id="S2.SS2.SSS1.p1.3.m3.1.1.2" xref="S2.SS2.SSS1.p1.3.m3.1.1.2.cmml">d</mi><mo id="S2.SS2.SSS1.p1.3.m3.1.1.1" xref="S2.SS2.SSS1.p1.3.m3.1.1.1.cmml">⁢</mo><msub id="S2.SS2.SSS1.p1.3.m3.1.1.3" xref="S2.SS2.SSS1.p1.3.m3.1.1.3.cmml"><mi id="S2.SS2.SSS1.p1.3.m3.1.1.3.2" xref="S2.SS2.SSS1.p1.3.m3.1.1.3.2.cmml">f</mi><mi id="S2.SS2.SSS1.p1.3.m3.1.1.3.3" xref="S2.SS2.SSS1.p1.3.m3.1.1.3.3.cmml">r</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.3.m3.1b"><apply id="S2.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1"><times id="S2.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.1"></times><ci id="S2.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.2">𝑑</ci><apply id="S2.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.3.m3.1.1.3.1.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS1.p1.3.m3.1.1.3.2.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.3.2">𝑓</ci><ci id="S2.SS2.SSS1.p1.3.m3.1.1.3.3.cmml" xref="S2.SS2.SSS1.p1.3.m3.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.3.m3.1c">df_{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.3.m3.1d">italic_d italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>) or the corpus (<math alttext="df_{g}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.4.m4.1"><semantics id="S2.SS2.SSS1.p1.4.m4.1a"><mrow id="S2.SS2.SSS1.p1.4.m4.1.1" xref="S2.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="S2.SS2.SSS1.p1.4.m4.1.1.2" xref="S2.SS2.SSS1.p1.4.m4.1.1.2.cmml">d</mi><mo id="S2.SS2.SSS1.p1.4.m4.1.1.1" xref="S2.SS2.SSS1.p1.4.m4.1.1.1.cmml">⁢</mo><msub id="S2.SS2.SSS1.p1.4.m4.1.1.3" xref="S2.SS2.SSS1.p1.4.m4.1.1.3.cmml"><mi id="S2.SS2.SSS1.p1.4.m4.1.1.3.2" xref="S2.SS2.SSS1.p1.4.m4.1.1.3.2.cmml">f</mi><mi id="S2.SS2.SSS1.p1.4.m4.1.1.3.3" xref="S2.SS2.SSS1.p1.4.m4.1.1.3.3.cmml">g</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.4.m4.1b"><apply id="S2.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1"><times id="S2.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.1"></times><ci id="S2.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.2">𝑑</ci><apply id="S2.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.4.m4.1.1.3.1.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS1.p1.4.m4.1.1.3.2.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.3.2">𝑓</ci><ci id="S2.SS2.SSS1.p1.4.m4.1.1.3.3.cmml" xref="S2.SS2.SSS1.p1.4.m4.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.4.m4.1c">df_{g}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.4.m4.1d">italic_d italic_f start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math>).
The <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS1.p1.4.4">differential</em> metric that tries to balance description and contrast:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{m}_{d}=\frac{{df}_{r}}{n_{r}}-\kappa\frac{({df}_{g}-{df}_{r})}{n_{g}-n_{r}}," class="ltx_Math" display="block" id="S2.E1.m1.2"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml"><msub id="S2.E1.m1.2.2.1.1.2" xref="S2.E1.m1.2.2.1.1.2.cmml"><mi id="S2.E1.m1.2.2.1.1.2.2" xref="S2.E1.m1.2.2.1.1.2.2.cmml">m</mi><mi id="S2.E1.m1.2.2.1.1.2.3" xref="S2.E1.m1.2.2.1.1.2.3.cmml">d</mi></msub><mo id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.2.2.1.1.3" xref="S2.E1.m1.2.2.1.1.3.cmml"><mfrac id="S2.E1.m1.2.2.1.1.3.2" xref="S2.E1.m1.2.2.1.1.3.2.cmml"><mrow id="S2.E1.m1.2.2.1.1.3.2.2" xref="S2.E1.m1.2.2.1.1.3.2.2.cmml"><mi id="S2.E1.m1.2.2.1.1.3.2.2.2" xref="S2.E1.m1.2.2.1.1.3.2.2.2.cmml">d</mi><mo id="S2.E1.m1.2.2.1.1.3.2.2.1" xref="S2.E1.m1.2.2.1.1.3.2.2.1.cmml">⁢</mo><msub id="S2.E1.m1.2.2.1.1.3.2.2.3" xref="S2.E1.m1.2.2.1.1.3.2.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.3.2.2.3.2" xref="S2.E1.m1.2.2.1.1.3.2.2.3.2.cmml">f</mi><mi id="S2.E1.m1.2.2.1.1.3.2.2.3.3" xref="S2.E1.m1.2.2.1.1.3.2.2.3.3.cmml">r</mi></msub></mrow><msub id="S2.E1.m1.2.2.1.1.3.2.3" xref="S2.E1.m1.2.2.1.1.3.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.3.2.3.2" xref="S2.E1.m1.2.2.1.1.3.2.3.2.cmml">n</mi><mi id="S2.E1.m1.2.2.1.1.3.2.3.3" xref="S2.E1.m1.2.2.1.1.3.2.3.3.cmml">r</mi></msub></mfrac><mo id="S2.E1.m1.2.2.1.1.3.1" xref="S2.E1.m1.2.2.1.1.3.1.cmml">−</mo><mrow id="S2.E1.m1.2.2.1.1.3.3" xref="S2.E1.m1.2.2.1.1.3.3.cmml"><mi id="S2.E1.m1.2.2.1.1.3.3.2" xref="S2.E1.m1.2.2.1.1.3.3.2.cmml">κ</mi><mo id="S2.E1.m1.2.2.1.1.3.3.1" xref="S2.E1.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mfrac id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.2.2.cmml">d</mi><mo id="S2.E1.m1.1.1.1.1.1.2.1" xref="S2.E1.m1.1.1.1.1.1.2.1.cmml">⁢</mo><msub id="S2.E1.m1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.2.3.2" xref="S2.E1.m1.1.1.1.1.1.2.3.2.cmml">f</mi><mi id="S2.E1.m1.1.1.1.1.1.2.3.3" xref="S2.E1.m1.1.1.1.1.1.2.3.3.cmml">g</mi></msub></mrow><mo id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.3.2.cmml">d</mi><mo id="S2.E1.m1.1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.1.3.1.cmml">⁢</mo><msub id="S2.E1.m1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.1.3.3.2.cmml">f</mi><mi id="S2.E1.m1.1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.1.3.3.3.cmml">r</mi></msub></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><msub id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml"><mi id="S2.E1.m1.1.1.3.2.2" xref="S2.E1.m1.1.1.3.2.2.cmml">n</mi><mi id="S2.E1.m1.1.1.3.2.3" xref="S2.E1.m1.1.1.3.2.3.cmml">g</mi></msub><mo id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml">−</mo><msub id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.3.3.2" xref="S2.E1.m1.1.1.3.3.2.cmml">n</mi><mi id="S2.E1.m1.1.1.3.3.3" xref="S2.E1.m1.1.1.3.3.3.cmml">r</mi></msub></mrow></mfrac></mrow></mrow></mrow><mo id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1"><eq id="S2.E1.m1.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1"></eq><apply id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.2">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.2.2">𝑚</ci><ci id="S2.E1.m1.2.2.1.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.2.3">𝑑</ci></apply><apply id="S2.E1.m1.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.3"><minus id="S2.E1.m1.2.2.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.1"></minus><apply id="S2.E1.m1.2.2.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2"><divide id="S2.E1.m1.2.2.1.1.3.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2"></divide><apply id="S2.E1.m1.2.2.1.1.3.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2"><times id="S2.E1.m1.2.2.1.1.3.2.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.1"></times><ci id="S2.E1.m1.2.2.1.1.3.2.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2">𝑑</ci><apply id="S2.E1.m1.2.2.1.1.3.2.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.3.2.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3.2">𝑓</ci><ci id="S2.E1.m1.2.2.1.1.3.2.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3.3">𝑟</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.3.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.3.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3.2">𝑛</ci><ci id="S2.E1.m1.2.2.1.1.3.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3.3">𝑟</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.3.3"><times id="S2.E1.m1.2.2.1.1.3.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.3.1"></times><ci id="S2.E1.m1.2.2.1.1.3.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.3.2">𝜅</ci><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><divide id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1"></divide><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"></minus><apply id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2"><times id="S2.E1.m1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.2.1"></times><ci id="S2.E1.m1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2.2">𝑑</ci><apply id="S2.E1.m1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2.3.2">𝑓</ci><ci id="S2.E1.m1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.2.3.3">𝑔</ci></apply></apply><apply id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3"><times id="S2.E1.m1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.3.2">𝑑</ci><apply id="S2.E1.m1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.3.3.2">𝑓</ci><ci id="S2.E1.m1.1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3.3.3">𝑟</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><minus id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"></minus><apply id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.3.2.2">𝑛</ci><ci id="S2.E1.m1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.3.2.3">𝑔</ci></apply><apply id="S2.E1.m1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.3.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.3.3.2">𝑛</ci><ci id="S2.E1.m1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.3.3.3">𝑟</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">{m}_{d}=\frac{{df}_{r}}{n_{r}}-\kappa\frac{({df}_{g}-{df}_{r})}{n_{g}-n_{r}},</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.2d">italic_m start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = divide start_ARG italic_d italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_ARG start_ARG italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_ARG - italic_κ divide start_ARG ( italic_d italic_f start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT - italic_d italic_f start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) end_ARG start_ARG italic_n start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT - italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.SSS1.p1.8">where <math alttext="n" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.5.m1.1"><semantics id="S2.SS2.SSS1.p1.5.m1.1a"><mi id="S2.SS2.SSS1.p1.5.m1.1.1" xref="S2.SS2.SSS1.p1.5.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.5.m1.1b"><ci id="S2.SS2.SSS1.p1.5.m1.1.1.cmml" xref="S2.SS2.SSS1.p1.5.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.5.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.5.m1.1d">italic_n</annotation></semantics></math> is the number documents in the region (<math alttext="n_{r}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.6.m2.1"><semantics id="S2.SS2.SSS1.p1.6.m2.1a"><msub id="S2.SS2.SSS1.p1.6.m2.1.1" xref="S2.SS2.SSS1.p1.6.m2.1.1.cmml"><mi id="S2.SS2.SSS1.p1.6.m2.1.1.2" xref="S2.SS2.SSS1.p1.6.m2.1.1.2.cmml">n</mi><mi id="S2.SS2.SSS1.p1.6.m2.1.1.3" xref="S2.SS2.SSS1.p1.6.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.6.m2.1b"><apply id="S2.SS2.SSS1.p1.6.m2.1.1.cmml" xref="S2.SS2.SSS1.p1.6.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.6.m2.1.1.1.cmml" xref="S2.SS2.SSS1.p1.6.m2.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p1.6.m2.1.1.2.cmml" xref="S2.SS2.SSS1.p1.6.m2.1.1.2">𝑛</ci><ci id="S2.SS2.SSS1.p1.6.m2.1.1.3.cmml" xref="S2.SS2.SSS1.p1.6.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.6.m2.1c">n_{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.6.m2.1d">italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>) and corpus (<math alttext="n_{g}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.7.m3.1"><semantics id="S2.SS2.SSS1.p1.7.m3.1a"><msub id="S2.SS2.SSS1.p1.7.m3.1.1" xref="S2.SS2.SSS1.p1.7.m3.1.1.cmml"><mi id="S2.SS2.SSS1.p1.7.m3.1.1.2" xref="S2.SS2.SSS1.p1.7.m3.1.1.2.cmml">n</mi><mi id="S2.SS2.SSS1.p1.7.m3.1.1.3" xref="S2.SS2.SSS1.p1.7.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.7.m3.1b"><apply id="S2.SS2.SSS1.p1.7.m3.1.1.cmml" xref="S2.SS2.SSS1.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p1.7.m3.1.1.1.cmml" xref="S2.SS2.SSS1.p1.7.m3.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p1.7.m3.1.1.2.cmml" xref="S2.SS2.SSS1.p1.7.m3.1.1.2">𝑛</ci><ci id="S2.SS2.SSS1.p1.7.m3.1.1.3.cmml" xref="S2.SS2.SSS1.p1.7.m3.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.7.m3.1c">n_{g}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.7.m3.1d">italic_n start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math>). <math alttext="\kappa" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p1.8.m4.1"><semantics id="S2.SS2.SSS1.p1.8.m4.1a"><mi id="S2.SS2.SSS1.p1.8.m4.1.1" xref="S2.SS2.SSS1.p1.8.m4.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p1.8.m4.1b"><ci id="S2.SS2.SSS1.p1.8.m4.1.1.cmml" xref="S2.SS2.SSS1.p1.8.m4.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p1.8.m4.1c">\kappa</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p1.8.m4.1d">italic_κ</annotation></semantics></math> is a constant used to balance between description and contrast and is usually set to 1.
The three metrics provide options that emphasize different words. We allow the user to switch between them.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS1.p2">
<span class="ltx_ERROR undefined" id="S2.SS2.SSS1.p2.1">\replaced</span>
<p class="ltx_p" id="S2.SS2.SSS1.p2.2">For pairs of documents, explanations show the terms that make the documents similar.Explaining the similarity between a pair of documents is a special case of term salience. Often, we would like to identify what makes the pair similar.
Salience is the amount a word contributes to the similarity metric.
For complex metrics, such as SPECTER, feature salience approaches such as perturbation or differentiation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib67" title="">67</a>]</cite> could be used, in theory. In practice, we have found such approaches to be ineffective (see <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib68" title="">68</a>]</cite> for potential reasons).
Instead, we define a term-based salience function for document pairs based on TF-IDF: common words have non-zero salience proportional to their term frequency and inverse document frequency. This salience correlates with causal explanations of term-based metrics. In practice, it often provides useful term selection even for SPECTER. Empirically, we see similar numbers of words highlighted in SPECTER and TF-IDF matches, with the number of matches decreasing as the similarity decreases (see the supplement for statistical details).</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS1.p3">
<p class="ltx_p" id="S2.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.SSS1.p3.1.1">Design Choice</span>: AbstractsViewer uses the term salience metrics to enhance its various views (described below).
Term salience is used to identify potentially interesting words in a single document, to highlight the similarity between a pair of documents, and to identify relevant words for defining neighborhoods and regions. Salience functions highlight terms in document views, selecting terms for hovering in maps, and emphasizing terms in matrix views.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Item Salience</h4>
<div class="ltx_para" id="S2.SS2.SSS2.p1">
<p class="ltx_p" id="S2.SS2.SSS2.p1.1">Item salience models determine how relevant an item might be to the situation. The models are used to order a list of documents, enabling the user to skim more quickly. Item salience models are used to sort the search results and lists of documents in regions.
Our system provides a number of item salience functions. The <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p1.1.1">search relevance</em> sorting is provided by the underlying text search engine, and is only available for the text search list. The search list may also be sorted by similarity to a user selected document.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p2">
<p class="ltx_p" id="S2.SS2.SSS2.p2.1">Item salience functions are used to select exemplars from a set of documents. <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p2.1.1">Similarity to the selected document</em> can be used to organize a set when there is a selection - whether or not that selection is in the set. Other salience functions do not require a selection.
The <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p2.1.2">neighbor list</em> metric approximates centrality to the set by counting the number of members of the set in each document’s near neighbor list. The <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS2.p2.1.3">region words occurrence</em> metric orders the documents by the number of words determined to be salient in the region as a way to find the documents that best fit the description of the region provided by the salient words.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS2.p3">
<p class="ltx_p" id="S2.SS2.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.SSS2.p3.1.1">Design Choice</span>: AbstractsViewer uses document salience functions to enhance various views so that a short list of documents can be descriptive of a larger set <span class="ltx_ERROR undefined" id="S2.SS2.SSS2.p3.1.2">\added</span>and such that lists can support workflows such as counterfactuals (e.g., looking for items similar to something not in the list, or similarities between items not considered similar).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Views</h3>
<div class="ltx_para" id="S2.SS3.p1">
<span class="ltx_ERROR undefined" id="S2.SS3.p1.1">\replaced</span>
<p class="ltx_p" id="S2.SS3.p1.2">AbstractsViewer provides a standard, multi-view, TCE interface. We have purposefully chosen familiar designs to ease learning the system. However, we enhance standard designs using salience functions for explanation, and some specific design decisions to support comparison. These functions enhance the views and help build connections between them.
See <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F4" title="Figure 4 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a> for a catalog of views in our system.


AbstractsViewer provides a number of views with multi-view coordination. We intentionally chose familiar visual representations, but enhance them using salience functions for explanation, and some specific design decisions to support comparison.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<span class="ltx_ERROR undefined" id="S2.SS3.p2.1">\added</span>
<p class="ltx_p" id="S2.SS3.p2.2">AbstractsViewer provides views that operate at different scales.
Corpus exploration involves a number of scales<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>]</cite>.
We identify four distinct levels. The largest <em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.2.1">corpus</em> scale refers to either the entire collection, or a subset that does not have a known coherence. The <em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.2.2">region</em> scale refers to a subset that has a coherent thematic relationship and/or is a determined subset of interest. We use the term region for this scale because in our system, these subsets are represented as spatial regions in the 2D embedding of the corpus, although, in general this scale could extend to identified clusters or topics. The <em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.2.3">neighborhood</em> scale refers to a small region centered around a particular document containing its nearest (most similar) neighbors. A document can have many different kinds of similarities to other documents, therefore its neighborhood (the k-nearest neighbors in high dimensions) can be a diverse set that show multiple facets. When placed in the embedding, a document must have a single position - ideally positioning it with documents that share a common focus. The <em class="ltx_emph ltx_font_italic" id="S2.SS3.p2.2.4">document</em> scale represents the smallest scale of specific, individual documents.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p3.1.1">Design Choice</span>:
<span class="ltx_ERROR undefined" id="S2.SS3.p3.1.2">\replaced</span>
AbstractsViewer provides views for each of these scales.


AbstractsViewer provdes a set of views at different scales to support the scales of inquiry we observe in exploration: individual document, local neighborhood (near neighbors of a specific document), region (related group), and the whole corpus.

Having views for different scales allows for focus+context<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib69" title="">69</a>]</cite> workflows and permits the choice of designs specialized for each scale. High-quality multiscale views have been demonstrated for text exploration (e.g., the efficient scatterplot scaling of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite> or multiscale text displays of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib71" title="">71</a>]</cite>) and would complement the simple views in our prototype.</p>
</div>
<div class="ltx_para" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p4.1.1">Design Choice</span>: At each scale, AbstractsViewer provides both a spatial view and a structured view. Brehmer and Munzner<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib19" title="">19</a>]</cite> note that structured (list) views are preferable for methodical scanning, while others have noted that spatial views can support pattern and group finding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite> or can provide context for items and terms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>]</cite>. To support the widest range of tasks, we provide both types of views at each scale. <span class="ltx_ERROR undefined" id="S2.SS3.p4.1.2">\added</span><a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F4" title="Figure 4 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a> organizes the views by scale.
Having many views has costs: users must learn about views and select between them, and screen space is required to show them.</p>
</div>
<div class="ltx_para" id="S2.SS3.p5">
<span class="ltx_ERROR undefined" id="S2.SS3.p5.1">\deleted</span>
<p class="ltx_p" id="S2.SS3.p5.2">See the supplement for a complete list and details of view types.</p>
</div>
<div class="ltx_para" id="S2.SS3.p6">
<p class="ltx_p" id="S2.SS3.p6.1">At the corpus-level scale, The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p6.1.1">Search Tools Panel</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>A) allows the user to perform a search, either using terms for a full-text search, or by providing an abstract that is used for similarity search. The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p6.1.2">Search List</span> provides a corpus-scale structured view of documents. It can be filtered and sorted by metadata, search results and relevance, or distance to the selected document. The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p6.1.3">Corpus Map</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>B) provides a spatial overview of the entire corpus.
The map is presented as a scatterplot, using a binned heatmap <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib72" title="">72</a>]</cite> to provide scalability.
To provide details (i.e., Zoom), the user can select a region by clicking a heatmap cell or sweep selecting a rectangle. The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p6.1.4">Corpus Map</span> combined with the <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p6.1.5">Region Scatter Plot View</span> provide a focus+context view of the corpus. The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p6.1.6">Corpus Map</span> shows the search results, selected items, and neighborhoods as scatterplot points overlaid on top of the heatmap. The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p6.1.7">Corpus Map</span> also indicates the selected region with a yellow border. Hovering over a grid cell shows information about the cell, including the most salient terms and the number of documents in the cell.</p>
</div>
<div class="ltx_para" id="S2.SS3.p7">
<p class="ltx_p" id="S2.SS3.p7.1">Three views provide information about regions.
The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p7.1.1">Region Scatter Plot View</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>C) provides a spatial view of the region as a Zoomed in view of the selected region of the <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p7.1.2">Corpus Map</span>. In the future, a continuous scaling design, as used in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite> may provide better scalability. The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p7.1.3">Region Matrix View</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>D) provides details about the selected region as a matrix of salient terms and documents. It effectively provides a term-based description of the region. The matrix can be reordered by choosing term- and <span class="ltx_ERROR undefined" id="S2.SS3.p7.1.4">\replaced</span>document-item- salience functions. The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p7.1.5">Region List</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>E) provides an <span class="ltx_ERROR undefined" id="S2.SS3.p7.1.6">\replaced</span>exemplar-baseditem-based description of the region and allows for systematic exploration. The list can be reordered by choosing an <span class="ltx_ERROR undefined" id="S2.SS3.p7.1.7">\replaced</span>documentitem salience function.
<span class="ltx_ERROR undefined" id="S2.SS3.p7.1.8">\added</span>Selectable salience functions enhance standard re-orderable lists and matrices.</p>
</div>
<div class="ltx_para" id="S2.SS3.p8">
<p class="ltx_p" id="S2.SS3.p8.2">Neighborhood views show information about the neighborhoods around the selected document (or documents if dual selections are in use). The neighborhood is defined as the <math alttext="n" class="ltx_Math" display="inline" id="S2.SS3.p8.1.m1.1"><semantics id="S2.SS3.p8.1.m1.1a"><mi id="S2.SS3.p8.1.m1.1.1" xref="S2.SS3.p8.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p8.1.m1.1b"><ci id="S2.SS3.p8.1.m1.1.1.cmml" xref="S2.SS3.p8.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p8.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p8.1.m1.1d">italic_n</annotation></semantics></math> closest neighbors in the selected vector space. While <math alttext="n=10" class="ltx_Math" display="inline" id="S2.SS3.p8.2.m2.1"><semantics id="S2.SS3.p8.2.m2.1a"><mrow id="S2.SS3.p8.2.m2.1.1" xref="S2.SS3.p8.2.m2.1.1.cmml"><mi id="S2.SS3.p8.2.m2.1.1.2" xref="S2.SS3.p8.2.m2.1.1.2.cmml">n</mi><mo id="S2.SS3.p8.2.m2.1.1.1" xref="S2.SS3.p8.2.m2.1.1.1.cmml">=</mo><mn id="S2.SS3.p8.2.m2.1.1.3" xref="S2.SS3.p8.2.m2.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p8.2.m2.1b"><apply id="S2.SS3.p8.2.m2.1.1.cmml" xref="S2.SS3.p8.2.m2.1.1"><eq id="S2.SS3.p8.2.m2.1.1.1.cmml" xref="S2.SS3.p8.2.m2.1.1.1"></eq><ci id="S2.SS3.p8.2.m2.1.1.2.cmml" xref="S2.SS3.p8.2.m2.1.1.2">𝑛</ci><cn id="S2.SS3.p8.2.m2.1.1.3.cmml" type="integer" xref="S2.SS3.p8.2.m2.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p8.2.m2.1c">n=10</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p8.2.m2.1d">italic_n = 10</annotation></semantics></math> by default, it can be adjusted by the user.
The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p8.2.1">Neighbor List View</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>H) shows the neighbors in rank order. The view shows a list for the selected vector space, but also a list for an alternate vector space. The coloring enables identifying common elements between lists (both for alternate spaces and between dual selected documents).
The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p8.2.2">Neighborhood Matrix View</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>F, provides a matrix view indicating the salient words within the neighborhood.
The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p8.2.3">Radial Neighborhood View</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>I) provides a spatial representation of the neighborhood using an approximate SolarView <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib73" title="">73</a>]</cite> radial embedding view of the neighborhood. This view preserves distance to the selected element, and shows grouping structure of the neighbors.</p>
</div>
<div class="ltx_para" id="S2.SS3.p9">
<p class="ltx_p" id="S2.SS3.p9.1">The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p9.1.1">Document View</span> (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S0.F2" title="Figure 2 ‣ 0.1 Overview and Example ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>G) shows details of the selected documents.
It uses word highlighting to indicate salient words. Search terms are highlighted in green.
Shades of yellow are used to indicate word salience. If a single document is selected, the G2 metric is used to differentiate the document from the corpus. If two documents are selected, the TF-IDF term salience (<a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2.SS2.SSS1" title="2.2.1 Term Salience ‣ 2.2 Salience Functions ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2.2.1</span></a>) is used to show the similarities.
<span class="ltx_ERROR undefined" id="S2.SS3.p9.1.2">\added</span>Optionally, a second color (cyan) is used to highlight words salient in the document’s region, providing an explanation of why the document appears where it does in the map. Word highlighting allows for estimation of quantity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib74" title="">74</a>]</cite>, although we do not correct for word length bias <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib75" title="">75</a>]</cite>.
Double-clicking a highlighted word causes it to change color across the interface, assisting in identifying matches and finding the word in other views.
The <span class="ltx_text ltx_font_sansserif" id="S2.SS3.p9.1.3">Document View</span> allows for highlighting to be disabled if the user finds it distracting (i.e., for close reading), and provides a toggle that adds the document to the favorites list.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Design for Comparison and Linking</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">AbstractsViewer uses selection and highlighting to build links across views. It has a notion of a selected document and a selected region (which may not contain the document). Regions may be specified by either sweep selecting in the map view, or clicking on a heatmap grid cell. The selected document may be specified throughout the interface: picking from a list or clicking an item in a scatterplot or matrix.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">To better support comparison, AbstractsViewer has a notion of dual selection: the user can select two documents.
Dual selections are shown in a similar manner. Both define neighborhoods, and both neighborhoods are shown across the interface.
The second selection allows for comparison in several ways: the two documents appear side-by-side in the <span class="ltx_text ltx_font_sansserif" id="S2.SS4.p2.1.1">Document View</span>, with similarities highlighted; the neighborhood lists can be compared, aided by coloring;
the neighbors are shown in different colors in the various spatial views, which can help contrast the contents. Additionally, the <span class="ltx_text ltx_font_sansserif" id="S2.SS4.p2.1.2">Neighborhood Matrix View</span> shows both neighborhoods for comparison.</p>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">AbstractsViewer uses a consistent coloring scheme for selections. The selected items are shown in yellow, neighbors of the first selection are shown in orange, and neighbors of the second selection are shown in pink. Green is used to indicate search results. These colors are used in the scatterplots for points (the disc is split with each side corresponding to one selection).
<span class="ltx_ERROR undefined" id="S2.SS4.p3.1.1">\added</span>The <span class="ltx_text ltx_font_sansserif" id="S2.SS4.p3.1.2">Corpus Map</span> can show the previous search result in an alternate color to help comparison.
The colors are used in list views (including the document titles in matrices), except that the search list does not show green (since all items would have this property). They are also used in the matrix views to color document titles and the radial views to color the outline of points.</p>
</div>
<div class="ltx_para" id="S2.SS4.p4">
<p class="ltx_p" id="S2.SS4.p4.1">AbstractsViewer also provides workflow support including a history to allow returning to a previous point in the exploration, a shopping-cart style favorites list to record discovered documents, linking to digital libraries, and exporting of the discovered lists.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Implementation and Data</h2>
<div class="ltx_para" id="S3.p1">
<span class="ltx_ERROR undefined" id="S3.p1.1">\replaced</span>
<p class="ltx_p" id="S3.p1.2">AbstractsViewer is a prototype system designed to embody our approach. It was designed for the exploration of scientific abstract corpora, although we also apply it to collections of newspaper articles. It intentionally focuses on content-based exploration, omitting features such as meta-data analysis so we can observe how content-based tools are applied in exploration.


The AbstractsViewer prototype system implements our approach.

The system has four components: a web-based front end that runs in browser, a server-based back end, a tool for preprocessing corpora to be used with the back end, and tools for scraping digital library web pages to construct corpora.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.p2.1.1">Front end:</span> The front end is written in JavaScript using the Vue<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span class="ltx_ERROR undefined" id="footnote3.1">\added</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://vuejs.org/" title="">https://vuejs.org/</a></span></span></span> framework and the D3<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><span class="ltx_ERROR undefined" id="footnote4.1">\added</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://d3js.org/" title="">https://d3js.org/</a></span></span></span> visualization library.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p3">
<p class="ltx_p" id="S3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.p3.1.1">Back end:</span> The back end is written in Python. The back end loads precomputed information about the corpus at start time. It is run with a single specific corpus; to support multiple corpora, we create multiple instances of the back end that appear as different web servers. For the experiments described in this paper, a back end instance for each corpus is deployed as a container on a cluster-based VM that runs on a departmental server. The VM is configured with VMware ESXi to have 4 virtual CPUs and 8GB of RAM and uses Portainer to run multiple containers.
The back end uses the Whoosh <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib76" title="">76</a>]</cite> library for indexing and search. It provides a query language, and handles word variants.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p4">
<p class="ltx_p" id="S3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.p4.1.1">Precomputation:</span> A Python-based application converts corpus data from standard bibliography files into data for the back end. The system precomputes the vectors for the various metrics, the embeddings for the <span class="ltx_text ltx_font_sansserif" id="S3.p4.1.2">Corpus Map</span>, each document’s 100 nearest neighbors, and word stems.
The preprocessor uses standard Python libraries (SciKit-Learn <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib77" title="">77</a>]</cite> and NLTK <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib78" title="">78</a>]</cite>) for text processing, constructing embeddings, and precomputing nearest-neighbor lists.
Text processing is done using the default parameters for NLTK, and includes stemming and stop word removal. These processed texts are used for vectorization and salience analyses.
Vector spaces are computed with standard Python <span class="ltx_ERROR undefined" id="S3.p4.1.3">\replaced</span>librarieslibraies.
<span class="ltx_ERROR undefined" id="S3.p4.1.4">\deleted</span>Details of the various vector space computations and salience metrics are provided in a supplement.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p5">
<p class="ltx_p" id="S3.p5.1"><span class="ltx_text ltx_font_bold" id="S3.p5.1.1">Data Scraping:</span> Like Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite>, we have built Python tools for retrieving bibliographic data from digital libraries. Our tools automate collecting abstracts for conferences and journals, and create visual summaries of corpus statistics so users can check coverage.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p6">
<p class="ltx_p" id="S3.p6.1"><span class="ltx_text ltx_font_bold" id="S3.p6.1.1">Corpora:</span> For our initial usage and testing we have developed several different corpora to use with AbstractsViewer. Our data is based on the abstracts (or leads from Newspaper articles).
The corpora used in our experiments are:</p>
</div>
<div class="ltx_para" id="S3.p7">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><em class="ltx_emph ltx_font_italic" id="S3.I1.i1.p1.1.1">Visualization:</em> A <span class="ltx_ERROR undefined" id="S3.I1.i1.p1.1.2">\replaced</span>corpuscollection of paper abstracts from a variety of visualization venues.
<span class="ltx_ERROR undefined" id="S3.I1.i1.p1.1.3">\deleted</span>The corpus comprises (5237 abstracts and 15600 terms)
</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><em class="ltx_emph ltx_font_italic" id="S3.I1.i2.p1.1.1">Robotics:</em> A <span class="ltx_ERROR undefined" id="S3.I1.i2.p1.1.2">\replaced</span>corpuscollection of abstracts from a variety of papers from robotics and haptics venues. (42114 abstracts with 52640 terms)</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><em class="ltx_emph ltx_font_italic" id="S3.I1.i3.p1.1.1">Recent Robotics:</em> A subset of the Robotics corpus comprising papers published after 2016.
(24785 abstracts and 39034 <span class="ltx_ERROR undefined" id="S3.I1.i3.p1.1.2">\added</span>terms)</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><em class="ltx_emph ltx_font_italic" id="S3.I1.i4.p1.1.1">NY Times 60K:</em> A <span class="ltx_ERROR undefined" id="S3.I1.i4.p1.1.2">\replaced</span>corpuscollection of newspaper article leads as described below.
(60000 articles and 109580 terms)</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.p8">
<p class="ltx_p" id="S3.p8.1">To provide testing corpora of different sizes with similar content, we created corpora by downsampling the <span class="ltx_text ltx_font_italic" id="S3.p8.1.1">The New York Times Annotated Corpus</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib79" title="">79</a>]</cite>. We use the “lead” from each article (generally the first paragraph). Our “60K” data set consists of 250 articles randomly selected from each month from 1987 to 2006. Our prototype was able to operate on a 120K <span class="ltx_ERROR undefined" id="S3.p8.1.2">\replaced</span>corpuscollection (500 articles per month), but was ineffective <span class="ltx_ERROR undefined" id="S3.p8.1.3">\added</span>(see <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S5" title="5 Discussion and Conclusion ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 5</span></a>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p9">
<p class="ltx_p" id="S3.p9.1"><em class="ltx_emph ltx_font_italic" id="S3.p9.1.1">Performance:</em> Our not-well-optimized prototype provides reasonable performance on the corpora we described. Sweep selection of regions in larger corpora is problematic because it requires computing region term statistics; for fixed (grid cell) regions, salient terms are precomputed (to enable the hover lists over the <span class="ltx_text ltx_font_sansserif" id="S3.p9.1.2">Corpus Map</span>).
On the smaller data sets, performance is much better. Scalability is a limitation of our prototype that we discuss in §<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#S5" title="5 Discussion and Conclusion ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Assessment</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We provide evidence of the utility of <span class="ltx_ERROR undefined" id="S4.p1.1.1">\replaced</span>our explanation and comparison enhancementsour approach through both a set of usage examples, and controlled user studies to see how researchers employ our tools.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>An Example Exploration</h3>
<figure class="ltx_figure" id="S4.F5"><svg class="ltx_picture ltx_centering" height="155.82" id="S4.F5.pic1" overflow="visible" version="1.1" width="598"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,155.82) matrix(1 0 0 -1 0 0) translate(-0.28,0) translate(0,6.55)"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="149" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="598"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="149" id="S4.F5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/5660384/Figures/new/awareness_combined.png" width="598"/></foreignobject></g><path d="M 14.96 3.74" style="fill:none"></path><g fill="#FF0000"><path d="M 23.82 3.74 C 23.82 8.63 19.85 12.6 14.96 12.6 C 10.07 12.6 6.1 8.63 6.1 3.74 C 6.1 -1.15 10.07 -5.12 14.96 -5.12 C 19.85 -5.12 23.82 -1.15 23.82 3.74 Z M 14.96 3.74" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 8.73 -1.94)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.45"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.F5.pic1.2.2.2.1.1" style="font-size:120%;">A</span></foreignobject></g><path d="M 239.42 3.74" style="fill:none"></path><g fill="#FF0000"><path d="M 248.28 3.74 C 248.28 8.63 244.31 12.6 239.42 12.6 C 234.53 12.6 230.56 8.63 230.56 3.74 C 230.56 -1.15 234.53 -5.12 239.42 -5.12 C 244.31 -5.12 248.28 -1.15 248.28 3.74 Z M 239.42 3.74" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 233.54 -1.94)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.76"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.F5.pic1.3.3.3.1.1" style="font-size:120%;">B</span></foreignobject></g><path d="M 478.84 3.74" style="fill:none"></path><g fill="#FF0000"><path d="M 487.7 3.74 C 487.7 8.63 483.74 12.6 478.84 12.6 C 473.95 12.6 469.99 8.63 469.99 3.74 C 469.99 -1.15 473.95 -5.12 478.84 -5.12 C 483.74 -5.12 487.7 -1.15 487.7 3.74 Z M 478.84 3.74" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 472.85 -1.94)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.99"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.F5.pic1.4.4.4.1.1" style="font-size:120%;">C</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.13.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.14.2" style="font-size:90%;">
Exploration for “human awareness of robots” described in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4.SS1" title="4.1 An Example Exploration ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 4.1</span></a>. <span class="ltx_ERROR undefined" id="S4.F5.14.2.1">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.F5.14.2.2">A</span> A keyword search for <span class="ltx_text ltx_font_typewriter" id="S4.F5.14.2.3">awareness</span> yields many hits (green dots in the <span class="ltx_text ltx_font_sansserif" id="S4.F5.14.2.4">Corpus Map</span>). Hovering over regions reveals a region promising region (yellow square). Sorting the <span class="ltx_text ltx_font_sansserif" id="S4.F5.14.2.5">Region List</span> reveals papers in the region that seem promising. We select a paper. <span class="ltx_ERROR undefined" id="S4.F5.14.2.6">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.F5.14.2.7">B</span> <span class="ltx_text ltx_font_sansserif" id="S4.F5.14.2.8">Document View</span> shows that the abstract connects to the region (blue highlights). The <span class="ltx_text ltx_font_sansserif" id="S4.F5.14.2.9">Radial Neighborhood View</span> shows its neighbors form groups. <span class="ltx_ERROR undefined" id="S4.F5.14.2.10">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="S4.F5.14.2.11">C</span> The neighborhood of the second document discovered shows that its neighbors connect to it through a diverse set of topics, other than awareness.
</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<span class="ltx_ERROR undefined" id="S4.SS1.p1.1">\added</span>
<p class="ltx_p" id="S4.SS1.p1.2">This example considers an exploratory search to identify entry points into the literature. It shows how explanation and comparison features help in the common pattern of refining a vague concept to reveal how papers describe a problem (terms), as well as to find some initial papers to learn about what has been done already (and provide for further citation-based gathering).
The topic is enabling human awareness of robots in human-robot collaboration: how can people be informed about what the robots in their environment are doing?
No obvious keyword search was specific enough to expose good entry points - the keywords are common, and generally lead to large numbers of papers about different problems (such as robots being aware of people).</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We begin with a keyword search for the term <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p2.1.1">awareness</span> (stem <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p2.1.2">aware</span>). This returns 500 hits in the Robotics 2016-2022 corpus <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4.F5" title="Figure 5 ‣ 4.1 An Example Exploration ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 5</span></a>(left). We observe many clumps of papers in the map, and begin a process of manually selecting regions to see if they may be of interest. The selected regions contain more than the search hits and provide context to the results. In some cases, the theme of a region is clear from its salient words, but it was unclear why awareness comes up. For example, a region had terms that implied it was about depth estimation; sorting its documents by
search terms revealed that awareness was used to refer to methods (e.g. “geometry-aware”). In other regions, the salient terms were unhelpful, but the exemplary documents revealed a clear theme. For example, a region that had salient words relating to broad concepts <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p2.1.3">simulation</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p2.1.4">trajectory</span> could be seen to be about autonomous vehicles.
<span class="ltx_ERROR undefined" id="S4.SS1.p2.1.5">\replaced</span>Explainations enabled quick dismissal of these regions.
These regions were easy to dismiss as unlikely to be fruitful locations to explore.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<span class="ltx_ERROR undefined" id="S4.SS1.p3.1">\replaced</span>
<p class="ltx_p" id="S4.SS1.p3.2">In another area, explanations help identify a promising region by highlighting salient stems (<span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.2.1">human</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.2.2">collabor</span>).
A region had promising salient stems (<span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.2.3">human</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.2.4">collabor</span>).
<span class="ltx_ERROR undefined" id="S4.SS1.p3.2.5">\replaced</span>The salient (exemplary) papers are
Looking at the salient (exemplary) papers showed papers
related to human performance in human robot collaboration, a promising area. Re-sorting the documents by search terms reveals a hit about “operator awareness” <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4.F5" title="Figure 5 ‣ 4.1 An Example Exploration ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 5</span></a>(left). The paper itself had irrelevant neighbors that shared methodological details <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4.F5" title="Figure 5 ‣ 4.1 An Example Exploration ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 5</span></a>(center), however the phrase seemed appropriate. The exact phrase does not occur elsewhere in the corpus, but searching for <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.2.6">operator</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p3.2.7">awareness</span> revealed a list of promising papers. One of the first hits seemed particularly useful, the title described an empirical study of effects on various aspects of operator performance, including awareness.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<span class="ltx_ERROR undefined" id="S4.SS1.p4.1">\replaced</span>
<p class="ltx_p" id="S4.SS1.p4.2">Using this relevant paper as an anchor for similarity search (i.e., the strategy shared with prior systems) was unfruitful.
The paper was relevant because it showed an empirical approach to understanding human awareness of robots. However, using it as a starting point for similarity search was unfruitful.
<span class="ltx_ERROR undefined" id="S4.SS1.p4.2.1">\replaced</span>Our approach allows us to understand why: using
Using
the <span class="ltx_text ltx_font_sansserif" id="S4.SS1.p4.2.2">Neighborhood Matrix View</span> shows that its neighbors relate to different aspects of the paper <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4.F5" title="Figure 5 ‣ 4.1 An Example Exploration ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 5</span></a>(right).
<span class="ltx_ERROR undefined" id="S4.SS1.p4.2.3">\replaced</span>Our approach also allows us use the paper as an examplar of what we are looking for in a region more likely to contain relevant papers.
However, we could still use this paper as an exemplar of what we are looking for (empirical studies of operator performance).
<span class="ltx_ERROR undefined" id="S4.SS1.p4.2.4">\replaced</span>Similarity to this paper serves as a salience function to identify appropriate papers in the <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p4.2.5">awareness</span> region identified above.
We used similarity to this paper to sort the <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p4.2.6">awareness</span> papers, bringing those interested in human performance to the top of the list.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span class="ltx_ERROR undefined" id="S4.SS2.1.1">\replaced</span>Usage VignettesAdditional Examples</h3>
<div class="ltx_para" id="S4.SS2.p1">
<span class="ltx_ERROR undefined" id="S4.SS2.p1.1">\replaced</span>
<p class="ltx_p" id="S4.SS2.p1.2">We provide a series of short vignettes that exemplify how elements of our approach enable users to achieve their objectives. Each vignette is chosen from a more complete use case to highlight a specific aspect of the system.
These examples are from actual use of our system and the unstructured explorations of study participants.
In some cases, we recreated the examples with different topics to preserve confidentiality of research in progress.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.1">Example: multiple similarity metrics and post hoc explanations:</em>
<span class="ltx_ERROR undefined" id="S4.SS2.p2.1.2">\replaced</span>A roboticist works with a specific algorithm (<em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.3">RelaxedIK</em>) that addresses a standard robotics problem (inverse kinematics, IK). They are
A robotics laboratory makes extensive use of <em class="ltx_emph ltx_font_italic" id="S4.SS2.p2.1.4">RelaxedIK</em>, an algorithm for solving a common class of robotics problems (inverse kinematics, IK). A researcher is 
interested in finding papers that provide competitive methods and potential new applications.
<span class="ltx_ERROR undefined" id="S4.SS2.p2.1.5">\added</span>By using different similarity metrics, they can address both questions, and by using post hoc explanations they can see how the metrics differ.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<span class="ltx_ERROR undefined" id="S4.SS2.p3.1">\replaced</span>
<p class="ltx_p" id="S4.SS2.p3.2">They
In AbstractsViewer, they
search for and select the RelaxedIK paper. The neighbors for the TF-IDF metric form an extremely tight cluster
(all the scatterplot points are so close that they are covered by the star glyph in the map requiring the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p3.2.1">Region Scatter Plot View</span> to see them)
in the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p3.2.2">Corpus Map</span> with one outlier.
The outlier is a paper that uses RelaxedIK.
Examining the neighborhood in the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p3.2.3">Neighborhood Matrix View</span> shows that all papers use similar methods for the same problem (constraint optimization approaches to RelaxedIK).
They examinined the region that the neighbors are contained in using the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p3.2.4">Region Matrix View</span> which showed that the salient terms include the method (<span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.2.5">constraint</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.2.6">optim</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.2.7">solve</span>) but also related problems (<span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.2.8">trajectory</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.2.9">control</span>).
Sorting the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p3.2.10">Region List</span> by centrality reveals that the exemplary papers all address various robotics problems with constrained optimization solvers. Sorting the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p3.2.11">Region Matrix View</span> shows all of these documents (including RelaxedIK) share terms about the method, but not the problems.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">In contrast, the neighborhood formed by the SPECTER metric has documents spread over the map with less obvious connections. The <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p4.1.1">Neighborhood Matrix View</span> with a contrastive metric shows terms <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p4.1.2">geometric</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p4.1.3">feasible</span>, and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p4.1.4">end-effector</span>, properties useful in robotics problems (and provided by RelaxedIK). Hovering over regions for the neighbors reveals these regions are about different applications (such as grasping, tele-operation, and deformable contact), suggesting potential applications that benefit from RelaxedIK’s properties.
<span class="ltx_ERROR undefined" id="S4.SS2.p4.1.5">\added</span>The different metrics provided differently relevant sets of papers, while the explanation visualizations allowed for rapid interpretation of these suggestions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.p5.1.1">Example: term refinement and related problem identification:</em> A robotics researcher was applying a new computer vision device for robotics application. They were trying to identify similar devices, the methods used with them, and their applications. One lead came when a review of a manuscript provided a related paper. Examining the neighbors of the paper in the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p5.1.2">Corpus Map</span> showed them to be in regions defined by common robotics problems (e.g., <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p5.1.3">slam</span>, <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p5.1.4">localization</span>) and methods applied to them (e.g., <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p5.1.5">trifocal</span>). This suggested techniques for comparison and potential applications. The <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p5.1.6">Neighborhood Matrix View</span> revealed <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p5.1.7">laser</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p5.1.8">rangefinder</span> as salient terms: looking in <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p5.1.9">Document View</span> showed that <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p5.1.10">laser rangefinder</span> was historically a commonly used device with similar properties to the sensors being considered.
<span class="ltx_ERROR undefined" id="S4.SS2.p5.1.11">\replaced</span>Explanations allowed similarity search to reveal better terms for subsequent searches and reference.
This led to a new search that revealed relevant related work.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.p6.1.1">Example: connecting terms and regions with explanations:</em>
A visualization researcher sought to use a known relevant paper to find other works related to her topic and to identify the common ways authors referred to the concepts.
To prioritize the most relevant neighbors, she used <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p6.1.2">Neighborhood Matrix View</span> to identify salient words.
She observed the term <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p6.1.3">fact</span> and used the prevalence of this term as a salience function to identify relevant documents that referred to her concept of interest.
Within this <span class="ltx_ERROR undefined" id="S4.SS2.p6.1.4">\replaced</span>document-baseditem-based description of similar documents, she observed that the term <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p6.1.5">insight</span> was often used in a similar manner, providing for both future searches as well as an alternate term for use in describing her work.
<span class="ltx_ERROR undefined" id="S4.SS2.p6.1.6">\added</span>This example shows how explanations allow similarity search to reveal terms.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p7">
<p class="ltx_p" id="S4.SS2.p7.1"><em class="ltx_emph ltx_font_italic" id="S4.SS2.p7.1.1">Example: identifying unexpected related topics with explanations:</em> a researcher sought to identify work related to a paper with a draft abstract about robot camera systems.
The neighbor search using SPECTER provided a set of neighbors that seemed irrelevant. Examining the <span class="ltx_text ltx_font_sansserif" id="S4.SS2.p7.1.2">Neighborhood Matrix View</span> revealed the stem <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p7.1.3">project</span> as salient to the neighborhood.
<span class="ltx_ERROR undefined" id="S4.SS2.p7.1.4">\replaced</span>This term seemed irrelevant, but examination the items using it
Examination of the documents
showed that they involved controlling projectors, which is a related problem to cameras,
making a connection in terms of topic as well as showing a set of papers to be relevant.
<span class="ltx_ERROR undefined" id="S4.SS2.p7.1.5">\added</span>This example shows how explanations turn unexpected terms into concepts for exploration by connecting term- and <span class="ltx_ERROR undefined" id="S4.SS2.p7.1.6">\replaced</span>document-baseditem-based explanations.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>User Studies</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The development of our approach included use by our collaborators in their research interleaved in the development process.
Additionally, we conducted two more formal studies. The first was a pilot study (<math alttext="n=6" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">n</mi><mo id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><eq id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></eq><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">𝑛</ci><cn id="S4.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.p1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">n=6</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_n = 6</annotation></semantics></math>) with an early prototype to understand how untrained participants would appreciate it.
<span class="ltx_ERROR undefined" id="S4.SS3.p1.1.1">\added</span>The pilot study followed a similar protocol to the study described below, however it used an earlier prototype system with fewer structured tasks.
The pilot study showed that researchers could apply our approach. They benefited from the enhancements we provided to the standard tools to better use recommendations and the spatial map to identify relevant documents and terms and to rapidly assess relevance.
However, it also exposed needs that led to the current designed
<span class="ltx_ERROR undefined" id="S4.SS3.p1.1.2">\replaced</span>For example, the need to better organize screen space and to allow for hiding seldom used features to avoid distraction..</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">We conducted a more thorough user study with a later prototype.
We sought to assess how well our target audience can use our approach to accomplish TCE tasks and observe the ways that they explore.
To make these observations, we designed a human subjects study where participants were trained to use the system, completed a set of structured tasks that exposed them to
elements of our approach, and performed free exploration using the system on a topic of their own choice.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Participants needed to be researchers
<span class="ltx_ERROR undefined" id="S4.SS3.p3.1.1">\replaced</span>(our audience)
(i.e., our target audience),
familiar with the literature in either robotics or visualization
<span class="ltx_ERROR undefined" id="S4.SS3.p3.1.2">\replaced</span>(the available corpora)
(as these were the available corpora), 
and have a specific topic to explore (we invited participants to bring an abstract of a work in progress). Each participant worked with either the robotics or visualization corpus based on their background, we developed a set of structured tasks based on each corpus.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.1"><em class="ltx_emph ltx_font_italic" id="S4.SS3.p4.1.1">Participants:</em> Our participant pool was limited because of the research experience requirements and the requirement to be available for an in-person study. Therefore, we recruited participants by convenience sampling from our colleagues working on topics related to visualization, robotics and haptics. These participants may be biased as they are all colleagues, or students of colleagues.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.1">We recruited 12 participants with various levels of research experience, including two professors, one post-doc, six senior graduate students and three new graduate students. Four identified as female and eight identified as male. Participants’ academic departments were Computer Sciences, Mechanical Engineering and Psychology. The participants were not compensated, but were eager to explore the literature related to their work.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Study Procedure:</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">The sessions took place in our laboratory. Participants used a desktop computer with sufficient performance to work well on the corpora and a 27-inch monitor.
Sessions were about 60 minutes. After providing informed consent, we began with a brief walkthrough of different views in the system. During this process, we presented specific examples of each view. Participants were then given a set of structured tasks to complete. In the final phase, we invited participants to explore the corpus freely based on their interests. At the end of the session, participants completed a demographic survey and a system usability scale (SUS) survey <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib80" title="">80</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p2">
<p class="ltx_p" id="S4.SS3.SSS1.p2.1">The sessions were recorded with both audio and screen recording. The experimenter was available during the entire session to answer questions and to encourage the participant to “think aloud” and explain what they were doing.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p3">
<p class="ltx_p" id="S4.SS3.SSS1.p3.1">Participants completed a set of structured tasks where we asked them to answer specific questions using the corpus.
The first type of task required participants to interpret specified regions of the corpus in the map. Participants were allowed to use any views they thought were appropriate. A second type of task involved presenting participants with a paper and its neighbors and asking them to assess their similarity and relevance. The final type of task asked the participant to search for a specified term and describe the distribution of results. <span class="ltx_ERROR undefined" id="S4.SS3.SSS1.p3.1.1">\added</span>Each task type was repeated multiple times.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p4">
<p class="ltx_p" id="S4.SS3.SSS1.p4.1">For the free exploration, participants were asked to bring an abstract of a work in progress to enable interest-driven explorations. Participants were free to discover any unexpected related work, alternative search terms or build a new understanding of the corpus.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Study Findings</h4>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1"><em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p1.1.1">Structured Tasks:</em> All participants were able to complete all <span class="ltx_ERROR undefined" id="S4.SS3.SSS2.p1.1.2">\added</span>of the structured tasks.
<span class="ltx_ERROR undefined" id="S4.SS3.SSS2.p1.1.3">\added</span>The participants made use of all of the key features of our approach in order to complete the structured tasks, showing their utility for (at least) these tasks.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p2">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1">All participants were able to explain the similarities between pairs of documents. 10 participants explicitly said that word highlighting in <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p2.1.1">Document View</span> helped.
Multiple participants agreed that the highlights reduced time to understand the similarity. For example, <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p2.1.2">P5</span> said “Just reading around the highlights helped me get the context quickly, rather than read through the whole thing”.
However, <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p2.1.3">P7</span> acknowledged the highlights “may be distracting in reading, but helps build the connection between 2 papers”. One participant used the highlighting for seeing the structure to speed her reading. We note that the experiment required all participants to use <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p2.1.4">Document View</span>’s TF-IDF explanations to explain both TF-IDF and SPECTER similarities. All participants were able to efficiently assess relevance. Only 5 explicitly mentioned <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p2.1.5">Document View</span> highlighting.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p3">
<p class="ltx_p" id="S4.SS3.SSS2.p3.1">All participants were able to interpret regions using both <span class="ltx_ERROR undefined" id="S4.SS3.SSS2.p3.1.1">\replaced</span>document-item- and term-based descriptions (<span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p3.1.2">Region Matrix View</span> and <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p3.1.3">Region List</span>). All participants made interpretations that required combining different views.
They expressed a range of preferences: 7 participants preferred the simplicity of the <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p3.1.4">Region List</span>, 1 preferred the intuition of the <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p3.1.5">Region Matrix View</span>, and 4 preferred the combination of both.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p4">
<p class="ltx_p" id="S4.SS3.SSS2.p4.1">During these structured explorations of regions, participants used the multiple term salience metrics in the <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p4.1.1">Region Matrix View</span>. Several identified the pattern that the differential metric brings general concepts to the top of list, while contrastive metrics bring out specific techniques.
For example, <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p4.1.2">P5</span> said “I think there is more information about the specific algorithms” (with contrastive).</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p5">
<p class="ltx_p" id="S4.SS3.SSS2.p5.1">Participants were asked to look at both SPECTER and TF-IDF neighbors in the process of exploration.
We did not observe a systematic preference: both were used by all participants. Many participants saw benefits in each, they observed that TF-IDF tended to identify specific details, while SPECTER identified general themes.
Participants found value in seemingly “wrong” recommendations. For example <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p5.1.1">P12</span> said “So this is interesting because this isn’t directly relevant to the paper at all, but it’s like a whole other area of work that I do”.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS2.p6">
<p class="ltx_p" id="S4.SS3.SSS2.p6.1"><em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p6.1.1">Quantitative SUS Results:</em>
Detailed SUS results are in the supplement. The results are generally favorable, but expected patterns emerge: participants found the system useful, but difficult to learn.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS2.p7">
<p class="ltx_p" id="S4.SS3.SSS2.p7.1"><em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS2.p7.1.1">Unstructured Exploration:</em>
All participants were able to discover relevant unexpected documents during the free exploration, which included identifying candidates and assessing their relevance. All participants self-reported that they had found something they were happy with.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p8">
<p class="ltx_p" id="S4.SS3.SSS2.p8.1">In the unstructured explorations, not all participants had the opportunity to use all features (possibly because of limited time).
For example, 8 out of 12 participants identified a neighborhood in the <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p8.1.1">Corpus Map</span> and explored it to identify documents of interest. Some participants only used the <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p8.1.2">Corpus Map</span> to provide context for documents they identified other ways.
Only two chose to investigate outliers in the <span class="ltx_text ltx_font_sansserif" id="S4.SS3.SSS2.p8.1.3">Corpus Map</span>. For some, outliers were not present in their explorations, others were more focused on clusters.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p9">
<p class="ltx_p" id="S4.SS3.SSS2.p9.1">The tasks in the structured exploration focused on our motivating uses: discovering candidate documents, rapidly assessing relevance, finding terms for search iteration, and identifying relevant map regions. However, observing unstructured explorations we saw a broader range of exploratory search behavior, including interesting ways to use the tools of our system to support it.
We observed participants discovering far more than documents (and terms to use in searching): they found topics and themes they were unaware of, unexpected groups in the literature (e.g., “I never expected so many papers about…”), and connections that surprised them.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p10">
<p class="ltx_p" id="S4.SS3.SSS2.p10.1">Even in the short sessions of the controlled studies, we observed emergent behaviors and a variety of exploratory goals beyond our prompts. While hard to quantify, we view it as reassuring evidence that the flexibility of our approach achieves its goals. In the first hour of working with the system, users do not have sufficient opportunity to learn to work with all of the tools it provides. We noted a pattern that many participants sought to gain familiarity with the system and corpus by looking for familiar terms and documents. In the process, they both built trust by seeing expected items and often discovered things.
In less structured observations with longer-term users, we (anecdotally) observe more advanced usages.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Experience with our prototype suggests that our target audience of researchers can apply our prototype system for real applications. Users interleave a variety of exploratory search objectives while working with a corpus. They discover documents by iteratively posing queries, assessing the relevance of the outcomes and learning about the corpus to improve their search, while also learning about the domain, the terms used, and the corpus. They use our variety of views, applying standard TCE tools with enhancements. They use post hoc explanations and comparison features to mix views at different scales.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">However, our initial experience with the prototype also exposes limitations such as:</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><em class="ltx_emph ltx_font_italic" id="S5.p3.1.1">Evaluation:</em> The success of target users applying our methods in TCE provides an initial validation of our approach. However, more detailed evaluation will be valuable in understanding the trade-offs between system complexity, flexibility and automation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p4">
<p class="ltx_p" id="S5.p4.1"><em class="ltx_emph ltx_font_italic" id="S5.p4.1.1">Usability:</em> Our approach is based on providing users with flexibility. However, this requires them to make many choices.
Strategies to combat the complexity include reasonable defaults, automated guidance (e.g., assistance in selecting options to achieve tasks), and culling seldom used options.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p5">
<span class="ltx_ERROR undefined" id="S5.p5.1">\added</span>
<p class="ltx_p" id="S5.p5.2"><em class="ltx_emph ltx_font_italic" id="S5.p5.2.1">Workflow Support:</em> AbstractsViewer does not provide explicit support for important aspects of workflows. For example, identified regions and groupings must be remembered by the user. Prior systems, such as Serendip <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib8" title="">8</a>]</cite> show how this can be supported with persistent annotations. Similarly, comparisons between regions rely on manual temporal juxtaposition. Systems such as EmbComp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib81" title="">81</a>]</cite> provide examples of how this can be better supported.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p6">
<p class="ltx_p" id="S5.p6.1"><em class="ltx_emph ltx_font_italic" id="S5.p6.1.1">Metadata:</em> AbstractsViewer focuses content-based tools to better explore their issues. Integrating with meta-data and citation-based exploration would be a valuable extension.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p7">
<p class="ltx_p" id="S5.p7.1"><em class="ltx_emph ltx_font_italic" id="S5.p7.1.1">Implementation:</em> AbstractsViewer is a prototype that may not scale to a robust deployment for many simultaneous users.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p8">
<p class="ltx_p" id="S5.p8.1"><em class="ltx_emph ltx_font_italic" id="S5.p8.1.1">Scalability:</em> Our system performs well on corpora of tens of thousands of short documents on modest hardware. However, larger corpora, strain the system in terms of performance (speed) and usability. Recent systems, such as Cartolabe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib7" title="">7</a>]</cite> and Vitality <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib5" title="">5</a>]</cite> provide examples of how TCE systems can be made to perform on larger corpora. Improved views will be required to operate at larger scales; lists, matrices and scatterplots become unusable with hundreds or thousands of documents in a region. Handling longer documents will require improved methods for showing similarity and salience words.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p9">
<p class="ltx_p" id="S5.p9.1"><em class="ltx_emph ltx_font_italic" id="S5.p9.1.1">Automated Analysis:</em> AbstractsViewer requires manual identification of summary structures such as clusters and topics. Integrating automated tools will raise new usability and interpretability challenges.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p10">
<p class="ltx_p" id="S5.p10.1"><em class="ltx_emph ltx_font_italic" id="S5.p10.1.1">Reliability of Post Hoc Strategies:</em> Post hoc explanations rely on the existence of, and the ability of algorithms to find, interpretable explanations of potentially complex things. There may be no simple explanation for why two documents are considered similar, or the surface level similarities may not be meaningful.
In practice, we believe the post hoc strategy often provides utility,
future studies should assess whether poor explanations are a distraction.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p11">
<p class="ltx_p" id="S5.p11.1"><em class="ltx_emph ltx_font_italic" id="S5.p11.1.1">Limited flexibility of regions:</em> The “regional scale” (a group of documents that is thought to be related) is valuable in exploration, but has limited implementation in our system.
<span class="ltx_ERROR undefined" id="S5.p11.1.2">\replaced</span>We seek to provide better interfaces for manually defining regions (both geometrically and as sets) and to integrate automation for region finding.
In the future we will seek to provide convenient interfaces for manually defining regions (both geometrically and as sets) and uses this as an opportunity for integration with automation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p12">
<span class="ltx_ERROR undefined" id="S5.p12.1">\added</span>
<p class="ltx_p" id="S5.p12.2"><em class="ltx_emph ltx_font_italic" id="S5.p12.2.1">Impact of multiple recommendation lists:</em> The use of multi-list recommendations is known to have benefits and costs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib58" title="">58</a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib59" title="">59</a>]</cite> including positive and negative effects on trust <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib54" title="">54</a>]</cite>. In the future, we will seek to balance the diversity and contrast with the extra user effort.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p13">
<p class="ltx_p" id="S5.p13.1"><span class="ltx_text ltx_font_bold" id="S5.p13.1.1">Reflections:</span>
In this paper, we have explored the use of post hoc explanations and comparison to enhance existing tools for text corpus exploration. While our approach has been prototyped in the AbstractsViewer system, we note some general themes that extend beyond our system and possibly beyond text applications. The varied nature of exploratory search suggests that users need to be supported in the iterative process of document discovery (including assessment and query refinement), but they also need support for the learning aspects of exploration. This variety of objectives occurs at a variety of scales, suggesting that supporting the multiscale nature of exploration is important. While different tools and views operate at specific scales, explanations and comparisons provide ways to link these scales. While TCE tools, such as recommendations and maps, provide value on their own, their value is enhanced by providing post hoc explanations that help connect across scales and between items and terms. These post hoc explanations can be created in a flexible, multiscale manner by defining salience functions that can be applied to different sets and used by different views.</p>
</div>
<div class="ltx_para" id="S5.p14">
<p class="ltx_p" id="S5.p14.1">Initially, we attempted to define a concrete list of specific tasks, and to <span class="ltx_ERROR undefined" id="S5.p14.1.1">\added</span>create a design to support these tasks. However, in practice we observed a much broader and unexpected range of user objectives and strategies, as the exploratory search literature might have predicted. We believe (and our study suggests) that our system supports key specific objectives, such as enabling document identification and assessment or term refinement. However, we also believe that the flexibility to adapt to the broad range of user objectives and workflows is a more important benefit of our approach, and is evident in our examples and study.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p15">
<p class="ltx_p" id="S5.p15.1"><span class="ltx_text ltx_font_bold" id="S5.p15.1.1">Conclusion:</span>
Our work has explored how a TCE system can support a range of exploratory objectives in text corpus exploration. By enhancing maps and recommendations with explanations and comparisons, these tools can connect across scales and between documents and terms. We introduced salience functions as an approach to flexible post hoc explanations that work across scales and item types. We used these ideas to enhance standard views so they better support exploratory tasks and to integrate among views at different scales. Experience with a prototype implementation suggests that users can employ this flexibility to achieve a variety of exploratory goals.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>This work was supported in part by NSF Award 2007436.


</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
R. White and R. Roth, <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Exploratory Search: Beyond the Query-Response
Paradigm</em>.   Springer, 01 2009, vol. 1.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Soufan, I. Ruthven, and L. Azzopardi, “Searching the Literature: An
Analysis of an Exploratory Search Task,” in <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the
2022 Conference on Human Information Interaction and Retrieval</em>,
ser. CHIIR ’22.   New York, NY,
USA: Association for Computing Machinery, Mar. 2022, pp. 146–157.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Rind, W. Aigner, M. Wagner, S. Miksch, and T. Lammarsch, “Task Cube:
A three-dimensional conceptual space of user tasks in visualization
design and evaluation,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Information Visualization</em>, vol. 15, no. 4,
pp. 288–300, Oct. 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Thudt, U. Hinrichs, and S. Carpendale, “The bohemian bookshelf,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 2012 ACM Annual Conference on Human Factors
in Computing Systems - CHI ’12</em>.   New York, New York, USA: ACM Press, 2012, p. 1461.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Narechania, A. Karduni, R. Wesslen, and E. Wall, “VITALITY: Promoting
Serendipitous Discovery of Academic Literature with Transformers
amp; Visual Analytics,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IEEE Transactions on Visualization and
Computer Graphics</em>, vol. 28, no. 1, pp. 486–496, Jan. 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Wise, J. Thomas, K. Pennock, D. Lantrip, M. Pottier, A. Schur, and V. Crow,
“Visualizing the non-visual: Spatial analysis and interaction with
information from text documents,” in <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of Visualization
1995 Conference</em>.   IEEE Comput.
Soc. Press, 1995, pp. 51–58,.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
P. Caillou, J. Renault, J.-D. Fekete, A.-C. Letournel, and M. Sebag,
“Cartolabe: A Web-Based Scalable Visualization of Large Document
Collections,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">IEEE Computer Graphics and Applications</em>, vol. 41,
no. 2, pp. 76–88, Mar. 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
E. Alexander, J. Kohlmann, R. Valenza, M. Witmore, and M. Gleicher, “Serendip:
Topic model-driven visual exploration of text corpora,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">2014
IEEE Conference on Visual Analytics Science and Technology
(VAST)</em>.   IEEE, Oct. 2014, pp.
173–182.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
E. Isaacs, K. Damico, S. Ahern, E. Bart, and M. Singhal, “Footprints: A
Visual Search Tool that Supports Discovery and Coverage Tracking,”
<em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 20,
no. 12, pp. 1793–1802, Dec. 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
P. Federico, F. Heimerl, S. Koch, and S. Miksch, “A Survey on Visual
Approaches for Analyzing Scientific Literature and Patents,”
<em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">IEEE Transactions on Visualization and Computer Graphics</em>, vol. 23,
no. 9, pp. 2179–2198, Sep. 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K. Kucher and A. Kerren, “Text visualization techniques: Taxonomy, visual
survey, and community insights,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">2015 IEEE Pacific Visualization
Symposium (PacificVis)</em>, Apr. 2015, pp. 117–121.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
G. Marchionini, “Exploratory search: From finding to understanding,”
<em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Communications of the ACM</em>, vol. 49, no. 4, pp. 41–46, Apr. 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. Kairam, N. H. Riche, S. Drucker, R. Fernandez, and J. Heer, “Refinery:
Visual Exploration of Large, Heterogeneous Networks through
Associative Browsing,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Computer Graphics Forum</em>, vol. 34, no. 3,
pp. 301–310, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. Dörk, N. Henry Riche, G. Ramos, and S. Dumais, “PivotPaths:
Strolling through Faceted Information Spaces,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">IEEE
Transactions on Visualization and Computer Graphics</em>, vol. 18, no. 12, pp.
2709–2718, Dec. 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
P. André, m. schraefel, J. Teevan, and S. T. Dumais, “Discovery is never
by chance: Designing for (un)serendipity,” in <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the
Seventh ACM Conference on Creativity and Cognition</em>, ser.
C&amp;amp;C ’09.   New York, NY, USA:
Association for Computing Machinery, Oct. 2009, pp. 305–314.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
H. Lee, J. Kihm, J. Choo, J. Stasko, and H. Park, “iVisClustering: An
Interactive Visual Document Clustering via Topic Modeling,”
<em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Computer Graphics Forum</em>, vol. 31, no. 3pt3, pp. 1155–1164, Jun. 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
S. Liu, M. X. Zhou, S. Pan, Y. Song, W. Qian, W. Cai, and X. Lian, “TIARA:
Interactive, Topic-Based Visual Text Summarization and
Analysis,” <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">ACM Transactions on Intelligent Systems and
Technology</em>, vol. 3, no. 2, pp. 25:1–25:28, Feb. 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. El-Assady, F. Sperrle, R. Sevastjanova, M. Sedlmair, and D. Keim,
“LTMA: Layered Topic Matching for the Comparative Exploration,
Evaluation, and Refinement of Topic Modeling Results,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">2018 International Symposium on Big Data Visual and Immersive
Analytics (BDVA)</em>.   IEEE, Oct.
2018, pp. 1–10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
M. Brehmer, S. Ingram, J. Stray, and T. Munzner, “Overview: The Design,
Adoption, and Analysis of a Visual Document Mining Tool for
Investigative Journalists,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">IEEE Transactions on Visualization and
Computer Graphics</em>, vol. 20, no. 12, pp. 2271–2280, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
W. Dou and S. Liu, “Topic- and Time-Oriented Visual Text Analysis,”
<em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">IEEE Computer Graphics and Applications</em>, vol. 36, no. 4, pp. 8–13,
Jul. 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Chuang, D. Ramage, C. Manning, and J. Heer, “Interpretation and trust:
Designing model-driven visualizations for text analysis,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems</em>, ser. CHI ’12.   New York, NY, USA: Association for Computing Machinery, May
2012, pp. 443–452.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. Dattolo, M. Corbatto, and M. Angelini, “Authoring and Reviewing
Bibliographies: Design and Development of a Visual Analytics
Online Platform,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">IEEE Access</em>, vol. 10, pp. 21 631–21 645, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
IEEE, “IEEE Xplore.” [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ieeexplore.ieee.org" title="">https://ieeexplore.ieee.org</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
National Library of Medicine, “PubMed.” [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pubmed.ncbi.nlm.nih.gov/" title="">https://pubmed.ncbi.nlm.nih.gov/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Allen Institute for Artificial Intelligence, “Semantic Scholar,” 2021.
[Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.semanticscholar.org" title="">https://www.semanticscholar.org</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
F. Beck and C. Krause, “Visually Explaining Publication Ranks in
Citation-based Literature Search with PURE Suggest,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">EuroVis Posters Proceedings</em>.   Rome: The Eurographics Association, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
W. H. Gomaa and A. A. Fahmy, “A Survey of Text Similarity
Approaches,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">International Journal of Computer Applications</em>,
vol. 68, no. 13, pp. 13–18, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
D. Witschard, I. Jusufi, R. M. Martins, K. Kucher, and A. Kerren, “Interactive
optimization of embedding-based text similarity calculations,”
<em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Information Visualization</em>, p. 14738716221114372, Aug. 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
T. Crnovrsanin, I. Liao, Y. Wu, and K.-L. Ma, “Visual Recommendations for
Network Navigation,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Computer Graphics Forum</em>, vol. 30, no. 3, pp.
1081–1090, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
D. Parra, P. Brusilovsky, and C. Trattner, “See what you want to see,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 19th International Conference on Intelligent User
Interfaces - IUI ’14</em>.   New
York, New York, USA: ACM Press, 2014, pp. 235–240.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
S. Kaski, T. Honkela, K. Lagus, and T. Kohonen, “WEBSOM –
Self-organizing maps of document collections11This work was supported
by the Academy of Finland.” <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Neurocomputing</em>, vol. 21, no. 1,
pp. 101–117, Nov. 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
F. Heimerl, M. John, Q. Han, S. Koch, and T. Ertl, “DocuCompass:
Effective exploration of document landscapes,” in <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">2016 IEEE
Conference on Visual Analytics Science and Technology (VAST)</em>,
Oct. 2016, pp. 11–20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
A. Nocaj and U. Brandes, “Organizing Search Results with a Reference
Map,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">IEEE Transactions on Visualization and Computer Graphics</em>,
vol. 18, no. 12, pp. 2546–2555, Dec. 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
E. Hetzler and A. Turner, “Analysis experiences using information
visualization,” <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">IEEE Computer Graphics and Applications</em>, vol. 24,
no. 5, pp. 22–26, Sep. 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
J. Choo, C. Lee, C. K. Reddy, and H. Park, “UTOPIAN: User-driven topic
modeling based on interactive nonnegative matrix factorization.” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">IEEE
transactions on visualization and computer graphics</em>, vol. 19, no. 12, pp.
1992–2001, Dec. 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Q. Han, M. John, S. Koch, I. Assenov, and T. Ertl, “LabelTransfer -
Integrating Static and Dynamic Label Representation for
Focus+Context Text Exploration,” in <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">2018 International
Symposium on Big Data Visual and Immersive Analytics (BDVA)</em>,
Oct. 2018, pp. 1–8.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
E. Kandogan, “Just-in-Time Annotation of Clusters, Outliers, and
Trends in Point-based Data Visualizations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">2012 IEEE
Conference on Visual Analytics Science and Technology (VAST)</em>,
2012, pp. 73–82.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
R. R. O. da Silva, P. E. Rauber, R. M. Martins, R. Minghim, and A. C. Telea,
“Attribute-based Visual Explanation of Multidimensional
Projections,” in <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">EuroVis Workshop on Visual Analytics
(EuroVA)</em>.   The Eurographics
Association, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
D. Park, S. Kim, J. Lee, J. Choo, N. Diakopoulos, and N. Elmqvist,
“ConceptVector: Text Visual Analytics via Interactive Lexicon
Building using Word Embedding,” <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">IEEE Transactions on
Visualization and Computer Graphics</em>, vol. 24, no. 1, pp. 361–370, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
F. Heimerl, S. Koch, H. Bosch, and T. Ertl, “Visual Classifier Training
for Text Document Retrieval,” <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">IEEE Transactions on Visualization
and Computer Graphics</em>, vol. 18, no. 12, pp. 2839–2848, Dec. 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
B. Zimmer, M. Sahlgren, and A. Kerren, “Visual Analysis of
Relationships between Heterogeneous Networks and Texts: An
Application on the IEEE VIS Publication Dataset,” <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Informatics</em>,
vol. 4, no. 2, p. 11, Jun. 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
M. Du, N. Liu, and X. Hu, “Techniques for interpretable machine learning,”
<em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Communications of the ACM</em>, vol. 63, no. 1, pp. 68–77, Dec. 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
W. J. Murdoch, C. Singh, K. Kumbier, R. Abbasi-Asl, and B. Yu, “Definitions,
methods, and applications in interpretable machine learning,”
<em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the National Academy of Sciences</em>, vol. 116, no. 44, pp.
22 071–22 080, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
M. Gleicher, “A Framework for Considering Comprehensibility in
Modeling,” <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Big Data</em>, vol. 4, no. 2, pp. 75–88, Jun. 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
A. Barredo Arrieta, N. Díaz-Rodríguez, J. Del Ser, A. Bennetot,
S. Tabik, A. Barbado, S. Garcia, S. Gil-Lopez, D. Molina, R. Benjamins,
R. Chatila, and F. Herrera, “Explainable Artificial Intelligence
(XAI): Concepts, taxonomies, opportunities and challenges toward
responsible AI,” <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Information Fusion</em>, vol. 58, pp. 82–115, Jun.
2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
C. Molnar, <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Interpretable Machine Learning</em>.   Web published (LeanPub), 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
M. Craven, “Extracting Comprehensible Models from Trained Neural
Networks,” Ph.D. dissertation, University of Wisconsin - Madison, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
M. T. Ribeiro, S. Singh, and C. Guestrin, ““Why Should I Trust You?”:
Explaining the Predictions of Any Classifier,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the 22nd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining - KDD ’16</em>.   New York, New York, USA: ACM Press, Feb. 2016,
pp. 1135–1144.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
S. M. Lundberg and S.-I. Lee, “A unified approach to interpreting model
predictions,” in <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the 31st International Conference
on Neural Information Processing Systems</em>, ser. NIPS’17.   Red Hook, NY, USA: Curran Associates Inc.,
Dec. 2017, pp. 4768–4777.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
H. Chen, G. Zheng, and Y. Ji, “Generating Hierarchical Explanations on
Text Classification via Feature Interaction Detection,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics</em>.   Online: Association for Computational Linguistics, Jul. 2020, pp.
5578–5593.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
K. Lee, A. Sood, and M. Craven, “Understanding Learned Models by
Identifying Important Features at the Right Resolution,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">AAAI</em>, Nov. 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
J. L. Herlocker, J. A. Konstan, and J. Riedl, “Explaining collaborative
filtering recommendations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 2000 ACM
Conference on Computer Supported Cooperative Work - CSCW ’00</em>.   New York, New York, USA: ACM Press,
2000, pp. 241–250.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
R. Sinha and K. Swearingen, “The role of transparency in recommender
systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">CHI ’02 Extended Abstracts on Human Factors
in Computing Systems</em>, ser. CHI EA ’02.   New York, NY, USA: Association for Computing Machinery, 2002,
pp. 830–831.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
P. Pu and L. Chen, “Trust-inspiring explanation interfaces for recommender
systems,” <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Knowledge-Based Systems</em>, vol. 20, no. 6, pp. 542–556, Aug.
2007.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
N. Tintarev and J. Masthoff, “Designing and Evaluating Explanations for
Recommender Systems,” in <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Recommender Systems Handbook</em>,
F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, Eds.   Boston, MA: Springer US, 2011, pp. 479–510.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
T. N. T. Tran, V. M. Le, M. Atas, A. Felfernig, M. Stettinger, and A. Popescu,
“Do Users Appreciate Explanations of Recommendations? An
Analysis in the Movie Domain,” in <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Fifteenth ACM Conference
on Recommender Systems</em>.   New
York, NY, USA: Association for Computing Machinery, Sep. 2021, pp.
645–650.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Y. Zhang and X. Chen, “Explainable Recommendation: A Survey and New
Perspectives,” <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Foundations and Trends® in
Information Retrieval</em>, vol. 14, no. 1, pp. 1–101, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
D. Jannach, M. Jesse, M. Jugovac, and C. Trattner, “Exploring Multi-List
User Interfaces for Similar-Item Recommendations,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Proceedings of the 29th ACM Conference on User Modeling,
Adaptation and Personalization</em>, ser. UMAP ’21.   New York, NY, USA: Association for Computing
Machinery, Jun. 2021, pp. 224–228.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
A. D. Starke, E. Asotic, C. Trattner, and E. J. Van Loo, “Examining the User
Evaluation of Multi-List Recommender Interfaces in the Context of
Healthy Recipe Choices,” <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">ACM Transactions on Recommender Systems</em>,
vol. 1, no. 4, pp. 18:1–18:31, Nov. 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
K. Sparck Jones, “A Statistical Interpretation Of Term Specificity and its
Application in Retrieval,” <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Journal of Documentation</em>, vol. 28,
no. 1, pp. 11–21, 1972.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
S. Robertson, “Understanding inverse document frequency: On theoretical
arguments for IDF,” <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Journal of Documentation</em>, vol. 60, no. 5, pp.
503–520, Jan. 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
A. Cohan, S. Feldman, I. Beltagy, D. Downey, and D. Weld, “SPECTER:
Document-level Representation Learning using Citation-informed
Transformers,” in <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics</em>.   Online: Association for Computational Linguistics,
2020, pp. 2270–2282.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
J. M. Jachimowicz, S. Duncan, E. U. Weber, and E. J. Johnson, “When and why
defaults influence decisions: A meta-analysis of default effects,”
<em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Behavioural Public Policy</em>, vol. 3, no. 2, pp. 159–186, Nov. 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
P. Lipton, “Contrastive Explanation,” <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Royal Institute of Philosophy
Supplements</em>, vol. 27, pp. 247–266, Mar. 1990.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
K. S. Hasan and V. Ng, “Automatic Keyphrase Extraction: A Survey of
the State of the Art,” in <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Proceedings of the 52nd Annual
Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers)</em>.   Baltimore, Maryland: Association for Computational Linguistics, Jun.
2014, pp. 1262–1273.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
P. Rayson and R. Garside, “Comparing corpora using frequency profiling,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">Proceedings of the Workshop on Comparing Corpora - Volume 9</em>,
ser. WCC ’00.   USA: Association
for Computational Linguistics, Oct. 2000, pp. 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
P. Atanasova, J. G. Simonsen, C. Lioma, and I. Augenstein, “A Diagnostic
Study of Explainability Techniques for Text Classification,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>.   Online: Association for Computational Linguistics, Nov. 2020,
pp. 3256–3274.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
A. Ali, T. Schnake, O. Eberle, G. Montavon, K.-R. Müller, and L. Wolf,
“XAI for Transformers: Better Explanations through
Conservative Propagation,” <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">arXiv:2202.07304 [cs]</em>, Feb. 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
G. W. Furnas, “Generalized fisheye views,” in <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems - CHI
’86</em>.   Boston, Massachusetts, United
States: ACM Press, 1986, pp. 16–23.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
S. Koch, M. John, M. Wörner, A. Müller, and T. Ertl,
“VarifocalReader — In-Depth Visual Analysis of Large
Text Documents,” <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">IEEE Transactions on Visualization and Computer
Graphics</em>, vol. 20, no. 12, pp. 1723–1732, Dec. 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
M. Correll, M. Witmore, and M. Gleicher, “Exploring Collections of
Tagged Text for Literary Scholarship,” <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">Computer Graphics
Forum</em>, vol. 30, no. 3, pp. 731–740, Jun. 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
F. Heimerl, C.-C. Chang, A. Sarikaya, and M. Gleicher, “Visual Designs for
Binned Aggregation of Multi-Class Scatterplots,”
<em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">arXiv:1810.02445 [cs]</em>, Jan. 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
T. Castermans, K. Verbeek, B. Speckmann, M. A. Westenberg, R. Koopman, S. Wang,
H. van den Berg, and A. Betti, “SolarView: Low Distortion Radial
Embedding with a Focus,” <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">IEEE Transactions on Visualization and
Computer Graphics</em>, vol. 25, no. 10, pp. 2969–2982, Oct. 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
M. A. Correll, E. C. Alexander, and M. Gleicher, “Quantity estimation in
visualizations of tagged text,” in <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems - CHI
’13</em>.   New York, New York, USA: ACM
Press, 2013, p. 2697.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
E. C. Alexander, C.-C. Chang, M. Shimabukuro, S. Franconeri, C. Collins, and
M. Gleicher, “Perceptual Biases in Font Size as a Data
Encoding,” <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">IEEE Transactions on Visualization and Computer
Graphics</em>, vol. 24, no. 8, pp. 2397–2410, Aug. 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
M. Chaput, “Whoosh 2.7.4 documentation,” 2021. [Online]. Available:
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://whoosh.readthedocs.io/en/latest/index.html" title="">https://whoosh.readthedocs.io/en/latest/index.html</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">et al.</em>,
“Scikit-learn: Machine learning in python,” <em class="ltx_emph ltx_font_italic" id="bib.bib77.2.2">the Journal of machine
Learning research</em>, vol. 12, pp. 2825–2830, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
E. Loper and S. Bird, “NLTK: The Natural Language Toolkit,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">Proceedings of the ACL-02 Workshop on Effective Tools and
Methodologies for Teaching Natural Language Processing and Computational
Linguistics - Volume 1</em>, ser. ETMTNLP ’02.   USA: Association for Computational Linguistics, 2002, pp.
63–70.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
E. Sandhaus, “The new york times annotated corpus,” <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">Linguistic Data
Consortium, Philadelphia</em>, vol. 6, no. 12, p. e26752, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
J. Brooke, “SUS: A retrospective,” <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">Journal of Usability Studies</em>,
vol. 8, no. 2, pp. 29–40, Feb. 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
F. Heimerl, C. Kralj, T. Möller, and M. Gleicher, “embComp: Visual
Interactive Comparison of Vector Embeddings,” <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">IEEE Transactions
on Visualization and Computer Graphics</em>, vol. Early Access, no. Accepted, to
appear, Dec. 2020.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Quantitative Details</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">This appendix provides quantitative details to support points in the paper.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Usability Assessment</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">AbstractsViewer is a prototype meant to explore the our approach of post hoc explanations and comparison. As a prototype, and as a tool targeting expert users, a polished interface was not a primary concern. However, we did assess system usability through a system-level evaluation.</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">A System Usability Scale (SUS) survey is a standard
approach to system evaluation with 10 standardized questions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib80" title="">80</a>]</cite>. A SUS survey was conducted as part of our user study
detailed in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S4.SS3" title="4.3 User Studies ‣ 4 Assessment ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 4.3</span></a>. Each of the 12 subjects completed the survey after completing their work with the system. The specific prompts used in the SUS survey and aggregated results are shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#A1.F6" title="Figure 6 ‣ A.2 Nearest-Neighbor Overlaps ‣ Appendix A Quantitative Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 6</span></a>.
We reverse the score of negative questions (so zero is the worst score for any question).
The standard scoring method gives a score of 74.17 which is slightly above average. We feel this is acceptable given the prototype nature of the system and target of an experienced audience of researchers who can invest the time to learn the tools. The results suggest that our participants appreciate the system and thought they would use it. They also acknowledged its complexity; AbstractsViewer does take time to learn. However, even in the limited time, users discovered complex (and unexpected) workflows.
</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Nearest-Neighbor Overlaps</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">In <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#S2.SS1" title="2.1 Similarity and Layout ‣ 2 Methods and Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Sec. 2.1</span></a> we note that the two provided embeddings are different. To quanitify this we computed the overlap for the top nearest neighbors over the entire corpus (here we report the Visualization corpus). <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#A1.F7" title="Figure 7 ‣ A.2 Nearest-Neighbor Overlaps ‣ Appendix A Quantitative Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 7</span></a>A shows for the top 10 nearest TF-IDF neighbors how many appear in the top <math alttext="n" class="ltx_Math" display="inline" id="A1.SS2.p1.1.m1.1"><semantics id="A1.SS2.p1.1.m1.1a"><mi id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.1b"><ci id="A1.SS2.p1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.1.m1.1d">italic_n</annotation></semantics></math> list of the Specter list. The leftmost bar indicates that the top 2 Specter match (list of length 2) overlaps with only 0.47 of the top 10 TF-IDF documents on average. For the nearest neighbor (list of length one) the value is zero (indicating that the nearest Specter neighbor never appears in the top-10 list of TF-IDF). The rightmost bar of the chart indicates that the average overlap between the top 10 TF-IDF and top 100 Specter documents is 4.77, that is, on average, less than half of the top 10 recommendations appear in the top-100 list of the other metric.
The lack of overlap may have positive benefits in terms of deduplication <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib58" title="">58</a>]</cite> and providing diversity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib54" title="">54</a>]</cite> but mixed impact on trust <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.09686v1#bib.bib54" title="">54</a>]</cite>.</p>
</div>
<div class="ltx_para" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1">We tried to assess word matching explanations for nearest neighbors in cases where they are not causal. For TDIDF, similarity is caused by matching words, whereas for Specter matching contributes indirectly. <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2406.09686v1#A1.F7" title="Figure 7 ‣ A.2 Nearest-Neighbor Overlaps ‣ Appendix A Quantitative Details ‣ Enhancing Text Corpus Exploration with Post Hoc Explanations and Comparative Design"><span class="ltx_text ltx_ref_tag">Fig. 7</span></a>B shows results of an experiment with average word overlaps for neighbors across the visualization corpus. We see that TF-IDF and Specter neighbors share similar numbers of words, and that the number of shared words decreases for weaker matches (more distant neighbors).</p>
</div>
<figure class="ltx_figure" id="A1.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="140" id="A1.F6.g1" src="extracted/5660384/Figures/appendix/sus_scores.png" width="568"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="A1.F6.2">;</p>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F6.3.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="A1.F6.4.2" style="font-size:90%;">The SUS scores across prompts present in the user study. Numbers are in a 0-4 range and negated for negative prompts such that zero is always the worst.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A1.F7"><svg class="ltx_picture" height="156.57" id="A1.F7.pic1" overflow="visible" version="1.1" width="568"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,156.57) matrix(1 0 0 -1 0 0) translate(-0.28,0) translate(0,7.29)"><g fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 0.28 0.28)"><foreignobject height="149" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="568"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="149" id="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.g1" src="extracted/5660384/Figures/appendix/embedding_overlap.png" width="568"/></foreignobject></g><path d="M 11.37 2.99" style="fill:none"></path><g fill="#FF0000"><path d="M 20.23 2.99 C 20.23 7.88 16.27 11.85 11.37 11.85 C 6.48 11.85 2.52 7.88 2.52 2.99 C 2.52 -1.9 6.48 -5.87 11.37 -5.87 C 16.27 -5.87 20.23 -1.9 20.23 2.99 Z M 11.37 2.99" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 5.15 -2.68)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="12.45"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.F7.pic1.2.2.2.1.1" style="font-size:120%;">A</span></foreignobject></g><path d="M 352.5 2.99" style="fill:none"></path><g fill="#FF0000"><path d="M 361.36 2.99 C 361.36 7.88 357.39 11.85 352.5 11.85 C 347.61 11.85 343.64 7.88 343.64 2.99 C 343.64 -1.9 347.61 -5.87 352.5 -5.87 C 357.39 -5.87 361.36 -1.9 361.36 2.99 Z M 352.5 2.99" style="stroke:none"></path></g><g fill="#FFFFFF" stroke="#FFFFFF" transform="matrix(1.0 0.0 0.0 1.0 346.62 -2.68)"><foreignobject color="#FFFFFF" height="11.35" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="11.76"><span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.F7.pic1.3.3.3.1.1" style="font-size:120%;">B</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F7.6.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="A1.F7.7.2" style="font-size:90%;">
<span class="ltx_ERROR undefined" id="A1.F7.7.2.1">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.F7.7.2.2">A</span> The average number of documents present in both the top 10 similar documents provided by TF-IDF and the top M similar documents provided by Specter.
<span class="ltx_ERROR undefined" id="A1.F7.7.2.3">\Circled</span>[fill color=red, outer color=red, inner color=white]<span class="ltx_text ltx_font_sansserif ltx_font_bold" id="A1.F7.7.2.4">B</span> The average percentages of shared words between documents and their top 10 most similar neighbors, as determined by both TF-IDF and Specter embeddings.
</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Jun 14 03:13:00 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
